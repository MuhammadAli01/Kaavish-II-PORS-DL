{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "train",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZhSsDYSf2L20",
    "colab_type": "code",
    "outputId": "25c0f9ec-d660-4c9f-ada3-5d5b23b82e82",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1589192274956,
     "user_tz": -300,
     "elapsed": 1110,
     "user": {
      "displayName": "Muhammad Ali",
      "photoUrl": "",
      "userId": "15673831022739340207"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "print('Hello world')\n",
    "import os\n",
    "# os.chdir('/content/drive/My Drive/Deep Fashion Retrieval/deep-fashion-retrieval')\n",
    "os.chdir(\"/home/ma02526/ResNet/deep-fashion-retrieval\")"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-JtZQgArAF9",
    "colab_type": "text"
   },
   "source": [
    "# Training with 26 most relevant categories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uoTUVg6grWZ0",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "outputId": "e68b2245-67c8-4f72-d1e2-4e9b1aa60bf4"
   },
   "source": [
    "# Freeze=True. LR=0.01. In-shop=False\n",
    "! python train.py"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Test() called at batch_idx: 0\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\r\n",
      "  warnings.warn(warning.format(ret))\r\n",
      "train.py:151: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 3.5236, Accuracy: 11/480 (2%)\r\n",
      "\r\n",
      "Train Epoch: 1 [0/110534 (0%)]\tClassification Loss: 3.2969\r\n",
      "Train Epoch: 1 [160/110534 (0%)]\tClassification Loss: 3.0659\r\n",
      "Train Epoch: 1 [320/110534 (0%)]\tClassification Loss: 2.9615\r\n",
      "Train Epoch: 1 [480/110534 (0%)]\tClassification Loss: 2.6653\r\n",
      "Train Epoch: 1 [640/110534 (1%)]\tClassification Loss: 2.6252\r\n",
      "Train Epoch: 1 [800/110534 (1%)]\tClassification Loss: 2.2417\r\n",
      "Train Epoch: 1 [960/110534 (1%)]\tClassification Loss: 2.5429\r\n",
      "Train Epoch: 1 [1120/110534 (1%)]\tClassification Loss: 2.5760\r\n",
      "Train Epoch: 1 [1280/110534 (1%)]\tClassification Loss: 2.4223\r\n",
      "Train Epoch: 1 [1440/110534 (1%)]\tClassification Loss: 2.6371\r\n",
      "Test() called at batch_idx: 100\r\n",
      "\r\n",
      "Test set: Average loss: 2.5387, Accuracy: 148/480 (31%)\r\n",
      "\r\n",
      "Train Epoch: 1 [1600/110534 (1%)]\tClassification Loss: 2.1587\r\n",
      "Train Epoch: 1 [1760/110534 (2%)]\tClassification Loss: 2.5418\r\n",
      "Train Epoch: 1 [1920/110534 (2%)]\tClassification Loss: 2.6153\r\n",
      "Train Epoch: 1 [2080/110534 (2%)]\tClassification Loss: 2.1017\r\n",
      "Train Epoch: 1 [2240/110534 (2%)]\tClassification Loss: 2.6444\r\n",
      "Train Epoch: 1 [2400/110534 (2%)]\tClassification Loss: 2.4051\r\n",
      "Train Epoch: 1 [2560/110534 (2%)]\tClassification Loss: 2.7018\r\n",
      "Train Epoch: 1 [2720/110534 (2%)]\tClassification Loss: 2.1669\r\n",
      "Train Epoch: 1 [2880/110534 (3%)]\tClassification Loss: 2.1730\r\n",
      "Train Epoch: 1 [3040/110534 (3%)]\tClassification Loss: 2.4610\r\n",
      "Test() called at batch_idx: 200\r\n",
      "\r\n",
      "Test set: Average loss: 2.3728, Accuracy: 165/480 (34%)\r\n",
      "\r\n",
      "Train Epoch: 1 [3200/110534 (3%)]\tClassification Loss: 2.3149\r\n",
      "Train Epoch: 1 [3360/110534 (3%)]\tClassification Loss: 1.9114\r\n",
      "Train Epoch: 1 [3520/110534 (3%)]\tClassification Loss: 2.1777\r\n",
      "Train Epoch: 1 [3680/110534 (3%)]\tClassification Loss: 2.3133\r\n",
      "Train Epoch: 1 [3840/110534 (3%)]\tClassification Loss: 2.2975\r\n",
      "Train Epoch: 1 [4000/110534 (4%)]\tClassification Loss: 2.2020\r\n",
      "Train Epoch: 1 [4160/110534 (4%)]\tClassification Loss: 2.0489\r\n",
      "Train Epoch: 1 [4320/110534 (4%)]\tClassification Loss: 2.1067\r\n",
      "Train Epoch: 1 [4480/110534 (4%)]\tClassification Loss: 1.9963\r\n",
      "Train Epoch: 1 [4640/110534 (4%)]\tClassification Loss: 2.4135\r\n",
      "Test() called at batch_idx: 300\r\n",
      "\r\n",
      "Test set: Average loss: 2.2527, Accuracy: 187/480 (39%)\r\n",
      "\r\n",
      "Train Epoch: 1 [4800/110534 (4%)]\tClassification Loss: 2.1862\r\n",
      "Train Epoch: 1 [4960/110534 (4%)]\tClassification Loss: 2.3000\r\n",
      "Train Epoch: 1 [5120/110534 (5%)]\tClassification Loss: 2.0660\r\n",
      "Train Epoch: 1 [5280/110534 (5%)]\tClassification Loss: 2.1858\r\n",
      "Train Epoch: 1 [5440/110534 (5%)]\tClassification Loss: 2.1033\r\n",
      "Train Epoch: 1 [5600/110534 (5%)]\tClassification Loss: 1.9092\r\n",
      "Train Epoch: 1 [5760/110534 (5%)]\tClassification Loss: 2.4419\r\n",
      "Train Epoch: 1 [5920/110534 (5%)]\tClassification Loss: 2.5703\r\n",
      "Train Epoch: 1 [6080/110534 (6%)]\tClassification Loss: 2.1652\r\n",
      "Train Epoch: 1 [6240/110534 (6%)]\tClassification Loss: 2.3830\r\n",
      "Test() called at batch_idx: 400\r\n",
      "\r\n",
      "Test set: Average loss: 2.1616, Accuracy: 187/480 (39%)\r\n",
      "\r\n",
      "Train Epoch: 1 [6400/110534 (6%)]\tClassification Loss: 1.7787\r\n",
      "Train Epoch: 1 [6560/110534 (6%)]\tClassification Loss: 2.5037\r\n",
      "Train Epoch: 1 [6720/110534 (6%)]\tClassification Loss: 2.2618\r\n",
      "Train Epoch: 1 [6880/110534 (6%)]\tClassification Loss: 2.0024\r\n",
      "Train Epoch: 1 [7040/110534 (6%)]\tClassification Loss: 1.6972\r\n",
      "Train Epoch: 1 [7200/110534 (7%)]\tClassification Loss: 2.0974\r\n",
      "Train Epoch: 1 [7360/110534 (7%)]\tClassification Loss: 2.0651\r\n",
      "Train Epoch: 1 [7520/110534 (7%)]\tClassification Loss: 2.6964\r\n",
      "Train Epoch: 1 [7680/110534 (7%)]\tClassification Loss: 2.3692\r\n",
      "Train Epoch: 1 [7840/110534 (7%)]\tClassification Loss: 2.1243\r\n",
      "Test() called at batch_idx: 500\r\n",
      "\r\n",
      "Test set: Average loss: 2.0922, Accuracy: 213/480 (44%)\r\n",
      "\r\n",
      "Train Epoch: 1 [8000/110534 (7%)]\tClassification Loss: 1.6280\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_500.pth.tar\r\n",
      "Train Epoch: 1 [8160/110534 (7%)]\tClassification Loss: 2.2901\r\n",
      "Train Epoch: 1 [8320/110534 (8%)]\tClassification Loss: 2.0871\r\n",
      "Train Epoch: 1 [8480/110534 (8%)]\tClassification Loss: 1.6708\r\n",
      "Train Epoch: 1 [8640/110534 (8%)]\tClassification Loss: 2.1576\r\n",
      "Train Epoch: 1 [8800/110534 (8%)]\tClassification Loss: 2.0127\r\n",
      "Train Epoch: 1 [8960/110534 (8%)]\tClassification Loss: 2.1141\r\n",
      "Train Epoch: 1 [9120/110534 (8%)]\tClassification Loss: 1.7539\r\n",
      "Train Epoch: 1 [9280/110534 (8%)]\tClassification Loss: 2.1378\r\n",
      "Train Epoch: 1 [9440/110534 (9%)]\tClassification Loss: 2.4394\r\n",
      "Test() called at batch_idx: 600\r\n",
      "\r\n",
      "Test set: Average loss: 2.0233, Accuracy: 217/480 (45%)\r\n",
      "\r\n",
      "Train Epoch: 1 [9600/110534 (9%)]\tClassification Loss: 1.7765\r\n",
      "Train Epoch: 1 [9760/110534 (9%)]\tClassification Loss: 2.1906\r\n",
      "Train Epoch: 1 [9920/110534 (9%)]\tClassification Loss: 2.2306\r\n",
      "Train Epoch: 1 [10080/110534 (9%)]\tClassification Loss: 1.5481\r\n",
      "Train Epoch: 1 [10240/110534 (9%)]\tClassification Loss: 2.4804\r\n",
      "Train Epoch: 1 [10400/110534 (9%)]\tClassification Loss: 1.8190\r\n",
      "Train Epoch: 1 [10560/110534 (10%)]\tClassification Loss: 2.1906\r\n",
      "Train Epoch: 1 [10720/110534 (10%)]\tClassification Loss: 2.0478\r\n",
      "Train Epoch: 1 [10880/110534 (10%)]\tClassification Loss: 1.8112\r\n",
      "Train Epoch: 1 [11040/110534 (10%)]\tClassification Loss: 1.7860\r\n",
      "Test() called at batch_idx: 700\r\n",
      "\r\n",
      "Test set: Average loss: 1.9788, Accuracy: 229/480 (48%)\r\n",
      "\r\n",
      "Train Epoch: 1 [11200/110534 (10%)]\tClassification Loss: 2.1369\r\n",
      "Train Epoch: 1 [11360/110534 (10%)]\tClassification Loss: 2.0424\r\n",
      "Train Epoch: 1 [11520/110534 (10%)]\tClassification Loss: 2.6285\r\n",
      "Train Epoch: 1 [11680/110534 (11%)]\tClassification Loss: 2.1605\r\n",
      "Train Epoch: 1 [11840/110534 (11%)]\tClassification Loss: 2.2765\r\n",
      "Train Epoch: 1 [12000/110534 (11%)]\tClassification Loss: 1.8158\r\n",
      "Train Epoch: 1 [12160/110534 (11%)]\tClassification Loss: 2.0894\r\n",
      "Train Epoch: 1 [12320/110534 (11%)]\tClassification Loss: 1.9807\r\n",
      "Train Epoch: 1 [12480/110534 (11%)]\tClassification Loss: 2.0829\r\n",
      "Train Epoch: 1 [12640/110534 (11%)]\tClassification Loss: 1.6022\r\n",
      "Test() called at batch_idx: 800\r\n",
      "\r\n",
      "Test set: Average loss: 1.9232, Accuracy: 243/480 (51%)\r\n",
      "\r\n",
      "Train Epoch: 1 [12800/110534 (12%)]\tClassification Loss: 2.2310\r\n",
      "Train Epoch: 1 [12960/110534 (12%)]\tClassification Loss: 2.0193\r\n",
      "Train Epoch: 1 [13120/110534 (12%)]\tClassification Loss: 1.6470\r\n",
      "Train Epoch: 1 [13280/110534 (12%)]\tClassification Loss: 2.0093\r\n",
      "Train Epoch: 1 [13440/110534 (12%)]\tClassification Loss: 1.9636\r\n",
      "Train Epoch: 1 [13600/110534 (12%)]\tClassification Loss: 1.5849\r\n",
      "Train Epoch: 1 [13760/110534 (12%)]\tClassification Loss: 2.2068\r\n",
      "Train Epoch: 1 [13920/110534 (13%)]\tClassification Loss: 2.1071\r\n",
      "Train Epoch: 1 [14080/110534 (13%)]\tClassification Loss: 1.7273\r\n",
      "Train Epoch: 1 [14240/110534 (13%)]\tClassification Loss: 1.9912\r\n",
      "Test() called at batch_idx: 900\r\n",
      "\r\n",
      "Test set: Average loss: 1.8923, Accuracy: 264/480 (55%)\r\n",
      "\r\n",
      "Train Epoch: 1 [14400/110534 (13%)]\tClassification Loss: 1.6301\r\n",
      "Train Epoch: 1 [14560/110534 (13%)]\tClassification Loss: 1.5352\r\n",
      "Train Epoch: 1 [14720/110534 (13%)]\tClassification Loss: 1.4630\r\n",
      "Train Epoch: 1 [14880/110534 (13%)]\tClassification Loss: 1.6245\r\n",
      "Train Epoch: 1 [15040/110534 (14%)]\tClassification Loss: 1.5216\r\n",
      "Train Epoch: 1 [15200/110534 (14%)]\tClassification Loss: 2.2250\r\n",
      "Train Epoch: 1 [15360/110534 (14%)]\tClassification Loss: 1.3467\r\n",
      "Train Epoch: 1 [15520/110534 (14%)]\tClassification Loss: 1.4302\r\n",
      "Train Epoch: 1 [15680/110534 (14%)]\tClassification Loss: 2.0362\r\n",
      "Train Epoch: 1 [15840/110534 (14%)]\tClassification Loss: 1.9966\r\n",
      "Test() called at batch_idx: 1000\r\n",
      "\r\n",
      "Test set: Average loss: 1.8620, Accuracy: 266/480 (55%)\r\n",
      "\r\n",
      "Train Epoch: 1 [16000/110534 (14%)]\tClassification Loss: 1.5581\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1000.pth.tar\r\n",
      "Train Epoch: 1 [16160/110534 (15%)]\tClassification Loss: 2.1224\r\n",
      "Train Epoch: 1 [16320/110534 (15%)]\tClassification Loss: 3.0082\r\n",
      "Train Epoch: 1 [16480/110534 (15%)]\tClassification Loss: 2.0881\r\n",
      "Train Epoch: 1 [16640/110534 (15%)]\tClassification Loss: 1.9731\r\n",
      "Train Epoch: 1 [16800/110534 (15%)]\tClassification Loss: 1.7291\r\n",
      "Train Epoch: 1 [16960/110534 (15%)]\tClassification Loss: 1.7558\r\n",
      "Train Epoch: 1 [17120/110534 (15%)]\tClassification Loss: 1.9956\r\n",
      "Train Epoch: 1 [17280/110534 (16%)]\tClassification Loss: 1.7463\r\n",
      "Train Epoch: 1 [17440/110534 (16%)]\tClassification Loss: 1.2031\r\n",
      "Test() called at batch_idx: 1100\r\n",
      "\r\n",
      "Test set: Average loss: 1.8314, Accuracy: 256/480 (53%)\r\n",
      "\r\n",
      "Train Epoch: 1 [17600/110534 (16%)]\tClassification Loss: 2.1545\r\n",
      "Train Epoch: 1 [17760/110534 (16%)]\tClassification Loss: 2.0759\r\n",
      "Train Epoch: 1 [17920/110534 (16%)]\tClassification Loss: 1.7196\r\n",
      "Train Epoch: 1 [18080/110534 (16%)]\tClassification Loss: 1.3447\r\n",
      "Train Epoch: 1 [18240/110534 (17%)]\tClassification Loss: 2.0556\r\n",
      "Train Epoch: 1 [18400/110534 (17%)]\tClassification Loss: 1.9377\r\n",
      "Train Epoch: 1 [18560/110534 (17%)]\tClassification Loss: 1.9900\r\n",
      "Train Epoch: 1 [18720/110534 (17%)]\tClassification Loss: 2.4485\r\n",
      "Train Epoch: 1 [18880/110534 (17%)]\tClassification Loss: 1.9205\r\n",
      "Train Epoch: 1 [19040/110534 (17%)]\tClassification Loss: 2.0708\r\n",
      "Test() called at batch_idx: 1200\r\n",
      "\r\n",
      "Test set: Average loss: 1.8138, Accuracy: 271/480 (56%)\r\n",
      "\r\n",
      "Train Epoch: 1 [19200/110534 (17%)]\tClassification Loss: 1.6526\r\n",
      "Train Epoch: 1 [19360/110534 (18%)]\tClassification Loss: 1.6445\r\n",
      "Train Epoch: 1 [19520/110534 (18%)]\tClassification Loss: 1.6553\r\n",
      "Train Epoch: 1 [19680/110534 (18%)]\tClassification Loss: 2.3347\r\n",
      "Train Epoch: 1 [19840/110534 (18%)]\tClassification Loss: 1.8636\r\n",
      "Train Epoch: 1 [20000/110534 (18%)]\tClassification Loss: 2.0033\r\n",
      "Train Epoch: 1 [20160/110534 (18%)]\tClassification Loss: 1.7422\r\n",
      "Train Epoch: 1 [20320/110534 (18%)]\tClassification Loss: 1.9308\r\n",
      "Train Epoch: 1 [20480/110534 (19%)]\tClassification Loss: 1.6460\r\n",
      "Train Epoch: 1 [20640/110534 (19%)]\tClassification Loss: 1.6974\r\n",
      "Test() called at batch_idx: 1300\r\n",
      "\r\n",
      "Test set: Average loss: 1.7990, Accuracy: 264/480 (55%)\r\n",
      "\r\n",
      "Train Epoch: 1 [20800/110534 (19%)]\tClassification Loss: 1.9631\r\n",
      "Train Epoch: 1 [20960/110534 (19%)]\tClassification Loss: 1.5025\r\n",
      "Train Epoch: 1 [21120/110534 (19%)]\tClassification Loss: 1.7015\r\n",
      "Train Epoch: 1 [21280/110534 (19%)]\tClassification Loss: 1.8145\r\n",
      "Train Epoch: 1 [21440/110534 (19%)]\tClassification Loss: 1.7974\r\n",
      "Train Epoch: 1 [21600/110534 (20%)]\tClassification Loss: 1.7739\r\n",
      "Train Epoch: 1 [21760/110534 (20%)]\tClassification Loss: 1.7987\r\n",
      "Train Epoch: 1 [21920/110534 (20%)]\tClassification Loss: 2.1234\r\n",
      "Train Epoch: 1 [22080/110534 (20%)]\tClassification Loss: 1.5852\r\n",
      "Train Epoch: 1 [22240/110534 (20%)]\tClassification Loss: 1.8597\r\n",
      "Test() called at batch_idx: 1400\r\n",
      "\r\n",
      "Test set: Average loss: 1.7837, Accuracy: 276/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [22400/110534 (20%)]\tClassification Loss: 1.7622\r\n",
      "Train Epoch: 1 [22560/110534 (20%)]\tClassification Loss: 1.7152\r\n",
      "Train Epoch: 1 [22720/110534 (21%)]\tClassification Loss: 1.9796\r\n",
      "Train Epoch: 1 [22880/110534 (21%)]\tClassification Loss: 1.8828\r\n",
      "Train Epoch: 1 [23040/110534 (21%)]\tClassification Loss: 1.6494\r\n",
      "Train Epoch: 1 [23200/110534 (21%)]\tClassification Loss: 1.9146\r\n",
      "Train Epoch: 1 [23360/110534 (21%)]\tClassification Loss: 1.6754\r\n",
      "Train Epoch: 1 [23520/110534 (21%)]\tClassification Loss: 2.0041\r\n",
      "Train Epoch: 1 [23680/110534 (21%)]\tClassification Loss: 2.0247\r\n",
      "Train Epoch: 1 [23840/110534 (22%)]\tClassification Loss: 2.1661\r\n",
      "Test() called at batch_idx: 1500\r\n",
      "\r\n",
      "Test set: Average loss: 1.7575, Accuracy: 270/480 (56%)\r\n",
      "\r\n",
      "Train Epoch: 1 [24000/110534 (22%)]\tClassification Loss: 1.9442\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1500.pth.tar\r\n",
      "Train Epoch: 1 [24160/110534 (22%)]\tClassification Loss: 2.0853\r\n",
      "Train Epoch: 1 [24320/110534 (22%)]\tClassification Loss: 1.4686\r\n",
      "Train Epoch: 1 [24480/110534 (22%)]\tClassification Loss: 2.4265\r\n",
      "Train Epoch: 1 [24640/110534 (22%)]\tClassification Loss: 2.1560\r\n",
      "Train Epoch: 1 [24800/110534 (22%)]\tClassification Loss: 1.7814\r\n",
      "Train Epoch: 1 [24960/110534 (23%)]\tClassification Loss: 1.7451\r\n",
      "Train Epoch: 1 [25120/110534 (23%)]\tClassification Loss: 1.3092\r\n",
      "Train Epoch: 1 [25280/110534 (23%)]\tClassification Loss: 1.7147\r\n",
      "Train Epoch: 1 [25440/110534 (23%)]\tClassification Loss: 2.5265\r\n",
      "Test() called at batch_idx: 1600\r\n",
      "\r\n",
      "Test set: Average loss: 1.7407, Accuracy: 262/480 (55%)\r\n",
      "\r\n",
      "Train Epoch: 1 [25600/110534 (23%)]\tClassification Loss: 2.0259\r\n",
      "Train Epoch: 1 [25760/110534 (23%)]\tClassification Loss: 1.9535\r\n",
      "Train Epoch: 1 [25920/110534 (23%)]\tClassification Loss: 1.6910\r\n",
      "Train Epoch: 1 [26080/110534 (24%)]\tClassification Loss: 1.6914\r\n",
      "Train Epoch: 1 [26240/110534 (24%)]\tClassification Loss: 1.3185\r\n",
      "Train Epoch: 1 [26400/110534 (24%)]\tClassification Loss: 1.9191\r\n",
      "Train Epoch: 1 [26560/110534 (24%)]\tClassification Loss: 1.7567\r\n",
      "Train Epoch: 1 [26720/110534 (24%)]\tClassification Loss: 1.4400\r\n",
      "Train Epoch: 1 [26880/110534 (24%)]\tClassification Loss: 1.1686\r\n",
      "Train Epoch: 1 [27040/110534 (24%)]\tClassification Loss: 2.0706\r\n",
      "Test() called at batch_idx: 1700\r\n",
      "\r\n",
      "Test set: Average loss: 1.7235, Accuracy: 279/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [27200/110534 (25%)]\tClassification Loss: 1.8582\r\n",
      "Train Epoch: 1 [27360/110534 (25%)]\tClassification Loss: 1.8845\r\n",
      "Train Epoch: 1 [27520/110534 (25%)]\tClassification Loss: 1.4820\r\n",
      "Train Epoch: 1 [27680/110534 (25%)]\tClassification Loss: 2.0105\r\n",
      "Train Epoch: 1 [27840/110534 (25%)]\tClassification Loss: 1.6496\r\n",
      "Train Epoch: 1 [28000/110534 (25%)]\tClassification Loss: 1.5640\r\n",
      "Train Epoch: 1 [28160/110534 (25%)]\tClassification Loss: 1.5148\r\n",
      "Train Epoch: 1 [28320/110534 (26%)]\tClassification Loss: 1.5198\r\n",
      "Train Epoch: 1 [28480/110534 (26%)]\tClassification Loss: 1.3764\r\n",
      "Train Epoch: 1 [28640/110534 (26%)]\tClassification Loss: 2.2782\r\n",
      "Test() called at batch_idx: 1800\r\n",
      "\r\n",
      "Test set: Average loss: 1.7133, Accuracy: 273/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [28800/110534 (26%)]\tClassification Loss: 2.4940\r\n",
      "Train Epoch: 1 [28960/110534 (26%)]\tClassification Loss: 1.4954\r\n",
      "Train Epoch: 1 [29120/110534 (26%)]\tClassification Loss: 1.6925\r\n",
      "Train Epoch: 1 [29280/110534 (26%)]\tClassification Loss: 1.8439\r\n",
      "Train Epoch: 1 [29440/110534 (27%)]\tClassification Loss: 2.1436\r\n",
      "Train Epoch: 1 [29600/110534 (27%)]\tClassification Loss: 1.8696\r\n",
      "Train Epoch: 1 [29760/110534 (27%)]\tClassification Loss: 1.6840\r\n",
      "Train Epoch: 1 [29920/110534 (27%)]\tClassification Loss: 1.9154\r\n",
      "Train Epoch: 1 [30080/110534 (27%)]\tClassification Loss: 1.1865\r\n",
      "Train Epoch: 1 [30240/110534 (27%)]\tClassification Loss: 1.7245\r\n",
      "Test() called at batch_idx: 1900\r\n",
      "\r\n",
      "Test set: Average loss: 1.7023, Accuracy: 274/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [30400/110534 (28%)]\tClassification Loss: 1.6278\r\n",
      "Train Epoch: 1 [30560/110534 (28%)]\tClassification Loss: 2.3665\r\n",
      "Train Epoch: 1 [30720/110534 (28%)]\tClassification Loss: 2.2784\r\n",
      "Train Epoch: 1 [30880/110534 (28%)]\tClassification Loss: 2.0351\r\n",
      "Train Epoch: 1 [31040/110534 (28%)]\tClassification Loss: 1.2272\r\n",
      "Train Epoch: 1 [31200/110534 (28%)]\tClassification Loss: 2.0334\r\n",
      "Train Epoch: 1 [31360/110534 (28%)]\tClassification Loss: 1.6242\r\n",
      "Train Epoch: 1 [31520/110534 (29%)]\tClassification Loss: 1.9249\r\n",
      "Train Epoch: 1 [31680/110534 (29%)]\tClassification Loss: 1.9184\r\n",
      "Train Epoch: 1 [31840/110534 (29%)]\tClassification Loss: 1.5526\r\n",
      "Test() called at batch_idx: 2000\r\n",
      "\r\n",
      "Test set: Average loss: 1.6924, Accuracy: 272/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [32000/110534 (29%)]\tClassification Loss: 1.0702\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_2000.pth.tar\r\n",
      "Train Epoch: 1 [32160/110534 (29%)]\tClassification Loss: 1.6283\r\n",
      "Train Epoch: 1 [32320/110534 (29%)]\tClassification Loss: 1.9985\r\n",
      "Train Epoch: 1 [32480/110534 (29%)]\tClassification Loss: 1.5235\r\n",
      "Train Epoch: 1 [32640/110534 (30%)]\tClassification Loss: 1.4024\r\n",
      "Train Epoch: 1 [32800/110534 (30%)]\tClassification Loss: 1.2160\r\n",
      "Train Epoch: 1 [32960/110534 (30%)]\tClassification Loss: 1.7555\r\n",
      "Train Epoch: 1 [33120/110534 (30%)]\tClassification Loss: 1.7934\r\n",
      "Train Epoch: 1 [33280/110534 (30%)]\tClassification Loss: 1.5391\r\n",
      "Train Epoch: 1 [33440/110534 (30%)]\tClassification Loss: 1.6495\r\n",
      "Test() called at batch_idx: 2100\r\n",
      "\r\n",
      "Test set: Average loss: 1.6947, Accuracy: 273/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [33600/110534 (30%)]\tClassification Loss: 1.5939\r\n",
      "Train Epoch: 1 [33760/110534 (31%)]\tClassification Loss: 1.4053\r\n",
      "Train Epoch: 1 [33920/110534 (31%)]\tClassification Loss: 1.2643\r\n",
      "Train Epoch: 1 [34080/110534 (31%)]\tClassification Loss: 1.5214\r\n",
      "Train Epoch: 1 [34240/110534 (31%)]\tClassification Loss: 2.0885\r\n",
      "Train Epoch: 1 [34400/110534 (31%)]\tClassification Loss: 1.4132\r\n",
      "Train Epoch: 1 [34560/110534 (31%)]\tClassification Loss: 1.9076\r\n",
      "Train Epoch: 1 [34720/110534 (31%)]\tClassification Loss: 2.2261\r\n",
      "Train Epoch: 1 [34880/110534 (32%)]\tClassification Loss: 2.2424\r\n",
      "Train Epoch: 1 [35040/110534 (32%)]\tClassification Loss: 1.3702\r\n",
      "Test() called at batch_idx: 2200\r\n",
      "\r\n",
      "Test set: Average loss: 1.6729, Accuracy: 275/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [35200/110534 (32%)]\tClassification Loss: 1.7979\r\n",
      "Train Epoch: 1 [35360/110534 (32%)]\tClassification Loss: 1.6887\r\n",
      "Train Epoch: 1 [35520/110534 (32%)]\tClassification Loss: 2.1254\r\n",
      "Train Epoch: 1 [35680/110534 (32%)]\tClassification Loss: 1.6761\r\n",
      "Train Epoch: 1 [35840/110534 (32%)]\tClassification Loss: 1.8322\r\n",
      "Train Epoch: 1 [36000/110534 (33%)]\tClassification Loss: 1.1748\r\n",
      "Train Epoch: 1 [36160/110534 (33%)]\tClassification Loss: 2.0962\r\n",
      "Train Epoch: 1 [36320/110534 (33%)]\tClassification Loss: 1.9618\r\n",
      "Train Epoch: 1 [36480/110534 (33%)]\tClassification Loss: 1.9572\r\n",
      "Train Epoch: 1 [36640/110534 (33%)]\tClassification Loss: 1.6696\r\n",
      "Test() called at batch_idx: 2300\r\n",
      "\r\n",
      "Test set: Average loss: 1.6668, Accuracy: 278/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [36800/110534 (33%)]\tClassification Loss: 1.7396\r\n",
      "Train Epoch: 1 [36960/110534 (33%)]\tClassification Loss: 1.5324\r\n",
      "Train Epoch: 1 [37120/110534 (34%)]\tClassification Loss: 1.5158\r\n",
      "Train Epoch: 1 [37280/110534 (34%)]\tClassification Loss: 2.1422\r\n",
      "Train Epoch: 1 [37440/110534 (34%)]\tClassification Loss: 2.0128\r\n",
      "Train Epoch: 1 [37600/110534 (34%)]\tClassification Loss: 1.8276\r\n",
      "Train Epoch: 1 [37760/110534 (34%)]\tClassification Loss: 2.0375\r\n",
      "Train Epoch: 1 [37920/110534 (34%)]\tClassification Loss: 2.0298\r\n",
      "Train Epoch: 1 [38080/110534 (34%)]\tClassification Loss: 1.5780\r\n",
      "Train Epoch: 1 [38240/110534 (35%)]\tClassification Loss: 1.7032\r\n",
      "Test() called at batch_idx: 2400\r\n",
      "\r\n",
      "Test set: Average loss: 1.6476, Accuracy: 275/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [38400/110534 (35%)]\tClassification Loss: 1.3987\r\n",
      "Train Epoch: 1 [38560/110534 (35%)]\tClassification Loss: 1.6390\r\n",
      "Train Epoch: 1 [38720/110534 (35%)]\tClassification Loss: 1.2926\r\n",
      "Train Epoch: 1 [38880/110534 (35%)]\tClassification Loss: 1.2562\r\n",
      "Train Epoch: 1 [39040/110534 (35%)]\tClassification Loss: 1.3411\r\n",
      "Train Epoch: 1 [39200/110534 (35%)]\tClassification Loss: 1.7668\r\n",
      "Train Epoch: 1 [39360/110534 (36%)]\tClassification Loss: 1.3954\r\n",
      "Train Epoch: 1 [39520/110534 (36%)]\tClassification Loss: 1.6738\r\n",
      "Train Epoch: 1 [39680/110534 (36%)]\tClassification Loss: 1.5631\r\n",
      "Train Epoch: 1 [39840/110534 (36%)]\tClassification Loss: 1.5360\r\n",
      "Test() called at batch_idx: 2500\r\n",
      "\r\n",
      "Test set: Average loss: 1.6459, Accuracy: 272/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [40000/110534 (36%)]\tClassification Loss: 1.2218\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_2500.pth.tar\r\n",
      "Train Epoch: 1 [40160/110534 (36%)]\tClassification Loss: 1.8867\r\n",
      "Train Epoch: 1 [40320/110534 (36%)]\tClassification Loss: 2.5028\r\n",
      "Train Epoch: 1 [40480/110534 (37%)]\tClassification Loss: 1.5072\r\n",
      "Train Epoch: 1 [40640/110534 (37%)]\tClassification Loss: 1.4271\r\n",
      "Train Epoch: 1 [40800/110534 (37%)]\tClassification Loss: 1.8082\r\n",
      "Train Epoch: 1 [40960/110534 (37%)]\tClassification Loss: 1.4719\r\n",
      "Train Epoch: 1 [41120/110534 (37%)]\tClassification Loss: 2.8728\r\n",
      "Train Epoch: 1 [41280/110534 (37%)]\tClassification Loss: 1.3714\r\n",
      "Train Epoch: 1 [41440/110534 (37%)]\tClassification Loss: 1.9079\r\n",
      "Test() called at batch_idx: 2600\r\n",
      "\r\n",
      "Test set: Average loss: 1.6410, Accuracy: 264/480 (55%)\r\n",
      "\r\n",
      "Train Epoch: 1 [41600/110534 (38%)]\tClassification Loss: 1.4347\r\n",
      "Train Epoch: 1 [41760/110534 (38%)]\tClassification Loss: 1.4188\r\n",
      "Train Epoch: 1 [41920/110534 (38%)]\tClassification Loss: 1.2001\r\n",
      "Train Epoch: 1 [42080/110534 (38%)]\tClassification Loss: 1.2133\r\n",
      "Train Epoch: 1 [42240/110534 (38%)]\tClassification Loss: 1.3965\r\n",
      "Train Epoch: 1 [42400/110534 (38%)]\tClassification Loss: 2.2922\r\n",
      "Train Epoch: 1 [42560/110534 (39%)]\tClassification Loss: 0.9053\r\n",
      "Train Epoch: 1 [42720/110534 (39%)]\tClassification Loss: 2.3342\r\n",
      "Train Epoch: 1 [42880/110534 (39%)]\tClassification Loss: 1.5349\r\n",
      "Train Epoch: 1 [43040/110534 (39%)]\tClassification Loss: 2.3101\r\n",
      "Test() called at batch_idx: 2700\r\n",
      "\r\n",
      "Test set: Average loss: 1.6229, Accuracy: 274/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [43200/110534 (39%)]\tClassification Loss: 1.4919\r\n",
      "Train Epoch: 1 [43360/110534 (39%)]\tClassification Loss: 1.8753\r\n",
      "Train Epoch: 1 [43520/110534 (39%)]\tClassification Loss: 1.4443\r\n",
      "Train Epoch: 1 [43680/110534 (40%)]\tClassification Loss: 1.6271\r\n",
      "Train Epoch: 1 [43840/110534 (40%)]\tClassification Loss: 1.8749\r\n",
      "Train Epoch: 1 [44000/110534 (40%)]\tClassification Loss: 1.4279\r\n",
      "Train Epoch: 1 [44160/110534 (40%)]\tClassification Loss: 1.7116\r\n",
      "Train Epoch: 1 [44320/110534 (40%)]\tClassification Loss: 1.5173\r\n",
      "Train Epoch: 1 [44480/110534 (40%)]\tClassification Loss: 1.5818\r\n",
      "Train Epoch: 1 [44640/110534 (40%)]\tClassification Loss: 1.7335\r\n",
      "Test() called at batch_idx: 2800\r\n",
      "\r\n",
      "Test set: Average loss: 1.6266, Accuracy: 272/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [44800/110534 (41%)]\tClassification Loss: 1.6724\r\n",
      "Train Epoch: 1 [44960/110534 (41%)]\tClassification Loss: 1.7066\r\n",
      "Train Epoch: 1 [45120/110534 (41%)]\tClassification Loss: 1.7723\r\n",
      "Train Epoch: 1 [45280/110534 (41%)]\tClassification Loss: 1.7303\r\n",
      "Train Epoch: 1 [45440/110534 (41%)]\tClassification Loss: 2.0546\r\n",
      "Train Epoch: 1 [45600/110534 (41%)]\tClassification Loss: 1.5772\r\n",
      "Train Epoch: 1 [45760/110534 (41%)]\tClassification Loss: 1.2008\r\n",
      "Train Epoch: 1 [45920/110534 (42%)]\tClassification Loss: 1.2618\r\n",
      "Train Epoch: 1 [46080/110534 (42%)]\tClassification Loss: 1.8051\r\n",
      "Train Epoch: 1 [46240/110534 (42%)]\tClassification Loss: 1.7878\r\n",
      "Test() called at batch_idx: 2900\r\n",
      "\r\n",
      "Test set: Average loss: 1.6195, Accuracy: 275/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [46400/110534 (42%)]\tClassification Loss: 1.5329\r\n",
      "Train Epoch: 1 [46560/110534 (42%)]\tClassification Loss: 1.9564\r\n",
      "Train Epoch: 1 [46720/110534 (42%)]\tClassification Loss: 1.7477\r\n",
      "Train Epoch: 1 [46880/110534 (42%)]\tClassification Loss: 1.6325\r\n",
      "Train Epoch: 1 [47040/110534 (43%)]\tClassification Loss: 2.0856\r\n",
      "Train Epoch: 1 [47200/110534 (43%)]\tClassification Loss: 1.4120\r\n",
      "Train Epoch: 1 [47360/110534 (43%)]\tClassification Loss: 1.8494\r\n",
      "Train Epoch: 1 [47520/110534 (43%)]\tClassification Loss: 1.8882\r\n",
      "Train Epoch: 1 [47680/110534 (43%)]\tClassification Loss: 1.1587\r\n",
      "Train Epoch: 1 [47840/110534 (43%)]\tClassification Loss: 1.6502\r\n",
      "Test() called at batch_idx: 3000\r\n",
      "\r\n",
      "Test set: Average loss: 1.6195, Accuracy: 280/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [48000/110534 (43%)]\tClassification Loss: 1.4464\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_3000.pth.tar\r\n",
      "Train Epoch: 1 [48160/110534 (44%)]\tClassification Loss: 1.7282\r\n",
      "Train Epoch: 1 [48320/110534 (44%)]\tClassification Loss: 1.9888\r\n",
      "Train Epoch: 1 [48480/110534 (44%)]\tClassification Loss: 1.6801\r\n",
      "Train Epoch: 1 [48640/110534 (44%)]\tClassification Loss: 1.6272\r\n",
      "Train Epoch: 1 [48800/110534 (44%)]\tClassification Loss: 1.6098\r\n",
      "Train Epoch: 1 [48960/110534 (44%)]\tClassification Loss: 1.6475\r\n",
      "Train Epoch: 1 [49120/110534 (44%)]\tClassification Loss: 1.9050\r\n",
      "Train Epoch: 1 [49280/110534 (45%)]\tClassification Loss: 1.4989\r\n",
      "Train Epoch: 1 [49440/110534 (45%)]\tClassification Loss: 1.7083\r\n",
      "Test() called at batch_idx: 3100\r\n",
      "\r\n",
      "Test set: Average loss: 1.6113, Accuracy: 270/480 (56%)\r\n",
      "\r\n",
      "Train Epoch: 1 [49600/110534 (45%)]\tClassification Loss: 1.9470\r\n",
      "Train Epoch: 1 [49760/110534 (45%)]\tClassification Loss: 1.7129\r\n",
      "Train Epoch: 1 [49920/110534 (45%)]\tClassification Loss: 1.7777\r\n",
      "Train Epoch: 1 [50080/110534 (45%)]\tClassification Loss: 1.5116\r\n",
      "Train Epoch: 1 [50240/110534 (45%)]\tClassification Loss: 1.5287\r\n",
      "Train Epoch: 1 [50400/110534 (46%)]\tClassification Loss: 1.3479\r\n",
      "Train Epoch: 1 [50560/110534 (46%)]\tClassification Loss: 1.3364\r\n",
      "Train Epoch: 1 [50720/110534 (46%)]\tClassification Loss: 1.9134\r\n",
      "Train Epoch: 1 [50880/110534 (46%)]\tClassification Loss: 1.5369\r\n",
      "Train Epoch: 1 [51040/110534 (46%)]\tClassification Loss: 1.4212\r\n",
      "Test() called at batch_idx: 3200\r\n",
      "\r\n",
      "Test set: Average loss: 1.6191, Accuracy: 281/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [51200/110534 (46%)]\tClassification Loss: 1.9137\r\n",
      "Train Epoch: 1 [51360/110534 (46%)]\tClassification Loss: 1.3887\r\n",
      "Train Epoch: 1 [51520/110534 (47%)]\tClassification Loss: 2.1278\r\n",
      "Train Epoch: 1 [51680/110534 (47%)]\tClassification Loss: 2.3356\r\n",
      "Train Epoch: 1 [51840/110534 (47%)]\tClassification Loss: 2.6925\r\n",
      "Train Epoch: 1 [52000/110534 (47%)]\tClassification Loss: 1.2439\r\n",
      "Train Epoch: 1 [52160/110534 (47%)]\tClassification Loss: 1.2674\r\n",
      "Train Epoch: 1 [52320/110534 (47%)]\tClassification Loss: 1.9816\r\n",
      "Train Epoch: 1 [52480/110534 (47%)]\tClassification Loss: 1.9840\r\n",
      "Train Epoch: 1 [52640/110534 (48%)]\tClassification Loss: 1.4901\r\n",
      "Test() called at batch_idx: 3300\r\n",
      "\r\n",
      "Test set: Average loss: 1.6046, Accuracy: 279/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [52800/110534 (48%)]\tClassification Loss: 1.8800\r\n",
      "Train Epoch: 1 [52960/110534 (48%)]\tClassification Loss: 1.1927\r\n",
      "Train Epoch: 1 [53120/110534 (48%)]\tClassification Loss: 1.5912\r\n",
      "Train Epoch: 1 [53280/110534 (48%)]\tClassification Loss: 1.8781\r\n",
      "Train Epoch: 1 [53440/110534 (48%)]\tClassification Loss: 2.3081\r\n",
      "Train Epoch: 1 [53600/110534 (48%)]\tClassification Loss: 1.3265\r\n",
      "Train Epoch: 1 [53760/110534 (49%)]\tClassification Loss: 2.0886\r\n",
      "Train Epoch: 1 [53920/110534 (49%)]\tClassification Loss: 1.5659\r\n",
      "Train Epoch: 1 [54080/110534 (49%)]\tClassification Loss: 2.0270\r\n",
      "Train Epoch: 1 [54240/110534 (49%)]\tClassification Loss: 1.7053\r\n",
      "Test() called at batch_idx: 3400\r\n",
      "\r\n",
      "Test set: Average loss: 1.5973, Accuracy: 271/480 (56%)\r\n",
      "\r\n",
      "Train Epoch: 1 [54400/110534 (49%)]\tClassification Loss: 1.8152\r\n",
      "Train Epoch: 1 [54560/110534 (49%)]\tClassification Loss: 1.6324\r\n",
      "Train Epoch: 1 [54720/110534 (50%)]\tClassification Loss: 1.6434\r\n",
      "Train Epoch: 1 [54880/110534 (50%)]\tClassification Loss: 1.5529\r\n",
      "Train Epoch: 1 [55040/110534 (50%)]\tClassification Loss: 1.2689\r\n",
      "Train Epoch: 1 [55200/110534 (50%)]\tClassification Loss: 1.3757\r\n",
      "Train Epoch: 1 [55360/110534 (50%)]\tClassification Loss: 1.9956\r\n",
      "Train Epoch: 1 [55520/110534 (50%)]\tClassification Loss: 1.9367\r\n",
      "Train Epoch: 1 [55680/110534 (50%)]\tClassification Loss: 1.5633\r\n",
      "Train Epoch: 1 [55840/110534 (51%)]\tClassification Loss: 2.0730\r\n",
      "Test() called at batch_idx: 3500\r\n",
      "\r\n",
      "Test set: Average loss: 1.5900, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 1 [56000/110534 (51%)]\tClassification Loss: 1.6285\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_3500.pth.tar\r\n",
      "Train Epoch: 1 [56160/110534 (51%)]\tClassification Loss: 1.1017\r\n",
      "Train Epoch: 1 [56320/110534 (51%)]\tClassification Loss: 1.7731\r\n",
      "Train Epoch: 1 [56480/110534 (51%)]\tClassification Loss: 1.8226\r\n",
      "Train Epoch: 1 [56640/110534 (51%)]\tClassification Loss: 1.1754\r\n",
      "Train Epoch: 1 [56800/110534 (51%)]\tClassification Loss: 1.8128\r\n",
      "Train Epoch: 1 [56960/110534 (52%)]\tClassification Loss: 1.0059\r\n",
      "Train Epoch: 1 [57120/110534 (52%)]\tClassification Loss: 2.1833\r\n",
      "Train Epoch: 1 [57280/110534 (52%)]\tClassification Loss: 1.6083\r\n",
      "Train Epoch: 1 [57440/110534 (52%)]\tClassification Loss: 1.4323\r\n",
      "Test() called at batch_idx: 3600\r\n",
      "\r\n",
      "Test set: Average loss: 1.5987, Accuracy: 279/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [57600/110534 (52%)]\tClassification Loss: 2.1029\r\n",
      "Train Epoch: 1 [57760/110534 (52%)]\tClassification Loss: 1.1899\r\n",
      "Train Epoch: 1 [57920/110534 (52%)]\tClassification Loss: 1.7240\r\n",
      "Train Epoch: 1 [58080/110534 (53%)]\tClassification Loss: 2.2978\r\n",
      "Train Epoch: 1 [58240/110534 (53%)]\tClassification Loss: 1.2247\r\n",
      "Train Epoch: 1 [58400/110534 (53%)]\tClassification Loss: 1.8546\r\n",
      "Train Epoch: 1 [58560/110534 (53%)]\tClassification Loss: 2.4532\r\n",
      "Train Epoch: 1 [58720/110534 (53%)]\tClassification Loss: 1.7262\r\n",
      "Train Epoch: 1 [58880/110534 (53%)]\tClassification Loss: 2.1529\r\n",
      "Train Epoch: 1 [59040/110534 (53%)]\tClassification Loss: 1.9896\r\n",
      "Test() called at batch_idx: 3700\r\n",
      "\r\n",
      "Test set: Average loss: 1.5853, Accuracy: 280/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [59200/110534 (54%)]\tClassification Loss: 1.8461\r\n",
      "Train Epoch: 1 [59360/110534 (54%)]\tClassification Loss: 0.9855\r\n",
      "Train Epoch: 1 [59520/110534 (54%)]\tClassification Loss: 1.9477\r\n",
      "Train Epoch: 1 [59680/110534 (54%)]\tClassification Loss: 1.9786\r\n",
      "Train Epoch: 1 [59840/110534 (54%)]\tClassification Loss: 1.9937\r\n",
      "Train Epoch: 1 [60000/110534 (54%)]\tClassification Loss: 1.7409\r\n",
      "Train Epoch: 1 [60160/110534 (54%)]\tClassification Loss: 1.9108\r\n",
      "Train Epoch: 1 [60320/110534 (55%)]\tClassification Loss: 2.2888\r\n",
      "Train Epoch: 1 [60480/110534 (55%)]\tClassification Loss: 1.4199\r\n",
      "Train Epoch: 1 [60640/110534 (55%)]\tClassification Loss: 1.3334\r\n",
      "Test() called at batch_idx: 3800\r\n",
      "\r\n",
      "Test set: Average loss: 1.6043, Accuracy: 271/480 (56%)\r\n",
      "\r\n",
      "Train Epoch: 1 [60800/110534 (55%)]\tClassification Loss: 1.1627\r\n",
      "Train Epoch: 1 [60960/110534 (55%)]\tClassification Loss: 1.8087\r\n",
      "Train Epoch: 1 [61120/110534 (55%)]\tClassification Loss: 1.8063\r\n",
      "Train Epoch: 1 [61280/110534 (55%)]\tClassification Loss: 1.8561\r\n",
      "Train Epoch: 1 [61440/110534 (56%)]\tClassification Loss: 1.6467\r\n",
      "Train Epoch: 1 [61600/110534 (56%)]\tClassification Loss: 1.5263\r\n",
      "Train Epoch: 1 [61760/110534 (56%)]\tClassification Loss: 1.4656\r\n",
      "Train Epoch: 1 [61920/110534 (56%)]\tClassification Loss: 2.0208\r\n",
      "Train Epoch: 1 [62080/110534 (56%)]\tClassification Loss: 1.4128\r\n",
      "Train Epoch: 1 [62240/110534 (56%)]\tClassification Loss: 1.3205\r\n",
      "Test() called at batch_idx: 3900\r\n",
      "\r\n",
      "Test set: Average loss: 1.5784, Accuracy: 276/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [62400/110534 (56%)]\tClassification Loss: 1.6452\r\n",
      "Train Epoch: 1 [62560/110534 (57%)]\tClassification Loss: 1.5490\r\n",
      "Train Epoch: 1 [62720/110534 (57%)]\tClassification Loss: 1.5588\r\n",
      "Train Epoch: 1 [62880/110534 (57%)]\tClassification Loss: 1.7572\r\n",
      "Train Epoch: 1 [63040/110534 (57%)]\tClassification Loss: 1.8341\r\n",
      "Train Epoch: 1 [63200/110534 (57%)]\tClassification Loss: 1.8870\r\n",
      "Train Epoch: 1 [63360/110534 (57%)]\tClassification Loss: 1.3717\r\n",
      "Train Epoch: 1 [63520/110534 (57%)]\tClassification Loss: 1.4998\r\n",
      "Train Epoch: 1 [63680/110534 (58%)]\tClassification Loss: 2.0594\r\n",
      "Train Epoch: 1 [63840/110534 (58%)]\tClassification Loss: 1.4176\r\n",
      "Test() called at batch_idx: 4000\r\n",
      "\r\n",
      "Test set: Average loss: 1.5714, Accuracy: 280/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [64000/110534 (58%)]\tClassification Loss: 1.4091\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_4000.pth.tar\r\n",
      "Train Epoch: 1 [64160/110534 (58%)]\tClassification Loss: 2.0171\r\n",
      "Train Epoch: 1 [64320/110534 (58%)]\tClassification Loss: 1.4212\r\n",
      "Train Epoch: 1 [64480/110534 (58%)]\tClassification Loss: 1.3254\r\n",
      "Train Epoch: 1 [64640/110534 (58%)]\tClassification Loss: 1.8968\r\n",
      "Train Epoch: 1 [64800/110534 (59%)]\tClassification Loss: 1.4349\r\n",
      "Train Epoch: 1 [64960/110534 (59%)]\tClassification Loss: 1.4540\r\n",
      "Train Epoch: 1 [65120/110534 (59%)]\tClassification Loss: 1.1272\r\n",
      "Train Epoch: 1 [65280/110534 (59%)]\tClassification Loss: 1.8756\r\n",
      "Train Epoch: 1 [65440/110534 (59%)]\tClassification Loss: 1.8639\r\n",
      "Test() called at batch_idx: 4100\r\n",
      "\r\n",
      "Test set: Average loss: 1.5679, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [65600/110534 (59%)]\tClassification Loss: 1.1853\r\n",
      "Train Epoch: 1 [65760/110534 (59%)]\tClassification Loss: 1.4089\r\n",
      "Train Epoch: 1 [65920/110534 (60%)]\tClassification Loss: 1.3219\r\n",
      "Train Epoch: 1 [66080/110534 (60%)]\tClassification Loss: 1.4902\r\n",
      "Train Epoch: 1 [66240/110534 (60%)]\tClassification Loss: 2.1046\r\n",
      "Train Epoch: 1 [66400/110534 (60%)]\tClassification Loss: 2.5711\r\n",
      "Train Epoch: 1 [66560/110534 (60%)]\tClassification Loss: 1.9669\r\n",
      "Train Epoch: 1 [66720/110534 (60%)]\tClassification Loss: 1.6596\r\n",
      "Train Epoch: 1 [66880/110534 (61%)]\tClassification Loss: 1.3223\r\n",
      "Train Epoch: 1 [67040/110534 (61%)]\tClassification Loss: 1.1058\r\n",
      "Test() called at batch_idx: 4200\r\n",
      "\r\n",
      "Test set: Average loss: 1.5589, Accuracy: 282/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [67200/110534 (61%)]\tClassification Loss: 2.5585\r\n",
      "Train Epoch: 1 [67360/110534 (61%)]\tClassification Loss: 1.9055\r\n",
      "Train Epoch: 1 [67520/110534 (61%)]\tClassification Loss: 1.4657\r\n",
      "Train Epoch: 1 [67680/110534 (61%)]\tClassification Loss: 1.4107\r\n",
      "Train Epoch: 1 [67840/110534 (61%)]\tClassification Loss: 1.4553\r\n",
      "Train Epoch: 1 [68000/110534 (62%)]\tClassification Loss: 1.9059\r\n",
      "Train Epoch: 1 [68160/110534 (62%)]\tClassification Loss: 1.6568\r\n",
      "Train Epoch: 1 [68320/110534 (62%)]\tClassification Loss: 1.9655\r\n",
      "Train Epoch: 1 [68480/110534 (62%)]\tClassification Loss: 1.8574\r\n",
      "Train Epoch: 1 [68640/110534 (62%)]\tClassification Loss: 1.8967\r\n",
      "Test() called at batch_idx: 4300\r\n",
      "\r\n",
      "Test set: Average loss: 1.5755, Accuracy: 282/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [68800/110534 (62%)]\tClassification Loss: 1.5078\r\n",
      "Train Epoch: 1 [68960/110534 (62%)]\tClassification Loss: 1.4068\r\n",
      "Train Epoch: 1 [69120/110534 (63%)]\tClassification Loss: 1.2087\r\n",
      "Train Epoch: 1 [69280/110534 (63%)]\tClassification Loss: 2.3797\r\n",
      "Train Epoch: 1 [69440/110534 (63%)]\tClassification Loss: 2.2691\r\n",
      "Train Epoch: 1 [69600/110534 (63%)]\tClassification Loss: 1.5185\r\n",
      "Train Epoch: 1 [69760/110534 (63%)]\tClassification Loss: 1.5842\r\n",
      "Train Epoch: 1 [69920/110534 (63%)]\tClassification Loss: 1.6069\r\n",
      "Train Epoch: 1 [70080/110534 (63%)]\tClassification Loss: 1.8029\r\n",
      "Train Epoch: 1 [70240/110534 (64%)]\tClassification Loss: 1.2691\r\n",
      "Test() called at batch_idx: 4400\r\n",
      "\r\n",
      "Test set: Average loss: 1.5567, Accuracy: 284/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [70400/110534 (64%)]\tClassification Loss: 2.2677\r\n",
      "Train Epoch: 1 [70560/110534 (64%)]\tClassification Loss: 1.2316\r\n",
      "Train Epoch: 1 [70720/110534 (64%)]\tClassification Loss: 1.7473\r\n",
      "Train Epoch: 1 [70880/110534 (64%)]\tClassification Loss: 2.2672\r\n",
      "Train Epoch: 1 [71040/110534 (64%)]\tClassification Loss: 1.6036\r\n",
      "Train Epoch: 1 [71200/110534 (64%)]\tClassification Loss: 2.0484\r\n",
      "Train Epoch: 1 [71360/110534 (65%)]\tClassification Loss: 1.9946\r\n",
      "Train Epoch: 1 [71520/110534 (65%)]\tClassification Loss: 1.4601\r\n",
      "Train Epoch: 1 [71680/110534 (65%)]\tClassification Loss: 1.6028\r\n",
      "Train Epoch: 1 [71840/110534 (65%)]\tClassification Loss: 1.2912\r\n",
      "Test() called at batch_idx: 4500\r\n",
      "\r\n",
      "Test set: Average loss: 1.5645, Accuracy: 284/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [72000/110534 (65%)]\tClassification Loss: 1.1268\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_4500.pth.tar\r\n",
      "Train Epoch: 1 [72160/110534 (65%)]\tClassification Loss: 1.7881\r\n",
      "Train Epoch: 1 [72320/110534 (65%)]\tClassification Loss: 1.5465\r\n",
      "Train Epoch: 1 [72480/110534 (66%)]\tClassification Loss: 1.7682\r\n",
      "Train Epoch: 1 [72640/110534 (66%)]\tClassification Loss: 2.0001\r\n",
      "Train Epoch: 1 [72800/110534 (66%)]\tClassification Loss: 2.3216\r\n",
      "Train Epoch: 1 [72960/110534 (66%)]\tClassification Loss: 1.8039\r\n",
      "Train Epoch: 1 [73120/110534 (66%)]\tClassification Loss: 1.4965\r\n",
      "Train Epoch: 1 [73280/110534 (66%)]\tClassification Loss: 1.9317\r\n",
      "Train Epoch: 1 [73440/110534 (66%)]\tClassification Loss: 2.0631\r\n",
      "Test() called at batch_idx: 4600\r\n",
      "\r\n",
      "Test set: Average loss: 1.5588, Accuracy: 283/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [73600/110534 (67%)]\tClassification Loss: 1.8093\r\n",
      "Train Epoch: 1 [73760/110534 (67%)]\tClassification Loss: 1.8850\r\n",
      "Train Epoch: 1 [73920/110534 (67%)]\tClassification Loss: 2.5521\r\n",
      "Train Epoch: 1 [74080/110534 (67%)]\tClassification Loss: 1.8713\r\n",
      "Train Epoch: 1 [74240/110534 (67%)]\tClassification Loss: 1.8304\r\n",
      "Train Epoch: 1 [74400/110534 (67%)]\tClassification Loss: 2.0438\r\n",
      "Train Epoch: 1 [74560/110534 (67%)]\tClassification Loss: 1.3929\r\n",
      "Train Epoch: 1 [74720/110534 (68%)]\tClassification Loss: 1.2585\r\n",
      "Train Epoch: 1 [74880/110534 (68%)]\tClassification Loss: 2.0766\r\n",
      "Train Epoch: 1 [75040/110534 (68%)]\tClassification Loss: 1.2872\r\n",
      "Test() called at batch_idx: 4700\r\n",
      "\r\n",
      "Test set: Average loss: 1.5521, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 1 [75200/110534 (68%)]\tClassification Loss: 1.1580\r\n",
      "Train Epoch: 1 [75360/110534 (68%)]\tClassification Loss: 1.9113\r\n",
      "Train Epoch: 1 [75520/110534 (68%)]\tClassification Loss: 1.8719\r\n",
      "Train Epoch: 1 [75680/110534 (68%)]\tClassification Loss: 1.5054\r\n",
      "Train Epoch: 1 [75840/110534 (69%)]\tClassification Loss: 1.2918\r\n",
      "Train Epoch: 1 [76000/110534 (69%)]\tClassification Loss: 1.5093\r\n",
      "Train Epoch: 1 [76160/110534 (69%)]\tClassification Loss: 2.2628\r\n",
      "Train Epoch: 1 [76320/110534 (69%)]\tClassification Loss: 1.1995\r\n",
      "Train Epoch: 1 [76480/110534 (69%)]\tClassification Loss: 2.4157\r\n",
      "Train Epoch: 1 [76640/110534 (69%)]\tClassification Loss: 1.0671\r\n",
      "Test() called at batch_idx: 4800\r\n",
      "\r\n",
      "Test set: Average loss: 1.5551, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [76800/110534 (69%)]\tClassification Loss: 2.1494\r\n",
      "Train Epoch: 1 [76960/110534 (70%)]\tClassification Loss: 1.4492\r\n",
      "Train Epoch: 1 [77120/110534 (70%)]\tClassification Loss: 1.8208\r\n",
      "Train Epoch: 1 [77280/110534 (70%)]\tClassification Loss: 1.7908\r\n",
      "Train Epoch: 1 [77440/110534 (70%)]\tClassification Loss: 1.3424\r\n",
      "Train Epoch: 1 [77600/110534 (70%)]\tClassification Loss: 1.8969\r\n",
      "Train Epoch: 1 [77760/110534 (70%)]\tClassification Loss: 1.7572\r\n",
      "Train Epoch: 1 [77920/110534 (70%)]\tClassification Loss: 1.7037\r\n",
      "Train Epoch: 1 [78080/110534 (71%)]\tClassification Loss: 1.6870\r\n",
      "Train Epoch: 1 [78240/110534 (71%)]\tClassification Loss: 1.7920\r\n",
      "Test() called at batch_idx: 4900\r\n",
      "\r\n",
      "Test set: Average loss: 1.5468, Accuracy: 284/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [78400/110534 (71%)]\tClassification Loss: 1.5512\r\n",
      "Train Epoch: 1 [78560/110534 (71%)]\tClassification Loss: 1.5180\r\n",
      "Train Epoch: 1 [78720/110534 (71%)]\tClassification Loss: 1.9913\r\n",
      "Train Epoch: 1 [78880/110534 (71%)]\tClassification Loss: 1.6426\r\n",
      "Train Epoch: 1 [79040/110534 (72%)]\tClassification Loss: 1.7947\r\n",
      "Train Epoch: 1 [79200/110534 (72%)]\tClassification Loss: 1.5641\r\n",
      "Train Epoch: 1 [79360/110534 (72%)]\tClassification Loss: 1.3331\r\n",
      "Train Epoch: 1 [79520/110534 (72%)]\tClassification Loss: 1.3236\r\n",
      "Train Epoch: 1 [79680/110534 (72%)]\tClassification Loss: 1.7437\r\n",
      "Train Epoch: 1 [79840/110534 (72%)]\tClassification Loss: 1.9210\r\n",
      "Test() called at batch_idx: 5000\r\n",
      "\r\n",
      "Test set: Average loss: 1.5447, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [80000/110534 (72%)]\tClassification Loss: 1.3836\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_5000.pth.tar\r\n",
      "Train Epoch: 1 [80160/110534 (73%)]\tClassification Loss: 1.3634\r\n",
      "Train Epoch: 1 [80320/110534 (73%)]\tClassification Loss: 1.8854\r\n",
      "Train Epoch: 1 [80480/110534 (73%)]\tClassification Loss: 1.6282\r\n",
      "Train Epoch: 1 [80640/110534 (73%)]\tClassification Loss: 1.7563\r\n",
      "Train Epoch: 1 [80800/110534 (73%)]\tClassification Loss: 1.9933\r\n",
      "Train Epoch: 1 [80960/110534 (73%)]\tClassification Loss: 1.9781\r\n",
      "Train Epoch: 1 [81120/110534 (73%)]\tClassification Loss: 1.7421\r\n",
      "Train Epoch: 1 [81280/110534 (74%)]\tClassification Loss: 2.3015\r\n",
      "Train Epoch: 1 [81440/110534 (74%)]\tClassification Loss: 1.7920\r\n",
      "Test() called at batch_idx: 5100\r\n",
      "\r\n",
      "Test set: Average loss: 1.5436, Accuracy: 283/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [81600/110534 (74%)]\tClassification Loss: 1.2457\r\n",
      "Train Epoch: 1 [81760/110534 (74%)]\tClassification Loss: 1.7535\r\n",
      "Train Epoch: 1 [81920/110534 (74%)]\tClassification Loss: 2.5846\r\n",
      "Train Epoch: 1 [82080/110534 (74%)]\tClassification Loss: 1.7090\r\n",
      "Train Epoch: 1 [82240/110534 (74%)]\tClassification Loss: 1.5670\r\n",
      "Train Epoch: 1 [82400/110534 (75%)]\tClassification Loss: 1.6334\r\n",
      "Train Epoch: 1 [82560/110534 (75%)]\tClassification Loss: 1.3950\r\n",
      "Train Epoch: 1 [82720/110534 (75%)]\tClassification Loss: 1.3636\r\n",
      "Train Epoch: 1 [82880/110534 (75%)]\tClassification Loss: 1.9374\r\n",
      "Train Epoch: 1 [83040/110534 (75%)]\tClassification Loss: 1.4603\r\n",
      "Test() called at batch_idx: 5200\r\n",
      "\r\n",
      "Test set: Average loss: 1.5416, Accuracy: 284/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [83200/110534 (75%)]\tClassification Loss: 1.4516\r\n",
      "Train Epoch: 1 [83360/110534 (75%)]\tClassification Loss: 1.3375\r\n",
      "Train Epoch: 1 [83520/110534 (76%)]\tClassification Loss: 2.2872\r\n",
      "Train Epoch: 1 [83680/110534 (76%)]\tClassification Loss: 1.8552\r\n",
      "Train Epoch: 1 [83840/110534 (76%)]\tClassification Loss: 1.6574\r\n",
      "Train Epoch: 1 [84000/110534 (76%)]\tClassification Loss: 1.7541\r\n",
      "Train Epoch: 1 [84160/110534 (76%)]\tClassification Loss: 1.8579\r\n",
      "Train Epoch: 1 [84320/110534 (76%)]\tClassification Loss: 1.8236\r\n",
      "Train Epoch: 1 [84480/110534 (76%)]\tClassification Loss: 2.0440\r\n",
      "Train Epoch: 1 [84640/110534 (77%)]\tClassification Loss: 2.2371\r\n",
      "Test() called at batch_idx: 5300\r\n",
      "\r\n",
      "Test set: Average loss: 1.5442, Accuracy: 284/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [84800/110534 (77%)]\tClassification Loss: 1.7614\r\n",
      "Train Epoch: 1 [84960/110534 (77%)]\tClassification Loss: 1.9665\r\n",
      "Train Epoch: 1 [85120/110534 (77%)]\tClassification Loss: 1.7587\r\n",
      "Train Epoch: 1 [85280/110534 (77%)]\tClassification Loss: 1.8776\r\n",
      "Train Epoch: 1 [85440/110534 (77%)]\tClassification Loss: 1.6798\r\n",
      "Train Epoch: 1 [85600/110534 (77%)]\tClassification Loss: 1.5771\r\n",
      "Train Epoch: 1 [85760/110534 (78%)]\tClassification Loss: 2.5240\r\n",
      "Train Epoch: 1 [85920/110534 (78%)]\tClassification Loss: 1.1522\r\n",
      "Train Epoch: 1 [86080/110534 (78%)]\tClassification Loss: 1.5814\r\n",
      "Train Epoch: 1 [86240/110534 (78%)]\tClassification Loss: 1.2495\r\n",
      "Test() called at batch_idx: 5400\r\n",
      "\r\n",
      "Test set: Average loss: 1.5452, Accuracy: 282/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [86400/110534 (78%)]\tClassification Loss: 1.4321\r\n",
      "Train Epoch: 1 [86560/110534 (78%)]\tClassification Loss: 1.8873\r\n",
      "Train Epoch: 1 [86720/110534 (78%)]\tClassification Loss: 1.7847\r\n",
      "Train Epoch: 1 [86880/110534 (79%)]\tClassification Loss: 1.5336\r\n",
      "Train Epoch: 1 [87040/110534 (79%)]\tClassification Loss: 1.5740\r\n",
      "Train Epoch: 1 [87200/110534 (79%)]\tClassification Loss: 1.8842\r\n",
      "Train Epoch: 1 [87360/110534 (79%)]\tClassification Loss: 1.9527\r\n",
      "Train Epoch: 1 [87520/110534 (79%)]\tClassification Loss: 1.3604\r\n",
      "Train Epoch: 1 [87680/110534 (79%)]\tClassification Loss: 1.0039\r\n",
      "Train Epoch: 1 [87840/110534 (79%)]\tClassification Loss: 1.8198\r\n",
      "Test() called at batch_idx: 5500\r\n",
      "\r\n",
      "Test set: Average loss: 1.5390, Accuracy: 291/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 1 [88000/110534 (80%)]\tClassification Loss: 1.4995\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_5500.pth.tar\r\n",
      "Train Epoch: 1 [88160/110534 (80%)]\tClassification Loss: 1.6042\r\n",
      "Train Epoch: 1 [88320/110534 (80%)]\tClassification Loss: 1.1430\r\n",
      "Train Epoch: 1 [88480/110534 (80%)]\tClassification Loss: 1.0383\r\n",
      "Train Epoch: 1 [88640/110534 (80%)]\tClassification Loss: 1.0476\r\n",
      "Train Epoch: 1 [88800/110534 (80%)]\tClassification Loss: 1.3865\r\n",
      "Train Epoch: 1 [88960/110534 (80%)]\tClassification Loss: 1.5312\r\n",
      "Train Epoch: 1 [89120/110534 (81%)]\tClassification Loss: 1.2525\r\n",
      "Train Epoch: 1 [89280/110534 (81%)]\tClassification Loss: 1.3203\r\n",
      "Train Epoch: 1 [89440/110534 (81%)]\tClassification Loss: 1.9168\r\n",
      "Test() called at batch_idx: 5600\r\n",
      "\r\n",
      "Test set: Average loss: 1.5479, Accuracy: 283/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [89600/110534 (81%)]\tClassification Loss: 1.4142\r\n",
      "Train Epoch: 1 [89760/110534 (81%)]\tClassification Loss: 1.9105\r\n",
      "Train Epoch: 1 [89920/110534 (81%)]\tClassification Loss: 1.7905\r\n",
      "Train Epoch: 1 [90080/110534 (81%)]\tClassification Loss: 1.3937\r\n",
      "Train Epoch: 1 [90240/110534 (82%)]\tClassification Loss: 1.8350\r\n",
      "Train Epoch: 1 [90400/110534 (82%)]\tClassification Loss: 1.6904\r\n",
      "Train Epoch: 1 [90560/110534 (82%)]\tClassification Loss: 1.3278\r\n",
      "Train Epoch: 1 [90720/110534 (82%)]\tClassification Loss: 1.4273\r\n",
      "Train Epoch: 1 [90880/110534 (82%)]\tClassification Loss: 1.5492\r\n",
      "Train Epoch: 1 [91040/110534 (82%)]\tClassification Loss: 1.8497\r\n",
      "Test() called at batch_idx: 5700\r\n",
      "\r\n",
      "Test set: Average loss: 1.5385, Accuracy: 279/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [91200/110534 (83%)]\tClassification Loss: 2.1638\r\n",
      "Train Epoch: 1 [91360/110534 (83%)]\tClassification Loss: 1.1038\r\n",
      "Train Epoch: 1 [91520/110534 (83%)]\tClassification Loss: 1.8015\r\n",
      "Train Epoch: 1 [91680/110534 (83%)]\tClassification Loss: 1.9757\r\n",
      "Train Epoch: 1 [91840/110534 (83%)]\tClassification Loss: 1.7666\r\n",
      "Train Epoch: 1 [92000/110534 (83%)]\tClassification Loss: 1.9808\r\n",
      "Train Epoch: 1 [92160/110534 (83%)]\tClassification Loss: 1.8300\r\n",
      "Train Epoch: 1 [92320/110534 (84%)]\tClassification Loss: 2.1043\r\n",
      "Train Epoch: 1 [92480/110534 (84%)]\tClassification Loss: 1.6668\r\n",
      "Train Epoch: 1 [92640/110534 (84%)]\tClassification Loss: 1.5013\r\n",
      "Test() called at batch_idx: 5800\r\n",
      "\r\n",
      "Test set: Average loss: 1.5357, Accuracy: 282/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [92800/110534 (84%)]\tClassification Loss: 2.3808\r\n",
      "Train Epoch: 1 [92960/110534 (84%)]\tClassification Loss: 1.8299\r\n",
      "Train Epoch: 1 [93120/110534 (84%)]\tClassification Loss: 2.1099\r\n",
      "Train Epoch: 1 [93280/110534 (84%)]\tClassification Loss: 1.7418\r\n",
      "Train Epoch: 1 [93440/110534 (85%)]\tClassification Loss: 2.1677\r\n",
      "Train Epoch: 1 [93600/110534 (85%)]\tClassification Loss: 1.5658\r\n",
      "Train Epoch: 1 [93760/110534 (85%)]\tClassification Loss: 1.6270\r\n",
      "Train Epoch: 1 [93920/110534 (85%)]\tClassification Loss: 1.6776\r\n",
      "Train Epoch: 1 [94080/110534 (85%)]\tClassification Loss: 1.9644\r\n",
      "Train Epoch: 1 [94240/110534 (85%)]\tClassification Loss: 2.3322\r\n",
      "Test() called at batch_idx: 5900\r\n",
      "\r\n",
      "Test set: Average loss: 1.5336, Accuracy: 286/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 1 [94400/110534 (85%)]\tClassification Loss: 1.4862\r\n",
      "Train Epoch: 1 [94560/110534 (86%)]\tClassification Loss: 1.6985\r\n",
      "Train Epoch: 1 [94720/110534 (86%)]\tClassification Loss: 1.4748\r\n",
      "Train Epoch: 1 [94880/110534 (86%)]\tClassification Loss: 1.2878\r\n",
      "Train Epoch: 1 [95040/110534 (86%)]\tClassification Loss: 1.2509\r\n",
      "Train Epoch: 1 [95200/110534 (86%)]\tClassification Loss: 1.2562\r\n",
      "Train Epoch: 1 [95360/110534 (86%)]\tClassification Loss: 1.8459\r\n",
      "Train Epoch: 1 [95520/110534 (86%)]\tClassification Loss: 1.5019\r\n",
      "Train Epoch: 1 [95680/110534 (87%)]\tClassification Loss: 1.5618\r\n",
      "Train Epoch: 1 [95840/110534 (87%)]\tClassification Loss: 1.1384\r\n",
      "Test() called at batch_idx: 6000\r\n",
      "\r\n",
      "Test set: Average loss: 1.5298, Accuracy: 282/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [96000/110534 (87%)]\tClassification Loss: 1.9285\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_6000.pth.tar\r\n",
      "Train Epoch: 1 [96160/110534 (87%)]\tClassification Loss: 1.9298\r\n",
      "Train Epoch: 1 [96320/110534 (87%)]\tClassification Loss: 1.4298\r\n",
      "Train Epoch: 1 [96480/110534 (87%)]\tClassification Loss: 1.2941\r\n",
      "Train Epoch: 1 [96640/110534 (87%)]\tClassification Loss: 1.3445\r\n",
      "Train Epoch: 1 [96800/110534 (88%)]\tClassification Loss: 1.6029\r\n",
      "Train Epoch: 1 [96960/110534 (88%)]\tClassification Loss: 1.2074\r\n",
      "Train Epoch: 1 [97120/110534 (88%)]\tClassification Loss: 1.9419\r\n",
      "Train Epoch: 1 [97280/110534 (88%)]\tClassification Loss: 1.4333\r\n",
      "Train Epoch: 1 [97440/110534 (88%)]\tClassification Loss: 2.0318\r\n",
      "Test() called at batch_idx: 6100\r\n",
      "\r\n",
      "Test set: Average loss: 1.5399, Accuracy: 278/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [97600/110534 (88%)]\tClassification Loss: 2.3158\r\n",
      "Train Epoch: 1 [97760/110534 (88%)]\tClassification Loss: 1.6710\r\n",
      "Train Epoch: 1 [97920/110534 (89%)]\tClassification Loss: 1.5249\r\n",
      "Train Epoch: 1 [98080/110534 (89%)]\tClassification Loss: 1.3652\r\n",
      "Train Epoch: 1 [98240/110534 (89%)]\tClassification Loss: 1.5329\r\n",
      "Train Epoch: 1 [98400/110534 (89%)]\tClassification Loss: 1.6994\r\n",
      "Train Epoch: 1 [98560/110534 (89%)]\tClassification Loss: 1.7602\r\n",
      "Train Epoch: 1 [98720/110534 (89%)]\tClassification Loss: 0.8863\r\n",
      "Train Epoch: 1 [98880/110534 (89%)]\tClassification Loss: 1.6902\r\n",
      "Train Epoch: 1 [99040/110534 (90%)]\tClassification Loss: 1.8159\r\n",
      "Test() called at batch_idx: 6200\r\n",
      "\r\n",
      "Test set: Average loss: 1.5296, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 1 [99200/110534 (90%)]\tClassification Loss: 2.2236\r\n",
      "Train Epoch: 1 [99360/110534 (90%)]\tClassification Loss: 1.5486\r\n",
      "Train Epoch: 1 [99520/110534 (90%)]\tClassification Loss: 2.1843\r\n",
      "Train Epoch: 1 [99680/110534 (90%)]\tClassification Loss: 1.3091\r\n",
      "Train Epoch: 1 [99840/110534 (90%)]\tClassification Loss: 2.0266\r\n",
      "Train Epoch: 1 [100000/110534 (90%)]\tClassification Loss: 1.6786\r\n",
      "Train Epoch: 1 [100160/110534 (91%)]\tClassification Loss: 2.5809\r\n",
      "Train Epoch: 1 [100320/110534 (91%)]\tClassification Loss: 1.3875\r\n",
      "Train Epoch: 1 [100480/110534 (91%)]\tClassification Loss: 1.8805\r\n",
      "Train Epoch: 1 [100640/110534 (91%)]\tClassification Loss: 1.5050\r\n",
      "Test() called at batch_idx: 6300\r\n",
      "\r\n",
      "Test set: Average loss: 1.5217, Accuracy: 286/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 1 [100800/110534 (91%)]\tClassification Loss: 1.2905\r\n",
      "Train Epoch: 1 [100960/110534 (91%)]\tClassification Loss: 1.8918\r\n",
      "Train Epoch: 1 [101120/110534 (91%)]\tClassification Loss: 1.6860\r\n",
      "Train Epoch: 1 [101280/110534 (92%)]\tClassification Loss: 1.1828\r\n",
      "Train Epoch: 1 [101440/110534 (92%)]\tClassification Loss: 1.3251\r\n",
      "Train Epoch: 1 [101600/110534 (92%)]\tClassification Loss: 1.9654\r\n",
      "Train Epoch: 1 [101760/110534 (92%)]\tClassification Loss: 1.9337\r\n",
      "Train Epoch: 1 [101920/110534 (92%)]\tClassification Loss: 1.6188\r\n",
      "Train Epoch: 1 [102080/110534 (92%)]\tClassification Loss: 1.7853\r\n",
      "Train Epoch: 1 [102240/110534 (92%)]\tClassification Loss: 1.5622\r\n",
      "Test() called at batch_idx: 6400\r\n",
      "\r\n",
      "Test set: Average loss: 1.5189, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 1 [102400/110534 (93%)]\tClassification Loss: 1.6174\r\n",
      "Train Epoch: 1 [102560/110534 (93%)]\tClassification Loss: 1.7694\r\n",
      "Train Epoch: 1 [102720/110534 (93%)]\tClassification Loss: 2.0493\r\n",
      "Train Epoch: 1 [102880/110534 (93%)]\tClassification Loss: 1.9873\r\n",
      "Train Epoch: 1 [103040/110534 (93%)]\tClassification Loss: 1.2890\r\n",
      "Train Epoch: 1 [103200/110534 (93%)]\tClassification Loss: 1.3441\r\n",
      "Train Epoch: 1 [103360/110534 (94%)]\tClassification Loss: 1.6202\r\n",
      "Train Epoch: 1 [103520/110534 (94%)]\tClassification Loss: 2.1429\r\n",
      "Train Epoch: 1 [103680/110534 (94%)]\tClassification Loss: 1.4795\r\n",
      "Train Epoch: 1 [103840/110534 (94%)]\tClassification Loss: 1.7216\r\n",
      "Test() called at batch_idx: 6500\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\r\n",
      "    self._send(header + buf)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\r\n",
      "    n = write(self._handle, buf)\r\n",
      "BrokenPipeError: [Errno 32] Broken pipe\r\n",
      "\r\n",
      "Test set: Average loss: 1.5430, Accuracy: 278/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [104000/110534 (94%)]\tClassification Loss: 1.6139\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_6500.pth.tar\r\n",
      "Train Epoch: 1 [104160/110534 (94%)]\tClassification Loss: 1.4467\r\n",
      "Train Epoch: 1 [104320/110534 (94%)]\tClassification Loss: 2.1583\r\n",
      "Train Epoch: 1 [104480/110534 (95%)]\tClassification Loss: 1.5799\r\n",
      "Train Epoch: 1 [104640/110534 (95%)]\tClassification Loss: 2.0265\r\n",
      "Train Epoch: 1 [104800/110534 (95%)]\tClassification Loss: 1.3410\r\n",
      "Train Epoch: 1 [104960/110534 (95%)]\tClassification Loss: 1.3422\r\n",
      "Train Epoch: 1 [105120/110534 (95%)]\tClassification Loss: 1.6176\r\n",
      "Train Epoch: 1 [105280/110534 (95%)]\tClassification Loss: 1.5795\r\n",
      "Train Epoch: 1 [105440/110534 (95%)]\tClassification Loss: 1.6484\r\n",
      "Test() called at batch_idx: 6600\r\n",
      "\r\n",
      "Test set: Average loss: 1.5346, Accuracy: 282/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [105600/110534 (96%)]\tClassification Loss: 1.7964\r\n",
      "Train Epoch: 1 [105760/110534 (96%)]\tClassification Loss: 1.1168\r\n",
      "Train Epoch: 1 [105920/110534 (96%)]\tClassification Loss: 1.6183\r\n",
      "Train Epoch: 1 [106080/110534 (96%)]\tClassification Loss: 1.4851\r\n",
      "Train Epoch: 1 [106240/110534 (96%)]\tClassification Loss: 2.1488\r\n",
      "Train Epoch: 1 [106400/110534 (96%)]\tClassification Loss: 2.1028\r\n",
      "Train Epoch: 1 [106560/110534 (96%)]\tClassification Loss: 2.5046\r\n",
      "Train Epoch: 1 [106720/110534 (97%)]\tClassification Loss: 1.8630\r\n",
      "Train Epoch: 1 [106880/110534 (97%)]\tClassification Loss: 1.5291\r\n",
      "Train Epoch: 1 [107040/110534 (97%)]\tClassification Loss: 1.2891\r\n",
      "Test() called at batch_idx: 6700\r\n",
      "\r\n",
      "Test set: Average loss: 1.5221, Accuracy: 284/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [107200/110534 (97%)]\tClassification Loss: 1.4496\r\n",
      "Train Epoch: 1 [107360/110534 (97%)]\tClassification Loss: 1.4436\r\n",
      "Train Epoch: 1 [107520/110534 (97%)]\tClassification Loss: 1.4562\r\n",
      "Train Epoch: 1 [107680/110534 (97%)]\tClassification Loss: 1.3366\r\n",
      "Train Epoch: 1 [107840/110534 (98%)]\tClassification Loss: 1.2811\r\n",
      "Train Epoch: 1 [108000/110534 (98%)]\tClassification Loss: 1.2774\r\n",
      "Train Epoch: 1 [108160/110534 (98%)]\tClassification Loss: 1.4330\r\n",
      "Train Epoch: 1 [108320/110534 (98%)]\tClassification Loss: 1.8459\r\n",
      "Train Epoch: 1 [108480/110534 (98%)]\tClassification Loss: 1.2715\r\n",
      "Train Epoch: 1 [108640/110534 (98%)]\tClassification Loss: 1.8055\r\n",
      "Test() called at batch_idx: 6800\r\n",
      "\r\n",
      "Test set: Average loss: 1.5167, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 1 [108800/110534 (98%)]\tClassification Loss: 1.5955\r\n",
      "Train Epoch: 1 [108960/110534 (99%)]\tClassification Loss: 1.6106\r\n",
      "Train Epoch: 1 [109120/110534 (99%)]\tClassification Loss: 1.3601\r\n",
      "Train Epoch: 1 [109280/110534 (99%)]\tClassification Loss: 1.4519\r\n",
      "Train Epoch: 1 [109440/110534 (99%)]\tClassification Loss: 1.8960\r\n",
      "Train Epoch: 1 [109600/110534 (99%)]\tClassification Loss: 1.5238\r\n",
      "Train Epoch: 1 [109760/110534 (99%)]\tClassification Loss: 1.1083\r\n",
      "Train Epoch: 1 [109920/110534 (99%)]\tClassification Loss: 1.3786\r\n",
      "Train Epoch: 1 [110080/110534 (100%)]\tClassification Loss: 1.6362\r\n",
      "Train Epoch: 1 [110240/110534 (100%)]\tClassification Loss: 1.5110\r\n",
      "Test() called at batch_idx: 6900\r\n",
      "\r\n",
      "Test set: Average loss: 1.5091, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 1 [110400/110534 (100%)]\tClassification Loss: 1.4046\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_final.pth.tar\r\n",
      "Test() called at batch_idx: 0\r\n",
      "\r\n",
      "Test set: Average loss: 1.5149, Accuracy: 282/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [0/110534 (0%)]\tClassification Loss: 1.3579\r\n",
      "Train Epoch: 2 [160/110534 (0%)]\tClassification Loss: 1.9178\r\n",
      "Train Epoch: 2 [320/110534 (0%)]\tClassification Loss: 1.4980\r\n",
      "Train Epoch: 2 [480/110534 (0%)]\tClassification Loss: 1.3834\r\n",
      "Train Epoch: 2 [640/110534 (1%)]\tClassification Loss: 1.7050\r\n",
      "Train Epoch: 2 [800/110534 (1%)]\tClassification Loss: 2.0559\r\n",
      "Train Epoch: 2 [960/110534 (1%)]\tClassification Loss: 1.5003\r\n",
      "Train Epoch: 2 [1120/110534 (1%)]\tClassification Loss: 1.3783\r\n",
      "Train Epoch: 2 [1280/110534 (1%)]\tClassification Loss: 1.6133\r\n",
      "Train Epoch: 2 [1440/110534 (1%)]\tClassification Loss: 2.2730\r\n",
      "Test() called at batch_idx: 100\r\n",
      "\r\n",
      "Test set: Average loss: 1.5098, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [1600/110534 (1%)]\tClassification Loss: 1.3295\r\n",
      "Train Epoch: 2 [1760/110534 (2%)]\tClassification Loss: 1.6881\r\n",
      "Train Epoch: 2 [1920/110534 (2%)]\tClassification Loss: 2.0057\r\n",
      "Train Epoch: 2 [2080/110534 (2%)]\tClassification Loss: 1.4883\r\n",
      "Train Epoch: 2 [2240/110534 (2%)]\tClassification Loss: 2.1335\r\n",
      "Train Epoch: 2 [2400/110534 (2%)]\tClassification Loss: 1.3029\r\n",
      "Train Epoch: 2 [2560/110534 (2%)]\tClassification Loss: 1.9427\r\n",
      "Train Epoch: 2 [2720/110534 (2%)]\tClassification Loss: 1.6479\r\n",
      "Train Epoch: 2 [2880/110534 (3%)]\tClassification Loss: 1.5485\r\n",
      "Train Epoch: 2 [3040/110534 (3%)]\tClassification Loss: 1.6937\r\n",
      "Test() called at batch_idx: 200\r\n",
      "\r\n",
      "Test set: Average loss: 1.5074, Accuracy: 291/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [3200/110534 (3%)]\tClassification Loss: 1.8267\r\n",
      "Train Epoch: 2 [3360/110534 (3%)]\tClassification Loss: 1.1433\r\n",
      "Train Epoch: 2 [3520/110534 (3%)]\tClassification Loss: 1.6083\r\n",
      "Train Epoch: 2 [3680/110534 (3%)]\tClassification Loss: 1.4902\r\n",
      "Train Epoch: 2 [3840/110534 (3%)]\tClassification Loss: 1.6721\r\n",
      "Train Epoch: 2 [4000/110534 (4%)]\tClassification Loss: 1.7768\r\n",
      "Train Epoch: 2 [4160/110534 (4%)]\tClassification Loss: 1.4818\r\n",
      "Train Epoch: 2 [4320/110534 (4%)]\tClassification Loss: 1.7216\r\n",
      "Train Epoch: 2 [4480/110534 (4%)]\tClassification Loss: 1.5594\r\n",
      "Train Epoch: 2 [4640/110534 (4%)]\tClassification Loss: 1.5968\r\n",
      "Test() called at batch_idx: 300\r\n",
      "\r\n",
      "Test set: Average loss: 1.5056, Accuracy: 291/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [4800/110534 (4%)]\tClassification Loss: 1.5866\r\n",
      "Train Epoch: 2 [4960/110534 (4%)]\tClassification Loss: 1.8445\r\n",
      "Train Epoch: 2 [5120/110534 (5%)]\tClassification Loss: 1.1174\r\n",
      "Train Epoch: 2 [5280/110534 (5%)]\tClassification Loss: 1.8390\r\n",
      "Train Epoch: 2 [5440/110534 (5%)]\tClassification Loss: 1.3776\r\n",
      "Train Epoch: 2 [5600/110534 (5%)]\tClassification Loss: 1.3988\r\n",
      "Train Epoch: 2 [5760/110534 (5%)]\tClassification Loss: 1.9024\r\n",
      "Train Epoch: 2 [5920/110534 (5%)]\tClassification Loss: 2.2760\r\n",
      "Train Epoch: 2 [6080/110534 (6%)]\tClassification Loss: 1.8309\r\n",
      "Train Epoch: 2 [6240/110534 (6%)]\tClassification Loss: 2.1754\r\n",
      "Test() called at batch_idx: 400\r\n",
      "\r\n",
      "Test set: Average loss: 1.5008, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [6400/110534 (6%)]\tClassification Loss: 1.6169\r\n",
      "Train Epoch: 2 [6560/110534 (6%)]\tClassification Loss: 1.8264\r\n",
      "Train Epoch: 2 [6720/110534 (6%)]\tClassification Loss: 1.9496\r\n",
      "Train Epoch: 2 [6880/110534 (6%)]\tClassification Loss: 1.5573\r\n",
      "Train Epoch: 2 [7040/110534 (6%)]\tClassification Loss: 1.2615\r\n",
      "Train Epoch: 2 [7200/110534 (7%)]\tClassification Loss: 1.4801\r\n",
      "Train Epoch: 2 [7360/110534 (7%)]\tClassification Loss: 1.6874\r\n",
      "Train Epoch: 2 [7520/110534 (7%)]\tClassification Loss: 2.4014\r\n",
      "Train Epoch: 2 [7680/110534 (7%)]\tClassification Loss: 1.6995\r\n",
      "Train Epoch: 2 [7840/110534 (7%)]\tClassification Loss: 1.7621\r\n",
      "Test() called at batch_idx: 500\r\n",
      "\r\n",
      "Test set: Average loss: 1.5080, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [8000/110534 (7%)]\tClassification Loss: 1.5416\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_500.pth.tar\r\n",
      "Train Epoch: 2 [8160/110534 (7%)]\tClassification Loss: 2.0032\r\n",
      "Train Epoch: 2 [8320/110534 (8%)]\tClassification Loss: 1.6451\r\n",
      "Train Epoch: 2 [8480/110534 (8%)]\tClassification Loss: 1.0701\r\n",
      "Train Epoch: 2 [8640/110534 (8%)]\tClassification Loss: 1.6418\r\n",
      "Train Epoch: 2 [8800/110534 (8%)]\tClassification Loss: 1.8637\r\n",
      "Train Epoch: 2 [8960/110534 (8%)]\tClassification Loss: 1.4373\r\n",
      "Train Epoch: 2 [9120/110534 (8%)]\tClassification Loss: 1.2279\r\n",
      "Train Epoch: 2 [9280/110534 (8%)]\tClassification Loss: 1.8177\r\n",
      "Train Epoch: 2 [9440/110534 (9%)]\tClassification Loss: 1.8411\r\n",
      "Test() called at batch_idx: 600\r\n",
      "\r\n",
      "Test set: Average loss: 1.5000, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [9600/110534 (9%)]\tClassification Loss: 1.2185\r\n",
      "Train Epoch: 2 [9760/110534 (9%)]\tClassification Loss: 2.2856\r\n",
      "Train Epoch: 2 [9920/110534 (9%)]\tClassification Loss: 1.8190\r\n",
      "Train Epoch: 2 [10080/110534 (9%)]\tClassification Loss: 1.3494\r\n",
      "Train Epoch: 2 [10240/110534 (9%)]\tClassification Loss: 2.2075\r\n",
      "Train Epoch: 2 [10400/110534 (9%)]\tClassification Loss: 1.6951\r\n",
      "Train Epoch: 2 [10560/110534 (10%)]\tClassification Loss: 1.5229\r\n",
      "Train Epoch: 2 [10720/110534 (10%)]\tClassification Loss: 1.7416\r\n",
      "Train Epoch: 2 [10880/110534 (10%)]\tClassification Loss: 1.3758\r\n",
      "Train Epoch: 2 [11040/110534 (10%)]\tClassification Loss: 1.1887\r\n",
      "Test() called at batch_idx: 700\r\n",
      "\r\n",
      "Test set: Average loss: 1.5071, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [11200/110534 (10%)]\tClassification Loss: 1.5585\r\n",
      "Train Epoch: 2 [11360/110534 (10%)]\tClassification Loss: 1.7414\r\n",
      "Train Epoch: 2 [11520/110534 (10%)]\tClassification Loss: 2.3561\r\n",
      "Train Epoch: 2 [11680/110534 (11%)]\tClassification Loss: 1.8135\r\n",
      "Train Epoch: 2 [11840/110534 (11%)]\tClassification Loss: 1.7460\r\n",
      "Train Epoch: 2 [12000/110534 (11%)]\tClassification Loss: 1.6083\r\n",
      "Train Epoch: 2 [12160/110534 (11%)]\tClassification Loss: 1.5865\r\n",
      "Train Epoch: 2 [12320/110534 (11%)]\tClassification Loss: 1.7435\r\n",
      "Train Epoch: 2 [12480/110534 (11%)]\tClassification Loss: 1.2800\r\n",
      "Train Epoch: 2 [12640/110534 (11%)]\tClassification Loss: 1.4057\r\n",
      "Test() called at batch_idx: 800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4907, Accuracy: 289/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [12800/110534 (12%)]\tClassification Loss: 1.6958\r\n",
      "Train Epoch: 2 [12960/110534 (12%)]\tClassification Loss: 1.7947\r\n",
      "Train Epoch: 2 [13120/110534 (12%)]\tClassification Loss: 1.4392\r\n",
      "Train Epoch: 2 [13280/110534 (12%)]\tClassification Loss: 1.4758\r\n",
      "Train Epoch: 2 [13440/110534 (12%)]\tClassification Loss: 1.8845\r\n",
      "Train Epoch: 2 [13600/110534 (12%)]\tClassification Loss: 1.8585\r\n",
      "Train Epoch: 2 [13760/110534 (12%)]\tClassification Loss: 1.7855\r\n",
      "Train Epoch: 2 [13920/110534 (13%)]\tClassification Loss: 1.5356\r\n",
      "Train Epoch: 2 [14080/110534 (13%)]\tClassification Loss: 1.4788\r\n",
      "Train Epoch: 2 [14240/110534 (13%)]\tClassification Loss: 1.8526\r\n",
      "Test() called at batch_idx: 900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4969, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [14400/110534 (13%)]\tClassification Loss: 1.7730\r\n",
      "Train Epoch: 2 [14560/110534 (13%)]\tClassification Loss: 1.0874\r\n",
      "Train Epoch: 2 [14720/110534 (13%)]\tClassification Loss: 1.1091\r\n",
      "Train Epoch: 2 [14880/110534 (13%)]\tClassification Loss: 1.4120\r\n",
      "Train Epoch: 2 [15040/110534 (14%)]\tClassification Loss: 1.3271\r\n",
      "Train Epoch: 2 [15200/110534 (14%)]\tClassification Loss: 2.0712\r\n",
      "Train Epoch: 2 [15360/110534 (14%)]\tClassification Loss: 1.1457\r\n",
      "Train Epoch: 2 [15520/110534 (14%)]\tClassification Loss: 0.9830\r\n",
      "Train Epoch: 2 [15680/110534 (14%)]\tClassification Loss: 1.6495\r\n",
      "Train Epoch: 2 [15840/110534 (14%)]\tClassification Loss: 1.6297\r\n",
      "Test() called at batch_idx: 1000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4983, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [16000/110534 (14%)]\tClassification Loss: 1.1526\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1000.pth.tar\r\n",
      "Train Epoch: 2 [16160/110534 (15%)]\tClassification Loss: 1.5273\r\n",
      "Train Epoch: 2 [16320/110534 (15%)]\tClassification Loss: 2.4712\r\n",
      "Train Epoch: 2 [16480/110534 (15%)]\tClassification Loss: 1.8613\r\n",
      "Train Epoch: 2 [16640/110534 (15%)]\tClassification Loss: 1.6517\r\n",
      "Train Epoch: 2 [16800/110534 (15%)]\tClassification Loss: 1.3908\r\n",
      "Train Epoch: 2 [16960/110534 (15%)]\tClassification Loss: 1.5715\r\n",
      "Train Epoch: 2 [17120/110534 (15%)]\tClassification Loss: 1.7271\r\n",
      "Train Epoch: 2 [17280/110534 (16%)]\tClassification Loss: 1.4370\r\n",
      "Train Epoch: 2 [17440/110534 (16%)]\tClassification Loss: 1.1990\r\n",
      "Test() called at batch_idx: 1100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4940, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [17600/110534 (16%)]\tClassification Loss: 1.7398\r\n",
      "Train Epoch: 2 [17760/110534 (16%)]\tClassification Loss: 1.7038\r\n",
      "Train Epoch: 2 [17920/110534 (16%)]\tClassification Loss: 1.5456\r\n",
      "Train Epoch: 2 [18080/110534 (16%)]\tClassification Loss: 1.2289\r\n",
      "Train Epoch: 2 [18240/110534 (17%)]\tClassification Loss: 1.7872\r\n",
      "Train Epoch: 2 [18400/110534 (17%)]\tClassification Loss: 1.7383\r\n",
      "Train Epoch: 2 [18560/110534 (17%)]\tClassification Loss: 1.9600\r\n",
      "Train Epoch: 2 [18720/110534 (17%)]\tClassification Loss: 2.1791\r\n",
      "Train Epoch: 2 [18880/110534 (17%)]\tClassification Loss: 1.5675\r\n",
      "Train Epoch: 2 [19040/110534 (17%)]\tClassification Loss: 2.0274\r\n",
      "Test() called at batch_idx: 1200\r\n",
      "\r\n",
      "Test set: Average loss: 1.5038, Accuracy: 286/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [19200/110534 (17%)]\tClassification Loss: 1.4353\r\n",
      "Train Epoch: 2 [19360/110534 (18%)]\tClassification Loss: 1.5293\r\n",
      "Train Epoch: 2 [19520/110534 (18%)]\tClassification Loss: 1.2877\r\n",
      "Train Epoch: 2 [19680/110534 (18%)]\tClassification Loss: 2.0538\r\n",
      "Train Epoch: 2 [19840/110534 (18%)]\tClassification Loss: 1.5391\r\n",
      "Train Epoch: 2 [20000/110534 (18%)]\tClassification Loss: 2.0201\r\n",
      "Train Epoch: 2 [20160/110534 (18%)]\tClassification Loss: 1.5482\r\n",
      "Train Epoch: 2 [20320/110534 (18%)]\tClassification Loss: 1.6593\r\n",
      "Train Epoch: 2 [20480/110534 (19%)]\tClassification Loss: 1.2007\r\n",
      "Train Epoch: 2 [20640/110534 (19%)]\tClassification Loss: 1.3416\r\n",
      "Test() called at batch_idx: 1300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4980, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [20800/110534 (19%)]\tClassification Loss: 1.6433\r\n",
      "Train Epoch: 2 [20960/110534 (19%)]\tClassification Loss: 1.2797\r\n",
      "Train Epoch: 2 [21120/110534 (19%)]\tClassification Loss: 2.0456\r\n",
      "Train Epoch: 2 [21280/110534 (19%)]\tClassification Loss: 1.4770\r\n",
      "Train Epoch: 2 [21440/110534 (19%)]\tClassification Loss: 1.5185\r\n",
      "Train Epoch: 2 [21600/110534 (20%)]\tClassification Loss: 1.3915\r\n",
      "Train Epoch: 2 [21760/110534 (20%)]\tClassification Loss: 1.3732\r\n",
      "Train Epoch: 2 [21920/110534 (20%)]\tClassification Loss: 1.7852\r\n",
      "Train Epoch: 2 [22080/110534 (20%)]\tClassification Loss: 1.5081\r\n",
      "Train Epoch: 2 [22240/110534 (20%)]\tClassification Loss: 1.3652\r\n",
      "Test() called at batch_idx: 1400\r\n",
      "\r\n",
      "Test set: Average loss: 1.5011, Accuracy: 283/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [22400/110534 (20%)]\tClassification Loss: 1.7572\r\n",
      "Train Epoch: 2 [22560/110534 (20%)]\tClassification Loss: 1.5081\r\n",
      "Train Epoch: 2 [22720/110534 (21%)]\tClassification Loss: 1.9005\r\n",
      "Train Epoch: 2 [22880/110534 (21%)]\tClassification Loss: 1.8560\r\n",
      "Train Epoch: 2 [23040/110534 (21%)]\tClassification Loss: 2.0987\r\n",
      "Train Epoch: 2 [23200/110534 (21%)]\tClassification Loss: 1.5421\r\n",
      "Train Epoch: 2 [23360/110534 (21%)]\tClassification Loss: 1.0912\r\n",
      "Train Epoch: 2 [23520/110534 (21%)]\tClassification Loss: 1.9865\r\n",
      "Train Epoch: 2 [23680/110534 (21%)]\tClassification Loss: 1.7715\r\n",
      "Train Epoch: 2 [23840/110534 (22%)]\tClassification Loss: 1.6193\r\n",
      "Test() called at batch_idx: 1500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4944, Accuracy: 284/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [24000/110534 (22%)]\tClassification Loss: 1.6920\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1500.pth.tar\r\n",
      "Train Epoch: 2 [24160/110534 (22%)]\tClassification Loss: 1.6136\r\n",
      "Train Epoch: 2 [24320/110534 (22%)]\tClassification Loss: 1.4498\r\n",
      "Train Epoch: 2 [24480/110534 (22%)]\tClassification Loss: 1.9594\r\n",
      "Train Epoch: 2 [24640/110534 (22%)]\tClassification Loss: 1.7244\r\n",
      "Train Epoch: 2 [24800/110534 (22%)]\tClassification Loss: 1.0464\r\n",
      "Train Epoch: 2 [24960/110534 (23%)]\tClassification Loss: 1.4422\r\n",
      "Train Epoch: 2 [25120/110534 (23%)]\tClassification Loss: 1.4409\r\n",
      "Train Epoch: 2 [25280/110534 (23%)]\tClassification Loss: 1.5864\r\n",
      "Train Epoch: 2 [25440/110534 (23%)]\tClassification Loss: 2.4680\r\n",
      "Test() called at batch_idx: 1600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4842, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [25600/110534 (23%)]\tClassification Loss: 1.7801\r\n",
      "Train Epoch: 2 [25760/110534 (23%)]\tClassification Loss: 1.8400\r\n",
      "Train Epoch: 2 [25920/110534 (23%)]\tClassification Loss: 1.6781\r\n",
      "Train Epoch: 2 [26080/110534 (24%)]\tClassification Loss: 1.3682\r\n",
      "Train Epoch: 2 [26240/110534 (24%)]\tClassification Loss: 1.2889\r\n",
      "Train Epoch: 2 [26400/110534 (24%)]\tClassification Loss: 1.7071\r\n",
      "Train Epoch: 2 [26560/110534 (24%)]\tClassification Loss: 1.4710\r\n",
      "Train Epoch: 2 [26720/110534 (24%)]\tClassification Loss: 1.6126\r\n",
      "Train Epoch: 2 [26880/110534 (24%)]\tClassification Loss: 0.8977\r\n",
      "Train Epoch: 2 [27040/110534 (24%)]\tClassification Loss: 1.8585\r\n",
      "Test() called at batch_idx: 1700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4919, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [27200/110534 (25%)]\tClassification Loss: 1.6291\r\n",
      "Train Epoch: 2 [27360/110534 (25%)]\tClassification Loss: 1.8848\r\n",
      "Train Epoch: 2 [27520/110534 (25%)]\tClassification Loss: 1.3885\r\n",
      "Train Epoch: 2 [27680/110534 (25%)]\tClassification Loss: 1.9935\r\n",
      "Train Epoch: 2 [27840/110534 (25%)]\tClassification Loss: 1.5535\r\n",
      "Train Epoch: 2 [28000/110534 (25%)]\tClassification Loss: 1.5628\r\n",
      "Train Epoch: 2 [28160/110534 (25%)]\tClassification Loss: 1.3948\r\n",
      "Train Epoch: 2 [28320/110534 (26%)]\tClassification Loss: 1.3906\r\n",
      "Train Epoch: 2 [28480/110534 (26%)]\tClassification Loss: 1.2541\r\n",
      "Train Epoch: 2 [28640/110534 (26%)]\tClassification Loss: 2.7536\r\n",
      "Test() called at batch_idx: 1800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4856, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [28800/110534 (26%)]\tClassification Loss: 1.8280\r\n",
      "Train Epoch: 2 [28960/110534 (26%)]\tClassification Loss: 1.5843\r\n",
      "Train Epoch: 2 [29120/110534 (26%)]\tClassification Loss: 1.3752\r\n",
      "Train Epoch: 2 [29280/110534 (26%)]\tClassification Loss: 1.5203\r\n",
      "Train Epoch: 2 [29440/110534 (27%)]\tClassification Loss: 1.8681\r\n",
      "Train Epoch: 2 [29600/110534 (27%)]\tClassification Loss: 1.7738\r\n",
      "Train Epoch: 2 [29760/110534 (27%)]\tClassification Loss: 1.5303\r\n",
      "Train Epoch: 2 [29920/110534 (27%)]\tClassification Loss: 1.6486\r\n",
      "Train Epoch: 2 [30080/110534 (27%)]\tClassification Loss: 0.8985\r\n",
      "Train Epoch: 2 [30240/110534 (27%)]\tClassification Loss: 1.5105\r\n",
      "Test() called at batch_idx: 1900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4851, Accuracy: 290/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [30400/110534 (28%)]\tClassification Loss: 1.3263\r\n",
      "Train Epoch: 2 [30560/110534 (28%)]\tClassification Loss: 1.8466\r\n",
      "Train Epoch: 2 [30720/110534 (28%)]\tClassification Loss: 2.0910\r\n",
      "Train Epoch: 2 [30880/110534 (28%)]\tClassification Loss: 1.5522\r\n",
      "Train Epoch: 2 [31040/110534 (28%)]\tClassification Loss: 1.0206\r\n",
      "Train Epoch: 2 [31200/110534 (28%)]\tClassification Loss: 2.0271\r\n",
      "Train Epoch: 2 [31360/110534 (28%)]\tClassification Loss: 1.3707\r\n",
      "Train Epoch: 2 [31520/110534 (29%)]\tClassification Loss: 2.0051\r\n",
      "Train Epoch: 2 [31680/110534 (29%)]\tClassification Loss: 1.8722\r\n",
      "Train Epoch: 2 [31840/110534 (29%)]\tClassification Loss: 1.7681\r\n",
      "Test() called at batch_idx: 2000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4851, Accuracy: 290/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [32000/110534 (29%)]\tClassification Loss: 1.1052\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_2000.pth.tar\r\n",
      "Train Epoch: 2 [32160/110534 (29%)]\tClassification Loss: 1.5363\r\n",
      "Train Epoch: 2 [32320/110534 (29%)]\tClassification Loss: 1.7692\r\n",
      "Train Epoch: 2 [32480/110534 (29%)]\tClassification Loss: 1.2948\r\n",
      "Train Epoch: 2 [32640/110534 (30%)]\tClassification Loss: 1.2736\r\n",
      "Train Epoch: 2 [32800/110534 (30%)]\tClassification Loss: 1.3662\r\n",
      "Train Epoch: 2 [32960/110534 (30%)]\tClassification Loss: 1.3598\r\n",
      "Train Epoch: 2 [33120/110534 (30%)]\tClassification Loss: 1.4746\r\n",
      "Train Epoch: 2 [33280/110534 (30%)]\tClassification Loss: 1.3145\r\n",
      "Train Epoch: 2 [33440/110534 (30%)]\tClassification Loss: 1.4164\r\n",
      "Test() called at batch_idx: 2100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4945, Accuracy: 290/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [33600/110534 (30%)]\tClassification Loss: 1.6306\r\n",
      "Train Epoch: 2 [33760/110534 (31%)]\tClassification Loss: 1.1654\r\n",
      "Train Epoch: 2 [33920/110534 (31%)]\tClassification Loss: 1.2709\r\n",
      "Train Epoch: 2 [34080/110534 (31%)]\tClassification Loss: 1.1741\r\n",
      "Train Epoch: 2 [34240/110534 (31%)]\tClassification Loss: 1.6685\r\n",
      "Train Epoch: 2 [34400/110534 (31%)]\tClassification Loss: 1.2815\r\n",
      "Train Epoch: 2 [34560/110534 (31%)]\tClassification Loss: 1.2733\r\n",
      "Train Epoch: 2 [34720/110534 (31%)]\tClassification Loss: 1.7781\r\n",
      "Train Epoch: 2 [34880/110534 (32%)]\tClassification Loss: 2.0930\r\n",
      "Train Epoch: 2 [35040/110534 (32%)]\tClassification Loss: 1.3736\r\n",
      "Test() called at batch_idx: 2200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4822, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [35200/110534 (32%)]\tClassification Loss: 1.5236\r\n",
      "Train Epoch: 2 [35360/110534 (32%)]\tClassification Loss: 1.2315\r\n",
      "Train Epoch: 2 [35520/110534 (32%)]\tClassification Loss: 1.7221\r\n",
      "Train Epoch: 2 [35680/110534 (32%)]\tClassification Loss: 1.6760\r\n",
      "Train Epoch: 2 [35840/110534 (32%)]\tClassification Loss: 1.5432\r\n",
      "Train Epoch: 2 [36000/110534 (33%)]\tClassification Loss: 1.5202\r\n",
      "Train Epoch: 2 [36160/110534 (33%)]\tClassification Loss: 2.1360\r\n",
      "Train Epoch: 2 [36320/110534 (33%)]\tClassification Loss: 2.1557\r\n",
      "Train Epoch: 2 [36480/110534 (33%)]\tClassification Loss: 1.8061\r\n",
      "Train Epoch: 2 [36640/110534 (33%)]\tClassification Loss: 1.4350\r\n",
      "Test() called at batch_idx: 2300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4838, Accuracy: 289/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [36800/110534 (33%)]\tClassification Loss: 1.4160\r\n",
      "Train Epoch: 2 [36960/110534 (33%)]\tClassification Loss: 1.4392\r\n",
      "Train Epoch: 2 [37120/110534 (34%)]\tClassification Loss: 1.3719\r\n",
      "Train Epoch: 2 [37280/110534 (34%)]\tClassification Loss: 1.9551\r\n",
      "Train Epoch: 2 [37440/110534 (34%)]\tClassification Loss: 1.6204\r\n",
      "Train Epoch: 2 [37600/110534 (34%)]\tClassification Loss: 1.6241\r\n",
      "Train Epoch: 2 [37760/110534 (34%)]\tClassification Loss: 1.9997\r\n",
      "Train Epoch: 2 [37920/110534 (34%)]\tClassification Loss: 2.2482\r\n",
      "Train Epoch: 2 [38080/110534 (34%)]\tClassification Loss: 1.5725\r\n",
      "Train Epoch: 2 [38240/110534 (35%)]\tClassification Loss: 1.4600\r\n",
      "Test() called at batch_idx: 2400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4717, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [38400/110534 (35%)]\tClassification Loss: 1.5959\r\n",
      "Train Epoch: 2 [38560/110534 (35%)]\tClassification Loss: 1.4897\r\n",
      "Train Epoch: 2 [38720/110534 (35%)]\tClassification Loss: 1.2547\r\n",
      "Train Epoch: 2 [38880/110534 (35%)]\tClassification Loss: 1.1527\r\n",
      "Train Epoch: 2 [39040/110534 (35%)]\tClassification Loss: 1.4439\r\n",
      "Train Epoch: 2 [39200/110534 (35%)]\tClassification Loss: 1.1245\r\n",
      "Train Epoch: 2 [39360/110534 (36%)]\tClassification Loss: 1.2484\r\n",
      "Train Epoch: 2 [39520/110534 (36%)]\tClassification Loss: 1.4837\r\n",
      "Train Epoch: 2 [39680/110534 (36%)]\tClassification Loss: 1.4427\r\n",
      "Train Epoch: 2 [39840/110534 (36%)]\tClassification Loss: 1.5345\r\n",
      "Test() called at batch_idx: 2500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4738, Accuracy: 292/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [40000/110534 (36%)]\tClassification Loss: 1.0524\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_2500.pth.tar\r\n",
      "Train Epoch: 2 [40160/110534 (36%)]\tClassification Loss: 1.7002\r\n",
      "Train Epoch: 2 [40320/110534 (36%)]\tClassification Loss: 2.0962\r\n",
      "Train Epoch: 2 [40480/110534 (37%)]\tClassification Loss: 1.3177\r\n",
      "Train Epoch: 2 [40640/110534 (37%)]\tClassification Loss: 1.2273\r\n",
      "Train Epoch: 2 [40800/110534 (37%)]\tClassification Loss: 1.9629\r\n",
      "Train Epoch: 2 [40960/110534 (37%)]\tClassification Loss: 1.4030\r\n",
      "Train Epoch: 2 [41120/110534 (37%)]\tClassification Loss: 2.8661\r\n",
      "Train Epoch: 2 [41280/110534 (37%)]\tClassification Loss: 1.2620\r\n",
      "Train Epoch: 2 [41440/110534 (37%)]\tClassification Loss: 1.4564\r\n",
      "Test() called at batch_idx: 2600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4758, Accuracy: 286/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [41600/110534 (38%)]\tClassification Loss: 1.3010\r\n",
      "Train Epoch: 2 [41760/110534 (38%)]\tClassification Loss: 1.6051\r\n",
      "Train Epoch: 2 [41920/110534 (38%)]\tClassification Loss: 1.0190\r\n",
      "Train Epoch: 2 [42080/110534 (38%)]\tClassification Loss: 1.3048\r\n",
      "Train Epoch: 2 [42240/110534 (38%)]\tClassification Loss: 1.2488\r\n",
      "Train Epoch: 2 [42400/110534 (38%)]\tClassification Loss: 2.3137\r\n",
      "Train Epoch: 2 [42560/110534 (39%)]\tClassification Loss: 1.2573\r\n",
      "Train Epoch: 2 [42720/110534 (39%)]\tClassification Loss: 2.0348\r\n",
      "Train Epoch: 2 [42880/110534 (39%)]\tClassification Loss: 1.1926\r\n",
      "Train Epoch: 2 [43040/110534 (39%)]\tClassification Loss: 2.0321\r\n",
      "Test() called at batch_idx: 2700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4632, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [43200/110534 (39%)]\tClassification Loss: 1.3446\r\n",
      "Train Epoch: 2 [43360/110534 (39%)]\tClassification Loss: 2.1619\r\n",
      "Train Epoch: 2 [43520/110534 (39%)]\tClassification Loss: 1.3142\r\n",
      "Train Epoch: 2 [43680/110534 (40%)]\tClassification Loss: 1.8722\r\n",
      "Train Epoch: 2 [43840/110534 (40%)]\tClassification Loss: 1.7318\r\n",
      "Train Epoch: 2 [44000/110534 (40%)]\tClassification Loss: 1.3657\r\n",
      "Train Epoch: 2 [44160/110534 (40%)]\tClassification Loss: 1.3173\r\n",
      "Train Epoch: 2 [44320/110534 (40%)]\tClassification Loss: 1.3145\r\n",
      "Train Epoch: 2 [44480/110534 (40%)]\tClassification Loss: 1.7595\r\n",
      "Train Epoch: 2 [44640/110534 (40%)]\tClassification Loss: 1.2456\r\n",
      "Test() called at batch_idx: 2800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4713, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [44800/110534 (41%)]\tClassification Loss: 1.8970\r\n",
      "Train Epoch: 2 [44960/110534 (41%)]\tClassification Loss: 1.6773\r\n",
      "Train Epoch: 2 [45120/110534 (41%)]\tClassification Loss: 1.6337\r\n",
      "Train Epoch: 2 [45280/110534 (41%)]\tClassification Loss: 1.3723\r\n",
      "Train Epoch: 2 [45440/110534 (41%)]\tClassification Loss: 2.0836\r\n",
      "Train Epoch: 2 [45600/110534 (41%)]\tClassification Loss: 1.6899\r\n",
      "Train Epoch: 2 [45760/110534 (41%)]\tClassification Loss: 0.9744\r\n",
      "Train Epoch: 2 [45920/110534 (42%)]\tClassification Loss: 1.1541\r\n",
      "Train Epoch: 2 [46080/110534 (42%)]\tClassification Loss: 1.3640\r\n",
      "Train Epoch: 2 [46240/110534 (42%)]\tClassification Loss: 1.6767\r\n",
      "Test() called at batch_idx: 2900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4710, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [46400/110534 (42%)]\tClassification Loss: 1.4827\r\n",
      "Train Epoch: 2 [46560/110534 (42%)]\tClassification Loss: 2.0083\r\n",
      "Train Epoch: 2 [46720/110534 (42%)]\tClassification Loss: 1.7225\r\n",
      "Train Epoch: 2 [46880/110534 (42%)]\tClassification Loss: 1.4461\r\n",
      "Train Epoch: 2 [47040/110534 (43%)]\tClassification Loss: 1.8770\r\n",
      "Train Epoch: 2 [47200/110534 (43%)]\tClassification Loss: 1.2666\r\n",
      "Train Epoch: 2 [47360/110534 (43%)]\tClassification Loss: 1.2432\r\n",
      "Train Epoch: 2 [47520/110534 (43%)]\tClassification Loss: 1.8431\r\n",
      "Train Epoch: 2 [47680/110534 (43%)]\tClassification Loss: 1.0503\r\n",
      "Train Epoch: 2 [47840/110534 (43%)]\tClassification Loss: 1.2896\r\n",
      "Test() called at batch_idx: 3000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4760, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [48000/110534 (43%)]\tClassification Loss: 1.5384\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_3000.pth.tar\r\n",
      "Train Epoch: 2 [48160/110534 (44%)]\tClassification Loss: 1.6434\r\n",
      "Train Epoch: 2 [48320/110534 (44%)]\tClassification Loss: 1.5993\r\n",
      "Train Epoch: 2 [48480/110534 (44%)]\tClassification Loss: 1.2754\r\n",
      "Train Epoch: 2 [48640/110534 (44%)]\tClassification Loss: 1.6262\r\n",
      "Train Epoch: 2 [48800/110534 (44%)]\tClassification Loss: 1.4663\r\n",
      "Train Epoch: 2 [48960/110534 (44%)]\tClassification Loss: 1.5035\r\n",
      "Train Epoch: 2 [49120/110534 (44%)]\tClassification Loss: 1.9587\r\n",
      "Train Epoch: 2 [49280/110534 (45%)]\tClassification Loss: 1.3843\r\n",
      "Train Epoch: 2 [49440/110534 (45%)]\tClassification Loss: 1.7640\r\n",
      "Test() called at batch_idx: 3100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4700, Accuracy: 292/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [49600/110534 (45%)]\tClassification Loss: 1.5080\r\n",
      "Train Epoch: 2 [49760/110534 (45%)]\tClassification Loss: 1.4879\r\n",
      "Train Epoch: 2 [49920/110534 (45%)]\tClassification Loss: 1.8451\r\n",
      "Train Epoch: 2 [50080/110534 (45%)]\tClassification Loss: 1.5923\r\n",
      "Train Epoch: 2 [50240/110534 (45%)]\tClassification Loss: 1.7400\r\n",
      "Train Epoch: 2 [50400/110534 (46%)]\tClassification Loss: 1.4417\r\n",
      "Train Epoch: 2 [50560/110534 (46%)]\tClassification Loss: 1.3885\r\n",
      "Train Epoch: 2 [50720/110534 (46%)]\tClassification Loss: 2.0902\r\n",
      "Train Epoch: 2 [50880/110534 (46%)]\tClassification Loss: 1.3591\r\n",
      "Train Epoch: 2 [51040/110534 (46%)]\tClassification Loss: 1.6067\r\n",
      "Test() called at batch_idx: 3200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4863, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [51200/110534 (46%)]\tClassification Loss: 1.5739\r\n",
      "Train Epoch: 2 [51360/110534 (46%)]\tClassification Loss: 1.5909\r\n",
      "Train Epoch: 2 [51520/110534 (47%)]\tClassification Loss: 2.2310\r\n",
      "Train Epoch: 2 [51680/110534 (47%)]\tClassification Loss: 2.3548\r\n",
      "Train Epoch: 2 [51840/110534 (47%)]\tClassification Loss: 2.4550\r\n",
      "Train Epoch: 2 [52000/110534 (47%)]\tClassification Loss: 1.1156\r\n",
      "Train Epoch: 2 [52160/110534 (47%)]\tClassification Loss: 1.1204\r\n",
      "Train Epoch: 2 [52320/110534 (47%)]\tClassification Loss: 1.9504\r\n",
      "Train Epoch: 2 [52480/110534 (47%)]\tClassification Loss: 1.4278\r\n",
      "Train Epoch: 2 [52640/110534 (48%)]\tClassification Loss: 1.7870\r\n",
      "Test() called at batch_idx: 3300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4774, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [52800/110534 (48%)]\tClassification Loss: 1.6066\r\n",
      "Train Epoch: 2 [52960/110534 (48%)]\tClassification Loss: 0.9547\r\n",
      "Train Epoch: 2 [53120/110534 (48%)]\tClassification Loss: 1.5167\r\n",
      "Train Epoch: 2 [53280/110534 (48%)]\tClassification Loss: 1.6958\r\n",
      "Train Epoch: 2 [53440/110534 (48%)]\tClassification Loss: 2.1291\r\n",
      "Train Epoch: 2 [53600/110534 (48%)]\tClassification Loss: 1.2641\r\n",
      "Train Epoch: 2 [53760/110534 (49%)]\tClassification Loss: 2.2021\r\n",
      "Train Epoch: 2 [53920/110534 (49%)]\tClassification Loss: 1.4671\r\n",
      "Train Epoch: 2 [54080/110534 (49%)]\tClassification Loss: 1.5968\r\n",
      "Train Epoch: 2 [54240/110534 (49%)]\tClassification Loss: 1.8128\r\n",
      "Test() called at batch_idx: 3400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4729, Accuracy: 290/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [54400/110534 (49%)]\tClassification Loss: 1.5597\r\n",
      "Train Epoch: 2 [54560/110534 (49%)]\tClassification Loss: 1.3079\r\n",
      "Train Epoch: 2 [54720/110534 (50%)]\tClassification Loss: 1.3144\r\n",
      "Train Epoch: 2 [54880/110534 (50%)]\tClassification Loss: 1.3466\r\n",
      "Train Epoch: 2 [55040/110534 (50%)]\tClassification Loss: 1.3712\r\n",
      "Train Epoch: 2 [55200/110534 (50%)]\tClassification Loss: 1.3071\r\n",
      "Train Epoch: 2 [55360/110534 (50%)]\tClassification Loss: 1.6866\r\n",
      "Train Epoch: 2 [55520/110534 (50%)]\tClassification Loss: 1.9141\r\n",
      "Train Epoch: 2 [55680/110534 (50%)]\tClassification Loss: 1.5507\r\n",
      "Train Epoch: 2 [55840/110534 (51%)]\tClassification Loss: 1.9652\r\n",
      "Test() called at batch_idx: 3500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4690, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [56000/110534 (51%)]\tClassification Loss: 1.3137\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_3500.pth.tar\r\n",
      "Train Epoch: 2 [56160/110534 (51%)]\tClassification Loss: 1.1771\r\n",
      "Train Epoch: 2 [56320/110534 (51%)]\tClassification Loss: 1.4364\r\n",
      "Train Epoch: 2 [56480/110534 (51%)]\tClassification Loss: 1.5935\r\n",
      "Train Epoch: 2 [56640/110534 (51%)]\tClassification Loss: 1.3976\r\n",
      "Train Epoch: 2 [56800/110534 (51%)]\tClassification Loss: 1.6215\r\n",
      "Train Epoch: 2 [56960/110534 (52%)]\tClassification Loss: 0.9176\r\n",
      "Train Epoch: 2 [57120/110534 (52%)]\tClassification Loss: 1.6179\r\n",
      "Train Epoch: 2 [57280/110534 (52%)]\tClassification Loss: 1.4155\r\n",
      "Train Epoch: 2 [57440/110534 (52%)]\tClassification Loss: 1.3887\r\n",
      "Test() called at batch_idx: 3600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4790, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [57600/110534 (52%)]\tClassification Loss: 1.6791\r\n",
      "Train Epoch: 2 [57760/110534 (52%)]\tClassification Loss: 1.1568\r\n",
      "Train Epoch: 2 [57920/110534 (52%)]\tClassification Loss: 1.5811\r\n",
      "Train Epoch: 2 [58080/110534 (53%)]\tClassification Loss: 1.8135\r\n",
      "Train Epoch: 2 [58240/110534 (53%)]\tClassification Loss: 1.2844\r\n",
      "Train Epoch: 2 [58400/110534 (53%)]\tClassification Loss: 1.7857\r\n",
      "Train Epoch: 2 [58560/110534 (53%)]\tClassification Loss: 2.0136\r\n",
      "Train Epoch: 2 [58720/110534 (53%)]\tClassification Loss: 1.6949\r\n",
      "Train Epoch: 2 [58880/110534 (53%)]\tClassification Loss: 2.1116\r\n",
      "Train Epoch: 2 [59040/110534 (53%)]\tClassification Loss: 1.9132\r\n",
      "Test() called at batch_idx: 3700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4691, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [59200/110534 (54%)]\tClassification Loss: 1.3398\r\n",
      "Train Epoch: 2 [59360/110534 (54%)]\tClassification Loss: 1.0851\r\n",
      "Train Epoch: 2 [59520/110534 (54%)]\tClassification Loss: 1.9945\r\n",
      "Train Epoch: 2 [59680/110534 (54%)]\tClassification Loss: 2.1915\r\n",
      "Train Epoch: 2 [59840/110534 (54%)]\tClassification Loss: 1.6047\r\n",
      "Train Epoch: 2 [60000/110534 (54%)]\tClassification Loss: 1.4666\r\n",
      "Train Epoch: 2 [60160/110534 (54%)]\tClassification Loss: 2.0970\r\n",
      "Train Epoch: 2 [60320/110534 (55%)]\tClassification Loss: 2.0436\r\n",
      "Train Epoch: 2 [60480/110534 (55%)]\tClassification Loss: 1.3528\r\n",
      "Train Epoch: 2 [60640/110534 (55%)]\tClassification Loss: 1.3608\r\n",
      "Test() called at batch_idx: 3800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4924, Accuracy: 284/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [60800/110534 (55%)]\tClassification Loss: 1.2904\r\n",
      "Train Epoch: 2 [60960/110534 (55%)]\tClassification Loss: 1.7339\r\n",
      "Train Epoch: 2 [61120/110534 (55%)]\tClassification Loss: 1.6671\r\n",
      "Train Epoch: 2 [61280/110534 (55%)]\tClassification Loss: 1.5767\r\n",
      "Train Epoch: 2 [61440/110534 (56%)]\tClassification Loss: 1.7311\r\n",
      "Train Epoch: 2 [61600/110534 (56%)]\tClassification Loss: 1.3231\r\n",
      "Train Epoch: 2 [61760/110534 (56%)]\tClassification Loss: 1.2140\r\n",
      "Train Epoch: 2 [61920/110534 (56%)]\tClassification Loss: 1.9199\r\n",
      "Train Epoch: 2 [62080/110534 (56%)]\tClassification Loss: 1.1819\r\n",
      "Train Epoch: 2 [62240/110534 (56%)]\tClassification Loss: 1.4646\r\n",
      "Test() called at batch_idx: 3900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4671, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [62400/110534 (56%)]\tClassification Loss: 1.6963\r\n",
      "Train Epoch: 2 [62560/110534 (57%)]\tClassification Loss: 1.4445\r\n",
      "Train Epoch: 2 [62720/110534 (57%)]\tClassification Loss: 1.7730\r\n",
      "Train Epoch: 2 [62880/110534 (57%)]\tClassification Loss: 1.6228\r\n",
      "Train Epoch: 2 [63040/110534 (57%)]\tClassification Loss: 1.6050\r\n",
      "Train Epoch: 2 [63200/110534 (57%)]\tClassification Loss: 1.9537\r\n",
      "Train Epoch: 2 [63360/110534 (57%)]\tClassification Loss: 1.7032\r\n",
      "Train Epoch: 2 [63520/110534 (57%)]\tClassification Loss: 1.4491\r\n",
      "Train Epoch: 2 [63680/110534 (58%)]\tClassification Loss: 1.8508\r\n",
      "Train Epoch: 2 [63840/110534 (58%)]\tClassification Loss: 1.0615\r\n",
      "Test() called at batch_idx: 4000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4706, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [64000/110534 (58%)]\tClassification Loss: 1.2179\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_4000.pth.tar\r\n",
      "Train Epoch: 2 [64160/110534 (58%)]\tClassification Loss: 1.5137\r\n",
      "Train Epoch: 2 [64320/110534 (58%)]\tClassification Loss: 1.7745\r\n",
      "Train Epoch: 2 [64480/110534 (58%)]\tClassification Loss: 1.2848\r\n",
      "Train Epoch: 2 [64640/110534 (58%)]\tClassification Loss: 1.7064\r\n",
      "Train Epoch: 2 [64800/110534 (59%)]\tClassification Loss: 1.6431\r\n",
      "Train Epoch: 2 [64960/110534 (59%)]\tClassification Loss: 1.3012\r\n",
      "Train Epoch: 2 [65120/110534 (59%)]\tClassification Loss: 0.9198\r\n",
      "Train Epoch: 2 [65280/110534 (59%)]\tClassification Loss: 1.6892\r\n",
      "Train Epoch: 2 [65440/110534 (59%)]\tClassification Loss: 1.8025\r\n",
      "Test() called at batch_idx: 4100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4677, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [65600/110534 (59%)]\tClassification Loss: 1.1438\r\n",
      "Train Epoch: 2 [65760/110534 (59%)]\tClassification Loss: 1.7355\r\n",
      "Train Epoch: 2 [65920/110534 (60%)]\tClassification Loss: 1.4463\r\n",
      "Train Epoch: 2 [66080/110534 (60%)]\tClassification Loss: 1.4236\r\n",
      "Train Epoch: 2 [66240/110534 (60%)]\tClassification Loss: 1.8599\r\n",
      "Train Epoch: 2 [66400/110534 (60%)]\tClassification Loss: 2.4733\r\n",
      "Train Epoch: 2 [66560/110534 (60%)]\tClassification Loss: 1.4623\r\n",
      "Train Epoch: 2 [66720/110534 (60%)]\tClassification Loss: 1.5329\r\n",
      "Train Epoch: 2 [66880/110534 (61%)]\tClassification Loss: 1.2637\r\n",
      "Train Epoch: 2 [67040/110534 (61%)]\tClassification Loss: 1.2459\r\n",
      "Test() called at batch_idx: 4200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4569, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 2 [67200/110534 (61%)]\tClassification Loss: 2.0966\r\n",
      "Train Epoch: 2 [67360/110534 (61%)]\tClassification Loss: 1.9445\r\n",
      "Train Epoch: 2 [67520/110534 (61%)]\tClassification Loss: 1.4191\r\n",
      "Train Epoch: 2 [67680/110534 (61%)]\tClassification Loss: 1.2986\r\n",
      "Train Epoch: 2 [67840/110534 (61%)]\tClassification Loss: 1.1130\r\n",
      "Train Epoch: 2 [68000/110534 (62%)]\tClassification Loss: 1.4160\r\n",
      "Train Epoch: 2 [68160/110534 (62%)]\tClassification Loss: 1.7473\r\n",
      "Train Epoch: 2 [68320/110534 (62%)]\tClassification Loss: 2.1491\r\n",
      "Train Epoch: 2 [68480/110534 (62%)]\tClassification Loss: 1.4694\r\n",
      "Train Epoch: 2 [68640/110534 (62%)]\tClassification Loss: 1.8504\r\n",
      "Test() called at batch_idx: 4300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4704, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 2 [68800/110534 (62%)]\tClassification Loss: 1.3200\r\n",
      "Train Epoch: 2 [68960/110534 (62%)]\tClassification Loss: 1.4302\r\n",
      "Train Epoch: 2 [69120/110534 (63%)]\tClassification Loss: 1.1629\r\n",
      "Train Epoch: 2 [69280/110534 (63%)]\tClassification Loss: 2.0458\r\n",
      "Train Epoch: 2 [69440/110534 (63%)]\tClassification Loss: 1.8100\r\n",
      "Train Epoch: 2 [69600/110534 (63%)]\tClassification Loss: 1.3402\r\n",
      "Train Epoch: 2 [69760/110534 (63%)]\tClassification Loss: 1.5197\r\n",
      "Train Epoch: 2 [69920/110534 (63%)]\tClassification Loss: 1.2443\r\n",
      "Train Epoch: 2 [70080/110534 (63%)]\tClassification Loss: 1.8676\r\n",
      "Train Epoch: 2 [70240/110534 (64%)]\tClassification Loss: 1.4600\r\n",
      "Test() called at batch_idx: 4400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4592, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [70400/110534 (64%)]\tClassification Loss: 2.2644\r\n",
      "Train Epoch: 2 [70560/110534 (64%)]\tClassification Loss: 1.1378\r\n",
      "Train Epoch: 2 [70720/110534 (64%)]\tClassification Loss: 1.5902\r\n",
      "Train Epoch: 2 [70880/110534 (64%)]\tClassification Loss: 2.0755\r\n",
      "Train Epoch: 2 [71040/110534 (64%)]\tClassification Loss: 1.6787\r\n",
      "Train Epoch: 2 [71200/110534 (64%)]\tClassification Loss: 1.6931\r\n",
      "Train Epoch: 2 [71360/110534 (65%)]\tClassification Loss: 1.6615\r\n",
      "Train Epoch: 2 [71520/110534 (65%)]\tClassification Loss: 1.7835\r\n",
      "Train Epoch: 2 [71680/110534 (65%)]\tClassification Loss: 1.3843\r\n",
      "Train Epoch: 2 [71840/110534 (65%)]\tClassification Loss: 1.1073\r\n",
      "Test() called at batch_idx: 4500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4663, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [72000/110534 (65%)]\tClassification Loss: 1.2062\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_4500.pth.tar\r\n",
      "Train Epoch: 2 [72160/110534 (65%)]\tClassification Loss: 1.4485\r\n",
      "Train Epoch: 2 [72320/110534 (65%)]\tClassification Loss: 1.4985\r\n",
      "Train Epoch: 2 [72480/110534 (66%)]\tClassification Loss: 1.6852\r\n",
      "Train Epoch: 2 [72640/110534 (66%)]\tClassification Loss: 2.0150\r\n",
      "Train Epoch: 2 [72800/110534 (66%)]\tClassification Loss: 2.0372\r\n",
      "Train Epoch: 2 [72960/110534 (66%)]\tClassification Loss: 1.7525\r\n",
      "Train Epoch: 2 [73120/110534 (66%)]\tClassification Loss: 1.3586\r\n",
      "Train Epoch: 2 [73280/110534 (66%)]\tClassification Loss: 1.8945\r\n",
      "Train Epoch: 2 [73440/110534 (66%)]\tClassification Loss: 2.0573\r\n",
      "Test() called at batch_idx: 4600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4615, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [73600/110534 (67%)]\tClassification Loss: 1.7652\r\n",
      "Train Epoch: 2 [73760/110534 (67%)]\tClassification Loss: 1.9264\r\n",
      "Train Epoch: 2 [73920/110534 (67%)]\tClassification Loss: 2.2030\r\n",
      "Train Epoch: 2 [74080/110534 (67%)]\tClassification Loss: 1.5773\r\n",
      "Train Epoch: 2 [74240/110534 (67%)]\tClassification Loss: 1.7055\r\n",
      "Train Epoch: 2 [74400/110534 (67%)]\tClassification Loss: 1.8192\r\n",
      "Train Epoch: 2 [74560/110534 (67%)]\tClassification Loss: 1.5635\r\n",
      "Train Epoch: 2 [74720/110534 (68%)]\tClassification Loss: 1.4252\r\n",
      "Train Epoch: 2 [74880/110534 (68%)]\tClassification Loss: 1.9150\r\n",
      "Train Epoch: 2 [75040/110534 (68%)]\tClassification Loss: 1.0189\r\n",
      "Test() called at batch_idx: 4700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4555, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 2 [75200/110534 (68%)]\tClassification Loss: 1.0903\r\n",
      "Train Epoch: 2 [75360/110534 (68%)]\tClassification Loss: 1.6253\r\n",
      "Train Epoch: 2 [75520/110534 (68%)]\tClassification Loss: 1.7336\r\n",
      "Train Epoch: 2 [75680/110534 (68%)]\tClassification Loss: 1.5503\r\n",
      "Train Epoch: 2 [75840/110534 (69%)]\tClassification Loss: 1.1441\r\n",
      "Train Epoch: 2 [76000/110534 (69%)]\tClassification Loss: 1.4021\r\n",
      "Train Epoch: 2 [76160/110534 (69%)]\tClassification Loss: 1.9580\r\n",
      "Train Epoch: 2 [76320/110534 (69%)]\tClassification Loss: 1.4224\r\n",
      "Train Epoch: 2 [76480/110534 (69%)]\tClassification Loss: 2.3812\r\n",
      "Train Epoch: 2 [76640/110534 (69%)]\tClassification Loss: 1.0034\r\n",
      "Test() called at batch_idx: 4800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4737, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [76800/110534 (69%)]\tClassification Loss: 1.9977\r\n",
      "Train Epoch: 2 [76960/110534 (70%)]\tClassification Loss: 1.5885\r\n",
      "Train Epoch: 2 [77120/110534 (70%)]\tClassification Loss: 1.5293\r\n",
      "Train Epoch: 2 [77280/110534 (70%)]\tClassification Loss: 1.7613\r\n",
      "Train Epoch: 2 [77440/110534 (70%)]\tClassification Loss: 1.4834\r\n",
      "Train Epoch: 2 [77600/110534 (70%)]\tClassification Loss: 1.7295\r\n",
      "Train Epoch: 2 [77760/110534 (70%)]\tClassification Loss: 1.6014\r\n",
      "Train Epoch: 2 [77920/110534 (70%)]\tClassification Loss: 1.5713\r\n",
      "Train Epoch: 2 [78080/110534 (71%)]\tClassification Loss: 1.4354\r\n",
      "Train Epoch: 2 [78240/110534 (71%)]\tClassification Loss: 1.6091\r\n",
      "Test() called at batch_idx: 4900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4545, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [78400/110534 (71%)]\tClassification Loss: 1.5327\r\n",
      "Train Epoch: 2 [78560/110534 (71%)]\tClassification Loss: 1.3580\r\n",
      "Train Epoch: 2 [78720/110534 (71%)]\tClassification Loss: 1.8258\r\n",
      "Train Epoch: 2 [78880/110534 (71%)]\tClassification Loss: 1.3805\r\n",
      "Train Epoch: 2 [79040/110534 (72%)]\tClassification Loss: 1.9490\r\n",
      "Train Epoch: 2 [79200/110534 (72%)]\tClassification Loss: 1.3465\r\n",
      "Train Epoch: 2 [79360/110534 (72%)]\tClassification Loss: 1.1683\r\n",
      "Train Epoch: 2 [79520/110534 (72%)]\tClassification Loss: 1.4133\r\n",
      "Train Epoch: 2 [79680/110534 (72%)]\tClassification Loss: 1.9264\r\n",
      "Train Epoch: 2 [79840/110534 (72%)]\tClassification Loss: 1.5526\r\n",
      "Test() called at batch_idx: 5000\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\r\n",
      "    self._send(header + buf)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\r\n",
      "    n = write(self._handle, buf)\r\n",
      "BrokenPipeError: [Errno 32] Broken pipe\r\n",
      "\r\n",
      "Test set: Average loss: 1.4614, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [80000/110534 (72%)]\tClassification Loss: 1.3633\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_5000.pth.tar\r\n",
      "Train Epoch: 2 [80160/110534 (73%)]\tClassification Loss: 1.4272\r\n",
      "Train Epoch: 2 [80320/110534 (73%)]\tClassification Loss: 1.8383\r\n",
      "Train Epoch: 2 [80480/110534 (73%)]\tClassification Loss: 1.6378\r\n",
      "Train Epoch: 2 [80640/110534 (73%)]\tClassification Loss: 1.5695\r\n",
      "Train Epoch: 2 [80800/110534 (73%)]\tClassification Loss: 1.7307\r\n",
      "Train Epoch: 2 [80960/110534 (73%)]\tClassification Loss: 1.6705\r\n",
      "Train Epoch: 2 [81120/110534 (73%)]\tClassification Loss: 1.7169\r\n",
      "Train Epoch: 2 [81280/110534 (74%)]\tClassification Loss: 2.2047\r\n",
      "Train Epoch: 2 [81440/110534 (74%)]\tClassification Loss: 1.7824\r\n",
      "Test() called at batch_idx: 5100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4533, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [81600/110534 (74%)]\tClassification Loss: 1.4126\r\n",
      "Train Epoch: 2 [81760/110534 (74%)]\tClassification Loss: 1.8199\r\n",
      "Train Epoch: 2 [81920/110534 (74%)]\tClassification Loss: 2.3161\r\n",
      "Train Epoch: 2 [82080/110534 (74%)]\tClassification Loss: 1.2324\r\n",
      "Train Epoch: 2 [82240/110534 (74%)]\tClassification Loss: 1.4798\r\n",
      "Train Epoch: 2 [82400/110534 (75%)]\tClassification Loss: 1.4222\r\n",
      "Train Epoch: 2 [82560/110534 (75%)]\tClassification Loss: 1.4602\r\n",
      "Train Epoch: 2 [82720/110534 (75%)]\tClassification Loss: 1.4442\r\n",
      "Train Epoch: 2 [82880/110534 (75%)]\tClassification Loss: 1.6652\r\n",
      "Train Epoch: 2 [83040/110534 (75%)]\tClassification Loss: 1.3846\r\n",
      "Test() called at batch_idx: 5200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4578, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [83200/110534 (75%)]\tClassification Loss: 1.2899\r\n",
      "Train Epoch: 2 [83360/110534 (75%)]\tClassification Loss: 1.1618\r\n",
      "Train Epoch: 2 [83520/110534 (76%)]\tClassification Loss: 2.2106\r\n",
      "Train Epoch: 2 [83680/110534 (76%)]\tClassification Loss: 1.9403\r\n",
      "Train Epoch: 2 [83840/110534 (76%)]\tClassification Loss: 1.5604\r\n",
      "Train Epoch: 2 [84000/110534 (76%)]\tClassification Loss: 1.4557\r\n",
      "Train Epoch: 2 [84160/110534 (76%)]\tClassification Loss: 1.7226\r\n",
      "Train Epoch: 2 [84320/110534 (76%)]\tClassification Loss: 1.7349\r\n",
      "Train Epoch: 2 [84480/110534 (76%)]\tClassification Loss: 2.0234\r\n",
      "Train Epoch: 2 [84640/110534 (77%)]\tClassification Loss: 2.3107\r\n",
      "Test() called at batch_idx: 5300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4578, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [84800/110534 (77%)]\tClassification Loss: 1.6820\r\n",
      "Train Epoch: 2 [84960/110534 (77%)]\tClassification Loss: 1.7731\r\n",
      "Train Epoch: 2 [85120/110534 (77%)]\tClassification Loss: 2.0547\r\n",
      "Train Epoch: 2 [85280/110534 (77%)]\tClassification Loss: 2.0479\r\n",
      "Train Epoch: 2 [85440/110534 (77%)]\tClassification Loss: 1.6651\r\n",
      "Train Epoch: 2 [85600/110534 (77%)]\tClassification Loss: 2.0045\r\n",
      "Train Epoch: 2 [85760/110534 (78%)]\tClassification Loss: 2.2967\r\n",
      "Train Epoch: 2 [85920/110534 (78%)]\tClassification Loss: 1.3505\r\n",
      "Train Epoch: 2 [86080/110534 (78%)]\tClassification Loss: 1.5476\r\n",
      "Train Epoch: 2 [86240/110534 (78%)]\tClassification Loss: 1.2216\r\n",
      "Test() called at batch_idx: 5400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4534, Accuracy: 292/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [86400/110534 (78%)]\tClassification Loss: 1.2743\r\n",
      "Train Epoch: 2 [86560/110534 (78%)]\tClassification Loss: 1.5922\r\n",
      "Train Epoch: 2 [86720/110534 (78%)]\tClassification Loss: 1.7603\r\n",
      "Train Epoch: 2 [86880/110534 (79%)]\tClassification Loss: 1.4188\r\n",
      "Train Epoch: 2 [87040/110534 (79%)]\tClassification Loss: 1.5355\r\n",
      "Train Epoch: 2 [87200/110534 (79%)]\tClassification Loss: 1.8385\r\n",
      "Train Epoch: 2 [87360/110534 (79%)]\tClassification Loss: 1.7946\r\n",
      "Train Epoch: 2 [87520/110534 (79%)]\tClassification Loss: 1.2614\r\n",
      "Train Epoch: 2 [87680/110534 (79%)]\tClassification Loss: 1.0485\r\n",
      "Train Epoch: 2 [87840/110534 (79%)]\tClassification Loss: 1.8997\r\n",
      "Test() called at batch_idx: 5500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4576, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [88000/110534 (80%)]\tClassification Loss: 1.3537\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_5500.pth.tar\r\n",
      "Train Epoch: 2 [88160/110534 (80%)]\tClassification Loss: 1.4092\r\n",
      "Train Epoch: 2 [88320/110534 (80%)]\tClassification Loss: 1.3615\r\n",
      "Train Epoch: 2 [88480/110534 (80%)]\tClassification Loss: 1.1287\r\n",
      "Train Epoch: 2 [88640/110534 (80%)]\tClassification Loss: 1.0836\r\n",
      "Train Epoch: 2 [88800/110534 (80%)]\tClassification Loss: 1.2340\r\n",
      "Train Epoch: 2 [88960/110534 (80%)]\tClassification Loss: 1.8015\r\n",
      "Train Epoch: 2 [89120/110534 (81%)]\tClassification Loss: 1.3121\r\n",
      "Train Epoch: 2 [89280/110534 (81%)]\tClassification Loss: 1.1272\r\n",
      "Train Epoch: 2 [89440/110534 (81%)]\tClassification Loss: 2.3607\r\n",
      "Test() called at batch_idx: 5600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4574, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 2 [89600/110534 (81%)]\tClassification Loss: 1.3565\r\n",
      "Train Epoch: 2 [89760/110534 (81%)]\tClassification Loss: 1.8110\r\n",
      "Train Epoch: 2 [89920/110534 (81%)]\tClassification Loss: 1.5949\r\n",
      "Train Epoch: 2 [90080/110534 (81%)]\tClassification Loss: 1.2405\r\n",
      "Train Epoch: 2 [90240/110534 (82%)]\tClassification Loss: 1.8221\r\n",
      "Train Epoch: 2 [90400/110534 (82%)]\tClassification Loss: 1.7423\r\n",
      "Train Epoch: 2 [90560/110534 (82%)]\tClassification Loss: 1.2816\r\n",
      "Train Epoch: 2 [90720/110534 (82%)]\tClassification Loss: 1.3173\r\n",
      "Train Epoch: 2 [90880/110534 (82%)]\tClassification Loss: 1.4921\r\n",
      "Train Epoch: 2 [91040/110534 (82%)]\tClassification Loss: 1.8999\r\n",
      "Test() called at batch_idx: 5700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4596, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [91200/110534 (83%)]\tClassification Loss: 1.9843\r\n",
      "Train Epoch: 2 [91360/110534 (83%)]\tClassification Loss: 1.1250\r\n",
      "Train Epoch: 2 [91520/110534 (83%)]\tClassification Loss: 1.4648\r\n",
      "Train Epoch: 2 [91680/110534 (83%)]\tClassification Loss: 1.5612\r\n",
      "Train Epoch: 2 [91840/110534 (83%)]\tClassification Loss: 1.5221\r\n",
      "Train Epoch: 2 [92000/110534 (83%)]\tClassification Loss: 1.6547\r\n",
      "Train Epoch: 2 [92160/110534 (83%)]\tClassification Loss: 1.8118\r\n",
      "Train Epoch: 2 [92320/110534 (84%)]\tClassification Loss: 2.1794\r\n",
      "Train Epoch: 2 [92480/110534 (84%)]\tClassification Loss: 1.5940\r\n",
      "Train Epoch: 2 [92640/110534 (84%)]\tClassification Loss: 1.5710\r\n",
      "Test() called at batch_idx: 5800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4521, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [92800/110534 (84%)]\tClassification Loss: 2.1671\r\n",
      "Train Epoch: 2 [92960/110534 (84%)]\tClassification Loss: 1.6055\r\n",
      "Train Epoch: 2 [93120/110534 (84%)]\tClassification Loss: 1.8531\r\n",
      "Train Epoch: 2 [93280/110534 (84%)]\tClassification Loss: 1.5630\r\n",
      "Train Epoch: 2 [93440/110534 (85%)]\tClassification Loss: 2.0094\r\n",
      "Train Epoch: 2 [93600/110534 (85%)]\tClassification Loss: 1.3998\r\n",
      "Train Epoch: 2 [93760/110534 (85%)]\tClassification Loss: 1.8696\r\n",
      "Train Epoch: 2 [93920/110534 (85%)]\tClassification Loss: 1.3152\r\n",
      "Train Epoch: 2 [94080/110534 (85%)]\tClassification Loss: 2.0441\r\n",
      "Train Epoch: 2 [94240/110534 (85%)]\tClassification Loss: 2.0542\r\n",
      "Test() called at batch_idx: 5900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4549, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [94400/110534 (85%)]\tClassification Loss: 1.3377\r\n",
      "Train Epoch: 2 [94560/110534 (86%)]\tClassification Loss: 1.9535\r\n",
      "Train Epoch: 2 [94720/110534 (86%)]\tClassification Loss: 1.2706\r\n",
      "Train Epoch: 2 [94880/110534 (86%)]\tClassification Loss: 1.5583\r\n",
      "Train Epoch: 2 [95040/110534 (86%)]\tClassification Loss: 0.9643\r\n",
      "Train Epoch: 2 [95200/110534 (86%)]\tClassification Loss: 1.2568\r\n",
      "Train Epoch: 2 [95360/110534 (86%)]\tClassification Loss: 1.8025\r\n",
      "Train Epoch: 2 [95520/110534 (86%)]\tClassification Loss: 1.4514\r\n",
      "Train Epoch: 2 [95680/110534 (87%)]\tClassification Loss: 1.5972\r\n",
      "Train Epoch: 2 [95840/110534 (87%)]\tClassification Loss: 1.2410\r\n",
      "Test() called at batch_idx: 6000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4546, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [96000/110534 (87%)]\tClassification Loss: 1.6747\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_6000.pth.tar\r\n",
      "Train Epoch: 2 [96160/110534 (87%)]\tClassification Loss: 1.5891\r\n",
      "Train Epoch: 2 [96320/110534 (87%)]\tClassification Loss: 1.3710\r\n",
      "Train Epoch: 2 [96480/110534 (87%)]\tClassification Loss: 0.9788\r\n",
      "Train Epoch: 2 [96640/110534 (87%)]\tClassification Loss: 1.3750\r\n",
      "Train Epoch: 2 [96800/110534 (88%)]\tClassification Loss: 1.5260\r\n",
      "Train Epoch: 2 [96960/110534 (88%)]\tClassification Loss: 1.4073\r\n",
      "Train Epoch: 2 [97120/110534 (88%)]\tClassification Loss: 1.9449\r\n",
      "Train Epoch: 2 [97280/110534 (88%)]\tClassification Loss: 1.2936\r\n",
      "Train Epoch: 2 [97440/110534 (88%)]\tClassification Loss: 1.8386\r\n",
      "Test() called at batch_idx: 6100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4657, Accuracy: 289/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [97600/110534 (88%)]\tClassification Loss: 2.0516\r\n",
      "Train Epoch: 2 [97760/110534 (88%)]\tClassification Loss: 1.8005\r\n",
      "Train Epoch: 2 [97920/110534 (89%)]\tClassification Loss: 1.5490\r\n",
      "Train Epoch: 2 [98080/110534 (89%)]\tClassification Loss: 1.4613\r\n",
      "Train Epoch: 2 [98240/110534 (89%)]\tClassification Loss: 1.4635\r\n",
      "Train Epoch: 2 [98400/110534 (89%)]\tClassification Loss: 1.4696\r\n",
      "Train Epoch: 2 [98560/110534 (89%)]\tClassification Loss: 1.9073\r\n",
      "Train Epoch: 2 [98720/110534 (89%)]\tClassification Loss: 0.7877\r\n",
      "Train Epoch: 2 [98880/110534 (89%)]\tClassification Loss: 1.6490\r\n",
      "Train Epoch: 2 [99040/110534 (90%)]\tClassification Loss: 1.5286\r\n",
      "Test() called at batch_idx: 6200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4571, Accuracy: 303/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 2 [99200/110534 (90%)]\tClassification Loss: 2.0839\r\n",
      "Train Epoch: 2 [99360/110534 (90%)]\tClassification Loss: 1.7362\r\n",
      "Train Epoch: 2 [99520/110534 (90%)]\tClassification Loss: 2.3536\r\n",
      "Train Epoch: 2 [99680/110534 (90%)]\tClassification Loss: 1.1785\r\n",
      "Train Epoch: 2 [99840/110534 (90%)]\tClassification Loss: 2.0509\r\n",
      "Train Epoch: 2 [100000/110534 (90%)]\tClassification Loss: 1.9919\r\n",
      "Train Epoch: 2 [100160/110534 (91%)]\tClassification Loss: 2.5992\r\n",
      "Train Epoch: 2 [100320/110534 (91%)]\tClassification Loss: 1.2533\r\n",
      "Train Epoch: 2 [100480/110534 (91%)]\tClassification Loss: 2.0673\r\n",
      "Train Epoch: 2 [100640/110534 (91%)]\tClassification Loss: 1.4575\r\n",
      "Test() called at batch_idx: 6300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4548, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 2 [100800/110534 (91%)]\tClassification Loss: 1.4675\r\n",
      "Train Epoch: 2 [100960/110534 (91%)]\tClassification Loss: 1.6188\r\n",
      "Train Epoch: 2 [101120/110534 (91%)]\tClassification Loss: 1.4050\r\n",
      "Train Epoch: 2 [101280/110534 (92%)]\tClassification Loss: 1.3347\r\n",
      "Train Epoch: 2 [101440/110534 (92%)]\tClassification Loss: 1.4057\r\n",
      "Train Epoch: 2 [101600/110534 (92%)]\tClassification Loss: 1.9928\r\n",
      "Train Epoch: 2 [101760/110534 (92%)]\tClassification Loss: 2.0056\r\n",
      "Train Epoch: 2 [101920/110534 (92%)]\tClassification Loss: 1.4130\r\n",
      "Train Epoch: 2 [102080/110534 (92%)]\tClassification Loss: 1.4169\r\n",
      "Train Epoch: 2 [102240/110534 (92%)]\tClassification Loss: 1.3806\r\n",
      "Test() called at batch_idx: 6400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4522, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [102400/110534 (93%)]\tClassification Loss: 1.4696\r\n",
      "Train Epoch: 2 [102560/110534 (93%)]\tClassification Loss: 1.3949\r\n",
      "Train Epoch: 2 [102720/110534 (93%)]\tClassification Loss: 2.1599\r\n",
      "Train Epoch: 2 [102880/110534 (93%)]\tClassification Loss: 1.6325\r\n",
      "Train Epoch: 2 [103040/110534 (93%)]\tClassification Loss: 1.2599\r\n",
      "Train Epoch: 2 [103200/110534 (93%)]\tClassification Loss: 1.8576\r\n",
      "Train Epoch: 2 [103360/110534 (94%)]\tClassification Loss: 1.4839\r\n",
      "Train Epoch: 2 [103520/110534 (94%)]\tClassification Loss: 2.1679\r\n",
      "Train Epoch: 2 [103680/110534 (94%)]\tClassification Loss: 1.3159\r\n",
      "Train Epoch: 2 [103840/110534 (94%)]\tClassification Loss: 1.2406\r\n",
      "Test() called at batch_idx: 6500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4725, Accuracy: 290/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [104000/110534 (94%)]\tClassification Loss: 1.9413\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_6500.pth.tar\r\n",
      "Train Epoch: 2 [104160/110534 (94%)]\tClassification Loss: 1.5984\r\n",
      "Train Epoch: 2 [104320/110534 (94%)]\tClassification Loss: 1.6290\r\n",
      "Train Epoch: 2 [104480/110534 (95%)]\tClassification Loss: 1.1023\r\n",
      "Train Epoch: 2 [104640/110534 (95%)]\tClassification Loss: 2.0398\r\n",
      "Train Epoch: 2 [104800/110534 (95%)]\tClassification Loss: 1.4141\r\n",
      "Train Epoch: 2 [104960/110534 (95%)]\tClassification Loss: 1.3914\r\n",
      "Train Epoch: 2 [105120/110534 (95%)]\tClassification Loss: 1.2361\r\n",
      "Train Epoch: 2 [105280/110534 (95%)]\tClassification Loss: 1.6162\r\n",
      "Train Epoch: 2 [105440/110534 (95%)]\tClassification Loss: 1.4443\r\n",
      "Test() called at batch_idx: 6600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4701, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [105600/110534 (96%)]\tClassification Loss: 1.6876\r\n",
      "Train Epoch: 2 [105760/110534 (96%)]\tClassification Loss: 1.0372\r\n",
      "Train Epoch: 2 [105920/110534 (96%)]\tClassification Loss: 1.8911\r\n",
      "Train Epoch: 2 [106080/110534 (96%)]\tClassification Loss: 1.3808\r\n",
      "Train Epoch: 2 [106240/110534 (96%)]\tClassification Loss: 2.4270\r\n",
      "Train Epoch: 2 [106400/110534 (96%)]\tClassification Loss: 1.7415\r\n",
      "Train Epoch: 2 [106560/110534 (96%)]\tClassification Loss: 2.0662\r\n",
      "Train Epoch: 2 [106720/110534 (97%)]\tClassification Loss: 1.9892\r\n",
      "Train Epoch: 2 [106880/110534 (97%)]\tClassification Loss: 1.7325\r\n",
      "Train Epoch: 2 [107040/110534 (97%)]\tClassification Loss: 1.2434\r\n",
      "Test() called at batch_idx: 6700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4538, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [107200/110534 (97%)]\tClassification Loss: 1.0645\r\n",
      "Train Epoch: 2 [107360/110534 (97%)]\tClassification Loss: 1.3034\r\n",
      "Train Epoch: 2 [107520/110534 (97%)]\tClassification Loss: 1.6791\r\n",
      "Train Epoch: 2 [107680/110534 (97%)]\tClassification Loss: 1.2620\r\n",
      "Train Epoch: 2 [107840/110534 (98%)]\tClassification Loss: 1.2890\r\n",
      "Train Epoch: 2 [108000/110534 (98%)]\tClassification Loss: 1.0944\r\n",
      "Train Epoch: 2 [108160/110534 (98%)]\tClassification Loss: 1.5172\r\n",
      "Train Epoch: 2 [108320/110534 (98%)]\tClassification Loss: 1.7214\r\n",
      "Train Epoch: 2 [108480/110534 (98%)]\tClassification Loss: 1.1593\r\n",
      "Train Epoch: 2 [108640/110534 (98%)]\tClassification Loss: 1.4892\r\n",
      "Test() called at batch_idx: 6800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4532, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [108800/110534 (98%)]\tClassification Loss: 1.3149\r\n",
      "Train Epoch: 2 [108960/110534 (99%)]\tClassification Loss: 1.4343\r\n",
      "Train Epoch: 2 [109120/110534 (99%)]\tClassification Loss: 1.2914\r\n",
      "Train Epoch: 2 [109280/110534 (99%)]\tClassification Loss: 1.2713\r\n",
      "Train Epoch: 2 [109440/110534 (99%)]\tClassification Loss: 1.5390\r\n",
      "Train Epoch: 2 [109600/110534 (99%)]\tClassification Loss: 1.4087\r\n",
      "Train Epoch: 2 [109760/110534 (99%)]\tClassification Loss: 1.1389\r\n",
      "Train Epoch: 2 [109920/110534 (99%)]\tClassification Loss: 1.3809\r\n",
      "Train Epoch: 2 [110080/110534 (100%)]\tClassification Loss: 1.4956\r\n",
      "Train Epoch: 2 [110240/110534 (100%)]\tClassification Loss: 1.5581\r\n",
      "Test() called at batch_idx: 6900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4455, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 2 [110400/110534 (100%)]\tClassification Loss: 1.2362\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_final.pth.tar\r\n",
      "Test() called at batch_idx: 0\r\n",
      "\r\n",
      "Test set: Average loss: 1.4513, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [0/110534 (0%)]\tClassification Loss: 1.5482\r\n",
      "Train Epoch: 3 [160/110534 (0%)]\tClassification Loss: 2.0315\r\n",
      "Train Epoch: 3 [320/110534 (0%)]\tClassification Loss: 1.5414\r\n",
      "Train Epoch: 3 [480/110534 (0%)]\tClassification Loss: 1.5181\r\n",
      "Train Epoch: 3 [640/110534 (1%)]\tClassification Loss: 1.5851\r\n",
      "Train Epoch: 3 [800/110534 (1%)]\tClassification Loss: 1.8029\r\n",
      "Train Epoch: 3 [960/110534 (1%)]\tClassification Loss: 1.4250\r\n",
      "Train Epoch: 3 [1120/110534 (1%)]\tClassification Loss: 1.2309\r\n",
      "Train Epoch: 3 [1280/110534 (1%)]\tClassification Loss: 1.5763\r\n",
      "Train Epoch: 3 [1440/110534 (1%)]\tClassification Loss: 2.1067\r\n",
      "Test() called at batch_idx: 100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4509, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [1600/110534 (1%)]\tClassification Loss: 1.6159\r\n",
      "Train Epoch: 3 [1760/110534 (2%)]\tClassification Loss: 1.5313\r\n",
      "Train Epoch: 3 [1920/110534 (2%)]\tClassification Loss: 1.8356\r\n",
      "Train Epoch: 3 [2080/110534 (2%)]\tClassification Loss: 1.4286\r\n",
      "Train Epoch: 3 [2240/110534 (2%)]\tClassification Loss: 2.3532\r\n",
      "Train Epoch: 3 [2400/110534 (2%)]\tClassification Loss: 1.3007\r\n",
      "Train Epoch: 3 [2560/110534 (2%)]\tClassification Loss: 1.9754\r\n",
      "Train Epoch: 3 [2720/110534 (2%)]\tClassification Loss: 1.4250\r\n",
      "Train Epoch: 3 [2880/110534 (3%)]\tClassification Loss: 1.8033\r\n",
      "Train Epoch: 3 [3040/110534 (3%)]\tClassification Loss: 1.7447\r\n",
      "Test() called at batch_idx: 200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4491, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [3200/110534 (3%)]\tClassification Loss: 1.5188\r\n",
      "Train Epoch: 3 [3360/110534 (3%)]\tClassification Loss: 1.1812\r\n",
      "Train Epoch: 3 [3520/110534 (3%)]\tClassification Loss: 1.4880\r\n",
      "Train Epoch: 3 [3680/110534 (3%)]\tClassification Loss: 1.4939\r\n",
      "Train Epoch: 3 [3840/110534 (3%)]\tClassification Loss: 1.9001\r\n",
      "Train Epoch: 3 [4000/110534 (4%)]\tClassification Loss: 1.6942\r\n",
      "Train Epoch: 3 [4160/110534 (4%)]\tClassification Loss: 1.1685\r\n",
      "Train Epoch: 3 [4320/110534 (4%)]\tClassification Loss: 1.6934\r\n",
      "Train Epoch: 3 [4480/110534 (4%)]\tClassification Loss: 1.2853\r\n",
      "Train Epoch: 3 [4640/110534 (4%)]\tClassification Loss: 1.9327\r\n",
      "Test() called at batch_idx: 300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4471, Accuracy: 306/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [4800/110534 (4%)]\tClassification Loss: 1.6043\r\n",
      "Train Epoch: 3 [4960/110534 (4%)]\tClassification Loss: 2.0326\r\n",
      "Train Epoch: 3 [5120/110534 (5%)]\tClassification Loss: 1.2978\r\n",
      "Train Epoch: 3 [5280/110534 (5%)]\tClassification Loss: 1.8925\r\n",
      "Train Epoch: 3 [5440/110534 (5%)]\tClassification Loss: 1.2395\r\n",
      "Train Epoch: 3 [5600/110534 (5%)]\tClassification Loss: 1.3612\r\n",
      "Train Epoch: 3 [5760/110534 (5%)]\tClassification Loss: 2.0049\r\n",
      "Train Epoch: 3 [5920/110534 (5%)]\tClassification Loss: 2.2396\r\n",
      "Train Epoch: 3 [6080/110534 (6%)]\tClassification Loss: 1.5633\r\n",
      "Train Epoch: 3 [6240/110534 (6%)]\tClassification Loss: 2.2579\r\n",
      "Test() called at batch_idx: 400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4466, Accuracy: 306/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [6400/110534 (6%)]\tClassification Loss: 1.5998\r\n",
      "Train Epoch: 3 [6560/110534 (6%)]\tClassification Loss: 2.0877\r\n",
      "Train Epoch: 3 [6720/110534 (6%)]\tClassification Loss: 2.1744\r\n",
      "Train Epoch: 3 [6880/110534 (6%)]\tClassification Loss: 1.6874\r\n",
      "Train Epoch: 3 [7040/110534 (6%)]\tClassification Loss: 1.0936\r\n",
      "Train Epoch: 3 [7200/110534 (7%)]\tClassification Loss: 1.3580\r\n",
      "Train Epoch: 3 [7360/110534 (7%)]\tClassification Loss: 1.7584\r\n",
      "Train Epoch: 3 [7520/110534 (7%)]\tClassification Loss: 2.6579\r\n",
      "Train Epoch: 3 [7680/110534 (7%)]\tClassification Loss: 1.7267\r\n",
      "Train Epoch: 3 [7840/110534 (7%)]\tClassification Loss: 1.5163\r\n",
      "Test() called at batch_idx: 500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4511, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [8000/110534 (7%)]\tClassification Loss: 1.2657\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_500.pth.tar\r\n",
      "Train Epoch: 3 [8160/110534 (7%)]\tClassification Loss: 1.7969\r\n",
      "Train Epoch: 3 [8320/110534 (8%)]\tClassification Loss: 1.7205\r\n",
      "Train Epoch: 3 [8480/110534 (8%)]\tClassification Loss: 1.1037\r\n",
      "Train Epoch: 3 [8640/110534 (8%)]\tClassification Loss: 1.7907\r\n",
      "Train Epoch: 3 [8800/110534 (8%)]\tClassification Loss: 1.4867\r\n",
      "Train Epoch: 3 [8960/110534 (8%)]\tClassification Loss: 2.1654\r\n",
      "Train Epoch: 3 [9120/110534 (8%)]\tClassification Loss: 1.0391\r\n",
      "Train Epoch: 3 [9280/110534 (8%)]\tClassification Loss: 1.7022\r\n",
      "Train Epoch: 3 [9440/110534 (9%)]\tClassification Loss: 1.7468\r\n",
      "Test() called at batch_idx: 600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4461, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [9600/110534 (9%)]\tClassification Loss: 1.3004\r\n",
      "Train Epoch: 3 [9760/110534 (9%)]\tClassification Loss: 1.9319\r\n",
      "Train Epoch: 3 [9920/110534 (9%)]\tClassification Loss: 2.0621\r\n",
      "Train Epoch: 3 [10080/110534 (9%)]\tClassification Loss: 1.0409\r\n",
      "Train Epoch: 3 [10240/110534 (9%)]\tClassification Loss: 2.2443\r\n",
      "Train Epoch: 3 [10400/110534 (9%)]\tClassification Loss: 1.4355\r\n",
      "Train Epoch: 3 [10560/110534 (10%)]\tClassification Loss: 1.6535\r\n",
      "Train Epoch: 3 [10720/110534 (10%)]\tClassification Loss: 1.6786\r\n",
      "Train Epoch: 3 [10880/110534 (10%)]\tClassification Loss: 1.4333\r\n",
      "Train Epoch: 3 [11040/110534 (10%)]\tClassification Loss: 1.5054\r\n",
      "Test() called at batch_idx: 700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4507, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [11200/110534 (10%)]\tClassification Loss: 1.1597\r\n",
      "Train Epoch: 3 [11360/110534 (10%)]\tClassification Loss: 1.6196\r\n",
      "Train Epoch: 3 [11520/110534 (10%)]\tClassification Loss: 2.1282\r\n",
      "Train Epoch: 3 [11680/110534 (11%)]\tClassification Loss: 1.8243\r\n",
      "Train Epoch: 3 [11840/110534 (11%)]\tClassification Loss: 1.7045\r\n",
      "Train Epoch: 3 [12000/110534 (11%)]\tClassification Loss: 1.3107\r\n",
      "Train Epoch: 3 [12160/110534 (11%)]\tClassification Loss: 1.5567\r\n",
      "Train Epoch: 3 [12320/110534 (11%)]\tClassification Loss: 1.6146\r\n",
      "Train Epoch: 3 [12480/110534 (11%)]\tClassification Loss: 1.4255\r\n",
      "Train Epoch: 3 [12640/110534 (11%)]\tClassification Loss: 1.5186\r\n",
      "Test() called at batch_idx: 800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4346, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [12800/110534 (12%)]\tClassification Loss: 1.7661\r\n",
      "Train Epoch: 3 [12960/110534 (12%)]\tClassification Loss: 1.9260\r\n",
      "Train Epoch: 3 [13120/110534 (12%)]\tClassification Loss: 1.5489\r\n",
      "Train Epoch: 3 [13280/110534 (12%)]\tClassification Loss: 1.5571\r\n",
      "Train Epoch: 3 [13440/110534 (12%)]\tClassification Loss: 1.9325\r\n",
      "Train Epoch: 3 [13600/110534 (12%)]\tClassification Loss: 1.4890\r\n",
      "Train Epoch: 3 [13760/110534 (12%)]\tClassification Loss: 1.8074\r\n",
      "Train Epoch: 3 [13920/110534 (13%)]\tClassification Loss: 1.5670\r\n",
      "Train Epoch: 3 [14080/110534 (13%)]\tClassification Loss: 1.2628\r\n",
      "Train Epoch: 3 [14240/110534 (13%)]\tClassification Loss: 1.9183\r\n",
      "Test() called at batch_idx: 900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4447, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [14400/110534 (13%)]\tClassification Loss: 1.4991\r\n",
      "Train Epoch: 3 [14560/110534 (13%)]\tClassification Loss: 1.2964\r\n",
      "Train Epoch: 3 [14720/110534 (13%)]\tClassification Loss: 0.8593\r\n",
      "Train Epoch: 3 [14880/110534 (13%)]\tClassification Loss: 1.2798\r\n",
      "Train Epoch: 3 [15040/110534 (14%)]\tClassification Loss: 1.1026\r\n",
      "Train Epoch: 3 [15200/110534 (14%)]\tClassification Loss: 1.9374\r\n",
      "Train Epoch: 3 [15360/110534 (14%)]\tClassification Loss: 0.9369\r\n",
      "Train Epoch: 3 [15520/110534 (14%)]\tClassification Loss: 0.9774\r\n",
      "Train Epoch: 3 [15680/110534 (14%)]\tClassification Loss: 2.0201\r\n",
      "Train Epoch: 3 [15840/110534 (14%)]\tClassification Loss: 1.5305\r\n",
      "Test() called at batch_idx: 1000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4416, Accuracy: 306/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [16000/110534 (14%)]\tClassification Loss: 1.3199\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1000.pth.tar\r\n",
      "Train Epoch: 3 [16160/110534 (15%)]\tClassification Loss: 1.6261\r\n",
      "Train Epoch: 3 [16320/110534 (15%)]\tClassification Loss: 2.1794\r\n",
      "Train Epoch: 3 [16480/110534 (15%)]\tClassification Loss: 1.9781\r\n",
      "Train Epoch: 3 [16640/110534 (15%)]\tClassification Loss: 1.5078\r\n",
      "Train Epoch: 3 [16800/110534 (15%)]\tClassification Loss: 1.4960\r\n",
      "Train Epoch: 3 [16960/110534 (15%)]\tClassification Loss: 1.5778\r\n",
      "Train Epoch: 3 [17120/110534 (15%)]\tClassification Loss: 1.7454\r\n",
      "Train Epoch: 3 [17280/110534 (16%)]\tClassification Loss: 1.5117\r\n",
      "Train Epoch: 3 [17440/110534 (16%)]\tClassification Loss: 1.0733\r\n",
      "Test() called at batch_idx: 1100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4513, Accuracy: 290/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 3 [17600/110534 (16%)]\tClassification Loss: 1.5880\r\n",
      "Train Epoch: 3 [17760/110534 (16%)]\tClassification Loss: 1.6923\r\n",
      "Train Epoch: 3 [17920/110534 (16%)]\tClassification Loss: 1.3031\r\n",
      "Train Epoch: 3 [18080/110534 (16%)]\tClassification Loss: 1.1829\r\n",
      "Train Epoch: 3 [18240/110534 (17%)]\tClassification Loss: 1.5016\r\n",
      "Train Epoch: 3 [18400/110534 (17%)]\tClassification Loss: 1.7046\r\n",
      "Train Epoch: 3 [18560/110534 (17%)]\tClassification Loss: 1.9634\r\n",
      "Train Epoch: 3 [18720/110534 (17%)]\tClassification Loss: 1.8078\r\n",
      "Train Epoch: 3 [18880/110534 (17%)]\tClassification Loss: 1.6016\r\n",
      "Train Epoch: 3 [19040/110534 (17%)]\tClassification Loss: 1.9238\r\n",
      "Test() called at batch_idx: 1200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4469, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [19200/110534 (17%)]\tClassification Loss: 1.5681\r\n",
      "Train Epoch: 3 [19360/110534 (18%)]\tClassification Loss: 1.3257\r\n",
      "Train Epoch: 3 [19520/110534 (18%)]\tClassification Loss: 1.3236\r\n",
      "Train Epoch: 3 [19680/110534 (18%)]\tClassification Loss: 1.9504\r\n",
      "Train Epoch: 3 [19840/110534 (18%)]\tClassification Loss: 1.8158\r\n",
      "Train Epoch: 3 [20000/110534 (18%)]\tClassification Loss: 1.7964\r\n",
      "Train Epoch: 3 [20160/110534 (18%)]\tClassification Loss: 1.7200\r\n",
      "Train Epoch: 3 [20320/110534 (18%)]\tClassification Loss: 1.6676\r\n",
      "Train Epoch: 3 [20480/110534 (19%)]\tClassification Loss: 1.1942\r\n",
      "Train Epoch: 3 [20640/110534 (19%)]\tClassification Loss: 1.2294\r\n",
      "Test() called at batch_idx: 1300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4504, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [20800/110534 (19%)]\tClassification Loss: 1.5749\r\n",
      "Train Epoch: 3 [20960/110534 (19%)]\tClassification Loss: 1.1986\r\n",
      "Train Epoch: 3 [21120/110534 (19%)]\tClassification Loss: 1.6342\r\n",
      "Train Epoch: 3 [21280/110534 (19%)]\tClassification Loss: 1.5694\r\n",
      "Train Epoch: 3 [21440/110534 (19%)]\tClassification Loss: 1.3389\r\n",
      "Train Epoch: 3 [21600/110534 (20%)]\tClassification Loss: 1.5449\r\n",
      "Train Epoch: 3 [21760/110534 (20%)]\tClassification Loss: 1.1411\r\n",
      "Train Epoch: 3 [21920/110534 (20%)]\tClassification Loss: 1.9280\r\n",
      "Train Epoch: 3 [22080/110534 (20%)]\tClassification Loss: 1.4858\r\n",
      "Train Epoch: 3 [22240/110534 (20%)]\tClassification Loss: 1.4243\r\n",
      "Test() called at batch_idx: 1400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4476, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [22400/110534 (20%)]\tClassification Loss: 2.0089\r\n",
      "Train Epoch: 3 [22560/110534 (20%)]\tClassification Loss: 1.5490\r\n",
      "Train Epoch: 3 [22720/110534 (21%)]\tClassification Loss: 1.7882\r\n",
      "Train Epoch: 3 [22880/110534 (21%)]\tClassification Loss: 1.7662\r\n",
      "Train Epoch: 3 [23040/110534 (21%)]\tClassification Loss: 1.3670\r\n",
      "Train Epoch: 3 [23200/110534 (21%)]\tClassification Loss: 1.4757\r\n",
      "Train Epoch: 3 [23360/110534 (21%)]\tClassification Loss: 1.3343\r\n",
      "Train Epoch: 3 [23520/110534 (21%)]\tClassification Loss: 1.8567\r\n",
      "Train Epoch: 3 [23680/110534 (21%)]\tClassification Loss: 1.7012\r\n",
      "Train Epoch: 3 [23840/110534 (22%)]\tClassification Loss: 1.6839\r\n",
      "Test() called at batch_idx: 1500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4458, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [24000/110534 (22%)]\tClassification Loss: 2.0020\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1500.pth.tar\r\n",
      "Train Epoch: 3 [24160/110534 (22%)]\tClassification Loss: 1.4293\r\n",
      "Train Epoch: 3 [24320/110534 (22%)]\tClassification Loss: 1.5604\r\n",
      "Train Epoch: 3 [24480/110534 (22%)]\tClassification Loss: 1.9931\r\n",
      "Train Epoch: 3 [24640/110534 (22%)]\tClassification Loss: 1.5385\r\n",
      "Train Epoch: 3 [24800/110534 (22%)]\tClassification Loss: 1.1544\r\n",
      "Train Epoch: 3 [24960/110534 (23%)]\tClassification Loss: 1.5175\r\n",
      "Train Epoch: 3 [25120/110534 (23%)]\tClassification Loss: 1.3413\r\n",
      "Train Epoch: 3 [25280/110534 (23%)]\tClassification Loss: 1.3960\r\n",
      "Train Epoch: 3 [25440/110534 (23%)]\tClassification Loss: 2.1738\r\n",
      "Test() called at batch_idx: 1600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4411, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [25600/110534 (23%)]\tClassification Loss: 1.6864\r\n",
      "Train Epoch: 3 [25760/110534 (23%)]\tClassification Loss: 1.6186\r\n",
      "Train Epoch: 3 [25920/110534 (23%)]\tClassification Loss: 1.1979\r\n",
      "Train Epoch: 3 [26080/110534 (24%)]\tClassification Loss: 1.5249\r\n",
      "Train Epoch: 3 [26240/110534 (24%)]\tClassification Loss: 1.2035\r\n",
      "Train Epoch: 3 [26400/110534 (24%)]\tClassification Loss: 1.7022\r\n",
      "Train Epoch: 3 [26560/110534 (24%)]\tClassification Loss: 1.7278\r\n",
      "Train Epoch: 3 [26720/110534 (24%)]\tClassification Loss: 1.2411\r\n",
      "Train Epoch: 3 [26880/110534 (24%)]\tClassification Loss: 1.0880\r\n",
      "Train Epoch: 3 [27040/110534 (24%)]\tClassification Loss: 1.7450\r\n",
      "Test() called at batch_idx: 1700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4390, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [27200/110534 (25%)]\tClassification Loss: 1.2520\r\n",
      "Train Epoch: 3 [27360/110534 (25%)]\tClassification Loss: 1.5525\r\n",
      "Train Epoch: 3 [27520/110534 (25%)]\tClassification Loss: 1.1777\r\n",
      "Train Epoch: 3 [27680/110534 (25%)]\tClassification Loss: 1.9771\r\n",
      "Train Epoch: 3 [27840/110534 (25%)]\tClassification Loss: 1.7346\r\n",
      "Train Epoch: 3 [28000/110534 (25%)]\tClassification Loss: 1.3440\r\n",
      "Train Epoch: 3 [28160/110534 (25%)]\tClassification Loss: 1.4265\r\n",
      "Train Epoch: 3 [28320/110534 (26%)]\tClassification Loss: 1.3715\r\n",
      "Train Epoch: 3 [28480/110534 (26%)]\tClassification Loss: 1.1143\r\n",
      "Train Epoch: 3 [28640/110534 (26%)]\tClassification Loss: 2.0679\r\n",
      "Test() called at batch_idx: 1800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4420, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [28800/110534 (26%)]\tClassification Loss: 2.0593\r\n",
      "Train Epoch: 3 [28960/110534 (26%)]\tClassification Loss: 1.1864\r\n",
      "Train Epoch: 3 [29120/110534 (26%)]\tClassification Loss: 1.1860\r\n",
      "Train Epoch: 3 [29280/110534 (26%)]\tClassification Loss: 1.4506\r\n",
      "Train Epoch: 3 [29440/110534 (27%)]\tClassification Loss: 1.5843\r\n",
      "Train Epoch: 3 [29600/110534 (27%)]\tClassification Loss: 2.1704\r\n",
      "Train Epoch: 3 [29760/110534 (27%)]\tClassification Loss: 1.3756\r\n",
      "Train Epoch: 3 [29920/110534 (27%)]\tClassification Loss: 1.5368\r\n",
      "Train Epoch: 3 [30080/110534 (27%)]\tClassification Loss: 0.9434\r\n",
      "Train Epoch: 3 [30240/110534 (27%)]\tClassification Loss: 1.2787\r\n",
      "Test() called at batch_idx: 1900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4406, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [30400/110534 (28%)]\tClassification Loss: 1.3023\r\n",
      "Train Epoch: 3 [30560/110534 (28%)]\tClassification Loss: 2.0194\r\n",
      "Train Epoch: 3 [30720/110534 (28%)]\tClassification Loss: 1.9938\r\n",
      "Train Epoch: 3 [30880/110534 (28%)]\tClassification Loss: 1.5945\r\n",
      "Train Epoch: 3 [31040/110534 (28%)]\tClassification Loss: 1.1067\r\n",
      "Train Epoch: 3 [31200/110534 (28%)]\tClassification Loss: 1.8889\r\n",
      "Train Epoch: 3 [31360/110534 (28%)]\tClassification Loss: 1.4487\r\n",
      "Train Epoch: 3 [31520/110534 (29%)]\tClassification Loss: 1.7155\r\n",
      "Train Epoch: 3 [31680/110534 (29%)]\tClassification Loss: 1.6110\r\n",
      "Train Epoch: 3 [31840/110534 (29%)]\tClassification Loss: 1.2512\r\n",
      "Test() called at batch_idx: 2000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4394, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [32000/110534 (29%)]\tClassification Loss: 0.8979\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_2000.pth.tar\r\n",
      "Train Epoch: 3 [32160/110534 (29%)]\tClassification Loss: 1.4559\r\n",
      "Train Epoch: 3 [32320/110534 (29%)]\tClassification Loss: 1.7061\r\n",
      "Train Epoch: 3 [32480/110534 (29%)]\tClassification Loss: 1.1761\r\n",
      "Train Epoch: 3 [32640/110534 (30%)]\tClassification Loss: 1.3163\r\n",
      "Train Epoch: 3 [32800/110534 (30%)]\tClassification Loss: 1.3276\r\n",
      "Train Epoch: 3 [32960/110534 (30%)]\tClassification Loss: 1.3787\r\n",
      "Train Epoch: 3 [33120/110534 (30%)]\tClassification Loss: 1.8168\r\n",
      "Train Epoch: 3 [33280/110534 (30%)]\tClassification Loss: 1.1759\r\n",
      "Train Epoch: 3 [33440/110534 (30%)]\tClassification Loss: 1.5223\r\n",
      "Test() called at batch_idx: 2100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4564, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [33600/110534 (30%)]\tClassification Loss: 1.6643\r\n",
      "Train Epoch: 3 [33760/110534 (31%)]\tClassification Loss: 1.1204\r\n",
      "Train Epoch: 3 [33920/110534 (31%)]\tClassification Loss: 1.1152\r\n",
      "Train Epoch: 3 [34080/110534 (31%)]\tClassification Loss: 1.0752\r\n",
      "Train Epoch: 3 [34240/110534 (31%)]\tClassification Loss: 1.6107\r\n",
      "Train Epoch: 3 [34400/110534 (31%)]\tClassification Loss: 1.3108\r\n",
      "Train Epoch: 3 [34560/110534 (31%)]\tClassification Loss: 1.1005\r\n",
      "Train Epoch: 3 [34720/110534 (31%)]\tClassification Loss: 1.7013\r\n",
      "Train Epoch: 3 [34880/110534 (32%)]\tClassification Loss: 2.0392\r\n",
      "Train Epoch: 3 [35040/110534 (32%)]\tClassification Loss: 1.2294\r\n",
      "Test() called at batch_idx: 2200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4332, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [35200/110534 (32%)]\tClassification Loss: 1.7039\r\n",
      "Train Epoch: 3 [35360/110534 (32%)]\tClassification Loss: 1.1996\r\n",
      "Train Epoch: 3 [35520/110534 (32%)]\tClassification Loss: 1.7494\r\n",
      "Train Epoch: 3 [35680/110534 (32%)]\tClassification Loss: 1.7723\r\n",
      "Train Epoch: 3 [35840/110534 (32%)]\tClassification Loss: 1.5844\r\n",
      "Train Epoch: 3 [36000/110534 (33%)]\tClassification Loss: 1.1447\r\n",
      "Train Epoch: 3 [36160/110534 (33%)]\tClassification Loss: 1.7800\r\n",
      "Train Epoch: 3 [36320/110534 (33%)]\tClassification Loss: 1.7531\r\n",
      "Train Epoch: 3 [36480/110534 (33%)]\tClassification Loss: 1.9581\r\n",
      "Train Epoch: 3 [36640/110534 (33%)]\tClassification Loss: 1.2214\r\n",
      "Test() called at batch_idx: 2300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4410, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [36800/110534 (33%)]\tClassification Loss: 1.4841\r\n",
      "Train Epoch: 3 [36960/110534 (33%)]\tClassification Loss: 1.5499\r\n",
      "Train Epoch: 3 [37120/110534 (34%)]\tClassification Loss: 1.2745\r\n",
      "Train Epoch: 3 [37280/110534 (34%)]\tClassification Loss: 2.0901\r\n",
      "Train Epoch: 3 [37440/110534 (34%)]\tClassification Loss: 1.5163\r\n",
      "Train Epoch: 3 [37600/110534 (34%)]\tClassification Loss: 1.3768\r\n",
      "Train Epoch: 3 [37760/110534 (34%)]\tClassification Loss: 1.7780\r\n",
      "Train Epoch: 3 [37920/110534 (34%)]\tClassification Loss: 2.0988\r\n",
      "Train Epoch: 3 [38080/110534 (34%)]\tClassification Loss: 1.4890\r\n",
      "Train Epoch: 3 [38240/110534 (35%)]\tClassification Loss: 1.4462\r\n",
      "Test() called at batch_idx: 2400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4340, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [38400/110534 (35%)]\tClassification Loss: 1.3683\r\n",
      "Train Epoch: 3 [38560/110534 (35%)]\tClassification Loss: 1.3825\r\n",
      "Train Epoch: 3 [38720/110534 (35%)]\tClassification Loss: 1.1658\r\n",
      "Train Epoch: 3 [38880/110534 (35%)]\tClassification Loss: 1.0442\r\n",
      "Train Epoch: 3 [39040/110534 (35%)]\tClassification Loss: 1.2612\r\n",
      "Train Epoch: 3 [39200/110534 (35%)]\tClassification Loss: 1.2822\r\n",
      "Train Epoch: 3 [39360/110534 (36%)]\tClassification Loss: 0.8279\r\n",
      "Train Epoch: 3 [39520/110534 (36%)]\tClassification Loss: 1.5009\r\n",
      "Train Epoch: 3 [39680/110534 (36%)]\tClassification Loss: 1.4779\r\n",
      "Train Epoch: 3 [39840/110534 (36%)]\tClassification Loss: 1.1212\r\n",
      "Test() called at batch_idx: 2500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4326, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [40000/110534 (36%)]\tClassification Loss: 1.1174\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_2500.pth.tar\r\n",
      "Train Epoch: 3 [40160/110534 (36%)]\tClassification Loss: 1.5724\r\n",
      "Train Epoch: 3 [40320/110534 (36%)]\tClassification Loss: 2.0948\r\n",
      "Train Epoch: 3 [40480/110534 (37%)]\tClassification Loss: 1.4025\r\n",
      "Train Epoch: 3 [40640/110534 (37%)]\tClassification Loss: 1.2950\r\n",
      "Train Epoch: 3 [40800/110534 (37%)]\tClassification Loss: 1.6672\r\n",
      "Train Epoch: 3 [40960/110534 (37%)]\tClassification Loss: 1.5314\r\n",
      "Train Epoch: 3 [41120/110534 (37%)]\tClassification Loss: 2.7689\r\n",
      "Train Epoch: 3 [41280/110534 (37%)]\tClassification Loss: 1.3542\r\n",
      "Train Epoch: 3 [41440/110534 (37%)]\tClassification Loss: 1.6594\r\n",
      "Test() called at batch_idx: 2600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4352, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [41600/110534 (38%)]\tClassification Loss: 1.2452\r\n",
      "Train Epoch: 3 [41760/110534 (38%)]\tClassification Loss: 1.3244\r\n",
      "Train Epoch: 3 [41920/110534 (38%)]\tClassification Loss: 0.9203\r\n",
      "Train Epoch: 3 [42080/110534 (38%)]\tClassification Loss: 1.2914\r\n",
      "Train Epoch: 3 [42240/110534 (38%)]\tClassification Loss: 1.1832\r\n",
      "Train Epoch: 3 [42400/110534 (38%)]\tClassification Loss: 1.6891\r\n",
      "Train Epoch: 3 [42560/110534 (39%)]\tClassification Loss: 0.8370\r\n",
      "Train Epoch: 3 [42720/110534 (39%)]\tClassification Loss: 1.9844\r\n",
      "Train Epoch: 3 [42880/110534 (39%)]\tClassification Loss: 1.1260\r\n",
      "Train Epoch: 3 [43040/110534 (39%)]\tClassification Loss: 2.1216\r\n",
      "Test() called at batch_idx: 2700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4220, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [43200/110534 (39%)]\tClassification Loss: 1.3818\r\n",
      "Train Epoch: 3 [43360/110534 (39%)]\tClassification Loss: 1.7874\r\n",
      "Train Epoch: 3 [43520/110534 (39%)]\tClassification Loss: 1.1691\r\n",
      "Train Epoch: 3 [43680/110534 (40%)]\tClassification Loss: 1.2746\r\n",
      "Train Epoch: 3 [43840/110534 (40%)]\tClassification Loss: 1.7801\r\n",
      "Train Epoch: 3 [44000/110534 (40%)]\tClassification Loss: 1.4601\r\n",
      "Train Epoch: 3 [44160/110534 (40%)]\tClassification Loss: 1.3189\r\n",
      "Train Epoch: 3 [44320/110534 (40%)]\tClassification Loss: 1.3411\r\n",
      "Train Epoch: 3 [44480/110534 (40%)]\tClassification Loss: 1.3741\r\n",
      "Train Epoch: 3 [44640/110534 (40%)]\tClassification Loss: 1.2604\r\n",
      "Test() called at batch_idx: 2800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4309, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [44800/110534 (41%)]\tClassification Loss: 1.6675\r\n",
      "Train Epoch: 3 [44960/110534 (41%)]\tClassification Loss: 1.6911\r\n",
      "Train Epoch: 3 [45120/110534 (41%)]\tClassification Loss: 1.4523\r\n",
      "Train Epoch: 3 [45280/110534 (41%)]\tClassification Loss: 1.3401\r\n",
      "Train Epoch: 3 [45440/110534 (41%)]\tClassification Loss: 2.0699\r\n",
      "Train Epoch: 3 [45600/110534 (41%)]\tClassification Loss: 1.6788\r\n",
      "Train Epoch: 3 [45760/110534 (41%)]\tClassification Loss: 1.3162\r\n",
      "Train Epoch: 3 [45920/110534 (42%)]\tClassification Loss: 1.1268\r\n",
      "Train Epoch: 3 [46080/110534 (42%)]\tClassification Loss: 1.5387\r\n",
      "Train Epoch: 3 [46240/110534 (42%)]\tClassification Loss: 1.4264\r\n",
      "Test() called at batch_idx: 2900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4289, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [46400/110534 (42%)]\tClassification Loss: 1.6128\r\n",
      "Train Epoch: 3 [46560/110534 (42%)]\tClassification Loss: 1.9826\r\n",
      "Train Epoch: 3 [46720/110534 (42%)]\tClassification Loss: 1.4727\r\n",
      "Train Epoch: 3 [46880/110534 (42%)]\tClassification Loss: 1.1642\r\n",
      "Train Epoch: 3 [47040/110534 (43%)]\tClassification Loss: 1.8809\r\n",
      "Train Epoch: 3 [47200/110534 (43%)]\tClassification Loss: 1.0674\r\n",
      "Train Epoch: 3 [47360/110534 (43%)]\tClassification Loss: 1.5263\r\n",
      "Train Epoch: 3 [47520/110534 (43%)]\tClassification Loss: 1.6895\r\n",
      "Train Epoch: 3 [47680/110534 (43%)]\tClassification Loss: 1.0721\r\n",
      "Train Epoch: 3 [47840/110534 (43%)]\tClassification Loss: 1.3078\r\n",
      "Test() called at batch_idx: 3000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4336, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [48000/110534 (43%)]\tClassification Loss: 1.3375\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_3000.pth.tar\r\n",
      "Train Epoch: 3 [48160/110534 (44%)]\tClassification Loss: 1.6209\r\n",
      "Train Epoch: 3 [48320/110534 (44%)]\tClassification Loss: 2.0509\r\n",
      "Train Epoch: 3 [48480/110534 (44%)]\tClassification Loss: 1.8493\r\n",
      "Train Epoch: 3 [48640/110534 (44%)]\tClassification Loss: 1.5503\r\n",
      "Train Epoch: 3 [48800/110534 (44%)]\tClassification Loss: 1.4064\r\n",
      "Train Epoch: 3 [48960/110534 (44%)]\tClassification Loss: 1.7235\r\n",
      "Train Epoch: 3 [49120/110534 (44%)]\tClassification Loss: 1.8147\r\n",
      "Train Epoch: 3 [49280/110534 (45%)]\tClassification Loss: 1.2242\r\n",
      "Train Epoch: 3 [49440/110534 (45%)]\tClassification Loss: 1.4785\r\n",
      "Test() called at batch_idx: 3100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4313, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [49600/110534 (45%)]\tClassification Loss: 1.6057\r\n",
      "Train Epoch: 3 [49760/110534 (45%)]\tClassification Loss: 1.4013\r\n",
      "Train Epoch: 3 [49920/110534 (45%)]\tClassification Loss: 1.5712\r\n",
      "Train Epoch: 3 [50080/110534 (45%)]\tClassification Loss: 1.3374\r\n",
      "Train Epoch: 3 [50240/110534 (45%)]\tClassification Loss: 1.6475\r\n",
      "Train Epoch: 3 [50400/110534 (46%)]\tClassification Loss: 1.3607\r\n",
      "Train Epoch: 3 [50560/110534 (46%)]\tClassification Loss: 1.3226\r\n",
      "Train Epoch: 3 [50720/110534 (46%)]\tClassification Loss: 1.7118\r\n",
      "Train Epoch: 3 [50880/110534 (46%)]\tClassification Loss: 1.4972\r\n",
      "Train Epoch: 3 [51040/110534 (46%)]\tClassification Loss: 1.8908\r\n",
      "Test() called at batch_idx: 3200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4449, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [51200/110534 (46%)]\tClassification Loss: 1.5080\r\n",
      "Train Epoch: 3 [51360/110534 (46%)]\tClassification Loss: 1.4095\r\n",
      "Train Epoch: 3 [51520/110534 (47%)]\tClassification Loss: 1.5177\r\n",
      "Train Epoch: 3 [51680/110534 (47%)]\tClassification Loss: 2.3047\r\n",
      "Train Epoch: 3 [51840/110534 (47%)]\tClassification Loss: 2.4891\r\n",
      "Train Epoch: 3 [52000/110534 (47%)]\tClassification Loss: 1.0522\r\n",
      "Train Epoch: 3 [52160/110534 (47%)]\tClassification Loss: 1.1552\r\n",
      "Train Epoch: 3 [52320/110534 (47%)]\tClassification Loss: 1.6336\r\n",
      "Train Epoch: 3 [52480/110534 (47%)]\tClassification Loss: 2.0986\r\n",
      "Train Epoch: 3 [52640/110534 (48%)]\tClassification Loss: 1.4664\r\n",
      "Test() called at batch_idx: 3300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4312, Accuracy: 306/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [52800/110534 (48%)]\tClassification Loss: 0.9589\r\n",
      "Train Epoch: 3 [52960/110534 (48%)]\tClassification Loss: 1.2030\r\n",
      "Train Epoch: 3 [53120/110534 (48%)]\tClassification Loss: 1.5531\r\n",
      "Train Epoch: 3 [53280/110534 (48%)]\tClassification Loss: 1.5015\r\n",
      "Train Epoch: 3 [53440/110534 (48%)]\tClassification Loss: 1.8303\r\n",
      "Train Epoch: 3 [53600/110534 (48%)]\tClassification Loss: 1.0050\r\n",
      "Train Epoch: 3 [53760/110534 (49%)]\tClassification Loss: 1.9612\r\n",
      "Train Epoch: 3 [53920/110534 (49%)]\tClassification Loss: 1.3935\r\n",
      "Train Epoch: 3 [54080/110534 (49%)]\tClassification Loss: 1.8135\r\n",
      "Train Epoch: 3 [54240/110534 (49%)]\tClassification Loss: 1.7675\r\n",
      "Test() called at batch_idx: 3400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4323, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [54400/110534 (49%)]\tClassification Loss: 1.7205\r\n",
      "Train Epoch: 3 [54560/110534 (49%)]\tClassification Loss: 1.4554\r\n",
      "Train Epoch: 3 [54720/110534 (50%)]\tClassification Loss: 1.0525\r\n",
      "Train Epoch: 3 [54880/110534 (50%)]\tClassification Loss: 1.2706\r\n",
      "Train Epoch: 3 [55040/110534 (50%)]\tClassification Loss: 1.4549\r\n",
      "Train Epoch: 3 [55200/110534 (50%)]\tClassification Loss: 1.3402\r\n",
      "Train Epoch: 3 [55360/110534 (50%)]\tClassification Loss: 1.5557\r\n",
      "Train Epoch: 3 [55520/110534 (50%)]\tClassification Loss: 1.6815\r\n",
      "Train Epoch: 3 [55680/110534 (50%)]\tClassification Loss: 1.5615\r\n",
      "Train Epoch: 3 [55840/110534 (51%)]\tClassification Loss: 2.1793\r\n",
      "Test() called at batch_idx: 3500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4300, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [56000/110534 (51%)]\tClassification Loss: 1.0125\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_3500.pth.tar\r\n",
      "Train Epoch: 3 [56160/110534 (51%)]\tClassification Loss: 1.2188\r\n",
      "Train Epoch: 3 [56320/110534 (51%)]\tClassification Loss: 1.4884\r\n",
      "Train Epoch: 3 [56480/110534 (51%)]\tClassification Loss: 1.5001\r\n",
      "Train Epoch: 3 [56640/110534 (51%)]\tClassification Loss: 1.0990\r\n",
      "Train Epoch: 3 [56800/110534 (51%)]\tClassification Loss: 1.4986\r\n",
      "Train Epoch: 3 [56960/110534 (52%)]\tClassification Loss: 0.9381\r\n",
      "Train Epoch: 3 [57120/110534 (52%)]\tClassification Loss: 1.7704\r\n",
      "Train Epoch: 3 [57280/110534 (52%)]\tClassification Loss: 1.4731\r\n",
      "Train Epoch: 3 [57440/110534 (52%)]\tClassification Loss: 1.2771\r\n",
      "Test() called at batch_idx: 3600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4341, Accuracy: 306/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [57600/110534 (52%)]\tClassification Loss: 1.6577\r\n",
      "Train Epoch: 3 [57760/110534 (52%)]\tClassification Loss: 1.4597\r\n",
      "Train Epoch: 3 [57920/110534 (52%)]\tClassification Loss: 1.4710\r\n",
      "Train Epoch: 3 [58080/110534 (53%)]\tClassification Loss: 1.9380\r\n",
      "Train Epoch: 3 [58240/110534 (53%)]\tClassification Loss: 1.1364\r\n",
      "Train Epoch: 3 [58400/110534 (53%)]\tClassification Loss: 1.6245\r\n",
      "Train Epoch: 3 [58560/110534 (53%)]\tClassification Loss: 2.1599\r\n",
      "Train Epoch: 3 [58720/110534 (53%)]\tClassification Loss: 1.6087\r\n",
      "Train Epoch: 3 [58880/110534 (53%)]\tClassification Loss: 2.0830\r\n",
      "Train Epoch: 3 [59040/110534 (53%)]\tClassification Loss: 1.8829\r\n",
      "Test() called at batch_idx: 3700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4349, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [59200/110534 (54%)]\tClassification Loss: 1.4533\r\n",
      "Train Epoch: 3 [59360/110534 (54%)]\tClassification Loss: 0.9757\r\n",
      "Train Epoch: 3 [59520/110534 (54%)]\tClassification Loss: 2.0771\r\n",
      "Train Epoch: 3 [59680/110534 (54%)]\tClassification Loss: 2.3255\r\n",
      "Train Epoch: 3 [59840/110534 (54%)]\tClassification Loss: 1.7983\r\n",
      "Train Epoch: 3 [60000/110534 (54%)]\tClassification Loss: 1.4929\r\n",
      "Train Epoch: 3 [60160/110534 (54%)]\tClassification Loss: 1.8015\r\n",
      "Train Epoch: 3 [60320/110534 (55%)]\tClassification Loss: 1.8801\r\n",
      "Train Epoch: 3 [60480/110534 (55%)]\tClassification Loss: 1.1218\r\n",
      "Train Epoch: 3 [60640/110534 (55%)]\tClassification Loss: 1.2877\r\n",
      "Test() called at batch_idx: 3800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4520, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [60800/110534 (55%)]\tClassification Loss: 1.4761\r\n",
      "Train Epoch: 3 [60960/110534 (55%)]\tClassification Loss: 1.7675\r\n",
      "Train Epoch: 3 [61120/110534 (55%)]\tClassification Loss: 1.5995\r\n",
      "Train Epoch: 3 [61280/110534 (55%)]\tClassification Loss: 1.5111\r\n",
      "Train Epoch: 3 [61440/110534 (56%)]\tClassification Loss: 1.6790\r\n",
      "Train Epoch: 3 [61600/110534 (56%)]\tClassification Loss: 1.6676\r\n",
      "Train Epoch: 3 [61760/110534 (56%)]\tClassification Loss: 1.3780\r\n",
      "Train Epoch: 3 [61920/110534 (56%)]\tClassification Loss: 1.9434\r\n",
      "Train Epoch: 3 [62080/110534 (56%)]\tClassification Loss: 1.1831\r\n",
      "Train Epoch: 3 [62240/110534 (56%)]\tClassification Loss: 1.1802\r\n",
      "Test() called at batch_idx: 3900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4325, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [62400/110534 (56%)]\tClassification Loss: 1.4466\r\n",
      "Train Epoch: 3 [62560/110534 (57%)]\tClassification Loss: 1.0928\r\n",
      "Train Epoch: 3 [62720/110534 (57%)]\tClassification Loss: 1.9050\r\n",
      "Train Epoch: 3 [62880/110534 (57%)]\tClassification Loss: 1.5480\r\n",
      "Train Epoch: 3 [63040/110534 (57%)]\tClassification Loss: 1.7702\r\n",
      "Train Epoch: 3 [63200/110534 (57%)]\tClassification Loss: 2.1784\r\n",
      "Train Epoch: 3 [63360/110534 (57%)]\tClassification Loss: 1.7248\r\n",
      "Train Epoch: 3 [63520/110534 (57%)]\tClassification Loss: 1.2213\r\n",
      "Train Epoch: 3 [63680/110534 (58%)]\tClassification Loss: 1.8156\r\n",
      "Train Epoch: 3 [63840/110534 (58%)]\tClassification Loss: 1.1409\r\n",
      "Test() called at batch_idx: 4000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4323, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [64000/110534 (58%)]\tClassification Loss: 1.1541\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_4000.pth.tar\r\n",
      "Train Epoch: 3 [64160/110534 (58%)]\tClassification Loss: 1.7084\r\n",
      "Train Epoch: 3 [64320/110534 (58%)]\tClassification Loss: 1.4410\r\n",
      "Train Epoch: 3 [64480/110534 (58%)]\tClassification Loss: 1.3737\r\n",
      "Train Epoch: 3 [64640/110534 (58%)]\tClassification Loss: 1.5011\r\n",
      "Train Epoch: 3 [64800/110534 (59%)]\tClassification Loss: 1.3402\r\n",
      "Train Epoch: 3 [64960/110534 (59%)]\tClassification Loss: 1.1801\r\n",
      "Train Epoch: 3 [65120/110534 (59%)]\tClassification Loss: 0.9187\r\n",
      "Train Epoch: 3 [65280/110534 (59%)]\tClassification Loss: 1.5786\r\n",
      "Train Epoch: 3 [65440/110534 (59%)]\tClassification Loss: 1.7880\r\n",
      "Test() called at batch_idx: 4100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4254, Accuracy: 303/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [65600/110534 (59%)]\tClassification Loss: 1.2587\r\n",
      "Train Epoch: 3 [65760/110534 (59%)]\tClassification Loss: 1.1862\r\n",
      "Train Epoch: 3 [65920/110534 (60%)]\tClassification Loss: 1.2681\r\n",
      "Train Epoch: 3 [66080/110534 (60%)]\tClassification Loss: 1.3701\r\n",
      "Train Epoch: 3 [66240/110534 (60%)]\tClassification Loss: 2.2049\r\n",
      "Train Epoch: 3 [66400/110534 (60%)]\tClassification Loss: 2.4362\r\n",
      "Train Epoch: 3 [66560/110534 (60%)]\tClassification Loss: 1.5230\r\n",
      "Train Epoch: 3 [66720/110534 (60%)]\tClassification Loss: 1.7390\r\n",
      "Train Epoch: 3 [66880/110534 (61%)]\tClassification Loss: 1.4893\r\n",
      "Train Epoch: 3 [67040/110534 (61%)]\tClassification Loss: 1.3683\r\n",
      "Test() called at batch_idx: 4200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4180, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [67200/110534 (61%)]\tClassification Loss: 2.5967\r\n",
      "Train Epoch: 3 [67360/110534 (61%)]\tClassification Loss: 1.9256\r\n",
      "Train Epoch: 3 [67520/110534 (61%)]\tClassification Loss: 1.2801\r\n",
      "Train Epoch: 3 [67680/110534 (61%)]\tClassification Loss: 1.2827\r\n",
      "Train Epoch: 3 [67840/110534 (61%)]\tClassification Loss: 1.1116\r\n",
      "Train Epoch: 3 [68000/110534 (62%)]\tClassification Loss: 1.6188\r\n",
      "Train Epoch: 3 [68160/110534 (62%)]\tClassification Loss: 1.3694\r\n",
      "Train Epoch: 3 [68320/110534 (62%)]\tClassification Loss: 1.7460\r\n",
      "Train Epoch: 3 [68480/110534 (62%)]\tClassification Loss: 1.0727\r\n",
      "Train Epoch: 3 [68640/110534 (62%)]\tClassification Loss: 1.7062\r\n",
      "Test() called at batch_idx: 4300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4374, Accuracy: 307/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [68800/110534 (62%)]\tClassification Loss: 1.3196\r\n",
      "Train Epoch: 3 [68960/110534 (62%)]\tClassification Loss: 1.4480\r\n",
      "Train Epoch: 3 [69120/110534 (63%)]\tClassification Loss: 1.2674\r\n",
      "Train Epoch: 3 [69280/110534 (63%)]\tClassification Loss: 2.2730\r\n",
      "Train Epoch: 3 [69440/110534 (63%)]\tClassification Loss: 2.2710\r\n",
      "Train Epoch: 3 [69600/110534 (63%)]\tClassification Loss: 1.4342\r\n",
      "Train Epoch: 3 [69760/110534 (63%)]\tClassification Loss: 1.7258\r\n",
      "Train Epoch: 3 [69920/110534 (63%)]\tClassification Loss: 1.3781\r\n",
      "Train Epoch: 3 [70080/110534 (63%)]\tClassification Loss: 1.9848\r\n",
      "Train Epoch: 3 [70240/110534 (64%)]\tClassification Loss: 1.1915\r\n",
      "Test() called at batch_idx: 4400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4249, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [70400/110534 (64%)]\tClassification Loss: 2.0689\r\n",
      "Train Epoch: 3 [70560/110534 (64%)]\tClassification Loss: 1.1171\r\n",
      "Train Epoch: 3 [70720/110534 (64%)]\tClassification Loss: 1.3677\r\n",
      "Train Epoch: 3 [70880/110534 (64%)]\tClassification Loss: 1.9260\r\n",
      "Train Epoch: 3 [71040/110534 (64%)]\tClassification Loss: 1.7598\r\n",
      "Train Epoch: 3 [71200/110534 (64%)]\tClassification Loss: 1.6931\r\n",
      "Train Epoch: 3 [71360/110534 (65%)]\tClassification Loss: 1.8326\r\n",
      "Train Epoch: 3 [71520/110534 (65%)]\tClassification Loss: 1.2228\r\n",
      "Train Epoch: 3 [71680/110534 (65%)]\tClassification Loss: 1.6310\r\n",
      "Train Epoch: 3 [71840/110534 (65%)]\tClassification Loss: 1.2910\r\n",
      "Test() called at batch_idx: 4500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4326, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [72000/110534 (65%)]\tClassification Loss: 1.0765\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_4500.pth.tar\r\n",
      "Train Epoch: 3 [72160/110534 (65%)]\tClassification Loss: 1.6373\r\n",
      "Train Epoch: 3 [72320/110534 (65%)]\tClassification Loss: 1.2581\r\n",
      "Train Epoch: 3 [72480/110534 (66%)]\tClassification Loss: 1.6469\r\n",
      "Train Epoch: 3 [72640/110534 (66%)]\tClassification Loss: 1.5427\r\n",
      "Train Epoch: 3 [72800/110534 (66%)]\tClassification Loss: 1.8321\r\n",
      "Train Epoch: 3 [72960/110534 (66%)]\tClassification Loss: 1.3603\r\n",
      "Train Epoch: 3 [73120/110534 (66%)]\tClassification Loss: 1.5367\r\n",
      "Train Epoch: 3 [73280/110534 (66%)]\tClassification Loss: 1.6336\r\n",
      "Train Epoch: 3 [73440/110534 (66%)]\tClassification Loss: 1.7280\r\n",
      "Test() called at batch_idx: 4600\r\n",
      "Traceback (most recent call last):\r\n",
      "\r\n",
      "Test set: Average loss: 1.4236, Accuracy: 306/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [73600/110534 (67%)]\tClassification Loss: 1.6201\r\n",
      "Train Epoch: 3 [73760/110534 (67%)]\tClassification Loss: 1.9805\r\n",
      "Train Epoch: 3 [73920/110534 (67%)]\tClassification Loss: 2.3748\r\n",
      "Train Epoch: 3 [74080/110534 (67%)]\tClassification Loss: 1.6082\r\n",
      "Train Epoch: 3 [74240/110534 (67%)]\tClassification Loss: 1.4933\r\n",
      "Train Epoch: 3 [74400/110534 (67%)]\tClassification Loss: 1.9490\r\n",
      "Train Epoch: 3 [74560/110534 (67%)]\tClassification Loss: 1.6013\r\n",
      "Train Epoch: 3 [74720/110534 (68%)]\tClassification Loss: 1.1838\r\n",
      "Train Epoch: 3 [74880/110534 (68%)]\tClassification Loss: 1.6909\r\n",
      "Train Epoch: 3 [75040/110534 (68%)]\tClassification Loss: 1.0573\r\n",
      "Test() called at batch_idx: 4700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4215, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [75200/110534 (68%)]\tClassification Loss: 0.9631\r\n",
      "Train Epoch: 3 [75360/110534 (68%)]\tClassification Loss: 1.5996\r\n",
      "Train Epoch: 3 [75520/110534 (68%)]\tClassification Loss: 1.6998\r\n",
      "Train Epoch: 3 [75680/110534 (68%)]\tClassification Loss: 1.2982\r\n",
      "Train Epoch: 3 [75840/110534 (69%)]\tClassification Loss: 1.5051\r\n",
      "Train Epoch: 3 [76000/110534 (69%)]\tClassification Loss: 1.1452\r\n",
      "Train Epoch: 3 [76160/110534 (69%)]\tClassification Loss: 1.4478\r\n",
      "Train Epoch: 3 [76320/110534 (69%)]\tClassification Loss: 1.2280\r\n",
      "Train Epoch: 3 [76480/110534 (69%)]\tClassification Loss: 2.2504\r\n",
      "Train Epoch: 3 [76640/110534 (69%)]\tClassification Loss: 1.0237\r\n",
      "Test() called at batch_idx: 4800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4364, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [76800/110534 (69%)]\tClassification Loss: 2.0359\r\n",
      "Train Epoch: 3 [76960/110534 (70%)]\tClassification Loss: 1.5842\r\n",
      "Train Epoch: 3 [77120/110534 (70%)]\tClassification Loss: 1.8118\r\n",
      "Train Epoch: 3 [77280/110534 (70%)]\tClassification Loss: 1.4308\r\n",
      "Train Epoch: 3 [77440/110534 (70%)]\tClassification Loss: 1.4920\r\n",
      "Train Epoch: 3 [77600/110534 (70%)]\tClassification Loss: 1.7796\r\n",
      "Train Epoch: 3 [77760/110534 (70%)]\tClassification Loss: 1.6570\r\n",
      "Train Epoch: 3 [77920/110534 (70%)]\tClassification Loss: 1.1072\r\n",
      "Train Epoch: 3 [78080/110534 (71%)]\tClassification Loss: 1.0832\r\n",
      "Train Epoch: 3 [78240/110534 (71%)]\tClassification Loss: 1.5526\r\n",
      "Test() called at batch_idx: 4900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4250, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [78400/110534 (71%)]\tClassification Loss: 1.9279\r\n",
      "Train Epoch: 3 [78560/110534 (71%)]\tClassification Loss: 1.5718\r\n",
      "Train Epoch: 3 [78720/110534 (71%)]\tClassification Loss: 1.7894\r\n",
      "Train Epoch: 3 [78880/110534 (71%)]\tClassification Loss: 1.4830\r\n",
      "Train Epoch: 3 [79040/110534 (72%)]\tClassification Loss: 1.4291\r\n",
      "Train Epoch: 3 [79200/110534 (72%)]\tClassification Loss: 1.3805\r\n",
      "Train Epoch: 3 [79360/110534 (72%)]\tClassification Loss: 1.0739\r\n",
      "Train Epoch: 3 [79520/110534 (72%)]\tClassification Loss: 1.4890\r\n",
      "Train Epoch: 3 [79680/110534 (72%)]\tClassification Loss: 2.1990\r\n",
      "Train Epoch: 3 [79840/110534 (72%)]\tClassification Loss: 1.3961\r\n",
      "Test() called at batch_idx: 5000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4227, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [80000/110534 (72%)]\tClassification Loss: 1.3174\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_5000.pth.tar\r\n",
      "Train Epoch: 3 [80160/110534 (73%)]\tClassification Loss: 1.3535\r\n",
      "Train Epoch: 3 [80320/110534 (73%)]\tClassification Loss: 1.5821\r\n",
      "Train Epoch: 3 [80480/110534 (73%)]\tClassification Loss: 1.2890\r\n",
      "Train Epoch: 3 [80640/110534 (73%)]\tClassification Loss: 1.7872\r\n",
      "Train Epoch: 3 [80800/110534 (73%)]\tClassification Loss: 1.7286\r\n",
      "Train Epoch: 3 [80960/110534 (73%)]\tClassification Loss: 1.9289\r\n",
      "Train Epoch: 3 [81120/110534 (73%)]\tClassification Loss: 1.9396\r\n",
      "Train Epoch: 3 [81280/110534 (74%)]\tClassification Loss: 2.1351\r\n",
      "Train Epoch: 3 [81440/110534 (74%)]\tClassification Loss: 1.9910\r\n",
      "Test() called at batch_idx: 5100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4216, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [81600/110534 (74%)]\tClassification Loss: 1.1204\r\n",
      "Train Epoch: 3 [81760/110534 (74%)]\tClassification Loss: 1.7616\r\n",
      "Train Epoch: 3 [81920/110534 (74%)]\tClassification Loss: 2.3866\r\n",
      "Train Epoch: 3 [82080/110534 (74%)]\tClassification Loss: 1.1285\r\n",
      "Train Epoch: 3 [82240/110534 (74%)]\tClassification Loss: 1.6437\r\n",
      "Train Epoch: 3 [82400/110534 (75%)]\tClassification Loss: 1.1213\r\n",
      "Train Epoch: 3 [82560/110534 (75%)]\tClassification Loss: 1.4859\r\n",
      "Train Epoch: 3 [82720/110534 (75%)]\tClassification Loss: 1.6904\r\n",
      "Train Epoch: 3 [82880/110534 (75%)]\tClassification Loss: 1.5839\r\n",
      "Train Epoch: 3 [83040/110534 (75%)]\tClassification Loss: 1.5349\r\n",
      "Test() called at batch_idx: 5200\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\r\n",
      "    self._send(header + buf)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\r\n",
      "    n = write(self._handle, buf)\r\n",
      "BrokenPipeError: [Errno 32] Broken pipe\r\n",
      "\r\n",
      "Test set: Average loss: 1.4226, Accuracy: 306/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [83200/110534 (75%)]\tClassification Loss: 1.3421\r\n",
      "Train Epoch: 3 [83360/110534 (75%)]\tClassification Loss: 1.0924\r\n",
      "Train Epoch: 3 [83520/110534 (76%)]\tClassification Loss: 2.1189\r\n",
      "Train Epoch: 3 [83680/110534 (76%)]\tClassification Loss: 1.7621\r\n",
      "Train Epoch: 3 [83840/110534 (76%)]\tClassification Loss: 1.3148\r\n",
      "Train Epoch: 3 [84000/110534 (76%)]\tClassification Loss: 1.8516\r\n",
      "Train Epoch: 3 [84160/110534 (76%)]\tClassification Loss: 1.6606\r\n",
      "Train Epoch: 3 [84320/110534 (76%)]\tClassification Loss: 1.8692\r\n",
      "Train Epoch: 3 [84480/110534 (76%)]\tClassification Loss: 1.7873\r\n",
      "Train Epoch: 3 [84640/110534 (77%)]\tClassification Loss: 2.0533\r\n",
      "Test() called at batch_idx: 5300\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\r\n",
      "    self._send(header + buf)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\r\n",
      "    n = write(self._handle, buf)\r\n",
      "BrokenPipeError: [Errno 32] Broken pipe\r\n",
      "\r\n",
      "Test set: Average loss: 1.4221, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [84800/110534 (77%)]\tClassification Loss: 1.8339\r\n",
      "Train Epoch: 3 [84960/110534 (77%)]\tClassification Loss: 1.4741\r\n",
      "Train Epoch: 3 [85120/110534 (77%)]\tClassification Loss: 1.7276\r\n",
      "Train Epoch: 3 [85280/110534 (77%)]\tClassification Loss: 1.9305\r\n",
      "Train Epoch: 3 [85440/110534 (77%)]\tClassification Loss: 1.6340\r\n",
      "Train Epoch: 3 [85600/110534 (77%)]\tClassification Loss: 1.5175\r\n",
      "Train Epoch: 3 [85760/110534 (78%)]\tClassification Loss: 2.3908\r\n",
      "Train Epoch: 3 [85920/110534 (78%)]\tClassification Loss: 0.9903\r\n",
      "Train Epoch: 3 [86080/110534 (78%)]\tClassification Loss: 1.4259\r\n",
      "Train Epoch: 3 [86240/110534 (78%)]\tClassification Loss: 1.0838\r\n",
      "Test() called at batch_idx: 5400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4299, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [86400/110534 (78%)]\tClassification Loss: 1.2007\r\n",
      "Train Epoch: 3 [86560/110534 (78%)]\tClassification Loss: 1.7935\r\n",
      "Train Epoch: 3 [86720/110534 (78%)]\tClassification Loss: 1.9941\r\n",
      "Train Epoch: 3 [86880/110534 (79%)]\tClassification Loss: 1.3392\r\n",
      "Train Epoch: 3 [87040/110534 (79%)]\tClassification Loss: 1.2886\r\n",
      "Train Epoch: 3 [87200/110534 (79%)]\tClassification Loss: 1.7778\r\n",
      "Train Epoch: 3 [87360/110534 (79%)]\tClassification Loss: 1.8878\r\n",
      "Train Epoch: 3 [87520/110534 (79%)]\tClassification Loss: 1.4624\r\n",
      "Train Epoch: 3 [87680/110534 (79%)]\tClassification Loss: 1.1495\r\n",
      "Train Epoch: 3 [87840/110534 (79%)]\tClassification Loss: 2.0072\r\n",
      "Test() called at batch_idx: 5500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4258, Accuracy: 307/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [88000/110534 (80%)]\tClassification Loss: 1.4789\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_5500.pth.tar\r\n",
      "Train Epoch: 3 [88160/110534 (80%)]\tClassification Loss: 1.4715\r\n",
      "Train Epoch: 3 [88320/110534 (80%)]\tClassification Loss: 1.6122\r\n",
      "Train Epoch: 3 [88480/110534 (80%)]\tClassification Loss: 1.3074\r\n",
      "Train Epoch: 3 [88640/110534 (80%)]\tClassification Loss: 1.1951\r\n",
      "Train Epoch: 3 [88800/110534 (80%)]\tClassification Loss: 1.3146\r\n",
      "Train Epoch: 3 [88960/110534 (80%)]\tClassification Loss: 2.2775\r\n",
      "Train Epoch: 3 [89120/110534 (81%)]\tClassification Loss: 1.3460\r\n",
      "Train Epoch: 3 [89280/110534 (81%)]\tClassification Loss: 1.2276\r\n",
      "Train Epoch: 3 [89440/110534 (81%)]\tClassification Loss: 2.5274\r\n",
      "Test() called at batch_idx: 5600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4364, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [89600/110534 (81%)]\tClassification Loss: 1.3841\r\n",
      "Train Epoch: 3 [89760/110534 (81%)]\tClassification Loss: 1.9570\r\n",
      "Train Epoch: 3 [89920/110534 (81%)]\tClassification Loss: 1.7014\r\n",
      "Train Epoch: 3 [90080/110534 (81%)]\tClassification Loss: 1.3865\r\n",
      "Train Epoch: 3 [90240/110534 (82%)]\tClassification Loss: 1.7951\r\n",
      "Train Epoch: 3 [90400/110534 (82%)]\tClassification Loss: 1.6198\r\n",
      "Train Epoch: 3 [90560/110534 (82%)]\tClassification Loss: 1.2498\r\n",
      "Train Epoch: 3 [90720/110534 (82%)]\tClassification Loss: 1.2934\r\n",
      "Train Epoch: 3 [90880/110534 (82%)]\tClassification Loss: 1.5135\r\n",
      "Train Epoch: 3 [91040/110534 (82%)]\tClassification Loss: 2.0596\r\n",
      "Test() called at batch_idx: 5700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4300, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [91200/110534 (83%)]\tClassification Loss: 2.0046\r\n",
      "Train Epoch: 3 [91360/110534 (83%)]\tClassification Loss: 1.1928\r\n",
      "Train Epoch: 3 [91520/110534 (83%)]\tClassification Loss: 1.3716\r\n",
      "Train Epoch: 3 [91680/110534 (83%)]\tClassification Loss: 1.7368\r\n",
      "Train Epoch: 3 [91840/110534 (83%)]\tClassification Loss: 1.4912\r\n",
      "Train Epoch: 3 [92000/110534 (83%)]\tClassification Loss: 2.0771\r\n",
      "Train Epoch: 3 [92160/110534 (83%)]\tClassification Loss: 1.9768\r\n",
      "Train Epoch: 3 [92320/110534 (84%)]\tClassification Loss: 2.2898\r\n",
      "Train Epoch: 3 [92480/110534 (84%)]\tClassification Loss: 1.8002\r\n",
      "Train Epoch: 3 [92640/110534 (84%)]\tClassification Loss: 1.7051\r\n",
      "Test() called at batch_idx: 5800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4240, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [92800/110534 (84%)]\tClassification Loss: 2.0054\r\n",
      "Train Epoch: 3 [92960/110534 (84%)]\tClassification Loss: 1.3849\r\n",
      "Train Epoch: 3 [93120/110534 (84%)]\tClassification Loss: 1.7828\r\n",
      "Train Epoch: 3 [93280/110534 (84%)]\tClassification Loss: 1.4934\r\n",
      "Train Epoch: 3 [93440/110534 (85%)]\tClassification Loss: 2.0910\r\n",
      "Train Epoch: 3 [93600/110534 (85%)]\tClassification Loss: 1.5583\r\n",
      "Train Epoch: 3 [93760/110534 (85%)]\tClassification Loss: 1.9994\r\n",
      "Train Epoch: 3 [93920/110534 (85%)]\tClassification Loss: 1.2319\r\n",
      "Train Epoch: 3 [94080/110534 (85%)]\tClassification Loss: 1.9174\r\n",
      "Train Epoch: 3 [94240/110534 (85%)]\tClassification Loss: 2.2265\r\n",
      "Test() called at batch_idx: 5900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4232, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [94400/110534 (85%)]\tClassification Loss: 1.2184\r\n",
      "Train Epoch: 3 [94560/110534 (86%)]\tClassification Loss: 1.6046\r\n",
      "Train Epoch: 3 [94720/110534 (86%)]\tClassification Loss: 1.1551\r\n",
      "Train Epoch: 3 [94880/110534 (86%)]\tClassification Loss: 1.5172\r\n",
      "Train Epoch: 3 [95040/110534 (86%)]\tClassification Loss: 1.0906\r\n",
      "Train Epoch: 3 [95200/110534 (86%)]\tClassification Loss: 1.3570\r\n",
      "Train Epoch: 3 [95360/110534 (86%)]\tClassification Loss: 1.4994\r\n",
      "Train Epoch: 3 [95520/110534 (86%)]\tClassification Loss: 1.4027\r\n",
      "Train Epoch: 3 [95680/110534 (87%)]\tClassification Loss: 1.4727\r\n",
      "Train Epoch: 3 [95840/110534 (87%)]\tClassification Loss: 0.9961\r\n",
      "Test() called at batch_idx: 6000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4310, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [96000/110534 (87%)]\tClassification Loss: 1.3731\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_6000.pth.tar\r\n",
      "Train Epoch: 3 [96160/110534 (87%)]\tClassification Loss: 1.6630\r\n",
      "Train Epoch: 3 [96320/110534 (87%)]\tClassification Loss: 1.4377\r\n",
      "Train Epoch: 3 [96480/110534 (87%)]\tClassification Loss: 1.1260\r\n",
      "Train Epoch: 3 [96640/110534 (87%)]\tClassification Loss: 1.0718\r\n",
      "Train Epoch: 3 [96800/110534 (88%)]\tClassification Loss: 1.6576\r\n",
      "Train Epoch: 3 [96960/110534 (88%)]\tClassification Loss: 1.1285\r\n",
      "Train Epoch: 3 [97120/110534 (88%)]\tClassification Loss: 1.7160\r\n",
      "Train Epoch: 3 [97280/110534 (88%)]\tClassification Loss: 1.2168\r\n",
      "Train Epoch: 3 [97440/110534 (88%)]\tClassification Loss: 1.8167\r\n",
      "Test() called at batch_idx: 6100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4365, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [97600/110534 (88%)]\tClassification Loss: 2.0830\r\n",
      "Train Epoch: 3 [97760/110534 (88%)]\tClassification Loss: 1.7969\r\n",
      "Train Epoch: 3 [97920/110534 (89%)]\tClassification Loss: 1.5529\r\n",
      "Train Epoch: 3 [98080/110534 (89%)]\tClassification Loss: 1.1283\r\n",
      "Train Epoch: 3 [98240/110534 (89%)]\tClassification Loss: 1.2739\r\n",
      "Train Epoch: 3 [98400/110534 (89%)]\tClassification Loss: 1.8034\r\n",
      "Train Epoch: 3 [98560/110534 (89%)]\tClassification Loss: 1.8030\r\n",
      "Train Epoch: 3 [98720/110534 (89%)]\tClassification Loss: 0.6458\r\n",
      "Train Epoch: 3 [98880/110534 (89%)]\tClassification Loss: 1.8411\r\n",
      "Train Epoch: 3 [99040/110534 (90%)]\tClassification Loss: 1.7861\r\n",
      "Test() called at batch_idx: 6200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4296, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [99200/110534 (90%)]\tClassification Loss: 1.8653\r\n",
      "Train Epoch: 3 [99360/110534 (90%)]\tClassification Loss: 1.4420\r\n",
      "Train Epoch: 3 [99520/110534 (90%)]\tClassification Loss: 2.1270\r\n",
      "Train Epoch: 3 [99680/110534 (90%)]\tClassification Loss: 1.0422\r\n",
      "Train Epoch: 3 [99840/110534 (90%)]\tClassification Loss: 1.9010\r\n",
      "Train Epoch: 3 [100000/110534 (90%)]\tClassification Loss: 2.0382\r\n",
      "Train Epoch: 3 [100160/110534 (91%)]\tClassification Loss: 2.4117\r\n",
      "Train Epoch: 3 [100320/110534 (91%)]\tClassification Loss: 1.3162\r\n",
      "Train Epoch: 3 [100480/110534 (91%)]\tClassification Loss: 1.9654\r\n",
      "Train Epoch: 3 [100640/110534 (91%)]\tClassification Loss: 1.7236\r\n",
      "Test() called at batch_idx: 6300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4259, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [100800/110534 (91%)]\tClassification Loss: 1.4397\r\n",
      "Train Epoch: 3 [100960/110534 (91%)]\tClassification Loss: 1.6951\r\n",
      "Train Epoch: 3 [101120/110534 (91%)]\tClassification Loss: 1.6178\r\n",
      "Train Epoch: 3 [101280/110534 (92%)]\tClassification Loss: 1.1609\r\n",
      "Train Epoch: 3 [101440/110534 (92%)]\tClassification Loss: 1.3429\r\n",
      "Train Epoch: 3 [101600/110534 (92%)]\tClassification Loss: 2.4373\r\n",
      "Train Epoch: 3 [101760/110534 (92%)]\tClassification Loss: 1.8296\r\n",
      "Train Epoch: 3 [101920/110534 (92%)]\tClassification Loss: 1.3894\r\n",
      "Train Epoch: 3 [102080/110534 (92%)]\tClassification Loss: 1.3300\r\n",
      "Train Epoch: 3 [102240/110534 (92%)]\tClassification Loss: 1.4173\r\n",
      "Test() called at batch_idx: 6400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4213, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [102400/110534 (93%)]\tClassification Loss: 1.7036\r\n",
      "Train Epoch: 3 [102560/110534 (93%)]\tClassification Loss: 1.7369\r\n",
      "Train Epoch: 3 [102720/110534 (93%)]\tClassification Loss: 2.0047\r\n",
      "Train Epoch: 3 [102880/110534 (93%)]\tClassification Loss: 1.6641\r\n",
      "Train Epoch: 3 [103040/110534 (93%)]\tClassification Loss: 1.2840\r\n",
      "Train Epoch: 3 [103200/110534 (93%)]\tClassification Loss: 1.1469\r\n",
      "Train Epoch: 3 [103360/110534 (94%)]\tClassification Loss: 1.6003\r\n",
      "Train Epoch: 3 [103520/110534 (94%)]\tClassification Loss: 2.1006\r\n",
      "Train Epoch: 3 [103680/110534 (94%)]\tClassification Loss: 1.4550\r\n",
      "Train Epoch: 3 [103840/110534 (94%)]\tClassification Loss: 1.5044\r\n",
      "Test() called at batch_idx: 6500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4439, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [104000/110534 (94%)]\tClassification Loss: 1.7989\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_6500.pth.tar\r\n",
      "Train Epoch: 3 [104160/110534 (94%)]\tClassification Loss: 1.7861\r\n",
      "Train Epoch: 3 [104320/110534 (94%)]\tClassification Loss: 1.9343\r\n",
      "Train Epoch: 3 [104480/110534 (95%)]\tClassification Loss: 1.3091\r\n",
      "Train Epoch: 3 [104640/110534 (95%)]\tClassification Loss: 1.6191\r\n",
      "Train Epoch: 3 [104800/110534 (95%)]\tClassification Loss: 1.2099\r\n",
      "Train Epoch: 3 [104960/110534 (95%)]\tClassification Loss: 1.2699\r\n",
      "Train Epoch: 3 [105120/110534 (95%)]\tClassification Loss: 1.2954\r\n",
      "Train Epoch: 3 [105280/110534 (95%)]\tClassification Loss: 1.6299\r\n",
      "Train Epoch: 3 [105440/110534 (95%)]\tClassification Loss: 1.4681\r\n",
      "Test() called at batch_idx: 6600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4421, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [105600/110534 (96%)]\tClassification Loss: 1.4995\r\n",
      "Train Epoch: 3 [105760/110534 (96%)]\tClassification Loss: 1.1102\r\n",
      "Train Epoch: 3 [105920/110534 (96%)]\tClassification Loss: 1.6315\r\n",
      "Train Epoch: 3 [106080/110534 (96%)]\tClassification Loss: 1.2889\r\n",
      "Train Epoch: 3 [106240/110534 (96%)]\tClassification Loss: 2.1501\r\n",
      "Train Epoch: 3 [106400/110534 (96%)]\tClassification Loss: 1.5604\r\n",
      "Train Epoch: 3 [106560/110534 (96%)]\tClassification Loss: 2.3438\r\n",
      "Train Epoch: 3 [106720/110534 (97%)]\tClassification Loss: 1.5675\r\n",
      "Train Epoch: 3 [106880/110534 (97%)]\tClassification Loss: 1.5212\r\n",
      "Train Epoch: 3 [107040/110534 (97%)]\tClassification Loss: 1.0624\r\n",
      "Test() called at batch_idx: 6700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4244, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [107200/110534 (97%)]\tClassification Loss: 1.2402\r\n",
      "Train Epoch: 3 [107360/110534 (97%)]\tClassification Loss: 1.6607\r\n",
      "Train Epoch: 3 [107520/110534 (97%)]\tClassification Loss: 1.6272\r\n",
      "Train Epoch: 3 [107680/110534 (97%)]\tClassification Loss: 1.7341\r\n",
      "Train Epoch: 3 [107840/110534 (98%)]\tClassification Loss: 1.2851\r\n",
      "Train Epoch: 3 [108000/110534 (98%)]\tClassification Loss: 1.2178\r\n",
      "Train Epoch: 3 [108160/110534 (98%)]\tClassification Loss: 1.4718\r\n",
      "Train Epoch: 3 [108320/110534 (98%)]\tClassification Loss: 1.6198\r\n",
      "Train Epoch: 3 [108480/110534 (98%)]\tClassification Loss: 1.2997\r\n",
      "Train Epoch: 3 [108640/110534 (98%)]\tClassification Loss: 1.4827\r\n",
      "Test() called at batch_idx: 6800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4254, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [108800/110534 (98%)]\tClassification Loss: 1.2115\r\n",
      "Train Epoch: 3 [108960/110534 (99%)]\tClassification Loss: 1.6051\r\n",
      "Train Epoch: 3 [109120/110534 (99%)]\tClassification Loss: 1.0497\r\n",
      "Train Epoch: 3 [109280/110534 (99%)]\tClassification Loss: 1.3427\r\n",
      "Train Epoch: 3 [109440/110534 (99%)]\tClassification Loss: 1.9437\r\n",
      "Train Epoch: 3 [109600/110534 (99%)]\tClassification Loss: 1.5485\r\n",
      "Train Epoch: 3 [109760/110534 (99%)]\tClassification Loss: 1.4035\r\n",
      "Train Epoch: 3 [109920/110534 (99%)]\tClassification Loss: 1.4017\r\n",
      "Train Epoch: 3 [110080/110534 (100%)]\tClassification Loss: 1.7751\r\n",
      "Train Epoch: 3 [110240/110534 (100%)]\tClassification Loss: 1.3345\r\n",
      "Test() called at batch_idx: 6900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4201, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [110400/110534 (100%)]\tClassification Loss: 1.1853\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_final.pth.tar\r\n",
      "Test() called at batch_idx: 0\r\n",
      "\r\n",
      "Test set: Average loss: 1.4214, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [0/110534 (0%)]\tClassification Loss: 1.3325\r\n",
      "Train Epoch: 4 [160/110534 (0%)]\tClassification Loss: 1.8467\r\n",
      "Train Epoch: 4 [320/110534 (0%)]\tClassification Loss: 1.6604\r\n",
      "Train Epoch: 4 [480/110534 (0%)]\tClassification Loss: 1.4771\r\n",
      "Train Epoch: 4 [640/110534 (1%)]\tClassification Loss: 1.8739\r\n",
      "Train Epoch: 4 [800/110534 (1%)]\tClassification Loss: 2.0523\r\n",
      "Train Epoch: 4 [960/110534 (1%)]\tClassification Loss: 1.1408\r\n",
      "Train Epoch: 4 [1120/110534 (1%)]\tClassification Loss: 1.1490\r\n",
      "Train Epoch: 4 [1280/110534 (1%)]\tClassification Loss: 1.6163\r\n",
      "Train Epoch: 4 [1440/110534 (1%)]\tClassification Loss: 1.7804\r\n",
      "Test() called at batch_idx: 100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4203, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [1600/110534 (1%)]\tClassification Loss: 1.2722\r\n",
      "Train Epoch: 4 [1760/110534 (2%)]\tClassification Loss: 1.5927\r\n",
      "Train Epoch: 4 [1920/110534 (2%)]\tClassification Loss: 1.9656\r\n",
      "Train Epoch: 4 [2080/110534 (2%)]\tClassification Loss: 1.5360\r\n",
      "Train Epoch: 4 [2240/110534 (2%)]\tClassification Loss: 1.7460\r\n",
      "Train Epoch: 4 [2400/110534 (2%)]\tClassification Loss: 1.4392\r\n",
      "Train Epoch: 4 [2560/110534 (2%)]\tClassification Loss: 2.1764\r\n",
      "Train Epoch: 4 [2720/110534 (2%)]\tClassification Loss: 1.5067\r\n",
      "Train Epoch: 4 [2880/110534 (3%)]\tClassification Loss: 1.6536\r\n",
      "Train Epoch: 4 [3040/110534 (3%)]\tClassification Loss: 1.6807\r\n",
      "Test() called at batch_idx: 200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4163, Accuracy: 308/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [3200/110534 (3%)]\tClassification Loss: 1.7043\r\n",
      "Train Epoch: 4 [3360/110534 (3%)]\tClassification Loss: 1.3240\r\n",
      "Train Epoch: 4 [3520/110534 (3%)]\tClassification Loss: 1.5096\r\n",
      "Train Epoch: 4 [3680/110534 (3%)]\tClassification Loss: 1.4967\r\n",
      "Train Epoch: 4 [3840/110534 (3%)]\tClassification Loss: 1.5226\r\n",
      "Train Epoch: 4 [4000/110534 (4%)]\tClassification Loss: 1.3822\r\n",
      "Train Epoch: 4 [4160/110534 (4%)]\tClassification Loss: 1.0773\r\n",
      "Train Epoch: 4 [4320/110534 (4%)]\tClassification Loss: 1.3225\r\n",
      "Train Epoch: 4 [4480/110534 (4%)]\tClassification Loss: 1.5988\r\n",
      "Train Epoch: 4 [4640/110534 (4%)]\tClassification Loss: 1.8448\r\n",
      "Test() called at batch_idx: 300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4209, Accuracy: 308/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [4800/110534 (4%)]\tClassification Loss: 1.5973\r\n",
      "Train Epoch: 4 [4960/110534 (4%)]\tClassification Loss: 1.9133\r\n",
      "Train Epoch: 4 [5120/110534 (5%)]\tClassification Loss: 1.0684\r\n",
      "Train Epoch: 4 [5280/110534 (5%)]\tClassification Loss: 1.8120\r\n",
      "Train Epoch: 4 [5440/110534 (5%)]\tClassification Loss: 1.5208\r\n",
      "Train Epoch: 4 [5600/110534 (5%)]\tClassification Loss: 1.5478\r\n",
      "Train Epoch: 4 [5760/110534 (5%)]\tClassification Loss: 1.6803\r\n",
      "Train Epoch: 4 [5920/110534 (5%)]\tClassification Loss: 2.1096\r\n",
      "Train Epoch: 4 [6080/110534 (6%)]\tClassification Loss: 1.6301\r\n",
      "Train Epoch: 4 [6240/110534 (6%)]\tClassification Loss: 1.9873\r\n",
      "Test() called at batch_idx: 400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4214, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [6400/110534 (6%)]\tClassification Loss: 1.2217\r\n",
      "Train Epoch: 4 [6560/110534 (6%)]\tClassification Loss: 1.5859\r\n",
      "Train Epoch: 4 [6720/110534 (6%)]\tClassification Loss: 2.2080\r\n",
      "Train Epoch: 4 [6880/110534 (6%)]\tClassification Loss: 1.3028\r\n",
      "Train Epoch: 4 [7040/110534 (6%)]\tClassification Loss: 1.1875\r\n",
      "Train Epoch: 4 [7200/110534 (7%)]\tClassification Loss: 1.3177\r\n",
      "Train Epoch: 4 [7360/110534 (7%)]\tClassification Loss: 1.7452\r\n",
      "Train Epoch: 4 [7520/110534 (7%)]\tClassification Loss: 2.5212\r\n",
      "Train Epoch: 4 [7680/110534 (7%)]\tClassification Loss: 1.5213\r\n",
      "Train Epoch: 4 [7840/110534 (7%)]\tClassification Loss: 1.8393\r\n",
      "Test() called at batch_idx: 500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4237, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [8000/110534 (7%)]\tClassification Loss: 1.5372\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_500.pth.tar\r\n",
      "Train Epoch: 4 [8160/110534 (7%)]\tClassification Loss: 2.0334\r\n",
      "Train Epoch: 4 [8320/110534 (8%)]\tClassification Loss: 1.6421\r\n",
      "Train Epoch: 4 [8480/110534 (8%)]\tClassification Loss: 0.9688\r\n",
      "Train Epoch: 4 [8640/110534 (8%)]\tClassification Loss: 1.8628\r\n",
      "Train Epoch: 4 [8800/110534 (8%)]\tClassification Loss: 1.6602\r\n",
      "Train Epoch: 4 [8960/110534 (8%)]\tClassification Loss: 1.6536\r\n",
      "Train Epoch: 4 [9120/110534 (8%)]\tClassification Loss: 0.9788\r\n",
      "Train Epoch: 4 [9280/110534 (8%)]\tClassification Loss: 1.7697\r\n",
      "Train Epoch: 4 [9440/110534 (9%)]\tClassification Loss: 1.7652\r\n",
      "Test() called at batch_idx: 600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4203, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [9600/110534 (9%)]\tClassification Loss: 1.2536\r\n",
      "Train Epoch: 4 [9760/110534 (9%)]\tClassification Loss: 1.9119\r\n",
      "Train Epoch: 4 [9920/110534 (9%)]\tClassification Loss: 1.9327\r\n",
      "Train Epoch: 4 [10080/110534 (9%)]\tClassification Loss: 1.1798\r\n",
      "Train Epoch: 4 [10240/110534 (9%)]\tClassification Loss: 2.3620\r\n",
      "Train Epoch: 4 [10400/110534 (9%)]\tClassification Loss: 1.5403\r\n",
      "Train Epoch: 4 [10560/110534 (10%)]\tClassification Loss: 1.4232\r\n",
      "Train Epoch: 4 [10720/110534 (10%)]\tClassification Loss: 1.6509\r\n",
      "Train Epoch: 4 [10880/110534 (10%)]\tClassification Loss: 1.2347\r\n",
      "Train Epoch: 4 [11040/110534 (10%)]\tClassification Loss: 1.2689\r\n",
      "Test() called at batch_idx: 700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4254, Accuracy: 306/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [11200/110534 (10%)]\tClassification Loss: 1.3087\r\n",
      "Train Epoch: 4 [11360/110534 (10%)]\tClassification Loss: 1.7060\r\n",
      "Train Epoch: 4 [11520/110534 (10%)]\tClassification Loss: 2.1195\r\n",
      "Train Epoch: 4 [11680/110534 (11%)]\tClassification Loss: 1.7486\r\n",
      "Train Epoch: 4 [11840/110534 (11%)]\tClassification Loss: 1.8649\r\n",
      "Train Epoch: 4 [12000/110534 (11%)]\tClassification Loss: 1.2989\r\n",
      "Train Epoch: 4 [12160/110534 (11%)]\tClassification Loss: 1.5121\r\n",
      "Train Epoch: 4 [12320/110534 (11%)]\tClassification Loss: 1.6532\r\n",
      "Train Epoch: 4 [12480/110534 (11%)]\tClassification Loss: 1.3987\r\n",
      "Train Epoch: 4 [12640/110534 (11%)]\tClassification Loss: 1.7209\r\n",
      "Test() called at batch_idx: 800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4129, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [12800/110534 (12%)]\tClassification Loss: 1.7709\r\n",
      "Train Epoch: 4 [12960/110534 (12%)]\tClassification Loss: 1.6433\r\n",
      "Train Epoch: 4 [13120/110534 (12%)]\tClassification Loss: 1.1039\r\n",
      "Train Epoch: 4 [13280/110534 (12%)]\tClassification Loss: 1.8900\r\n",
      "Train Epoch: 4 [13440/110534 (12%)]\tClassification Loss: 1.8469\r\n",
      "Train Epoch: 4 [13600/110534 (12%)]\tClassification Loss: 1.3699\r\n",
      "Train Epoch: 4 [13760/110534 (12%)]\tClassification Loss: 1.7685\r\n",
      "Train Epoch: 4 [13920/110534 (13%)]\tClassification Loss: 1.4605\r\n",
      "Train Epoch: 4 [14080/110534 (13%)]\tClassification Loss: 1.3535\r\n",
      "Train Epoch: 4 [14240/110534 (13%)]\tClassification Loss: 1.7235\r\n",
      "Test() called at batch_idx: 900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4180, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [14400/110534 (13%)]\tClassification Loss: 1.7051\r\n",
      "Train Epoch: 4 [14560/110534 (13%)]\tClassification Loss: 1.1492\r\n",
      "Train Epoch: 4 [14720/110534 (13%)]\tClassification Loss: 0.9934\r\n",
      "Train Epoch: 4 [14880/110534 (13%)]\tClassification Loss: 1.3116\r\n",
      "Train Epoch: 4 [15040/110534 (14%)]\tClassification Loss: 1.2748\r\n",
      "Train Epoch: 4 [15200/110534 (14%)]\tClassification Loss: 1.8411\r\n",
      "Train Epoch: 4 [15360/110534 (14%)]\tClassification Loss: 0.9863\r\n",
      "Train Epoch: 4 [15520/110534 (14%)]\tClassification Loss: 0.7464\r\n",
      "Train Epoch: 4 [15680/110534 (14%)]\tClassification Loss: 1.4150\r\n",
      "Train Epoch: 4 [15840/110534 (14%)]\tClassification Loss: 1.3851\r\n",
      "Test() called at batch_idx: 1000\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\r\n",
      "    self._send(header + buf)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\r\n",
      "    n = write(self._handle, buf)\r\n",
      "\r\n",
      "Test set: Average loss: 1.4170, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [16000/110534 (14%)]\tClassification Loss: 1.3648\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1000.pth.tar\r\n",
      "Train Epoch: 4 [16160/110534 (15%)]\tClassification Loss: 1.3646\r\n",
      "Train Epoch: 4 [16320/110534 (15%)]\tClassification Loss: 2.2077\r\n",
      "Train Epoch: 4 [16480/110534 (15%)]\tClassification Loss: 1.9472\r\n",
      "Train Epoch: 4 [16640/110534 (15%)]\tClassification Loss: 1.6047\r\n",
      "Train Epoch: 4 [16800/110534 (15%)]\tClassification Loss: 1.4809\r\n",
      "Train Epoch: 4 [16960/110534 (15%)]\tClassification Loss: 1.5103\r\n",
      "Train Epoch: 4 [17120/110534 (15%)]\tClassification Loss: 1.7957\r\n",
      "Train Epoch: 4 [17280/110534 (16%)]\tClassification Loss: 1.2493\r\n",
      "Train Epoch: 4 [17440/110534 (16%)]\tClassification Loss: 1.0052\r\n",
      "Test() called at batch_idx: 1100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4185, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [17600/110534 (16%)]\tClassification Loss: 1.7783\r\n",
      "Train Epoch: 4 [17760/110534 (16%)]\tClassification Loss: 1.6175\r\n",
      "Train Epoch: 4 [17920/110534 (16%)]\tClassification Loss: 1.2189\r\n",
      "Train Epoch: 4 [18080/110534 (16%)]\tClassification Loss: 1.3886\r\n",
      "Train Epoch: 4 [18240/110534 (17%)]\tClassification Loss: 1.7121\r\n",
      "Train Epoch: 4 [18400/110534 (17%)]\tClassification Loss: 1.6323\r\n",
      "Train Epoch: 4 [18560/110534 (17%)]\tClassification Loss: 1.8059\r\n",
      "Train Epoch: 4 [18720/110534 (17%)]\tClassification Loss: 1.9650\r\n",
      "Train Epoch: 4 [18880/110534 (17%)]\tClassification Loss: 1.7332\r\n",
      "Train Epoch: 4 [19040/110534 (17%)]\tClassification Loss: 1.7927\r\n",
      "Test() called at batch_idx: 1200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4224, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [19200/110534 (17%)]\tClassification Loss: 1.6610\r\n",
      "Train Epoch: 4 [19360/110534 (18%)]\tClassification Loss: 1.5154\r\n",
      "Train Epoch: 4 [19520/110534 (18%)]\tClassification Loss: 1.5456\r\n",
      "Train Epoch: 4 [19680/110534 (18%)]\tClassification Loss: 1.5205\r\n",
      "Train Epoch: 4 [19840/110534 (18%)]\tClassification Loss: 1.7342\r\n",
      "Train Epoch: 4 [20000/110534 (18%)]\tClassification Loss: 2.1652\r\n",
      "Train Epoch: 4 [20160/110534 (18%)]\tClassification Loss: 1.4231\r\n",
      "Train Epoch: 4 [20320/110534 (18%)]\tClassification Loss: 1.8128\r\n",
      "Train Epoch: 4 [20480/110534 (19%)]\tClassification Loss: 1.1284\r\n",
      "Train Epoch: 4 [20640/110534 (19%)]\tClassification Loss: 1.3676\r\n",
      "Test() called at batch_idx: 1300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4292, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [20800/110534 (19%)]\tClassification Loss: 1.6833\r\n",
      "Train Epoch: 4 [20960/110534 (19%)]\tClassification Loss: 1.0508\r\n",
      "Train Epoch: 4 [21120/110534 (19%)]\tClassification Loss: 1.3382\r\n",
      "Train Epoch: 4 [21280/110534 (19%)]\tClassification Loss: 1.1982\r\n",
      "Train Epoch: 4 [21440/110534 (19%)]\tClassification Loss: 1.4875\r\n",
      "Train Epoch: 4 [21600/110534 (20%)]\tClassification Loss: 1.4212\r\n",
      "Train Epoch: 4 [21760/110534 (20%)]\tClassification Loss: 1.3495\r\n",
      "Train Epoch: 4 [21920/110534 (20%)]\tClassification Loss: 1.7382\r\n",
      "Train Epoch: 4 [22080/110534 (20%)]\tClassification Loss: 1.5106\r\n",
      "Train Epoch: 4 [22240/110534 (20%)]\tClassification Loss: 1.3468\r\n",
      "Test() called at batch_idx: 1400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4301, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [22400/110534 (20%)]\tClassification Loss: 1.6350\r\n",
      "Train Epoch: 4 [22560/110534 (20%)]\tClassification Loss: 1.3744\r\n",
      "Train Epoch: 4 [22720/110534 (21%)]\tClassification Loss: 1.7335\r\n",
      "Train Epoch: 4 [22880/110534 (21%)]\tClassification Loss: 1.8723\r\n",
      "Train Epoch: 4 [23040/110534 (21%)]\tClassification Loss: 1.4129\r\n",
      "Train Epoch: 4 [23200/110534 (21%)]\tClassification Loss: 1.4569\r\n",
      "Train Epoch: 4 [23360/110534 (21%)]\tClassification Loss: 1.2374\r\n",
      "Train Epoch: 4 [23520/110534 (21%)]\tClassification Loss: 2.0055\r\n",
      "Train Epoch: 4 [23680/110534 (21%)]\tClassification Loss: 1.4595\r\n",
      "Train Epoch: 4 [23840/110534 (22%)]\tClassification Loss: 1.7581\r\n",
      "Test() called at batch_idx: 1500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4217, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [24000/110534 (22%)]\tClassification Loss: 1.9534\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1500.pth.tar\r\n",
      "Train Epoch: 4 [24160/110534 (22%)]\tClassification Loss: 1.4832\r\n",
      "Train Epoch: 4 [24320/110534 (22%)]\tClassification Loss: 1.3134\r\n",
      "Train Epoch: 4 [24480/110534 (22%)]\tClassification Loss: 2.0666\r\n",
      "Train Epoch: 4 [24640/110534 (22%)]\tClassification Loss: 1.5410\r\n",
      "Train Epoch: 4 [24800/110534 (22%)]\tClassification Loss: 1.4090\r\n",
      "Train Epoch: 4 [24960/110534 (23%)]\tClassification Loss: 1.5588\r\n",
      "Train Epoch: 4 [25120/110534 (23%)]\tClassification Loss: 1.3216\r\n",
      "Train Epoch: 4 [25280/110534 (23%)]\tClassification Loss: 1.1160\r\n",
      "Train Epoch: 4 [25440/110534 (23%)]\tClassification Loss: 2.1838\r\n",
      "Test() called at batch_idx: 1600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4180, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [25600/110534 (23%)]\tClassification Loss: 1.7940\r\n",
      "Train Epoch: 4 [25760/110534 (23%)]\tClassification Loss: 1.6465\r\n",
      "Train Epoch: 4 [25920/110534 (23%)]\tClassification Loss: 1.4533\r\n",
      "Train Epoch: 4 [26080/110534 (24%)]\tClassification Loss: 1.4242\r\n",
      "Train Epoch: 4 [26240/110534 (24%)]\tClassification Loss: 1.4235\r\n",
      "Train Epoch: 4 [26400/110534 (24%)]\tClassification Loss: 1.5061\r\n",
      "Train Epoch: 4 [26560/110534 (24%)]\tClassification Loss: 1.6897\r\n",
      "Train Epoch: 4 [26720/110534 (24%)]\tClassification Loss: 1.2047\r\n",
      "Train Epoch: 4 [26880/110534 (24%)]\tClassification Loss: 0.9170\r\n",
      "Train Epoch: 4 [27040/110534 (24%)]\tClassification Loss: 1.9297\r\n",
      "Test() called at batch_idx: 1700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4219, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [27200/110534 (25%)]\tClassification Loss: 1.3692\r\n",
      "Train Epoch: 4 [27360/110534 (25%)]\tClassification Loss: 1.7068\r\n",
      "Train Epoch: 4 [27520/110534 (25%)]\tClassification Loss: 1.1079\r\n",
      "Train Epoch: 4 [27680/110534 (25%)]\tClassification Loss: 1.8889\r\n",
      "Train Epoch: 4 [27840/110534 (25%)]\tClassification Loss: 1.3796\r\n",
      "Train Epoch: 4 [28000/110534 (25%)]\tClassification Loss: 1.2390\r\n",
      "Train Epoch: 4 [28160/110534 (25%)]\tClassification Loss: 1.4050\r\n",
      "Train Epoch: 4 [28320/110534 (26%)]\tClassification Loss: 1.2027\r\n",
      "Train Epoch: 4 [28480/110534 (26%)]\tClassification Loss: 1.0906\r\n",
      "Train Epoch: 4 [28640/110534 (26%)]\tClassification Loss: 2.4658\r\n",
      "Test() called at batch_idx: 1800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4176, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [28800/110534 (26%)]\tClassification Loss: 2.6908\r\n",
      "Train Epoch: 4 [28960/110534 (26%)]\tClassification Loss: 1.1403\r\n",
      "Train Epoch: 4 [29120/110534 (26%)]\tClassification Loss: 1.4191\r\n",
      "Train Epoch: 4 [29280/110534 (26%)]\tClassification Loss: 1.1763\r\n",
      "Train Epoch: 4 [29440/110534 (27%)]\tClassification Loss: 2.0186\r\n",
      "Train Epoch: 4 [29600/110534 (27%)]\tClassification Loss: 2.0478\r\n",
      "Train Epoch: 4 [29760/110534 (27%)]\tClassification Loss: 1.6067\r\n",
      "Train Epoch: 4 [29920/110534 (27%)]\tClassification Loss: 1.3583\r\n",
      "Train Epoch: 4 [30080/110534 (27%)]\tClassification Loss: 0.9096\r\n",
      "Train Epoch: 4 [30240/110534 (27%)]\tClassification Loss: 1.5206\r\n",
      "Test() called at batch_idx: 1900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4194, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [30400/110534 (28%)]\tClassification Loss: 1.1344\r\n",
      "Train Epoch: 4 [30560/110534 (28%)]\tClassification Loss: 1.8872\r\n",
      "Train Epoch: 4 [30720/110534 (28%)]\tClassification Loss: 1.8611\r\n",
      "Train Epoch: 4 [30880/110534 (28%)]\tClassification Loss: 2.1789\r\n",
      "Train Epoch: 4 [31040/110534 (28%)]\tClassification Loss: 1.0938\r\n",
      "Train Epoch: 4 [31200/110534 (28%)]\tClassification Loss: 1.7640\r\n",
      "Train Epoch: 4 [31360/110534 (28%)]\tClassification Loss: 1.2214\r\n",
      "Train Epoch: 4 [31520/110534 (29%)]\tClassification Loss: 1.6810\r\n",
      "Train Epoch: 4 [31680/110534 (29%)]\tClassification Loss: 1.7270\r\n",
      "Train Epoch: 4 [31840/110534 (29%)]\tClassification Loss: 1.5260\r\n",
      "Test() called at batch_idx: 2000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4173, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [32000/110534 (29%)]\tClassification Loss: 0.8949\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_2000.pth.tar\r\n",
      "Train Epoch: 4 [32160/110534 (29%)]\tClassification Loss: 1.7272\r\n",
      "Train Epoch: 4 [32320/110534 (29%)]\tClassification Loss: 1.8629\r\n",
      "Train Epoch: 4 [32480/110534 (29%)]\tClassification Loss: 1.1890\r\n",
      "Train Epoch: 4 [32640/110534 (30%)]\tClassification Loss: 1.1666\r\n",
      "Train Epoch: 4 [32800/110534 (30%)]\tClassification Loss: 1.1585\r\n",
      "Train Epoch: 4 [32960/110534 (30%)]\tClassification Loss: 1.8655\r\n",
      "Train Epoch: 4 [33120/110534 (30%)]\tClassification Loss: 1.6203\r\n",
      "Train Epoch: 4 [33280/110534 (30%)]\tClassification Loss: 1.1808\r\n",
      "Train Epoch: 4 [33440/110534 (30%)]\tClassification Loss: 1.3731\r\n",
      "Test() called at batch_idx: 2100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4321, Accuracy: 303/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [33600/110534 (30%)]\tClassification Loss: 1.5106\r\n",
      "Train Epoch: 4 [33760/110534 (31%)]\tClassification Loss: 1.2950\r\n",
      "Train Epoch: 4 [33920/110534 (31%)]\tClassification Loss: 1.1475\r\n",
      "Train Epoch: 4 [34080/110534 (31%)]\tClassification Loss: 0.9904\r\n",
      "Train Epoch: 4 [34240/110534 (31%)]\tClassification Loss: 1.7385\r\n",
      "Train Epoch: 4 [34400/110534 (31%)]\tClassification Loss: 1.4255\r\n",
      "Train Epoch: 4 [34560/110534 (31%)]\tClassification Loss: 1.3547\r\n",
      "Train Epoch: 4 [34720/110534 (31%)]\tClassification Loss: 2.2712\r\n",
      "Train Epoch: 4 [34880/110534 (32%)]\tClassification Loss: 1.7326\r\n",
      "Train Epoch: 4 [35040/110534 (32%)]\tClassification Loss: 1.0896\r\n",
      "Test() called at batch_idx: 2200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4103, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [35200/110534 (32%)]\tClassification Loss: 1.6408\r\n",
      "Train Epoch: 4 [35360/110534 (32%)]\tClassification Loss: 1.5058\r\n",
      "Train Epoch: 4 [35520/110534 (32%)]\tClassification Loss: 1.6147\r\n",
      "Train Epoch: 4 [35680/110534 (32%)]\tClassification Loss: 1.5027\r\n",
      "Train Epoch: 4 [35840/110534 (32%)]\tClassification Loss: 1.7097\r\n",
      "Train Epoch: 4 [36000/110534 (33%)]\tClassification Loss: 1.0856\r\n",
      "Train Epoch: 4 [36160/110534 (33%)]\tClassification Loss: 1.8662\r\n",
      "Train Epoch: 4 [36320/110534 (33%)]\tClassification Loss: 1.9492\r\n",
      "Train Epoch: 4 [36480/110534 (33%)]\tClassification Loss: 2.1938\r\n",
      "Train Epoch: 4 [36640/110534 (33%)]\tClassification Loss: 1.0541\r\n",
      "Test() called at batch_idx: 2300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4207, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [36800/110534 (33%)]\tClassification Loss: 1.5983\r\n",
      "Train Epoch: 4 [36960/110534 (33%)]\tClassification Loss: 1.4201\r\n",
      "Train Epoch: 4 [37120/110534 (34%)]\tClassification Loss: 1.4148\r\n",
      "Train Epoch: 4 [37280/110534 (34%)]\tClassification Loss: 2.1168\r\n",
      "Train Epoch: 4 [37440/110534 (34%)]\tClassification Loss: 1.8062\r\n",
      "Train Epoch: 4 [37600/110534 (34%)]\tClassification Loss: 1.6369\r\n",
      "Train Epoch: 4 [37760/110534 (34%)]\tClassification Loss: 2.1177\r\n",
      "Train Epoch: 4 [37920/110534 (34%)]\tClassification Loss: 2.3091\r\n",
      "Train Epoch: 4 [38080/110534 (34%)]\tClassification Loss: 1.4564\r\n",
      "Train Epoch: 4 [38240/110534 (35%)]\tClassification Loss: 1.3351\r\n",
      "Test() called at batch_idx: 2400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4093, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [38400/110534 (35%)]\tClassification Loss: 1.4532\r\n",
      "Train Epoch: 4 [38560/110534 (35%)]\tClassification Loss: 1.6732\r\n",
      "Train Epoch: 4 [38720/110534 (35%)]\tClassification Loss: 1.3521\r\n",
      "Train Epoch: 4 [38880/110534 (35%)]\tClassification Loss: 1.1686\r\n",
      "Train Epoch: 4 [39040/110534 (35%)]\tClassification Loss: 1.1630\r\n",
      "Train Epoch: 4 [39200/110534 (35%)]\tClassification Loss: 1.3664\r\n",
      "Train Epoch: 4 [39360/110534 (36%)]\tClassification Loss: 1.0810\r\n",
      "Train Epoch: 4 [39520/110534 (36%)]\tClassification Loss: 1.4349\r\n",
      "Train Epoch: 4 [39680/110534 (36%)]\tClassification Loss: 1.1649\r\n",
      "Train Epoch: 4 [39840/110534 (36%)]\tClassification Loss: 1.3179\r\n",
      "Test() called at batch_idx: 2500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4133, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [40000/110534 (36%)]\tClassification Loss: 1.0790\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_2500.pth.tar\r\n",
      "Train Epoch: 4 [40160/110534 (36%)]\tClassification Loss: 1.6363\r\n",
      "Train Epoch: 4 [40320/110534 (36%)]\tClassification Loss: 2.0784\r\n",
      "Train Epoch: 4 [40480/110534 (37%)]\tClassification Loss: 1.3116\r\n",
      "Train Epoch: 4 [40640/110534 (37%)]\tClassification Loss: 1.5948\r\n",
      "Train Epoch: 4 [40800/110534 (37%)]\tClassification Loss: 2.3071\r\n",
      "Train Epoch: 4 [40960/110534 (37%)]\tClassification Loss: 1.2458\r\n",
      "Train Epoch: 4 [41120/110534 (37%)]\tClassification Loss: 2.9017\r\n",
      "Train Epoch: 4 [41280/110534 (37%)]\tClassification Loss: 1.3245\r\n",
      "Train Epoch: 4 [41440/110534 (37%)]\tClassification Loss: 1.7084\r\n",
      "Test() called at batch_idx: 2600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4137, Accuracy: 303/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [41600/110534 (38%)]\tClassification Loss: 1.1592\r\n",
      "Train Epoch: 4 [41760/110534 (38%)]\tClassification Loss: 1.3342\r\n",
      "Train Epoch: 4 [41920/110534 (38%)]\tClassification Loss: 0.8741\r\n",
      "Train Epoch: 4 [42080/110534 (38%)]\tClassification Loss: 1.2484\r\n",
      "Train Epoch: 4 [42240/110534 (38%)]\tClassification Loss: 1.2164\r\n",
      "Train Epoch: 4 [42400/110534 (38%)]\tClassification Loss: 2.1285\r\n",
      "Train Epoch: 4 [42560/110534 (39%)]\tClassification Loss: 1.0873\r\n",
      "Train Epoch: 4 [42720/110534 (39%)]\tClassification Loss: 2.1490\r\n",
      "Train Epoch: 4 [42880/110534 (39%)]\tClassification Loss: 1.2791\r\n",
      "Train Epoch: 4 [43040/110534 (39%)]\tClassification Loss: 2.0076\r\n",
      "Test() called at batch_idx: 2700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4031, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [43200/110534 (39%)]\tClassification Loss: 1.2679\r\n",
      "Train Epoch: 4 [43360/110534 (39%)]\tClassification Loss: 2.0844\r\n",
      "Train Epoch: 4 [43520/110534 (39%)]\tClassification Loss: 1.1951\r\n",
      "Train Epoch: 4 [43680/110534 (40%)]\tClassification Loss: 1.2694\r\n",
      "Train Epoch: 4 [43840/110534 (40%)]\tClassification Loss: 1.7380\r\n",
      "Train Epoch: 4 [44000/110534 (40%)]\tClassification Loss: 1.4978\r\n",
      "Train Epoch: 4 [44160/110534 (40%)]\tClassification Loss: 1.3296\r\n",
      "Train Epoch: 4 [44320/110534 (40%)]\tClassification Loss: 1.4376\r\n",
      "Train Epoch: 4 [44480/110534 (40%)]\tClassification Loss: 1.5403\r\n",
      "Train Epoch: 4 [44640/110534 (40%)]\tClassification Loss: 1.1210\r\n",
      "Test() called at batch_idx: 2800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4108, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [44800/110534 (41%)]\tClassification Loss: 1.6131\r\n",
      "Train Epoch: 4 [44960/110534 (41%)]\tClassification Loss: 1.3754\r\n",
      "Train Epoch: 4 [45120/110534 (41%)]\tClassification Loss: 1.2325\r\n",
      "Train Epoch: 4 [45280/110534 (41%)]\tClassification Loss: 1.5548\r\n",
      "Train Epoch: 4 [45440/110534 (41%)]\tClassification Loss: 1.7815\r\n",
      "Train Epoch: 4 [45600/110534 (41%)]\tClassification Loss: 1.3942\r\n",
      "Train Epoch: 4 [45760/110534 (41%)]\tClassification Loss: 1.2496\r\n",
      "Train Epoch: 4 [45920/110534 (42%)]\tClassification Loss: 1.1945\r\n",
      "Train Epoch: 4 [46080/110534 (42%)]\tClassification Loss: 1.5077\r\n",
      "Train Epoch: 4 [46240/110534 (42%)]\tClassification Loss: 1.2785\r\n",
      "Test() called at batch_idx: 2900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4061, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [46400/110534 (42%)]\tClassification Loss: 1.5822\r\n",
      "Train Epoch: 4 [46560/110534 (42%)]\tClassification Loss: 2.1921\r\n",
      "Train Epoch: 4 [46720/110534 (42%)]\tClassification Loss: 1.6197\r\n",
      "Train Epoch: 4 [46880/110534 (42%)]\tClassification Loss: 1.5219\r\n",
      "Train Epoch: 4 [47040/110534 (43%)]\tClassification Loss: 2.0953\r\n",
      "Train Epoch: 4 [47200/110534 (43%)]\tClassification Loss: 1.2027\r\n",
      "Train Epoch: 4 [47360/110534 (43%)]\tClassification Loss: 1.8936\r\n",
      "Train Epoch: 4 [47520/110534 (43%)]\tClassification Loss: 1.8570\r\n",
      "Train Epoch: 4 [47680/110534 (43%)]\tClassification Loss: 1.2260\r\n",
      "Train Epoch: 4 [47840/110534 (43%)]\tClassification Loss: 1.6712\r\n",
      "Test() called at batch_idx: 3000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4161, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [48000/110534 (43%)]\tClassification Loss: 1.1326\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_3000.pth.tar\r\n",
      "Train Epoch: 4 [48160/110534 (44%)]\tClassification Loss: 1.5956\r\n",
      "Train Epoch: 4 [48320/110534 (44%)]\tClassification Loss: 1.7890\r\n",
      "Train Epoch: 4 [48480/110534 (44%)]\tClassification Loss: 1.9773\r\n",
      "Train Epoch: 4 [48640/110534 (44%)]\tClassification Loss: 1.5262\r\n",
      "Train Epoch: 4 [48800/110534 (44%)]\tClassification Loss: 1.4164\r\n",
      "Train Epoch: 4 [48960/110534 (44%)]\tClassification Loss: 1.9111\r\n",
      "Train Epoch: 4 [49120/110534 (44%)]\tClassification Loss: 2.0636\r\n",
      "Train Epoch: 4 [49280/110534 (45%)]\tClassification Loss: 1.2034\r\n",
      "Train Epoch: 4 [49440/110534 (45%)]\tClassification Loss: 1.3648\r\n",
      "Test() called at batch_idx: 3100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4075, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [49600/110534 (45%)]\tClassification Loss: 1.9172\r\n",
      "Train Epoch: 4 [49760/110534 (45%)]\tClassification Loss: 1.2914\r\n",
      "Train Epoch: 4 [49920/110534 (45%)]\tClassification Loss: 1.4084\r\n",
      "Train Epoch: 4 [50080/110534 (45%)]\tClassification Loss: 1.9236\r\n",
      "Train Epoch: 4 [50240/110534 (45%)]\tClassification Loss: 1.3566\r\n",
      "Train Epoch: 4 [50400/110534 (46%)]\tClassification Loss: 1.0581\r\n",
      "Train Epoch: 4 [50560/110534 (46%)]\tClassification Loss: 1.2814\r\n",
      "Train Epoch: 4 [50720/110534 (46%)]\tClassification Loss: 1.6252\r\n",
      "Train Epoch: 4 [50880/110534 (46%)]\tClassification Loss: 1.3716\r\n",
      "Train Epoch: 4 [51040/110534 (46%)]\tClassification Loss: 1.7923\r\n",
      "Test() called at batch_idx: 3200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4240, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [51200/110534 (46%)]\tClassification Loss: 1.5128\r\n",
      "Train Epoch: 4 [51360/110534 (46%)]\tClassification Loss: 1.5919\r\n",
      "Train Epoch: 4 [51520/110534 (47%)]\tClassification Loss: 2.0632\r\n",
      "Train Epoch: 4 [51680/110534 (47%)]\tClassification Loss: 2.2068\r\n",
      "Train Epoch: 4 [51840/110534 (47%)]\tClassification Loss: 2.6946\r\n",
      "Train Epoch: 4 [52000/110534 (47%)]\tClassification Loss: 1.3703\r\n",
      "Train Epoch: 4 [52160/110534 (47%)]\tClassification Loss: 1.0288\r\n",
      "Train Epoch: 4 [52320/110534 (47%)]\tClassification Loss: 1.6980\r\n",
      "Train Epoch: 4 [52480/110534 (47%)]\tClassification Loss: 1.9553\r\n",
      "Train Epoch: 4 [52640/110534 (48%)]\tClassification Loss: 1.5642\r\n",
      "Test() called at batch_idx: 3300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4138, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [52800/110534 (48%)]\tClassification Loss: 1.5332\r\n",
      "Train Epoch: 4 [52960/110534 (48%)]\tClassification Loss: 1.1645\r\n",
      "Train Epoch: 4 [53120/110534 (48%)]\tClassification Loss: 1.5418\r\n",
      "Train Epoch: 4 [53280/110534 (48%)]\tClassification Loss: 1.5330\r\n",
      "Train Epoch: 4 [53440/110534 (48%)]\tClassification Loss: 1.8220\r\n",
      "Train Epoch: 4 [53600/110534 (48%)]\tClassification Loss: 1.0452\r\n",
      "Train Epoch: 4 [53760/110534 (49%)]\tClassification Loss: 1.8048\r\n",
      "Train Epoch: 4 [53920/110534 (49%)]\tClassification Loss: 1.5527\r\n",
      "Train Epoch: 4 [54080/110534 (49%)]\tClassification Loss: 1.5653\r\n",
      "Train Epoch: 4 [54240/110534 (49%)]\tClassification Loss: 1.7345\r\n",
      "Test() called at batch_idx: 3400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4137, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [54400/110534 (49%)]\tClassification Loss: 1.6375\r\n",
      "Train Epoch: 4 [54560/110534 (49%)]\tClassification Loss: 1.3852\r\n",
      "Train Epoch: 4 [54720/110534 (50%)]\tClassification Loss: 1.4220\r\n",
      "Train Epoch: 4 [54880/110534 (50%)]\tClassification Loss: 1.4716\r\n",
      "Train Epoch: 4 [55040/110534 (50%)]\tClassification Loss: 1.2191\r\n",
      "Train Epoch: 4 [55200/110534 (50%)]\tClassification Loss: 1.4928\r\n",
      "Train Epoch: 4 [55360/110534 (50%)]\tClassification Loss: 1.7317\r\n",
      "Train Epoch: 4 [55520/110534 (50%)]\tClassification Loss: 1.7928\r\n",
      "Train Epoch: 4 [55680/110534 (50%)]\tClassification Loss: 1.5170\r\n",
      "Train Epoch: 4 [55840/110534 (51%)]\tClassification Loss: 2.0352\r\n",
      "Test() called at batch_idx: 3500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4031, Accuracy: 308/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [56000/110534 (51%)]\tClassification Loss: 1.0440\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_3500.pth.tar\r\n",
      "Train Epoch: 4 [56160/110534 (51%)]\tClassification Loss: 0.8143\r\n",
      "Train Epoch: 4 [56320/110534 (51%)]\tClassification Loss: 1.3813\r\n",
      "Train Epoch: 4 [56480/110534 (51%)]\tClassification Loss: 1.5108\r\n",
      "Train Epoch: 4 [56640/110534 (51%)]\tClassification Loss: 1.1823\r\n",
      "Train Epoch: 4 [56800/110534 (51%)]\tClassification Loss: 1.3683\r\n",
      "Train Epoch: 4 [56960/110534 (52%)]\tClassification Loss: 0.8410\r\n",
      "Train Epoch: 4 [57120/110534 (52%)]\tClassification Loss: 1.7330\r\n",
      "Train Epoch: 4 [57280/110534 (52%)]\tClassification Loss: 1.5592\r\n",
      "Train Epoch: 4 [57440/110534 (52%)]\tClassification Loss: 1.5531\r\n",
      "Test() called at batch_idx: 3600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4200, Accuracy: 308/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [57600/110534 (52%)]\tClassification Loss: 1.6588\r\n",
      "Train Epoch: 4 [57760/110534 (52%)]\tClassification Loss: 1.3412\r\n",
      "Train Epoch: 4 [57920/110534 (52%)]\tClassification Loss: 1.5157\r\n",
      "Train Epoch: 4 [58080/110534 (53%)]\tClassification Loss: 1.7219\r\n",
      "Train Epoch: 4 [58240/110534 (53%)]\tClassification Loss: 1.1502\r\n",
      "Train Epoch: 4 [58400/110534 (53%)]\tClassification Loss: 1.7898\r\n",
      "Train Epoch: 4 [58560/110534 (53%)]\tClassification Loss: 1.8679\r\n",
      "Train Epoch: 4 [58720/110534 (53%)]\tClassification Loss: 1.5654\r\n",
      "Train Epoch: 4 [58880/110534 (53%)]\tClassification Loss: 2.0233\r\n",
      "Train Epoch: 4 [59040/110534 (53%)]\tClassification Loss: 1.9660\r\n",
      "Test() called at batch_idx: 3700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4113, Accuracy: 307/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [59200/110534 (54%)]\tClassification Loss: 1.3025\r\n",
      "Train Epoch: 4 [59360/110534 (54%)]\tClassification Loss: 1.0886\r\n",
      "Train Epoch: 4 [59520/110534 (54%)]\tClassification Loss: 2.1218\r\n",
      "Train Epoch: 4 [59680/110534 (54%)]\tClassification Loss: 1.9289\r\n",
      "Train Epoch: 4 [59840/110534 (54%)]\tClassification Loss: 1.3951\r\n",
      "Train Epoch: 4 [60000/110534 (54%)]\tClassification Loss: 1.4022\r\n",
      "Train Epoch: 4 [60160/110534 (54%)]\tClassification Loss: 1.9611\r\n",
      "Train Epoch: 4 [60320/110534 (55%)]\tClassification Loss: 1.8827\r\n",
      "Train Epoch: 4 [60480/110534 (55%)]\tClassification Loss: 1.2967\r\n",
      "Train Epoch: 4 [60640/110534 (55%)]\tClassification Loss: 1.4020\r\n",
      "Test() called at batch_idx: 3800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4383, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [60800/110534 (55%)]\tClassification Loss: 1.3930\r\n",
      "Train Epoch: 4 [60960/110534 (55%)]\tClassification Loss: 1.5263\r\n",
      "Train Epoch: 4 [61120/110534 (55%)]\tClassification Loss: 1.6456\r\n",
      "Train Epoch: 4 [61280/110534 (55%)]\tClassification Loss: 1.6182\r\n",
      "Train Epoch: 4 [61440/110534 (56%)]\tClassification Loss: 1.5813\r\n",
      "Train Epoch: 4 [61600/110534 (56%)]\tClassification Loss: 1.1575\r\n",
      "Train Epoch: 4 [61760/110534 (56%)]\tClassification Loss: 1.1251\r\n",
      "Train Epoch: 4 [61920/110534 (56%)]\tClassification Loss: 1.7175\r\n",
      "Train Epoch: 4 [62080/110534 (56%)]\tClassification Loss: 1.1512\r\n",
      "Train Epoch: 4 [62240/110534 (56%)]\tClassification Loss: 1.1266\r\n",
      "Test() called at batch_idx: 3900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4086, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [62400/110534 (56%)]\tClassification Loss: 1.4331\r\n",
      "Train Epoch: 4 [62560/110534 (57%)]\tClassification Loss: 1.2836\r\n",
      "Train Epoch: 4 [62720/110534 (57%)]\tClassification Loss: 1.5444\r\n",
      "Train Epoch: 4 [62880/110534 (57%)]\tClassification Loss: 1.4865\r\n",
      "Train Epoch: 4 [63040/110534 (57%)]\tClassification Loss: 1.5045\r\n",
      "Train Epoch: 4 [63200/110534 (57%)]\tClassification Loss: 2.0207\r\n",
      "Train Epoch: 4 [63360/110534 (57%)]\tClassification Loss: 1.4869\r\n",
      "Train Epoch: 4 [63520/110534 (57%)]\tClassification Loss: 1.0081\r\n",
      "Train Epoch: 4 [63680/110534 (58%)]\tClassification Loss: 2.0774\r\n",
      "Train Epoch: 4 [63840/110534 (58%)]\tClassification Loss: 0.9848\r\n",
      "Test() called at batch_idx: 4000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4131, Accuracy: 303/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [64000/110534 (58%)]\tClassification Loss: 1.3757\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_4000.pth.tar\r\n",
      "Train Epoch: 4 [64160/110534 (58%)]\tClassification Loss: 1.6850\r\n",
      "Train Epoch: 4 [64320/110534 (58%)]\tClassification Loss: 1.4911\r\n",
      "Train Epoch: 4 [64480/110534 (58%)]\tClassification Loss: 1.2739\r\n",
      "Train Epoch: 4 [64640/110534 (58%)]\tClassification Loss: 1.3957\r\n",
      "Train Epoch: 4 [64800/110534 (59%)]\tClassification Loss: 1.2393\r\n",
      "Train Epoch: 4 [64960/110534 (59%)]\tClassification Loss: 1.2280\r\n",
      "Train Epoch: 4 [65120/110534 (59%)]\tClassification Loss: 1.3016\r\n",
      "Train Epoch: 4 [65280/110534 (59%)]\tClassification Loss: 1.6553\r\n",
      "Train Epoch: 4 [65440/110534 (59%)]\tClassification Loss: 1.6402\r\n",
      "Test() called at batch_idx: 4100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4095, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [65600/110534 (59%)]\tClassification Loss: 1.3382\r\n",
      "Train Epoch: 4 [65760/110534 (59%)]\tClassification Loss: 1.3096\r\n",
      "Train Epoch: 4 [65920/110534 (60%)]\tClassification Loss: 1.0688\r\n",
      "Train Epoch: 4 [66080/110534 (60%)]\tClassification Loss: 1.3148\r\n",
      "Train Epoch: 4 [66240/110534 (60%)]\tClassification Loss: 2.0674\r\n",
      "Train Epoch: 4 [66400/110534 (60%)]\tClassification Loss: 2.4022\r\n",
      "Train Epoch: 4 [66560/110534 (60%)]\tClassification Loss: 1.4275\r\n",
      "Train Epoch: 4 [66720/110534 (60%)]\tClassification Loss: 1.5733\r\n",
      "Train Epoch: 4 [66880/110534 (61%)]\tClassification Loss: 1.3204\r\n",
      "Train Epoch: 4 [67040/110534 (61%)]\tClassification Loss: 0.8314\r\n",
      "Test() called at batch_idx: 4200\r\n",
      "\r\n",
      "Test set: Average loss: 1.3995, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [67200/110534 (61%)]\tClassification Loss: 2.4467\r\n",
      "Train Epoch: 4 [67360/110534 (61%)]\tClassification Loss: 1.7679\r\n",
      "Train Epoch: 4 [67520/110534 (61%)]\tClassification Loss: 1.3367\r\n",
      "Train Epoch: 4 [67680/110534 (61%)]\tClassification Loss: 1.1389\r\n",
      "Train Epoch: 4 [67840/110534 (61%)]\tClassification Loss: 1.3875\r\n",
      "Train Epoch: 4 [68000/110534 (62%)]\tClassification Loss: 1.6011\r\n",
      "Train Epoch: 4 [68160/110534 (62%)]\tClassification Loss: 1.4018\r\n",
      "Train Epoch: 4 [68320/110534 (62%)]\tClassification Loss: 1.6638\r\n",
      "Train Epoch: 4 [68480/110534 (62%)]\tClassification Loss: 1.0277\r\n",
      "Train Epoch: 4 [68640/110534 (62%)]\tClassification Loss: 2.0610\r\n",
      "Test() called at batch_idx: 4300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4217, Accuracy: 311/480 (65%)\r\n",
      "\r\n",
      "Train Epoch: 4 [68800/110534 (62%)]\tClassification Loss: 1.6743\r\n",
      "Train Epoch: 4 [68960/110534 (62%)]\tClassification Loss: 1.0810\r\n",
      "Train Epoch: 4 [69120/110534 (63%)]\tClassification Loss: 0.9499\r\n",
      "Train Epoch: 4 [69280/110534 (63%)]\tClassification Loss: 2.0277\r\n",
      "Train Epoch: 4 [69440/110534 (63%)]\tClassification Loss: 2.2880\r\n",
      "Train Epoch: 4 [69600/110534 (63%)]\tClassification Loss: 1.2972\r\n",
      "Train Epoch: 4 [69760/110534 (63%)]\tClassification Loss: 1.8074\r\n",
      "Train Epoch: 4 [69920/110534 (63%)]\tClassification Loss: 1.1478\r\n",
      "Train Epoch: 4 [70080/110534 (63%)]\tClassification Loss: 1.7007\r\n",
      "Train Epoch: 4 [70240/110534 (64%)]\tClassification Loss: 1.6984\r\n",
      "Test() called at batch_idx: 4400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4086, Accuracy: 306/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [70400/110534 (64%)]\tClassification Loss: 2.1221\r\n",
      "Train Epoch: 4 [70560/110534 (64%)]\tClassification Loss: 1.0233\r\n",
      "Train Epoch: 4 [70720/110534 (64%)]\tClassification Loss: 1.2911\r\n",
      "Train Epoch: 4 [70880/110534 (64%)]\tClassification Loss: 1.7681\r\n",
      "Train Epoch: 4 [71040/110534 (64%)]\tClassification Loss: 1.3846\r\n",
      "Train Epoch: 4 [71200/110534 (64%)]\tClassification Loss: 1.4922\r\n",
      "Train Epoch: 4 [71360/110534 (65%)]\tClassification Loss: 1.7908\r\n",
      "Train Epoch: 4 [71520/110534 (65%)]\tClassification Loss: 1.3944\r\n",
      "Train Epoch: 4 [71680/110534 (65%)]\tClassification Loss: 1.5520\r\n",
      "Train Epoch: 4 [71840/110534 (65%)]\tClassification Loss: 1.2550\r\n",
      "Test() called at batch_idx: 4500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4152, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [72000/110534 (65%)]\tClassification Loss: 1.2935\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_4500.pth.tar\r\n",
      "Train Epoch: 4 [72160/110534 (65%)]\tClassification Loss: 1.4058\r\n",
      "Train Epoch: 4 [72320/110534 (65%)]\tClassification Loss: 1.2813\r\n",
      "Train Epoch: 4 [72480/110534 (66%)]\tClassification Loss: 1.6048\r\n",
      "Train Epoch: 4 [72640/110534 (66%)]\tClassification Loss: 1.8529\r\n",
      "Train Epoch: 4 [72800/110534 (66%)]\tClassification Loss: 1.8259\r\n",
      "Train Epoch: 4 [72960/110534 (66%)]\tClassification Loss: 1.5187\r\n",
      "Train Epoch: 4 [73120/110534 (66%)]\tClassification Loss: 1.3853\r\n",
      "Train Epoch: 4 [73280/110534 (66%)]\tClassification Loss: 1.5185\r\n",
      "Train Epoch: 4 [73440/110534 (66%)]\tClassification Loss: 1.8808\r\n",
      "Test() called at batch_idx: 4600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4092, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [73600/110534 (67%)]\tClassification Loss: 1.4427\r\n",
      "Train Epoch: 4 [73760/110534 (67%)]\tClassification Loss: 2.0472\r\n",
      "Train Epoch: 4 [73920/110534 (67%)]\tClassification Loss: 2.3285\r\n",
      "Train Epoch: 4 [74080/110534 (67%)]\tClassification Loss: 1.7737\r\n",
      "Train Epoch: 4 [74240/110534 (67%)]\tClassification Loss: 1.4916\r\n",
      "Train Epoch: 4 [74400/110534 (67%)]\tClassification Loss: 1.9460\r\n",
      "Train Epoch: 4 [74560/110534 (67%)]\tClassification Loss: 1.3774\r\n",
      "Train Epoch: 4 [74720/110534 (68%)]\tClassification Loss: 1.1721\r\n",
      "Train Epoch: 4 [74880/110534 (68%)]\tClassification Loss: 1.7488\r\n",
      "Train Epoch: 4 [75040/110534 (68%)]\tClassification Loss: 1.2040\r\n",
      "Test() called at batch_idx: 4700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4021, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [75200/110534 (68%)]\tClassification Loss: 0.8842\r\n",
      "Train Epoch: 4 [75360/110534 (68%)]\tClassification Loss: 1.6936\r\n",
      "Train Epoch: 4 [75520/110534 (68%)]\tClassification Loss: 1.4863\r\n",
      "Train Epoch: 4 [75680/110534 (68%)]\tClassification Loss: 1.6962\r\n",
      "Train Epoch: 4 [75840/110534 (69%)]\tClassification Loss: 0.9325\r\n",
      "Train Epoch: 4 [76000/110534 (69%)]\tClassification Loss: 1.4929\r\n",
      "Train Epoch: 4 [76160/110534 (69%)]\tClassification Loss: 1.7733\r\n",
      "Train Epoch: 4 [76320/110534 (69%)]\tClassification Loss: 1.2265\r\n",
      "Train Epoch: 4 [76480/110534 (69%)]\tClassification Loss: 2.3346\r\n",
      "Train Epoch: 4 [76640/110534 (69%)]\tClassification Loss: 1.0613\r\n",
      "Test() called at batch_idx: 4800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4264, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [76800/110534 (69%)]\tClassification Loss: 2.1082\r\n",
      "Train Epoch: 4 [76960/110534 (70%)]\tClassification Loss: 1.5938\r\n",
      "Train Epoch: 4 [77120/110534 (70%)]\tClassification Loss: 1.6113\r\n",
      "Train Epoch: 4 [77280/110534 (70%)]\tClassification Loss: 1.5060\r\n",
      "Train Epoch: 4 [77440/110534 (70%)]\tClassification Loss: 1.4469\r\n",
      "Train Epoch: 4 [77600/110534 (70%)]\tClassification Loss: 1.6771\r\n",
      "Train Epoch: 4 [77760/110534 (70%)]\tClassification Loss: 1.4511\r\n",
      "Train Epoch: 4 [77920/110534 (70%)]\tClassification Loss: 1.1848\r\n",
      "Train Epoch: 4 [78080/110534 (71%)]\tClassification Loss: 1.5397\r\n",
      "Train Epoch: 4 [78240/110534 (71%)]\tClassification Loss: 1.3916\r\n",
      "Test() called at batch_idx: 4900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4053, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [78400/110534 (71%)]\tClassification Loss: 1.5531\r\n",
      "Train Epoch: 4 [78560/110534 (71%)]\tClassification Loss: 1.4581\r\n",
      "Train Epoch: 4 [78720/110534 (71%)]\tClassification Loss: 1.9014\r\n",
      "Train Epoch: 4 [78880/110534 (71%)]\tClassification Loss: 1.4032\r\n",
      "Train Epoch: 4 [79040/110534 (72%)]\tClassification Loss: 1.5737\r\n",
      "Train Epoch: 4 [79200/110534 (72%)]\tClassification Loss: 1.2171\r\n",
      "Train Epoch: 4 [79360/110534 (72%)]\tClassification Loss: 1.0267\r\n",
      "Train Epoch: 4 [79520/110534 (72%)]\tClassification Loss: 1.7143\r\n",
      "Train Epoch: 4 [79680/110534 (72%)]\tClassification Loss: 1.9159\r\n",
      "Train Epoch: 4 [79840/110534 (72%)]\tClassification Loss: 1.6125\r\n",
      "Test() called at batch_idx: 5000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4069, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [80000/110534 (72%)]\tClassification Loss: 1.2088\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_5000.pth.tar\r\n",
      "Train Epoch: 4 [80160/110534 (73%)]\tClassification Loss: 1.4035\r\n",
      "Train Epoch: 4 [80320/110534 (73%)]\tClassification Loss: 1.6815\r\n",
      "Train Epoch: 4 [80480/110534 (73%)]\tClassification Loss: 1.1831\r\n",
      "Train Epoch: 4 [80640/110534 (73%)]\tClassification Loss: 1.7169\r\n",
      "Train Epoch: 4 [80800/110534 (73%)]\tClassification Loss: 1.5544\r\n",
      "Train Epoch: 4 [80960/110534 (73%)]\tClassification Loss: 2.0331\r\n",
      "Train Epoch: 4 [81120/110534 (73%)]\tClassification Loss: 1.6324\r\n",
      "Train Epoch: 4 [81280/110534 (74%)]\tClassification Loss: 2.1538\r\n",
      "Train Epoch: 4 [81440/110534 (74%)]\tClassification Loss: 1.7397\r\n",
      "Test() called at batch_idx: 5100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4048, Accuracy: 310/480 (65%)\r\n",
      "\r\n",
      "Train Epoch: 4 [81600/110534 (74%)]\tClassification Loss: 1.3042\r\n",
      "Train Epoch: 4 [81760/110534 (74%)]\tClassification Loss: 1.9698\r\n",
      "Train Epoch: 4 [81920/110534 (74%)]\tClassification Loss: 2.2512\r\n",
      "Train Epoch: 4 [82080/110534 (74%)]\tClassification Loss: 1.6262\r\n",
      "Train Epoch: 4 [82240/110534 (74%)]\tClassification Loss: 1.3919\r\n",
      "Train Epoch: 4 [82400/110534 (75%)]\tClassification Loss: 1.2989\r\n",
      "Train Epoch: 4 [82560/110534 (75%)]\tClassification Loss: 1.2384\r\n",
      "Train Epoch: 4 [82720/110534 (75%)]\tClassification Loss: 1.4641\r\n",
      "Train Epoch: 4 [82880/110534 (75%)]\tClassification Loss: 1.6317\r\n",
      "Train Epoch: 4 [83040/110534 (75%)]\tClassification Loss: 1.7795\r\n",
      "Test() called at batch_idx: 5200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4073, Accuracy: 308/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [83200/110534 (75%)]\tClassification Loss: 1.2548\r\n",
      "Train Epoch: 4 [83360/110534 (75%)]\tClassification Loss: 0.9460\r\n",
      "Train Epoch: 4 [83520/110534 (76%)]\tClassification Loss: 2.0470\r\n",
      "Train Epoch: 4 [83680/110534 (76%)]\tClassification Loss: 1.7674\r\n",
      "Train Epoch: 4 [83840/110534 (76%)]\tClassification Loss: 1.5411\r\n",
      "Train Epoch: 4 [84000/110534 (76%)]\tClassification Loss: 1.8154\r\n",
      "Train Epoch: 4 [84160/110534 (76%)]\tClassification Loss: 1.6501\r\n",
      "Train Epoch: 4 [84320/110534 (76%)]\tClassification Loss: 1.6427\r\n",
      "Train Epoch: 4 [84480/110534 (76%)]\tClassification Loss: 1.8278\r\n",
      "Train Epoch: 4 [84640/110534 (77%)]\tClassification Loss: 2.3067\r\n",
      "Test() called at batch_idx: 5300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4066, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [84800/110534 (77%)]\tClassification Loss: 1.5244\r\n",
      "Train Epoch: 4 [84960/110534 (77%)]\tClassification Loss: 2.0461\r\n",
      "Train Epoch: 4 [85120/110534 (77%)]\tClassification Loss: 1.8383\r\n",
      "Train Epoch: 4 [85280/110534 (77%)]\tClassification Loss: 1.7762\r\n",
      "Train Epoch: 4 [85440/110534 (77%)]\tClassification Loss: 1.7783\r\n",
      "Train Epoch: 4 [85600/110534 (77%)]\tClassification Loss: 1.4149\r\n",
      "Train Epoch: 4 [85760/110534 (78%)]\tClassification Loss: 2.8360\r\n",
      "Train Epoch: 4 [85920/110534 (78%)]\tClassification Loss: 1.2985\r\n",
      "Train Epoch: 4 [86080/110534 (78%)]\tClassification Loss: 1.3561\r\n",
      "Train Epoch: 4 [86240/110534 (78%)]\tClassification Loss: 1.3377\r\n",
      "Test() called at batch_idx: 5400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4051, Accuracy: 306/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [86400/110534 (78%)]\tClassification Loss: 1.2585\r\n",
      "Train Epoch: 4 [86560/110534 (78%)]\tClassification Loss: 1.5375\r\n",
      "Train Epoch: 4 [86720/110534 (78%)]\tClassification Loss: 1.4671\r\n",
      "Train Epoch: 4 [86880/110534 (79%)]\tClassification Loss: 1.2008\r\n",
      "Train Epoch: 4 [87040/110534 (79%)]\tClassification Loss: 1.3694\r\n",
      "Train Epoch: 4 [87200/110534 (79%)]\tClassification Loss: 1.9551\r\n",
      "Train Epoch: 4 [87360/110534 (79%)]\tClassification Loss: 1.4398\r\n",
      "Train Epoch: 4 [87520/110534 (79%)]\tClassification Loss: 1.2025\r\n",
      "Train Epoch: 4 [87680/110534 (79%)]\tClassification Loss: 1.0490\r\n",
      "Train Epoch: 4 [87840/110534 (79%)]\tClassification Loss: 1.9396\r\n",
      "Test() called at batch_idx: 5500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4086, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [88000/110534 (80%)]\tClassification Loss: 1.3212\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_5500.pth.tar\r\n",
      "Train Epoch: 4 [88160/110534 (80%)]\tClassification Loss: 1.1341\r\n",
      "Train Epoch: 4 [88320/110534 (80%)]\tClassification Loss: 1.1975\r\n",
      "Train Epoch: 4 [88480/110534 (80%)]\tClassification Loss: 1.0748\r\n",
      "Train Epoch: 4 [88640/110534 (80%)]\tClassification Loss: 1.2244\r\n",
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"train.py\", line 227, in <module>\r\n",
      "    \r\n",
      "  File \"train.py\", line 130, in train\r\n",
      "    epoch, batch_idx * len(data), len(train_loader.dataset),\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torch/tensor.py\", line 418, in __format__\r\n",
      "    return self.item().__format__(format_spec)\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jydikJ4fdXdf",
    "colab_type": "code",
    "outputId": "253d2624-ba17-4fef-8bea-4eda61707948",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1584862857505,
     "user_tz": -300,
     "elapsed": 669079,
     "user": {
      "displayName": "Muhammad Ali",
      "photoUrl": "",
      "userId": "15673831022739340207"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "# From scratch. Freeze=True. LR=0.03\n",
    "! python train.py"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Test() called at batch_idx: 0\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\r\n",
      "  warnings.warn(warning.format(ret))\r\n",
      "train.py:160: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 3.5429, Accuracy: 1/480 (0%)\r\n",
      "\r\n",
      "Train Epoch: 1 [0/110534 (0%)]\tClassification Loss: 3.3302\r\n",
      "Train Epoch: 1 [160/110534 (0%)]\tClassification Loss: 3.0378\r\n",
      "Train Epoch: 1 [320/110534 (0%)]\tClassification Loss: 2.4269\r\n",
      "Train Epoch: 1 [480/110534 (0%)]\tClassification Loss: 2.8654\r\n",
      "Train Epoch: 1 [640/110534 (1%)]\tClassification Loss: 2.3642\r\n",
      "Train Epoch: 1 [800/110534 (1%)]\tClassification Loss: 2.4053\r\n",
      "Train Epoch: 1 [960/110534 (1%)]\tClassification Loss: 2.3633\r\n",
      "Train Epoch: 1 [1120/110534 (1%)]\tClassification Loss: 2.6062\r\n",
      "Train Epoch: 1 [1280/110534 (1%)]\tClassification Loss: 2.3803\r\n",
      "Train Epoch: 1 [1440/110534 (1%)]\tClassification Loss: 1.9474\r\n",
      "Test() called at batch_idx: 100\r\n",
      "\r\n",
      "Test set: Average loss: 2.5243, Accuracy: 146/480 (30%)\r\n",
      "\r\n",
      "Train Epoch: 1 [1600/110534 (1%)]\tClassification Loss: 2.1585\r\n",
      "Train Epoch: 1 [1760/110534 (2%)]\tClassification Loss: 2.4833\r\n",
      "Train Epoch: 1 [1920/110534 (2%)]\tClassification Loss: 2.0809\r\n",
      "Train Epoch: 1 [2080/110534 (2%)]\tClassification Loss: 2.2871\r\n",
      "Train Epoch: 1 [2240/110534 (2%)]\tClassification Loss: 2.4930\r\n",
      "Train Epoch: 1 [2400/110534 (2%)]\tClassification Loss: 1.9530\r\n",
      "Train Epoch: 1 [2560/110534 (2%)]\tClassification Loss: 2.2659\r\n",
      "Train Epoch: 1 [2720/110534 (2%)]\tClassification Loss: 3.0160\r\n",
      "Train Epoch: 1 [2880/110534 (3%)]\tClassification Loss: 1.9033\r\n",
      "Train Epoch: 1 [3040/110534 (3%)]\tClassification Loss: 2.3647\r\n",
      "Test() called at batch_idx: 200\r\n",
      "\r\n",
      "Test set: Average loss: 2.3682, Accuracy: 162/480 (34%)\r\n",
      "\r\n",
      "Train Epoch: 1 [3200/110534 (3%)]\tClassification Loss: 2.0673\r\n",
      "Train Epoch: 1 [3360/110534 (3%)]\tClassification Loss: 2.3248\r\n",
      "Train Epoch: 1 [3520/110534 (3%)]\tClassification Loss: 2.1113\r\n",
      "Train Epoch: 1 [3680/110534 (3%)]\tClassification Loss: 2.1149\r\n",
      "Train Epoch: 1 [3840/110534 (3%)]\tClassification Loss: 2.0728\r\n",
      "Train Epoch: 1 [4000/110534 (4%)]\tClassification Loss: 2.2351\r\n",
      "Train Epoch: 1 [4160/110534 (4%)]\tClassification Loss: 2.3083\r\n",
      "Train Epoch: 1 [4320/110534 (4%)]\tClassification Loss: 1.9784\r\n",
      "Train Epoch: 1 [4480/110534 (4%)]\tClassification Loss: 2.1690\r\n",
      "Train Epoch: 1 [4640/110534 (4%)]\tClassification Loss: 1.9620\r\n",
      "Test() called at batch_idx: 300\r\n",
      "\r\n",
      "Test set: Average loss: 2.2796, Accuracy: 185/480 (39%)\r\n",
      "\r\n",
      "Train Epoch: 1 [4800/110534 (4%)]\tClassification Loss: 2.8246\r\n",
      "Train Epoch: 1 [4960/110534 (4%)]\tClassification Loss: 1.9509\r\n",
      "Train Epoch: 1 [5120/110534 (5%)]\tClassification Loss: 2.5240\r\n",
      "Train Epoch: 1 [5280/110534 (5%)]\tClassification Loss: 2.0692\r\n",
      "Train Epoch: 1 [5440/110534 (5%)]\tClassification Loss: 2.0212\r\n",
      "Train Epoch: 1 [5600/110534 (5%)]\tClassification Loss: 2.0421\r\n",
      "Train Epoch: 1 [5760/110534 (5%)]\tClassification Loss: 1.9695\r\n",
      "Train Epoch: 1 [5920/110534 (5%)]\tClassification Loss: 1.7293\r\n",
      "Train Epoch: 1 [6080/110534 (6%)]\tClassification Loss: 2.0507\r\n",
      "Train Epoch: 1 [6240/110534 (6%)]\tClassification Loss: 1.7297\r\n",
      "Test() called at batch_idx: 400\r\n",
      "\r\n",
      "Test set: Average loss: 2.1807, Accuracy: 193/480 (40%)\r\n",
      "\r\n",
      "Train Epoch: 1 [6400/110534 (6%)]\tClassification Loss: 1.9671\r\n",
      "Train Epoch: 1 [6560/110534 (6%)]\tClassification Loss: 2.7068\r\n",
      "Train Epoch: 1 [6720/110534 (6%)]\tClassification Loss: 2.0820\r\n",
      "Train Epoch: 1 [6880/110534 (6%)]\tClassification Loss: 2.4928\r\n",
      "Train Epoch: 1 [7040/110534 (6%)]\tClassification Loss: 1.9869\r\n",
      "Train Epoch: 1 [7200/110534 (7%)]\tClassification Loss: 2.0303\r\n",
      "Train Epoch: 1 [7360/110534 (7%)]\tClassification Loss: 1.9663\r\n",
      "Train Epoch: 1 [7520/110534 (7%)]\tClassification Loss: 2.1650\r\n",
      "Train Epoch: 1 [7680/110534 (7%)]\tClassification Loss: 2.1280\r\n",
      "Train Epoch: 1 [7840/110534 (7%)]\tClassification Loss: 2.7915\r\n",
      "Test() called at batch_idx: 500\r\n",
      "\r\n",
      "Test set: Average loss: 2.1209, Accuracy: 210/480 (44%)\r\n",
      "\r\n",
      "Train Epoch: 1 [8000/110534 (7%)]\tClassification Loss: 1.6656\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_500.pth.tar\r\n",
      "Train Epoch: 1 [8160/110534 (7%)]\tClassification Loss: 1.8838\r\n",
      "Train Epoch: 1 [8320/110534 (8%)]\tClassification Loss: 1.9992\r\n",
      "Train Epoch: 1 [8480/110534 (8%)]\tClassification Loss: 2.2627\r\n",
      "Train Epoch: 1 [8640/110534 (8%)]\tClassification Loss: 2.1363\r\n",
      "Train Epoch: 1 [8800/110534 (8%)]\tClassification Loss: 1.9521\r\n",
      "Train Epoch: 1 [8960/110534 (8%)]\tClassification Loss: 2.0769\r\n",
      "Train Epoch: 1 [9120/110534 (8%)]\tClassification Loss: 2.0877\r\n",
      "Train Epoch: 1 [9280/110534 (8%)]\tClassification Loss: 1.8068\r\n",
      "Train Epoch: 1 [9440/110534 (9%)]\tClassification Loss: 2.0970\r\n",
      "Test() called at batch_idx: 600\r\n",
      "\r\n",
      "Test set: Average loss: 2.0539, Accuracy: 236/480 (49%)\r\n",
      "\r\n",
      "Train Epoch: 1 [9600/110534 (9%)]\tClassification Loss: 2.0558\r\n",
      "Train Epoch: 1 [9760/110534 (9%)]\tClassification Loss: 1.7948\r\n",
      "Train Epoch: 1 [9920/110534 (9%)]\tClassification Loss: 2.1296\r\n",
      "Train Epoch: 1 [10080/110534 (9%)]\tClassification Loss: 2.1951\r\n",
      "Train Epoch: 1 [10240/110534 (9%)]\tClassification Loss: 1.6386\r\n",
      "Train Epoch: 1 [10400/110534 (9%)]\tClassification Loss: 1.6826\r\n",
      "Train Epoch: 1 [10560/110534 (10%)]\tClassification Loss: 1.6778\r\n",
      "Train Epoch: 1 [10720/110534 (10%)]\tClassification Loss: 2.1445\r\n",
      "Train Epoch: 1 [10880/110534 (10%)]\tClassification Loss: 2.1024\r\n",
      "Train Epoch: 1 [11040/110534 (10%)]\tClassification Loss: 2.0390\r\n",
      "Test() called at batch_idx: 700\r\n",
      "\r\n",
      "Test set: Average loss: 2.0054, Accuracy: 230/480 (48%)\r\n",
      "\r\n",
      "Train Epoch: 1 [11200/110534 (10%)]\tClassification Loss: 1.8661\r\n",
      "Train Epoch: 1 [11360/110534 (10%)]\tClassification Loss: 1.9754\r\n",
      "Train Epoch: 1 [11520/110534 (10%)]\tClassification Loss: 2.3589\r\n",
      "Train Epoch: 1 [11680/110534 (11%)]\tClassification Loss: 2.0869\r\n",
      "Train Epoch: 1 [11840/110534 (11%)]\tClassification Loss: 1.7236\r\n",
      "Train Epoch: 1 [12000/110534 (11%)]\tClassification Loss: 1.9904\r\n",
      "Train Epoch: 1 [12160/110534 (11%)]\tClassification Loss: 2.0947\r\n",
      "Train Epoch: 1 [12320/110534 (11%)]\tClassification Loss: 1.3209\r\n",
      "Train Epoch: 1 [12480/110534 (11%)]\tClassification Loss: 2.2203\r\n",
      "Train Epoch: 1 [12640/110534 (11%)]\tClassification Loss: 2.0855\r\n",
      "Test() called at batch_idx: 800\r\n",
      "\r\n",
      "Test set: Average loss: 1.9634, Accuracy: 250/480 (52%)\r\n",
      "\r\n",
      "Train Epoch: 1 [12800/110534 (12%)]\tClassification Loss: 1.8380\r\n",
      "Train Epoch: 1 [12960/110534 (12%)]\tClassification Loss: 2.2426\r\n",
      "Train Epoch: 1 [13120/110534 (12%)]\tClassification Loss: 2.2820\r\n",
      "Train Epoch: 1 [13280/110534 (12%)]\tClassification Loss: 2.2119\r\n",
      "Train Epoch: 1 [13440/110534 (12%)]\tClassification Loss: 2.0036\r\n",
      "Train Epoch: 1 [13600/110534 (12%)]\tClassification Loss: 1.8499\r\n",
      "Train Epoch: 1 [13760/110534 (12%)]\tClassification Loss: 1.6892\r\n",
      "Train Epoch: 1 [13920/110534 (13%)]\tClassification Loss: 1.5579\r\n",
      "Train Epoch: 1 [14080/110534 (13%)]\tClassification Loss: 1.6766\r\n",
      "Train Epoch: 1 [14240/110534 (13%)]\tClassification Loss: 2.1429\r\n",
      "Test() called at batch_idx: 900\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\r\n",
      "    self._send(header + buf)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\r\n",
      "    n = write(self._handle, buf)\r\n",
      "BrokenPipeError: [Errno 32] Broken pipe\r\n",
      "\r\n",
      "Test set: Average loss: 1.9358, Accuracy: 255/480 (53%)\r\n",
      "\r\n",
      "Train Epoch: 1 [14400/110534 (13%)]\tClassification Loss: 1.5029\r\n",
      "Train Epoch: 1 [14560/110534 (13%)]\tClassification Loss: 1.7582\r\n",
      "Train Epoch: 1 [14720/110534 (13%)]\tClassification Loss: 1.7053\r\n",
      "Train Epoch: 1 [14880/110534 (13%)]\tClassification Loss: 1.9322\r\n",
      "Train Epoch: 1 [15040/110534 (14%)]\tClassification Loss: 1.8636\r\n",
      "Train Epoch: 1 [15200/110534 (14%)]\tClassification Loss: 1.6661\r\n",
      "Train Epoch: 1 [15360/110534 (14%)]\tClassification Loss: 1.5637\r\n",
      "Train Epoch: 1 [15520/110534 (14%)]\tClassification Loss: 1.8015\r\n",
      "Train Epoch: 1 [15680/110534 (14%)]\tClassification Loss: 2.0027\r\n",
      "Train Epoch: 1 [15840/110534 (14%)]\tClassification Loss: 1.5430\r\n",
      "Test() called at batch_idx: 1000\r\n",
      "\r\n",
      "Test set: Average loss: 1.9182, Accuracy: 241/480 (50%)\r\n",
      "\r\n",
      "Train Epoch: 1 [16000/110534 (14%)]\tClassification Loss: 1.6629\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1000.pth.tar\r\n",
      "Train Epoch: 1 [16160/110534 (15%)]\tClassification Loss: 1.8324\r\n",
      "Train Epoch: 1 [16320/110534 (15%)]\tClassification Loss: 2.4069\r\n",
      "Train Epoch: 1 [16480/110534 (15%)]\tClassification Loss: 1.8271\r\n",
      "Train Epoch: 1 [16640/110534 (15%)]\tClassification Loss: 1.8430\r\n",
      "Train Epoch: 1 [16800/110534 (15%)]\tClassification Loss: 1.5063\r\n",
      "Train Epoch: 1 [16960/110534 (15%)]\tClassification Loss: 2.1742\r\n",
      "Train Epoch: 1 [17120/110534 (15%)]\tClassification Loss: 2.5461\r\n",
      "Train Epoch: 1 [17280/110534 (16%)]\tClassification Loss: 1.6704\r\n",
      "Train Epoch: 1 [17440/110534 (16%)]\tClassification Loss: 1.6738\r\n",
      "Test() called at batch_idx: 1100\r\n",
      "\r\n",
      "Test set: Average loss: 1.9021, Accuracy: 252/480 (52%)\r\n",
      "\r\n",
      "Train Epoch: 1 [17600/110534 (16%)]\tClassification Loss: 1.4875\r\n",
      "Train Epoch: 1 [17760/110534 (16%)]\tClassification Loss: 1.4807\r\n",
      "Train Epoch: 1 [17920/110534 (16%)]\tClassification Loss: 2.0973\r\n",
      "Train Epoch: 1 [18080/110534 (16%)]\tClassification Loss: 2.2080\r\n",
      "Train Epoch: 1 [18240/110534 (17%)]\tClassification Loss: 1.8813\r\n",
      "Train Epoch: 1 [18400/110534 (17%)]\tClassification Loss: 1.6700\r\n",
      "Train Epoch: 1 [18560/110534 (17%)]\tClassification Loss: 1.7685\r\n",
      "Train Epoch: 1 [18720/110534 (17%)]\tClassification Loss: 2.3192\r\n",
      "Train Epoch: 1 [18880/110534 (17%)]\tClassification Loss: 1.5390\r\n",
      "Train Epoch: 1 [19040/110534 (17%)]\tClassification Loss: 2.1453\r\n",
      "Test() called at batch_idx: 1200\r\n",
      "\r\n",
      "Test set: Average loss: 1.8557, Accuracy: 264/480 (55%)\r\n",
      "\r\n",
      "Train Epoch: 1 [19200/110534 (17%)]\tClassification Loss: 2.0594\r\n",
      "Train Epoch: 1 [19360/110534 (18%)]\tClassification Loss: 1.8890\r\n",
      "Train Epoch: 1 [19520/110534 (18%)]\tClassification Loss: 2.4471\r\n",
      "Train Epoch: 1 [19680/110534 (18%)]\tClassification Loss: 1.8814\r\n",
      "Train Epoch: 1 [19840/110534 (18%)]\tClassification Loss: 1.5226\r\n",
      "Train Epoch: 1 [20000/110534 (18%)]\tClassification Loss: 2.4139\r\n",
      "Train Epoch: 1 [20160/110534 (18%)]\tClassification Loss: 1.9050\r\n",
      "Train Epoch: 1 [20320/110534 (18%)]\tClassification Loss: 1.4885\r\n",
      "Train Epoch: 1 [20480/110534 (19%)]\tClassification Loss: 1.7705\r\n",
      "Train Epoch: 1 [20640/110534 (19%)]\tClassification Loss: 2.6594\r\n",
      "Test() called at batch_idx: 1300\r\n",
      "\r\n",
      "Test set: Average loss: 1.8528, Accuracy: 261/480 (54%)\r\n",
      "\r\n",
      "Train Epoch: 1 [20800/110534 (19%)]\tClassification Loss: 2.0833\r\n",
      "Train Epoch: 1 [20960/110534 (19%)]\tClassification Loss: 2.1806\r\n",
      "Train Epoch: 1 [21120/110534 (19%)]\tClassification Loss: 2.2960\r\n",
      "Train Epoch: 1 [21280/110534 (19%)]\tClassification Loss: 1.8940\r\n",
      "Train Epoch: 1 [21440/110534 (19%)]\tClassification Loss: 1.5788\r\n",
      "Train Epoch: 1 [21600/110534 (20%)]\tClassification Loss: 1.6998\r\n",
      "Train Epoch: 1 [21760/110534 (20%)]\tClassification Loss: 1.7235\r\n",
      "Train Epoch: 1 [21920/110534 (20%)]\tClassification Loss: 1.7197\r\n",
      "Train Epoch: 1 [22080/110534 (20%)]\tClassification Loss: 2.5129\r\n",
      "Train Epoch: 1 [22240/110534 (20%)]\tClassification Loss: 1.8574\r\n",
      "Test() called at batch_idx: 1400\r\n",
      "\r\n",
      "Test set: Average loss: 1.8165, Accuracy: 262/480 (55%)\r\n",
      "\r\n",
      "Train Epoch: 1 [22400/110534 (20%)]\tClassification Loss: 1.8145\r\n",
      "Train Epoch: 1 [22560/110534 (20%)]\tClassification Loss: 1.6967\r\n",
      "Train Epoch: 1 [22720/110534 (21%)]\tClassification Loss: 1.2567\r\n",
      "Train Epoch: 1 [22880/110534 (21%)]\tClassification Loss: 1.8841\r\n",
      "Train Epoch: 1 [23040/110534 (21%)]\tClassification Loss: 1.6984\r\n",
      "Train Epoch: 1 [23200/110534 (21%)]\tClassification Loss: 2.2630\r\n",
      "Train Epoch: 1 [23360/110534 (21%)]\tClassification Loss: 1.4887\r\n",
      "Train Epoch: 1 [23520/110534 (21%)]\tClassification Loss: 1.6077\r\n",
      "Train Epoch: 1 [23680/110534 (21%)]\tClassification Loss: 1.4375\r\n",
      "Train Epoch: 1 [23840/110534 (22%)]\tClassification Loss: 1.9254\r\n",
      "Test() called at batch_idx: 1500\r\n",
      "\r\n",
      "Test set: Average loss: 1.8231, Accuracy: 254/480 (53%)\r\n",
      "\r\n",
      "Train Epoch: 1 [24000/110534 (22%)]\tClassification Loss: 1.4485\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1500.pth.tar\r\n",
      "Train Epoch: 1 [24160/110534 (22%)]\tClassification Loss: 2.1401\r\n",
      "Train Epoch: 1 [24320/110534 (22%)]\tClassification Loss: 1.8846\r\n",
      "Train Epoch: 1 [24480/110534 (22%)]\tClassification Loss: 1.6227\r\n",
      "Train Epoch: 1 [24640/110534 (22%)]\tClassification Loss: 1.4986\r\n",
      "Train Epoch: 1 [24800/110534 (22%)]\tClassification Loss: 1.6565\r\n",
      "Train Epoch: 1 [24960/110534 (23%)]\tClassification Loss: 1.9379\r\n",
      "Train Epoch: 1 [25120/110534 (23%)]\tClassification Loss: 1.3779\r\n",
      "Train Epoch: 1 [25280/110534 (23%)]\tClassification Loss: 1.7678\r\n",
      "Train Epoch: 1 [25440/110534 (23%)]\tClassification Loss: 1.8709\r\n",
      "Test() called at batch_idx: 1600\r\n",
      "\r\n",
      "Test set: Average loss: 1.8208, Accuracy: 257/480 (54%)\r\n",
      "\r\n",
      "Train Epoch: 1 [25600/110534 (23%)]\tClassification Loss: 1.5073\r\n",
      "Train Epoch: 1 [25760/110534 (23%)]\tClassification Loss: 1.7391\r\n",
      "Train Epoch: 1 [25920/110534 (23%)]\tClassification Loss: 1.8266\r\n",
      "Train Epoch: 1 [26080/110534 (24%)]\tClassification Loss: 1.8274\r\n",
      "Train Epoch: 1 [26240/110534 (24%)]\tClassification Loss: 1.8583\r\n",
      "Train Epoch: 1 [26400/110534 (24%)]\tClassification Loss: 2.3676\r\n",
      "Train Epoch: 1 [26560/110534 (24%)]\tClassification Loss: 1.9888\r\n",
      "Train Epoch: 1 [26720/110534 (24%)]\tClassification Loss: 2.1665\r\n",
      "Train Epoch: 1 [26880/110534 (24%)]\tClassification Loss: 1.9167\r\n",
      "Train Epoch: 1 [27040/110534 (24%)]\tClassification Loss: 1.8217\r\n",
      "Test() called at batch_idx: 1700\r\n",
      "\r\n",
      "Test set: Average loss: 1.7750, Accuracy: 265/480 (55%)\r\n",
      "\r\n",
      "Train Epoch: 1 [27200/110534 (25%)]\tClassification Loss: 1.3456\r\n",
      "Train Epoch: 1 [27360/110534 (25%)]\tClassification Loss: 1.2493\r\n",
      "Train Epoch: 1 [27520/110534 (25%)]\tClassification Loss: 2.0154\r\n",
      "Train Epoch: 1 [27680/110534 (25%)]\tClassification Loss: 2.0837\r\n",
      "Train Epoch: 1 [27840/110534 (25%)]\tClassification Loss: 2.1901\r\n",
      "Train Epoch: 1 [28000/110534 (25%)]\tClassification Loss: 1.9156\r\n",
      "Train Epoch: 1 [28160/110534 (25%)]\tClassification Loss: 2.0540\r\n",
      "Train Epoch: 1 [28320/110534 (26%)]\tClassification Loss: 2.2422\r\n",
      "Train Epoch: 1 [28480/110534 (26%)]\tClassification Loss: 1.5242\r\n",
      "Train Epoch: 1 [28640/110534 (26%)]\tClassification Loss: 1.6223\r\n",
      "Test() called at batch_idx: 1800\r\n",
      "\r\n",
      "Test set: Average loss: 1.7672, Accuracy: 263/480 (55%)\r\n",
      "\r\n",
      "Train Epoch: 1 [28800/110534 (26%)]\tClassification Loss: 1.9081\r\n",
      "Train Epoch: 1 [28960/110534 (26%)]\tClassification Loss: 2.3624\r\n",
      "Train Epoch: 1 [29120/110534 (26%)]\tClassification Loss: 1.6501\r\n",
      "Train Epoch: 1 [29280/110534 (26%)]\tClassification Loss: 1.3870\r\n",
      "Train Epoch: 1 [29440/110534 (27%)]\tClassification Loss: 1.7254\r\n",
      "Train Epoch: 1 [29600/110534 (27%)]\tClassification Loss: 1.8293\r\n",
      "Train Epoch: 1 [29760/110534 (27%)]\tClassification Loss: 1.4208\r\n",
      "Train Epoch: 1 [29920/110534 (27%)]\tClassification Loss: 1.5563\r\n",
      "Train Epoch: 1 [30080/110534 (27%)]\tClassification Loss: 1.5182\r\n",
      "Train Epoch: 1 [30240/110534 (27%)]\tClassification Loss: 1.7166\r\n",
      "Test() called at batch_idx: 1900\r\n",
      "\r\n",
      "Test set: Average loss: 1.7630, Accuracy: 263/480 (55%)\r\n",
      "\r\n",
      "Train Epoch: 1 [30400/110534 (28%)]\tClassification Loss: 2.3750\r\n",
      "Train Epoch: 1 [30560/110534 (28%)]\tClassification Loss: 1.7429\r\n",
      "Train Epoch: 1 [30720/110534 (28%)]\tClassification Loss: 1.8003\r\n",
      "Train Epoch: 1 [30880/110534 (28%)]\tClassification Loss: 2.3056\r\n",
      "Train Epoch: 1 [31040/110534 (28%)]\tClassification Loss: 1.5605\r\n",
      "Train Epoch: 1 [31200/110534 (28%)]\tClassification Loss: 1.4453\r\n",
      "Train Epoch: 1 [31360/110534 (28%)]\tClassification Loss: 2.1679\r\n",
      "Train Epoch: 1 [31520/110534 (29%)]\tClassification Loss: 1.5162\r\n",
      "Train Epoch: 1 [31680/110534 (29%)]\tClassification Loss: 1.7302\r\n",
      "Train Epoch: 1 [31840/110534 (29%)]\tClassification Loss: 1.4820\r\n",
      "Test() called at batch_idx: 2000\r\n",
      "\r\n",
      "Test set: Average loss: 1.7411, Accuracy: 269/480 (56%)\r\n",
      "\r\n",
      "Train Epoch: 1 [32000/110534 (29%)]\tClassification Loss: 1.3635\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_2000.pth.tar\r\n",
      "Train Epoch: 1 [32160/110534 (29%)]\tClassification Loss: 1.3140\r\n",
      "Train Epoch: 1 [32320/110534 (29%)]\tClassification Loss: 1.9173\r\n",
      "Train Epoch: 1 [32480/110534 (29%)]\tClassification Loss: 1.5581\r\n",
      "Train Epoch: 1 [32640/110534 (30%)]\tClassification Loss: 1.6923\r\n",
      "Train Epoch: 1 [32800/110534 (30%)]\tClassification Loss: 2.2279\r\n",
      "Train Epoch: 1 [32960/110534 (30%)]\tClassification Loss: 1.7608\r\n",
      "Train Epoch: 1 [33120/110534 (30%)]\tClassification Loss: 1.5782\r\n",
      "Train Epoch: 1 [33280/110534 (30%)]\tClassification Loss: 1.8986\r\n",
      "Train Epoch: 1 [33440/110534 (30%)]\tClassification Loss: 1.9359\r\n",
      "Test() called at batch_idx: 2100\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "\r\n",
      "Test set: Average loss: 1.7518, Accuracy: 275/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [33600/110534 (30%)]\tClassification Loss: 1.3320\r\n",
      "Train Epoch: 1 [33760/110534 (31%)]\tClassification Loss: 1.6454\r\n",
      "Train Epoch: 1 [33920/110534 (31%)]\tClassification Loss: 2.4587\r\n",
      "Train Epoch: 1 [34080/110534 (31%)]\tClassification Loss: 1.6932\r\n",
      "Train Epoch: 1 [34240/110534 (31%)]\tClassification Loss: 2.2147\r\n",
      "Train Epoch: 1 [34400/110534 (31%)]\tClassification Loss: 2.1410\r\n",
      "Train Epoch: 1 [34560/110534 (31%)]\tClassification Loss: 2.0317\r\n",
      "Train Epoch: 1 [34720/110534 (31%)]\tClassification Loss: 1.9624\r\n",
      "Train Epoch: 1 [34880/110534 (32%)]\tClassification Loss: 2.4270\r\n",
      "Train Epoch: 1 [35040/110534 (32%)]\tClassification Loss: 1.3457\r\n",
      "Test() called at batch_idx: 2200\r\n",
      "\r\n",
      "Test set: Average loss: 1.7276, Accuracy: 263/480 (55%)\r\n",
      "\r\n",
      "Train Epoch: 1 [35200/110534 (32%)]\tClassification Loss: 2.0809\r\n",
      "Train Epoch: 1 [35360/110534 (32%)]\tClassification Loss: 1.8527\r\n",
      "Train Epoch: 1 [35520/110534 (32%)]\tClassification Loss: 1.1794\r\n",
      "Train Epoch: 1 [35680/110534 (32%)]\tClassification Loss: 2.2412\r\n",
      "Train Epoch: 1 [35840/110534 (32%)]\tClassification Loss: 1.4771\r\n",
      "Train Epoch: 1 [36000/110534 (33%)]\tClassification Loss: 1.5502\r\n",
      "Train Epoch: 1 [36160/110534 (33%)]\tClassification Loss: 1.4301\r\n",
      "Train Epoch: 1 [36320/110534 (33%)]\tClassification Loss: 2.3698\r\n",
      "Train Epoch: 1 [36480/110534 (33%)]\tClassification Loss: 1.3546\r\n",
      "Train Epoch: 1 [36640/110534 (33%)]\tClassification Loss: 1.6427\r\n",
      "Test() called at batch_idx: 2300\r\n",
      "\r\n",
      "Test set: Average loss: 1.7291, Accuracy: 267/480 (56%)\r\n",
      "\r\n",
      "Train Epoch: 1 [36800/110534 (33%)]\tClassification Loss: 2.1023\r\n",
      "Train Epoch: 1 [36960/110534 (33%)]\tClassification Loss: 1.3783\r\n",
      "Train Epoch: 1 [37120/110534 (34%)]\tClassification Loss: 1.3899\r\n",
      "Train Epoch: 1 [37280/110534 (34%)]\tClassification Loss: 1.5063\r\n",
      "Train Epoch: 1 [37440/110534 (34%)]\tClassification Loss: 1.6728\r\n",
      "Train Epoch: 1 [37600/110534 (34%)]\tClassification Loss: 2.1043\r\n",
      "Train Epoch: 1 [37760/110534 (34%)]\tClassification Loss: 2.3757\r\n",
      "Train Epoch: 1 [37920/110534 (34%)]\tClassification Loss: 1.7846\r\n",
      "Train Epoch: 1 [38080/110534 (34%)]\tClassification Loss: 2.0215\r\n",
      "Train Epoch: 1 [38240/110534 (35%)]\tClassification Loss: 1.7916\r\n",
      "Test() called at batch_idx: 2400\r\n",
      "\r\n",
      "Test set: Average loss: 1.7020, Accuracy: 271/480 (56%)\r\n",
      "\r\n",
      "Train Epoch: 1 [38400/110534 (35%)]\tClassification Loss: 1.1908\r\n",
      "Train Epoch: 1 [38560/110534 (35%)]\tClassification Loss: 1.5436\r\n",
      "Train Epoch: 1 [38720/110534 (35%)]\tClassification Loss: 1.8600\r\n",
      "Train Epoch: 1 [38880/110534 (35%)]\tClassification Loss: 1.7937\r\n",
      "Train Epoch: 1 [39040/110534 (35%)]\tClassification Loss: 2.2061\r\n",
      "Train Epoch: 1 [39200/110534 (35%)]\tClassification Loss: 1.1051\r\n",
      "Train Epoch: 1 [39360/110534 (36%)]\tClassification Loss: 1.3471\r\n",
      "Train Epoch: 1 [39520/110534 (36%)]\tClassification Loss: 1.2488\r\n",
      "Train Epoch: 1 [39680/110534 (36%)]\tClassification Loss: 1.2862\r\n",
      "Train Epoch: 1 [39840/110534 (36%)]\tClassification Loss: 1.6052\r\n",
      "Test() called at batch_idx: 2500\r\n",
      "\r\n",
      "Test set: Average loss: 1.6967, Accuracy: 269/480 (56%)\r\n",
      "\r\n",
      "Train Epoch: 1 [40000/110534 (36%)]\tClassification Loss: 2.1532\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_2500.pth.tar\r\n",
      "Train Epoch: 1 [40160/110534 (36%)]\tClassification Loss: 1.4128\r\n",
      "Train Epoch: 1 [40320/110534 (36%)]\tClassification Loss: 1.7234\r\n",
      "Train Epoch: 1 [40480/110534 (37%)]\tClassification Loss: 1.5300\r\n",
      "Train Epoch: 1 [40640/110534 (37%)]\tClassification Loss: 2.0964\r\n",
      "Train Epoch: 1 [40800/110534 (37%)]\tClassification Loss: 1.9544\r\n",
      "Train Epoch: 1 [40960/110534 (37%)]\tClassification Loss: 2.1709\r\n",
      "Train Epoch: 1 [41120/110534 (37%)]\tClassification Loss: 1.9849\r\n",
      "Train Epoch: 1 [41280/110534 (37%)]\tClassification Loss: 1.8001\r\n",
      "Train Epoch: 1 [41440/110534 (37%)]\tClassification Loss: 1.5916\r\n",
      "Test() called at batch_idx: 2600\r\n",
      "\r\n",
      "Test set: Average loss: 1.6912, Accuracy: 270/480 (56%)\r\n",
      "\r\n",
      "Train Epoch: 1 [41600/110534 (38%)]\tClassification Loss: 2.4490\r\n",
      "Train Epoch: 1 [41760/110534 (38%)]\tClassification Loss: 1.8961\r\n",
      "Train Epoch: 1 [41920/110534 (38%)]\tClassification Loss: 1.9244\r\n",
      "Train Epoch: 1 [42080/110534 (38%)]\tClassification Loss: 1.3417\r\n",
      "Train Epoch: 1 [42240/110534 (38%)]\tClassification Loss: 1.8321\r\n",
      "Train Epoch: 1 [42400/110534 (38%)]\tClassification Loss: 1.4833\r\n",
      "Train Epoch: 1 [42560/110534 (39%)]\tClassification Loss: 1.6734\r\n",
      "Train Epoch: 1 [42720/110534 (39%)]\tClassification Loss: 2.2783\r\n",
      "Train Epoch: 1 [42880/110534 (39%)]\tClassification Loss: 1.5330\r\n",
      "Train Epoch: 1 [43040/110534 (39%)]\tClassification Loss: 1.2039\r\n",
      "Test() called at batch_idx: 2700\r\n",
      "\r\n",
      "Test set: Average loss: 1.6904, Accuracy: 272/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [43200/110534 (39%)]\tClassification Loss: 1.3383\r\n",
      "Train Epoch: 1 [43360/110534 (39%)]\tClassification Loss: 1.3112\r\n",
      "Train Epoch: 1 [43520/110534 (39%)]\tClassification Loss: 1.2284\r\n",
      "Train Epoch: 1 [43680/110534 (40%)]\tClassification Loss: 1.6495\r\n",
      "Train Epoch: 1 [43840/110534 (40%)]\tClassification Loss: 1.7300\r\n",
      "Train Epoch: 1 [44000/110534 (40%)]\tClassification Loss: 1.4378\r\n",
      "Train Epoch: 1 [44160/110534 (40%)]\tClassification Loss: 2.1121\r\n",
      "Train Epoch: 1 [44320/110534 (40%)]\tClassification Loss: 1.3064\r\n",
      "Train Epoch: 1 [44480/110534 (40%)]\tClassification Loss: 1.9524\r\n",
      "Train Epoch: 1 [44640/110534 (40%)]\tClassification Loss: 1.6788\r\n",
      "Test() called at batch_idx: 2800\r\n",
      "\r\n",
      "Test set: Average loss: 1.6931, Accuracy: 274/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [44800/110534 (41%)]\tClassification Loss: 2.0594\r\n",
      "Train Epoch: 1 [44960/110534 (41%)]\tClassification Loss: 1.2223\r\n",
      "Train Epoch: 1 [45120/110534 (41%)]\tClassification Loss: 1.8968\r\n",
      "Train Epoch: 1 [45280/110534 (41%)]\tClassification Loss: 1.7076\r\n",
      "Train Epoch: 1 [45440/110534 (41%)]\tClassification Loss: 1.8991\r\n",
      "Train Epoch: 1 [45600/110534 (41%)]\tClassification Loss: 1.4177\r\n",
      "Train Epoch: 1 [45760/110534 (41%)]\tClassification Loss: 1.6314\r\n",
      "Train Epoch: 1 [45920/110534 (42%)]\tClassification Loss: 1.5101\r\n",
      "Train Epoch: 1 [46080/110534 (42%)]\tClassification Loss: 1.6689\r\n",
      "Train Epoch: 1 [46240/110534 (42%)]\tClassification Loss: 1.5005\r\n",
      "Test() called at batch_idx: 2900\r\n",
      "\r\n",
      "Test set: Average loss: 1.6686, Accuracy: 275/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [46400/110534 (42%)]\tClassification Loss: 1.6424\r\n",
      "Train Epoch: 1 [46560/110534 (42%)]\tClassification Loss: 1.4638\r\n",
      "Train Epoch: 1 [46720/110534 (42%)]\tClassification Loss: 2.5370\r\n",
      "Train Epoch: 1 [46880/110534 (42%)]\tClassification Loss: 1.9972\r\n",
      "Train Epoch: 1 [47040/110534 (43%)]\tClassification Loss: 1.8106\r\n",
      "Train Epoch: 1 [47200/110534 (43%)]\tClassification Loss: 1.5306\r\n",
      "Train Epoch: 1 [47360/110534 (43%)]\tClassification Loss: 2.0411\r\n",
      "Train Epoch: 1 [47520/110534 (43%)]\tClassification Loss: 1.7274\r\n",
      "Train Epoch: 1 [47680/110534 (43%)]\tClassification Loss: 1.7054\r\n",
      "Train Epoch: 1 [47840/110534 (43%)]\tClassification Loss: 1.4599\r\n",
      "Test() called at batch_idx: 3000\r\n",
      "\r\n",
      "Test set: Average loss: 1.6639, Accuracy: 272/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [48000/110534 (43%)]\tClassification Loss: 1.9514\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_3000.pth.tar\r\n",
      "Train Epoch: 1 [48160/110534 (44%)]\tClassification Loss: 1.7443\r\n",
      "Train Epoch: 1 [48320/110534 (44%)]\tClassification Loss: 1.4454\r\n",
      "Train Epoch: 1 [48480/110534 (44%)]\tClassification Loss: 1.6655\r\n",
      "Train Epoch: 1 [48640/110534 (44%)]\tClassification Loss: 1.8483\r\n",
      "Train Epoch: 1 [48800/110534 (44%)]\tClassification Loss: 1.3196\r\n",
      "Train Epoch: 1 [48960/110534 (44%)]\tClassification Loss: 1.4738\r\n",
      "Train Epoch: 1 [49120/110534 (44%)]\tClassification Loss: 1.7372\r\n",
      "Train Epoch: 1 [49280/110534 (45%)]\tClassification Loss: 1.2094\r\n",
      "Train Epoch: 1 [49440/110534 (45%)]\tClassification Loss: 2.0159\r\n",
      "Test() called at batch_idx: 3100\r\n",
      "\r\n",
      "Test set: Average loss: 1.6760, Accuracy: 273/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [49600/110534 (45%)]\tClassification Loss: 1.8434\r\n",
      "Train Epoch: 1 [49760/110534 (45%)]\tClassification Loss: 1.8750\r\n",
      "Train Epoch: 1 [49920/110534 (45%)]\tClassification Loss: 2.4191\r\n",
      "Train Epoch: 1 [50080/110534 (45%)]\tClassification Loss: 1.9404\r\n",
      "Train Epoch: 1 [50240/110534 (45%)]\tClassification Loss: 1.8952\r\n",
      "Train Epoch: 1 [50400/110534 (46%)]\tClassification Loss: 1.8651\r\n",
      "Train Epoch: 1 [50560/110534 (46%)]\tClassification Loss: 1.7875\r\n",
      "Train Epoch: 1 [50720/110534 (46%)]\tClassification Loss: 2.0344\r\n",
      "Train Epoch: 1 [50880/110534 (46%)]\tClassification Loss: 1.2005\r\n",
      "Train Epoch: 1 [51040/110534 (46%)]\tClassification Loss: 2.3449\r\n",
      "Test() called at batch_idx: 3200\r\n",
      "\r\n",
      "Test set: Average loss: 1.6551, Accuracy: 273/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [51200/110534 (46%)]\tClassification Loss: 1.9099\r\n",
      "Train Epoch: 1 [51360/110534 (46%)]\tClassification Loss: 1.9570\r\n",
      "Train Epoch: 1 [51520/110534 (47%)]\tClassification Loss: 1.2044\r\n",
      "Train Epoch: 1 [51680/110534 (47%)]\tClassification Loss: 2.0934\r\n",
      "Train Epoch: 1 [51840/110534 (47%)]\tClassification Loss: 2.1494\r\n",
      "Train Epoch: 1 [52000/110534 (47%)]\tClassification Loss: 1.3670\r\n",
      "Train Epoch: 1 [52160/110534 (47%)]\tClassification Loss: 2.2653\r\n",
      "Train Epoch: 1 [52320/110534 (47%)]\tClassification Loss: 1.3174\r\n",
      "Train Epoch: 1 [52480/110534 (47%)]\tClassification Loss: 1.8826\r\n",
      "Train Epoch: 1 [52640/110534 (48%)]\tClassification Loss: 1.4941\r\n",
      "Test() called at batch_idx: 3300\r\n",
      "\r\n",
      "Test set: Average loss: 1.6778, Accuracy: 266/480 (55%)\r\n",
      "\r\n",
      "Train Epoch: 1 [52800/110534 (48%)]\tClassification Loss: 1.5664\r\n",
      "Train Epoch: 1 [52960/110534 (48%)]\tClassification Loss: 1.5994\r\n",
      "Train Epoch: 1 [53120/110534 (48%)]\tClassification Loss: 1.6641\r\n",
      "Train Epoch: 1 [53280/110534 (48%)]\tClassification Loss: 1.6939\r\n",
      "Train Epoch: 1 [53440/110534 (48%)]\tClassification Loss: 1.5968\r\n",
      "Train Epoch: 1 [53600/110534 (48%)]\tClassification Loss: 1.3508\r\n",
      "Train Epoch: 1 [53760/110534 (49%)]\tClassification Loss: 1.6826\r\n",
      "Train Epoch: 1 [53920/110534 (49%)]\tClassification Loss: 1.9349\r\n",
      "Train Epoch: 1 [54080/110534 (49%)]\tClassification Loss: 1.2896\r\n",
      "Train Epoch: 1 [54240/110534 (49%)]\tClassification Loss: 2.5955\r\n",
      "Test() called at batch_idx: 3400\r\n",
      "\r\n",
      "Test set: Average loss: 1.6637, Accuracy: 267/480 (56%)\r\n",
      "\r\n",
      "Train Epoch: 1 [54400/110534 (49%)]\tClassification Loss: 1.9666\r\n",
      "Train Epoch: 1 [54560/110534 (49%)]\tClassification Loss: 1.3509\r\n",
      "Train Epoch: 1 [54720/110534 (50%)]\tClassification Loss: 2.3386\r\n",
      "Train Epoch: 1 [54880/110534 (50%)]\tClassification Loss: 1.9170\r\n",
      "Train Epoch: 1 [55040/110534 (50%)]\tClassification Loss: 1.8410\r\n",
      "Train Epoch: 1 [55200/110534 (50%)]\tClassification Loss: 1.3623\r\n",
      "Train Epoch: 1 [55360/110534 (50%)]\tClassification Loss: 2.0161\r\n",
      "Train Epoch: 1 [55520/110534 (50%)]\tClassification Loss: 1.3634\r\n",
      "Train Epoch: 1 [55680/110534 (50%)]\tClassification Loss: 1.5127\r\n",
      "Train Epoch: 1 [55840/110534 (51%)]\tClassification Loss: 1.8612\r\n",
      "Test() called at batch_idx: 3500\r\n",
      "\r\n",
      "Test set: Average loss: 1.6358, Accuracy: 278/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [56000/110534 (51%)]\tClassification Loss: 2.1033\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_3500.pth.tar\r\n",
      "Train Epoch: 1 [56160/110534 (51%)]\tClassification Loss: 1.9256\r\n",
      "Train Epoch: 1 [56320/110534 (51%)]\tClassification Loss: 1.5740\r\n",
      "Train Epoch: 1 [56480/110534 (51%)]\tClassification Loss: 1.8118\r\n",
      "Train Epoch: 1 [56640/110534 (51%)]\tClassification Loss: 2.3179\r\n",
      "Train Epoch: 1 [56800/110534 (51%)]\tClassification Loss: 1.3025\r\n",
      "Train Epoch: 1 [56960/110534 (52%)]\tClassification Loss: 1.5443\r\n",
      "Train Epoch: 1 [57120/110534 (52%)]\tClassification Loss: 2.0485\r\n",
      "Train Epoch: 1 [57280/110534 (52%)]\tClassification Loss: 2.1768\r\n",
      "Train Epoch: 1 [57440/110534 (52%)]\tClassification Loss: 1.6643\r\n",
      "Test() called at batch_idx: 3600\r\n",
      "\r\n",
      "Test set: Average loss: 1.6403, Accuracy: 272/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [57600/110534 (52%)]\tClassification Loss: 1.4750\r\n",
      "Train Epoch: 1 [57760/110534 (52%)]\tClassification Loss: 1.4098\r\n",
      "Train Epoch: 1 [57920/110534 (52%)]\tClassification Loss: 1.4894\r\n",
      "Train Epoch: 1 [58080/110534 (53%)]\tClassification Loss: 1.5129\r\n",
      "Train Epoch: 1 [58240/110534 (53%)]\tClassification Loss: 1.5663\r\n",
      "Train Epoch: 1 [58400/110534 (53%)]\tClassification Loss: 1.8163\r\n",
      "Train Epoch: 1 [58560/110534 (53%)]\tClassification Loss: 1.7776\r\n",
      "Train Epoch: 1 [58720/110534 (53%)]\tClassification Loss: 1.5519\r\n",
      "Train Epoch: 1 [58880/110534 (53%)]\tClassification Loss: 1.4662\r\n",
      "Train Epoch: 1 [59040/110534 (53%)]\tClassification Loss: 1.5556\r\n",
      "Test() called at batch_idx: 3700\r\n",
      "\r\n",
      "Test set: Average loss: 1.6419, Accuracy: 277/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [59200/110534 (54%)]\tClassification Loss: 1.7597\r\n",
      "Train Epoch: 1 [59360/110534 (54%)]\tClassification Loss: 1.7816\r\n",
      "Train Epoch: 1 [59520/110534 (54%)]\tClassification Loss: 1.8950\r\n",
      "Train Epoch: 1 [59680/110534 (54%)]\tClassification Loss: 2.2434\r\n",
      "Train Epoch: 1 [59840/110534 (54%)]\tClassification Loss: 1.7897\r\n",
      "Train Epoch: 1 [60000/110534 (54%)]\tClassification Loss: 1.7524\r\n",
      "Train Epoch: 1 [60160/110534 (54%)]\tClassification Loss: 1.3986\r\n",
      "Train Epoch: 1 [60320/110534 (55%)]\tClassification Loss: 1.7545\r\n",
      "Train Epoch: 1 [60480/110534 (55%)]\tClassification Loss: 2.0260\r\n",
      "Train Epoch: 1 [60640/110534 (55%)]\tClassification Loss: 1.6133\r\n",
      "Test() called at batch_idx: 3800\r\n",
      "\r\n",
      "Test set: Average loss: 1.6159, Accuracy: 274/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [60800/110534 (55%)]\tClassification Loss: 1.6808\r\n",
      "Train Epoch: 1 [60960/110534 (55%)]\tClassification Loss: 2.2828\r\n",
      "Train Epoch: 1 [61120/110534 (55%)]\tClassification Loss: 2.0361\r\n",
      "Train Epoch: 1 [61280/110534 (55%)]\tClassification Loss: 1.9339\r\n",
      "Train Epoch: 1 [61440/110534 (56%)]\tClassification Loss: 1.8931\r\n",
      "Train Epoch: 1 [61600/110534 (56%)]\tClassification Loss: 1.6281\r\n",
      "Train Epoch: 1 [61760/110534 (56%)]\tClassification Loss: 1.4982\r\n",
      "Train Epoch: 1 [61920/110534 (56%)]\tClassification Loss: 1.9256\r\n",
      "Train Epoch: 1 [62080/110534 (56%)]\tClassification Loss: 1.5738\r\n",
      "Train Epoch: 1 [62240/110534 (56%)]\tClassification Loss: 2.4067\r\n",
      "Test() called at batch_idx: 3900\r\n",
      "\r\n",
      "Test set: Average loss: 1.6208, Accuracy: 279/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [62400/110534 (56%)]\tClassification Loss: 1.6853\r\n",
      "Train Epoch: 1 [62560/110534 (57%)]\tClassification Loss: 1.6058\r\n",
      "Train Epoch: 1 [62720/110534 (57%)]\tClassification Loss: 0.8683\r\n",
      "Train Epoch: 1 [62880/110534 (57%)]\tClassification Loss: 1.4727\r\n",
      "Train Epoch: 1 [63040/110534 (57%)]\tClassification Loss: 1.5783\r\n",
      "Train Epoch: 1 [63200/110534 (57%)]\tClassification Loss: 1.6711\r\n",
      "Train Epoch: 1 [63360/110534 (57%)]\tClassification Loss: 1.4703\r\n",
      "Train Epoch: 1 [63520/110534 (57%)]\tClassification Loss: 1.2652\r\n",
      "Train Epoch: 1 [63680/110534 (58%)]\tClassification Loss: 1.9552\r\n",
      "Train Epoch: 1 [63840/110534 (58%)]\tClassification Loss: 1.5613\r\n",
      "Test() called at batch_idx: 4000\r\n",
      "\r\n",
      "Test set: Average loss: 1.6098, Accuracy: 280/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [64000/110534 (58%)]\tClassification Loss: 1.8569\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_4000.pth.tar\r\n",
      "Train Epoch: 1 [64160/110534 (58%)]\tClassification Loss: 1.9680\r\n",
      "Train Epoch: 1 [64320/110534 (58%)]\tClassification Loss: 1.2801\r\n",
      "Train Epoch: 1 [64480/110534 (58%)]\tClassification Loss: 2.0192\r\n",
      "Train Epoch: 1 [64640/110534 (58%)]\tClassification Loss: 2.4042\r\n",
      "Train Epoch: 1 [64800/110534 (59%)]\tClassification Loss: 1.5572\r\n",
      "Train Epoch: 1 [64960/110534 (59%)]\tClassification Loss: 1.8042\r\n",
      "Train Epoch: 1 [65120/110534 (59%)]\tClassification Loss: 1.7358\r\n",
      "Train Epoch: 1 [65280/110534 (59%)]\tClassification Loss: 1.8526\r\n",
      "Train Epoch: 1 [65440/110534 (59%)]\tClassification Loss: 1.6248\r\n",
      "Test() called at batch_idx: 4100\r\n",
      "\r\n",
      "Test set: Average loss: 1.6198, Accuracy: 272/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [65600/110534 (59%)]\tClassification Loss: 1.5245\r\n",
      "Train Epoch: 1 [65760/110534 (59%)]\tClassification Loss: 2.2194\r\n",
      "Train Epoch: 1 [65920/110534 (60%)]\tClassification Loss: 1.6376\r\n",
      "Train Epoch: 1 [66080/110534 (60%)]\tClassification Loss: 1.5760\r\n",
      "Train Epoch: 1 [66240/110534 (60%)]\tClassification Loss: 1.7457\r\n",
      "Train Epoch: 1 [66400/110534 (60%)]\tClassification Loss: 1.8772\r\n",
      "Train Epoch: 1 [66560/110534 (60%)]\tClassification Loss: 2.0596\r\n",
      "Train Epoch: 1 [66720/110534 (60%)]\tClassification Loss: 1.5069\r\n",
      "Train Epoch: 1 [66880/110534 (61%)]\tClassification Loss: 1.2350\r\n",
      "Train Epoch: 1 [67040/110534 (61%)]\tClassification Loss: 1.8529\r\n",
      "Test() called at batch_idx: 4200\r\n",
      "\r\n",
      "Test set: Average loss: 1.6137, Accuracy: 280/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [67200/110534 (61%)]\tClassification Loss: 2.1354\r\n",
      "Train Epoch: 1 [67360/110534 (61%)]\tClassification Loss: 1.7506\r\n",
      "Train Epoch: 1 [67520/110534 (61%)]\tClassification Loss: 1.4176\r\n",
      "Train Epoch: 1 [67680/110534 (61%)]\tClassification Loss: 1.3653\r\n",
      "Train Epoch: 1 [67840/110534 (61%)]\tClassification Loss: 2.1186\r\n",
      "Train Epoch: 1 [68000/110534 (62%)]\tClassification Loss: 1.5168\r\n",
      "Train Epoch: 1 [68160/110534 (62%)]\tClassification Loss: 1.5737\r\n",
      "Train Epoch: 1 [68320/110534 (62%)]\tClassification Loss: 2.1764\r\n",
      "Train Epoch: 1 [68480/110534 (62%)]\tClassification Loss: 2.1558\r\n",
      "Train Epoch: 1 [68640/110534 (62%)]\tClassification Loss: 1.1005\r\n",
      "Test() called at batch_idx: 4300\r\n",
      "\r\n",
      "Test set: Average loss: 1.6071, Accuracy: 274/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [68800/110534 (62%)]\tClassification Loss: 1.9845\r\n",
      "Train Epoch: 1 [68960/110534 (62%)]\tClassification Loss: 1.2055\r\n",
      "Train Epoch: 1 [69120/110534 (63%)]\tClassification Loss: 1.3426\r\n",
      "Train Epoch: 1 [69280/110534 (63%)]\tClassification Loss: 1.5282\r\n",
      "Train Epoch: 1 [69440/110534 (63%)]\tClassification Loss: 1.6561\r\n",
      "Train Epoch: 1 [69600/110534 (63%)]\tClassification Loss: 1.3516\r\n",
      "Train Epoch: 1 [69760/110534 (63%)]\tClassification Loss: 1.8493\r\n",
      "Train Epoch: 1 [69920/110534 (63%)]\tClassification Loss: 1.4601\r\n",
      "Train Epoch: 1 [70080/110534 (63%)]\tClassification Loss: 1.2715\r\n",
      "Train Epoch: 1 [70240/110534 (64%)]\tClassification Loss: 1.3743\r\n",
      "Test() called at batch_idx: 4400\r\n",
      "\r\n",
      "Test set: Average loss: 1.5998, Accuracy: 280/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [70400/110534 (64%)]\tClassification Loss: 1.3655\r\n",
      "Train Epoch: 1 [70560/110534 (64%)]\tClassification Loss: 1.5211\r\n",
      "Train Epoch: 1 [70720/110534 (64%)]\tClassification Loss: 1.0888\r\n",
      "Train Epoch: 1 [70880/110534 (64%)]\tClassification Loss: 1.7649\r\n",
      "Train Epoch: 1 [71040/110534 (64%)]\tClassification Loss: 1.6192\r\n",
      "Train Epoch: 1 [71200/110534 (64%)]\tClassification Loss: 1.5642\r\n",
      "Train Epoch: 1 [71360/110534 (65%)]\tClassification Loss: 2.5651\r\n",
      "Train Epoch: 1 [71520/110534 (65%)]\tClassification Loss: 2.0115\r\n",
      "Train Epoch: 1 [71680/110534 (65%)]\tClassification Loss: 1.3826\r\n",
      "Train Epoch: 1 [71840/110534 (65%)]\tClassification Loss: 2.0861\r\n",
      "Test() called at batch_idx: 4500\r\n",
      "\r\n",
      "Test set: Average loss: 1.6331, Accuracy: 272/480 (57%)\r\n",
      "\r\n",
      "Train Epoch: 1 [72000/110534 (65%)]\tClassification Loss: 1.9056\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_4500.pth.tar\r\n",
      "Train Epoch: 1 [72160/110534 (65%)]\tClassification Loss: 1.8884\r\n",
      "Train Epoch: 1 [72320/110534 (65%)]\tClassification Loss: 1.7196\r\n",
      "Train Epoch: 1 [72480/110534 (66%)]\tClassification Loss: 1.7187\r\n",
      "Train Epoch: 1 [72640/110534 (66%)]\tClassification Loss: 1.5634\r\n",
      "Train Epoch: 1 [72800/110534 (66%)]\tClassification Loss: 1.3032\r\n",
      "Train Epoch: 1 [72960/110534 (66%)]\tClassification Loss: 1.7611\r\n",
      "Train Epoch: 1 [73120/110534 (66%)]\tClassification Loss: 1.7183\r\n",
      "Train Epoch: 1 [73280/110534 (66%)]\tClassification Loss: 1.4907\r\n",
      "Train Epoch: 1 [73440/110534 (66%)]\tClassification Loss: 1.6933\r\n",
      "Test() called at batch_idx: 4600\r\n",
      "\r\n",
      "Test set: Average loss: 1.6058, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [73600/110534 (67%)]\tClassification Loss: 1.8013\r\n",
      "Train Epoch: 1 [73760/110534 (67%)]\tClassification Loss: 1.5915\r\n",
      "Train Epoch: 1 [73920/110534 (67%)]\tClassification Loss: 1.4446\r\n",
      "Train Epoch: 1 [74080/110534 (67%)]\tClassification Loss: 1.9566\r\n",
      "Train Epoch: 1 [74240/110534 (67%)]\tClassification Loss: 1.5760\r\n",
      "Train Epoch: 1 [74400/110534 (67%)]\tClassification Loss: 1.6354\r\n",
      "Train Epoch: 1 [74560/110534 (67%)]\tClassification Loss: 1.2102\r\n",
      "Train Epoch: 1 [74720/110534 (68%)]\tClassification Loss: 1.4201\r\n",
      "Train Epoch: 1 [74880/110534 (68%)]\tClassification Loss: 1.8559\r\n",
      "Train Epoch: 1 [75040/110534 (68%)]\tClassification Loss: 1.7903\r\n",
      "Test() called at batch_idx: 4700\r\n",
      "\r\n",
      "Test set: Average loss: 1.5982, Accuracy: 278/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [75200/110534 (68%)]\tClassification Loss: 1.4632\r\n",
      "Train Epoch: 1 [75360/110534 (68%)]\tClassification Loss: 1.9520\r\n",
      "Train Epoch: 1 [75520/110534 (68%)]\tClassification Loss: 1.6847\r\n",
      "Train Epoch: 1 [75680/110534 (68%)]\tClassification Loss: 1.4763\r\n",
      "Train Epoch: 1 [75840/110534 (69%)]\tClassification Loss: 1.8607\r\n",
      "Train Epoch: 1 [76000/110534 (69%)]\tClassification Loss: 1.2944\r\n",
      "Train Epoch: 1 [76160/110534 (69%)]\tClassification Loss: 1.6553\r\n",
      "Train Epoch: 1 [76320/110534 (69%)]\tClassification Loss: 1.7274\r\n",
      "Train Epoch: 1 [76480/110534 (69%)]\tClassification Loss: 1.3292\r\n",
      "Train Epoch: 1 [76640/110534 (69%)]\tClassification Loss: 1.5313\r\n",
      "Test() called at batch_idx: 4800\r\n",
      "\r\n",
      "Test set: Average loss: 1.6018, Accuracy: 282/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [76800/110534 (69%)]\tClassification Loss: 2.0607\r\n",
      "Train Epoch: 1 [76960/110534 (70%)]\tClassification Loss: 1.3735\r\n",
      "Train Epoch: 1 [77120/110534 (70%)]\tClassification Loss: 1.3919\r\n",
      "Train Epoch: 1 [77280/110534 (70%)]\tClassification Loss: 1.9316\r\n",
      "Train Epoch: 1 [77440/110534 (70%)]\tClassification Loss: 1.5788\r\n",
      "Train Epoch: 1 [77600/110534 (70%)]\tClassification Loss: 1.6027\r\n",
      "Train Epoch: 1 [77760/110534 (70%)]\tClassification Loss: 1.6162\r\n",
      "Train Epoch: 1 [77920/110534 (70%)]\tClassification Loss: 1.7784\r\n",
      "Train Epoch: 1 [78080/110534 (71%)]\tClassification Loss: 1.8821\r\n",
      "Train Epoch: 1 [78240/110534 (71%)]\tClassification Loss: 1.9865\r\n",
      "Test() called at batch_idx: 4900\r\n",
      "\r\n",
      "Test set: Average loss: 1.5875, Accuracy: 281/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [78400/110534 (71%)]\tClassification Loss: 1.4988\r\n",
      "Train Epoch: 1 [78560/110534 (71%)]\tClassification Loss: 1.5991\r\n",
      "Train Epoch: 1 [78720/110534 (71%)]\tClassification Loss: 1.7230\r\n",
      "Train Epoch: 1 [78880/110534 (71%)]\tClassification Loss: 2.6391\r\n",
      "Train Epoch: 1 [79040/110534 (72%)]\tClassification Loss: 1.7691\r\n",
      "Train Epoch: 1 [79200/110534 (72%)]\tClassification Loss: 1.5004\r\n",
      "Train Epoch: 1 [79360/110534 (72%)]\tClassification Loss: 1.0870\r\n",
      "Train Epoch: 1 [79520/110534 (72%)]\tClassification Loss: 1.1192\r\n",
      "Train Epoch: 1 [79680/110534 (72%)]\tClassification Loss: 1.2844\r\n",
      "Train Epoch: 1 [79840/110534 (72%)]\tClassification Loss: 1.8335\r\n",
      "Test() called at batch_idx: 5000\r\n",
      "\r\n",
      "Test set: Average loss: 1.5798, Accuracy: 283/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [80000/110534 (72%)]\tClassification Loss: 1.5679\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_5000.pth.tar\r\n",
      "Train Epoch: 1 [80160/110534 (73%)]\tClassification Loss: 1.7153\r\n",
      "Train Epoch: 1 [80320/110534 (73%)]\tClassification Loss: 1.9416\r\n",
      "Train Epoch: 1 [80480/110534 (73%)]\tClassification Loss: 1.7625\r\n",
      "Train Epoch: 1 [80640/110534 (73%)]\tClassification Loss: 1.4315\r\n",
      "Train Epoch: 1 [80800/110534 (73%)]\tClassification Loss: 1.8694\r\n",
      "Train Epoch: 1 [80960/110534 (73%)]\tClassification Loss: 1.7210\r\n",
      "Train Epoch: 1 [81120/110534 (73%)]\tClassification Loss: 1.8247\r\n",
      "Train Epoch: 1 [81280/110534 (74%)]\tClassification Loss: 1.5848\r\n",
      "Train Epoch: 1 [81440/110534 (74%)]\tClassification Loss: 1.5514\r\n",
      "Test() called at batch_idx: 5100\r\n",
      "\r\n",
      "Test set: Average loss: 1.5818, Accuracy: 281/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [81600/110534 (74%)]\tClassification Loss: 1.6190\r\n",
      "Train Epoch: 1 [81760/110534 (74%)]\tClassification Loss: 1.5102\r\n",
      "Train Epoch: 1 [81920/110534 (74%)]\tClassification Loss: 1.1214\r\n",
      "Train Epoch: 1 [82080/110534 (74%)]\tClassification Loss: 1.6134\r\n",
      "Train Epoch: 1 [82240/110534 (74%)]\tClassification Loss: 1.3991\r\n",
      "Train Epoch: 1 [82400/110534 (75%)]\tClassification Loss: 2.7954\r\n",
      "Train Epoch: 1 [82560/110534 (75%)]\tClassification Loss: 1.1104\r\n",
      "Train Epoch: 1 [82720/110534 (75%)]\tClassification Loss: 1.7749\r\n",
      "Train Epoch: 1 [82880/110534 (75%)]\tClassification Loss: 1.4045\r\n",
      "Train Epoch: 1 [83040/110534 (75%)]\tClassification Loss: 1.1820\r\n",
      "Test() called at batch_idx: 5200\r\n",
      "\r\n",
      "Test set: Average loss: 1.6182, Accuracy: 276/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [83200/110534 (75%)]\tClassification Loss: 1.9322\r\n",
      "Train Epoch: 1 [83360/110534 (75%)]\tClassification Loss: 1.3383\r\n",
      "Train Epoch: 1 [83520/110534 (76%)]\tClassification Loss: 2.5358\r\n",
      "Train Epoch: 1 [83680/110534 (76%)]\tClassification Loss: 1.4439\r\n",
      "Train Epoch: 1 [83840/110534 (76%)]\tClassification Loss: 2.1788\r\n",
      "Train Epoch: 1 [84000/110534 (76%)]\tClassification Loss: 1.8272\r\n",
      "Train Epoch: 1 [84160/110534 (76%)]\tClassification Loss: 1.4984\r\n",
      "Train Epoch: 1 [84320/110534 (76%)]\tClassification Loss: 1.6131\r\n",
      "Train Epoch: 1 [84480/110534 (76%)]\tClassification Loss: 1.8943\r\n",
      "Train Epoch: 1 [84640/110534 (77%)]\tClassification Loss: 1.2921\r\n",
      "Test() called at batch_idx: 5300\r\n",
      "\r\n",
      "Test set: Average loss: 1.5819, Accuracy: 277/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [84800/110534 (77%)]\tClassification Loss: 1.8820\r\n",
      "Train Epoch: 1 [84960/110534 (77%)]\tClassification Loss: 1.5286\r\n",
      "Train Epoch: 1 [85120/110534 (77%)]\tClassification Loss: 1.3720\r\n",
      "Train Epoch: 1 [85280/110534 (77%)]\tClassification Loss: 1.6516\r\n",
      "Train Epoch: 1 [85440/110534 (77%)]\tClassification Loss: 1.5328\r\n",
      "Train Epoch: 1 [85600/110534 (77%)]\tClassification Loss: 1.4524\r\n",
      "Train Epoch: 1 [85760/110534 (78%)]\tClassification Loss: 1.6437\r\n",
      "Train Epoch: 1 [85920/110534 (78%)]\tClassification Loss: 1.6835\r\n",
      "Train Epoch: 1 [86080/110534 (78%)]\tClassification Loss: 1.4927\r\n",
      "Train Epoch: 1 [86240/110534 (78%)]\tClassification Loss: 1.3939\r\n",
      "Test() called at batch_idx: 5400\r\n",
      "\r\n",
      "Test set: Average loss: 1.5760, Accuracy: 284/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [86400/110534 (78%)]\tClassification Loss: 1.6826\r\n",
      "Train Epoch: 1 [86560/110534 (78%)]\tClassification Loss: 1.6016\r\n",
      "Train Epoch: 1 [86720/110534 (78%)]\tClassification Loss: 1.9412\r\n",
      "Train Epoch: 1 [86880/110534 (79%)]\tClassification Loss: 1.4870\r\n",
      "Train Epoch: 1 [87040/110534 (79%)]\tClassification Loss: 1.7825\r\n",
      "Train Epoch: 1 [87200/110534 (79%)]\tClassification Loss: 1.4124\r\n",
      "Train Epoch: 1 [87360/110534 (79%)]\tClassification Loss: 1.3607\r\n",
      "Train Epoch: 1 [87520/110534 (79%)]\tClassification Loss: 1.2215\r\n",
      "Train Epoch: 1 [87680/110534 (79%)]\tClassification Loss: 1.6311\r\n",
      "Train Epoch: 1 [87840/110534 (79%)]\tClassification Loss: 1.3077\r\n",
      "Test() called at batch_idx: 5500\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "\r\n",
      "Test set: Average loss: 1.5679, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 1 [88000/110534 (80%)]\tClassification Loss: 1.5546\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_5500.pth.tar\r\n",
      "Train Epoch: 1 [88160/110534 (80%)]\tClassification Loss: 1.7797\r\n",
      "Train Epoch: 1 [88320/110534 (80%)]\tClassification Loss: 1.2920\r\n",
      "Train Epoch: 1 [88480/110534 (80%)]\tClassification Loss: 1.6028\r\n",
      "Train Epoch: 1 [88640/110534 (80%)]\tClassification Loss: 2.7186\r\n",
      "Train Epoch: 1 [88800/110534 (80%)]\tClassification Loss: 2.1566\r\n",
      "Train Epoch: 1 [88960/110534 (80%)]\tClassification Loss: 1.9483\r\n",
      "Train Epoch: 1 [89120/110534 (81%)]\tClassification Loss: 1.1532\r\n",
      "Train Epoch: 1 [89280/110534 (81%)]\tClassification Loss: 1.1286\r\n",
      "Train Epoch: 1 [89440/110534 (81%)]\tClassification Loss: 1.1332\r\n",
      "Test() called at batch_idx: 5600\r\n",
      "\r\n",
      "Test set: Average loss: 1.6046, Accuracy: 283/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [89600/110534 (81%)]\tClassification Loss: 1.5669\r\n",
      "Train Epoch: 1 [89760/110534 (81%)]\tClassification Loss: 1.3388\r\n",
      "Train Epoch: 1 [89920/110534 (81%)]\tClassification Loss: 1.8136\r\n",
      "Train Epoch: 1 [90080/110534 (81%)]\tClassification Loss: 1.8047\r\n",
      "Train Epoch: 1 [90240/110534 (82%)]\tClassification Loss: 1.6239\r\n",
      "Train Epoch: 1 [90400/110534 (82%)]\tClassification Loss: 2.0041\r\n",
      "Train Epoch: 1 [90560/110534 (82%)]\tClassification Loss: 1.3715\r\n",
      "Train Epoch: 1 [90720/110534 (82%)]\tClassification Loss: 1.6062\r\n",
      "Train Epoch: 1 [90880/110534 (82%)]\tClassification Loss: 1.4254\r\n",
      "Train Epoch: 1 [91040/110534 (82%)]\tClassification Loss: 1.5812\r\n",
      "Test() called at batch_idx: 5700\r\n",
      "\r\n",
      "Test set: Average loss: 1.5628, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 1 [91200/110534 (83%)]\tClassification Loss: 1.8520\r\n",
      "Train Epoch: 1 [91360/110534 (83%)]\tClassification Loss: 1.7249\r\n",
      "Train Epoch: 1 [91520/110534 (83%)]\tClassification Loss: 1.7282\r\n",
      "Train Epoch: 1 [91680/110534 (83%)]\tClassification Loss: 1.6366\r\n",
      "Train Epoch: 1 [91840/110534 (83%)]\tClassification Loss: 1.3965\r\n",
      "Train Epoch: 1 [92000/110534 (83%)]\tClassification Loss: 1.0946\r\n",
      "Train Epoch: 1 [92160/110534 (83%)]\tClassification Loss: 1.4105\r\n",
      "Train Epoch: 1 [92320/110534 (84%)]\tClassification Loss: 1.9627\r\n",
      "Train Epoch: 1 [92480/110534 (84%)]\tClassification Loss: 1.4897\r\n",
      "Train Epoch: 1 [92640/110534 (84%)]\tClassification Loss: 1.5957\r\n",
      "Test() called at batch_idx: 5800\r\n",
      "\r\n",
      "Test set: Average loss: 1.5772, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 1 [92800/110534 (84%)]\tClassification Loss: 1.9902\r\n",
      "Train Epoch: 1 [92960/110534 (84%)]\tClassification Loss: 1.7533\r\n",
      "Train Epoch: 1 [93120/110534 (84%)]\tClassification Loss: 1.5868\r\n",
      "Train Epoch: 1 [93280/110534 (84%)]\tClassification Loss: 0.8880\r\n",
      "Train Epoch: 1 [93440/110534 (85%)]\tClassification Loss: 1.6050\r\n",
      "Train Epoch: 1 [93600/110534 (85%)]\tClassification Loss: 1.4778\r\n",
      "Train Epoch: 1 [93760/110534 (85%)]\tClassification Loss: 1.6325\r\n",
      "Train Epoch: 1 [93920/110534 (85%)]\tClassification Loss: 1.4494\r\n",
      "Train Epoch: 1 [94080/110534 (85%)]\tClassification Loss: 2.2528\r\n",
      "Train Epoch: 1 [94240/110534 (85%)]\tClassification Loss: 1.2215\r\n",
      "Test() called at batch_idx: 5900\r\n",
      "\r\n",
      "Test set: Average loss: 1.5721, Accuracy: 286/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 1 [94400/110534 (85%)]\tClassification Loss: 1.6622\r\n",
      "Train Epoch: 1 [94560/110534 (86%)]\tClassification Loss: 2.0308\r\n",
      "Train Epoch: 1 [94720/110534 (86%)]\tClassification Loss: 1.1379\r\n",
      "Train Epoch: 1 [94880/110534 (86%)]\tClassification Loss: 1.6681\r\n",
      "Train Epoch: 1 [95040/110534 (86%)]\tClassification Loss: 2.0068\r\n",
      "Train Epoch: 1 [95200/110534 (86%)]\tClassification Loss: 1.9355\r\n",
      "Train Epoch: 1 [95360/110534 (86%)]\tClassification Loss: 1.7866\r\n",
      "Train Epoch: 1 [95520/110534 (86%)]\tClassification Loss: 2.3920\r\n",
      "Train Epoch: 1 [95680/110534 (87%)]\tClassification Loss: 1.4840\r\n",
      "Train Epoch: 1 [95840/110534 (87%)]\tClassification Loss: 2.0900\r\n",
      "Test() called at batch_idx: 6000\r\n",
      "\r\n",
      "Test set: Average loss: 1.5819, Accuracy: 281/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [96000/110534 (87%)]\tClassification Loss: 1.3229\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_6000.pth.tar\r\n",
      "Train Epoch: 1 [96160/110534 (87%)]\tClassification Loss: 1.7793\r\n",
      "Train Epoch: 1 [96320/110534 (87%)]\tClassification Loss: 1.3747\r\n",
      "Train Epoch: 1 [96480/110534 (87%)]\tClassification Loss: 1.8575\r\n",
      "Train Epoch: 1 [96640/110534 (87%)]\tClassification Loss: 1.2186\r\n",
      "Train Epoch: 1 [96800/110534 (88%)]\tClassification Loss: 1.1002\r\n",
      "Train Epoch: 1 [96960/110534 (88%)]\tClassification Loss: 1.5424\r\n",
      "Train Epoch: 1 [97120/110534 (88%)]\tClassification Loss: 2.5749\r\n",
      "Train Epoch: 1 [97280/110534 (88%)]\tClassification Loss: 1.6237\r\n",
      "Train Epoch: 1 [97440/110534 (88%)]\tClassification Loss: 1.4471\r\n",
      "Test() called at batch_idx: 6100\r\n",
      "\r\n",
      "Test set: Average loss: 1.5580, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 1 [97600/110534 (88%)]\tClassification Loss: 2.0561\r\n",
      "Train Epoch: 1 [97760/110534 (88%)]\tClassification Loss: 1.9686\r\n",
      "Train Epoch: 1 [97920/110534 (89%)]\tClassification Loss: 1.4144\r\n",
      "Train Epoch: 1 [98080/110534 (89%)]\tClassification Loss: 1.5259\r\n",
      "Train Epoch: 1 [98240/110534 (89%)]\tClassification Loss: 1.8888\r\n",
      "Train Epoch: 1 [98400/110534 (89%)]\tClassification Loss: 1.6932\r\n",
      "Train Epoch: 1 [98560/110534 (89%)]\tClassification Loss: 2.5929\r\n",
      "Train Epoch: 1 [98720/110534 (89%)]\tClassification Loss: 1.6969\r\n",
      "Train Epoch: 1 [98880/110534 (89%)]\tClassification Loss: 1.8701\r\n",
      "Train Epoch: 1 [99040/110534 (90%)]\tClassification Loss: 2.1285\r\n",
      "Test() called at batch_idx: 6200\r\n",
      "\r\n",
      "Test set: Average loss: 1.5606, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 1 [99200/110534 (90%)]\tClassification Loss: 2.0225\r\n",
      "Train Epoch: 1 [99360/110534 (90%)]\tClassification Loss: 2.0902\r\n",
      "Train Epoch: 1 [99520/110534 (90%)]\tClassification Loss: 1.8250\r\n",
      "Train Epoch: 1 [99680/110534 (90%)]\tClassification Loss: 1.7677\r\n",
      "Train Epoch: 1 [99840/110534 (90%)]\tClassification Loss: 1.9327\r\n",
      "Train Epoch: 1 [100000/110534 (90%)]\tClassification Loss: 1.6139\r\n",
      "Train Epoch: 1 [100160/110534 (91%)]\tClassification Loss: 1.4591\r\n",
      "Train Epoch: 1 [100320/110534 (91%)]\tClassification Loss: 2.0663\r\n",
      "Train Epoch: 1 [100480/110534 (91%)]\tClassification Loss: 1.3378\r\n",
      "Train Epoch: 1 [100640/110534 (91%)]\tClassification Loss: 1.6896\r\n",
      "Test() called at batch_idx: 6300\r\n",
      "\r\n",
      "Test set: Average loss: 1.5451, Accuracy: 282/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [100800/110534 (91%)]\tClassification Loss: 2.0398\r\n",
      "Train Epoch: 1 [100960/110534 (91%)]\tClassification Loss: 1.3799\r\n",
      "Train Epoch: 1 [101120/110534 (91%)]\tClassification Loss: 1.4496\r\n",
      "Train Epoch: 1 [101280/110534 (92%)]\tClassification Loss: 1.3352\r\n",
      "Train Epoch: 1 [101440/110534 (92%)]\tClassification Loss: 1.7972\r\n",
      "Train Epoch: 1 [101600/110534 (92%)]\tClassification Loss: 1.7149\r\n",
      "Train Epoch: 1 [101760/110534 (92%)]\tClassification Loss: 1.2161\r\n",
      "Train Epoch: 1 [101920/110534 (92%)]\tClassification Loss: 1.5083\r\n",
      "Train Epoch: 1 [102080/110534 (92%)]\tClassification Loss: 1.8235\r\n",
      "Train Epoch: 1 [102240/110534 (93%)]\tClassification Loss: 1.2081\r\n",
      "Test() called at batch_idx: 6400\r\n",
      "\r\n",
      "Test set: Average loss: 1.5508, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 1 [102400/110534 (93%)]\tClassification Loss: 1.3217\r\n",
      "Train Epoch: 1 [102560/110534 (93%)]\tClassification Loss: 1.5134\r\n",
      "Train Epoch: 1 [102720/110534 (93%)]\tClassification Loss: 1.5969\r\n",
      "Train Epoch: 1 [102880/110534 (93%)]\tClassification Loss: 1.8738\r\n",
      "Train Epoch: 1 [103040/110534 (93%)]\tClassification Loss: 1.6617\r\n",
      "Train Epoch: 1 [103200/110534 (93%)]\tClassification Loss: 1.6203\r\n",
      "Train Epoch: 1 [103360/110534 (94%)]\tClassification Loss: 1.8457\r\n",
      "Train Epoch: 1 [103520/110534 (94%)]\tClassification Loss: 1.5961\r\n",
      "Train Epoch: 1 [103680/110534 (94%)]\tClassification Loss: 1.1892\r\n",
      "Train Epoch: 1 [103840/110534 (94%)]\tClassification Loss: 1.5118\r\n",
      "Test() called at batch_idx: 6500\r\n",
      "Traceback (most recent call last):\r\n",
      "\r\n",
      "Test set: Average loss: 1.5400, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 1 [104000/110534 (94%)]\tClassification Loss: 1.4382\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_6500.pth.tar\r\n",
      "Train Epoch: 1 [104160/110534 (94%)]\tClassification Loss: 2.0302\r\n",
      "Train Epoch: 1 [104320/110534 (94%)]\tClassification Loss: 2.1347\r\n",
      "Train Epoch: 1 [104480/110534 (95%)]\tClassification Loss: 1.8514\r\n",
      "Train Epoch: 1 [104640/110534 (95%)]\tClassification Loss: 1.3208\r\n",
      "Train Epoch: 1 [104800/110534 (95%)]\tClassification Loss: 1.4034\r\n",
      "Train Epoch: 1 [104960/110534 (95%)]\tClassification Loss: 1.0149\r\n",
      "Train Epoch: 1 [105120/110534 (95%)]\tClassification Loss: 1.2007\r\n",
      "Train Epoch: 1 [105280/110534 (95%)]\tClassification Loss: 1.6492\r\n",
      "Train Epoch: 1 [105440/110534 (95%)]\tClassification Loss: 1.6495\r\n",
      "Test() called at batch_idx: 6600\r\n",
      "\r\n",
      "Test set: Average loss: 1.5485, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 1 [105600/110534 (96%)]\tClassification Loss: 1.3875\r\n",
      "Train Epoch: 1 [105760/110534 (96%)]\tClassification Loss: 1.5547\r\n",
      "Train Epoch: 1 [105920/110534 (96%)]\tClassification Loss: 1.0012\r\n",
      "Train Epoch: 1 [106080/110534 (96%)]\tClassification Loss: 1.6681\r\n",
      "Train Epoch: 1 [106240/110534 (96%)]\tClassification Loss: 1.6806\r\n",
      "Train Epoch: 1 [106400/110534 (96%)]\tClassification Loss: 1.4221\r\n",
      "Train Epoch: 1 [106560/110534 (96%)]\tClassification Loss: 1.3805\r\n",
      "Train Epoch: 1 [106720/110534 (97%)]\tClassification Loss: 1.1886\r\n",
      "Train Epoch: 1 [106880/110534 (97%)]\tClassification Loss: 1.6801\r\n",
      "Train Epoch: 1 [107040/110534 (97%)]\tClassification Loss: 1.4404\r\n",
      "Test() called at batch_idx: 6700\r\n",
      "\r\n",
      "Test set: Average loss: 1.5441, Accuracy: 289/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 1 [107200/110534 (97%)]\tClassification Loss: 1.5543\r\n",
      "Train Epoch: 1 [107360/110534 (97%)]\tClassification Loss: 1.6777\r\n",
      "Train Epoch: 1 [107520/110534 (97%)]\tClassification Loss: 2.2734\r\n",
      "Train Epoch: 1 [107680/110534 (97%)]\tClassification Loss: 1.6086\r\n",
      "Train Epoch: 1 [107840/110534 (98%)]\tClassification Loss: 1.4456\r\n",
      "Train Epoch: 1 [108000/110534 (98%)]\tClassification Loss: 1.8062\r\n",
      "Train Epoch: 1 [108160/110534 (98%)]\tClassification Loss: 2.1319\r\n",
      "Train Epoch: 1 [108320/110534 (98%)]\tClassification Loss: 1.1392\r\n",
      "Train Epoch: 1 [108480/110534 (98%)]\tClassification Loss: 1.0064\r\n",
      "Train Epoch: 1 [108640/110534 (98%)]\tClassification Loss: 0.9760\r\n",
      "Test() called at batch_idx: 6800\r\n",
      "\r\n",
      "Test set: Average loss: 1.5472, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 1 [108800/110534 (98%)]\tClassification Loss: 1.5655\r\n",
      "Train Epoch: 1 [108960/110534 (99%)]\tClassification Loss: 1.9539\r\n",
      "Train Epoch: 1 [109120/110534 (99%)]\tClassification Loss: 1.7042\r\n",
      "Train Epoch: 1 [109280/110534 (99%)]\tClassification Loss: 1.1305\r\n",
      "Train Epoch: 1 [109440/110534 (99%)]\tClassification Loss: 1.3122\r\n",
      "Train Epoch: 1 [109600/110534 (99%)]\tClassification Loss: 1.3366\r\n",
      "Train Epoch: 1 [109760/110534 (99%)]\tClassification Loss: 1.7579\r\n",
      "Train Epoch: 1 [109920/110534 (99%)]\tClassification Loss: 1.7176\r\n",
      "Train Epoch: 1 [110080/110534 (100%)]\tClassification Loss: 2.0183\r\n",
      "Train Epoch: 1 [110240/110534 (100%)]\tClassification Loss: 1.4912\r\n",
      "Test() called at batch_idx: 6900\r\n",
      "\r\n",
      "Test set: Average loss: 1.5456, Accuracy: 280/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 1 [110400/110534 (100%)]\tClassification Loss: 1.3113\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_final.pth.tar\r\n",
      "Test() called at batch_idx: 0\r\n",
      "\r\n",
      "Test set: Average loss: 1.5496, Accuracy: 282/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [0/110534 (0%)]\tClassification Loss: 1.5192\r\n",
      "Train Epoch: 2 [160/110534 (0%)]\tClassification Loss: 1.6233\r\n",
      "Train Epoch: 2 [320/110534 (0%)]\tClassification Loss: 0.9120\r\n",
      "Train Epoch: 2 [480/110534 (0%)]\tClassification Loss: 2.4696\r\n",
      "Train Epoch: 2 [640/110534 (1%)]\tClassification Loss: 1.3313\r\n",
      "Train Epoch: 2 [800/110534 (1%)]\tClassification Loss: 1.3117\r\n",
      "Train Epoch: 2 [960/110534 (1%)]\tClassification Loss: 1.4225\r\n",
      "Train Epoch: 2 [1120/110534 (1%)]\tClassification Loss: 1.3630\r\n",
      "Train Epoch: 2 [1280/110534 (1%)]\tClassification Loss: 1.5532\r\n",
      "Train Epoch: 2 [1440/110534 (1%)]\tClassification Loss: 0.8219\r\n",
      "Test() called at batch_idx: 100\r\n",
      "\r\n",
      "Test set: Average loss: 1.5323, Accuracy: 290/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [1600/110534 (1%)]\tClassification Loss: 1.2283\r\n",
      "Train Epoch: 2 [1760/110534 (2%)]\tClassification Loss: 1.7782\r\n",
      "Train Epoch: 2 [1920/110534 (2%)]\tClassification Loss: 1.1535\r\n",
      "Train Epoch: 2 [2080/110534 (2%)]\tClassification Loss: 1.5839\r\n",
      "Train Epoch: 2 [2240/110534 (2%)]\tClassification Loss: 2.0442\r\n",
      "Train Epoch: 2 [2400/110534 (2%)]\tClassification Loss: 1.2676\r\n",
      "Train Epoch: 2 [2560/110534 (2%)]\tClassification Loss: 2.4441\r\n",
      "Train Epoch: 2 [2720/110534 (2%)]\tClassification Loss: 2.1747\r\n",
      "Train Epoch: 2 [2880/110534 (3%)]\tClassification Loss: 1.8216\r\n",
      "Train Epoch: 2 [3040/110534 (3%)]\tClassification Loss: 2.1121\r\n",
      "Test() called at batch_idx: 200\r\n",
      "\r\n",
      "Test set: Average loss: 1.5426, Accuracy: 279/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 2 [3200/110534 (3%)]\tClassification Loss: 1.4870\r\n",
      "Train Epoch: 2 [3360/110534 (3%)]\tClassification Loss: 1.7992\r\n",
      "Train Epoch: 2 [3520/110534 (3%)]\tClassification Loss: 1.6971\r\n",
      "Train Epoch: 2 [3680/110534 (3%)]\tClassification Loss: 1.6810\r\n",
      "Train Epoch: 2 [3840/110534 (3%)]\tClassification Loss: 1.3791\r\n",
      "Train Epoch: 2 [4000/110534 (4%)]\tClassification Loss: 1.8112\r\n",
      "Train Epoch: 2 [4160/110534 (4%)]\tClassification Loss: 1.6940\r\n",
      "Train Epoch: 2 [4320/110534 (4%)]\tClassification Loss: 1.1207\r\n",
      "Train Epoch: 2 [4480/110534 (4%)]\tClassification Loss: 1.0320\r\n",
      "Train Epoch: 2 [4640/110534 (4%)]\tClassification Loss: 1.3888\r\n",
      "Test() called at batch_idx: 300\r\n",
      "\r\n",
      "Test set: Average loss: 1.5588, Accuracy: 286/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [4800/110534 (4%)]\tClassification Loss: 2.3912\r\n",
      "Train Epoch: 2 [4960/110534 (4%)]\tClassification Loss: 1.3812\r\n",
      "Train Epoch: 2 [5120/110534 (5%)]\tClassification Loss: 2.2474\r\n",
      "Train Epoch: 2 [5280/110534 (5%)]\tClassification Loss: 1.3407\r\n",
      "Train Epoch: 2 [5440/110534 (5%)]\tClassification Loss: 1.3137\r\n",
      "Train Epoch: 2 [5600/110534 (5%)]\tClassification Loss: 1.3267\r\n",
      "Train Epoch: 2 [5760/110534 (5%)]\tClassification Loss: 1.7485\r\n",
      "Train Epoch: 2 [5920/110534 (5%)]\tClassification Loss: 1.3001\r\n",
      "Train Epoch: 2 [6080/110534 (6%)]\tClassification Loss: 1.3782\r\n",
      "Train Epoch: 2 [6240/110534 (6%)]\tClassification Loss: 1.2332\r\n",
      "Test() called at batch_idx: 400\r\n",
      "\r\n",
      "Test set: Average loss: 1.5352, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [6400/110534 (6%)]\tClassification Loss: 1.1904\r\n",
      "Train Epoch: 2 [6560/110534 (6%)]\tClassification Loss: 2.4005\r\n",
      "Train Epoch: 2 [6720/110534 (6%)]\tClassification Loss: 1.5001\r\n",
      "Train Epoch: 2 [6880/110534 (6%)]\tClassification Loss: 2.0343\r\n",
      "Train Epoch: 2 [7040/110534 (6%)]\tClassification Loss: 1.3862\r\n",
      "Train Epoch: 2 [7200/110534 (7%)]\tClassification Loss: 1.4414\r\n",
      "Train Epoch: 2 [7360/110534 (7%)]\tClassification Loss: 1.7518\r\n",
      "Train Epoch: 2 [7520/110534 (7%)]\tClassification Loss: 1.1448\r\n",
      "Train Epoch: 2 [7680/110534 (7%)]\tClassification Loss: 1.4287\r\n",
      "Train Epoch: 2 [7840/110534 (7%)]\tClassification Loss: 1.9707\r\n",
      "Test() called at batch_idx: 500\r\n",
      "\r\n",
      "Test set: Average loss: 1.5497, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [8000/110534 (7%)]\tClassification Loss: 1.3096\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_500.pth.tar\r\n",
      "Train Epoch: 2 [8160/110534 (7%)]\tClassification Loss: 1.5281\r\n",
      "Train Epoch: 2 [8320/110534 (8%)]\tClassification Loss: 1.7188\r\n",
      "Train Epoch: 2 [8480/110534 (8%)]\tClassification Loss: 1.8914\r\n",
      "Train Epoch: 2 [8640/110534 (8%)]\tClassification Loss: 1.5202\r\n",
      "Train Epoch: 2 [8800/110534 (8%)]\tClassification Loss: 1.5870\r\n",
      "Train Epoch: 2 [8960/110534 (8%)]\tClassification Loss: 1.7793\r\n",
      "Train Epoch: 2 [9120/110534 (8%)]\tClassification Loss: 1.7827\r\n",
      "Train Epoch: 2 [9280/110534 (8%)]\tClassification Loss: 1.4529\r\n",
      "Train Epoch: 2 [9440/110534 (9%)]\tClassification Loss: 1.6144\r\n",
      "Test() called at batch_idx: 600\r\n",
      "\r\n",
      "Test set: Average loss: 1.5387, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [9600/110534 (9%)]\tClassification Loss: 2.0460\r\n",
      "Train Epoch: 2 [9760/110534 (9%)]\tClassification Loss: 1.1835\r\n",
      "Train Epoch: 2 [9920/110534 (9%)]\tClassification Loss: 1.8684\r\n",
      "Train Epoch: 2 [10080/110534 (9%)]\tClassification Loss: 1.8324\r\n",
      "Train Epoch: 2 [10240/110534 (9%)]\tClassification Loss: 1.5504\r\n",
      "Train Epoch: 2 [10400/110534 (9%)]\tClassification Loss: 1.4467\r\n",
      "Train Epoch: 2 [10560/110534 (10%)]\tClassification Loss: 1.5608\r\n",
      "Train Epoch: 2 [10720/110534 (10%)]\tClassification Loss: 2.0252\r\n",
      "Train Epoch: 2 [10880/110534 (10%)]\tClassification Loss: 1.7963\r\n",
      "Train Epoch: 2 [11040/110534 (10%)]\tClassification Loss: 1.4297\r\n",
      "Test() called at batch_idx: 700\r\n",
      "\r\n",
      "Test set: Average loss: 1.5351, Accuracy: 291/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [11200/110534 (10%)]\tClassification Loss: 1.6564\r\n",
      "Train Epoch: 2 [11360/110534 (10%)]\tClassification Loss: 1.4948\r\n",
      "Train Epoch: 2 [11520/110534 (10%)]\tClassification Loss: 1.7936\r\n",
      "Train Epoch: 2 [11680/110534 (11%)]\tClassification Loss: 1.4521\r\n",
      "Train Epoch: 2 [11840/110534 (11%)]\tClassification Loss: 1.5000\r\n",
      "Train Epoch: 2 [12000/110534 (11%)]\tClassification Loss: 1.6954\r\n",
      "Train Epoch: 2 [12160/110534 (11%)]\tClassification Loss: 1.4492\r\n",
      "Train Epoch: 2 [12320/110534 (11%)]\tClassification Loss: 1.3849\r\n",
      "Train Epoch: 2 [12480/110534 (11%)]\tClassification Loss: 1.6035\r\n",
      "Train Epoch: 2 [12640/110534 (11%)]\tClassification Loss: 2.0355\r\n",
      "Test() called at batch_idx: 800\r\n",
      "\r\n",
      "Test set: Average loss: 1.5350, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [12800/110534 (12%)]\tClassification Loss: 1.5587\r\n",
      "Train Epoch: 2 [12960/110534 (12%)]\tClassification Loss: 1.7881\r\n",
      "Train Epoch: 2 [13120/110534 (12%)]\tClassification Loss: 1.7606\r\n",
      "Train Epoch: 2 [13280/110534 (12%)]\tClassification Loss: 1.5187\r\n",
      "Train Epoch: 2 [13440/110534 (12%)]\tClassification Loss: 2.1775\r\n",
      "Train Epoch: 2 [13600/110534 (12%)]\tClassification Loss: 1.4937\r\n",
      "Train Epoch: 2 [13760/110534 (12%)]\tClassification Loss: 1.3152\r\n",
      "Train Epoch: 2 [13920/110534 (13%)]\tClassification Loss: 1.2340\r\n",
      "Train Epoch: 2 [14080/110534 (13%)]\tClassification Loss: 1.3590\r\n",
      "Train Epoch: 2 [14240/110534 (13%)]\tClassification Loss: 2.3261\r\n",
      "Test() called at batch_idx: 900\r\n",
      "\r\n",
      "Test set: Average loss: 1.5461, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [14400/110534 (13%)]\tClassification Loss: 1.0908\r\n",
      "Train Epoch: 2 [14560/110534 (13%)]\tClassification Loss: 1.2515\r\n",
      "Train Epoch: 2 [14720/110534 (13%)]\tClassification Loss: 1.2108\r\n",
      "Train Epoch: 2 [14880/110534 (13%)]\tClassification Loss: 1.5018\r\n",
      "Train Epoch: 2 [15040/110534 (14%)]\tClassification Loss: 1.2475\r\n",
      "Train Epoch: 2 [15200/110534 (14%)]\tClassification Loss: 1.1653\r\n",
      "Train Epoch: 2 [15360/110534 (14%)]\tClassification Loss: 1.3563\r\n",
      "Train Epoch: 2 [15520/110534 (14%)]\tClassification Loss: 1.4104\r\n",
      "Train Epoch: 2 [15680/110534 (14%)]\tClassification Loss: 2.4621\r\n",
      "Train Epoch: 2 [15840/110534 (14%)]\tClassification Loss: 1.4902\r\n",
      "Test() called at batch_idx: 1000\r\n",
      "\r\n",
      "Test set: Average loss: 1.5451, Accuracy: 282/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [16000/110534 (14%)]\tClassification Loss: 1.1629\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1000.pth.tar\r\n",
      "Train Epoch: 2 [16160/110534 (15%)]\tClassification Loss: 1.4158\r\n",
      "Train Epoch: 2 [16320/110534 (15%)]\tClassification Loss: 2.2466\r\n",
      "Train Epoch: 2 [16480/110534 (15%)]\tClassification Loss: 1.3272\r\n",
      "Train Epoch: 2 [16640/110534 (15%)]\tClassification Loss: 1.2589\r\n",
      "Train Epoch: 2 [16800/110534 (15%)]\tClassification Loss: 1.5633\r\n",
      "Train Epoch: 2 [16960/110534 (15%)]\tClassification Loss: 1.7900\r\n",
      "Train Epoch: 2 [17120/110534 (15%)]\tClassification Loss: 2.1250\r\n",
      "Train Epoch: 2 [17280/110534 (16%)]\tClassification Loss: 1.1840\r\n",
      "Train Epoch: 2 [17440/110534 (16%)]\tClassification Loss: 1.4877\r\n",
      "Test() called at batch_idx: 1100\r\n",
      "\r\n",
      "Test set: Average loss: 1.5463, Accuracy: 280/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 2 [17600/110534 (16%)]\tClassification Loss: 1.1888\r\n",
      "Train Epoch: 2 [17760/110534 (16%)]\tClassification Loss: 1.0741\r\n",
      "Train Epoch: 2 [17920/110534 (16%)]\tClassification Loss: 1.3753\r\n",
      "Train Epoch: 2 [18080/110534 (16%)]\tClassification Loss: 1.8777\r\n",
      "Train Epoch: 2 [18240/110534 (17%)]\tClassification Loss: 2.1056\r\n",
      "Train Epoch: 2 [18400/110534 (17%)]\tClassification Loss: 1.7591\r\n",
      "Train Epoch: 2 [18560/110534 (17%)]\tClassification Loss: 1.6114\r\n",
      "Train Epoch: 2 [18720/110534 (17%)]\tClassification Loss: 2.3862\r\n",
      "Train Epoch: 2 [18880/110534 (17%)]\tClassification Loss: 1.2382\r\n",
      "Train Epoch: 2 [19040/110534 (17%)]\tClassification Loss: 1.8982\r\n",
      "Test() called at batch_idx: 1200\r\n",
      "\r\n",
      "Test set: Average loss: 1.5291, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [19200/110534 (17%)]\tClassification Loss: 1.2198\r\n",
      "Train Epoch: 2 [19360/110534 (18%)]\tClassification Loss: 1.4409\r\n",
      "Train Epoch: 2 [19520/110534 (18%)]\tClassification Loss: 1.9826\r\n",
      "Train Epoch: 2 [19680/110534 (18%)]\tClassification Loss: 1.7698\r\n",
      "Train Epoch: 2 [19840/110534 (18%)]\tClassification Loss: 1.2724\r\n",
      "Train Epoch: 2 [20000/110534 (18%)]\tClassification Loss: 1.7632\r\n",
      "Train Epoch: 2 [20160/110534 (18%)]\tClassification Loss: 1.9923\r\n",
      "Train Epoch: 2 [20320/110534 (18%)]\tClassification Loss: 1.0792\r\n",
      "Train Epoch: 2 [20480/110534 (19%)]\tClassification Loss: 1.5469\r\n",
      "Train Epoch: 2 [20640/110534 (19%)]\tClassification Loss: 2.3698\r\n",
      "Test() called at batch_idx: 1300\r\n",
      "\r\n",
      "Test set: Average loss: 1.5447, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [20800/110534 (19%)]\tClassification Loss: 2.1871\r\n",
      "Train Epoch: 2 [20960/110534 (19%)]\tClassification Loss: 1.8623\r\n",
      "Train Epoch: 2 [21120/110534 (19%)]\tClassification Loss: 2.1791\r\n",
      "Train Epoch: 2 [21280/110534 (19%)]\tClassification Loss: 1.4789\r\n",
      "Train Epoch: 2 [21440/110534 (19%)]\tClassification Loss: 1.4825\r\n",
      "Train Epoch: 2 [21600/110534 (20%)]\tClassification Loss: 1.4738\r\n",
      "Train Epoch: 2 [21760/110534 (20%)]\tClassification Loss: 1.3335\r\n",
      "Train Epoch: 2 [21920/110534 (20%)]\tClassification Loss: 1.6944\r\n",
      "Train Epoch: 2 [22080/110534 (20%)]\tClassification Loss: 2.1464\r\n",
      "Train Epoch: 2 [22240/110534 (20%)]\tClassification Loss: 1.4057\r\n",
      "Test() called at batch_idx: 1400\r\n",
      "\r\n",
      "Test set: Average loss: 1.5347, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [22400/110534 (20%)]\tClassification Loss: 1.7423\r\n",
      "Train Epoch: 2 [22560/110534 (20%)]\tClassification Loss: 1.5723\r\n",
      "Train Epoch: 2 [22720/110534 (21%)]\tClassification Loss: 0.9686\r\n",
      "Train Epoch: 2 [22880/110534 (21%)]\tClassification Loss: 1.3363\r\n",
      "Train Epoch: 2 [23040/110534 (21%)]\tClassification Loss: 1.4237\r\n",
      "Train Epoch: 2 [23200/110534 (21%)]\tClassification Loss: 1.9254\r\n",
      "Train Epoch: 2 [23360/110534 (21%)]\tClassification Loss: 1.5823\r\n",
      "Train Epoch: 2 [23520/110534 (21%)]\tClassification Loss: 1.4688\r\n",
      "Train Epoch: 2 [23680/110534 (21%)]\tClassification Loss: 1.3104\r\n",
      "Train Epoch: 2 [23840/110534 (22%)]\tClassification Loss: 2.1860\r\n",
      "Test() called at batch_idx: 1500\r\n",
      "\r\n",
      "Test set: Average loss: 1.5410, Accuracy: 292/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [24000/110534 (22%)]\tClassification Loss: 1.0336\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1500.pth.tar\r\n",
      "Train Epoch: 2 [24160/110534 (22%)]\tClassification Loss: 1.6055\r\n",
      "Train Epoch: 2 [24320/110534 (22%)]\tClassification Loss: 1.6249\r\n",
      "Train Epoch: 2 [24480/110534 (22%)]\tClassification Loss: 1.4355\r\n",
      "Train Epoch: 2 [24640/110534 (22%)]\tClassification Loss: 1.5968\r\n",
      "Train Epoch: 2 [24800/110534 (22%)]\tClassification Loss: 1.5381\r\n",
      "Train Epoch: 2 [24960/110534 (23%)]\tClassification Loss: 1.5728\r\n",
      "Train Epoch: 2 [25120/110534 (23%)]\tClassification Loss: 0.9547\r\n",
      "Train Epoch: 2 [25280/110534 (23%)]\tClassification Loss: 1.5954\r\n",
      "Train Epoch: 2 [25440/110534 (23%)]\tClassification Loss: 1.7848\r\n",
      "Test() called at batch_idx: 1600\r\n",
      "\r\n",
      "Test set: Average loss: 1.5553, Accuracy: 278/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 2 [25600/110534 (23%)]\tClassification Loss: 1.0974\r\n",
      "Train Epoch: 2 [25760/110534 (23%)]\tClassification Loss: 1.5316\r\n",
      "Train Epoch: 2 [25920/110534 (23%)]\tClassification Loss: 1.4370\r\n",
      "Train Epoch: 2 [26080/110534 (24%)]\tClassification Loss: 1.3958\r\n",
      "Train Epoch: 2 [26240/110534 (24%)]\tClassification Loss: 1.9319\r\n",
      "Train Epoch: 2 [26400/110534 (24%)]\tClassification Loss: 2.0901\r\n",
      "Train Epoch: 2 [26560/110534 (24%)]\tClassification Loss: 1.9840\r\n",
      "Train Epoch: 2 [26720/110534 (24%)]\tClassification Loss: 1.8553\r\n",
      "Train Epoch: 2 [26880/110534 (24%)]\tClassification Loss: 1.8556\r\n",
      "Train Epoch: 2 [27040/110534 (24%)]\tClassification Loss: 1.9273\r\n",
      "Test() called at batch_idx: 1700\r\n",
      "\r\n",
      "Test set: Average loss: 1.5283, Accuracy: 290/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [27200/110534 (25%)]\tClassification Loss: 1.1764\r\n",
      "Train Epoch: 2 [27360/110534 (25%)]\tClassification Loss: 1.1940\r\n",
      "Train Epoch: 2 [27520/110534 (25%)]\tClassification Loss: 1.2342\r\n",
      "Train Epoch: 2 [27680/110534 (25%)]\tClassification Loss: 1.9285\r\n",
      "Train Epoch: 2 [27840/110534 (25%)]\tClassification Loss: 2.2549\r\n",
      "Train Epoch: 2 [28000/110534 (25%)]\tClassification Loss: 1.7462\r\n",
      "Train Epoch: 2 [28160/110534 (25%)]\tClassification Loss: 1.8868\r\n",
      "Train Epoch: 2 [28320/110534 (26%)]\tClassification Loss: 2.5257\r\n",
      "Train Epoch: 2 [28480/110534 (26%)]\tClassification Loss: 0.8985\r\n",
      "Train Epoch: 2 [28640/110534 (26%)]\tClassification Loss: 1.3013\r\n",
      "Test() called at batch_idx: 1800\r\n",
      "\r\n",
      "Test set: Average loss: 1.5322, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [28800/110534 (26%)]\tClassification Loss: 1.3972\r\n",
      "Train Epoch: 2 [28960/110534 (26%)]\tClassification Loss: 2.0741\r\n",
      "Train Epoch: 2 [29120/110534 (26%)]\tClassification Loss: 1.6236\r\n",
      "Train Epoch: 2 [29280/110534 (26%)]\tClassification Loss: 1.6511\r\n",
      "Train Epoch: 2 [29440/110534 (27%)]\tClassification Loss: 1.5529\r\n",
      "Train Epoch: 2 [29600/110534 (27%)]\tClassification Loss: 1.5298\r\n",
      "Train Epoch: 2 [29760/110534 (27%)]\tClassification Loss: 1.1322\r\n",
      "Train Epoch: 2 [29920/110534 (27%)]\tClassification Loss: 1.4191\r\n",
      "Train Epoch: 2 [30080/110534 (27%)]\tClassification Loss: 1.2542\r\n",
      "Train Epoch: 2 [30240/110534 (27%)]\tClassification Loss: 1.1284\r\n",
      "Test() called at batch_idx: 1900\r\n",
      "\r\n",
      "Test set: Average loss: 1.5286, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [30400/110534 (28%)]\tClassification Loss: 2.5646\r\n",
      "Train Epoch: 2 [30560/110534 (28%)]\tClassification Loss: 1.7622\r\n",
      "Train Epoch: 2 [30720/110534 (28%)]\tClassification Loss: 1.5824\r\n",
      "Train Epoch: 2 [30880/110534 (28%)]\tClassification Loss: 2.1106\r\n",
      "Train Epoch: 2 [31040/110534 (28%)]\tClassification Loss: 1.8189\r\n",
      "Train Epoch: 2 [31200/110534 (28%)]\tClassification Loss: 1.3978\r\n",
      "Train Epoch: 2 [31360/110534 (28%)]\tClassification Loss: 1.7581\r\n",
      "Train Epoch: 2 [31520/110534 (29%)]\tClassification Loss: 1.5568\r\n",
      "Train Epoch: 2 [31680/110534 (29%)]\tClassification Loss: 1.4777\r\n",
      "Train Epoch: 2 [31840/110534 (29%)]\tClassification Loss: 1.1511\r\n",
      "Test() called at batch_idx: 2000\r\n",
      "\r\n",
      "Test set: Average loss: 1.5208, Accuracy: 292/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [32000/110534 (29%)]\tClassification Loss: 1.2010\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_2000.pth.tar\r\n",
      "Train Epoch: 2 [32160/110534 (29%)]\tClassification Loss: 1.3131\r\n",
      "Train Epoch: 2 [32320/110534 (29%)]\tClassification Loss: 1.5056\r\n",
      "Train Epoch: 2 [32480/110534 (29%)]\tClassification Loss: 1.6316\r\n",
      "Train Epoch: 2 [32640/110534 (30%)]\tClassification Loss: 1.6535\r\n",
      "Train Epoch: 2 [32800/110534 (30%)]\tClassification Loss: 2.1825\r\n",
      "Train Epoch: 2 [32960/110534 (30%)]\tClassification Loss: 1.6139\r\n",
      "Train Epoch: 2 [33120/110534 (30%)]\tClassification Loss: 1.1525\r\n",
      "Train Epoch: 2 [33280/110534 (30%)]\tClassification Loss: 1.6344\r\n",
      "Train Epoch: 2 [33440/110534 (30%)]\tClassification Loss: 1.3679\r\n",
      "Test() called at batch_idx: 2100\r\n",
      "\r\n",
      "Test set: Average loss: 1.5395, Accuracy: 281/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [33600/110534 (30%)]\tClassification Loss: 1.2663\r\n",
      "Train Epoch: 2 [33760/110534 (31%)]\tClassification Loss: 1.4312\r\n",
      "Train Epoch: 2 [33920/110534 (31%)]\tClassification Loss: 1.7892\r\n",
      "Train Epoch: 2 [34080/110534 (31%)]\tClassification Loss: 2.0527\r\n",
      "Train Epoch: 2 [34240/110534 (31%)]\tClassification Loss: 2.0882\r\n",
      "Train Epoch: 2 [34400/110534 (31%)]\tClassification Loss: 2.0657\r\n",
      "Train Epoch: 2 [34560/110534 (31%)]\tClassification Loss: 1.7549\r\n",
      "Train Epoch: 2 [34720/110534 (31%)]\tClassification Loss: 1.8573\r\n",
      "Train Epoch: 2 [34880/110534 (32%)]\tClassification Loss: 2.7459\r\n",
      "Train Epoch: 2 [35040/110534 (32%)]\tClassification Loss: 1.5167\r\n",
      "Test() called at batch_idx: 2200\r\n",
      "\r\n",
      "Test set: Average loss: 1.5231, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [35200/110534 (32%)]\tClassification Loss: 1.9557\r\n",
      "Train Epoch: 2 [35360/110534 (32%)]\tClassification Loss: 1.5690\r\n",
      "Train Epoch: 2 [35520/110534 (32%)]\tClassification Loss: 1.0602\r\n",
      "Train Epoch: 2 [35680/110534 (32%)]\tClassification Loss: 2.1266\r\n",
      "Train Epoch: 2 [35840/110534 (32%)]\tClassification Loss: 1.3180\r\n",
      "Train Epoch: 2 [36000/110534 (33%)]\tClassification Loss: 1.4370\r\n",
      "Train Epoch: 2 [36160/110534 (33%)]\tClassification Loss: 1.3510\r\n",
      "Train Epoch: 2 [36320/110534 (33%)]\tClassification Loss: 1.9831\r\n",
      "Train Epoch: 2 [36480/110534 (33%)]\tClassification Loss: 1.1933\r\n",
      "Train Epoch: 2 [36640/110534 (33%)]\tClassification Loss: 1.7089\r\n",
      "Test() called at batch_idx: 2300\r\n",
      "\r\n",
      "Test set: Average loss: 1.5340, Accuracy: 292/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [36800/110534 (33%)]\tClassification Loss: 1.5985\r\n",
      "Train Epoch: 2 [36960/110534 (33%)]\tClassification Loss: 1.6741\r\n",
      "Train Epoch: 2 [37120/110534 (34%)]\tClassification Loss: 1.4984\r\n",
      "Train Epoch: 2 [37280/110534 (34%)]\tClassification Loss: 1.3732\r\n",
      "Train Epoch: 2 [37440/110534 (34%)]\tClassification Loss: 1.6398\r\n",
      "Train Epoch: 2 [37600/110534 (34%)]\tClassification Loss: 2.0474\r\n",
      "Train Epoch: 2 [37760/110534 (34%)]\tClassification Loss: 2.0237\r\n",
      "Train Epoch: 2 [37920/110534 (34%)]\tClassification Loss: 1.6946\r\n",
      "Train Epoch: 2 [38080/110534 (34%)]\tClassification Loss: 1.8493\r\n",
      "Train Epoch: 2 [38240/110534 (35%)]\tClassification Loss: 1.2990\r\n",
      "Test() called at batch_idx: 2400\r\n",
      "\r\n",
      "Test set: Average loss: 1.5154, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [38400/110534 (35%)]\tClassification Loss: 1.2012\r\n",
      "Train Epoch: 2 [38560/110534 (35%)]\tClassification Loss: 1.6450\r\n",
      "Train Epoch: 2 [38720/110534 (35%)]\tClassification Loss: 1.7880\r\n",
      "Train Epoch: 2 [38880/110534 (35%)]\tClassification Loss: 1.6418\r\n",
      "Train Epoch: 2 [39040/110534 (35%)]\tClassification Loss: 1.7846\r\n",
      "Train Epoch: 2 [39200/110534 (35%)]\tClassification Loss: 0.9363\r\n",
      "Train Epoch: 2 [39360/110534 (36%)]\tClassification Loss: 0.9607\r\n",
      "Train Epoch: 2 [39520/110534 (36%)]\tClassification Loss: 1.2473\r\n",
      "Train Epoch: 2 [39680/110534 (36%)]\tClassification Loss: 1.2633\r\n",
      "Train Epoch: 2 [39840/110534 (36%)]\tClassification Loss: 1.9020\r\n",
      "Test() called at batch_idx: 2500\r\n",
      "\r\n",
      "Test set: Average loss: 1.5170, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [40000/110534 (36%)]\tClassification Loss: 2.0838\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_2500.pth.tar\r\n",
      "Train Epoch: 2 [40160/110534 (36%)]\tClassification Loss: 1.3620\r\n",
      "Train Epoch: 2 [40320/110534 (36%)]\tClassification Loss: 2.1026\r\n",
      "Train Epoch: 2 [40480/110534 (37%)]\tClassification Loss: 1.4915\r\n",
      "Train Epoch: 2 [40640/110534 (37%)]\tClassification Loss: 2.2795\r\n",
      "Train Epoch: 2 [40800/110534 (37%)]\tClassification Loss: 1.6382\r\n",
      "Train Epoch: 2 [40960/110534 (37%)]\tClassification Loss: 2.0368\r\n",
      "Train Epoch: 2 [41120/110534 (37%)]\tClassification Loss: 1.6539\r\n",
      "Train Epoch: 2 [41280/110534 (37%)]\tClassification Loss: 1.9004\r\n",
      "Train Epoch: 2 [41440/110534 (37%)]\tClassification Loss: 1.2483\r\n",
      "Test() called at batch_idx: 2600\r\n",
      "\r\n",
      "Test set: Average loss: 1.5153, Accuracy: 290/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [41600/110534 (38%)]\tClassification Loss: 2.1828\r\n",
      "Train Epoch: 2 [41760/110534 (38%)]\tClassification Loss: 1.7058\r\n",
      "Train Epoch: 2 [41920/110534 (38%)]\tClassification Loss: 1.4702\r\n",
      "Train Epoch: 2 [42080/110534 (38%)]\tClassification Loss: 1.3687\r\n",
      "Train Epoch: 2 [42240/110534 (38%)]\tClassification Loss: 1.6512\r\n",
      "Train Epoch: 2 [42400/110534 (38%)]\tClassification Loss: 1.2036\r\n",
      "Train Epoch: 2 [42560/110534 (39%)]\tClassification Loss: 2.1925\r\n",
      "Train Epoch: 2 [42720/110534 (39%)]\tClassification Loss: 1.6575\r\n",
      "Train Epoch: 2 [42880/110534 (39%)]\tClassification Loss: 1.4147\r\n",
      "Train Epoch: 2 [43040/110534 (39%)]\tClassification Loss: 1.3575\r\n",
      "Test() called at batch_idx: 2700\r\n",
      "\r\n",
      "Test set: Average loss: 1.5155, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [43200/110534 (39%)]\tClassification Loss: 1.3445\r\n",
      "Train Epoch: 2 [43360/110534 (39%)]\tClassification Loss: 1.3183\r\n",
      "Train Epoch: 2 [43520/110534 (39%)]\tClassification Loss: 1.1463\r\n",
      "Train Epoch: 2 [43680/110534 (40%)]\tClassification Loss: 1.6480\r\n",
      "Train Epoch: 2 [43840/110534 (40%)]\tClassification Loss: 1.3609\r\n",
      "Train Epoch: 2 [44000/110534 (40%)]\tClassification Loss: 1.3771\r\n",
      "Train Epoch: 2 [44160/110534 (40%)]\tClassification Loss: 1.7222\r\n",
      "Train Epoch: 2 [44320/110534 (40%)]\tClassification Loss: 1.1725\r\n",
      "Train Epoch: 2 [44480/110534 (40%)]\tClassification Loss: 1.7309\r\n",
      "Train Epoch: 2 [44640/110534 (40%)]\tClassification Loss: 1.7074\r\n",
      "Test() called at batch_idx: 2800\r\n",
      "\r\n",
      "Test set: Average loss: 1.5222, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [44800/110534 (41%)]\tClassification Loss: 1.9056\r\n",
      "Train Epoch: 2 [44960/110534 (41%)]\tClassification Loss: 1.4345\r\n",
      "Train Epoch: 2 [45120/110534 (41%)]\tClassification Loss: 1.7115\r\n",
      "Train Epoch: 2 [45280/110534 (41%)]\tClassification Loss: 1.7022\r\n",
      "Train Epoch: 2 [45440/110534 (41%)]\tClassification Loss: 1.4755\r\n",
      "Train Epoch: 2 [45600/110534 (41%)]\tClassification Loss: 1.2292\r\n",
      "Train Epoch: 2 [45760/110534 (41%)]\tClassification Loss: 1.4249\r\n",
      "Train Epoch: 2 [45920/110534 (42%)]\tClassification Loss: 1.2890\r\n",
      "Train Epoch: 2 [46080/110534 (42%)]\tClassification Loss: 1.3897\r\n",
      "Train Epoch: 2 [46240/110534 (42%)]\tClassification Loss: 1.4575\r\n",
      "Test() called at batch_idx: 2900\r\n",
      "\r\n",
      "Test set: Average loss: 1.5080, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [46400/110534 (42%)]\tClassification Loss: 1.2957\r\n",
      "Train Epoch: 2 [46560/110534 (42%)]\tClassification Loss: 1.4332\r\n",
      "Train Epoch: 2 [46720/110534 (42%)]\tClassification Loss: 2.4114\r\n",
      "Train Epoch: 2 [46880/110534 (42%)]\tClassification Loss: 1.8787\r\n",
      "Train Epoch: 2 [47040/110534 (43%)]\tClassification Loss: 1.7835\r\n",
      "Train Epoch: 2 [47200/110534 (43%)]\tClassification Loss: 1.5441\r\n",
      "Train Epoch: 2 [47360/110534 (43%)]\tClassification Loss: 1.7103\r\n",
      "Train Epoch: 2 [47520/110534 (43%)]\tClassification Loss: 1.7279\r\n",
      "Train Epoch: 2 [47680/110534 (43%)]\tClassification Loss: 1.4345\r\n",
      "Train Epoch: 2 [47840/110534 (43%)]\tClassification Loss: 1.5986\r\n",
      "Test() called at batch_idx: 3000\r\n",
      "\r\n",
      "Test set: Average loss: 1.5110, Accuracy: 289/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [48000/110534 (43%)]\tClassification Loss: 1.7765\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_3000.pth.tar\r\n",
      "Train Epoch: 2 [48160/110534 (44%)]\tClassification Loss: 1.4232\r\n",
      "Train Epoch: 2 [48320/110534 (44%)]\tClassification Loss: 1.3414\r\n",
      "Train Epoch: 2 [48480/110534 (44%)]\tClassification Loss: 1.5314\r\n",
      "Train Epoch: 2 [48640/110534 (44%)]\tClassification Loss: 1.5934\r\n",
      "Train Epoch: 2 [48800/110534 (44%)]\tClassification Loss: 1.4067\r\n",
      "Train Epoch: 2 [48960/110534 (44%)]\tClassification Loss: 1.5376\r\n",
      "Train Epoch: 2 [49120/110534 (44%)]\tClassification Loss: 1.6309\r\n",
      "Train Epoch: 2 [49280/110534 (45%)]\tClassification Loss: 1.3578\r\n",
      "Train Epoch: 2 [49440/110534 (45%)]\tClassification Loss: 1.6313\r\n",
      "Test() called at batch_idx: 3100\r\n",
      "\r\n",
      "Test set: Average loss: 1.5190, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [49600/110534 (45%)]\tClassification Loss: 1.4553\r\n",
      "Train Epoch: 2 [49760/110534 (45%)]\tClassification Loss: 2.0108\r\n",
      "Train Epoch: 2 [49920/110534 (45%)]\tClassification Loss: 2.1954\r\n",
      "Train Epoch: 2 [50080/110534 (45%)]\tClassification Loss: 2.1167\r\n",
      "Train Epoch: 2 [50240/110534 (45%)]\tClassification Loss: 1.8151\r\n",
      "Train Epoch: 2 [50400/110534 (46%)]\tClassification Loss: 1.6457\r\n",
      "Train Epoch: 2 [50560/110534 (46%)]\tClassification Loss: 1.5754\r\n",
      "Train Epoch: 2 [50720/110534 (46%)]\tClassification Loss: 1.7624\r\n",
      "Train Epoch: 2 [50880/110534 (46%)]\tClassification Loss: 1.4562\r\n",
      "Train Epoch: 2 [51040/110534 (46%)]\tClassification Loss: 2.0498\r\n",
      "Test() called at batch_idx: 3200\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "\r\n",
      "Test set: Average loss: 1.5095, Accuracy: 289/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [51200/110534 (46%)]\tClassification Loss: 1.8271\r\n",
      "Train Epoch: 2 [51360/110534 (46%)]\tClassification Loss: 1.8663\r\n",
      "Train Epoch: 2 [51520/110534 (47%)]\tClassification Loss: 1.0157\r\n",
      "Train Epoch: 2 [51680/110534 (47%)]\tClassification Loss: 1.9599\r\n",
      "Train Epoch: 2 [51840/110534 (47%)]\tClassification Loss: 1.7478\r\n",
      "Train Epoch: 2 [52000/110534 (47%)]\tClassification Loss: 1.2962\r\n",
      "Train Epoch: 2 [52160/110534 (47%)]\tClassification Loss: 1.7512\r\n",
      "Train Epoch: 2 [52320/110534 (47%)]\tClassification Loss: 1.5568\r\n",
      "Train Epoch: 2 [52480/110534 (47%)]\tClassification Loss: 1.7600\r\n",
      "Train Epoch: 2 [52640/110534 (48%)]\tClassification Loss: 1.2820\r\n",
      "Test() called at batch_idx: 3300\r\n",
      "\r\n",
      "Test set: Average loss: 1.5249, Accuracy: 286/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [52800/110534 (48%)]\tClassification Loss: 1.5120\r\n",
      "Train Epoch: 2 [52960/110534 (48%)]\tClassification Loss: 1.5064\r\n",
      "Train Epoch: 2 [53120/110534 (48%)]\tClassification Loss: 1.6565\r\n",
      "Train Epoch: 2 [53280/110534 (48%)]\tClassification Loss: 1.4404\r\n",
      "Train Epoch: 2 [53440/110534 (48%)]\tClassification Loss: 1.5898\r\n",
      "Train Epoch: 2 [53600/110534 (48%)]\tClassification Loss: 1.2840\r\n",
      "Train Epoch: 2 [53760/110534 (49%)]\tClassification Loss: 1.6224\r\n",
      "Train Epoch: 2 [53920/110534 (49%)]\tClassification Loss: 1.6522\r\n",
      "Train Epoch: 2 [54080/110534 (49%)]\tClassification Loss: 0.9635\r\n",
      "Train Epoch: 2 [54240/110534 (49%)]\tClassification Loss: 2.4055\r\n",
      "Test() called at batch_idx: 3400\r\n",
      "\r\n",
      "Test set: Average loss: 1.5221, Accuracy: 283/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [54400/110534 (49%)]\tClassification Loss: 1.7400\r\n",
      "Train Epoch: 2 [54560/110534 (49%)]\tClassification Loss: 1.1201\r\n",
      "Train Epoch: 2 [54720/110534 (50%)]\tClassification Loss: 1.8856\r\n",
      "Train Epoch: 2 [54880/110534 (50%)]\tClassification Loss: 1.6403\r\n",
      "Train Epoch: 2 [55040/110534 (50%)]\tClassification Loss: 2.0086\r\n",
      "Train Epoch: 2 [55200/110534 (50%)]\tClassification Loss: 1.4038\r\n",
      "Train Epoch: 2 [55360/110534 (50%)]\tClassification Loss: 1.7484\r\n",
      "Train Epoch: 2 [55520/110534 (50%)]\tClassification Loss: 1.4645\r\n",
      "Train Epoch: 2 [55680/110534 (50%)]\tClassification Loss: 1.3171\r\n",
      "Train Epoch: 2 [55840/110534 (51%)]\tClassification Loss: 1.4732\r\n",
      "Test() called at batch_idx: 3500\r\n",
      "\r\n",
      "Test set: Average loss: 1.5048, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [56000/110534 (51%)]\tClassification Loss: 2.1832\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_3500.pth.tar\r\n",
      "Train Epoch: 2 [56160/110534 (51%)]\tClassification Loss: 1.4333\r\n",
      "Train Epoch: 2 [56320/110534 (51%)]\tClassification Loss: 1.6213\r\n",
      "Train Epoch: 2 [56480/110534 (51%)]\tClassification Loss: 1.9200\r\n",
      "Train Epoch: 2 [56640/110534 (51%)]\tClassification Loss: 2.3938\r\n",
      "Train Epoch: 2 [56800/110534 (51%)]\tClassification Loss: 1.0849\r\n",
      "Train Epoch: 2 [56960/110534 (52%)]\tClassification Loss: 1.7863\r\n",
      "Train Epoch: 2 [57120/110534 (52%)]\tClassification Loss: 2.1432\r\n",
      "Train Epoch: 2 [57280/110534 (52%)]\tClassification Loss: 1.8865\r\n",
      "Train Epoch: 2 [57440/110534 (52%)]\tClassification Loss: 1.7620\r\n",
      "Test() called at batch_idx: 3600\r\n",
      "\r\n",
      "Test set: Average loss: 1.5125, Accuracy: 291/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [57600/110534 (52%)]\tClassification Loss: 1.5961\r\n",
      "Train Epoch: 2 [57760/110534 (52%)]\tClassification Loss: 1.5719\r\n",
      "Train Epoch: 2 [57920/110534 (52%)]\tClassification Loss: 1.3981\r\n",
      "Train Epoch: 2 [58080/110534 (53%)]\tClassification Loss: 1.4099\r\n",
      "Train Epoch: 2 [58240/110534 (53%)]\tClassification Loss: 0.9928\r\n",
      "Train Epoch: 2 [58400/110534 (53%)]\tClassification Loss: 1.7465\r\n",
      "Train Epoch: 2 [58560/110534 (53%)]\tClassification Loss: 1.7890\r\n",
      "Train Epoch: 2 [58720/110534 (53%)]\tClassification Loss: 1.4343\r\n",
      "Train Epoch: 2 [58880/110534 (53%)]\tClassification Loss: 1.1699\r\n",
      "Train Epoch: 2 [59040/110534 (53%)]\tClassification Loss: 1.5403\r\n",
      "Test() called at batch_idx: 3700\r\n",
      "\r\n",
      "Test set: Average loss: 1.5127, Accuracy: 289/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [59200/110534 (54%)]\tClassification Loss: 1.4997\r\n",
      "Train Epoch: 2 [59360/110534 (54%)]\tClassification Loss: 1.7960\r\n",
      "Train Epoch: 2 [59520/110534 (54%)]\tClassification Loss: 1.5106\r\n",
      "Train Epoch: 2 [59680/110534 (54%)]\tClassification Loss: 1.6788\r\n",
      "Train Epoch: 2 [59840/110534 (54%)]\tClassification Loss: 1.6628\r\n",
      "Train Epoch: 2 [60000/110534 (54%)]\tClassification Loss: 1.5499\r\n",
      "Train Epoch: 2 [60160/110534 (54%)]\tClassification Loss: 1.1058\r\n",
      "Train Epoch: 2 [60320/110534 (55%)]\tClassification Loss: 1.3455\r\n",
      "Train Epoch: 2 [60480/110534 (55%)]\tClassification Loss: 1.5642\r\n",
      "Train Epoch: 2 [60640/110534 (55%)]\tClassification Loss: 1.5182\r\n",
      "Test() called at batch_idx: 3800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4939, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [60800/110534 (55%)]\tClassification Loss: 1.5989\r\n",
      "Train Epoch: 2 [60960/110534 (55%)]\tClassification Loss: 2.4328\r\n",
      "Train Epoch: 2 [61120/110534 (55%)]\tClassification Loss: 1.9204\r\n",
      "Train Epoch: 2 [61280/110534 (55%)]\tClassification Loss: 1.4475\r\n",
      "Train Epoch: 2 [61440/110534 (56%)]\tClassification Loss: 2.2866\r\n",
      "Train Epoch: 2 [61600/110534 (56%)]\tClassification Loss: 1.7589\r\n",
      "Train Epoch: 2 [61760/110534 (56%)]\tClassification Loss: 1.3420\r\n",
      "Train Epoch: 2 [61920/110534 (56%)]\tClassification Loss: 1.4509\r\n",
      "Train Epoch: 2 [62080/110534 (56%)]\tClassification Loss: 1.7851\r\n",
      "Train Epoch: 2 [62240/110534 (56%)]\tClassification Loss: 1.9507\r\n",
      "Test() called at batch_idx: 3900\r\n",
      "\r\n",
      "Test set: Average loss: 1.5088, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [62400/110534 (56%)]\tClassification Loss: 1.6974\r\n",
      "Train Epoch: 2 [62560/110534 (57%)]\tClassification Loss: 1.2080\r\n",
      "Train Epoch: 2 [62720/110534 (57%)]\tClassification Loss: 1.0214\r\n",
      "Train Epoch: 2 [62880/110534 (57%)]\tClassification Loss: 1.2832\r\n",
      "Train Epoch: 2 [63040/110534 (57%)]\tClassification Loss: 1.2349\r\n",
      "Train Epoch: 2 [63200/110534 (57%)]\tClassification Loss: 1.5075\r\n",
      "Train Epoch: 2 [63360/110534 (57%)]\tClassification Loss: 1.2739\r\n",
      "Train Epoch: 2 [63520/110534 (57%)]\tClassification Loss: 1.4888\r\n",
      "Train Epoch: 2 [63680/110534 (58%)]\tClassification Loss: 1.7441\r\n",
      "Train Epoch: 2 [63840/110534 (58%)]\tClassification Loss: 1.4237\r\n",
      "Test() called at batch_idx: 4000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4984, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [64000/110534 (58%)]\tClassification Loss: 1.6872\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_4000.pth.tar\r\n",
      "Train Epoch: 2 [64160/110534 (58%)]\tClassification Loss: 1.7249\r\n",
      "Train Epoch: 2 [64320/110534 (58%)]\tClassification Loss: 1.3966\r\n",
      "Train Epoch: 2 [64480/110534 (58%)]\tClassification Loss: 1.7636\r\n",
      "Train Epoch: 2 [64640/110534 (58%)]\tClassification Loss: 2.1948\r\n",
      "Train Epoch: 2 [64800/110534 (59%)]\tClassification Loss: 1.5795\r\n",
      "Train Epoch: 2 [64960/110534 (59%)]\tClassification Loss: 1.4759\r\n",
      "Train Epoch: 2 [65120/110534 (59%)]\tClassification Loss: 1.5116\r\n",
      "Train Epoch: 2 [65280/110534 (59%)]\tClassification Loss: 1.4575\r\n",
      "Train Epoch: 2 [65440/110534 (59%)]\tClassification Loss: 1.5763\r\n",
      "Test() called at batch_idx: 4100\r\n",
      "\r\n",
      "Test set: Average loss: 1.5035, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [65600/110534 (59%)]\tClassification Loss: 1.2401\r\n",
      "Train Epoch: 2 [65760/110534 (59%)]\tClassification Loss: 2.0038\r\n",
      "Train Epoch: 2 [65920/110534 (60%)]\tClassification Loss: 1.1733\r\n",
      "Train Epoch: 2 [66080/110534 (60%)]\tClassification Loss: 1.6409\r\n",
      "Train Epoch: 2 [66240/110534 (60%)]\tClassification Loss: 1.3167\r\n",
      "Train Epoch: 2 [66400/110534 (60%)]\tClassification Loss: 1.6001\r\n",
      "Train Epoch: 2 [66560/110534 (60%)]\tClassification Loss: 1.7534\r\n",
      "Train Epoch: 2 [66720/110534 (60%)]\tClassification Loss: 1.5765\r\n",
      "Train Epoch: 2 [66880/110534 (61%)]\tClassification Loss: 1.3884\r\n",
      "Train Epoch: 2 [67040/110534 (61%)]\tClassification Loss: 1.6355\r\n",
      "Test() called at batch_idx: 4200\r\n",
      "\r\n",
      "Test set: Average loss: 1.5070, Accuracy: 289/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [67200/110534 (61%)]\tClassification Loss: 1.8240\r\n",
      "Train Epoch: 2 [67360/110534 (61%)]\tClassification Loss: 1.7060\r\n",
      "Train Epoch: 2 [67520/110534 (61%)]\tClassification Loss: 1.3794\r\n",
      "Train Epoch: 2 [67680/110534 (61%)]\tClassification Loss: 1.3425\r\n",
      "Train Epoch: 2 [67840/110534 (61%)]\tClassification Loss: 2.0374\r\n",
      "Train Epoch: 2 [68000/110534 (62%)]\tClassification Loss: 1.1946\r\n",
      "Train Epoch: 2 [68160/110534 (62%)]\tClassification Loss: 1.7842\r\n",
      "Train Epoch: 2 [68320/110534 (62%)]\tClassification Loss: 1.9855\r\n",
      "Train Epoch: 2 [68480/110534 (62%)]\tClassification Loss: 2.1645\r\n",
      "Train Epoch: 2 [68640/110534 (62%)]\tClassification Loss: 1.5089\r\n",
      "Test() called at batch_idx: 4300\r\n",
      "\r\n",
      "Test set: Average loss: 1.5020, Accuracy: 289/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [68800/110534 (62%)]\tClassification Loss: 1.8984\r\n",
      "Train Epoch: 2 [68960/110534 (62%)]\tClassification Loss: 1.3599\r\n",
      "Train Epoch: 2 [69120/110534 (63%)]\tClassification Loss: 1.3870\r\n",
      "Train Epoch: 2 [69280/110534 (63%)]\tClassification Loss: 1.4920\r\n",
      "Train Epoch: 2 [69440/110534 (63%)]\tClassification Loss: 1.3484\r\n",
      "Train Epoch: 2 [69600/110534 (63%)]\tClassification Loss: 1.4656\r\n",
      "Train Epoch: 2 [69760/110534 (63%)]\tClassification Loss: 1.6228\r\n",
      "Train Epoch: 2 [69920/110534 (63%)]\tClassification Loss: 1.7374\r\n",
      "Train Epoch: 2 [70080/110534 (63%)]\tClassification Loss: 1.1550\r\n",
      "Train Epoch: 2 [70240/110534 (64%)]\tClassification Loss: 1.5168\r\n",
      "Test() called at batch_idx: 4400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4952, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [70400/110534 (64%)]\tClassification Loss: 1.5017\r\n",
      "Train Epoch: 2 [70560/110534 (64%)]\tClassification Loss: 1.4825\r\n",
      "Train Epoch: 2 [70720/110534 (64%)]\tClassification Loss: 1.0925\r\n",
      "Train Epoch: 2 [70880/110534 (64%)]\tClassification Loss: 1.7185\r\n",
      "Train Epoch: 2 [71040/110534 (64%)]\tClassification Loss: 1.7650\r\n",
      "Train Epoch: 2 [71200/110534 (64%)]\tClassification Loss: 1.8837\r\n",
      "Train Epoch: 2 [71360/110534 (65%)]\tClassification Loss: 2.7445\r\n",
      "Train Epoch: 2 [71520/110534 (65%)]\tClassification Loss: 1.9588\r\n",
      "Train Epoch: 2 [71680/110534 (65%)]\tClassification Loss: 1.6727\r\n",
      "Train Epoch: 2 [71840/110534 (65%)]\tClassification Loss: 2.0975\r\n",
      "Test() called at batch_idx: 4500\r\n",
      "\r\n",
      "Test set: Average loss: 1.5258, Accuracy: 288/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 2 [72000/110534 (65%)]\tClassification Loss: 2.1079\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_4500.pth.tar\r\n",
      "Train Epoch: 2 [72160/110534 (65%)]\tClassification Loss: 1.8584\r\n",
      "Train Epoch: 2 [72320/110534 (65%)]\tClassification Loss: 1.8556\r\n",
      "Train Epoch: 2 [72480/110534 (66%)]\tClassification Loss: 1.9944\r\n",
      "Train Epoch: 2 [72640/110534 (66%)]\tClassification Loss: 1.5807\r\n",
      "Train Epoch: 2 [72800/110534 (66%)]\tClassification Loss: 1.3432\r\n",
      "Train Epoch: 2 [72960/110534 (66%)]\tClassification Loss: 1.8470\r\n",
      "Train Epoch: 2 [73120/110534 (66%)]\tClassification Loss: 1.6680\r\n",
      "Train Epoch: 2 [73280/110534 (66%)]\tClassification Loss: 1.3205\r\n",
      "Train Epoch: 2 [73440/110534 (66%)]\tClassification Loss: 1.5925\r\n",
      "Test() called at batch_idx: 4600\r\n",
      "\r\n",
      "Test set: Average loss: 1.5093, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [73600/110534 (67%)]\tClassification Loss: 1.7525\r\n",
      "Train Epoch: 2 [73760/110534 (67%)]\tClassification Loss: 1.6808\r\n",
      "Train Epoch: 2 [73920/110534 (67%)]\tClassification Loss: 1.6826\r\n",
      "Train Epoch: 2 [74080/110534 (67%)]\tClassification Loss: 1.8561\r\n",
      "Train Epoch: 2 [74240/110534 (67%)]\tClassification Loss: 1.6862\r\n",
      "Train Epoch: 2 [74400/110534 (67%)]\tClassification Loss: 1.8462\r\n",
      "Train Epoch: 2 [74560/110534 (67%)]\tClassification Loss: 1.5567\r\n",
      "Train Epoch: 2 [74720/110534 (68%)]\tClassification Loss: 1.1642\r\n",
      "Train Epoch: 2 [74880/110534 (68%)]\tClassification Loss: 1.4914\r\n",
      "Train Epoch: 2 [75040/110534 (68%)]\tClassification Loss: 1.5205\r\n",
      "Test() called at batch_idx: 4700\r\n",
      "\r\n",
      "Test set: Average loss: 1.5040, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [75200/110534 (68%)]\tClassification Loss: 1.4204\r\n",
      "Train Epoch: 2 [75360/110534 (68%)]\tClassification Loss: 1.7714\r\n",
      "Train Epoch: 2 [75520/110534 (68%)]\tClassification Loss: 1.4403\r\n",
      "Train Epoch: 2 [75680/110534 (68%)]\tClassification Loss: 1.2761\r\n",
      "Train Epoch: 2 [75840/110534 (69%)]\tClassification Loss: 1.5750\r\n",
      "Train Epoch: 2 [76000/110534 (69%)]\tClassification Loss: 1.4345\r\n",
      "Train Epoch: 2 [76160/110534 (69%)]\tClassification Loss: 1.5836\r\n",
      "Train Epoch: 2 [76320/110534 (69%)]\tClassification Loss: 1.9617\r\n",
      "Train Epoch: 2 [76480/110534 (69%)]\tClassification Loss: 1.0274\r\n",
      "Train Epoch: 2 [76640/110534 (69%)]\tClassification Loss: 1.7378\r\n",
      "Test() called at batch_idx: 4800\r\n",
      "\r\n",
      "Test set: Average loss: 1.5031, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [76800/110534 (69%)]\tClassification Loss: 2.0036\r\n",
      "Train Epoch: 2 [76960/110534 (70%)]\tClassification Loss: 1.3077\r\n",
      "Train Epoch: 2 [77120/110534 (70%)]\tClassification Loss: 1.5329\r\n",
      "Train Epoch: 2 [77280/110534 (70%)]\tClassification Loss: 1.6517\r\n",
      "Train Epoch: 2 [77440/110534 (70%)]\tClassification Loss: 1.1673\r\n",
      "Train Epoch: 2 [77600/110534 (70%)]\tClassification Loss: 1.5243\r\n",
      "Train Epoch: 2 [77760/110534 (70%)]\tClassification Loss: 1.2868\r\n",
      "Train Epoch: 2 [77920/110534 (70%)]\tClassification Loss: 1.4292\r\n",
      "Train Epoch: 2 [78080/110534 (71%)]\tClassification Loss: 1.4308\r\n",
      "Train Epoch: 2 [78240/110534 (71%)]\tClassification Loss: 1.7535\r\n",
      "Test() called at batch_idx: 4900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4958, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [78400/110534 (71%)]\tClassification Loss: 1.2605\r\n",
      "Train Epoch: 2 [78560/110534 (71%)]\tClassification Loss: 1.7321\r\n",
      "Train Epoch: 2 [78720/110534 (71%)]\tClassification Loss: 1.5155\r\n",
      "Train Epoch: 2 [78880/110534 (71%)]\tClassification Loss: 2.2837\r\n",
      "Train Epoch: 2 [79040/110534 (72%)]\tClassification Loss: 1.6964\r\n",
      "Train Epoch: 2 [79200/110534 (72%)]\tClassification Loss: 1.5442\r\n",
      "Train Epoch: 2 [79360/110534 (72%)]\tClassification Loss: 1.2255\r\n",
      "Train Epoch: 2 [79520/110534 (72%)]\tClassification Loss: 1.0262\r\n",
      "Train Epoch: 2 [79680/110534 (72%)]\tClassification Loss: 1.1930\r\n",
      "Train Epoch: 2 [79840/110534 (72%)]\tClassification Loss: 1.7781\r\n",
      "Test() called at batch_idx: 5000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4891, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [80000/110534 (72%)]\tClassification Loss: 1.4638\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_5000.pth.tar\r\n",
      "Train Epoch: 2 [80160/110534 (73%)]\tClassification Loss: 1.6183\r\n",
      "Train Epoch: 2 [80320/110534 (73%)]\tClassification Loss: 1.7906\r\n",
      "Train Epoch: 2 [80480/110534 (73%)]\tClassification Loss: 1.8927\r\n",
      "Train Epoch: 2 [80640/110534 (73%)]\tClassification Loss: 1.2008\r\n",
      "Train Epoch: 2 [80800/110534 (73%)]\tClassification Loss: 1.8294\r\n",
      "Train Epoch: 2 [80960/110534 (73%)]\tClassification Loss: 1.9729\r\n",
      "Train Epoch: 2 [81120/110534 (73%)]\tClassification Loss: 1.7514\r\n",
      "Train Epoch: 2 [81280/110534 (74%)]\tClassification Loss: 1.5416\r\n",
      "Train Epoch: 2 [81440/110534 (74%)]\tClassification Loss: 1.4048\r\n",
      "Test() called at batch_idx: 5100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4879, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [81600/110534 (74%)]\tClassification Loss: 1.7012\r\n",
      "Train Epoch: 2 [81760/110534 (74%)]\tClassification Loss: 1.4656\r\n",
      "Train Epoch: 2 [81920/110534 (74%)]\tClassification Loss: 1.3158\r\n",
      "Train Epoch: 2 [82080/110534 (74%)]\tClassification Loss: 1.2214\r\n",
      "Train Epoch: 2 [82240/110534 (74%)]\tClassification Loss: 1.1342\r\n",
      "Train Epoch: 2 [82400/110534 (75%)]\tClassification Loss: 2.5599\r\n",
      "Train Epoch: 2 [82560/110534 (75%)]\tClassification Loss: 0.9198\r\n",
      "Train Epoch: 2 [82720/110534 (75%)]\tClassification Loss: 1.8724\r\n",
      "Train Epoch: 2 [82880/110534 (75%)]\tClassification Loss: 1.2640\r\n",
      "Train Epoch: 2 [83040/110534 (75%)]\tClassification Loss: 1.4423\r\n",
      "Test() called at batch_idx: 5200\r\n",
      "\r\n",
      "Test set: Average loss: 1.5226, Accuracy: 279/480 (58%)\r\n",
      "\r\n",
      "Train Epoch: 2 [83200/110534 (75%)]\tClassification Loss: 1.8982\r\n",
      "Train Epoch: 2 [83360/110534 (75%)]\tClassification Loss: 1.5009\r\n",
      "Train Epoch: 2 [83520/110534 (76%)]\tClassification Loss: 2.2251\r\n",
      "Train Epoch: 2 [83680/110534 (76%)]\tClassification Loss: 1.5756\r\n",
      "Train Epoch: 2 [83840/110534 (76%)]\tClassification Loss: 2.0860\r\n",
      "Train Epoch: 2 [84000/110534 (76%)]\tClassification Loss: 1.7948\r\n",
      "Train Epoch: 2 [84160/110534 (76%)]\tClassification Loss: 1.0736\r\n",
      "Train Epoch: 2 [84320/110534 (76%)]\tClassification Loss: 2.0665\r\n",
      "Train Epoch: 2 [84480/110534 (76%)]\tClassification Loss: 1.6225\r\n",
      "Train Epoch: 2 [84640/110534 (77%)]\tClassification Loss: 1.0623\r\n",
      "Test() called at batch_idx: 5300\r\n",
      "Traceback (most recent call last):\r\n",
      "\r\n",
      "Test set: Average loss: 1.4929, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [84800/110534 (77%)]\tClassification Loss: 1.7119\r\n",
      "Train Epoch: 2 [84960/110534 (77%)]\tClassification Loss: 1.4867\r\n",
      "Train Epoch: 2 [85120/110534 (77%)]\tClassification Loss: 1.3018\r\n",
      "Train Epoch: 2 [85280/110534 (77%)]\tClassification Loss: 1.8080\r\n",
      "Train Epoch: 2 [85440/110534 (77%)]\tClassification Loss: 1.6263\r\n",
      "Train Epoch: 2 [85600/110534 (77%)]\tClassification Loss: 1.6491\r\n",
      "Train Epoch: 2 [85760/110534 (78%)]\tClassification Loss: 1.7790\r\n",
      "Train Epoch: 2 [85920/110534 (78%)]\tClassification Loss: 1.5793\r\n",
      "Train Epoch: 2 [86080/110534 (78%)]\tClassification Loss: 1.4925\r\n",
      "Train Epoch: 2 [86240/110534 (78%)]\tClassification Loss: 1.4615\r\n",
      "Test() called at batch_idx: 5400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4907, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [86400/110534 (78%)]\tClassification Loss: 1.5748\r\n",
      "Train Epoch: 2 [86560/110534 (78%)]\tClassification Loss: 1.3863\r\n",
      "Train Epoch: 2 [86720/110534 (78%)]\tClassification Loss: 1.7591\r\n",
      "Train Epoch: 2 [86880/110534 (79%)]\tClassification Loss: 1.4523\r\n",
      "Train Epoch: 2 [87040/110534 (79%)]\tClassification Loss: 2.1277\r\n",
      "Train Epoch: 2 [87200/110534 (79%)]\tClassification Loss: 1.5958\r\n",
      "Train Epoch: 2 [87360/110534 (79%)]\tClassification Loss: 1.4108\r\n",
      "Train Epoch: 2 [87520/110534 (79%)]\tClassification Loss: 1.1586\r\n",
      "Train Epoch: 2 [87680/110534 (79%)]\tClassification Loss: 1.4089\r\n",
      "Train Epoch: 2 [87840/110534 (79%)]\tClassification Loss: 1.4067\r\n",
      "Test() called at batch_idx: 5500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4878, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [88000/110534 (80%)]\tClassification Loss: 1.5459\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_5500.pth.tar\r\n",
      "Train Epoch: 2 [88160/110534 (80%)]\tClassification Loss: 1.6500\r\n",
      "Train Epoch: 2 [88320/110534 (80%)]\tClassification Loss: 1.0690\r\n",
      "Train Epoch: 2 [88480/110534 (80%)]\tClassification Loss: 1.8413\r\n",
      "Train Epoch: 2 [88640/110534 (80%)]\tClassification Loss: 2.6428\r\n",
      "Train Epoch: 2 [88800/110534 (80%)]\tClassification Loss: 2.1719\r\n",
      "Train Epoch: 2 [88960/110534 (80%)]\tClassification Loss: 1.7137\r\n",
      "Train Epoch: 2 [89120/110534 (81%)]\tClassification Loss: 1.3517\r\n",
      "Train Epoch: 2 [89280/110534 (81%)]\tClassification Loss: 1.1776\r\n",
      "Train Epoch: 2 [89440/110534 (81%)]\tClassification Loss: 1.0316\r\n",
      "Test() called at batch_idx: 5600\r\n",
      "\r\n",
      "Test set: Average loss: 1.5301, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [89600/110534 (81%)]\tClassification Loss: 1.2740\r\n",
      "Train Epoch: 2 [89760/110534 (81%)]\tClassification Loss: 1.0606\r\n",
      "Train Epoch: 2 [89920/110534 (81%)]\tClassification Loss: 1.5683\r\n",
      "Train Epoch: 2 [90080/110534 (81%)]\tClassification Loss: 1.4222\r\n",
      "Train Epoch: 2 [90240/110534 (82%)]\tClassification Loss: 1.5209\r\n",
      "Train Epoch: 2 [90400/110534 (82%)]\tClassification Loss: 1.7342\r\n",
      "Train Epoch: 2 [90560/110534 (82%)]\tClassification Loss: 1.2687\r\n",
      "Train Epoch: 2 [90720/110534 (82%)]\tClassification Loss: 1.2488\r\n",
      "Train Epoch: 2 [90880/110534 (82%)]\tClassification Loss: 1.1223\r\n",
      "Train Epoch: 2 [91040/110534 (82%)]\tClassification Loss: 1.5966\r\n",
      "Test() called at batch_idx: 5700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4832, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 2 [91200/110534 (83%)]\tClassification Loss: 1.9428\r\n",
      "Train Epoch: 2 [91360/110534 (83%)]\tClassification Loss: 1.4111\r\n",
      "Train Epoch: 2 [91520/110534 (83%)]\tClassification Loss: 1.9432\r\n",
      "Train Epoch: 2 [91680/110534 (83%)]\tClassification Loss: 1.5171\r\n",
      "Train Epoch: 2 [91840/110534 (83%)]\tClassification Loss: 1.2942\r\n",
      "Train Epoch: 2 [92000/110534 (83%)]\tClassification Loss: 1.3268\r\n",
      "Train Epoch: 2 [92160/110534 (83%)]\tClassification Loss: 1.5992\r\n",
      "Train Epoch: 2 [92320/110534 (84%)]\tClassification Loss: 1.7673\r\n",
      "Train Epoch: 2 [92480/110534 (84%)]\tClassification Loss: 1.4792\r\n",
      "Train Epoch: 2 [92640/110534 (84%)]\tClassification Loss: 1.6533\r\n",
      "Test() called at batch_idx: 5800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4997, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [92800/110534 (84%)]\tClassification Loss: 1.9428\r\n",
      "Train Epoch: 2 [92960/110534 (84%)]\tClassification Loss: 1.5281\r\n",
      "Train Epoch: 2 [93120/110534 (84%)]\tClassification Loss: 1.6614\r\n",
      "Train Epoch: 2 [93280/110534 (84%)]\tClassification Loss: 0.9213\r\n",
      "Train Epoch: 2 [93440/110534 (85%)]\tClassification Loss: 1.6711\r\n",
      "Train Epoch: 2 [93600/110534 (85%)]\tClassification Loss: 1.5075\r\n",
      "Train Epoch: 2 [93760/110534 (85%)]\tClassification Loss: 1.2150\r\n",
      "Train Epoch: 2 [93920/110534 (85%)]\tClassification Loss: 1.2955\r\n",
      "Train Epoch: 2 [94080/110534 (85%)]\tClassification Loss: 1.8359\r\n",
      "Train Epoch: 2 [94240/110534 (85%)]\tClassification Loss: 1.2150\r\n",
      "Test() called at batch_idx: 5900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4979, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [94400/110534 (85%)]\tClassification Loss: 1.7840\r\n",
      "Train Epoch: 2 [94560/110534 (86%)]\tClassification Loss: 1.9298\r\n",
      "Train Epoch: 2 [94720/110534 (86%)]\tClassification Loss: 1.1561\r\n",
      "Train Epoch: 2 [94880/110534 (86%)]\tClassification Loss: 1.5613\r\n",
      "Train Epoch: 2 [95040/110534 (86%)]\tClassification Loss: 1.8860\r\n",
      "Train Epoch: 2 [95200/110534 (86%)]\tClassification Loss: 1.7356\r\n",
      "Train Epoch: 2 [95360/110534 (86%)]\tClassification Loss: 2.0743\r\n",
      "Train Epoch: 2 [95520/110534 (86%)]\tClassification Loss: 2.1639\r\n",
      "Train Epoch: 2 [95680/110534 (87%)]\tClassification Loss: 1.3074\r\n",
      "Train Epoch: 2 [95840/110534 (87%)]\tClassification Loss: 1.7077\r\n",
      "Test() called at batch_idx: 6000\r\n",
      "\r\n",
      "Test set: Average loss: 1.5074, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 2 [96000/110534 (87%)]\tClassification Loss: 1.7849\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_6000.pth.tar\r\n",
      "Train Epoch: 2 [96160/110534 (87%)]\tClassification Loss: 1.6360\r\n",
      "Train Epoch: 2 [96320/110534 (87%)]\tClassification Loss: 1.2607\r\n",
      "Train Epoch: 2 [96480/110534 (87%)]\tClassification Loss: 1.9812\r\n",
      "Train Epoch: 2 [96640/110534 (87%)]\tClassification Loss: 1.2156\r\n",
      "Train Epoch: 2 [96800/110534 (88%)]\tClassification Loss: 1.0306\r\n",
      "Train Epoch: 2 [96960/110534 (88%)]\tClassification Loss: 1.6321\r\n",
      "Train Epoch: 2 [97120/110534 (88%)]\tClassification Loss: 1.7204\r\n",
      "Train Epoch: 2 [97280/110534 (88%)]\tClassification Loss: 1.4344\r\n",
      "Train Epoch: 2 [97440/110534 (88%)]\tClassification Loss: 1.2775\r\n",
      "Test() called at batch_idx: 6100\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\r\n",
      "    self._send(header + buf)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\r\n",
      "    n = write(self._handle, buf)\r\n",
      "BrokenPipeError: [Errno 32] Broken pipe\r\n",
      "\r\n",
      "Test set: Average loss: 1.4793, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [97600/110534 (88%)]\tClassification Loss: 1.8983\r\n",
      "Train Epoch: 2 [97760/110534 (88%)]\tClassification Loss: 2.1306\r\n",
      "Train Epoch: 2 [97920/110534 (89%)]\tClassification Loss: 1.2362\r\n",
      "Train Epoch: 2 [98080/110534 (89%)]\tClassification Loss: 1.3568\r\n",
      "Train Epoch: 2 [98240/110534 (89%)]\tClassification Loss: 1.5015\r\n",
      "Train Epoch: 2 [98400/110534 (89%)]\tClassification Loss: 1.6551\r\n",
      "Train Epoch: 2 [98560/110534 (89%)]\tClassification Loss: 2.5506\r\n",
      "Train Epoch: 2 [98720/110534 (89%)]\tClassification Loss: 1.3648\r\n",
      "Train Epoch: 2 [98880/110534 (89%)]\tClassification Loss: 2.1444\r\n",
      "Train Epoch: 2 [99040/110534 (90%)]\tClassification Loss: 1.6395\r\n",
      "Test() called at batch_idx: 6200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4799, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [99200/110534 (90%)]\tClassification Loss: 1.6616\r\n",
      "Train Epoch: 2 [99360/110534 (90%)]\tClassification Loss: 1.8197\r\n",
      "Train Epoch: 2 [99520/110534 (90%)]\tClassification Loss: 1.4413\r\n",
      "Train Epoch: 2 [99680/110534 (90%)]\tClassification Loss: 1.7234\r\n",
      "Train Epoch: 2 [99840/110534 (90%)]\tClassification Loss: 1.5671\r\n",
      "Train Epoch: 2 [100000/110534 (90%)]\tClassification Loss: 1.7928\r\n",
      "Train Epoch: 2 [100160/110534 (91%)]\tClassification Loss: 1.4191\r\n",
      "Train Epoch: 2 [100320/110534 (91%)]\tClassification Loss: 1.7507\r\n",
      "Train Epoch: 2 [100480/110534 (91%)]\tClassification Loss: 1.4582\r\n",
      "Train Epoch: 2 [100640/110534 (91%)]\tClassification Loss: 1.5851\r\n",
      "Test() called at batch_idx: 6300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4771, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [100800/110534 (91%)]\tClassification Loss: 1.6618\r\n",
      "Train Epoch: 2 [100960/110534 (91%)]\tClassification Loss: 1.5572\r\n",
      "Train Epoch: 2 [101120/110534 (91%)]\tClassification Loss: 1.3885\r\n",
      "Train Epoch: 2 [101280/110534 (92%)]\tClassification Loss: 1.5125\r\n",
      "Train Epoch: 2 [101440/110534 (92%)]\tClassification Loss: 1.5926\r\n",
      "Train Epoch: 2 [101600/110534 (92%)]\tClassification Loss: 1.8370\r\n",
      "Train Epoch: 2 [101760/110534 (92%)]\tClassification Loss: 1.1576\r\n",
      "Train Epoch: 2 [101920/110534 (92%)]\tClassification Loss: 1.1247\r\n",
      "Train Epoch: 2 [102080/110534 (92%)]\tClassification Loss: 1.8478\r\n",
      "Train Epoch: 2 [102240/110534 (93%)]\tClassification Loss: 1.6544\r\n",
      "Test() called at batch_idx: 6400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4826, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [102400/110534 (93%)]\tClassification Loss: 1.6792\r\n",
      "Train Epoch: 2 [102560/110534 (93%)]\tClassification Loss: 1.1857\r\n",
      "Train Epoch: 2 [102720/110534 (93%)]\tClassification Loss: 1.6287\r\n",
      "Train Epoch: 2 [102880/110534 (93%)]\tClassification Loss: 1.9925\r\n",
      "Train Epoch: 2 [103040/110534 (93%)]\tClassification Loss: 1.5783\r\n",
      "Train Epoch: 2 [103200/110534 (93%)]\tClassification Loss: 1.6173\r\n",
      "Train Epoch: 2 [103360/110534 (94%)]\tClassification Loss: 1.8722\r\n",
      "Train Epoch: 2 [103520/110534 (94%)]\tClassification Loss: 1.3113\r\n",
      "Train Epoch: 2 [103680/110534 (94%)]\tClassification Loss: 1.1470\r\n",
      "Train Epoch: 2 [103840/110534 (94%)]\tClassification Loss: 1.5983\r\n",
      "Test() called at batch_idx: 6500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4761, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [104000/110534 (94%)]\tClassification Loss: 1.3700\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_6500.pth.tar\r\n",
      "Train Epoch: 2 [104160/110534 (94%)]\tClassification Loss: 2.0053\r\n",
      "Train Epoch: 2 [104320/110534 (94%)]\tClassification Loss: 2.0610\r\n",
      "Train Epoch: 2 [104480/110534 (95%)]\tClassification Loss: 1.7065\r\n",
      "Train Epoch: 2 [104640/110534 (95%)]\tClassification Loss: 1.4045\r\n",
      "Train Epoch: 2 [104800/110534 (95%)]\tClassification Loss: 1.2912\r\n",
      "Train Epoch: 2 [104960/110534 (95%)]\tClassification Loss: 1.1143\r\n",
      "Train Epoch: 2 [105120/110534 (95%)]\tClassification Loss: 1.2060\r\n",
      "Train Epoch: 2 [105280/110534 (95%)]\tClassification Loss: 1.4428\r\n",
      "Train Epoch: 2 [105440/110534 (95%)]\tClassification Loss: 1.4228\r\n",
      "Test() called at batch_idx: 6600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4851, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [105600/110534 (96%)]\tClassification Loss: 1.3912\r\n",
      "Train Epoch: 2 [105760/110534 (96%)]\tClassification Loss: 1.3685\r\n",
      "Train Epoch: 2 [105920/110534 (96%)]\tClassification Loss: 1.0270\r\n",
      "Train Epoch: 2 [106080/110534 (96%)]\tClassification Loss: 1.6805\r\n",
      "Train Epoch: 2 [106240/110534 (96%)]\tClassification Loss: 1.5867\r\n",
      "Train Epoch: 2 [106400/110534 (96%)]\tClassification Loss: 1.2146\r\n",
      "Train Epoch: 2 [106560/110534 (96%)]\tClassification Loss: 1.6165\r\n",
      "Train Epoch: 2 [106720/110534 (97%)]\tClassification Loss: 1.3612\r\n",
      "Train Epoch: 2 [106880/110534 (97%)]\tClassification Loss: 1.3952\r\n",
      "Train Epoch: 2 [107040/110534 (97%)]\tClassification Loss: 1.2980\r\n",
      "Test() called at batch_idx: 6700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4788, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [107200/110534 (97%)]\tClassification Loss: 1.5430\r\n",
      "Train Epoch: 2 [107360/110534 (97%)]\tClassification Loss: 1.5107\r\n",
      "Train Epoch: 2 [107520/110534 (97%)]\tClassification Loss: 2.3692\r\n",
      "Train Epoch: 2 [107680/110534 (97%)]\tClassification Loss: 1.5472\r\n",
      "Train Epoch: 2 [107840/110534 (98%)]\tClassification Loss: 1.3169\r\n",
      "Train Epoch: 2 [108000/110534 (98%)]\tClassification Loss: 1.6565\r\n",
      "Train Epoch: 2 [108160/110534 (98%)]\tClassification Loss: 1.4691\r\n",
      "Train Epoch: 2 [108320/110534 (98%)]\tClassification Loss: 0.9530\r\n",
      "Train Epoch: 2 [108480/110534 (98%)]\tClassification Loss: 1.2900\r\n",
      "Train Epoch: 2 [108640/110534 (98%)]\tClassification Loss: 1.0114\r\n",
      "Test() called at batch_idx: 6800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4822, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 2 [108800/110534 (98%)]\tClassification Loss: 1.9721\r\n",
      "Train Epoch: 2 [108960/110534 (99%)]\tClassification Loss: 1.7398\r\n",
      "Train Epoch: 2 [109120/110534 (99%)]\tClassification Loss: 1.7405\r\n",
      "Train Epoch: 2 [109280/110534 (99%)]\tClassification Loss: 1.0497\r\n",
      "Train Epoch: 2 [109440/110534 (99%)]\tClassification Loss: 1.2890\r\n",
      "Train Epoch: 2 [109600/110534 (99%)]\tClassification Loss: 1.3542\r\n",
      "Train Epoch: 2 [109760/110534 (99%)]\tClassification Loss: 1.8303\r\n",
      "Train Epoch: 2 [109920/110534 (99%)]\tClassification Loss: 1.5989\r\n",
      "Train Epoch: 2 [110080/110534 (100%)]\tClassification Loss: 1.8414\r\n",
      "Train Epoch: 2 [110240/110534 (100%)]\tClassification Loss: 1.2649\r\n",
      "Test() called at batch_idx: 6900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4845, Accuracy: 291/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 2 [110400/110534 (100%)]\tClassification Loss: 1.3046\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_final.pth.tar\r\n",
      "Test() called at batch_idx: 0\r\n",
      "\r\n",
      "Test set: Average loss: 1.4892, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [0/110534 (0%)]\tClassification Loss: 1.6677\r\n",
      "Train Epoch: 3 [160/110534 (0%)]\tClassification Loss: 1.8857\r\n",
      "Train Epoch: 3 [320/110534 (0%)]\tClassification Loss: 0.8140\r\n",
      "Train Epoch: 3 [480/110534 (0%)]\tClassification Loss: 2.1224\r\n",
      "Train Epoch: 3 [640/110534 (1%)]\tClassification Loss: 1.4441\r\n",
      "Train Epoch: 3 [800/110534 (1%)]\tClassification Loss: 1.3801\r\n",
      "Train Epoch: 3 [960/110534 (1%)]\tClassification Loss: 1.3579\r\n",
      "Train Epoch: 3 [1120/110534 (1%)]\tClassification Loss: 1.5034\r\n",
      "Train Epoch: 3 [1280/110534 (1%)]\tClassification Loss: 1.8709\r\n",
      "Train Epoch: 3 [1440/110534 (1%)]\tClassification Loss: 0.8089\r\n",
      "Test() called at batch_idx: 100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4660, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [1600/110534 (1%)]\tClassification Loss: 1.3991\r\n",
      "Train Epoch: 3 [1760/110534 (2%)]\tClassification Loss: 2.1066\r\n",
      "Train Epoch: 3 [1920/110534 (2%)]\tClassification Loss: 1.1156\r\n",
      "Train Epoch: 3 [2080/110534 (2%)]\tClassification Loss: 1.5009\r\n",
      "Train Epoch: 3 [2240/110534 (2%)]\tClassification Loss: 1.7315\r\n",
      "Train Epoch: 3 [2400/110534 (2%)]\tClassification Loss: 1.3537\r\n",
      "Train Epoch: 3 [2560/110534 (2%)]\tClassification Loss: 1.7257\r\n",
      "Train Epoch: 3 [2720/110534 (2%)]\tClassification Loss: 2.0959\r\n",
      "Train Epoch: 3 [2880/110534 (3%)]\tClassification Loss: 1.5636\r\n",
      "Train Epoch: 3 [3040/110534 (3%)]\tClassification Loss: 2.1514\r\n",
      "Test() called at batch_idx: 200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4800, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [3200/110534 (3%)]\tClassification Loss: 1.2234\r\n",
      "Train Epoch: 3 [3360/110534 (3%)]\tClassification Loss: 1.6113\r\n",
      "Train Epoch: 3 [3520/110534 (3%)]\tClassification Loss: 1.3722\r\n",
      "Train Epoch: 3 [3680/110534 (3%)]\tClassification Loss: 1.4269\r\n",
      "Train Epoch: 3 [3840/110534 (3%)]\tClassification Loss: 1.4007\r\n",
      "Train Epoch: 3 [4000/110534 (4%)]\tClassification Loss: 1.6305\r\n",
      "Train Epoch: 3 [4160/110534 (4%)]\tClassification Loss: 1.3768\r\n",
      "Train Epoch: 3 [4320/110534 (4%)]\tClassification Loss: 1.3017\r\n",
      "Train Epoch: 3 [4480/110534 (4%)]\tClassification Loss: 0.9874\r\n",
      "Train Epoch: 3 [4640/110534 (4%)]\tClassification Loss: 1.2116\r\n",
      "Test() called at batch_idx: 300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4987, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [4800/110534 (4%)]\tClassification Loss: 2.1546\r\n",
      "Train Epoch: 3 [4960/110534 (4%)]\tClassification Loss: 1.3161\r\n",
      "Train Epoch: 3 [5120/110534 (5%)]\tClassification Loss: 1.9212\r\n",
      "Train Epoch: 3 [5280/110534 (5%)]\tClassification Loss: 1.1138\r\n",
      "Train Epoch: 3 [5440/110534 (5%)]\tClassification Loss: 1.4188\r\n",
      "Train Epoch: 3 [5600/110534 (5%)]\tClassification Loss: 1.3265\r\n",
      "Train Epoch: 3 [5760/110534 (5%)]\tClassification Loss: 1.5743\r\n",
      "Train Epoch: 3 [5920/110534 (5%)]\tClassification Loss: 1.0992\r\n",
      "Train Epoch: 3 [6080/110534 (6%)]\tClassification Loss: 1.2459\r\n",
      "Train Epoch: 3 [6240/110534 (6%)]\tClassification Loss: 1.3390\r\n",
      "Test() called at batch_idx: 400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4727, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [6400/110534 (6%)]\tClassification Loss: 1.3047\r\n",
      "Train Epoch: 3 [6560/110534 (6%)]\tClassification Loss: 2.2197\r\n",
      "Train Epoch: 3 [6720/110534 (6%)]\tClassification Loss: 1.2008\r\n",
      "Train Epoch: 3 [6880/110534 (6%)]\tClassification Loss: 2.0129\r\n",
      "Train Epoch: 3 [7040/110534 (6%)]\tClassification Loss: 1.1330\r\n",
      "Train Epoch: 3 [7200/110534 (7%)]\tClassification Loss: 1.2151\r\n",
      "Train Epoch: 3 [7360/110534 (7%)]\tClassification Loss: 1.7034\r\n",
      "Train Epoch: 3 [7520/110534 (7%)]\tClassification Loss: 1.5202\r\n",
      "Train Epoch: 3 [7680/110534 (7%)]\tClassification Loss: 1.3426\r\n",
      "Train Epoch: 3 [7840/110534 (7%)]\tClassification Loss: 2.4290\r\n",
      "Test() called at batch_idx: 500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4878, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [8000/110534 (7%)]\tClassification Loss: 1.0432\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_500.pth.tar\r\n",
      "Train Epoch: 3 [8160/110534 (7%)]\tClassification Loss: 1.3841\r\n",
      "Train Epoch: 3 [8320/110534 (8%)]\tClassification Loss: 1.6440\r\n",
      "Train Epoch: 3 [8480/110534 (8%)]\tClassification Loss: 1.5631\r\n",
      "Train Epoch: 3 [8640/110534 (8%)]\tClassification Loss: 1.5655\r\n",
      "Train Epoch: 3 [8800/110534 (8%)]\tClassification Loss: 1.4349\r\n",
      "Train Epoch: 3 [8960/110534 (8%)]\tClassification Loss: 1.7234\r\n",
      "Train Epoch: 3 [9120/110534 (8%)]\tClassification Loss: 1.7200\r\n",
      "Train Epoch: 3 [9280/110534 (8%)]\tClassification Loss: 1.3563\r\n",
      "Train Epoch: 3 [9440/110534 (9%)]\tClassification Loss: 1.4451\r\n",
      "Test() called at batch_idx: 600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4764, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [9600/110534 (9%)]\tClassification Loss: 1.6391\r\n",
      "Train Epoch: 3 [9760/110534 (9%)]\tClassification Loss: 0.9739\r\n",
      "Train Epoch: 3 [9920/110534 (9%)]\tClassification Loss: 1.7500\r\n",
      "Train Epoch: 3 [10080/110534 (9%)]\tClassification Loss: 1.5839\r\n",
      "Train Epoch: 3 [10240/110534 (9%)]\tClassification Loss: 1.6908\r\n",
      "Train Epoch: 3 [10400/110534 (9%)]\tClassification Loss: 1.4470\r\n",
      "Train Epoch: 3 [10560/110534 (10%)]\tClassification Loss: 1.7244\r\n",
      "Train Epoch: 3 [10720/110534 (10%)]\tClassification Loss: 2.0210\r\n",
      "Train Epoch: 3 [10880/110534 (10%)]\tClassification Loss: 2.3440\r\n",
      "Train Epoch: 3 [11040/110534 (10%)]\tClassification Loss: 1.3946\r\n",
      "Test() called at batch_idx: 700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4770, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [11200/110534 (10%)]\tClassification Loss: 1.2650\r\n",
      "Train Epoch: 3 [11360/110534 (10%)]\tClassification Loss: 1.7167\r\n",
      "Train Epoch: 3 [11520/110534 (10%)]\tClassification Loss: 1.6658\r\n",
      "Train Epoch: 3 [11680/110534 (11%)]\tClassification Loss: 1.5070\r\n",
      "Train Epoch: 3 [11840/110534 (11%)]\tClassification Loss: 1.4116\r\n",
      "Train Epoch: 3 [12000/110534 (11%)]\tClassification Loss: 1.4709\r\n",
      "Train Epoch: 3 [12160/110534 (11%)]\tClassification Loss: 1.6789\r\n",
      "Train Epoch: 3 [12320/110534 (11%)]\tClassification Loss: 1.1301\r\n",
      "Train Epoch: 3 [12480/110534 (11%)]\tClassification Loss: 1.5505\r\n",
      "Train Epoch: 3 [12640/110534 (11%)]\tClassification Loss: 1.5571\r\n",
      "Test() called at batch_idx: 800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4773, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [12800/110534 (12%)]\tClassification Loss: 1.2842\r\n",
      "Train Epoch: 3 [12960/110534 (12%)]\tClassification Loss: 1.8373\r\n",
      "Train Epoch: 3 [13120/110534 (12%)]\tClassification Loss: 1.7326\r\n",
      "Train Epoch: 3 [13280/110534 (12%)]\tClassification Loss: 1.9226\r\n",
      "Train Epoch: 3 [13440/110534 (12%)]\tClassification Loss: 2.0202\r\n",
      "Train Epoch: 3 [13600/110534 (12%)]\tClassification Loss: 1.7816\r\n",
      "Train Epoch: 3 [13760/110534 (12%)]\tClassification Loss: 1.1000\r\n",
      "Train Epoch: 3 [13920/110534 (13%)]\tClassification Loss: 1.1852\r\n",
      "Train Epoch: 3 [14080/110534 (13%)]\tClassification Loss: 1.5262\r\n",
      "Train Epoch: 3 [14240/110534 (13%)]\tClassification Loss: 2.4480\r\n",
      "Test() called at batch_idx: 900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4909, Accuracy: 290/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 3 [14400/110534 (13%)]\tClassification Loss: 1.3447\r\n",
      "Train Epoch: 3 [14560/110534 (13%)]\tClassification Loss: 1.1976\r\n",
      "Train Epoch: 3 [14720/110534 (13%)]\tClassification Loss: 1.3715\r\n",
      "Train Epoch: 3 [14880/110534 (13%)]\tClassification Loss: 1.6133\r\n",
      "Train Epoch: 3 [15040/110534 (14%)]\tClassification Loss: 1.3477\r\n",
      "Train Epoch: 3 [15200/110534 (14%)]\tClassification Loss: 1.2625\r\n",
      "Train Epoch: 3 [15360/110534 (14%)]\tClassification Loss: 1.3434\r\n",
      "Train Epoch: 3 [15520/110534 (14%)]\tClassification Loss: 1.4547\r\n",
      "Train Epoch: 3 [15680/110534 (14%)]\tClassification Loss: 1.6678\r\n",
      "Train Epoch: 3 [15840/110534 (14%)]\tClassification Loss: 1.0583\r\n",
      "Test() called at batch_idx: 1000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4919, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [16000/110534 (14%)]\tClassification Loss: 1.1640\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1000.pth.tar\r\n",
      "Train Epoch: 3 [16160/110534 (15%)]\tClassification Loss: 1.5346\r\n",
      "Train Epoch: 3 [16320/110534 (15%)]\tClassification Loss: 2.2141\r\n",
      "Train Epoch: 3 [16480/110534 (15%)]\tClassification Loss: 1.5257\r\n",
      "Train Epoch: 3 [16640/110534 (15%)]\tClassification Loss: 1.3549\r\n",
      "Train Epoch: 3 [16800/110534 (15%)]\tClassification Loss: 1.3449\r\n",
      "Train Epoch: 3 [16960/110534 (15%)]\tClassification Loss: 1.8507\r\n",
      "Train Epoch: 3 [17120/110534 (15%)]\tClassification Loss: 1.7630\r\n",
      "Train Epoch: 3 [17280/110534 (16%)]\tClassification Loss: 1.3009\r\n",
      "Train Epoch: 3 [17440/110534 (16%)]\tClassification Loss: 1.3126\r\n",
      "Test() called at batch_idx: 1100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4933, Accuracy: 283/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 3 [17600/110534 (16%)]\tClassification Loss: 1.3135\r\n",
      "Train Epoch: 3 [17760/110534 (16%)]\tClassification Loss: 1.0409\r\n",
      "Train Epoch: 3 [17920/110534 (16%)]\tClassification Loss: 1.5150\r\n",
      "Train Epoch: 3 [18080/110534 (16%)]\tClassification Loss: 1.6878\r\n",
      "Train Epoch: 3 [18240/110534 (17%)]\tClassification Loss: 1.8885\r\n",
      "Train Epoch: 3 [18400/110534 (17%)]\tClassification Loss: 1.7232\r\n",
      "Train Epoch: 3 [18560/110534 (17%)]\tClassification Loss: 1.3917\r\n",
      "Train Epoch: 3 [18720/110534 (17%)]\tClassification Loss: 2.2029\r\n",
      "Train Epoch: 3 [18880/110534 (17%)]\tClassification Loss: 1.2450\r\n",
      "Train Epoch: 3 [19040/110534 (17%)]\tClassification Loss: 1.8125\r\n",
      "Test() called at batch_idx: 1200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4734, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [19200/110534 (17%)]\tClassification Loss: 1.3091\r\n",
      "Train Epoch: 3 [19360/110534 (18%)]\tClassification Loss: 1.4749\r\n",
      "Train Epoch: 3 [19520/110534 (18%)]\tClassification Loss: 2.0222\r\n",
      "Train Epoch: 3 [19680/110534 (18%)]\tClassification Loss: 1.5616\r\n",
      "Train Epoch: 3 [19840/110534 (18%)]\tClassification Loss: 1.5597\r\n",
      "Train Epoch: 3 [20000/110534 (18%)]\tClassification Loss: 1.6793\r\n",
      "Train Epoch: 3 [20160/110534 (18%)]\tClassification Loss: 1.5584\r\n",
      "Train Epoch: 3 [20320/110534 (18%)]\tClassification Loss: 1.1346\r\n",
      "Train Epoch: 3 [20480/110534 (19%)]\tClassification Loss: 1.9000\r\n",
      "Train Epoch: 3 [20640/110534 (19%)]\tClassification Loss: 2.1875\r\n",
      "Test() called at batch_idx: 1300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4938, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [20800/110534 (19%)]\tClassification Loss: 2.0452\r\n",
      "Train Epoch: 3 [20960/110534 (19%)]\tClassification Loss: 1.6937\r\n",
      "Train Epoch: 3 [21120/110534 (19%)]\tClassification Loss: 2.2624\r\n",
      "Train Epoch: 3 [21280/110534 (19%)]\tClassification Loss: 1.3971\r\n",
      "Train Epoch: 3 [21440/110534 (19%)]\tClassification Loss: 1.4026\r\n",
      "Train Epoch: 3 [21600/110534 (20%)]\tClassification Loss: 1.3707\r\n",
      "Train Epoch: 3 [21760/110534 (20%)]\tClassification Loss: 1.2851\r\n",
      "Train Epoch: 3 [21920/110534 (20%)]\tClassification Loss: 1.5056\r\n",
      "Train Epoch: 3 [22080/110534 (20%)]\tClassification Loss: 1.7661\r\n",
      "Train Epoch: 3 [22240/110534 (20%)]\tClassification Loss: 1.4065\r\n",
      "Test() called at batch_idx: 1400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4754, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [22400/110534 (20%)]\tClassification Loss: 2.1215\r\n",
      "Train Epoch: 3 [22560/110534 (20%)]\tClassification Loss: 1.4279\r\n",
      "Train Epoch: 3 [22720/110534 (21%)]\tClassification Loss: 0.9568\r\n",
      "Train Epoch: 3 [22880/110534 (21%)]\tClassification Loss: 1.2392\r\n",
      "Train Epoch: 3 [23040/110534 (21%)]\tClassification Loss: 1.5975\r\n",
      "Train Epoch: 3 [23200/110534 (21%)]\tClassification Loss: 1.6715\r\n",
      "Train Epoch: 3 [23360/110534 (21%)]\tClassification Loss: 1.4929\r\n",
      "Train Epoch: 3 [23520/110534 (21%)]\tClassification Loss: 1.5450\r\n",
      "Train Epoch: 3 [23680/110534 (21%)]\tClassification Loss: 1.1802\r\n",
      "Train Epoch: 3 [23840/110534 (22%)]\tClassification Loss: 1.9458\r\n",
      "Test() called at batch_idx: 1500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4936, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [24000/110534 (22%)]\tClassification Loss: 0.9603\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1500.pth.tar\r\n",
      "Train Epoch: 3 [24160/110534 (22%)]\tClassification Loss: 1.9280\r\n",
      "Train Epoch: 3 [24320/110534 (22%)]\tClassification Loss: 1.5070\r\n",
      "Train Epoch: 3 [24480/110534 (22%)]\tClassification Loss: 1.1618\r\n",
      "Train Epoch: 3 [24640/110534 (22%)]\tClassification Loss: 1.0784\r\n",
      "Train Epoch: 3 [24800/110534 (22%)]\tClassification Loss: 1.3381\r\n",
      "Train Epoch: 3 [24960/110534 (23%)]\tClassification Loss: 1.8295\r\n",
      "Train Epoch: 3 [25120/110534 (23%)]\tClassification Loss: 1.0799\r\n",
      "Train Epoch: 3 [25280/110534 (23%)]\tClassification Loss: 1.5410\r\n",
      "Train Epoch: 3 [25440/110534 (23%)]\tClassification Loss: 1.4881\r\n",
      "Test() called at batch_idx: 1600\r\n",
      "\r\n",
      "Test set: Average loss: 1.5022, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 3 [25600/110534 (23%)]\tClassification Loss: 1.1955\r\n",
      "Train Epoch: 3 [25760/110534 (23%)]\tClassification Loss: 1.6729\r\n",
      "Train Epoch: 3 [25920/110534 (23%)]\tClassification Loss: 1.3394\r\n",
      "Train Epoch: 3 [26080/110534 (24%)]\tClassification Loss: 1.2490\r\n",
      "Train Epoch: 3 [26240/110534 (24%)]\tClassification Loss: 2.0256\r\n",
      "Train Epoch: 3 [26400/110534 (24%)]\tClassification Loss: 2.0933\r\n",
      "Train Epoch: 3 [26560/110534 (24%)]\tClassification Loss: 1.9355\r\n",
      "Train Epoch: 3 [26720/110534 (24%)]\tClassification Loss: 1.9261\r\n",
      "Train Epoch: 3 [26880/110534 (24%)]\tClassification Loss: 2.0974\r\n",
      "Train Epoch: 3 [27040/110534 (24%)]\tClassification Loss: 1.6345\r\n",
      "Test() called at batch_idx: 1700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4775, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [27200/110534 (25%)]\tClassification Loss: 1.2146\r\n",
      "Train Epoch: 3 [27360/110534 (25%)]\tClassification Loss: 1.2600\r\n",
      "Train Epoch: 3 [27520/110534 (25%)]\tClassification Loss: 1.5601\r\n",
      "Train Epoch: 3 [27680/110534 (25%)]\tClassification Loss: 1.7856\r\n",
      "Train Epoch: 3 [27840/110534 (25%)]\tClassification Loss: 1.9923\r\n",
      "Train Epoch: 3 [28000/110534 (25%)]\tClassification Loss: 1.7996\r\n",
      "Train Epoch: 3 [28160/110534 (25%)]\tClassification Loss: 1.4222\r\n",
      "Train Epoch: 3 [28320/110534 (26%)]\tClassification Loss: 2.5431\r\n",
      "Train Epoch: 3 [28480/110534 (26%)]\tClassification Loss: 1.2664\r\n",
      "Train Epoch: 3 [28640/110534 (26%)]\tClassification Loss: 1.5931\r\n",
      "Test() called at batch_idx: 1800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4896, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [28800/110534 (26%)]\tClassification Loss: 1.5089\r\n",
      "Train Epoch: 3 [28960/110534 (26%)]\tClassification Loss: 2.1076\r\n",
      "Train Epoch: 3 [29120/110534 (26%)]\tClassification Loss: 1.2387\r\n",
      "Train Epoch: 3 [29280/110534 (26%)]\tClassification Loss: 1.5737\r\n",
      "Train Epoch: 3 [29440/110534 (27%)]\tClassification Loss: 1.4469\r\n",
      "Train Epoch: 3 [29600/110534 (27%)]\tClassification Loss: 1.3200\r\n",
      "Train Epoch: 3 [29760/110534 (27%)]\tClassification Loss: 0.9786\r\n",
      "Train Epoch: 3 [29920/110534 (27%)]\tClassification Loss: 1.2452\r\n",
      "Train Epoch: 3 [30080/110534 (27%)]\tClassification Loss: 1.4472\r\n",
      "Train Epoch: 3 [30240/110534 (27%)]\tClassification Loss: 1.2182\r\n",
      "Test() called at batch_idx: 1900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4957, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 3 [30400/110534 (28%)]\tClassification Loss: 2.1533\r\n",
      "Train Epoch: 3 [30560/110534 (28%)]\tClassification Loss: 1.8370\r\n",
      "Train Epoch: 3 [30720/110534 (28%)]\tClassification Loss: 1.4507\r\n",
      "Train Epoch: 3 [30880/110534 (28%)]\tClassification Loss: 2.3069\r\n",
      "Train Epoch: 3 [31040/110534 (28%)]\tClassification Loss: 1.7299\r\n",
      "Train Epoch: 3 [31200/110534 (28%)]\tClassification Loss: 1.3389\r\n",
      "Train Epoch: 3 [31360/110534 (28%)]\tClassification Loss: 2.1871\r\n",
      "Train Epoch: 3 [31520/110534 (29%)]\tClassification Loss: 1.4932\r\n",
      "Train Epoch: 3 [31680/110534 (29%)]\tClassification Loss: 1.4928\r\n",
      "Train Epoch: 3 [31840/110534 (29%)]\tClassification Loss: 1.1913\r\n",
      "Test() called at batch_idx: 2000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4710, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [32000/110534 (29%)]\tClassification Loss: 1.0577\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_2000.pth.tar\r\n",
      "Train Epoch: 3 [32160/110534 (29%)]\tClassification Loss: 1.5607\r\n",
      "Train Epoch: 3 [32320/110534 (29%)]\tClassification Loss: 1.8144\r\n",
      "Train Epoch: 3 [32480/110534 (29%)]\tClassification Loss: 1.5722\r\n",
      "Train Epoch: 3 [32640/110534 (30%)]\tClassification Loss: 1.4499\r\n",
      "Train Epoch: 3 [32800/110534 (30%)]\tClassification Loss: 2.0907\r\n",
      "Train Epoch: 3 [32960/110534 (30%)]\tClassification Loss: 1.5138\r\n",
      "Train Epoch: 3 [33120/110534 (30%)]\tClassification Loss: 1.1491\r\n",
      "Train Epoch: 3 [33280/110534 (30%)]\tClassification Loss: 1.7244\r\n",
      "Train Epoch: 3 [33440/110534 (30%)]\tClassification Loss: 1.1721\r\n",
      "Test() called at batch_idx: 2100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4979, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [33600/110534 (30%)]\tClassification Loss: 1.3950\r\n",
      "Train Epoch: 3 [33760/110534 (31%)]\tClassification Loss: 1.3210\r\n",
      "Train Epoch: 3 [33920/110534 (31%)]\tClassification Loss: 1.6598\r\n",
      "Train Epoch: 3 [34080/110534 (31%)]\tClassification Loss: 1.6135\r\n",
      "Train Epoch: 3 [34240/110534 (31%)]\tClassification Loss: 1.7275\r\n",
      "Train Epoch: 3 [34400/110534 (31%)]\tClassification Loss: 1.5209\r\n",
      "Train Epoch: 3 [34560/110534 (31%)]\tClassification Loss: 1.6491\r\n",
      "Train Epoch: 3 [34720/110534 (31%)]\tClassification Loss: 2.1525\r\n",
      "Train Epoch: 3 [34880/110534 (32%)]\tClassification Loss: 2.5663\r\n",
      "Train Epoch: 3 [35040/110534 (32%)]\tClassification Loss: 1.2341\r\n",
      "Test() called at batch_idx: 2200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4803, Accuracy: 290/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 3 [35200/110534 (32%)]\tClassification Loss: 2.1011\r\n",
      "Train Epoch: 3 [35360/110534 (32%)]\tClassification Loss: 1.6221\r\n",
      "Train Epoch: 3 [35520/110534 (32%)]\tClassification Loss: 1.1199\r\n",
      "Train Epoch: 3 [35680/110534 (32%)]\tClassification Loss: 2.1801\r\n",
      "Train Epoch: 3 [35840/110534 (32%)]\tClassification Loss: 1.4404\r\n",
      "Train Epoch: 3 [36000/110534 (33%)]\tClassification Loss: 1.4457\r\n",
      "Train Epoch: 3 [36160/110534 (33%)]\tClassification Loss: 1.3015\r\n",
      "Train Epoch: 3 [36320/110534 (33%)]\tClassification Loss: 2.0919\r\n",
      "Train Epoch: 3 [36480/110534 (33%)]\tClassification Loss: 1.2579\r\n",
      "Train Epoch: 3 [36640/110534 (33%)]\tClassification Loss: 2.0080\r\n",
      "Test() called at batch_idx: 2300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4853, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [36800/110534 (33%)]\tClassification Loss: 1.7856\r\n",
      "Train Epoch: 3 [36960/110534 (33%)]\tClassification Loss: 1.3711\r\n",
      "Train Epoch: 3 [37120/110534 (34%)]\tClassification Loss: 1.4968\r\n",
      "Train Epoch: 3 [37280/110534 (34%)]\tClassification Loss: 1.1643\r\n",
      "Train Epoch: 3 [37440/110534 (34%)]\tClassification Loss: 1.5170\r\n",
      "Train Epoch: 3 [37600/110534 (34%)]\tClassification Loss: 1.8960\r\n",
      "Train Epoch: 3 [37760/110534 (34%)]\tClassification Loss: 1.9650\r\n",
      "Train Epoch: 3 [37920/110534 (34%)]\tClassification Loss: 1.8213\r\n",
      "Train Epoch: 3 [38080/110534 (34%)]\tClassification Loss: 1.8313\r\n",
      "Train Epoch: 3 [38240/110534 (35%)]\tClassification Loss: 1.5429\r\n",
      "Test() called at batch_idx: 2400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4712, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [38400/110534 (35%)]\tClassification Loss: 1.1161\r\n",
      "Train Epoch: 3 [38560/110534 (35%)]\tClassification Loss: 1.7774\r\n",
      "Train Epoch: 3 [38720/110534 (35%)]\tClassification Loss: 1.5772\r\n",
      "Train Epoch: 3 [38880/110534 (35%)]\tClassification Loss: 1.7465\r\n",
      "Train Epoch: 3 [39040/110534 (35%)]\tClassification Loss: 1.8892\r\n",
      "Train Epoch: 3 [39200/110534 (35%)]\tClassification Loss: 0.9743\r\n",
      "Train Epoch: 3 [39360/110534 (36%)]\tClassification Loss: 0.9301\r\n",
      "Train Epoch: 3 [39520/110534 (36%)]\tClassification Loss: 1.4076\r\n",
      "Train Epoch: 3 [39680/110534 (36%)]\tClassification Loss: 1.3732\r\n",
      "Train Epoch: 3 [39840/110534 (36%)]\tClassification Loss: 1.8573\r\n",
      "Test() called at batch_idx: 2500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4762, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [40000/110534 (36%)]\tClassification Loss: 1.7599\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_2500.pth.tar\r\n",
      "Train Epoch: 3 [40160/110534 (36%)]\tClassification Loss: 1.0963\r\n",
      "Train Epoch: 3 [40320/110534 (36%)]\tClassification Loss: 1.3842\r\n",
      "Train Epoch: 3 [40480/110534 (37%)]\tClassification Loss: 1.1567\r\n",
      "Train Epoch: 3 [40640/110534 (37%)]\tClassification Loss: 1.9609\r\n",
      "Train Epoch: 3 [40800/110534 (37%)]\tClassification Loss: 1.6131\r\n",
      "Train Epoch: 3 [40960/110534 (37%)]\tClassification Loss: 2.1076\r\n",
      "Train Epoch: 3 [41120/110534 (37%)]\tClassification Loss: 1.6583\r\n",
      "Train Epoch: 3 [41280/110534 (37%)]\tClassification Loss: 1.6374\r\n",
      "Train Epoch: 3 [41440/110534 (37%)]\tClassification Loss: 1.0732\r\n",
      "Test() called at batch_idx: 2600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4748, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [41600/110534 (38%)]\tClassification Loss: 2.1841\r\n",
      "Train Epoch: 3 [41760/110534 (38%)]\tClassification Loss: 1.8250\r\n",
      "Train Epoch: 3 [41920/110534 (38%)]\tClassification Loss: 1.5785\r\n",
      "Train Epoch: 3 [42080/110534 (38%)]\tClassification Loss: 1.2185\r\n",
      "Train Epoch: 3 [42240/110534 (38%)]\tClassification Loss: 1.6330\r\n",
      "Train Epoch: 3 [42400/110534 (38%)]\tClassification Loss: 1.2730\r\n",
      "Train Epoch: 3 [42560/110534 (39%)]\tClassification Loss: 1.5739\r\n",
      "Train Epoch: 3 [42720/110534 (39%)]\tClassification Loss: 1.5327\r\n",
      "Train Epoch: 3 [42880/110534 (39%)]\tClassification Loss: 1.3817\r\n",
      "Train Epoch: 3 [43040/110534 (39%)]\tClassification Loss: 1.3006\r\n",
      "Test() called at batch_idx: 2700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4673, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [43200/110534 (39%)]\tClassification Loss: 1.2193\r\n",
      "Train Epoch: 3 [43360/110534 (39%)]\tClassification Loss: 1.2331\r\n",
      "Train Epoch: 3 [43520/110534 (39%)]\tClassification Loss: 1.1857\r\n",
      "Train Epoch: 3 [43680/110534 (40%)]\tClassification Loss: 1.3977\r\n",
      "Train Epoch: 3 [43840/110534 (40%)]\tClassification Loss: 1.8004\r\n",
      "Train Epoch: 3 [44000/110534 (40%)]\tClassification Loss: 1.2055\r\n",
      "Train Epoch: 3 [44160/110534 (40%)]\tClassification Loss: 2.0019\r\n",
      "Train Epoch: 3 [44320/110534 (40%)]\tClassification Loss: 1.2212\r\n",
      "Train Epoch: 3 [44480/110534 (40%)]\tClassification Loss: 1.4446\r\n",
      "Train Epoch: 3 [44640/110534 (40%)]\tClassification Loss: 1.6761\r\n",
      "Test() called at batch_idx: 2800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4752, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [44800/110534 (41%)]\tClassification Loss: 2.2873\r\n",
      "Train Epoch: 3 [44960/110534 (41%)]\tClassification Loss: 1.0367\r\n",
      "Train Epoch: 3 [45120/110534 (41%)]\tClassification Loss: 1.7837\r\n",
      "Train Epoch: 3 [45280/110534 (41%)]\tClassification Loss: 1.7827\r\n",
      "Train Epoch: 3 [45440/110534 (41%)]\tClassification Loss: 1.4696\r\n",
      "Train Epoch: 3 [45600/110534 (41%)]\tClassification Loss: 1.5263\r\n",
      "Train Epoch: 3 [45760/110534 (41%)]\tClassification Loss: 1.5305\r\n",
      "Train Epoch: 3 [45920/110534 (42%)]\tClassification Loss: 1.3207\r\n",
      "Train Epoch: 3 [46080/110534 (42%)]\tClassification Loss: 1.1702\r\n",
      "Train Epoch: 3 [46240/110534 (42%)]\tClassification Loss: 1.5073\r\n",
      "Test() called at batch_idx: 2900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4644, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [46400/110534 (42%)]\tClassification Loss: 1.2588\r\n",
      "Train Epoch: 3 [46560/110534 (42%)]\tClassification Loss: 1.5891\r\n",
      "Train Epoch: 3 [46720/110534 (42%)]\tClassification Loss: 2.2983\r\n",
      "Train Epoch: 3 [46880/110534 (42%)]\tClassification Loss: 1.4750\r\n",
      "Train Epoch: 3 [47040/110534 (43%)]\tClassification Loss: 1.7078\r\n",
      "Train Epoch: 3 [47200/110534 (43%)]\tClassification Loss: 1.4289\r\n",
      "Train Epoch: 3 [47360/110534 (43%)]\tClassification Loss: 1.9302\r\n",
      "Train Epoch: 3 [47520/110534 (43%)]\tClassification Loss: 1.9184\r\n",
      "Train Epoch: 3 [47680/110534 (43%)]\tClassification Loss: 1.5256\r\n",
      "Train Epoch: 3 [47840/110534 (43%)]\tClassification Loss: 1.8154\r\n",
      "Test() called at batch_idx: 3000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4664, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [48000/110534 (43%)]\tClassification Loss: 1.8038\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_3000.pth.tar\r\n",
      "Train Epoch: 3 [48160/110534 (44%)]\tClassification Loss: 1.5575\r\n",
      "Train Epoch: 3 [48320/110534 (44%)]\tClassification Loss: 1.3017\r\n",
      "Train Epoch: 3 [48480/110534 (44%)]\tClassification Loss: 1.9521\r\n",
      "Train Epoch: 3 [48640/110534 (44%)]\tClassification Loss: 1.7628\r\n",
      "Train Epoch: 3 [48800/110534 (44%)]\tClassification Loss: 1.2361\r\n",
      "Train Epoch: 3 [48960/110534 (44%)]\tClassification Loss: 1.5519\r\n",
      "Train Epoch: 3 [49120/110534 (44%)]\tClassification Loss: 1.7257\r\n",
      "Train Epoch: 3 [49280/110534 (45%)]\tClassification Loss: 1.1371\r\n",
      "Train Epoch: 3 [49440/110534 (45%)]\tClassification Loss: 1.5991\r\n",
      "Test() called at batch_idx: 3100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4785, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [49600/110534 (45%)]\tClassification Loss: 1.5130\r\n",
      "Train Epoch: 3 [49760/110534 (45%)]\tClassification Loss: 1.6215\r\n",
      "Train Epoch: 3 [49920/110534 (45%)]\tClassification Loss: 2.2999\r\n",
      "Train Epoch: 3 [50080/110534 (45%)]\tClassification Loss: 1.3411\r\n",
      "Train Epoch: 3 [50240/110534 (45%)]\tClassification Loss: 1.7537\r\n",
      "Train Epoch: 3 [50400/110534 (46%)]\tClassification Loss: 1.7708\r\n",
      "Train Epoch: 3 [50560/110534 (46%)]\tClassification Loss: 1.4681\r\n",
      "Train Epoch: 3 [50720/110534 (46%)]\tClassification Loss: 1.8065\r\n",
      "Train Epoch: 3 [50880/110534 (46%)]\tClassification Loss: 1.3161\r\n",
      "Train Epoch: 3 [51040/110534 (46%)]\tClassification Loss: 1.8561\r\n",
      "Test() called at batch_idx: 3200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4682, Accuracy: 292/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [51200/110534 (46%)]\tClassification Loss: 1.6159\r\n",
      "Train Epoch: 3 [51360/110534 (46%)]\tClassification Loss: 1.9096\r\n",
      "Train Epoch: 3 [51520/110534 (47%)]\tClassification Loss: 1.1494\r\n",
      "Train Epoch: 3 [51680/110534 (47%)]\tClassification Loss: 1.8706\r\n",
      "Train Epoch: 3 [51840/110534 (47%)]\tClassification Loss: 1.7627\r\n",
      "Train Epoch: 3 [52000/110534 (47%)]\tClassification Loss: 0.9660\r\n",
      "Train Epoch: 3 [52160/110534 (47%)]\tClassification Loss: 1.9403\r\n",
      "Train Epoch: 3 [52320/110534 (47%)]\tClassification Loss: 1.4293\r\n",
      "Train Epoch: 3 [52480/110534 (47%)]\tClassification Loss: 1.7268\r\n",
      "Train Epoch: 3 [52640/110534 (48%)]\tClassification Loss: 1.4977\r\n",
      "Test() called at batch_idx: 3300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4844, Accuracy: 286/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 3 [52800/110534 (48%)]\tClassification Loss: 1.3767\r\n",
      "Train Epoch: 3 [52960/110534 (48%)]\tClassification Loss: 1.4965\r\n",
      "Train Epoch: 3 [53120/110534 (48%)]\tClassification Loss: 1.7260\r\n",
      "Train Epoch: 3 [53280/110534 (48%)]\tClassification Loss: 1.5944\r\n",
      "Train Epoch: 3 [53440/110534 (48%)]\tClassification Loss: 1.4570\r\n",
      "Train Epoch: 3 [53600/110534 (48%)]\tClassification Loss: 1.2555\r\n",
      "Train Epoch: 3 [53760/110534 (49%)]\tClassification Loss: 1.6105\r\n",
      "Train Epoch: 3 [53920/110534 (49%)]\tClassification Loss: 1.7903\r\n",
      "Train Epoch: 3 [54080/110534 (49%)]\tClassification Loss: 1.0662\r\n",
      "Train Epoch: 3 [54240/110534 (49%)]\tClassification Loss: 2.3546\r\n",
      "Test() called at batch_idx: 3400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4801, Accuracy: 291/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [54400/110534 (49%)]\tClassification Loss: 1.9626\r\n",
      "Train Epoch: 3 [54560/110534 (49%)]\tClassification Loss: 1.2171\r\n",
      "Train Epoch: 3 [54720/110534 (50%)]\tClassification Loss: 2.0043\r\n",
      "Train Epoch: 3 [54880/110534 (50%)]\tClassification Loss: 1.2445\r\n",
      "Train Epoch: 3 [55040/110534 (50%)]\tClassification Loss: 1.7037\r\n",
      "Train Epoch: 3 [55200/110534 (50%)]\tClassification Loss: 1.3379\r\n",
      "Train Epoch: 3 [55360/110534 (50%)]\tClassification Loss: 1.9108\r\n",
      "Train Epoch: 3 [55520/110534 (50%)]\tClassification Loss: 1.2931\r\n",
      "Train Epoch: 3 [55680/110534 (50%)]\tClassification Loss: 1.2366\r\n",
      "Train Epoch: 3 [55840/110534 (51%)]\tClassification Loss: 1.7144\r\n",
      "Test() called at batch_idx: 3500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4688, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [56000/110534 (51%)]\tClassification Loss: 1.9369\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_3500.pth.tar\r\n",
      "Train Epoch: 3 [56160/110534 (51%)]\tClassification Loss: 1.6157\r\n",
      "Train Epoch: 3 [56320/110534 (51%)]\tClassification Loss: 1.4159\r\n",
      "Train Epoch: 3 [56480/110534 (51%)]\tClassification Loss: 1.7614\r\n",
      "Train Epoch: 3 [56640/110534 (51%)]\tClassification Loss: 2.1302\r\n",
      "Train Epoch: 3 [56800/110534 (51%)]\tClassification Loss: 1.2220\r\n",
      "Train Epoch: 3 [56960/110534 (52%)]\tClassification Loss: 1.8325\r\n",
      "Train Epoch: 3 [57120/110534 (52%)]\tClassification Loss: 1.8924\r\n",
      "Train Epoch: 3 [57280/110534 (52%)]\tClassification Loss: 2.1257\r\n",
      "Train Epoch: 3 [57440/110534 (52%)]\tClassification Loss: 1.5872\r\n",
      "Test() called at batch_idx: 3600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4802, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [57600/110534 (52%)]\tClassification Loss: 1.7137\r\n",
      "Train Epoch: 3 [57760/110534 (52%)]\tClassification Loss: 1.5029\r\n",
      "Train Epoch: 3 [57920/110534 (52%)]\tClassification Loss: 1.4639\r\n",
      "Train Epoch: 3 [58080/110534 (53%)]\tClassification Loss: 1.2493\r\n",
      "Train Epoch: 3 [58240/110534 (53%)]\tClassification Loss: 1.0509\r\n",
      "Train Epoch: 3 [58400/110534 (53%)]\tClassification Loss: 1.6835\r\n",
      "Train Epoch: 3 [58560/110534 (53%)]\tClassification Loss: 1.3056\r\n",
      "Train Epoch: 3 [58720/110534 (53%)]\tClassification Loss: 1.4908\r\n",
      "Train Epoch: 3 [58880/110534 (53%)]\tClassification Loss: 1.2572\r\n",
      "Train Epoch: 3 [59040/110534 (53%)]\tClassification Loss: 1.5575\r\n",
      "Test() called at batch_idx: 3700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4835, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [59200/110534 (54%)]\tClassification Loss: 1.6371\r\n",
      "Train Epoch: 3 [59360/110534 (54%)]\tClassification Loss: 1.8542\r\n",
      "Train Epoch: 3 [59520/110534 (54%)]\tClassification Loss: 1.3934\r\n",
      "Train Epoch: 3 [59680/110534 (54%)]\tClassification Loss: 1.9226\r\n",
      "Train Epoch: 3 [59840/110534 (54%)]\tClassification Loss: 1.9139\r\n",
      "Train Epoch: 3 [60000/110534 (54%)]\tClassification Loss: 1.4711\r\n",
      "Train Epoch: 3 [60160/110534 (54%)]\tClassification Loss: 1.1979\r\n",
      "Train Epoch: 3 [60320/110534 (55%)]\tClassification Loss: 1.3137\r\n",
      "Train Epoch: 3 [60480/110534 (55%)]\tClassification Loss: 1.5744\r\n",
      "Train Epoch: 3 [60640/110534 (55%)]\tClassification Loss: 1.4943\r\n",
      "Test() called at batch_idx: 3800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4561, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [60800/110534 (55%)]\tClassification Loss: 1.4393\r\n",
      "Train Epoch: 3 [60960/110534 (55%)]\tClassification Loss: 1.9395\r\n",
      "Train Epoch: 3 [61120/110534 (55%)]\tClassification Loss: 1.8036\r\n",
      "Train Epoch: 3 [61280/110534 (55%)]\tClassification Loss: 1.4658\r\n",
      "Train Epoch: 3 [61440/110534 (56%)]\tClassification Loss: 2.3694\r\n",
      "Train Epoch: 3 [61600/110534 (56%)]\tClassification Loss: 1.5751\r\n",
      "Train Epoch: 3 [61760/110534 (56%)]\tClassification Loss: 1.3982\r\n",
      "Train Epoch: 3 [61920/110534 (56%)]\tClassification Loss: 1.6076\r\n",
      "Train Epoch: 3 [62080/110534 (56%)]\tClassification Loss: 1.5129\r\n",
      "Train Epoch: 3 [62240/110534 (56%)]\tClassification Loss: 1.6911\r\n",
      "Test() called at batch_idx: 3900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4620, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [62400/110534 (56%)]\tClassification Loss: 1.6186\r\n",
      "Train Epoch: 3 [62560/110534 (57%)]\tClassification Loss: 1.3577\r\n",
      "Train Epoch: 3 [62720/110534 (57%)]\tClassification Loss: 0.9390\r\n",
      "Train Epoch: 3 [62880/110534 (57%)]\tClassification Loss: 1.3681\r\n",
      "Train Epoch: 3 [63040/110534 (57%)]\tClassification Loss: 1.2060\r\n",
      "Train Epoch: 3 [63200/110534 (57%)]\tClassification Loss: 1.1761\r\n",
      "Train Epoch: 3 [63360/110534 (57%)]\tClassification Loss: 1.3560\r\n",
      "Train Epoch: 3 [63520/110534 (57%)]\tClassification Loss: 1.5342\r\n",
      "Train Epoch: 3 [63680/110534 (58%)]\tClassification Loss: 1.9835\r\n",
      "Train Epoch: 3 [63840/110534 (58%)]\tClassification Loss: 1.5217\r\n",
      "Test() called at batch_idx: 4000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4588, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [64000/110534 (58%)]\tClassification Loss: 1.6116\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_4000.pth.tar\r\n",
      "Train Epoch: 3 [64160/110534 (58%)]\tClassification Loss: 1.6400\r\n",
      "Train Epoch: 3 [64320/110534 (58%)]\tClassification Loss: 1.2976\r\n",
      "Train Epoch: 3 [64480/110534 (58%)]\tClassification Loss: 1.7906\r\n",
      "Train Epoch: 3 [64640/110534 (58%)]\tClassification Loss: 2.2806\r\n",
      "Train Epoch: 3 [64800/110534 (59%)]\tClassification Loss: 1.3710\r\n",
      "Train Epoch: 3 [64960/110534 (59%)]\tClassification Loss: 1.3977\r\n",
      "Train Epoch: 3 [65120/110534 (59%)]\tClassification Loss: 1.3084\r\n",
      "Train Epoch: 3 [65280/110534 (59%)]\tClassification Loss: 1.4920\r\n",
      "Train Epoch: 3 [65440/110534 (59%)]\tClassification Loss: 1.4480\r\n",
      "Test() called at batch_idx: 4100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4646, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [65600/110534 (59%)]\tClassification Loss: 1.1055\r\n",
      "Train Epoch: 3 [65760/110534 (59%)]\tClassification Loss: 2.0564\r\n",
      "Train Epoch: 3 [65920/110534 (60%)]\tClassification Loss: 1.3688\r\n",
      "Train Epoch: 3 [66080/110534 (60%)]\tClassification Loss: 1.6599\r\n",
      "Train Epoch: 3 [66240/110534 (60%)]\tClassification Loss: 1.5651\r\n",
      "Train Epoch: 3 [66400/110534 (60%)]\tClassification Loss: 1.7524\r\n",
      "Train Epoch: 3 [66560/110534 (60%)]\tClassification Loss: 1.5232\r\n",
      "Train Epoch: 3 [66720/110534 (60%)]\tClassification Loss: 1.3446\r\n",
      "Train Epoch: 3 [66880/110534 (61%)]\tClassification Loss: 1.6307\r\n",
      "Train Epoch: 3 [67040/110534 (61%)]\tClassification Loss: 1.5526\r\n",
      "Test() called at batch_idx: 4200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4627, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [67200/110534 (61%)]\tClassification Loss: 1.8972\r\n",
      "Train Epoch: 3 [67360/110534 (61%)]\tClassification Loss: 1.8217\r\n",
      "Train Epoch: 3 [67520/110534 (61%)]\tClassification Loss: 1.5063\r\n",
      "Train Epoch: 3 [67680/110534 (61%)]\tClassification Loss: 1.4392\r\n",
      "Train Epoch: 3 [67840/110534 (61%)]\tClassification Loss: 1.7133\r\n",
      "Train Epoch: 3 [68000/110534 (62%)]\tClassification Loss: 1.4353\r\n",
      "Train Epoch: 3 [68160/110534 (62%)]\tClassification Loss: 1.4467\r\n",
      "Train Epoch: 3 [68320/110534 (62%)]\tClassification Loss: 1.7523\r\n",
      "Train Epoch: 3 [68480/110534 (62%)]\tClassification Loss: 2.1770\r\n",
      "Train Epoch: 3 [68640/110534 (62%)]\tClassification Loss: 1.2292\r\n",
      "Test() called at batch_idx: 4300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4572, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [68800/110534 (62%)]\tClassification Loss: 1.7481\r\n",
      "Train Epoch: 3 [68960/110534 (62%)]\tClassification Loss: 1.2580\r\n",
      "Train Epoch: 3 [69120/110534 (63%)]\tClassification Loss: 1.2902\r\n",
      "Train Epoch: 3 [69280/110534 (63%)]\tClassification Loss: 1.4584\r\n",
      "Train Epoch: 3 [69440/110534 (63%)]\tClassification Loss: 1.3411\r\n",
      "Train Epoch: 3 [69600/110534 (63%)]\tClassification Loss: 1.5220\r\n",
      "Train Epoch: 3 [69760/110534 (63%)]\tClassification Loss: 1.2683\r\n",
      "Train Epoch: 3 [69920/110534 (63%)]\tClassification Loss: 1.7676\r\n",
      "Train Epoch: 3 [70080/110534 (63%)]\tClassification Loss: 1.2648\r\n",
      "Train Epoch: 3 [70240/110534 (64%)]\tClassification Loss: 1.5510\r\n",
      "Test() called at batch_idx: 4400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4553, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [70400/110534 (64%)]\tClassification Loss: 1.3523\r\n",
      "Train Epoch: 3 [70560/110534 (64%)]\tClassification Loss: 1.5923\r\n",
      "Train Epoch: 3 [70720/110534 (64%)]\tClassification Loss: 0.9911\r\n",
      "Train Epoch: 3 [70880/110534 (64%)]\tClassification Loss: 1.8260\r\n",
      "Train Epoch: 3 [71040/110534 (64%)]\tClassification Loss: 1.4705\r\n",
      "Train Epoch: 3 [71200/110534 (64%)]\tClassification Loss: 2.0953\r\n",
      "Train Epoch: 3 [71360/110534 (65%)]\tClassification Loss: 2.3686\r\n",
      "Train Epoch: 3 [71520/110534 (65%)]\tClassification Loss: 2.0815\r\n",
      "Train Epoch: 3 [71680/110534 (65%)]\tClassification Loss: 1.4287\r\n",
      "Train Epoch: 3 [71840/110534 (65%)]\tClassification Loss: 1.9349\r\n",
      "Test() called at batch_idx: 4500\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\r\n",
      "    self._send(header + buf)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\r\n",
      "    n = write(self._handle, buf)\r\n",
      "BrokenPipeError: [Errno 32] Broken pipe\r\n",
      "\r\n",
      "Test set: Average loss: 1.4853, Accuracy: 286/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 3 [72000/110534 (65%)]\tClassification Loss: 1.5104\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_4500.pth.tar\r\n",
      "Train Epoch: 3 [72160/110534 (65%)]\tClassification Loss: 1.7951\r\n",
      "Train Epoch: 3 [72320/110534 (65%)]\tClassification Loss: 1.5252\r\n",
      "Train Epoch: 3 [72480/110534 (66%)]\tClassification Loss: 1.7650\r\n",
      "Train Epoch: 3 [72640/110534 (66%)]\tClassification Loss: 1.6927\r\n",
      "Train Epoch: 3 [72800/110534 (66%)]\tClassification Loss: 1.1683\r\n",
      "Train Epoch: 3 [72960/110534 (66%)]\tClassification Loss: 1.6839\r\n",
      "Train Epoch: 3 [73120/110534 (66%)]\tClassification Loss: 1.4760\r\n",
      "Train Epoch: 3 [73280/110534 (66%)]\tClassification Loss: 1.4388\r\n",
      "Train Epoch: 3 [73440/110534 (66%)]\tClassification Loss: 1.5356\r\n",
      "Test() called at batch_idx: 4600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4674, Accuracy: 303/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [73600/110534 (67%)]\tClassification Loss: 1.8784\r\n",
      "Train Epoch: 3 [73760/110534 (67%)]\tClassification Loss: 1.4113\r\n",
      "Train Epoch: 3 [73920/110534 (67%)]\tClassification Loss: 1.8936\r\n",
      "Train Epoch: 3 [74080/110534 (67%)]\tClassification Loss: 1.8647\r\n",
      "Train Epoch: 3 [74240/110534 (67%)]\tClassification Loss: 1.5074\r\n",
      "Train Epoch: 3 [74400/110534 (67%)]\tClassification Loss: 1.5832\r\n",
      "Train Epoch: 3 [74560/110534 (67%)]\tClassification Loss: 1.1095\r\n",
      "Train Epoch: 3 [74720/110534 (68%)]\tClassification Loss: 1.1938\r\n",
      "Train Epoch: 3 [74880/110534 (68%)]\tClassification Loss: 1.4261\r\n",
      "Train Epoch: 3 [75040/110534 (68%)]\tClassification Loss: 1.6553\r\n",
      "Test() called at batch_idx: 4700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4670, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [75200/110534 (68%)]\tClassification Loss: 1.4615\r\n",
      "Train Epoch: 3 [75360/110534 (68%)]\tClassification Loss: 1.5920\r\n",
      "Train Epoch: 3 [75520/110534 (68%)]\tClassification Loss: 1.5335\r\n",
      "Train Epoch: 3 [75680/110534 (68%)]\tClassification Loss: 1.1404\r\n",
      "Train Epoch: 3 [75840/110534 (69%)]\tClassification Loss: 1.7607\r\n",
      "Train Epoch: 3 [76000/110534 (69%)]\tClassification Loss: 1.4142\r\n",
      "Train Epoch: 3 [76160/110534 (69%)]\tClassification Loss: 1.6015\r\n",
      "Train Epoch: 3 [76320/110534 (69%)]\tClassification Loss: 1.8327\r\n",
      "Train Epoch: 3 [76480/110534 (69%)]\tClassification Loss: 1.1545\r\n",
      "Train Epoch: 3 [76640/110534 (69%)]\tClassification Loss: 1.5669\r\n",
      "Test() called at batch_idx: 4800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4670, Accuracy: 303/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [76800/110534 (69%)]\tClassification Loss: 1.6620\r\n",
      "Train Epoch: 3 [76960/110534 (70%)]\tClassification Loss: 1.3114\r\n",
      "Train Epoch: 3 [77120/110534 (70%)]\tClassification Loss: 1.2884\r\n",
      "Train Epoch: 3 [77280/110534 (70%)]\tClassification Loss: 1.5834\r\n",
      "Train Epoch: 3 [77440/110534 (70%)]\tClassification Loss: 1.4285\r\n",
      "Train Epoch: 3 [77600/110534 (70%)]\tClassification Loss: 1.4051\r\n",
      "Train Epoch: 3 [77760/110534 (70%)]\tClassification Loss: 1.1340\r\n",
      "Train Epoch: 3 [77920/110534 (70%)]\tClassification Loss: 1.4664\r\n",
      "Train Epoch: 3 [78080/110534 (71%)]\tClassification Loss: 1.5938\r\n",
      "Train Epoch: 3 [78240/110534 (71%)]\tClassification Loss: 1.8963\r\n",
      "Test() called at batch_idx: 4900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4567, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [78400/110534 (71%)]\tClassification Loss: 1.6791\r\n",
      "Train Epoch: 3 [78560/110534 (71%)]\tClassification Loss: 1.5722\r\n",
      "Train Epoch: 3 [78720/110534 (71%)]\tClassification Loss: 1.7427\r\n",
      "Train Epoch: 3 [78880/110534 (71%)]\tClassification Loss: 2.4606\r\n",
      "Train Epoch: 3 [79040/110534 (72%)]\tClassification Loss: 1.4196\r\n",
      "Train Epoch: 3 [79200/110534 (72%)]\tClassification Loss: 1.1146\r\n",
      "Train Epoch: 3 [79360/110534 (72%)]\tClassification Loss: 1.2761\r\n",
      "Train Epoch: 3 [79520/110534 (72%)]\tClassification Loss: 1.1189\r\n",
      "Train Epoch: 3 [79680/110534 (72%)]\tClassification Loss: 0.8157\r\n",
      "Train Epoch: 3 [79840/110534 (72%)]\tClassification Loss: 1.8840\r\n",
      "Test() called at batch_idx: 5000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4583, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [80000/110534 (72%)]\tClassification Loss: 1.5320\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_5000.pth.tar\r\n",
      "Train Epoch: 3 [80160/110534 (73%)]\tClassification Loss: 1.6113\r\n",
      "Train Epoch: 3 [80320/110534 (73%)]\tClassification Loss: 1.5751\r\n",
      "Train Epoch: 3 [80480/110534 (73%)]\tClassification Loss: 1.6006\r\n",
      "Train Epoch: 3 [80640/110534 (73%)]\tClassification Loss: 1.2861\r\n",
      "Train Epoch: 3 [80800/110534 (73%)]\tClassification Loss: 1.8943\r\n",
      "Train Epoch: 3 [80960/110534 (73%)]\tClassification Loss: 1.8034\r\n",
      "Train Epoch: 3 [81120/110534 (73%)]\tClassification Loss: 1.8123\r\n",
      "Train Epoch: 3 [81280/110534 (74%)]\tClassification Loss: 1.5272\r\n",
      "Train Epoch: 3 [81440/110534 (74%)]\tClassification Loss: 1.2154\r\n",
      "Test() called at batch_idx: 5100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4603, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [81600/110534 (74%)]\tClassification Loss: 1.4865\r\n",
      "Train Epoch: 3 [81760/110534 (74%)]\tClassification Loss: 1.5285\r\n",
      "Train Epoch: 3 [81920/110534 (74%)]\tClassification Loss: 1.0204\r\n",
      "Train Epoch: 3 [82080/110534 (74%)]\tClassification Loss: 1.6301\r\n",
      "Train Epoch: 3 [82240/110534 (74%)]\tClassification Loss: 1.1855\r\n",
      "Train Epoch: 3 [82400/110534 (75%)]\tClassification Loss: 2.4395\r\n",
      "Train Epoch: 3 [82560/110534 (75%)]\tClassification Loss: 1.3447\r\n",
      "Train Epoch: 3 [82720/110534 (75%)]\tClassification Loss: 2.0263\r\n",
      "Train Epoch: 3 [82880/110534 (75%)]\tClassification Loss: 1.5613\r\n",
      "Train Epoch: 3 [83040/110534 (75%)]\tClassification Loss: 1.2733\r\n",
      "Test() called at batch_idx: 5200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4900, Accuracy: 289/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 3 [83200/110534 (75%)]\tClassification Loss: 1.9954\r\n",
      "Train Epoch: 3 [83360/110534 (75%)]\tClassification Loss: 1.4130\r\n",
      "Train Epoch: 3 [83520/110534 (76%)]\tClassification Loss: 2.0627\r\n",
      "Train Epoch: 3 [83680/110534 (76%)]\tClassification Loss: 1.5386\r\n",
      "Train Epoch: 3 [83840/110534 (76%)]\tClassification Loss: 1.8719\r\n",
      "Train Epoch: 3 [84000/110534 (76%)]\tClassification Loss: 1.6867\r\n",
      "Train Epoch: 3 [84160/110534 (76%)]\tClassification Loss: 1.1890\r\n",
      "Train Epoch: 3 [84320/110534 (76%)]\tClassification Loss: 1.6549\r\n",
      "Train Epoch: 3 [84480/110534 (76%)]\tClassification Loss: 2.0296\r\n",
      "Train Epoch: 3 [84640/110534 (77%)]\tClassification Loss: 1.1919\r\n",
      "Test() called at batch_idx: 5300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4662, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [84800/110534 (77%)]\tClassification Loss: 1.7368\r\n",
      "Train Epoch: 3 [84960/110534 (77%)]\tClassification Loss: 1.3264\r\n",
      "Train Epoch: 3 [85120/110534 (77%)]\tClassification Loss: 1.6431\r\n",
      "Train Epoch: 3 [85280/110534 (77%)]\tClassification Loss: 1.5708\r\n",
      "Train Epoch: 3 [85440/110534 (77%)]\tClassification Loss: 1.2207\r\n",
      "Train Epoch: 3 [85600/110534 (77%)]\tClassification Loss: 1.3180\r\n",
      "Train Epoch: 3 [85760/110534 (78%)]\tClassification Loss: 1.9789\r\n",
      "Train Epoch: 3 [85920/110534 (78%)]\tClassification Loss: 1.7612\r\n",
      "Train Epoch: 3 [86080/110534 (78%)]\tClassification Loss: 1.3481\r\n",
      "Train Epoch: 3 [86240/110534 (78%)]\tClassification Loss: 1.2427\r\n",
      "Test() called at batch_idx: 5400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4577, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [86400/110534 (78%)]\tClassification Loss: 1.2056\r\n",
      "Train Epoch: 3 [86560/110534 (78%)]\tClassification Loss: 1.5217\r\n",
      "Train Epoch: 3 [86720/110534 (78%)]\tClassification Loss: 1.6569\r\n",
      "Train Epoch: 3 [86880/110534 (79%)]\tClassification Loss: 1.2720\r\n",
      "Train Epoch: 3 [87040/110534 (79%)]\tClassification Loss: 1.8763\r\n",
      "Train Epoch: 3 [87200/110534 (79%)]\tClassification Loss: 1.3367\r\n",
      "Train Epoch: 3 [87360/110534 (79%)]\tClassification Loss: 1.2789\r\n",
      "Train Epoch: 3 [87520/110534 (79%)]\tClassification Loss: 1.4520\r\n",
      "Train Epoch: 3 [87680/110534 (79%)]\tClassification Loss: 1.5979\r\n",
      "Train Epoch: 3 [87840/110534 (79%)]\tClassification Loss: 1.1429\r\n",
      "Test() called at batch_idx: 5500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4547, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [88000/110534 (80%)]\tClassification Loss: 1.5513\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_5500.pth.tar\r\n",
      "Train Epoch: 3 [88160/110534 (80%)]\tClassification Loss: 1.3298\r\n",
      "Train Epoch: 3 [88320/110534 (80%)]\tClassification Loss: 1.2669\r\n",
      "Train Epoch: 3 [88480/110534 (80%)]\tClassification Loss: 1.5202\r\n",
      "Train Epoch: 3 [88640/110534 (80%)]\tClassification Loss: 2.6010\r\n",
      "Train Epoch: 3 [88800/110534 (80%)]\tClassification Loss: 1.9537\r\n",
      "Train Epoch: 3 [88960/110534 (80%)]\tClassification Loss: 1.7616\r\n",
      "Train Epoch: 3 [89120/110534 (81%)]\tClassification Loss: 1.5194\r\n",
      "Train Epoch: 3 [89280/110534 (81%)]\tClassification Loss: 1.1337\r\n",
      "Train Epoch: 3 [89440/110534 (81%)]\tClassification Loss: 1.7014\r\n",
      "Test() called at batch_idx: 5600\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "\r\n",
      "Test set: Average loss: 1.4918, Accuracy: 289/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 3 [89600/110534 (81%)]\tClassification Loss: 1.3632\r\n",
      "Train Epoch: 3 [89760/110534 (81%)]\tClassification Loss: 1.3009\r\n",
      "Train Epoch: 3 [89920/110534 (81%)]\tClassification Loss: 1.6551\r\n",
      "Train Epoch: 3 [90080/110534 (81%)]\tClassification Loss: 1.2763\r\n",
      "Train Epoch: 3 [90240/110534 (82%)]\tClassification Loss: 1.6179\r\n",
      "Train Epoch: 3 [90400/110534 (82%)]\tClassification Loss: 1.6787\r\n",
      "Train Epoch: 3 [90560/110534 (82%)]\tClassification Loss: 1.2316\r\n",
      "Train Epoch: 3 [90720/110534 (82%)]\tClassification Loss: 1.3730\r\n",
      "Train Epoch: 3 [90880/110534 (82%)]\tClassification Loss: 1.4178\r\n",
      "Train Epoch: 3 [91040/110534 (82%)]\tClassification Loss: 1.5217\r\n",
      "Test() called at batch_idx: 5700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4532, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [91200/110534 (83%)]\tClassification Loss: 1.9491\r\n",
      "Train Epoch: 3 [91360/110534 (83%)]\tClassification Loss: 1.4378\r\n",
      "Train Epoch: 3 [91520/110534 (83%)]\tClassification Loss: 1.7376\r\n",
      "Train Epoch: 3 [91680/110534 (83%)]\tClassification Loss: 1.3002\r\n",
      "Train Epoch: 3 [91840/110534 (83%)]\tClassification Loss: 1.4914\r\n",
      "Train Epoch: 3 [92000/110534 (83%)]\tClassification Loss: 1.1590\r\n",
      "Train Epoch: 3 [92160/110534 (83%)]\tClassification Loss: 1.5606\r\n",
      "Train Epoch: 3 [92320/110534 (84%)]\tClassification Loss: 1.7525\r\n",
      "Train Epoch: 3 [92480/110534 (84%)]\tClassification Loss: 1.3547\r\n",
      "Train Epoch: 3 [92640/110534 (84%)]\tClassification Loss: 1.9099\r\n",
      "Test() called at batch_idx: 5800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4696, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [92800/110534 (84%)]\tClassification Loss: 1.8628\r\n",
      "Train Epoch: 3 [92960/110534 (84%)]\tClassification Loss: 1.7309\r\n",
      "Train Epoch: 3 [93120/110534 (84%)]\tClassification Loss: 1.8018\r\n",
      "Train Epoch: 3 [93280/110534 (84%)]\tClassification Loss: 0.9440\r\n",
      "Train Epoch: 3 [93440/110534 (85%)]\tClassification Loss: 1.6977\r\n",
      "Train Epoch: 3 [93600/110534 (85%)]\tClassification Loss: 1.4288\r\n",
      "Train Epoch: 3 [93760/110534 (85%)]\tClassification Loss: 1.2205\r\n",
      "Train Epoch: 3 [93920/110534 (85%)]\tClassification Loss: 1.6723\r\n",
      "Train Epoch: 3 [94080/110534 (85%)]\tClassification Loss: 1.8295\r\n",
      "Train Epoch: 3 [94240/110534 (85%)]\tClassification Loss: 0.9736\r\n",
      "Test() called at batch_idx: 5900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4770, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [94400/110534 (85%)]\tClassification Loss: 1.6278\r\n",
      "Train Epoch: 3 [94560/110534 (86%)]\tClassification Loss: 1.9043\r\n",
      "Train Epoch: 3 [94720/110534 (86%)]\tClassification Loss: 1.0833\r\n",
      "Train Epoch: 3 [94880/110534 (86%)]\tClassification Loss: 1.5934\r\n",
      "Train Epoch: 3 [95040/110534 (86%)]\tClassification Loss: 1.8064\r\n",
      "Train Epoch: 3 [95200/110534 (86%)]\tClassification Loss: 1.5695\r\n",
      "Train Epoch: 3 [95360/110534 (86%)]\tClassification Loss: 1.7298\r\n",
      "Train Epoch: 3 [95520/110534 (86%)]\tClassification Loss: 1.7807\r\n",
      "Train Epoch: 3 [95680/110534 (87%)]\tClassification Loss: 1.1865\r\n",
      "Train Epoch: 3 [95840/110534 (87%)]\tClassification Loss: 2.0118\r\n",
      "Test() called at batch_idx: 6000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4797, Accuracy: 291/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 3 [96000/110534 (87%)]\tClassification Loss: 1.3727\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_6000.pth.tar\r\n",
      "Train Epoch: 3 [96160/110534 (87%)]\tClassification Loss: 1.7909\r\n",
      "Train Epoch: 3 [96320/110534 (87%)]\tClassification Loss: 1.3929\r\n",
      "Train Epoch: 3 [96480/110534 (87%)]\tClassification Loss: 1.7491\r\n",
      "Train Epoch: 3 [96640/110534 (87%)]\tClassification Loss: 1.3085\r\n",
      "Train Epoch: 3 [96800/110534 (88%)]\tClassification Loss: 1.2043\r\n",
      "Train Epoch: 3 [96960/110534 (88%)]\tClassification Loss: 1.7810\r\n",
      "Train Epoch: 3 [97120/110534 (88%)]\tClassification Loss: 2.0737\r\n",
      "Train Epoch: 3 [97280/110534 (88%)]\tClassification Loss: 1.4562\r\n",
      "Train Epoch: 3 [97440/110534 (88%)]\tClassification Loss: 1.4780\r\n",
      "Test() called at batch_idx: 6100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4521, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [97600/110534 (88%)]\tClassification Loss: 1.8178\r\n",
      "Train Epoch: 3 [97760/110534 (88%)]\tClassification Loss: 1.9442\r\n",
      "Train Epoch: 3 [97920/110534 (89%)]\tClassification Loss: 1.4421\r\n",
      "Train Epoch: 3 [98080/110534 (89%)]\tClassification Loss: 1.4232\r\n",
      "Train Epoch: 3 [98240/110534 (89%)]\tClassification Loss: 1.4768\r\n",
      "Train Epoch: 3 [98400/110534 (89%)]\tClassification Loss: 1.5497\r\n",
      "Train Epoch: 3 [98560/110534 (89%)]\tClassification Loss: 2.4953\r\n",
      "Train Epoch: 3 [98720/110534 (89%)]\tClassification Loss: 1.6867\r\n",
      "Train Epoch: 3 [98880/110534 (89%)]\tClassification Loss: 1.7520\r\n",
      "Train Epoch: 3 [99040/110534 (90%)]\tClassification Loss: 1.9109\r\n",
      "Test() called at batch_idx: 6200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4586, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [99200/110534 (90%)]\tClassification Loss: 2.0324\r\n",
      "Train Epoch: 3 [99360/110534 (90%)]\tClassification Loss: 1.9109\r\n",
      "Train Epoch: 3 [99520/110534 (90%)]\tClassification Loss: 1.8701\r\n",
      "Train Epoch: 3 [99680/110534 (90%)]\tClassification Loss: 1.4864\r\n",
      "Train Epoch: 3 [99840/110534 (90%)]\tClassification Loss: 1.7164\r\n",
      "Train Epoch: 3 [100000/110534 (90%)]\tClassification Loss: 1.5256\r\n",
      "Train Epoch: 3 [100160/110534 (91%)]\tClassification Loss: 1.4753\r\n",
      "Train Epoch: 3 [100320/110534 (91%)]\tClassification Loss: 2.0527\r\n",
      "Train Epoch: 3 [100480/110534 (91%)]\tClassification Loss: 1.0856\r\n",
      "Train Epoch: 3 [100640/110534 (91%)]\tClassification Loss: 1.6019\r\n",
      "Test() called at batch_idx: 6300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4528, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [100800/110534 (91%)]\tClassification Loss: 1.9304\r\n",
      "Train Epoch: 3 [100960/110534 (91%)]\tClassification Loss: 1.4725\r\n",
      "Train Epoch: 3 [101120/110534 (91%)]\tClassification Loss: 1.4424\r\n",
      "Train Epoch: 3 [101280/110534 (92%)]\tClassification Loss: 1.0008\r\n",
      "Train Epoch: 3 [101440/110534 (92%)]\tClassification Loss: 1.6485\r\n",
      "Train Epoch: 3 [101600/110534 (92%)]\tClassification Loss: 1.6545\r\n",
      "Train Epoch: 3 [101760/110534 (92%)]\tClassification Loss: 1.2551\r\n",
      "Train Epoch: 3 [101920/110534 (92%)]\tClassification Loss: 1.2650\r\n",
      "Train Epoch: 3 [102080/110534 (92%)]\tClassification Loss: 1.7109\r\n",
      "Train Epoch: 3 [102240/110534 (93%)]\tClassification Loss: 1.3014\r\n",
      "Test() called at batch_idx: 6400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4515, Accuracy: 303/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [102400/110534 (93%)]\tClassification Loss: 1.5245\r\n",
      "Train Epoch: 3 [102560/110534 (93%)]\tClassification Loss: 1.3631\r\n",
      "Train Epoch: 3 [102720/110534 (93%)]\tClassification Loss: 1.7365\r\n",
      "Train Epoch: 3 [102880/110534 (93%)]\tClassification Loss: 2.1644\r\n",
      "Train Epoch: 3 [103040/110534 (93%)]\tClassification Loss: 1.6496\r\n",
      "Train Epoch: 3 [103200/110534 (93%)]\tClassification Loss: 1.6391\r\n",
      "Train Epoch: 3 [103360/110534 (94%)]\tClassification Loss: 1.7968\r\n",
      "Train Epoch: 3 [103520/110534 (94%)]\tClassification Loss: 1.4163\r\n",
      "Train Epoch: 3 [103680/110534 (94%)]\tClassification Loss: 1.1480\r\n",
      "Train Epoch: 3 [103840/110534 (94%)]\tClassification Loss: 1.4094\r\n",
      "Test() called at batch_idx: 6500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4469, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [104000/110534 (94%)]\tClassification Loss: 1.4141\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_6500.pth.tar\r\n",
      "Train Epoch: 3 [104160/110534 (94%)]\tClassification Loss: 1.9743\r\n",
      "Train Epoch: 3 [104320/110534 (94%)]\tClassification Loss: 2.2362\r\n",
      "Train Epoch: 3 [104480/110534 (95%)]\tClassification Loss: 1.5235\r\n",
      "Train Epoch: 3 [104640/110534 (95%)]\tClassification Loss: 1.3573\r\n",
      "Train Epoch: 3 [104800/110534 (95%)]\tClassification Loss: 1.2725\r\n",
      "Train Epoch: 3 [104960/110534 (95%)]\tClassification Loss: 0.9851\r\n",
      "Train Epoch: 3 [105120/110534 (95%)]\tClassification Loss: 1.4288\r\n",
      "Train Epoch: 3 [105280/110534 (95%)]\tClassification Loss: 1.4351\r\n",
      "Train Epoch: 3 [105440/110534 (95%)]\tClassification Loss: 1.4820\r\n",
      "Test() called at batch_idx: 6600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4638, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [105600/110534 (96%)]\tClassification Loss: 1.8915\r\n",
      "Train Epoch: 3 [105760/110534 (96%)]\tClassification Loss: 1.4155\r\n",
      "Train Epoch: 3 [105920/110534 (96%)]\tClassification Loss: 0.8549\r\n",
      "Train Epoch: 3 [106080/110534 (96%)]\tClassification Loss: 1.9048\r\n",
      "Train Epoch: 3 [106240/110534 (96%)]\tClassification Loss: 1.7848\r\n",
      "Train Epoch: 3 [106400/110534 (96%)]\tClassification Loss: 1.1829\r\n",
      "Train Epoch: 3 [106560/110534 (96%)]\tClassification Loss: 1.1452\r\n",
      "Train Epoch: 3 [106720/110534 (97%)]\tClassification Loss: 1.5756\r\n",
      "Train Epoch: 3 [106880/110534 (97%)]\tClassification Loss: 1.6385\r\n",
      "Train Epoch: 3 [107040/110534 (97%)]\tClassification Loss: 1.4562\r\n",
      "Test() called at batch_idx: 6700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4504, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 3 [107200/110534 (97%)]\tClassification Loss: 1.7145\r\n",
      "Train Epoch: 3 [107360/110534 (97%)]\tClassification Loss: 1.7997\r\n",
      "Train Epoch: 3 [107520/110534 (97%)]\tClassification Loss: 1.8879\r\n",
      "Train Epoch: 3 [107680/110534 (97%)]\tClassification Loss: 1.7358\r\n",
      "Train Epoch: 3 [107840/110534 (98%)]\tClassification Loss: 1.2375\r\n",
      "Train Epoch: 3 [108000/110534 (98%)]\tClassification Loss: 1.5935\r\n",
      "Train Epoch: 3 [108160/110534 (98%)]\tClassification Loss: 1.6634\r\n",
      "Train Epoch: 3 [108320/110534 (98%)]\tClassification Loss: 1.1650\r\n",
      "Train Epoch: 3 [108480/110534 (98%)]\tClassification Loss: 1.1184\r\n",
      "Train Epoch: 3 [108640/110534 (98%)]\tClassification Loss: 1.1272\r\n",
      "Test() called at batch_idx: 6800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4517, Accuracy: 306/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 3 [108800/110534 (98%)]\tClassification Loss: 1.5999\r\n",
      "Train Epoch: 3 [108960/110534 (99%)]\tClassification Loss: 1.9705\r\n",
      "Train Epoch: 3 [109120/110534 (99%)]\tClassification Loss: 1.6459\r\n",
      "Train Epoch: 3 [109280/110534 (99%)]\tClassification Loss: 0.9781\r\n",
      "Train Epoch: 3 [109440/110534 (99%)]\tClassification Loss: 1.2445\r\n",
      "Train Epoch: 3 [109600/110534 (99%)]\tClassification Loss: 1.5822\r\n",
      "Train Epoch: 3 [109760/110534 (99%)]\tClassification Loss: 1.4944\r\n",
      "Train Epoch: 3 [109920/110534 (99%)]\tClassification Loss: 1.3449\r\n",
      "Train Epoch: 3 [110080/110534 (100%)]\tClassification Loss: 1.9200\r\n",
      "Train Epoch: 3 [110240/110534 (100%)]\tClassification Loss: 1.2431\r\n",
      "Test() called at batch_idx: 6900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4558, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 3 [110400/110534 (100%)]\tClassification Loss: 0.8662\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_final.pth.tar\r\n",
      "Test() called at batch_idx: 0\r\n",
      "\r\n",
      "Test set: Average loss: 1.4596, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [0/110534 (0%)]\tClassification Loss: 1.4576\r\n",
      "Train Epoch: 4 [160/110534 (0%)]\tClassification Loss: 1.5427\r\n",
      "Train Epoch: 4 [320/110534 (0%)]\tClassification Loss: 0.8466\r\n",
      "Train Epoch: 4 [480/110534 (0%)]\tClassification Loss: 2.1662\r\n",
      "Train Epoch: 4 [640/110534 (1%)]\tClassification Loss: 1.2121\r\n",
      "Train Epoch: 4 [800/110534 (1%)]\tClassification Loss: 1.1457\r\n",
      "Train Epoch: 4 [960/110534 (1%)]\tClassification Loss: 1.4442\r\n",
      "Train Epoch: 4 [1120/110534 (1%)]\tClassification Loss: 1.0603\r\n",
      "Train Epoch: 4 [1280/110534 (1%)]\tClassification Loss: 1.4962\r\n",
      "Train Epoch: 4 [1440/110534 (1%)]\tClassification Loss: 0.9083\r\n",
      "Test() called at batch_idx: 100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4413, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [1600/110534 (1%)]\tClassification Loss: 1.6613\r\n",
      "Train Epoch: 4 [1760/110534 (2%)]\tClassification Loss: 1.8693\r\n",
      "Train Epoch: 4 [1920/110534 (2%)]\tClassification Loss: 1.7857\r\n",
      "Train Epoch: 4 [2080/110534 (2%)]\tClassification Loss: 1.5725\r\n",
      "Train Epoch: 4 [2240/110534 (2%)]\tClassification Loss: 1.8446\r\n",
      "Train Epoch: 4 [2400/110534 (2%)]\tClassification Loss: 1.3879\r\n",
      "Train Epoch: 4 [2560/110534 (2%)]\tClassification Loss: 1.8467\r\n",
      "Train Epoch: 4 [2720/110534 (2%)]\tClassification Loss: 2.0412\r\n",
      "Train Epoch: 4 [2880/110534 (3%)]\tClassification Loss: 2.1495\r\n",
      "Train Epoch: 4 [3040/110534 (3%)]\tClassification Loss: 2.0925\r\n",
      "Test() called at batch_idx: 200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4579, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [3200/110534 (3%)]\tClassification Loss: 1.4732\r\n",
      "Train Epoch: 4 [3360/110534 (3%)]\tClassification Loss: 1.6455\r\n",
      "Train Epoch: 4 [3520/110534 (3%)]\tClassification Loss: 1.5389\r\n",
      "Train Epoch: 4 [3680/110534 (3%)]\tClassification Loss: 1.2245\r\n",
      "Train Epoch: 4 [3840/110534 (3%)]\tClassification Loss: 1.2269\r\n",
      "Train Epoch: 4 [4000/110534 (4%)]\tClassification Loss: 1.4176\r\n",
      "Train Epoch: 4 [4160/110534 (4%)]\tClassification Loss: 1.4107\r\n",
      "Train Epoch: 4 [4320/110534 (4%)]\tClassification Loss: 1.1350\r\n",
      "Train Epoch: 4 [4480/110534 (4%)]\tClassification Loss: 1.2770\r\n",
      "Train Epoch: 4 [4640/110534 (4%)]\tClassification Loss: 1.1507\r\n",
      "Test() called at batch_idx: 300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4754, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [4800/110534 (4%)]\tClassification Loss: 2.0212\r\n",
      "Train Epoch: 4 [4960/110534 (4%)]\tClassification Loss: 1.3295\r\n",
      "Train Epoch: 4 [5120/110534 (5%)]\tClassification Loss: 2.0851\r\n",
      "Train Epoch: 4 [5280/110534 (5%)]\tClassification Loss: 1.1266\r\n",
      "Train Epoch: 4 [5440/110534 (5%)]\tClassification Loss: 1.2364\r\n",
      "Train Epoch: 4 [5600/110534 (5%)]\tClassification Loss: 1.3297\r\n",
      "Train Epoch: 4 [5760/110534 (5%)]\tClassification Loss: 1.5339\r\n",
      "Train Epoch: 4 [5920/110534 (5%)]\tClassification Loss: 1.1299\r\n",
      "Train Epoch: 4 [6080/110534 (6%)]\tClassification Loss: 1.2436\r\n",
      "Train Epoch: 4 [6240/110534 (6%)]\tClassification Loss: 1.1779\r\n",
      "Test() called at batch_idx: 400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4498, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [6400/110534 (6%)]\tClassification Loss: 1.1212\r\n",
      "Train Epoch: 4 [6560/110534 (6%)]\tClassification Loss: 1.8317\r\n",
      "Train Epoch: 4 [6720/110534 (6%)]\tClassification Loss: 1.0960\r\n",
      "Train Epoch: 4 [6880/110534 (6%)]\tClassification Loss: 1.8725\r\n",
      "Train Epoch: 4 [7040/110534 (6%)]\tClassification Loss: 1.2365\r\n",
      "Train Epoch: 4 [7200/110534 (7%)]\tClassification Loss: 1.3643\r\n",
      "Train Epoch: 4 [7360/110534 (7%)]\tClassification Loss: 1.9720\r\n",
      "Train Epoch: 4 [7520/110534 (7%)]\tClassification Loss: 1.2579\r\n",
      "Train Epoch: 4 [7680/110534 (7%)]\tClassification Loss: 1.1733\r\n",
      "Train Epoch: 4 [7840/110534 (7%)]\tClassification Loss: 1.9727\r\n",
      "Test() called at batch_idx: 500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4697, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [8000/110534 (7%)]\tClassification Loss: 1.4218\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_500.pth.tar\r\n",
      "Train Epoch: 4 [8160/110534 (7%)]\tClassification Loss: 1.3542\r\n",
      "Train Epoch: 4 [8320/110534 (8%)]\tClassification Loss: 1.6269\r\n",
      "Train Epoch: 4 [8480/110534 (8%)]\tClassification Loss: 1.2452\r\n",
      "Train Epoch: 4 [8640/110534 (8%)]\tClassification Loss: 1.3943\r\n",
      "Train Epoch: 4 [8800/110534 (8%)]\tClassification Loss: 1.6262\r\n",
      "Train Epoch: 4 [8960/110534 (8%)]\tClassification Loss: 1.7464\r\n",
      "Train Epoch: 4 [9120/110534 (8%)]\tClassification Loss: 1.7057\r\n",
      "Train Epoch: 4 [9280/110534 (8%)]\tClassification Loss: 1.4800\r\n",
      "Train Epoch: 4 [9440/110534 (9%)]\tClassification Loss: 1.1858\r\n",
      "Test() called at batch_idx: 600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4601, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [9600/110534 (9%)]\tClassification Loss: 1.1976\r\n",
      "Train Epoch: 4 [9760/110534 (9%)]\tClassification Loss: 0.9131\r\n",
      "Train Epoch: 4 [9920/110534 (9%)]\tClassification Loss: 1.5658\r\n",
      "Train Epoch: 4 [10080/110534 (9%)]\tClassification Loss: 1.6195\r\n",
      "Train Epoch: 4 [10240/110534 (9%)]\tClassification Loss: 1.2234\r\n",
      "Train Epoch: 4 [10400/110534 (9%)]\tClassification Loss: 1.3661\r\n",
      "Train Epoch: 4 [10560/110534 (10%)]\tClassification Loss: 1.4798\r\n",
      "Train Epoch: 4 [10720/110534 (10%)]\tClassification Loss: 1.8279\r\n",
      "Train Epoch: 4 [10880/110534 (10%)]\tClassification Loss: 1.9394\r\n",
      "Train Epoch: 4 [11040/110534 (10%)]\tClassification Loss: 1.2913\r\n",
      "Test() called at batch_idx: 700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4513, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [11200/110534 (10%)]\tClassification Loss: 1.4404\r\n",
      "Train Epoch: 4 [11360/110534 (10%)]\tClassification Loss: 1.4232\r\n",
      "Train Epoch: 4 [11520/110534 (10%)]\tClassification Loss: 1.8895\r\n",
      "Train Epoch: 4 [11680/110534 (11%)]\tClassification Loss: 1.4898\r\n",
      "Train Epoch: 4 [11840/110534 (11%)]\tClassification Loss: 1.3979\r\n",
      "Train Epoch: 4 [12000/110534 (11%)]\tClassification Loss: 1.3312\r\n",
      "Train Epoch: 4 [12160/110534 (11%)]\tClassification Loss: 1.3153\r\n",
      "Train Epoch: 4 [12320/110534 (11%)]\tClassification Loss: 1.1283\r\n",
      "Train Epoch: 4 [12480/110534 (11%)]\tClassification Loss: 1.1565\r\n",
      "Train Epoch: 4 [12640/110534 (11%)]\tClassification Loss: 1.5858\r\n",
      "Test() called at batch_idx: 800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4551, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [12800/110534 (12%)]\tClassification Loss: 1.3694\r\n",
      "Train Epoch: 4 [12960/110534 (12%)]\tClassification Loss: 1.7097\r\n",
      "Train Epoch: 4 [13120/110534 (12%)]\tClassification Loss: 1.7410\r\n",
      "Train Epoch: 4 [13280/110534 (12%)]\tClassification Loss: 1.5786\r\n",
      "Train Epoch: 4 [13440/110534 (12%)]\tClassification Loss: 1.8909\r\n",
      "Train Epoch: 4 [13600/110534 (12%)]\tClassification Loss: 1.3333\r\n",
      "Train Epoch: 4 [13760/110534 (12%)]\tClassification Loss: 1.5684\r\n",
      "Train Epoch: 4 [13920/110534 (13%)]\tClassification Loss: 1.1137\r\n",
      "Train Epoch: 4 [14080/110534 (13%)]\tClassification Loss: 1.3641\r\n",
      "Train Epoch: 4 [14240/110534 (13%)]\tClassification Loss: 1.8972\r\n",
      "Test() called at batch_idx: 900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4676, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [14400/110534 (13%)]\tClassification Loss: 1.1196\r\n",
      "Train Epoch: 4 [14560/110534 (13%)]\tClassification Loss: 1.3004\r\n",
      "Train Epoch: 4 [14720/110534 (13%)]\tClassification Loss: 1.6547\r\n",
      "Train Epoch: 4 [14880/110534 (13%)]\tClassification Loss: 1.7789\r\n",
      "Train Epoch: 4 [15040/110534 (14%)]\tClassification Loss: 1.3080\r\n",
      "Train Epoch: 4 [15200/110534 (14%)]\tClassification Loss: 1.5297\r\n",
      "Train Epoch: 4 [15360/110534 (14%)]\tClassification Loss: 1.3714\r\n",
      "Train Epoch: 4 [15520/110534 (14%)]\tClassification Loss: 1.4877\r\n",
      "Train Epoch: 4 [15680/110534 (14%)]\tClassification Loss: 1.6932\r\n",
      "Train Epoch: 4 [15840/110534 (14%)]\tClassification Loss: 1.2076\r\n",
      "Test() called at batch_idx: 1000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4613, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [16000/110534 (14%)]\tClassification Loss: 1.1562\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1000.pth.tar\r\n",
      "Train Epoch: 4 [16160/110534 (15%)]\tClassification Loss: 1.0682\r\n",
      "Train Epoch: 4 [16320/110534 (15%)]\tClassification Loss: 1.9491\r\n",
      "Train Epoch: 4 [16480/110534 (15%)]\tClassification Loss: 1.4490\r\n",
      "Train Epoch: 4 [16640/110534 (15%)]\tClassification Loss: 1.4624\r\n",
      "Train Epoch: 4 [16800/110534 (15%)]\tClassification Loss: 1.7995\r\n",
      "Train Epoch: 4 [16960/110534 (15%)]\tClassification Loss: 1.7395\r\n",
      "Train Epoch: 4 [17120/110534 (15%)]\tClassification Loss: 1.9143\r\n",
      "Train Epoch: 4 [17280/110534 (16%)]\tClassification Loss: 1.1851\r\n",
      "Train Epoch: 4 [17440/110534 (16%)]\tClassification Loss: 1.3298\r\n",
      "Test() called at batch_idx: 1100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4643, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 4 [17600/110534 (16%)]\tClassification Loss: 1.0835\r\n",
      "Train Epoch: 4 [17760/110534 (16%)]\tClassification Loss: 0.9452\r\n",
      "Train Epoch: 4 [17920/110534 (16%)]\tClassification Loss: 1.4708\r\n",
      "Train Epoch: 4 [18080/110534 (16%)]\tClassification Loss: 1.7058\r\n",
      "Train Epoch: 4 [18240/110534 (17%)]\tClassification Loss: 2.0190\r\n",
      "Train Epoch: 4 [18400/110534 (17%)]\tClassification Loss: 1.6355\r\n",
      "Train Epoch: 4 [18560/110534 (17%)]\tClassification Loss: 1.3038\r\n",
      "Train Epoch: 4 [18720/110534 (17%)]\tClassification Loss: 2.1157\r\n",
      "Train Epoch: 4 [18880/110534 (17%)]\tClassification Loss: 1.2474\r\n",
      "Train Epoch: 4 [19040/110534 (17%)]\tClassification Loss: 1.6651\r\n",
      "Test() called at batch_idx: 1200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4475, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [19200/110534 (17%)]\tClassification Loss: 1.3230\r\n",
      "Train Epoch: 4 [19360/110534 (18%)]\tClassification Loss: 1.4734\r\n",
      "Train Epoch: 4 [19520/110534 (18%)]\tClassification Loss: 1.4926\r\n",
      "Train Epoch: 4 [19680/110534 (18%)]\tClassification Loss: 1.7845\r\n",
      "Train Epoch: 4 [19840/110534 (18%)]\tClassification Loss: 1.3240\r\n",
      "Train Epoch: 4 [20000/110534 (18%)]\tClassification Loss: 1.7659\r\n",
      "Train Epoch: 4 [20160/110534 (18%)]\tClassification Loss: 2.1745\r\n",
      "Train Epoch: 4 [20320/110534 (18%)]\tClassification Loss: 1.1106\r\n",
      "Train Epoch: 4 [20480/110534 (19%)]\tClassification Loss: 1.5961\r\n",
      "Train Epoch: 4 [20640/110534 (19%)]\tClassification Loss: 1.8885\r\n",
      "Test() called at batch_idx: 1300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4665, Accuracy: 303/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [20800/110534 (19%)]\tClassification Loss: 2.0668\r\n",
      "Train Epoch: 4 [20960/110534 (19%)]\tClassification Loss: 1.4789\r\n",
      "Train Epoch: 4 [21120/110534 (19%)]\tClassification Loss: 1.8350\r\n",
      "Train Epoch: 4 [21280/110534 (19%)]\tClassification Loss: 1.5931\r\n",
      "Train Epoch: 4 [21440/110534 (19%)]\tClassification Loss: 1.3367\r\n",
      "Train Epoch: 4 [21600/110534 (20%)]\tClassification Loss: 1.3391\r\n",
      "Train Epoch: 4 [21760/110534 (20%)]\tClassification Loss: 1.2000\r\n",
      "Train Epoch: 4 [21920/110534 (20%)]\tClassification Loss: 1.2815\r\n",
      "Train Epoch: 4 [22080/110534 (20%)]\tClassification Loss: 1.9459\r\n",
      "Train Epoch: 4 [22240/110534 (20%)]\tClassification Loss: 1.4065\r\n",
      "Test() called at batch_idx: 1400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4457, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [22400/110534 (20%)]\tClassification Loss: 1.8393\r\n",
      "Train Epoch: 4 [22560/110534 (20%)]\tClassification Loss: 1.4788\r\n",
      "Train Epoch: 4 [22720/110534 (21%)]\tClassification Loss: 1.1024\r\n",
      "Train Epoch: 4 [22880/110534 (21%)]\tClassification Loss: 1.3989\r\n",
      "Train Epoch: 4 [23040/110534 (21%)]\tClassification Loss: 1.3857\r\n",
      "Train Epoch: 4 [23200/110534 (21%)]\tClassification Loss: 1.6162\r\n",
      "Train Epoch: 4 [23360/110534 (21%)]\tClassification Loss: 1.5728\r\n",
      "Train Epoch: 4 [23520/110534 (21%)]\tClassification Loss: 1.7132\r\n",
      "Train Epoch: 4 [23680/110534 (21%)]\tClassification Loss: 1.2056\r\n",
      "Train Epoch: 4 [23840/110534 (22%)]\tClassification Loss: 2.0353\r\n",
      "Test() called at batch_idx: 1500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4609, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [24000/110534 (22%)]\tClassification Loss: 1.1736\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1500.pth.tar\r\n",
      "Train Epoch: 4 [24160/110534 (22%)]\tClassification Loss: 1.7129\r\n",
      "Train Epoch: 4 [24320/110534 (22%)]\tClassification Loss: 1.6993\r\n",
      "Train Epoch: 4 [24480/110534 (22%)]\tClassification Loss: 1.4355\r\n",
      "Train Epoch: 4 [24640/110534 (22%)]\tClassification Loss: 1.4697\r\n",
      "Train Epoch: 4 [24800/110534 (22%)]\tClassification Loss: 1.3707\r\n",
      "Train Epoch: 4 [24960/110534 (23%)]\tClassification Loss: 1.6747\r\n",
      "Train Epoch: 4 [25120/110534 (23%)]\tClassification Loss: 0.9168\r\n",
      "Train Epoch: 4 [25280/110534 (23%)]\tClassification Loss: 1.4981\r\n",
      "Train Epoch: 4 [25440/110534 (23%)]\tClassification Loss: 1.6246\r\n",
      "Test() called at batch_idx: 1600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4800, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 4 [25600/110534 (23%)]\tClassification Loss: 1.2163\r\n",
      "Train Epoch: 4 [25760/110534 (23%)]\tClassification Loss: 1.7763\r\n",
      "Train Epoch: 4 [25920/110534 (23%)]\tClassification Loss: 1.2035\r\n",
      "Train Epoch: 4 [26080/110534 (24%)]\tClassification Loss: 1.3419\r\n",
      "Train Epoch: 4 [26240/110534 (24%)]\tClassification Loss: 1.9260\r\n",
      "Train Epoch: 4 [26400/110534 (24%)]\tClassification Loss: 2.3063\r\n",
      "Train Epoch: 4 [26560/110534 (24%)]\tClassification Loss: 1.7758\r\n",
      "Train Epoch: 4 [26720/110534 (24%)]\tClassification Loss: 1.8117\r\n",
      "Train Epoch: 4 [26880/110534 (24%)]\tClassification Loss: 1.8967\r\n",
      "Train Epoch: 4 [27040/110534 (24%)]\tClassification Loss: 1.7361\r\n",
      "Test() called at batch_idx: 1700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4514, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [27200/110534 (25%)]\tClassification Loss: 1.1060\r\n",
      "Train Epoch: 4 [27360/110534 (25%)]\tClassification Loss: 1.1852\r\n",
      "Train Epoch: 4 [27520/110534 (25%)]\tClassification Loss: 1.2380\r\n",
      "Train Epoch: 4 [27680/110534 (25%)]\tClassification Loss: 2.0472\r\n",
      "Train Epoch: 4 [27840/110534 (25%)]\tClassification Loss: 2.0658\r\n",
      "Train Epoch: 4 [28000/110534 (25%)]\tClassification Loss: 1.3124\r\n",
      "Train Epoch: 4 [28160/110534 (25%)]\tClassification Loss: 1.2937\r\n",
      "Train Epoch: 4 [28320/110534 (26%)]\tClassification Loss: 2.2549\r\n",
      "Train Epoch: 4 [28480/110534 (26%)]\tClassification Loss: 1.2736\r\n",
      "Train Epoch: 4 [28640/110534 (26%)]\tClassification Loss: 1.7630\r\n",
      "Test() called at batch_idx: 1800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4574, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [28800/110534 (26%)]\tClassification Loss: 1.4298\r\n",
      "Train Epoch: 4 [28960/110534 (26%)]\tClassification Loss: 2.0074\r\n",
      "Train Epoch: 4 [29120/110534 (26%)]\tClassification Loss: 1.5872\r\n",
      "Train Epoch: 4 [29280/110534 (26%)]\tClassification Loss: 1.1213\r\n",
      "Train Epoch: 4 [29440/110534 (27%)]\tClassification Loss: 1.5365\r\n",
      "Train Epoch: 4 [29600/110534 (27%)]\tClassification Loss: 1.4004\r\n",
      "Train Epoch: 4 [29760/110534 (27%)]\tClassification Loss: 1.4349\r\n",
      "Train Epoch: 4 [29920/110534 (27%)]\tClassification Loss: 1.2756\r\n",
      "Train Epoch: 4 [30080/110534 (27%)]\tClassification Loss: 1.3914\r\n",
      "Train Epoch: 4 [30240/110534 (27%)]\tClassification Loss: 1.2607\r\n",
      "Test() called at batch_idx: 1900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4701, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 4 [30400/110534 (28%)]\tClassification Loss: 2.1999\r\n",
      "Train Epoch: 4 [30560/110534 (28%)]\tClassification Loss: 1.7203\r\n",
      "Train Epoch: 4 [30720/110534 (28%)]\tClassification Loss: 1.6701\r\n",
      "Train Epoch: 4 [30880/110534 (28%)]\tClassification Loss: 2.4544\r\n",
      "Train Epoch: 4 [31040/110534 (28%)]\tClassification Loss: 1.5083\r\n",
      "Train Epoch: 4 [31200/110534 (28%)]\tClassification Loss: 1.1374\r\n",
      "Train Epoch: 4 [31360/110534 (28%)]\tClassification Loss: 1.7265\r\n",
      "Train Epoch: 4 [31520/110534 (29%)]\tClassification Loss: 1.3711\r\n",
      "Train Epoch: 4 [31680/110534 (29%)]\tClassification Loss: 1.5106\r\n",
      "Train Epoch: 4 [31840/110534 (29%)]\tClassification Loss: 0.9036\r\n",
      "Test() called at batch_idx: 2000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4509, Accuracy: 306/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [32000/110534 (29%)]\tClassification Loss: 0.9842\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_2000.pth.tar\r\n",
      "Train Epoch: 4 [32160/110534 (29%)]\tClassification Loss: 1.5102\r\n",
      "Train Epoch: 4 [32320/110534 (29%)]\tClassification Loss: 1.3037\r\n",
      "Train Epoch: 4 [32480/110534 (29%)]\tClassification Loss: 1.7548\r\n",
      "Train Epoch: 4 [32640/110534 (30%)]\tClassification Loss: 1.7341\r\n",
      "Train Epoch: 4 [32800/110534 (30%)]\tClassification Loss: 1.7098\r\n",
      "Train Epoch: 4 [32960/110534 (30%)]\tClassification Loss: 1.4254\r\n",
      "Train Epoch: 4 [33120/110534 (30%)]\tClassification Loss: 0.9555\r\n",
      "Train Epoch: 4 [33280/110534 (30%)]\tClassification Loss: 1.6926\r\n",
      "Train Epoch: 4 [33440/110534 (30%)]\tClassification Loss: 1.3492\r\n",
      "Test() called at batch_idx: 2100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4734, Accuracy: 289/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 4 [33600/110534 (30%)]\tClassification Loss: 1.2258\r\n",
      "Train Epoch: 4 [33760/110534 (31%)]\tClassification Loss: 1.3062\r\n",
      "Train Epoch: 4 [33920/110534 (31%)]\tClassification Loss: 1.8540\r\n",
      "Train Epoch: 4 [34080/110534 (31%)]\tClassification Loss: 1.5645\r\n",
      "Train Epoch: 4 [34240/110534 (31%)]\tClassification Loss: 1.6341\r\n",
      "Train Epoch: 4 [34400/110534 (31%)]\tClassification Loss: 1.7617\r\n",
      "Train Epoch: 4 [34560/110534 (31%)]\tClassification Loss: 1.9410\r\n",
      "Train Epoch: 4 [34720/110534 (31%)]\tClassification Loss: 1.9617\r\n",
      "Train Epoch: 4 [34880/110534 (32%)]\tClassification Loss: 2.3413\r\n",
      "Train Epoch: 4 [35040/110534 (32%)]\tClassification Loss: 1.5418\r\n",
      "Test() called at batch_idx: 2200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4516, Accuracy: 291/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [35200/110534 (32%)]\tClassification Loss: 2.4079\r\n",
      "Train Epoch: 4 [35360/110534 (32%)]\tClassification Loss: 1.7227\r\n",
      "Train Epoch: 4 [35520/110534 (32%)]\tClassification Loss: 0.9432\r\n",
      "Train Epoch: 4 [35680/110534 (32%)]\tClassification Loss: 1.7153\r\n",
      "Train Epoch: 4 [35840/110534 (32%)]\tClassification Loss: 1.3825\r\n",
      "Train Epoch: 4 [36000/110534 (33%)]\tClassification Loss: 1.5076\r\n",
      "Train Epoch: 4 [36160/110534 (33%)]\tClassification Loss: 1.2213\r\n",
      "Train Epoch: 4 [36320/110534 (33%)]\tClassification Loss: 1.9981\r\n",
      "Train Epoch: 4 [36480/110534 (33%)]\tClassification Loss: 1.3529\r\n",
      "Train Epoch: 4 [36640/110534 (33%)]\tClassification Loss: 1.5636\r\n",
      "Test() called at batch_idx: 2300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4650, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [36800/110534 (33%)]\tClassification Loss: 1.8040\r\n",
      "Train Epoch: 4 [36960/110534 (33%)]\tClassification Loss: 1.1926\r\n",
      "Train Epoch: 4 [37120/110534 (34%)]\tClassification Loss: 1.3977\r\n",
      "Train Epoch: 4 [37280/110534 (34%)]\tClassification Loss: 1.1323\r\n",
      "Train Epoch: 4 [37440/110534 (34%)]\tClassification Loss: 1.4112\r\n",
      "Train Epoch: 4 [37600/110534 (34%)]\tClassification Loss: 1.7629\r\n",
      "Train Epoch: 4 [37760/110534 (34%)]\tClassification Loss: 1.9972\r\n",
      "Train Epoch: 4 [37920/110534 (34%)]\tClassification Loss: 1.5718\r\n",
      "Train Epoch: 4 [38080/110534 (34%)]\tClassification Loss: 1.8350\r\n",
      "Train Epoch: 4 [38240/110534 (35%)]\tClassification Loss: 1.7156\r\n",
      "Test() called at batch_idx: 2400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4437, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [38400/110534 (35%)]\tClassification Loss: 1.1409\r\n",
      "Train Epoch: 4 [38560/110534 (35%)]\tClassification Loss: 1.7424\r\n",
      "Train Epoch: 4 [38720/110534 (35%)]\tClassification Loss: 1.7072\r\n",
      "Train Epoch: 4 [38880/110534 (35%)]\tClassification Loss: 1.5341\r\n",
      "Train Epoch: 4 [39040/110534 (35%)]\tClassification Loss: 1.9047\r\n",
      "Train Epoch: 4 [39200/110534 (35%)]\tClassification Loss: 0.7266\r\n",
      "Train Epoch: 4 [39360/110534 (36%)]\tClassification Loss: 1.0267\r\n",
      "Train Epoch: 4 [39520/110534 (36%)]\tClassification Loss: 1.3507\r\n",
      "Train Epoch: 4 [39680/110534 (36%)]\tClassification Loss: 1.3091\r\n",
      "Train Epoch: 4 [39840/110534 (36%)]\tClassification Loss: 1.7981\r\n",
      "Test() called at batch_idx: 2500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4520, Accuracy: 291/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [40000/110534 (36%)]\tClassification Loss: 1.6181\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_2500.pth.tar\r\n",
      "Train Epoch: 4 [40160/110534 (36%)]\tClassification Loss: 1.2404\r\n",
      "Train Epoch: 4 [40320/110534 (36%)]\tClassification Loss: 1.4834\r\n",
      "Train Epoch: 4 [40480/110534 (37%)]\tClassification Loss: 1.4094\r\n",
      "Train Epoch: 4 [40640/110534 (37%)]\tClassification Loss: 1.8580\r\n",
      "Train Epoch: 4 [40800/110534 (37%)]\tClassification Loss: 1.7782\r\n",
      "Train Epoch: 4 [40960/110534 (37%)]\tClassification Loss: 1.8958\r\n",
      "Train Epoch: 4 [41120/110534 (37%)]\tClassification Loss: 1.6953\r\n",
      "Train Epoch: 4 [41280/110534 (37%)]\tClassification Loss: 1.6306\r\n",
      "Train Epoch: 4 [41440/110534 (37%)]\tClassification Loss: 1.0796\r\n",
      "Test() called at batch_idx: 2600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4520, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [41600/110534 (38%)]\tClassification Loss: 1.8937\r\n",
      "Train Epoch: 4 [41760/110534 (38%)]\tClassification Loss: 1.6581\r\n",
      "Train Epoch: 4 [41920/110534 (38%)]\tClassification Loss: 1.4773\r\n",
      "Train Epoch: 4 [42080/110534 (38%)]\tClassification Loss: 1.3777\r\n",
      "Train Epoch: 4 [42240/110534 (38%)]\tClassification Loss: 1.4472\r\n",
      "Train Epoch: 4 [42400/110534 (38%)]\tClassification Loss: 1.4209\r\n",
      "Train Epoch: 4 [42560/110534 (39%)]\tClassification Loss: 1.7813\r\n",
      "Train Epoch: 4 [42720/110534 (39%)]\tClassification Loss: 1.7389\r\n",
      "Train Epoch: 4 [42880/110534 (39%)]\tClassification Loss: 1.4190\r\n",
      "Train Epoch: 4 [43040/110534 (39%)]\tClassification Loss: 1.7318\r\n",
      "Test() called at batch_idx: 2700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4474, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [43200/110534 (39%)]\tClassification Loss: 1.0100\r\n",
      "Train Epoch: 4 [43360/110534 (39%)]\tClassification Loss: 0.9711\r\n",
      "Train Epoch: 4 [43520/110534 (39%)]\tClassification Loss: 1.1518\r\n",
      "Train Epoch: 4 [43680/110534 (40%)]\tClassification Loss: 1.5064\r\n",
      "Train Epoch: 4 [43840/110534 (40%)]\tClassification Loss: 1.4482\r\n",
      "Train Epoch: 4 [44000/110534 (40%)]\tClassification Loss: 1.3223\r\n",
      "Train Epoch: 4 [44160/110534 (40%)]\tClassification Loss: 1.7126\r\n",
      "Train Epoch: 4 [44320/110534 (40%)]\tClassification Loss: 1.4005\r\n",
      "Train Epoch: 4 [44480/110534 (40%)]\tClassification Loss: 1.7890\r\n",
      "Train Epoch: 4 [44640/110534 (40%)]\tClassification Loss: 1.7114\r\n",
      "Test() called at batch_idx: 2800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4561, Accuracy: 292/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [44800/110534 (41%)]\tClassification Loss: 2.4728\r\n",
      "Train Epoch: 4 [44960/110534 (41%)]\tClassification Loss: 1.1660\r\n",
      "Train Epoch: 4 [45120/110534 (41%)]\tClassification Loss: 1.5198\r\n",
      "Train Epoch: 4 [45280/110534 (41%)]\tClassification Loss: 1.6746\r\n",
      "Train Epoch: 4 [45440/110534 (41%)]\tClassification Loss: 1.6998\r\n",
      "Train Epoch: 4 [45600/110534 (41%)]\tClassification Loss: 1.4367\r\n",
      "Train Epoch: 4 [45760/110534 (41%)]\tClassification Loss: 1.3506\r\n",
      "Train Epoch: 4 [45920/110534 (42%)]\tClassification Loss: 1.2733\r\n",
      "Train Epoch: 4 [46080/110534 (42%)]\tClassification Loss: 1.1183\r\n",
      "Train Epoch: 4 [46240/110534 (42%)]\tClassification Loss: 1.3528\r\n",
      "Test() called at batch_idx: 2900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4438, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [46400/110534 (42%)]\tClassification Loss: 1.3227\r\n",
      "Train Epoch: 4 [46560/110534 (42%)]\tClassification Loss: 1.5206\r\n",
      "Train Epoch: 4 [46720/110534 (42%)]\tClassification Loss: 2.5253\r\n",
      "Train Epoch: 4 [46880/110534 (42%)]\tClassification Loss: 1.3888\r\n",
      "Train Epoch: 4 [47040/110534 (43%)]\tClassification Loss: 1.7900\r\n",
      "Train Epoch: 4 [47200/110534 (43%)]\tClassification Loss: 1.4394\r\n",
      "Train Epoch: 4 [47360/110534 (43%)]\tClassification Loss: 1.6737\r\n",
      "Train Epoch: 4 [47520/110534 (43%)]\tClassification Loss: 1.7770\r\n",
      "Train Epoch: 4 [47680/110534 (43%)]\tClassification Loss: 1.3933\r\n",
      "Train Epoch: 4 [47840/110534 (43%)]\tClassification Loss: 1.5281\r\n",
      "Test() called at batch_idx: 3000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4452, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [48000/110534 (43%)]\tClassification Loss: 1.5793\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_3000.pth.tar\r\n",
      "Train Epoch: 4 [48160/110534 (44%)]\tClassification Loss: 1.4061\r\n",
      "Train Epoch: 4 [48320/110534 (44%)]\tClassification Loss: 1.4668\r\n",
      "Train Epoch: 4 [48480/110534 (44%)]\tClassification Loss: 1.4900\r\n",
      "Train Epoch: 4 [48640/110534 (44%)]\tClassification Loss: 1.7239\r\n",
      "Train Epoch: 4 [48800/110534 (44%)]\tClassification Loss: 1.2043\r\n",
      "Train Epoch: 4 [48960/110534 (44%)]\tClassification Loss: 1.3818\r\n",
      "Train Epoch: 4 [49120/110534 (44%)]\tClassification Loss: 1.6382\r\n",
      "Train Epoch: 4 [49280/110534 (45%)]\tClassification Loss: 0.9593\r\n",
      "Train Epoch: 4 [49440/110534 (45%)]\tClassification Loss: 1.7821\r\n",
      "Test() called at batch_idx: 3100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4593, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [49600/110534 (45%)]\tClassification Loss: 1.3943\r\n",
      "Train Epoch: 4 [49760/110534 (45%)]\tClassification Loss: 1.5587\r\n",
      "Train Epoch: 4 [49920/110534 (45%)]\tClassification Loss: 2.0373\r\n",
      "Train Epoch: 4 [50080/110534 (45%)]\tClassification Loss: 1.3192\r\n",
      "Train Epoch: 4 [50240/110534 (45%)]\tClassification Loss: 1.6851\r\n",
      "Train Epoch: 4 [50400/110534 (46%)]\tClassification Loss: 1.2869\r\n",
      "Train Epoch: 4 [50560/110534 (46%)]\tClassification Loss: 1.2112\r\n",
      "Train Epoch: 4 [50720/110534 (46%)]\tClassification Loss: 1.6550\r\n",
      "Train Epoch: 4 [50880/110534 (46%)]\tClassification Loss: 1.7547\r\n",
      "Train Epoch: 4 [51040/110534 (46%)]\tClassification Loss: 1.7726\r\n",
      "Test() called at batch_idx: 3200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4412, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [51200/110534 (46%)]\tClassification Loss: 1.6613\r\n",
      "Train Epoch: 4 [51360/110534 (46%)]\tClassification Loss: 1.6041\r\n",
      "Train Epoch: 4 [51520/110534 (47%)]\tClassification Loss: 0.8457\r\n",
      "Train Epoch: 4 [51680/110534 (47%)]\tClassification Loss: 1.6013\r\n",
      "Train Epoch: 4 [51840/110534 (47%)]\tClassification Loss: 1.7284\r\n",
      "Train Epoch: 4 [52000/110534 (47%)]\tClassification Loss: 1.1386\r\n",
      "Train Epoch: 4 [52160/110534 (47%)]\tClassification Loss: 1.9594\r\n",
      "Train Epoch: 4 [52320/110534 (47%)]\tClassification Loss: 1.5736\r\n",
      "Train Epoch: 4 [52480/110534 (47%)]\tClassification Loss: 1.7480\r\n",
      "Train Epoch: 4 [52640/110534 (48%)]\tClassification Loss: 1.3793\r\n",
      "Test() called at batch_idx: 3300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4573, Accuracy: 291/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [52800/110534 (48%)]\tClassification Loss: 1.2351\r\n",
      "Train Epoch: 4 [52960/110534 (48%)]\tClassification Loss: 1.6473\r\n",
      "Train Epoch: 4 [53120/110534 (48%)]\tClassification Loss: 1.7926\r\n",
      "Train Epoch: 4 [53280/110534 (48%)]\tClassification Loss: 1.4332\r\n",
      "Train Epoch: 4 [53440/110534 (48%)]\tClassification Loss: 1.6858\r\n",
      "Train Epoch: 4 [53600/110534 (48%)]\tClassification Loss: 1.2863\r\n",
      "Train Epoch: 4 [53760/110534 (49%)]\tClassification Loss: 1.3785\r\n",
      "Train Epoch: 4 [53920/110534 (49%)]\tClassification Loss: 1.5842\r\n",
      "Train Epoch: 4 [54080/110534 (49%)]\tClassification Loss: 1.0678\r\n",
      "Train Epoch: 4 [54240/110534 (49%)]\tClassification Loss: 2.1569\r\n",
      "Test() called at batch_idx: 3400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4664, Accuracy: 285/480 (59%)\r\n",
      "\r\n",
      "Train Epoch: 4 [54400/110534 (49%)]\tClassification Loss: 1.6462\r\n",
      "Train Epoch: 4 [54560/110534 (49%)]\tClassification Loss: 1.1854\r\n",
      "Train Epoch: 4 [54720/110534 (50%)]\tClassification Loss: 1.8990\r\n",
      "Train Epoch: 4 [54880/110534 (50%)]\tClassification Loss: 1.3106\r\n",
      "Train Epoch: 4 [55040/110534 (50%)]\tClassification Loss: 1.5966\r\n",
      "Train Epoch: 4 [55200/110534 (50%)]\tClassification Loss: 1.3868\r\n",
      "Train Epoch: 4 [55360/110534 (50%)]\tClassification Loss: 1.6960\r\n",
      "Train Epoch: 4 [55520/110534 (50%)]\tClassification Loss: 1.4482\r\n",
      "Train Epoch: 4 [55680/110534 (50%)]\tClassification Loss: 1.2627\r\n",
      "Train Epoch: 4 [55840/110534 (51%)]\tClassification Loss: 1.7259\r\n",
      "Test() called at batch_idx: 3500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4396, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [56000/110534 (51%)]\tClassification Loss: 1.8998\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_3500.pth.tar\r\n",
      "Train Epoch: 4 [56160/110534 (51%)]\tClassification Loss: 1.5418\r\n",
      "Train Epoch: 4 [56320/110534 (51%)]\tClassification Loss: 1.2313\r\n",
      "Train Epoch: 4 [56480/110534 (51%)]\tClassification Loss: 1.9572\r\n",
      "Train Epoch: 4 [56640/110534 (51%)]\tClassification Loss: 2.2597\r\n",
      "Train Epoch: 4 [56800/110534 (51%)]\tClassification Loss: 1.0837\r\n",
      "Train Epoch: 4 [56960/110534 (52%)]\tClassification Loss: 1.6761\r\n",
      "Train Epoch: 4 [57120/110534 (52%)]\tClassification Loss: 1.6708\r\n",
      "Train Epoch: 4 [57280/110534 (52%)]\tClassification Loss: 2.0546\r\n",
      "Train Epoch: 4 [57440/110534 (52%)]\tClassification Loss: 1.7494\r\n",
      "Test() called at batch_idx: 3600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4515, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [57600/110534 (52%)]\tClassification Loss: 1.2981\r\n",
      "Train Epoch: 4 [57760/110534 (52%)]\tClassification Loss: 1.4794\r\n",
      "Train Epoch: 4 [57920/110534 (52%)]\tClassification Loss: 1.5885\r\n",
      "Train Epoch: 4 [58080/110534 (53%)]\tClassification Loss: 1.0575\r\n",
      "Train Epoch: 4 [58240/110534 (53%)]\tClassification Loss: 1.2172\r\n",
      "Train Epoch: 4 [58400/110534 (53%)]\tClassification Loss: 1.5246\r\n",
      "Train Epoch: 4 [58560/110534 (53%)]\tClassification Loss: 1.4714\r\n",
      "Train Epoch: 4 [58720/110534 (53%)]\tClassification Loss: 1.2259\r\n",
      "Train Epoch: 4 [58880/110534 (53%)]\tClassification Loss: 1.5611\r\n",
      "Train Epoch: 4 [59040/110534 (53%)]\tClassification Loss: 1.4108\r\n",
      "Test() called at batch_idx: 3700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4563, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [59200/110534 (54%)]\tClassification Loss: 1.6317\r\n",
      "Train Epoch: 4 [59360/110534 (54%)]\tClassification Loss: 1.7853\r\n",
      "Train Epoch: 4 [59520/110534 (54%)]\tClassification Loss: 1.5886\r\n",
      "Train Epoch: 4 [59680/110534 (54%)]\tClassification Loss: 1.8534\r\n",
      "Train Epoch: 4 [59840/110534 (54%)]\tClassification Loss: 1.8620\r\n",
      "Train Epoch: 4 [60000/110534 (54%)]\tClassification Loss: 1.4227\r\n",
      "Train Epoch: 4 [60160/110534 (54%)]\tClassification Loss: 1.2022\r\n",
      "Train Epoch: 4 [60320/110534 (55%)]\tClassification Loss: 2.0305\r\n",
      "Train Epoch: 4 [60480/110534 (55%)]\tClassification Loss: 1.3323\r\n",
      "Train Epoch: 4 [60640/110534 (55%)]\tClassification Loss: 1.3242\r\n",
      "Test() called at batch_idx: 3800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4351, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [60800/110534 (55%)]\tClassification Loss: 1.7034\r\n",
      "Train Epoch: 4 [60960/110534 (55%)]\tClassification Loss: 2.1845\r\n",
      "Train Epoch: 4 [61120/110534 (55%)]\tClassification Loss: 1.6539\r\n",
      "Train Epoch: 4 [61280/110534 (55%)]\tClassification Loss: 2.0257\r\n",
      "Train Epoch: 4 [61440/110534 (56%)]\tClassification Loss: 2.2546\r\n",
      "Train Epoch: 4 [61600/110534 (56%)]\tClassification Loss: 1.6536\r\n",
      "Train Epoch: 4 [61760/110534 (56%)]\tClassification Loss: 1.5200\r\n",
      "Train Epoch: 4 [61920/110534 (56%)]\tClassification Loss: 1.7866\r\n",
      "Train Epoch: 4 [62080/110534 (56%)]\tClassification Loss: 1.6314\r\n",
      "Train Epoch: 4 [62240/110534 (56%)]\tClassification Loss: 1.7654\r\n",
      "Test() called at batch_idx: 3900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4481, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [62400/110534 (56%)]\tClassification Loss: 1.6906\r\n",
      "Train Epoch: 4 [62560/110534 (57%)]\tClassification Loss: 1.4862\r\n",
      "Train Epoch: 4 [62720/110534 (57%)]\tClassification Loss: 0.8393\r\n",
      "Train Epoch: 4 [62880/110534 (57%)]\tClassification Loss: 1.6625\r\n",
      "Train Epoch: 4 [63040/110534 (57%)]\tClassification Loss: 1.0804\r\n",
      "Train Epoch: 4 [63200/110534 (57%)]\tClassification Loss: 1.5454\r\n",
      "Train Epoch: 4 [63360/110534 (57%)]\tClassification Loss: 1.3920\r\n",
      "Train Epoch: 4 [63520/110534 (57%)]\tClassification Loss: 1.4166\r\n",
      "Train Epoch: 4 [63680/110534 (58%)]\tClassification Loss: 1.5499\r\n",
      "Train Epoch: 4 [63840/110534 (58%)]\tClassification Loss: 1.5569\r\n",
      "Test() called at batch_idx: 4000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4419, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [64000/110534 (58%)]\tClassification Loss: 1.5000\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_4000.pth.tar\r\n",
      "Train Epoch: 4 [64160/110534 (58%)]\tClassification Loss: 1.7291\r\n",
      "Train Epoch: 4 [64320/110534 (58%)]\tClassification Loss: 1.1901\r\n",
      "Train Epoch: 4 [64480/110534 (58%)]\tClassification Loss: 1.6732\r\n",
      "Train Epoch: 4 [64640/110534 (58%)]\tClassification Loss: 1.9509\r\n",
      "Train Epoch: 4 [64800/110534 (59%)]\tClassification Loss: 1.5245\r\n",
      "Train Epoch: 4 [64960/110534 (59%)]\tClassification Loss: 1.4696\r\n",
      "Train Epoch: 4 [65120/110534 (59%)]\tClassification Loss: 1.3202\r\n",
      "Train Epoch: 4 [65280/110534 (59%)]\tClassification Loss: 1.8905\r\n",
      "Train Epoch: 4 [65440/110534 (59%)]\tClassification Loss: 1.3684\r\n",
      "Test() called at batch_idx: 4100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4448, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [65600/110534 (59%)]\tClassification Loss: 1.4336\r\n",
      "Train Epoch: 4 [65760/110534 (59%)]\tClassification Loss: 1.9018\r\n",
      "Train Epoch: 4 [65920/110534 (60%)]\tClassification Loss: 1.2777\r\n",
      "Train Epoch: 4 [66080/110534 (60%)]\tClassification Loss: 1.5638\r\n",
      "Train Epoch: 4 [66240/110534 (60%)]\tClassification Loss: 1.1741\r\n",
      "Train Epoch: 4 [66400/110534 (60%)]\tClassification Loss: 1.8273\r\n",
      "Train Epoch: 4 [66560/110534 (60%)]\tClassification Loss: 1.6681\r\n",
      "Train Epoch: 4 [66720/110534 (60%)]\tClassification Loss: 1.6266\r\n",
      "Train Epoch: 4 [66880/110534 (61%)]\tClassification Loss: 1.1420\r\n",
      "Train Epoch: 4 [67040/110534 (61%)]\tClassification Loss: 1.8403\r\n",
      "Test() called at batch_idx: 4200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4420, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [67200/110534 (61%)]\tClassification Loss: 1.9923\r\n",
      "Train Epoch: 4 [67360/110534 (61%)]\tClassification Loss: 1.6469\r\n",
      "Train Epoch: 4 [67520/110534 (61%)]\tClassification Loss: 1.5848\r\n",
      "Train Epoch: 4 [67680/110534 (61%)]\tClassification Loss: 1.1121\r\n",
      "Train Epoch: 4 [67840/110534 (61%)]\tClassification Loss: 1.8449\r\n",
      "Train Epoch: 4 [68000/110534 (62%)]\tClassification Loss: 1.2498\r\n",
      "Train Epoch: 4 [68160/110534 (62%)]\tClassification Loss: 1.5826\r\n",
      "Train Epoch: 4 [68320/110534 (62%)]\tClassification Loss: 1.6064\r\n",
      "Train Epoch: 4 [68480/110534 (62%)]\tClassification Loss: 1.9022\r\n",
      "Train Epoch: 4 [68640/110534 (62%)]\tClassification Loss: 1.2473\r\n",
      "Test() called at batch_idx: 4300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4459, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [68800/110534 (62%)]\tClassification Loss: 1.6959\r\n",
      "Train Epoch: 4 [68960/110534 (62%)]\tClassification Loss: 1.3876\r\n",
      "Train Epoch: 4 [69120/110534 (63%)]\tClassification Loss: 1.4544\r\n",
      "Train Epoch: 4 [69280/110534 (63%)]\tClassification Loss: 1.6624\r\n",
      "Train Epoch: 4 [69440/110534 (63%)]\tClassification Loss: 1.4802\r\n",
      "Train Epoch: 4 [69600/110534 (63%)]\tClassification Loss: 1.2529\r\n",
      "Train Epoch: 4 [69760/110534 (63%)]\tClassification Loss: 1.2595\r\n",
      "Train Epoch: 4 [69920/110534 (63%)]\tClassification Loss: 1.9342\r\n",
      "Train Epoch: 4 [70080/110534 (63%)]\tClassification Loss: 1.4067\r\n",
      "Train Epoch: 4 [70240/110534 (64%)]\tClassification Loss: 1.7184\r\n",
      "Test() called at batch_idx: 4400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4347, Accuracy: 307/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [70400/110534 (64%)]\tClassification Loss: 1.3366\r\n",
      "Train Epoch: 4 [70560/110534 (64%)]\tClassification Loss: 1.4580\r\n",
      "Train Epoch: 4 [70720/110534 (64%)]\tClassification Loss: 0.9219\r\n",
      "Train Epoch: 4 [70880/110534 (64%)]\tClassification Loss: 1.6823\r\n",
      "Train Epoch: 4 [71040/110534 (64%)]\tClassification Loss: 1.4004\r\n",
      "Train Epoch: 4 [71200/110534 (64%)]\tClassification Loss: 1.5350\r\n",
      "Train Epoch: 4 [71360/110534 (65%)]\tClassification Loss: 2.3887\r\n",
      "Train Epoch: 4 [71520/110534 (65%)]\tClassification Loss: 2.0322\r\n",
      "Train Epoch: 4 [71680/110534 (65%)]\tClassification Loss: 1.3626\r\n",
      "Train Epoch: 4 [71840/110534 (65%)]\tClassification Loss: 1.9049\r\n",
      "Test() called at batch_idx: 4500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4727, Accuracy: 287/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 4 [72000/110534 (65%)]\tClassification Loss: 1.4308\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_4500.pth.tar\r\n",
      "Train Epoch: 4 [72160/110534 (65%)]\tClassification Loss: 1.6276\r\n",
      "Train Epoch: 4 [72320/110534 (65%)]\tClassification Loss: 1.5927\r\n",
      "Train Epoch: 4 [72480/110534 (66%)]\tClassification Loss: 1.6930\r\n",
      "Train Epoch: 4 [72640/110534 (66%)]\tClassification Loss: 1.6700\r\n",
      "Train Epoch: 4 [72800/110534 (66%)]\tClassification Loss: 1.3202\r\n",
      "Train Epoch: 4 [72960/110534 (66%)]\tClassification Loss: 1.6961\r\n",
      "Train Epoch: 4 [73120/110534 (66%)]\tClassification Loss: 1.6937\r\n",
      "Train Epoch: 4 [73280/110534 (66%)]\tClassification Loss: 1.1507\r\n",
      "Train Epoch: 4 [73440/110534 (66%)]\tClassification Loss: 1.6975\r\n",
      "Test() called at batch_idx: 4600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4503, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [73600/110534 (67%)]\tClassification Loss: 1.6786\r\n",
      "Train Epoch: 4 [73760/110534 (67%)]\tClassification Loss: 1.2940\r\n",
      "Train Epoch: 4 [73920/110534 (67%)]\tClassification Loss: 2.0557\r\n",
      "Train Epoch: 4 [74080/110534 (67%)]\tClassification Loss: 1.9492\r\n",
      "Train Epoch: 4 [74240/110534 (67%)]\tClassification Loss: 1.4716\r\n",
      "Train Epoch: 4 [74400/110534 (67%)]\tClassification Loss: 1.3117\r\n",
      "Train Epoch: 4 [74560/110534 (67%)]\tClassification Loss: 1.3238\r\n",
      "Train Epoch: 4 [74720/110534 (68%)]\tClassification Loss: 1.1161\r\n",
      "Train Epoch: 4 [74880/110534 (68%)]\tClassification Loss: 1.5320\r\n",
      "Train Epoch: 4 [75040/110534 (68%)]\tClassification Loss: 1.7879\r\n",
      "Test() called at batch_idx: 4700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4460, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [75200/110534 (68%)]\tClassification Loss: 1.1736\r\n",
      "Train Epoch: 4 [75360/110534 (68%)]\tClassification Loss: 1.6518\r\n",
      "Train Epoch: 4 [75520/110534 (68%)]\tClassification Loss: 1.3765\r\n",
      "Train Epoch: 4 [75680/110534 (68%)]\tClassification Loss: 1.2092\r\n",
      "Train Epoch: 4 [75840/110534 (69%)]\tClassification Loss: 1.4151\r\n",
      "Train Epoch: 4 [76000/110534 (69%)]\tClassification Loss: 1.4435\r\n",
      "Train Epoch: 4 [76160/110534 (69%)]\tClassification Loss: 1.2056\r\n",
      "Train Epoch: 4 [76320/110534 (69%)]\tClassification Loss: 1.4696\r\n",
      "Train Epoch: 4 [76480/110534 (69%)]\tClassification Loss: 1.0229\r\n",
      "Train Epoch: 4 [76640/110534 (69%)]\tClassification Loss: 1.6763\r\n",
      "Test() called at batch_idx: 4800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4468, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [76800/110534 (69%)]\tClassification Loss: 2.1550\r\n",
      "Train Epoch: 4 [76960/110534 (70%)]\tClassification Loss: 1.2201\r\n",
      "Train Epoch: 4 [77120/110534 (70%)]\tClassification Loss: 1.1178\r\n",
      "Train Epoch: 4 [77280/110534 (70%)]\tClassification Loss: 1.5568\r\n",
      "Train Epoch: 4 [77440/110534 (70%)]\tClassification Loss: 1.1492\r\n",
      "Train Epoch: 4 [77600/110534 (70%)]\tClassification Loss: 1.5360\r\n",
      "Train Epoch: 4 [77760/110534 (70%)]\tClassification Loss: 1.3828\r\n",
      "Train Epoch: 4 [77920/110534 (70%)]\tClassification Loss: 1.4444\r\n",
      "Train Epoch: 4 [78080/110534 (71%)]\tClassification Loss: 1.6005\r\n",
      "Train Epoch: 4 [78240/110534 (71%)]\tClassification Loss: 1.6581\r\n",
      "Test() called at batch_idx: 4900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4377, Accuracy: 296/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [78400/110534 (71%)]\tClassification Loss: 1.4202\r\n",
      "Train Epoch: 4 [78560/110534 (71%)]\tClassification Loss: 1.4261\r\n",
      "Train Epoch: 4 [78720/110534 (71%)]\tClassification Loss: 1.4064\r\n",
      "Train Epoch: 4 [78880/110534 (71%)]\tClassification Loss: 2.3597\r\n",
      "Train Epoch: 4 [79040/110534 (72%)]\tClassification Loss: 1.4291\r\n",
      "Train Epoch: 4 [79200/110534 (72%)]\tClassification Loss: 1.1175\r\n",
      "Train Epoch: 4 [79360/110534 (72%)]\tClassification Loss: 1.1565\r\n",
      "Train Epoch: 4 [79520/110534 (72%)]\tClassification Loss: 0.9470\r\n",
      "Train Epoch: 4 [79680/110534 (72%)]\tClassification Loss: 0.9217\r\n",
      "Train Epoch: 4 [79840/110534 (72%)]\tClassification Loss: 1.6202\r\n",
      "Test() called at batch_idx: 5000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4374, Accuracy: 304/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [80000/110534 (72%)]\tClassification Loss: 1.6005\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_5000.pth.tar\r\n",
      "Train Epoch: 4 [80160/110534 (73%)]\tClassification Loss: 1.3593\r\n",
      "Train Epoch: 4 [80320/110534 (73%)]\tClassification Loss: 1.8952\r\n",
      "Train Epoch: 4 [80480/110534 (73%)]\tClassification Loss: 1.6792\r\n",
      "Train Epoch: 4 [80640/110534 (73%)]\tClassification Loss: 1.3937\r\n",
      "Train Epoch: 4 [80800/110534 (73%)]\tClassification Loss: 1.9885\r\n",
      "Train Epoch: 4 [80960/110534 (73%)]\tClassification Loss: 1.5390\r\n",
      "Train Epoch: 4 [81120/110534 (73%)]\tClassification Loss: 1.7436\r\n",
      "Train Epoch: 4 [81280/110534 (74%)]\tClassification Loss: 1.2787\r\n",
      "Train Epoch: 4 [81440/110534 (74%)]\tClassification Loss: 1.3299\r\n",
      "Test() called at batch_idx: 5100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4393, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [81600/110534 (74%)]\tClassification Loss: 1.8321\r\n",
      "Train Epoch: 4 [81760/110534 (74%)]\tClassification Loss: 1.3857\r\n",
      "Train Epoch: 4 [81920/110534 (74%)]\tClassification Loss: 1.3805\r\n",
      "Train Epoch: 4 [82080/110534 (74%)]\tClassification Loss: 1.8681\r\n",
      "Train Epoch: 4 [82240/110534 (74%)]\tClassification Loss: 1.1044\r\n",
      "Train Epoch: 4 [82400/110534 (75%)]\tClassification Loss: 2.3612\r\n",
      "Train Epoch: 4 [82560/110534 (75%)]\tClassification Loss: 0.9235\r\n",
      "Train Epoch: 4 [82720/110534 (75%)]\tClassification Loss: 1.9483\r\n",
      "Train Epoch: 4 [82880/110534 (75%)]\tClassification Loss: 1.5270\r\n",
      "Train Epoch: 4 [83040/110534 (75%)]\tClassification Loss: 1.3348\r\n",
      "Test() called at batch_idx: 5200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4744, Accuracy: 293/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [83200/110534 (75%)]\tClassification Loss: 1.5794\r\n",
      "Train Epoch: 4 [83360/110534 (75%)]\tClassification Loss: 1.1774\r\n",
      "Train Epoch: 4 [83520/110534 (76%)]\tClassification Loss: 1.9803\r\n",
      "Train Epoch: 4 [83680/110534 (76%)]\tClassification Loss: 1.7814\r\n",
      "Train Epoch: 4 [83840/110534 (76%)]\tClassification Loss: 1.8038\r\n",
      "Train Epoch: 4 [84000/110534 (76%)]\tClassification Loss: 1.7200\r\n",
      "Train Epoch: 4 [84160/110534 (76%)]\tClassification Loss: 1.1390\r\n",
      "Train Epoch: 4 [84320/110534 (76%)]\tClassification Loss: 1.7136\r\n",
      "Train Epoch: 4 [84480/110534 (76%)]\tClassification Loss: 1.5620\r\n",
      "Train Epoch: 4 [84640/110534 (77%)]\tClassification Loss: 1.1650\r\n",
      "Test() called at batch_idx: 5300\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\r\n",
      "    self._send(header + buf)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\r\n",
      "    n = write(self._handle, buf)\r\n",
      "BrokenPipeError: [Errno 32] Broken pipe\r\n",
      "\r\n",
      "Test set: Average loss: 1.4416, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [84800/110534 (77%)]\tClassification Loss: 1.5151\r\n",
      "Train Epoch: 4 [84960/110534 (77%)]\tClassification Loss: 1.5504\r\n",
      "Train Epoch: 4 [85120/110534 (77%)]\tClassification Loss: 1.2207\r\n",
      "Train Epoch: 4 [85280/110534 (77%)]\tClassification Loss: 1.9163\r\n",
      "Train Epoch: 4 [85440/110534 (77%)]\tClassification Loss: 1.6660\r\n",
      "Train Epoch: 4 [85600/110534 (77%)]\tClassification Loss: 1.6190\r\n",
      "Train Epoch: 4 [85760/110534 (78%)]\tClassification Loss: 1.8237\r\n",
      "Train Epoch: 4 [85920/110534 (78%)]\tClassification Loss: 1.6703\r\n",
      "Train Epoch: 4 [86080/110534 (78%)]\tClassification Loss: 1.6000\r\n",
      "Train Epoch: 4 [86240/110534 (78%)]\tClassification Loss: 1.5312\r\n",
      "Test() called at batch_idx: 5400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4393, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [86400/110534 (78%)]\tClassification Loss: 1.2677\r\n",
      "Train Epoch: 4 [86560/110534 (78%)]\tClassification Loss: 1.4685\r\n",
      "Train Epoch: 4 [86720/110534 (78%)]\tClassification Loss: 1.5566\r\n",
      "Train Epoch: 4 [86880/110534 (79%)]\tClassification Loss: 1.4385\r\n",
      "Train Epoch: 4 [87040/110534 (79%)]\tClassification Loss: 1.9246\r\n",
      "Train Epoch: 4 [87200/110534 (79%)]\tClassification Loss: 1.2250\r\n",
      "Train Epoch: 4 [87360/110534 (79%)]\tClassification Loss: 1.4902\r\n",
      "Train Epoch: 4 [87520/110534 (79%)]\tClassification Loss: 1.2055\r\n",
      "Train Epoch: 4 [87680/110534 (79%)]\tClassification Loss: 1.3536\r\n",
      "Train Epoch: 4 [87840/110534 (79%)]\tClassification Loss: 1.2418\r\n",
      "Test() called at batch_idx: 5500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4351, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [88000/110534 (80%)]\tClassification Loss: 1.3388\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_5500.pth.tar\r\n",
      "Train Epoch: 4 [88160/110534 (80%)]\tClassification Loss: 1.3192\r\n",
      "Train Epoch: 4 [88320/110534 (80%)]\tClassification Loss: 1.2343\r\n",
      "Train Epoch: 4 [88480/110534 (80%)]\tClassification Loss: 1.7042\r\n",
      "Train Epoch: 4 [88640/110534 (80%)]\tClassification Loss: 2.2356\r\n",
      "Train Epoch: 4 [88800/110534 (80%)]\tClassification Loss: 2.2225\r\n",
      "Train Epoch: 4 [88960/110534 (80%)]\tClassification Loss: 1.8221\r\n",
      "Train Epoch: 4 [89120/110534 (81%)]\tClassification Loss: 1.4595\r\n",
      "Train Epoch: 4 [89280/110534 (81%)]\tClassification Loss: 1.3980\r\n",
      "Train Epoch: 4 [89440/110534 (81%)]\tClassification Loss: 1.2426\r\n",
      "Test() called at batch_idx: 5600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4791, Accuracy: 290/480 (60%)\r\n",
      "\r\n",
      "Train Epoch: 4 [89600/110534 (81%)]\tClassification Loss: 1.4308\r\n",
      "Train Epoch: 4 [89760/110534 (81%)]\tClassification Loss: 1.3032\r\n",
      "Train Epoch: 4 [89920/110534 (81%)]\tClassification Loss: 1.8094\r\n",
      "Train Epoch: 4 [90080/110534 (81%)]\tClassification Loss: 1.1487\r\n",
      "Train Epoch: 4 [90240/110534 (82%)]\tClassification Loss: 1.5760\r\n",
      "Train Epoch: 4 [90400/110534 (82%)]\tClassification Loss: 1.7694\r\n",
      "Train Epoch: 4 [90560/110534 (82%)]\tClassification Loss: 1.3366\r\n",
      "Train Epoch: 4 [90720/110534 (82%)]\tClassification Loss: 1.4474\r\n",
      "Train Epoch: 4 [90880/110534 (82%)]\tClassification Loss: 1.4773\r\n",
      "Train Epoch: 4 [91040/110534 (82%)]\tClassification Loss: 1.7718\r\n",
      "Test() called at batch_idx: 5700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4364, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [91200/110534 (83%)]\tClassification Loss: 1.9294\r\n",
      "Train Epoch: 4 [91360/110534 (83%)]\tClassification Loss: 1.3508\r\n",
      "Train Epoch: 4 [91520/110534 (83%)]\tClassification Loss: 1.6271\r\n",
      "Train Epoch: 4 [91680/110534 (83%)]\tClassification Loss: 1.8328\r\n",
      "Train Epoch: 4 [91840/110534 (83%)]\tClassification Loss: 1.6018\r\n",
      "Train Epoch: 4 [92000/110534 (83%)]\tClassification Loss: 1.0258\r\n",
      "Train Epoch: 4 [92160/110534 (83%)]\tClassification Loss: 1.2711\r\n",
      "Train Epoch: 4 [92320/110534 (84%)]\tClassification Loss: 2.0493\r\n",
      "Train Epoch: 4 [92480/110534 (84%)]\tClassification Loss: 1.0186\r\n",
      "Train Epoch: 4 [92640/110534 (84%)]\tClassification Loss: 1.8043\r\n",
      "Test() called at batch_idx: 5800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4527, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [92800/110534 (84%)]\tClassification Loss: 1.8362\r\n",
      "Train Epoch: 4 [92960/110534 (84%)]\tClassification Loss: 1.8180\r\n",
      "Train Epoch: 4 [93120/110534 (84%)]\tClassification Loss: 1.8379\r\n",
      "Train Epoch: 4 [93280/110534 (84%)]\tClassification Loss: 0.8854\r\n",
      "Train Epoch: 4 [93440/110534 (85%)]\tClassification Loss: 1.6960\r\n",
      "Train Epoch: 4 [93600/110534 (85%)]\tClassification Loss: 1.4442\r\n",
      "Train Epoch: 4 [93760/110534 (85%)]\tClassification Loss: 0.9156\r\n",
      "Train Epoch: 4 [93920/110534 (85%)]\tClassification Loss: 1.6489\r\n",
      "Train Epoch: 4 [94080/110534 (85%)]\tClassification Loss: 1.7958\r\n",
      "Train Epoch: 4 [94240/110534 (85%)]\tClassification Loss: 0.9982\r\n",
      "Test() called at batch_idx: 5900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4473, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [94400/110534 (85%)]\tClassification Loss: 1.7538\r\n",
      "Train Epoch: 4 [94560/110534 (86%)]\tClassification Loss: 1.9305\r\n",
      "Train Epoch: 4 [94720/110534 (86%)]\tClassification Loss: 0.8776\r\n",
      "Train Epoch: 4 [94880/110534 (86%)]\tClassification Loss: 1.5485\r\n",
      "Train Epoch: 4 [95040/110534 (86%)]\tClassification Loss: 1.7412\r\n",
      "Train Epoch: 4 [95200/110534 (86%)]\tClassification Loss: 1.4917\r\n",
      "Train Epoch: 4 [95360/110534 (86%)]\tClassification Loss: 1.4255\r\n",
      "Train Epoch: 4 [95520/110534 (86%)]\tClassification Loss: 1.7202\r\n",
      "Train Epoch: 4 [95680/110534 (87%)]\tClassification Loss: 1.3468\r\n",
      "Train Epoch: 4 [95840/110534 (87%)]\tClassification Loss: 1.6740\r\n",
      "Test() called at batch_idx: 6000\r\n",
      "\r\n",
      "Test set: Average loss: 1.4535, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [96000/110534 (87%)]\tClassification Loss: 1.2929\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_6000.pth.tar\r\n",
      "Train Epoch: 4 [96160/110534 (87%)]\tClassification Loss: 1.6540\r\n",
      "Train Epoch: 4 [96320/110534 (87%)]\tClassification Loss: 1.2403\r\n",
      "Train Epoch: 4 [96480/110534 (87%)]\tClassification Loss: 1.5645\r\n",
      "Train Epoch: 4 [96640/110534 (87%)]\tClassification Loss: 1.4089\r\n",
      "Train Epoch: 4 [96800/110534 (88%)]\tClassification Loss: 1.0543\r\n",
      "Train Epoch: 4 [96960/110534 (88%)]\tClassification Loss: 1.5349\r\n",
      "Train Epoch: 4 [97120/110534 (88%)]\tClassification Loss: 2.0032\r\n",
      "Train Epoch: 4 [97280/110534 (88%)]\tClassification Loss: 1.3625\r\n",
      "Train Epoch: 4 [97440/110534 (88%)]\tClassification Loss: 1.4280\r\n",
      "Test() called at batch_idx: 6100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4299, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [97600/110534 (88%)]\tClassification Loss: 1.7407\r\n",
      "Train Epoch: 4 [97760/110534 (88%)]\tClassification Loss: 1.7917\r\n",
      "Train Epoch: 4 [97920/110534 (89%)]\tClassification Loss: 1.6521\r\n",
      "Train Epoch: 4 [98080/110534 (89%)]\tClassification Loss: 1.2687\r\n",
      "Train Epoch: 4 [98240/110534 (89%)]\tClassification Loss: 1.3868\r\n",
      "Train Epoch: 4 [98400/110534 (89%)]\tClassification Loss: 1.7079\r\n",
      "Train Epoch: 4 [98560/110534 (89%)]\tClassification Loss: 2.0615\r\n",
      "Train Epoch: 4 [98720/110534 (89%)]\tClassification Loss: 1.7124\r\n",
      "Train Epoch: 4 [98880/110534 (89%)]\tClassification Loss: 1.8509\r\n",
      "Train Epoch: 4 [99040/110534 (90%)]\tClassification Loss: 2.2486\r\n",
      "Test() called at batch_idx: 6200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4387, Accuracy: 301/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [99200/110534 (90%)]\tClassification Loss: 1.8712\r\n",
      "Train Epoch: 4 [99360/110534 (90%)]\tClassification Loss: 1.9533\r\n",
      "Train Epoch: 4 [99520/110534 (90%)]\tClassification Loss: 1.3030\r\n",
      "Train Epoch: 4 [99680/110534 (90%)]\tClassification Loss: 1.4632\r\n",
      "Train Epoch: 4 [99840/110534 (90%)]\tClassification Loss: 1.7284\r\n",
      "Train Epoch: 4 [100000/110534 (90%)]\tClassification Loss: 1.4282\r\n",
      "Train Epoch: 4 [100160/110534 (91%)]\tClassification Loss: 1.2366\r\n",
      "Train Epoch: 4 [100320/110534 (91%)]\tClassification Loss: 1.7877\r\n",
      "Train Epoch: 4 [100480/110534 (91%)]\tClassification Loss: 1.4863\r\n",
      "Train Epoch: 4 [100640/110534 (91%)]\tClassification Loss: 1.3718\r\n",
      "Test() called at batch_idx: 6300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4398, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [100800/110534 (91%)]\tClassification Loss: 1.9659\r\n",
      "Train Epoch: 4 [100960/110534 (91%)]\tClassification Loss: 1.3452\r\n",
      "Train Epoch: 4 [101120/110534 (91%)]\tClassification Loss: 1.5075\r\n",
      "Train Epoch: 4 [101280/110534 (92%)]\tClassification Loss: 1.7791\r\n",
      "Train Epoch: 4 [101440/110534 (92%)]\tClassification Loss: 1.7403\r\n",
      "Train Epoch: 4 [101600/110534 (92%)]\tClassification Loss: 1.7005\r\n",
      "Train Epoch: 4 [101760/110534 (92%)]\tClassification Loss: 1.0406\r\n",
      "Train Epoch: 4 [101920/110534 (92%)]\tClassification Loss: 1.5220\r\n",
      "Train Epoch: 4 [102080/110534 (92%)]\tClassification Loss: 1.7550\r\n",
      "Train Epoch: 4 [102240/110534 (93%)]\tClassification Loss: 1.1915\r\n",
      "Test() called at batch_idx: 6400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4361, Accuracy: 303/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 4 [102400/110534 (93%)]\tClassification Loss: 1.3575\r\n",
      "Train Epoch: 4 [102560/110534 (93%)]\tClassification Loss: 1.3403\r\n",
      "Train Epoch: 4 [102720/110534 (93%)]\tClassification Loss: 1.4694\r\n",
      "Train Epoch: 4 [102880/110534 (93%)]\tClassification Loss: 2.0390\r\n",
      "Train Epoch: 4 [103040/110534 (93%)]\tClassification Loss: 1.3368\r\n",
      "Train Epoch: 4 [103200/110534 (93%)]\tClassification Loss: 1.5862\r\n",
      "Train Epoch: 4 [103360/110534 (94%)]\tClassification Loss: 2.1226\r\n",
      "Train Epoch: 4 [103520/110534 (94%)]\tClassification Loss: 1.5263\r\n",
      "Train Epoch: 4 [103680/110534 (94%)]\tClassification Loss: 0.9502\r\n",
      "Train Epoch: 4 [103840/110534 (94%)]\tClassification Loss: 1.3092\r\n",
      "Test() called at batch_idx: 6500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4336, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [104000/110534 (94%)]\tClassification Loss: 1.3441\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_6500.pth.tar\r\n",
      "Train Epoch: 4 [104160/110534 (94%)]\tClassification Loss: 2.2052\r\n",
      "Train Epoch: 4 [104320/110534 (94%)]\tClassification Loss: 2.2548\r\n",
      "Train Epoch: 4 [104480/110534 (95%)]\tClassification Loss: 1.8364\r\n",
      "Train Epoch: 4 [104640/110534 (95%)]\tClassification Loss: 1.3917\r\n",
      "Train Epoch: 4 [104800/110534 (95%)]\tClassification Loss: 1.1624\r\n",
      "Train Epoch: 4 [104960/110534 (95%)]\tClassification Loss: 0.8947\r\n",
      "Train Epoch: 4 [105120/110534 (95%)]\tClassification Loss: 1.3535\r\n",
      "Train Epoch: 4 [105280/110534 (95%)]\tClassification Loss: 1.2816\r\n",
      "Train Epoch: 4 [105440/110534 (95%)]\tClassification Loss: 1.3813\r\n",
      "Test() called at batch_idx: 6600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4504, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [105600/110534 (96%)]\tClassification Loss: 1.7792\r\n",
      "Train Epoch: 4 [105760/110534 (96%)]\tClassification Loss: 1.6266\r\n",
      "Train Epoch: 4 [105920/110534 (96%)]\tClassification Loss: 0.9865\r\n",
      "Train Epoch: 4 [106080/110534 (96%)]\tClassification Loss: 1.4795\r\n",
      "Train Epoch: 4 [106240/110534 (96%)]\tClassification Loss: 1.9020\r\n",
      "Train Epoch: 4 [106400/110534 (96%)]\tClassification Loss: 1.1966\r\n",
      "Train Epoch: 4 [106560/110534 (96%)]\tClassification Loss: 1.7534\r\n",
      "Train Epoch: 4 [106720/110534 (97%)]\tClassification Loss: 1.5159\r\n",
      "Train Epoch: 4 [106880/110534 (97%)]\tClassification Loss: 1.6787\r\n",
      "Train Epoch: 4 [107040/110534 (97%)]\tClassification Loss: 1.1068\r\n",
      "Test() called at batch_idx: 6700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4380, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 4 [107200/110534 (97%)]\tClassification Loss: 1.4376\r\n",
      "Train Epoch: 4 [107360/110534 (97%)]\tClassification Loss: 1.6239\r\n",
      "Train Epoch: 4 [107520/110534 (97%)]\tClassification Loss: 1.7312\r\n",
      "Train Epoch: 4 [107680/110534 (97%)]\tClassification Loss: 1.2634\r\n",
      "Train Epoch: 4 [107840/110534 (98%)]\tClassification Loss: 1.2641\r\n",
      "Train Epoch: 4 [108000/110534 (98%)]\tClassification Loss: 1.6194\r\n",
      "Train Epoch: 4 [108160/110534 (98%)]\tClassification Loss: 1.8684\r\n",
      "Train Epoch: 4 [108320/110534 (98%)]\tClassification Loss: 0.9875\r\n",
      "Train Epoch: 4 [108480/110534 (98%)]\tClassification Loss: 1.2067\r\n",
      "Train Epoch: 4 [108640/110534 (98%)]\tClassification Loss: 1.0093\r\n",
      "Test() called at batch_idx: 6800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4409, Accuracy: 306/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 4 [108800/110534 (98%)]\tClassification Loss: 1.5610\r\n",
      "Train Epoch: 4 [108960/110534 (99%)]\tClassification Loss: 2.3153\r\n",
      "Train Epoch: 4 [109120/110534 (99%)]\tClassification Loss: 2.0472\r\n",
      "Train Epoch: 4 [109280/110534 (99%)]\tClassification Loss: 1.1090\r\n",
      "Train Epoch: 4 [109440/110534 (99%)]\tClassification Loss: 1.2929\r\n",
      "Train Epoch: 4 [109600/110534 (99%)]\tClassification Loss: 1.4159\r\n",
      "Train Epoch: 4 [109760/110534 (99%)]\tClassification Loss: 1.5766\r\n",
      "Train Epoch: 4 [109920/110534 (99%)]\tClassification Loss: 1.3060\r\n",
      "Train Epoch: 4 [110080/110534 (100%)]\tClassification Loss: 1.8900\r\n",
      "Train Epoch: 4 [110240/110534 (100%)]\tClassification Loss: 1.5783\r\n",
      "Test() called at batch_idx: 6900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4488, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 4 [110400/110534 (100%)]\tClassification Loss: 1.3661\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_final.pth.tar\r\n",
      "Test() called at batch_idx: 0\r\n",
      "\r\n",
      "Test set: Average loss: 1.4506, Accuracy: 295/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 5 [0/110534 (0%)]\tClassification Loss: 1.8425\r\n",
      "Train Epoch: 5 [160/110534 (0%)]\tClassification Loss: 1.3345\r\n",
      "Train Epoch: 5 [320/110534 (0%)]\tClassification Loss: 1.1468\r\n",
      "Train Epoch: 5 [480/110534 (0%)]\tClassification Loss: 2.0338\r\n",
      "Train Epoch: 5 [640/110534 (1%)]\tClassification Loss: 1.2095\r\n",
      "Train Epoch: 5 [800/110534 (1%)]\tClassification Loss: 1.1548\r\n",
      "Train Epoch: 5 [960/110534 (1%)]\tClassification Loss: 1.2796\r\n",
      "Train Epoch: 5 [1120/110534 (1%)]\tClassification Loss: 1.1798\r\n",
      "Train Epoch: 5 [1280/110534 (1%)]\tClassification Loss: 1.6992\r\n",
      "Train Epoch: 5 [1440/110534 (1%)]\tClassification Loss: 0.7861\r\n",
      "Test() called at batch_idx: 100\r\n",
      "\r\n",
      "Test set: Average loss: 1.4314, Accuracy: 305/480 (64%)\r\n",
      "\r\n",
      "Train Epoch: 5 [1600/110534 (1%)]\tClassification Loss: 1.3949\r\n",
      "Train Epoch: 5 [1760/110534 (2%)]\tClassification Loss: 2.2076\r\n",
      "Train Epoch: 5 [1920/110534 (2%)]\tClassification Loss: 1.4602\r\n",
      "Train Epoch: 5 [2080/110534 (2%)]\tClassification Loss: 1.4011\r\n",
      "Train Epoch: 5 [2240/110534 (2%)]\tClassification Loss: 1.4859\r\n",
      "Train Epoch: 5 [2400/110534 (2%)]\tClassification Loss: 1.5079\r\n",
      "Train Epoch: 5 [2560/110534 (2%)]\tClassification Loss: 1.6586\r\n",
      "Train Epoch: 5 [2720/110534 (2%)]\tClassification Loss: 1.9055\r\n",
      "Train Epoch: 5 [2880/110534 (3%)]\tClassification Loss: 1.8466\r\n",
      "Train Epoch: 5 [3040/110534 (3%)]\tClassification Loss: 1.9143\r\n",
      "Test() called at batch_idx: 200\r\n",
      "\r\n",
      "Test set: Average loss: 1.4425, Accuracy: 294/480 (61%)\r\n",
      "\r\n",
      "Train Epoch: 5 [3200/110534 (3%)]\tClassification Loss: 1.2244\r\n",
      "Train Epoch: 5 [3360/110534 (3%)]\tClassification Loss: 1.7333\r\n",
      "Train Epoch: 5 [3520/110534 (3%)]\tClassification Loss: 1.3974\r\n",
      "Train Epoch: 5 [3680/110534 (3%)]\tClassification Loss: 1.4449\r\n",
      "Train Epoch: 5 [3840/110534 (3%)]\tClassification Loss: 1.1913\r\n",
      "Train Epoch: 5 [4000/110534 (4%)]\tClassification Loss: 1.3526\r\n",
      "Train Epoch: 5 [4160/110534 (4%)]\tClassification Loss: 1.3292\r\n",
      "Train Epoch: 5 [4320/110534 (4%)]\tClassification Loss: 1.3210\r\n",
      "Train Epoch: 5 [4480/110534 (4%)]\tClassification Loss: 1.0718\r\n",
      "Train Epoch: 5 [4640/110534 (4%)]\tClassification Loss: 1.2608\r\n",
      "Test() called at batch_idx: 300\r\n",
      "\r\n",
      "Test set: Average loss: 1.4569, Accuracy: 300/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 5 [4800/110534 (4%)]\tClassification Loss: 2.0513\r\n",
      "Train Epoch: 5 [4960/110534 (4%)]\tClassification Loss: 1.3435\r\n",
      "Train Epoch: 5 [5120/110534 (5%)]\tClassification Loss: 1.7883\r\n",
      "Train Epoch: 5 [5280/110534 (5%)]\tClassification Loss: 1.1636\r\n",
      "Train Epoch: 5 [5440/110534 (5%)]\tClassification Loss: 1.3539\r\n",
      "Train Epoch: 5 [5600/110534 (5%)]\tClassification Loss: 1.4956\r\n",
      "Train Epoch: 5 [5760/110534 (5%)]\tClassification Loss: 1.4441\r\n",
      "Train Epoch: 5 [5920/110534 (5%)]\tClassification Loss: 1.1734\r\n",
      "Train Epoch: 5 [6080/110534 (6%)]\tClassification Loss: 1.3988\r\n",
      "Train Epoch: 5 [6240/110534 (6%)]\tClassification Loss: 1.6041\r\n",
      "Test() called at batch_idx: 400\r\n",
      "\r\n",
      "Test set: Average loss: 1.4362, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 5 [6400/110534 (6%)]\tClassification Loss: 1.2174\r\n",
      "Train Epoch: 5 [6560/110534 (6%)]\tClassification Loss: 1.8039\r\n",
      "Train Epoch: 5 [6720/110534 (6%)]\tClassification Loss: 1.3460\r\n",
      "Train Epoch: 5 [6880/110534 (6%)]\tClassification Loss: 1.9042\r\n",
      "Train Epoch: 5 [7040/110534 (6%)]\tClassification Loss: 1.2491\r\n",
      "Train Epoch: 5 [7200/110534 (7%)]\tClassification Loss: 1.1371\r\n",
      "Train Epoch: 5 [7360/110534 (7%)]\tClassification Loss: 1.9401\r\n",
      "Train Epoch: 5 [7520/110534 (7%)]\tClassification Loss: 1.3476\r\n",
      "Train Epoch: 5 [7680/110534 (7%)]\tClassification Loss: 1.2727\r\n",
      "Train Epoch: 5 [7840/110534 (7%)]\tClassification Loss: 2.1764\r\n",
      "Test() called at batch_idx: 500\r\n",
      "\r\n",
      "Test set: Average loss: 1.4566, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 5 [8000/110534 (7%)]\tClassification Loss: 1.3014\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_500.pth.tar\r\n",
      "Train Epoch: 5 [8160/110534 (7%)]\tClassification Loss: 1.3069\r\n",
      "Train Epoch: 5 [8320/110534 (8%)]\tClassification Loss: 1.4968\r\n",
      "Train Epoch: 5 [8480/110534 (8%)]\tClassification Loss: 1.6342\r\n",
      "Train Epoch: 5 [8640/110534 (8%)]\tClassification Loss: 1.3791\r\n",
      "Train Epoch: 5 [8800/110534 (8%)]\tClassification Loss: 1.3338\r\n",
      "Train Epoch: 5 [8960/110534 (8%)]\tClassification Loss: 1.6439\r\n",
      "Train Epoch: 5 [9120/110534 (8%)]\tClassification Loss: 1.8126\r\n",
      "Train Epoch: 5 [9280/110534 (8%)]\tClassification Loss: 1.7457\r\n",
      "Train Epoch: 5 [9440/110534 (9%)]\tClassification Loss: 0.9925\r\n",
      "Test() called at batch_idx: 600\r\n",
      "\r\n",
      "Test set: Average loss: 1.4432, Accuracy: 298/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 5 [9600/110534 (9%)]\tClassification Loss: 1.6751\r\n",
      "Train Epoch: 5 [9760/110534 (9%)]\tClassification Loss: 1.0050\r\n",
      "Train Epoch: 5 [9920/110534 (9%)]\tClassification Loss: 1.5249\r\n",
      "Train Epoch: 5 [10080/110534 (9%)]\tClassification Loss: 1.6717\r\n",
      "Train Epoch: 5 [10240/110534 (9%)]\tClassification Loss: 1.4874\r\n",
      "Train Epoch: 5 [10400/110534 (9%)]\tClassification Loss: 1.3671\r\n",
      "Train Epoch: 5 [10560/110534 (10%)]\tClassification Loss: 1.1370\r\n",
      "Train Epoch: 5 [10720/110534 (10%)]\tClassification Loss: 2.3164\r\n",
      "Train Epoch: 5 [10880/110534 (10%)]\tClassification Loss: 1.8180\r\n",
      "Train Epoch: 5 [11040/110534 (10%)]\tClassification Loss: 1.3032\r\n",
      "Test() called at batch_idx: 700\r\n",
      "\r\n",
      "Test set: Average loss: 1.4410, Accuracy: 302/480 (63%)\r\n",
      "\r\n",
      "Train Epoch: 5 [11200/110534 (10%)]\tClassification Loss: 1.2280\r\n",
      "Train Epoch: 5 [11360/110534 (10%)]\tClassification Loss: 1.4470\r\n",
      "Train Epoch: 5 [11520/110534 (10%)]\tClassification Loss: 1.5648\r\n",
      "Train Epoch: 5 [11680/110534 (11%)]\tClassification Loss: 1.3632\r\n",
      "Train Epoch: 5 [11840/110534 (11%)]\tClassification Loss: 1.3608\r\n",
      "Train Epoch: 5 [12000/110534 (11%)]\tClassification Loss: 1.4751\r\n",
      "Train Epoch: 5 [12160/110534 (11%)]\tClassification Loss: 1.4111\r\n",
      "Train Epoch: 5 [12320/110534 (11%)]\tClassification Loss: 1.0934\r\n",
      "Train Epoch: 5 [12480/110534 (11%)]\tClassification Loss: 1.4837\r\n",
      "Train Epoch: 5 [12640/110534 (11%)]\tClassification Loss: 1.6586\r\n",
      "Test() called at batch_idx: 800\r\n",
      "\r\n",
      "Test set: Average loss: 1.4408, Accuracy: 299/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 5 [12800/110534 (12%)]\tClassification Loss: 1.6494\r\n",
      "Train Epoch: 5 [12960/110534 (12%)]\tClassification Loss: 1.8092\r\n",
      "Train Epoch: 5 [13120/110534 (12%)]\tClassification Loss: 1.6356\r\n",
      "Train Epoch: 5 [13280/110534 (12%)]\tClassification Loss: 1.5446\r\n",
      "Train Epoch: 5 [13440/110534 (12%)]\tClassification Loss: 1.9240\r\n",
      "Train Epoch: 5 [13600/110534 (12%)]\tClassification Loss: 1.6834\r\n",
      "Train Epoch: 5 [13760/110534 (12%)]\tClassification Loss: 1.2163\r\n",
      "Train Epoch: 5 [13920/110534 (13%)]\tClassification Loss: 1.0815\r\n",
      "Train Epoch: 5 [14080/110534 (13%)]\tClassification Loss: 1.3339\r\n",
      "Train Epoch: 5 [14240/110534 (13%)]\tClassification Loss: 2.2763\r\n",
      "Test() called at batch_idx: 900\r\n",
      "\r\n",
      "Test set: Average loss: 1.4525, Accuracy: 297/480 (62%)\r\n",
      "\r\n",
      "Train Epoch: 5 [14400/110534 (13%)]\tClassification Loss: 1.1710\r\n",
      "Train Epoch: 5 [14560/110534 (13%)]\tClassification Loss: 1.1452\r\n",
      "Train Epoch: 5 [14720/110534 (13%)]\tClassification Loss: 1.6905\r\n",
      "Train Epoch: 5 [14880/110534 (13%)]\tClassification Loss: 1.4459\r\n",
      "Train Epoch: 5 [15040/110534 (14%)]\tClassification Loss: 1.3324\r\n",
      "Train Epoch: 5 [15200/110534 (14%)]\tClassification Loss: 1.3544\r\n",
      "Train Epoch: 5 [15360/110534 (14%)]\tClassification Loss: 1.3246\r\n",
      "^C\r\n",
      "Exception in thread Thread-291:\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n",
      "    self.run()\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/threading.py\", line 870, in run\r\n",
      "    self._target(*self._args, **self._kwargs)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\r\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 116, in get\r\n",
      "    return _ForkingPickler.loads(res)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\", line 294, in rebuild_storage_fd\r\n",
      "    fd = df.detach()\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/resource_sharer.py\", line 57, in detach\r\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/resource_sharer.py\", line 87, in get_connection\r\n",
      "    c = Client(address, authkey=process.current_process().authkey)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 502, in Client\r\n",
      "    c = SocketClient(address)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 629, in SocketClient\r\n",
      "    s.connect(address)\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"train.py\", line 236, in <module>\r\n",
      "    for epoch in range(1, EPOCH + 1):\r\n",
      "  File \"train.py\", line 89, in train\r\n",
      "    running_correct += pred.eq(target.data.view_as(pred)).cpu().sum()\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oFYsssLDaSDJ",
    "colab_type": "code",
    "outputId": "c8b0c1e4-9039-4b20-cef8-c971efa437aa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1584954545220,
     "user_tz": -300,
     "elapsed": 3922822,
     "user": {
      "displayName": "Muhammad Ali",
      "photoUrl": "",
      "userId": "15673831022739340207"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "# model_5_1500.pth.tar. Freeze=True. LR=0.03\n",
    "! python train.py"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:220: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:704: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  \"please use transforms.RandomResizedCrop instead.\")\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
      "100% 97.8M/97.8M [00:01<00:00, 62.9MB/s]\n",
      "Loading model model_5_1500.pth.tar\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "train.py:132: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "\n",
      "Test set: Average loss: 1.4784, Accuracy: 280/480 (58%)\n",
      "\n",
      "Train Epoch: 1 [0/110534 (0%)]\tAll Loss: 2.1485\tTriple Loss(1): 0.2993\tClassification Loss: 1.5500\n",
      "Train Epoch: 1 [160/110534 (0%)]\tAll Loss: 1.5572\tTriple Loss(0): 0.0000\tClassification Loss: 1.5572\n",
      "Train Epoch: 1 [320/110534 (0%)]\tAll Loss: 2.2011\tTriple Loss(1): 0.3139\tClassification Loss: 1.5733\n",
      "Train Epoch: 1 [480/110534 (0%)]\tAll Loss: 1.4629\tTriple Loss(1): 0.2042\tClassification Loss: 1.0544\n",
      "Train Epoch: 1 [640/110534 (1%)]\tAll Loss: 0.8739\tTriple Loss(1): 0.0252\tClassification Loss: 0.8235\n",
      "Train Epoch: 1 [800/110534 (1%)]\tAll Loss: 2.8054\tTriple Loss(1): 0.4463\tClassification Loss: 1.9128\n",
      "Train Epoch: 1 [960/110534 (1%)]\tAll Loss: 1.1585\tTriple Loss(0): 0.0000\tClassification Loss: 1.1585\n",
      "Train Epoch: 1 [1120/110534 (1%)]\tAll Loss: 1.9586\tTriple Loss(1): 0.0987\tClassification Loss: 1.7612\n",
      "Train Epoch: 1 [1280/110534 (1%)]\tAll Loss: 1.3543\tTriple Loss(1): 0.0641\tClassification Loss: 1.2262\n",
      "Train Epoch: 1 [1440/110534 (1%)]\tAll Loss: 1.9506\tTriple Loss(1): 0.1715\tClassification Loss: 1.6075\n",
      "\n",
      "Test set: Average loss: 1.4848, Accuracy: 284/480 (59%)\n",
      "\n",
      "Train Epoch: 1 [1600/110534 (1%)]\tAll Loss: 2.2874\tTriple Loss(1): 0.5040\tClassification Loss: 1.2794\n",
      "Train Epoch: 1 [1760/110534 (2%)]\tAll Loss: 2.0542\tTriple Loss(0): 0.0000\tClassification Loss: 2.0542\n",
      "Train Epoch: 1 [1920/110534 (2%)]\tAll Loss: 1.7936\tTriple Loss(1): 0.1969\tClassification Loss: 1.3998\n",
      "Train Epoch: 1 [2080/110534 (2%)]\tAll Loss: 1.9291\tTriple Loss(1): 0.0973\tClassification Loss: 1.7345\n",
      "Train Epoch: 1 [2240/110534 (2%)]\tAll Loss: 1.7137\tTriple Loss(1): 0.0563\tClassification Loss: 1.6012\n",
      "Train Epoch: 1 [2400/110534 (2%)]\tAll Loss: 1.3432\tTriple Loss(0): 0.0000\tClassification Loss: 1.3432\n",
      "Train Epoch: 1 [2560/110534 (2%)]\tAll Loss: 1.3121\tTriple Loss(0): 0.0000\tClassification Loss: 1.3121\n",
      "Train Epoch: 1 [2720/110534 (2%)]\tAll Loss: 1.6070\tTriple Loss(1): 0.1249\tClassification Loss: 1.3571\n",
      "Train Epoch: 1 [2880/110534 (3%)]\tAll Loss: 1.9302\tTriple Loss(1): 0.0000\tClassification Loss: 1.9302\n",
      "Train Epoch: 1 [3040/110534 (3%)]\tAll Loss: 1.9748\tTriple Loss(1): 0.1526\tClassification Loss: 1.6696\n",
      "\n",
      "Test set: Average loss: 1.4676, Accuracy: 278/480 (58%)\n",
      "\n",
      "Train Epoch: 1 [3200/110534 (3%)]\tAll Loss: 2.5632\tTriple Loss(1): 0.3726\tClassification Loss: 1.8181\n",
      "Train Epoch: 1 [3360/110534 (3%)]\tAll Loss: 1.6722\tTriple Loss(0): 0.0000\tClassification Loss: 1.6722\n",
      "Train Epoch: 1 [3520/110534 (3%)]\tAll Loss: 1.6611\tTriple Loss(1): 0.0245\tClassification Loss: 1.6121\n",
      "Train Epoch: 1 [3680/110534 (3%)]\tAll Loss: 1.4897\tTriple Loss(0): 0.0000\tClassification Loss: 1.4897\n",
      "Train Epoch: 1 [3840/110534 (3%)]\tAll Loss: 1.4168\tTriple Loss(1): 0.0571\tClassification Loss: 1.3026\n",
      "Train Epoch: 1 [4000/110534 (4%)]\tAll Loss: 2.1130\tTriple Loss(1): 0.1193\tClassification Loss: 1.8744\n",
      "Train Epoch: 1 [4160/110534 (4%)]\tAll Loss: 1.8125\tTriple Loss(1): 0.0955\tClassification Loss: 1.6216\n",
      "Train Epoch: 1 [4320/110534 (4%)]\tAll Loss: 5.3454\tTriple Loss(0): 2.2449\tClassification Loss: 0.8556\n",
      "Train Epoch: 1 [4480/110534 (4%)]\tAll Loss: 2.0839\tTriple Loss(1): 0.2863\tClassification Loss: 1.5113\n",
      "Train Epoch: 1 [4640/110534 (4%)]\tAll Loss: 1.6224\tTriple Loss(1): 0.2456\tClassification Loss: 1.1312\n",
      "\n",
      "Test set: Average loss: 1.4687, Accuracy: 279/480 (58%)\n",
      "\n",
      "Train Epoch: 1 [4800/110534 (4%)]\tAll Loss: 1.4135\tTriple Loss(1): 0.0139\tClassification Loss: 1.3856\n",
      "Train Epoch: 1 [4960/110534 (4%)]\tAll Loss: 2.1947\tTriple Loss(1): 0.2180\tClassification Loss: 1.7586\n",
      "Train Epoch: 1 [5120/110534 (5%)]\tAll Loss: 2.0731\tTriple Loss(1): 0.3403\tClassification Loss: 1.3924\n",
      "Train Epoch: 1 [5280/110534 (5%)]\tAll Loss: 1.2558\tTriple Loss(1): 0.0465\tClassification Loss: 1.1628\n",
      "Train Epoch: 1 [5440/110534 (5%)]\tAll Loss: 1.3919\tTriple Loss(0): 0.0000\tClassification Loss: 1.3919\n",
      "Train Epoch: 1 [5600/110534 (5%)]\tAll Loss: 2.7083\tTriple Loss(1): 0.4737\tClassification Loss: 1.7609\n",
      "Train Epoch: 1 [5760/110534 (5%)]\tAll Loss: 2.4983\tTriple Loss(1): 0.3686\tClassification Loss: 1.7612\n",
      "Train Epoch: 1 [5920/110534 (5%)]\tAll Loss: 2.2455\tTriple Loss(0): 0.5020\tClassification Loss: 1.2415\n",
      "Train Epoch: 1 [6080/110534 (6%)]\tAll Loss: 2.5902\tTriple Loss(1): 0.3992\tClassification Loss: 1.7918\n",
      "Train Epoch: 1 [6240/110534 (6%)]\tAll Loss: 1.5443\tTriple Loss(1): 0.0369\tClassification Loss: 1.4706\n",
      "\n",
      "Test set: Average loss: 1.4641, Accuracy: 282/480 (59%)\n",
      "\n",
      "Train Epoch: 1 [6400/110534 (6%)]\tAll Loss: 1.7944\tTriple Loss(1): 0.0691\tClassification Loss: 1.6561\n",
      "Train Epoch: 1 [6560/110534 (6%)]\tAll Loss: 2.3275\tTriple Loss(1): 0.4020\tClassification Loss: 1.5236\n",
      "Train Epoch: 1 [6720/110534 (6%)]\tAll Loss: 1.5509\tTriple Loss(0): 0.0000\tClassification Loss: 1.5509\n",
      "Train Epoch: 1 [6880/110534 (6%)]\tAll Loss: 1.7928\tTriple Loss(1): 0.2394\tClassification Loss: 1.3141\n",
      "Train Epoch: 1 [7040/110534 (6%)]\tAll Loss: 2.6062\tTriple Loss(1): 0.4534\tClassification Loss: 1.6994\n",
      "Train Epoch: 1 [7200/110534 (7%)]\tAll Loss: 1.9709\tTriple Loss(1): 0.1490\tClassification Loss: 1.6729\n",
      "Train Epoch: 1 [7360/110534 (7%)]\tAll Loss: 2.1860\tTriple Loss(1): 0.2535\tClassification Loss: 1.6791\n",
      "Train Epoch: 1 [7520/110534 (7%)]\tAll Loss: 1.7795\tTriple Loss(1): 0.1393\tClassification Loss: 1.5010\n",
      "Train Epoch: 1 [7680/110534 (7%)]\tAll Loss: 1.8702\tTriple Loss(1): 0.1276\tClassification Loss: 1.6149\n",
      "Train Epoch: 1 [7840/110534 (7%)]\tAll Loss: 1.9531\tTriple Loss(1): 0.3214\tClassification Loss: 1.3104\n",
      "\n",
      "Test set: Average loss: 1.4802, Accuracy: 278/480 (58%)\n",
      "\n",
      "Train Epoch: 1 [8000/110534 (7%)]\tAll Loss: 2.2457\tTriple Loss(1): 0.3598\tClassification Loss: 1.5261\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_500.pth.tar\n",
      "Train Epoch: 1 [8160/110534 (7%)]\tAll Loss: 2.4300\tTriple Loss(1): 0.6691\tClassification Loss: 1.0918\n",
      "Train Epoch: 1 [8320/110534 (8%)]\tAll Loss: 1.2499\tTriple Loss(0): 0.0000\tClassification Loss: 1.2499\n",
      "Train Epoch: 1 [8480/110534 (8%)]\tAll Loss: 2.7319\tTriple Loss(1): 0.3658\tClassification Loss: 2.0004\n",
      "Train Epoch: 1 [8640/110534 (8%)]\tAll Loss: 1.2924\tTriple Loss(1): 0.0819\tClassification Loss: 1.1286\n",
      "Train Epoch: 1 [8800/110534 (8%)]\tAll Loss: 2.1268\tTriple Loss(1): 0.2611\tClassification Loss: 1.6046\n",
      "Train Epoch: 1 [8960/110534 (8%)]\tAll Loss: 1.2018\tTriple Loss(1): 0.0210\tClassification Loss: 1.1598\n",
      "Train Epoch: 1 [9120/110534 (8%)]\tAll Loss: 2.1419\tTriple Loss(1): 0.4273\tClassification Loss: 1.2874\n",
      "Train Epoch: 1 [9280/110534 (8%)]\tAll Loss: 1.3895\tTriple Loss(1): 0.2315\tClassification Loss: 0.9265\n",
      "Train Epoch: 1 [9440/110534 (9%)]\tAll Loss: 2.4712\tTriple Loss(1): 0.1975\tClassification Loss: 2.0761\n",
      "\n",
      "Test set: Average loss: 1.4743, Accuracy: 281/480 (59%)\n",
      "\n",
      "Train Epoch: 1 [9600/110534 (9%)]\tAll Loss: 2.6672\tTriple Loss(1): 0.3993\tClassification Loss: 1.8687\n",
      "Train Epoch: 1 [9760/110534 (9%)]\tAll Loss: 2.5614\tTriple Loss(1): 0.4342\tClassification Loss: 1.6930\n",
      "Train Epoch: 1 [9920/110534 (9%)]\tAll Loss: 1.7607\tTriple Loss(1): 0.3231\tClassification Loss: 1.1145\n",
      "Train Epoch: 1 [10080/110534 (9%)]\tAll Loss: 2.4324\tTriple Loss(1): 0.2577\tClassification Loss: 1.9170\n",
      "Train Epoch: 1 [10240/110534 (9%)]\tAll Loss: 1.5599\tTriple Loss(1): 0.0797\tClassification Loss: 1.4004\n",
      "Train Epoch: 1 [10400/110534 (9%)]\tAll Loss: 1.3439\tTriple Loss(1): 0.0972\tClassification Loss: 1.1494\n",
      "Train Epoch: 1 [10560/110534 (10%)]\tAll Loss: 1.5434\tTriple Loss(1): 0.0224\tClassification Loss: 1.4986\n",
      "Train Epoch: 1 [10720/110534 (10%)]\tAll Loss: 1.2186\tTriple Loss(0): 0.0000\tClassification Loss: 1.2186\n",
      "Train Epoch: 1 [10880/110534 (10%)]\tAll Loss: 1.8394\tTriple Loss(1): 0.1979\tClassification Loss: 1.4437\n",
      "Train Epoch: 1 [11040/110534 (10%)]\tAll Loss: 1.9028\tTriple Loss(0): 0.0000\tClassification Loss: 1.9028\n",
      "\n",
      "Test set: Average loss: 1.4741, Accuracy: 282/480 (59%)\n",
      "\n",
      "Train Epoch: 1 [11200/110534 (10%)]\tAll Loss: 1.5566\tTriple Loss(1): 0.1851\tClassification Loss: 1.1864\n",
      "Train Epoch: 1 [11360/110534 (10%)]\tAll Loss: 1.8884\tTriple Loss(1): 0.2180\tClassification Loss: 1.4524\n",
      "Train Epoch: 1 [11520/110534 (10%)]\tAll Loss: 2.2547\tTriple Loss(1): 0.1081\tClassification Loss: 2.0386\n",
      "Train Epoch: 1 [11680/110534 (11%)]\tAll Loss: 1.7746\tTriple Loss(1): 0.0000\tClassification Loss: 1.7746\n",
      "Train Epoch: 1 [11840/110534 (11%)]\tAll Loss: 1.6530\tTriple Loss(1): 0.2216\tClassification Loss: 1.2098\n",
      "Train Epoch: 1 [12000/110534 (11%)]\tAll Loss: 1.7803\tTriple Loss(1): 0.0000\tClassification Loss: 1.7803\n",
      "Train Epoch: 1 [12160/110534 (11%)]\tAll Loss: 2.2128\tTriple Loss(1): 0.2627\tClassification Loss: 1.6874\n",
      "Train Epoch: 1 [12320/110534 (11%)]\tAll Loss: 2.0811\tTriple Loss(1): 0.0724\tClassification Loss: 1.9363\n",
      "Train Epoch: 1 [12480/110534 (11%)]\tAll Loss: 1.9745\tTriple Loss(1): 0.1601\tClassification Loss: 1.6544\n",
      "Train Epoch: 1 [12640/110534 (11%)]\tAll Loss: 2.1191\tTriple Loss(1): 0.2349\tClassification Loss: 1.6493\n",
      "\n",
      "Test set: Average loss: 1.4817, Accuracy: 290/480 (60%)\n",
      "\n",
      "Train Epoch: 1 [12800/110534 (12%)]\tAll Loss: 1.2917\tTriple Loss(0): 0.0000\tClassification Loss: 1.2917\n",
      "Train Epoch: 1 [12960/110534 (12%)]\tAll Loss: 1.6510\tTriple Loss(1): 0.0193\tClassification Loss: 1.6124\n",
      "Train Epoch: 1 [13120/110534 (12%)]\tAll Loss: 2.8667\tTriple Loss(1): 0.7331\tClassification Loss: 1.4006\n",
      "Train Epoch: 1 [13280/110534 (12%)]\tAll Loss: 1.1861\tTriple Loss(1): 0.0934\tClassification Loss: 0.9992\n",
      "Train Epoch: 1 [13440/110534 (12%)]\tAll Loss: 1.5811\tTriple Loss(0): 0.0000\tClassification Loss: 1.5811\n",
      "Train Epoch: 1 [13600/110534 (12%)]\tAll Loss: 2.0700\tTriple Loss(1): 0.1368\tClassification Loss: 1.7965\n",
      "Train Epoch: 1 [13760/110534 (12%)]\tAll Loss: 1.3364\tTriple Loss(1): 0.0000\tClassification Loss: 1.3364\n",
      "Train Epoch: 1 [13920/110534 (13%)]\tAll Loss: 1.8641\tTriple Loss(1): 0.1542\tClassification Loss: 1.5558\n",
      "Train Epoch: 1 [14080/110534 (13%)]\tAll Loss: 2.4826\tTriple Loss(1): 0.0000\tClassification Loss: 2.4826\n",
      "Train Epoch: 1 [14240/110534 (13%)]\tAll Loss: 2.1868\tTriple Loss(1): 0.1343\tClassification Loss: 1.9182\n",
      "\n",
      "Test set: Average loss: 1.4519, Accuracy: 289/480 (60%)\n",
      "\n",
      "Train Epoch: 1 [14400/110534 (13%)]\tAll Loss: 7.3120\tTriple Loss(0): 2.9192\tClassification Loss: 1.4735\n",
      "Train Epoch: 1 [14560/110534 (13%)]\tAll Loss: 1.7987\tTriple Loss(0): 0.0000\tClassification Loss: 1.7987\n",
      "Train Epoch: 1 [14720/110534 (13%)]\tAll Loss: 1.7948\tTriple Loss(0): 0.0000\tClassification Loss: 1.7948\n",
      "Train Epoch: 1 [14880/110534 (13%)]\tAll Loss: 2.3041\tTriple Loss(1): 0.3911\tClassification Loss: 1.5219\n",
      "Train Epoch: 1 [15040/110534 (14%)]\tAll Loss: 2.4737\tTriple Loss(1): 0.4331\tClassification Loss: 1.6074\n",
      "Train Epoch: 1 [15200/110534 (14%)]\tAll Loss: 1.7377\tTriple Loss(1): 0.0913\tClassification Loss: 1.5552\n",
      "Train Epoch: 1 [15360/110534 (14%)]\tAll Loss: 1.8896\tTriple Loss(1): 0.1160\tClassification Loss: 1.6577\n",
      "Train Epoch: 1 [15520/110534 (14%)]\tAll Loss: 1.2980\tTriple Loss(1): 0.0470\tClassification Loss: 1.2040\n",
      "Train Epoch: 1 [15680/110534 (14%)]\tAll Loss: 1.0194\tTriple Loss(0): 0.0000\tClassification Loss: 1.0194\n",
      "Train Epoch: 1 [15840/110534 (14%)]\tAll Loss: 2.4260\tTriple Loss(1): 0.4589\tClassification Loss: 1.5081\n",
      "\n",
      "Test set: Average loss: 1.4787, Accuracy: 282/480 (59%)\n",
      "\n",
      "Train Epoch: 1 [16000/110534 (14%)]\tAll Loss: 1.5371\tTriple Loss(1): 0.3083\tClassification Loss: 0.9206\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_1000.pth.tar\n",
      "Train Epoch: 1 [16160/110534 (15%)]\tAll Loss: 2.4289\tTriple Loss(1): 0.4117\tClassification Loss: 1.6055\n",
      "Train Epoch: 1 [16320/110534 (15%)]\tAll Loss: 2.0229\tTriple Loss(1): 0.4199\tClassification Loss: 1.1831\n",
      "Train Epoch: 1 [16480/110534 (15%)]\tAll Loss: 1.0554\tTriple Loss(0): 0.0000\tClassification Loss: 1.0554\n",
      "Train Epoch: 1 [16640/110534 (15%)]\tAll Loss: 2.4721\tTriple Loss(1): 0.4556\tClassification Loss: 1.5609\n",
      "Train Epoch: 1 [16800/110534 (15%)]\tAll Loss: 1.4633\tTriple Loss(0): 0.0000\tClassification Loss: 1.4633\n",
      "Train Epoch: 1 [16960/110534 (15%)]\tAll Loss: 1.9433\tTriple Loss(1): 0.0068\tClassification Loss: 1.9297\n",
      "Train Epoch: 1 [17120/110534 (15%)]\tAll Loss: 2.6055\tTriple Loss(1): 0.1601\tClassification Loss: 2.2853\n",
      "Train Epoch: 1 [17280/110534 (16%)]\tAll Loss: 2.2885\tTriple Loss(1): 0.2389\tClassification Loss: 1.8107\n",
      "Train Epoch: 1 [17440/110534 (16%)]\tAll Loss: 1.7113\tTriple Loss(1): 0.0583\tClassification Loss: 1.5948\n",
      "\n",
      "Test set: Average loss: 1.5157, Accuracy: 276/480 (58%)\n",
      "\n",
      "Train Epoch: 1 [17600/110534 (16%)]\tAll Loss: 1.7592\tTriple Loss(0): 0.0000\tClassification Loss: 1.7592\n",
      "Train Epoch: 1 [17760/110534 (16%)]\tAll Loss: 2.7573\tTriple Loss(1): 0.7667\tClassification Loss: 1.2238\n",
      "Train Epoch: 1 [17920/110534 (16%)]\tAll Loss: 1.9448\tTriple Loss(1): 0.2167\tClassification Loss: 1.5115\n",
      "Train Epoch: 1 [18080/110534 (16%)]\tAll Loss: 1.3275\tTriple Loss(1): 0.0630\tClassification Loss: 1.2016\n",
      "Train Epoch: 1 [18240/110534 (17%)]\tAll Loss: 2.7852\tTriple Loss(1): 0.3515\tClassification Loss: 2.0822\n",
      "Train Epoch: 1 [18400/110534 (17%)]\tAll Loss: 2.7686\tTriple Loss(1): 0.4493\tClassification Loss: 1.8701\n",
      "Train Epoch: 1 [18560/110534 (17%)]\tAll Loss: 1.7376\tTriple Loss(0): 0.0000\tClassification Loss: 1.7376\n",
      "Train Epoch: 1 [18720/110534 (17%)]\tAll Loss: 2.2665\tTriple Loss(1): 0.1823\tClassification Loss: 1.9018\n",
      "Train Epoch: 1 [18880/110534 (17%)]\tAll Loss: 2.0899\tTriple Loss(0): 0.0000\tClassification Loss: 2.0899\n",
      "Train Epoch: 1 [19040/110534 (17%)]\tAll Loss: 1.2108\tTriple Loss(1): 0.0000\tClassification Loss: 1.2108\n",
      "\n",
      "Test set: Average loss: 1.4896, Accuracy: 285/480 (59%)\n",
      "\n",
      "Train Epoch: 1 [19200/110534 (17%)]\tAll Loss: 2.3287\tTriple Loss(1): 0.2214\tClassification Loss: 1.8860\n",
      "Train Epoch: 1 [19360/110534 (18%)]\tAll Loss: 1.6626\tTriple Loss(1): 0.1319\tClassification Loss: 1.3988\n",
      "Train Epoch: 1 [19520/110534 (18%)]\tAll Loss: 2.2105\tTriple Loss(1): 0.3638\tClassification Loss: 1.4829\n",
      "Train Epoch: 1 [19680/110534 (18%)]\tAll Loss: 2.5274\tTriple Loss(1): 0.0845\tClassification Loss: 2.3584\n",
      "Train Epoch: 1 [19840/110534 (18%)]\tAll Loss: 1.3955\tTriple Loss(1): 0.1797\tClassification Loss: 1.0361\n",
      "Train Epoch: 1 [20000/110534 (18%)]\tAll Loss: 1.6571\tTriple Loss(1): 0.2495\tClassification Loss: 1.1581\n",
      "Train Epoch: 1 [20160/110534 (18%)]\tAll Loss: 1.8518\tTriple Loss(1): 0.0000\tClassification Loss: 1.8518\n",
      "Train Epoch: 1 [20320/110534 (18%)]\tAll Loss: 1.6773\tTriple Loss(1): 0.0514\tClassification Loss: 1.5745\n",
      "Train Epoch: 1 [20480/110534 (19%)]\tAll Loss: 1.6440\tTriple Loss(1): 0.1238\tClassification Loss: 1.3964\n",
      "Train Epoch: 1 [20640/110534 (19%)]\tAll Loss: 1.3566\tTriple Loss(0): 0.0000\tClassification Loss: 1.3566\n",
      "\n",
      "Test set: Average loss: 1.4783, Accuracy: 294/480 (61%)\n",
      "\n",
      "Train Epoch: 1 [20800/110534 (19%)]\tAll Loss: 1.1796\tTriple Loss(1): 0.0000\tClassification Loss: 1.1796\n",
      "Train Epoch: 1 [20960/110534 (19%)]\tAll Loss: 1.3157\tTriple Loss(1): 0.1050\tClassification Loss: 1.1056\n",
      "Train Epoch: 1 [21120/110534 (19%)]\tAll Loss: 2.6405\tTriple Loss(1): 0.5577\tClassification Loss: 1.5252\n",
      "Train Epoch: 1 [21280/110534 (19%)]\tAll Loss: 1.7987\tTriple Loss(1): 0.2973\tClassification Loss: 1.2041\n",
      "Train Epoch: 1 [21440/110534 (19%)]\tAll Loss: 2.0077\tTriple Loss(0): 0.0000\tClassification Loss: 2.0077\n",
      "Train Epoch: 1 [21600/110534 (20%)]\tAll Loss: 2.0398\tTriple Loss(1): 0.0933\tClassification Loss: 1.8532\n",
      "Train Epoch: 1 [21760/110534 (20%)]\tAll Loss: 2.2771\tTriple Loss(1): 0.3939\tClassification Loss: 1.4893\n",
      "Train Epoch: 1 [21920/110534 (20%)]\tAll Loss: 1.3958\tTriple Loss(1): 0.1727\tClassification Loss: 1.0504\n",
      "Train Epoch: 1 [22080/110534 (20%)]\tAll Loss: 1.6934\tTriple Loss(1): 0.0440\tClassification Loss: 1.6054\n",
      "Train Epoch: 1 [22240/110534 (20%)]\tAll Loss: 1.7097\tTriple Loss(0): 0.0000\tClassification Loss: 1.7097\n",
      "\n",
      "Test set: Average loss: 1.5168, Accuracy: 281/480 (59%)\n",
      "\n",
      "Train Epoch: 1 [22400/110534 (20%)]\tAll Loss: 1.3569\tTriple Loss(1): 0.1120\tClassification Loss: 1.1328\n",
      "Train Epoch: 1 [22560/110534 (20%)]\tAll Loss: 2.0133\tTriple Loss(1): 0.0000\tClassification Loss: 2.0133\n",
      "Train Epoch: 1 [22720/110534 (21%)]\tAll Loss: 1.7410\tTriple Loss(1): 0.0000\tClassification Loss: 1.7410\n",
      "Train Epoch: 1 [22880/110534 (21%)]\tAll Loss: 2.1969\tTriple Loss(1): 0.1687\tClassification Loss: 1.8594\n",
      "Train Epoch: 1 [23040/110534 (21%)]\tAll Loss: 1.6867\tTriple Loss(1): 0.1232\tClassification Loss: 1.4404\n",
      "Train Epoch: 1 [23200/110534 (21%)]\tAll Loss: 1.7056\tTriple Loss(1): 0.1947\tClassification Loss: 1.3162\n",
      "Train Epoch: 1 [23360/110534 (21%)]\tAll Loss: 2.0242\tTriple Loss(1): 0.2051\tClassification Loss: 1.6141\n",
      "Train Epoch: 1 [23520/110534 (21%)]\tAll Loss: 2.1472\tTriple Loss(1): 0.1665\tClassification Loss: 1.8141\n",
      "Train Epoch: 1 [23680/110534 (21%)]\tAll Loss: 1.6691\tTriple Loss(1): 0.0881\tClassification Loss: 1.4929\n",
      "Train Epoch: 1 [23840/110534 (22%)]\tAll Loss: 1.3429\tTriple Loss(1): 0.0662\tClassification Loss: 1.2105\n",
      "\n",
      "Test set: Average loss: 1.4670, Accuracy: 290/480 (60%)\n",
      "\n",
      "Train Epoch: 1 [24000/110534 (22%)]\tAll Loss: 2.0289\tTriple Loss(0): 0.0000\tClassification Loss: 2.0289\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_1500.pth.tar\n",
      "Train Epoch: 1 [24160/110534 (22%)]\tAll Loss: 2.2555\tTriple Loss(1): 0.3803\tClassification Loss: 1.4949\n",
      "Train Epoch: 1 [24320/110534 (22%)]\tAll Loss: 2.2030\tTriple Loss(1): 0.2343\tClassification Loss: 1.7344\n",
      "Train Epoch: 1 [24480/110534 (22%)]\tAll Loss: 2.3656\tTriple Loss(1): 0.1791\tClassification Loss: 2.0074\n",
      "Train Epoch: 1 [24640/110534 (22%)]\tAll Loss: 1.1767\tTriple Loss(1): 0.1044\tClassification Loss: 0.9678\n",
      "Train Epoch: 1 [24800/110534 (22%)]\tAll Loss: 2.1673\tTriple Loss(1): 0.1407\tClassification Loss: 1.8858\n",
      "Train Epoch: 1 [24960/110534 (23%)]\tAll Loss: 1.7119\tTriple Loss(1): 0.1732\tClassification Loss: 1.3656\n",
      "Train Epoch: 1 [25120/110534 (23%)]\tAll Loss: 1.8443\tTriple Loss(0): 0.0000\tClassification Loss: 1.8443\n",
      "Train Epoch: 1 [25280/110534 (23%)]\tAll Loss: 1.3995\tTriple Loss(1): 0.0518\tClassification Loss: 1.2960\n",
      "Train Epoch: 1 [25440/110534 (23%)]\tAll Loss: 1.1575\tTriple Loss(0): 0.0000\tClassification Loss: 1.1575\n",
      "\n",
      "Test set: Average loss: 1.4959, Accuracy: 286/480 (60%)\n",
      "\n",
      "Train Epoch: 1 [25600/110534 (23%)]\tAll Loss: 1.7937\tTriple Loss(0): 0.0000\tClassification Loss: 1.7937\n",
      "Train Epoch: 1 [25760/110534 (23%)]\tAll Loss: 2.4361\tTriple Loss(1): 0.3797\tClassification Loss: 1.6766\n",
      "Train Epoch: 1 [25920/110534 (23%)]\tAll Loss: 1.7123\tTriple Loss(1): 0.0664\tClassification Loss: 1.5796\n",
      "Train Epoch: 1 [26080/110534 (24%)]\tAll Loss: 1.4447\tTriple Loss(1): 0.0579\tClassification Loss: 1.3289\n",
      "Train Epoch: 1 [26240/110534 (24%)]\tAll Loss: 1.8269\tTriple Loss(1): 0.0000\tClassification Loss: 1.8269\n",
      "ERROR: Unexpected segmentation fault encountered in worker.\n",
      "\u0000Traceback (most recent call last):\n",
      "  File \"train.py\", line 87, in train\n",
      "    data_tri_list = next(triplet_loader_iter)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 831, in _next_data\n",
      "    raise StopIteration\n",
      "StopIteration\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 761, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/usr/lib/python3.6/queue.py\", line 173, in get\n",
      "    self.not_empty.wait(remaining)\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 299, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 5720) is killed by signal: Segmentation fault. \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 155, in <module>\n",
      "    train(epoch)\n",
      "  File \"train.py\", line 90, in train\n",
      "    data_tri_list = next(triplet_loader_iter)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 841, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 798, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 774, in _try_get_data\n",
      "    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str))\n",
      "RuntimeError: DataLoader worker (pid(s) 5720) exited unexpectedly\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g5b-KDF5GUd7",
    "colab_type": "code",
    "outputId": "40ecd8a2-32bd-46e0-bb17-ff2429062648",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1584699253819,
     "user_tz": -300,
     "elapsed": 64469,
     "user": {
      "displayName": "Muhammad Ali",
      "photoUrl": "",
      "userId": "15673831022739340207"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# From scratch. Freeze=True (2). LR=0.01\n",
    "# model_5_500.pth.tar trained for 4.16 epochs. Stable at 58% accuracy and loss around 1.6 but loss was still going down slightly\n",
    "! python train.py"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:220: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:704: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  \"please use transforms.RandomResizedCrop instead.\")\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
      "100% 97.8M/97.8M [00:00<00:00, 168MB/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "train.py:132: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "\n",
      "Test set: Average loss: 3.4765, Accuracy: 45/960 (5%)\n",
      "\n",
      "Train Epoch: 1 [0/110534 (0%)]\tAll Loss: 4.3483\tTriple Loss(1): 0.5163\tClassification Loss: 3.3158\n",
      "Train Epoch: 1 [320/110534 (0%)]\tAll Loss: 4.3431\tTriple Loss(1): 0.6884\tClassification Loss: 2.9662\n",
      "Train Epoch: 1 [640/110534 (1%)]\tAll Loss: 5.8130\tTriple Loss(0): 1.5165\tClassification Loss: 2.7800\n",
      "Train Epoch: 1 [960/110534 (1%)]\tAll Loss: 3.2336\tTriple Loss(1): 0.2471\tClassification Loss: 2.7393\n",
      "Train Epoch: 1 [1280/110534 (1%)]\tAll Loss: 2.7347\tTriple Loss(0): 0.0000\tClassification Loss: 2.7347\n",
      "Train Epoch: 1 [1600/110534 (1%)]\tAll Loss: 2.5127\tTriple Loss(0): 0.0000\tClassification Loss: 2.5127\n",
      "Train Epoch: 1 [1920/110534 (2%)]\tAll Loss: 3.7189\tTriple Loss(1): 0.5633\tClassification Loss: 2.5924\n",
      "Train Epoch: 1 [2240/110534 (2%)]\tAll Loss: 3.3676\tTriple Loss(1): 0.4493\tClassification Loss: 2.4691\n",
      "Train Epoch: 1 [2560/110534 (2%)]\tAll Loss: 3.1038\tTriple Loss(1): 0.3192\tClassification Loss: 2.4655\n",
      "Train Epoch: 1 [2880/110534 (3%)]\tAll Loss: 2.9974\tTriple Loss(1): 0.2652\tClassification Loss: 2.4670\n",
      "\n",
      "Test set: Average loss: 2.5878, Accuracy: 239/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [3200/110534 (3%)]\tAll Loss: 3.7002\tTriple Loss(1): 0.5625\tClassification Loss: 2.5753\n",
      "Train Epoch: 1 [3520/110534 (3%)]\tAll Loss: 2.1138\tTriple Loss(0): 0.0000\tClassification Loss: 2.1138\n",
      "Train Epoch: 1 [3840/110534 (3%)]\tAll Loss: 3.3530\tTriple Loss(1): 0.4862\tClassification Loss: 2.3806\n",
      "Train Epoch: 1 [4160/110534 (4%)]\tAll Loss: 3.3885\tTriple Loss(1): 0.4694\tClassification Loss: 2.4498\n",
      "Train Epoch: 1 [4480/110534 (4%)]\tAll Loss: 3.1319\tTriple Loss(1): 0.3365\tClassification Loss: 2.4590\n",
      "Train Epoch: 1 [4800/110534 (4%)]\tAll Loss: 3.2836\tTriple Loss(1): 0.4319\tClassification Loss: 2.4199\n",
      "Train Epoch: 1 [5120/110534 (5%)]\tAll Loss: 3.4411\tTriple Loss(1): 0.5314\tClassification Loss: 2.3783\n",
      "Train Epoch: 1 [5440/110534 (5%)]\tAll Loss: 2.4496\tTriple Loss(0): 0.0000\tClassification Loss: 2.4496\n",
      "Train Epoch: 1 [5760/110534 (5%)]\tAll Loss: 3.2715\tTriple Loss(1): 0.5521\tClassification Loss: 2.1672\n",
      "Train Epoch: 1 [6080/110534 (5%)]\tAll Loss: 3.2655\tTriple Loss(1): 0.4961\tClassification Loss: 2.2734\n",
      "\n",
      "Test set: Average loss: 2.4070, Accuracy: 293/960 (31%)\n",
      "\n",
      "Train Epoch: 1 [6400/110534 (6%)]\tAll Loss: 3.4184\tTriple Loss(1): 0.4781\tClassification Loss: 2.4621\n",
      "Train Epoch: 1 [6720/110534 (6%)]\tAll Loss: 3.3485\tTriple Loss(1): 0.4487\tClassification Loss: 2.4512\n",
      "Train Epoch: 1 [7040/110534 (6%)]\tAll Loss: 3.9483\tTriple Loss(1): 0.7355\tClassification Loss: 2.4773\n",
      "Train Epoch: 1 [7360/110534 (7%)]\tAll Loss: 2.8470\tTriple Loss(1): 0.4186\tClassification Loss: 2.0097\n",
      "Train Epoch: 1 [7680/110534 (7%)]\tAll Loss: 3.0134\tTriple Loss(1): 0.4657\tClassification Loss: 2.0820\n",
      "Train Epoch: 1 [8000/110534 (7%)]\tAll Loss: 1.9897\tTriple Loss(0): 0.0000\tClassification Loss: 1.9897\n",
      "Train Epoch: 1 [8320/110534 (8%)]\tAll Loss: 2.1861\tTriple Loss(0): 0.0000\tClassification Loss: 2.1861\n",
      "Train Epoch: 1 [8640/110534 (8%)]\tAll Loss: 2.0087\tTriple Loss(0): 0.0000\tClassification Loss: 2.0087\n",
      "Train Epoch: 1 [8960/110534 (8%)]\tAll Loss: 2.9460\tTriple Loss(1): 0.4324\tClassification Loss: 2.0813\n",
      "Train Epoch: 1 [9280/110534 (8%)]\tAll Loss: 3.2819\tTriple Loss(1): 0.6515\tClassification Loss: 1.9788\n",
      "\n",
      "Test set: Average loss: 2.2947, Accuracy: 356/960 (37%)\n",
      "\n",
      "Train Epoch: 1 [9600/110534 (9%)]\tAll Loss: 2.3249\tTriple Loss(0): 0.0000\tClassification Loss: 2.3249\n",
      "Train Epoch: 1 [9920/110534 (9%)]\tAll Loss: 2.9201\tTriple Loss(1): 0.3725\tClassification Loss: 2.1750\n",
      "Train Epoch: 1 [10240/110534 (9%)]\tAll Loss: 2.2955\tTriple Loss(0): 0.0000\tClassification Loss: 2.2955\n",
      "Train Epoch: 1 [10560/110534 (10%)]\tAll Loss: 4.7827\tTriple Loss(0): 1.2674\tClassification Loss: 2.2480\n",
      "Train Epoch: 1 [10880/110534 (10%)]\tAll Loss: 2.4254\tTriple Loss(0): 0.0000\tClassification Loss: 2.4254\n",
      "Train Epoch: 1 [11200/110534 (10%)]\tAll Loss: 2.4969\tTriple Loss(1): 0.3294\tClassification Loss: 1.8382\n",
      "Train Epoch: 1 [11520/110534 (10%)]\tAll Loss: 2.8650\tTriple Loss(1): 0.3630\tClassification Loss: 2.1389\n",
      "Train Epoch: 1 [11840/110534 (11%)]\tAll Loss: 2.5245\tTriple Loss(1): 0.2584\tClassification Loss: 2.0077\n",
      "Train Epoch: 1 [12160/110534 (11%)]\tAll Loss: 2.3520\tTriple Loss(0): 0.0000\tClassification Loss: 2.3520\n",
      "Train Epoch: 1 [12480/110534 (11%)]\tAll Loss: 2.9566\tTriple Loss(1): 0.4006\tClassification Loss: 2.1554\n",
      "\n",
      "Test set: Average loss: 2.2093, Accuracy: 353/960 (37%)\n",
      "\n",
      "Train Epoch: 1 [12800/110534 (12%)]\tAll Loss: 2.8315\tTriple Loss(1): 0.3449\tClassification Loss: 2.1417\n",
      "Train Epoch: 1 [13120/110534 (12%)]\tAll Loss: 2.6978\tTriple Loss(1): 0.4072\tClassification Loss: 1.8835\n",
      "Train Epoch: 1 [13440/110534 (12%)]\tAll Loss: 3.2743\tTriple Loss(1): 0.4901\tClassification Loss: 2.2942\n",
      "Train Epoch: 1 [13760/110534 (12%)]\tAll Loss: 2.9040\tTriple Loss(1): 0.3723\tClassification Loss: 2.1593\n",
      "Train Epoch: 1 [14080/110534 (13%)]\tAll Loss: 2.4449\tTriple Loss(1): 0.1961\tClassification Loss: 2.0528\n",
      "Train Epoch: 1 [14400/110534 (13%)]\tAll Loss: 3.0787\tTriple Loss(1): 0.3534\tClassification Loss: 2.3719\n",
      "Train Epoch: 1 [14720/110534 (13%)]\tAll Loss: 2.5468\tTriple Loss(1): 0.1878\tClassification Loss: 2.1712\n",
      "Train Epoch: 1 [15040/110534 (14%)]\tAll Loss: 2.8062\tTriple Loss(1): 0.4043\tClassification Loss: 1.9977\n",
      "Train Epoch: 1 [15360/110534 (14%)]\tAll Loss: 3.1750\tTriple Loss(1): 0.6566\tClassification Loss: 1.8619\n",
      "Train Epoch: 1 [15680/110534 (14%)]\tAll Loss: 1.9020\tTriple Loss(0): 0.0000\tClassification Loss: 1.9020\n",
      "\n",
      "Test set: Average loss: 2.1455, Accuracy: 414/960 (43%)\n",
      "\n",
      "Train Epoch: 1 [16000/110534 (14%)]\tAll Loss: 3.3954\tTriple Loss(1): 0.6302\tClassification Loss: 2.1351\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_500.pth.tar\n",
      "Train Epoch: 1 [16320/110534 (15%)]\tAll Loss: 1.8333\tTriple Loss(0): 0.0000\tClassification Loss: 1.8333\n",
      "Train Epoch: 1 [16640/110534 (15%)]\tAll Loss: 3.3811\tTriple Loss(1): 0.6631\tClassification Loss: 2.0548\n",
      "Train Epoch: 1 [16960/110534 (15%)]\tAll Loss: 2.9412\tTriple Loss(1): 0.3009\tClassification Loss: 2.3394\n",
      "Train Epoch: 1 [17280/110534 (16%)]\tAll Loss: 2.6089\tTriple Loss(1): 0.3809\tClassification Loss: 1.8472\n",
      "Train Epoch: 1 [17600/110534 (16%)]\tAll Loss: 2.7778\tTriple Loss(1): 0.3351\tClassification Loss: 2.1077\n",
      "Train Epoch: 1 [17920/110534 (16%)]\tAll Loss: 3.1198\tTriple Loss(1): 0.5424\tClassification Loss: 2.0351\n",
      "Train Epoch: 1 [18240/110534 (16%)]\tAll Loss: 3.1858\tTriple Loss(1): 0.5191\tClassification Loss: 2.1476\n",
      "Train Epoch: 1 [18560/110534 (17%)]\tAll Loss: 2.7241\tTriple Loss(1): 0.3870\tClassification Loss: 1.9502\n",
      "Train Epoch: 1 [18880/110534 (17%)]\tAll Loss: 2.1246\tTriple Loss(0): 0.0000\tClassification Loss: 2.1246\n",
      "\n",
      "Test set: Average loss: 2.0926, Accuracy: 451/960 (47%)\n",
      "\n",
      "Train Epoch: 1 [19200/110534 (17%)]\tAll Loss: 2.9398\tTriple Loss(1): 0.5479\tClassification Loss: 1.8440\n",
      "Train Epoch: 1 [19520/110534 (18%)]\tAll Loss: 3.1365\tTriple Loss(1): 0.4846\tClassification Loss: 2.1672\n",
      "Train Epoch: 1 [19840/110534 (18%)]\tAll Loss: 2.7402\tTriple Loss(1): 0.3493\tClassification Loss: 2.0415\n",
      "Train Epoch: 1 [20160/110534 (18%)]\tAll Loss: 2.4842\tTriple Loss(1): 0.2579\tClassification Loss: 1.9684\n",
      "Train Epoch: 1 [20480/110534 (19%)]\tAll Loss: 2.9076\tTriple Loss(1): 0.5844\tClassification Loss: 1.7389\n",
      "Train Epoch: 1 [20800/110534 (19%)]\tAll Loss: 2.3740\tTriple Loss(0): 0.0000\tClassification Loss: 2.3740\n",
      "Train Epoch: 1 [21120/110534 (19%)]\tAll Loss: 2.5532\tTriple Loss(1): 0.3270\tClassification Loss: 1.8992\n",
      "Train Epoch: 1 [21440/110534 (19%)]\tAll Loss: 2.9301\tTriple Loss(1): 0.4902\tClassification Loss: 1.9498\n",
      "Train Epoch: 1 [21760/110534 (20%)]\tAll Loss: 2.9281\tTriple Loss(1): 0.4011\tClassification Loss: 2.1259\n",
      "Train Epoch: 1 [22080/110534 (20%)]\tAll Loss: 2.1255\tTriple Loss(0): 0.0000\tClassification Loss: 2.1255\n",
      "\n",
      "Test set: Average loss: 2.0552, Accuracy: 442/960 (46%)\n",
      "\n",
      "Train Epoch: 1 [22400/110534 (20%)]\tAll Loss: 2.4062\tTriple Loss(1): 0.3059\tClassification Loss: 1.7944\n",
      "Train Epoch: 1 [22720/110534 (21%)]\tAll Loss: 2.0716\tTriple Loss(0): 0.0000\tClassification Loss: 2.0716\n",
      "Train Epoch: 1 [23040/110534 (21%)]\tAll Loss: 2.6025\tTriple Loss(1): 0.3060\tClassification Loss: 1.9905\n",
      "Train Epoch: 1 [23360/110534 (21%)]\tAll Loss: 2.9490\tTriple Loss(1): 0.4043\tClassification Loss: 2.1405\n",
      "Train Epoch: 1 [23680/110534 (21%)]\tAll Loss: 3.5304\tTriple Loss(1): 0.6128\tClassification Loss: 2.3049\n",
      "Train Epoch: 1 [24000/110534 (22%)]\tAll Loss: 2.7842\tTriple Loss(1): 0.4443\tClassification Loss: 1.8957\n",
      "Train Epoch: 1 [24320/110534 (22%)]\tAll Loss: 2.9956\tTriple Loss(1): 0.4409\tClassification Loss: 2.1139\n",
      "Train Epoch: 1 [24640/110534 (22%)]\tAll Loss: 3.2313\tTriple Loss(1): 0.5145\tClassification Loss: 2.2024\n",
      "Train Epoch: 1 [24960/110534 (23%)]\tAll Loss: 2.6267\tTriple Loss(1): 0.3616\tClassification Loss: 1.9035\n",
      "Train Epoch: 1 [25280/110534 (23%)]\tAll Loss: 2.5326\tTriple Loss(1): 0.2467\tClassification Loss: 2.0391\n",
      "\n",
      "Test set: Average loss: 2.0189, Accuracy: 445/960 (46%)\n",
      "\n",
      "Train Epoch: 1 [25600/110534 (23%)]\tAll Loss: 2.8240\tTriple Loss(1): 0.3765\tClassification Loss: 2.0709\n",
      "Train Epoch: 1 [25920/110534 (23%)]\tAll Loss: 2.7654\tTriple Loss(1): 0.2802\tClassification Loss: 2.2051\n",
      "Train Epoch: 1 [26240/110534 (24%)]\tAll Loss: 2.6757\tTriple Loss(1): 0.4651\tClassification Loss: 1.7454\n",
      "Train Epoch: 1 [26560/110534 (24%)]\tAll Loss: 2.7239\tTriple Loss(1): 0.2846\tClassification Loss: 2.1547\n",
      "Train Epoch: 1 [26880/110534 (24%)]\tAll Loss: 2.8952\tTriple Loss(1): 0.3654\tClassification Loss: 2.1643\n",
      "Train Epoch: 1 [27200/110534 (25%)]\tAll Loss: 2.5882\tTriple Loss(1): 0.2133\tClassification Loss: 2.1617\n",
      "Train Epoch: 1 [27520/110534 (25%)]\tAll Loss: 2.9765\tTriple Loss(1): 0.4522\tClassification Loss: 2.0720\n",
      "Train Epoch: 1 [27840/110534 (25%)]\tAll Loss: 2.6444\tTriple Loss(1): 0.4858\tClassification Loss: 1.6727\n",
      "Train Epoch: 1 [28160/110534 (25%)]\tAll Loss: 2.1910\tTriple Loss(0): 0.0000\tClassification Loss: 2.1910\n",
      "Train Epoch: 1 [28480/110534 (26%)]\tAll Loss: 2.6191\tTriple Loss(1): 0.2397\tClassification Loss: 2.1397\n",
      "\n",
      "Test set: Average loss: 1.9852, Accuracy: 464/960 (48%)\n",
      "\n",
      "Train Epoch: 1 [28800/110534 (26%)]\tAll Loss: 2.8718\tTriple Loss(1): 0.5096\tClassification Loss: 1.8527\n",
      "Train Epoch: 1 [29120/110534 (26%)]\tAll Loss: 1.9934\tTriple Loss(0): 0.0000\tClassification Loss: 1.9934\n",
      "Train Epoch: 1 [29440/110534 (27%)]\tAll Loss: 1.8415\tTriple Loss(0): 0.0000\tClassification Loss: 1.8415\n",
      "Train Epoch: 1 [29760/110534 (27%)]\tAll Loss: 2.8349\tTriple Loss(1): 0.5418\tClassification Loss: 1.7513\n",
      "Train Epoch: 1 [30080/110534 (27%)]\tAll Loss: 2.8767\tTriple Loss(1): 0.5367\tClassification Loss: 1.8032\n",
      "Train Epoch: 1 [30400/110534 (27%)]\tAll Loss: 1.8885\tTriple Loss(0): 0.0000\tClassification Loss: 1.8885\n",
      "Train Epoch: 1 [30720/110534 (28%)]\tAll Loss: 2.3419\tTriple Loss(1): 0.3519\tClassification Loss: 1.6381\n",
      "Train Epoch: 1 [31040/110534 (28%)]\tAll Loss: 2.0692\tTriple Loss(0): 0.0000\tClassification Loss: 2.0692\n",
      "Train Epoch: 1 [31360/110534 (28%)]\tAll Loss: 2.4971\tTriple Loss(1): 0.1483\tClassification Loss: 2.2005\n",
      "Train Epoch: 1 [31680/110534 (29%)]\tAll Loss: 2.8840\tTriple Loss(1): 0.5302\tClassification Loss: 1.8236\n",
      "\n",
      "Test set: Average loss: 1.9634, Accuracy: 495/960 (52%)\n",
      "\n",
      "Train Epoch: 1 [32000/110534 (29%)]\tAll Loss: 2.7454\tTriple Loss(1): 0.3377\tClassification Loss: 2.0701\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_1000.pth.tar\n",
      "Train Epoch: 1 [32320/110534 (29%)]\tAll Loss: 2.7000\tTriple Loss(1): 0.4641\tClassification Loss: 1.7718\n",
      "Train Epoch: 1 [32640/110534 (30%)]\tAll Loss: 2.9430\tTriple Loss(1): 0.4569\tClassification Loss: 2.0292\n",
      "Train Epoch: 1 [32960/110534 (30%)]\tAll Loss: 2.1577\tTriple Loss(0): 0.0000\tClassification Loss: 2.1577\n",
      "Train Epoch: 1 [33280/110534 (30%)]\tAll Loss: 2.9199\tTriple Loss(1): 0.4382\tClassification Loss: 2.0434\n",
      "Train Epoch: 1 [33600/110534 (30%)]\tAll Loss: 2.3569\tTriple Loss(1): 0.2624\tClassification Loss: 1.8322\n",
      "Train Epoch: 1 [33920/110534 (31%)]\tAll Loss: 2.4958\tTriple Loss(1): 0.3111\tClassification Loss: 1.8736\n",
      "Train Epoch: 1 [34240/110534 (31%)]\tAll Loss: 2.3389\tTriple Loss(1): 0.1821\tClassification Loss: 1.9747\n",
      "Train Epoch: 1 [34560/110534 (31%)]\tAll Loss: 2.2353\tTriple Loss(1): 0.2653\tClassification Loss: 1.7047\n",
      "Train Epoch: 1 [34880/110534 (32%)]\tAll Loss: 2.4089\tTriple Loss(1): 0.2764\tClassification Loss: 1.8561\n",
      "\n",
      "Test set: Average loss: 1.9388, Accuracy: 509/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [35200/110534 (32%)]\tAll Loss: 3.0277\tTriple Loss(1): 0.4425\tClassification Loss: 2.1426\n",
      "Train Epoch: 1 [35520/110534 (32%)]\tAll Loss: 2.5437\tTriple Loss(1): 0.3404\tClassification Loss: 1.8630\n",
      "Train Epoch: 1 [35840/110534 (32%)]\tAll Loss: 2.4272\tTriple Loss(1): 0.3055\tClassification Loss: 1.8162\n",
      "Train Epoch: 1 [36160/110534 (33%)]\tAll Loss: 1.7582\tTriple Loss(0): 0.0000\tClassification Loss: 1.7582\n",
      "Train Epoch: 1 [36480/110534 (33%)]\tAll Loss: 2.0010\tTriple Loss(0): 0.0000\tClassification Loss: 2.0010\n",
      "Train Epoch: 1 [36800/110534 (33%)]\tAll Loss: 2.5182\tTriple Loss(1): 0.3421\tClassification Loss: 1.8340\n",
      "Train Epoch: 1 [37120/110534 (34%)]\tAll Loss: 2.0998\tTriple Loss(0): 0.0000\tClassification Loss: 2.0998\n",
      "Train Epoch: 1 [37440/110534 (34%)]\tAll Loss: 2.1519\tTriple Loss(0): 0.0000\tClassification Loss: 2.1519\n",
      "Train Epoch: 1 [37760/110534 (34%)]\tAll Loss: 2.2487\tTriple Loss(1): 0.2287\tClassification Loss: 1.7913\n",
      "Train Epoch: 1 [38080/110534 (34%)]\tAll Loss: 2.7475\tTriple Loss(1): 0.3595\tClassification Loss: 2.0285\n",
      "\n",
      "Test set: Average loss: 1.9134, Accuracy: 506/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [38400/110534 (35%)]\tAll Loss: 2.1651\tTriple Loss(1): 0.2237\tClassification Loss: 1.7178\n",
      "Train Epoch: 1 [38720/110534 (35%)]\tAll Loss: 2.3181\tTriple Loss(1): 0.2214\tClassification Loss: 1.8752\n",
      "Train Epoch: 1 [39040/110534 (35%)]\tAll Loss: 1.7000\tTriple Loss(0): 0.0000\tClassification Loss: 1.7000\n",
      "Train Epoch: 1 [39360/110534 (36%)]\tAll Loss: 2.3534\tTriple Loss(1): 0.3298\tClassification Loss: 1.6938\n",
      "Train Epoch: 1 [39680/110534 (36%)]\tAll Loss: 2.1633\tTriple Loss(0): 0.0000\tClassification Loss: 2.1633\n",
      "Train Epoch: 1 [40000/110534 (36%)]\tAll Loss: 2.1082\tTriple Loss(1): 0.3570\tClassification Loss: 1.3942\n",
      "Train Epoch: 1 [40320/110534 (36%)]\tAll Loss: 1.9464\tTriple Loss(0): 0.0000\tClassification Loss: 1.9464\n",
      "Train Epoch: 1 [40640/110534 (37%)]\tAll Loss: 2.4581\tTriple Loss(1): 0.2881\tClassification Loss: 1.8819\n",
      "Train Epoch: 1 [40960/110534 (37%)]\tAll Loss: 2.4596\tTriple Loss(1): 0.3763\tClassification Loss: 1.7070\n",
      "Train Epoch: 1 [41280/110534 (37%)]\tAll Loss: 2.8360\tTriple Loss(1): 0.3933\tClassification Loss: 2.0495\n",
      "\n",
      "Test set: Average loss: 1.8913, Accuracy: 501/960 (52%)\n",
      "\n",
      "Train Epoch: 1 [41600/110534 (38%)]\tAll Loss: 2.6485\tTriple Loss(1): 0.2794\tClassification Loss: 2.0896\n",
      "Train Epoch: 1 [41920/110534 (38%)]\tAll Loss: 1.8013\tTriple Loss(0): 0.0000\tClassification Loss: 1.8013\n",
      "Train Epoch: 1 [42240/110534 (38%)]\tAll Loss: 2.3413\tTriple Loss(1): 0.2126\tClassification Loss: 1.9160\n",
      "Train Epoch: 1 [42560/110534 (38%)]\tAll Loss: 2.4925\tTriple Loss(1): 0.3506\tClassification Loss: 1.7913\n",
      "Train Epoch: 1 [42880/110534 (39%)]\tAll Loss: 2.5602\tTriple Loss(1): 0.3528\tClassification Loss: 1.8546\n",
      "Train Epoch: 1 [43200/110534 (39%)]\tAll Loss: 2.9310\tTriple Loss(1): 0.4195\tClassification Loss: 2.0920\n",
      "Train Epoch: 1 [43520/110534 (39%)]\tAll Loss: 2.2854\tTriple Loss(1): 0.2855\tClassification Loss: 1.7144\n",
      "Train Epoch: 1 [43840/110534 (40%)]\tAll Loss: 2.2022\tTriple Loss(1): 0.2600\tClassification Loss: 1.6823\n",
      "Train Epoch: 1 [44160/110534 (40%)]\tAll Loss: 2.6150\tTriple Loss(1): 0.2260\tClassification Loss: 2.1630\n",
      "Train Epoch: 1 [44480/110534 (40%)]\tAll Loss: 2.5634\tTriple Loss(1): 0.2866\tClassification Loss: 1.9902\n",
      "\n",
      "Test set: Average loss: 1.8762, Accuracy: 507/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [44800/110534 (41%)]\tAll Loss: 2.0189\tTriple Loss(1): 0.2534\tClassification Loss: 1.5121\n",
      "Train Epoch: 1 [45120/110534 (41%)]\tAll Loss: 2.7420\tTriple Loss(1): 0.4076\tClassification Loss: 1.9269\n",
      "Train Epoch: 1 [45440/110534 (41%)]\tAll Loss: 2.1491\tTriple Loss(1): 0.1709\tClassification Loss: 1.8072\n",
      "Train Epoch: 1 [45760/110534 (41%)]\tAll Loss: 2.4320\tTriple Loss(1): 0.4516\tClassification Loss: 1.5288\n",
      "Train Epoch: 1 [46080/110534 (42%)]\tAll Loss: 1.5956\tTriple Loss(0): 0.0000\tClassification Loss: 1.5956\n",
      "Train Epoch: 1 [46400/110534 (42%)]\tAll Loss: 2.4420\tTriple Loss(1): 0.1715\tClassification Loss: 2.0991\n",
      "Train Epoch: 1 [46720/110534 (42%)]\tAll Loss: 2.8519\tTriple Loss(1): 0.4245\tClassification Loss: 2.0029\n",
      "Train Epoch: 1 [47040/110534 (43%)]\tAll Loss: 2.5904\tTriple Loss(1): 0.3942\tClassification Loss: 1.8020\n",
      "Train Epoch: 1 [47360/110534 (43%)]\tAll Loss: 2.6433\tTriple Loss(1): 0.3151\tClassification Loss: 2.0130\n",
      "Train Epoch: 1 [47680/110534 (43%)]\tAll Loss: 1.6539\tTriple Loss(1): 0.0781\tClassification Loss: 1.4976\n",
      "\n",
      "Test set: Average loss: 1.8631, Accuracy: 505/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [48000/110534 (43%)]\tAll Loss: 3.2785\tTriple Loss(1): 0.5653\tClassification Loss: 2.1478\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_1500.pth.tar\n",
      "Train Epoch: 1 [48320/110534 (44%)]\tAll Loss: 1.8732\tTriple Loss(0): 0.0000\tClassification Loss: 1.8732\n",
      "Train Epoch: 1 [48640/110534 (44%)]\tAll Loss: 2.5874\tTriple Loss(1): 0.2613\tClassification Loss: 2.0649\n",
      "Train Epoch: 1 [48960/110534 (44%)]\tAll Loss: 2.1897\tTriple Loss(1): 0.2048\tClassification Loss: 1.7800\n",
      "Train Epoch: 1 [49280/110534 (45%)]\tAll Loss: 2.7718\tTriple Loss(1): 0.4770\tClassification Loss: 1.8178\n",
      "Train Epoch: 1 [49600/110534 (45%)]\tAll Loss: 2.2213\tTriple Loss(1): 0.1181\tClassification Loss: 1.9852\n",
      "Train Epoch: 1 [49920/110534 (45%)]\tAll Loss: 2.5682\tTriple Loss(1): 0.4894\tClassification Loss: 1.5893\n",
      "Train Epoch: 1 [50240/110534 (45%)]\tAll Loss: 2.1994\tTriple Loss(1): 0.3703\tClassification Loss: 1.4588\n",
      "Train Epoch: 1 [50560/110534 (46%)]\tAll Loss: 2.9597\tTriple Loss(1): 0.4937\tClassification Loss: 1.9723\n",
      "Train Epoch: 1 [50880/110534 (46%)]\tAll Loss: 2.4249\tTriple Loss(1): 0.3435\tClassification Loss: 1.7379\n",
      "\n",
      "Test set: Average loss: 1.8459, Accuracy: 514/960 (54%)\n",
      "\n",
      "Train Epoch: 1 [51200/110534 (46%)]\tAll Loss: 2.6998\tTriple Loss(1): 0.4711\tClassification Loss: 1.7577\n",
      "Train Epoch: 1 [51520/110534 (47%)]\tAll Loss: 2.5335\tTriple Loss(1): 0.4784\tClassification Loss: 1.5767\n",
      "Train Epoch: 1 [51840/110534 (47%)]\tAll Loss: 2.4529\tTriple Loss(1): 0.3118\tClassification Loss: 1.8293\n",
      "Train Epoch: 1 [52160/110534 (47%)]\tAll Loss: 1.8344\tTriple Loss(0): 0.0000\tClassification Loss: 1.8344\n",
      "Train Epoch: 1 [52480/110534 (47%)]\tAll Loss: 2.6516\tTriple Loss(1): 0.1587\tClassification Loss: 2.3342\n",
      "Train Epoch: 1 [52800/110534 (48%)]\tAll Loss: 1.7014\tTriple Loss(0): 0.0000\tClassification Loss: 1.7014\n",
      "Train Epoch: 1 [53120/110534 (48%)]\tAll Loss: 1.7610\tTriple Loss(0): 0.0000\tClassification Loss: 1.7610\n",
      "Train Epoch: 1 [53440/110534 (48%)]\tAll Loss: 2.1598\tTriple Loss(1): 0.1105\tClassification Loss: 1.9388\n",
      "Train Epoch: 1 [53760/110534 (49%)]\tAll Loss: 2.5967\tTriple Loss(1): 0.3039\tClassification Loss: 1.9889\n",
      "Train Epoch: 1 [54080/110534 (49%)]\tAll Loss: 2.7736\tTriple Loss(1): 0.4240\tClassification Loss: 1.9255\n",
      "\n",
      "Test set: Average loss: 1.8410, Accuracy: 508/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [54400/110534 (49%)]\tAll Loss: 2.8189\tTriple Loss(1): 0.4549\tClassification Loss: 1.9091\n",
      "Train Epoch: 1 [54720/110534 (49%)]\tAll Loss: 2.6048\tTriple Loss(1): 0.3069\tClassification Loss: 1.9909\n",
      "Train Epoch: 1 [55040/110534 (50%)]\tAll Loss: 2.5006\tTriple Loss(1): 0.1884\tClassification Loss: 2.1238\n",
      "Train Epoch: 1 [55360/110534 (50%)]\tAll Loss: 1.9566\tTriple Loss(1): 0.1422\tClassification Loss: 1.6722\n",
      "Train Epoch: 1 [55680/110534 (50%)]\tAll Loss: 2.2964\tTriple Loss(1): 0.1742\tClassification Loss: 1.9481\n",
      "Train Epoch: 1 [56000/110534 (51%)]\tAll Loss: 3.4284\tTriple Loss(1): 0.5743\tClassification Loss: 2.2799\n",
      "Train Epoch: 1 [56320/110534 (51%)]\tAll Loss: 2.3117\tTriple Loss(1): 0.1571\tClassification Loss: 1.9976\n",
      "Train Epoch: 1 [56640/110534 (51%)]\tAll Loss: 2.4158\tTriple Loss(1): 0.5048\tClassification Loss: 1.4063\n",
      "Train Epoch: 1 [56960/110534 (52%)]\tAll Loss: 2.8628\tTriple Loss(1): 0.5304\tClassification Loss: 1.8021\n",
      "Train Epoch: 1 [57280/110534 (52%)]\tAll Loss: 3.0746\tTriple Loss(1): 0.5206\tClassification Loss: 2.0335\n",
      "\n",
      "Test set: Average loss: 1.8273, Accuracy: 521/960 (54%)\n",
      "\n",
      "Train Epoch: 1 [57600/110534 (52%)]\tAll Loss: 2.3462\tTriple Loss(1): 0.1881\tClassification Loss: 1.9701\n",
      "Train Epoch: 1 [57920/110534 (52%)]\tAll Loss: 2.9457\tTriple Loss(1): 0.4668\tClassification Loss: 2.0122\n",
      "Train Epoch: 1 [58240/110534 (53%)]\tAll Loss: 2.2595\tTriple Loss(1): 0.2970\tClassification Loss: 1.6654\n",
      "Train Epoch: 1 [58560/110534 (53%)]\tAll Loss: 1.8096\tTriple Loss(0): 0.0000\tClassification Loss: 1.8096\n",
      "Train Epoch: 1 [58880/110534 (53%)]\tAll Loss: 1.9453\tTriple Loss(0): 0.0000\tClassification Loss: 1.9453\n",
      "Train Epoch: 1 [59200/110534 (54%)]\tAll Loss: 2.0179\tTriple Loss(0): 0.0000\tClassification Loss: 2.0179\n",
      "Train Epoch: 1 [59520/110534 (54%)]\tAll Loss: 1.9886\tTriple Loss(1): 0.1341\tClassification Loss: 1.7204\n",
      "Train Epoch: 1 [59840/110534 (54%)]\tAll Loss: 1.6498\tTriple Loss(0): 0.0000\tClassification Loss: 1.6498\n",
      "Train Epoch: 1 [60160/110534 (54%)]\tAll Loss: 2.3359\tTriple Loss(1): 0.3142\tClassification Loss: 1.7074\n",
      "Train Epoch: 1 [60480/110534 (55%)]\tAll Loss: 1.7006\tTriple Loss(0): 0.0000\tClassification Loss: 1.7006\n",
      "\n",
      "Test set: Average loss: 1.8186, Accuracy: 516/960 (54%)\n",
      "\n",
      "Train Epoch: 1 [60800/110534 (55%)]\tAll Loss: 1.9742\tTriple Loss(0): 0.0000\tClassification Loss: 1.9742\n",
      "Train Epoch: 1 [61120/110534 (55%)]\tAll Loss: 2.8295\tTriple Loss(1): 0.4873\tClassification Loss: 1.8549\n",
      "Train Epoch: 1 [61440/110534 (56%)]\tAll Loss: 2.5856\tTriple Loss(1): 0.6225\tClassification Loss: 1.3406\n",
      "Train Epoch: 1 [61760/110534 (56%)]\tAll Loss: 2.5430\tTriple Loss(1): 0.2986\tClassification Loss: 1.9459\n",
      "Train Epoch: 1 [62080/110534 (56%)]\tAll Loss: 2.4627\tTriple Loss(1): 0.3963\tClassification Loss: 1.6701\n",
      "Train Epoch: 1 [62400/110534 (56%)]\tAll Loss: 2.0829\tTriple Loss(1): 0.1892\tClassification Loss: 1.7045\n",
      "Train Epoch: 1 [62720/110534 (57%)]\tAll Loss: 1.4925\tTriple Loss(0): 0.0000\tClassification Loss: 1.4925\n",
      "Train Epoch: 1 [63040/110534 (57%)]\tAll Loss: 2.7423\tTriple Loss(1): 0.1598\tClassification Loss: 2.4227\n",
      "Train Epoch: 1 [63360/110534 (57%)]\tAll Loss: 2.3618\tTriple Loss(1): 0.2468\tClassification Loss: 1.8681\n",
      "Train Epoch: 1 [63680/110534 (58%)]\tAll Loss: 2.3278\tTriple Loss(1): 0.4459\tClassification Loss: 1.4361\n",
      "\n",
      "Test set: Average loss: 1.8103, Accuracy: 506/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [64000/110534 (58%)]\tAll Loss: 2.8265\tTriple Loss(1): 0.3108\tClassification Loss: 2.2049\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_2000.pth.tar\n",
      "Train Epoch: 1 [64320/110534 (58%)]\tAll Loss: 1.6694\tTriple Loss(0): 0.0000\tClassification Loss: 1.6694\n",
      "Train Epoch: 1 [64640/110534 (58%)]\tAll Loss: 2.8607\tTriple Loss(1): 0.1525\tClassification Loss: 2.5558\n",
      "Train Epoch: 1 [64960/110534 (59%)]\tAll Loss: 2.3631\tTriple Loss(1): 0.3434\tClassification Loss: 1.6764\n",
      "Train Epoch: 1 [65280/110534 (59%)]\tAll Loss: 2.6446\tTriple Loss(1): 0.3635\tClassification Loss: 1.9175\n",
      "Train Epoch: 1 [65600/110534 (59%)]\tAll Loss: 4.7827\tTriple Loss(1): 1.4682\tClassification Loss: 1.8464\n",
      "Train Epoch: 1 [65920/110534 (60%)]\tAll Loss: 2.0072\tTriple Loss(1): 0.2383\tClassification Loss: 1.5306\n",
      "Train Epoch: 1 [66240/110534 (60%)]\tAll Loss: 2.4007\tTriple Loss(1): 0.3395\tClassification Loss: 1.7217\n",
      "Train Epoch: 1 [66560/110534 (60%)]\tAll Loss: 2.8311\tTriple Loss(1): 0.5403\tClassification Loss: 1.7505\n",
      "Train Epoch: 1 [66880/110534 (60%)]\tAll Loss: 2.5571\tTriple Loss(1): 0.2954\tClassification Loss: 1.9662\n",
      "\n",
      "Test set: Average loss: 1.8084, Accuracy: 507/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [67200/110534 (61%)]\tAll Loss: 2.4412\tTriple Loss(1): 0.2294\tClassification Loss: 1.9824\n",
      "Train Epoch: 1 [67520/110534 (61%)]\tAll Loss: 2.6413\tTriple Loss(1): 0.3574\tClassification Loss: 1.9264\n",
      "Train Epoch: 1 [67840/110534 (61%)]\tAll Loss: 2.9034\tTriple Loss(1): 0.4123\tClassification Loss: 2.0788\n",
      "Train Epoch: 1 [68160/110534 (62%)]\tAll Loss: 1.7608\tTriple Loss(1): 0.1701\tClassification Loss: 1.4205\n",
      "Train Epoch: 1 [68480/110534 (62%)]\tAll Loss: 2.0638\tTriple Loss(1): 0.2492\tClassification Loss: 1.5654\n",
      "Train Epoch: 1 [68800/110534 (62%)]\tAll Loss: 2.3183\tTriple Loss(1): 0.3316\tClassification Loss: 1.6551\n",
      "Train Epoch: 1 [69120/110534 (63%)]\tAll Loss: 2.3030\tTriple Loss(1): 0.2948\tClassification Loss: 1.7135\n",
      "Train Epoch: 1 [69440/110534 (63%)]\tAll Loss: 2.4529\tTriple Loss(1): 0.2853\tClassification Loss: 1.8823\n",
      "Train Epoch: 1 [69760/110534 (63%)]\tAll Loss: 2.0452\tTriple Loss(1): 0.1375\tClassification Loss: 1.7701\n",
      "Train Epoch: 1 [70080/110534 (63%)]\tAll Loss: 1.6478\tTriple Loss(1): 0.0251\tClassification Loss: 1.5975\n",
      "\n",
      "Test set: Average loss: 1.7928, Accuracy: 519/960 (54%)\n",
      "\n",
      "Train Epoch: 1 [70400/110534 (64%)]\tAll Loss: 2.3296\tTriple Loss(1): 0.3641\tClassification Loss: 1.6013\n",
      "Train Epoch: 1 [70720/110534 (64%)]\tAll Loss: 1.8982\tTriple Loss(1): 0.2154\tClassification Loss: 1.4675\n",
      "Train Epoch: 1 [71040/110534 (64%)]\tAll Loss: 2.2778\tTriple Loss(1): 0.2835\tClassification Loss: 1.7109\n",
      "Train Epoch: 1 [71360/110534 (65%)]\tAll Loss: 2.1244\tTriple Loss(1): 0.1839\tClassification Loss: 1.7567\n",
      "Train Epoch: 1 [71680/110534 (65%)]\tAll Loss: 2.4158\tTriple Loss(1): 0.2634\tClassification Loss: 1.8889\n",
      "Train Epoch: 1 [72000/110534 (65%)]\tAll Loss: 2.6531\tTriple Loss(1): 0.4082\tClassification Loss: 1.8368\n",
      "Train Epoch: 1 [72320/110534 (65%)]\tAll Loss: 2.3675\tTriple Loss(1): 0.3691\tClassification Loss: 1.6293\n",
      "Train Epoch: 1 [72640/110534 (66%)]\tAll Loss: 2.2782\tTriple Loss(1): 0.4456\tClassification Loss: 1.3870\n",
      "Train Epoch: 1 [72960/110534 (66%)]\tAll Loss: 2.0959\tTriple Loss(1): 0.2819\tClassification Loss: 1.5322\n",
      "Train Epoch: 1 [73280/110534 (66%)]\tAll Loss: 2.0327\tTriple Loss(1): 0.3087\tClassification Loss: 1.4154\n",
      "\n",
      "Test set: Average loss: 1.7856, Accuracy: 525/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [73600/110534 (67%)]\tAll Loss: 2.8245\tTriple Loss(1): 0.3028\tClassification Loss: 2.2190\n",
      "Train Epoch: 1 [73920/110534 (67%)]\tAll Loss: 2.5612\tTriple Loss(1): 0.3287\tClassification Loss: 1.9038\n",
      "Train Epoch: 1 [74240/110534 (67%)]\tAll Loss: 2.0773\tTriple Loss(1): 0.2912\tClassification Loss: 1.4949\n",
      "Train Epoch: 1 [74560/110534 (67%)]\tAll Loss: 2.9874\tTriple Loss(1): 0.3831\tClassification Loss: 2.2212\n",
      "Train Epoch: 1 [74880/110534 (68%)]\tAll Loss: 2.4087\tTriple Loss(1): 0.2402\tClassification Loss: 1.9284\n",
      "Train Epoch: 1 [75200/110534 (68%)]\tAll Loss: 2.0415\tTriple Loss(1): 0.1795\tClassification Loss: 1.6826\n",
      "Train Epoch: 1 [75520/110534 (68%)]\tAll Loss: 2.2684\tTriple Loss(1): 0.3777\tClassification Loss: 1.5129\n",
      "Train Epoch: 1 [75840/110534 (69%)]\tAll Loss: 2.3190\tTriple Loss(1): 0.2496\tClassification Loss: 1.8198\n",
      "Train Epoch: 1 [76160/110534 (69%)]\tAll Loss: 2.1836\tTriple Loss(1): 0.1938\tClassification Loss: 1.7961\n",
      "Train Epoch: 1 [76480/110534 (69%)]\tAll Loss: 2.0495\tTriple Loss(1): 0.2256\tClassification Loss: 1.5982\n",
      "\n",
      "Test set: Average loss: 1.7764, Accuracy: 532/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [76800/110534 (69%)]\tAll Loss: 1.7576\tTriple Loss(0): 0.0000\tClassification Loss: 1.7576\n",
      "Train Epoch: 1 [77120/110534 (70%)]\tAll Loss: 1.7004\tTriple Loss(0): 0.0000\tClassification Loss: 1.7004\n",
      "Train Epoch: 1 [77440/110534 (70%)]\tAll Loss: 1.7737\tTriple Loss(0): 0.0000\tClassification Loss: 1.7737\n",
      "Train Epoch: 1 [77760/110534 (70%)]\tAll Loss: 1.5699\tTriple Loss(0): 0.0000\tClassification Loss: 1.5699\n",
      "Train Epoch: 1 [78080/110534 (71%)]\tAll Loss: 2.1513\tTriple Loss(0): 0.0000\tClassification Loss: 2.1513\n",
      "Train Epoch: 1 [78400/110534 (71%)]\tAll Loss: 1.8238\tTriple Loss(0): 0.0000\tClassification Loss: 1.8238\n",
      "Train Epoch: 1 [78720/110534 (71%)]\tAll Loss: 1.9410\tTriple Loss(1): 0.2228\tClassification Loss: 1.4953\n",
      "Train Epoch: 1 [79040/110534 (71%)]\tAll Loss: 2.2730\tTriple Loss(1): 0.2462\tClassification Loss: 1.7806\n",
      "Train Epoch: 1 [79360/110534 (72%)]\tAll Loss: 2.7604\tTriple Loss(1): 0.3362\tClassification Loss: 2.0881\n",
      "Train Epoch: 1 [79680/110534 (72%)]\tAll Loss: 2.2181\tTriple Loss(1): 0.2943\tClassification Loss: 1.6295\n",
      "\n",
      "Test set: Average loss: 1.7714, Accuracy: 522/960 (54%)\n",
      "\n",
      "Train Epoch: 1 [80000/110534 (72%)]\tAll Loss: 2.3018\tTriple Loss(1): 0.2581\tClassification Loss: 1.7856\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_2500.pth.tar\n",
      "Train Epoch: 1 [80320/110534 (73%)]\tAll Loss: 1.8587\tTriple Loss(1): 0.2124\tClassification Loss: 1.4340\n",
      "Train Epoch: 1 [80640/110534 (73%)]\tAll Loss: 1.8738\tTriple Loss(1): 0.1223\tClassification Loss: 1.6291\n",
      "Train Epoch: 1 [80960/110534 (73%)]\tAll Loss: 1.6995\tTriple Loss(0): 0.0000\tClassification Loss: 1.6995\n",
      "Train Epoch: 1 [81280/110534 (74%)]\tAll Loss: 2.2450\tTriple Loss(1): 0.3222\tClassification Loss: 1.6006\n",
      "Train Epoch: 1 [81600/110534 (74%)]\tAll Loss: 1.4992\tTriple Loss(0): 0.0000\tClassification Loss: 1.4992\n",
      "Train Epoch: 1 [81920/110534 (74%)]\tAll Loss: 2.1801\tTriple Loss(1): 0.2521\tClassification Loss: 1.6758\n",
      "Train Epoch: 1 [82240/110534 (74%)]\tAll Loss: 2.8596\tTriple Loss(1): 0.5311\tClassification Loss: 1.7975\n",
      "Train Epoch: 1 [82560/110534 (75%)]\tAll Loss: 1.7594\tTriple Loss(0): 0.0000\tClassification Loss: 1.7594\n",
      "Train Epoch: 1 [82880/110534 (75%)]\tAll Loss: 1.9521\tTriple Loss(0): 0.0000\tClassification Loss: 1.9521\n",
      "\n",
      "Test set: Average loss: 1.7686, Accuracy: 524/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [83200/110534 (75%)]\tAll Loss: 2.5890\tTriple Loss(1): 0.4552\tClassification Loss: 1.6786\n",
      "Train Epoch: 1 [83520/110534 (76%)]\tAll Loss: 2.0330\tTriple Loss(1): 0.1459\tClassification Loss: 1.7413\n",
      "Train Epoch: 1 [83840/110534 (76%)]\tAll Loss: 2.1185\tTriple Loss(1): 0.2446\tClassification Loss: 1.6293\n",
      "Train Epoch: 1 [84160/110534 (76%)]\tAll Loss: 2.1832\tTriple Loss(1): 0.3422\tClassification Loss: 1.4988\n",
      "Train Epoch: 1 [84480/110534 (76%)]\tAll Loss: 1.7955\tTriple Loss(1): 0.1631\tClassification Loss: 1.4693\n",
      "Train Epoch: 1 [84800/110534 (77%)]\tAll Loss: 2.3203\tTriple Loss(1): 0.1800\tClassification Loss: 1.9603\n",
      "Train Epoch: 1 [85120/110534 (77%)]\tAll Loss: 2.3963\tTriple Loss(1): 0.4111\tClassification Loss: 1.5741\n",
      "Train Epoch: 1 [85440/110534 (77%)]\tAll Loss: 1.9818\tTriple Loss(1): 0.2462\tClassification Loss: 1.4894\n",
      "Train Epoch: 1 [85760/110534 (78%)]\tAll Loss: 2.2152\tTriple Loss(1): 0.2293\tClassification Loss: 1.7566\n",
      "Train Epoch: 1 [86080/110534 (78%)]\tAll Loss: 2.4546\tTriple Loss(1): 0.3882\tClassification Loss: 1.6782\n",
      "\n",
      "Test set: Average loss: 1.7602, Accuracy: 529/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [86400/110534 (78%)]\tAll Loss: 2.5731\tTriple Loss(1): 0.1879\tClassification Loss: 2.1973\n",
      "Train Epoch: 1 [86720/110534 (78%)]\tAll Loss: 1.9862\tTriple Loss(1): 0.2532\tClassification Loss: 1.4797\n",
      "Train Epoch: 1 [87040/110534 (79%)]\tAll Loss: 2.3193\tTriple Loss(1): 0.3745\tClassification Loss: 1.5703\n",
      "Train Epoch: 1 [87360/110534 (79%)]\tAll Loss: 2.4982\tTriple Loss(1): 0.3791\tClassification Loss: 1.7399\n",
      "Train Epoch: 1 [87680/110534 (79%)]\tAll Loss: 2.1686\tTriple Loss(1): 0.2151\tClassification Loss: 1.7384\n",
      "Train Epoch: 1 [88000/110534 (80%)]\tAll Loss: 3.0999\tTriple Loss(1): 0.3523\tClassification Loss: 2.3954\n",
      "Train Epoch: 1 [88320/110534 (80%)]\tAll Loss: 2.3341\tTriple Loss(1): 0.3855\tClassification Loss: 1.5630\n",
      "Train Epoch: 1 [88640/110534 (80%)]\tAll Loss: 3.2444\tTriple Loss(1): 0.5510\tClassification Loss: 2.1423\n",
      "Train Epoch: 1 [88960/110534 (80%)]\tAll Loss: 2.5136\tTriple Loss(1): 0.3174\tClassification Loss: 1.8788\n",
      "Train Epoch: 1 [89280/110534 (81%)]\tAll Loss: 6.7501\tTriple Loss(0): 2.5056\tClassification Loss: 1.7390\n",
      "\n",
      "Test set: Average loss: 1.7580, Accuracy: 533/960 (56%)\n",
      "\n",
      "Train Epoch: 1 [89600/110534 (81%)]\tAll Loss: 2.7892\tTriple Loss(1): 0.3187\tClassification Loss: 2.1518\n",
      "Train Epoch: 1 [89920/110534 (81%)]\tAll Loss: 2.8351\tTriple Loss(1): 0.3775\tClassification Loss: 2.0800\n",
      "Train Epoch: 1 [90240/110534 (82%)]\tAll Loss: 2.0197\tTriple Loss(1): 0.2858\tClassification Loss: 1.4481\n",
      "Train Epoch: 1 [90560/110534 (82%)]\tAll Loss: 1.7117\tTriple Loss(1): 0.1398\tClassification Loss: 1.4321\n",
      "Train Epoch: 1 [90880/110534 (82%)]\tAll Loss: 1.7422\tTriple Loss(0): 0.0000\tClassification Loss: 1.7422\n",
      "Train Epoch: 1 [91200/110534 (82%)]\tAll Loss: 2.0855\tTriple Loss(1): 0.1686\tClassification Loss: 1.7483\n",
      "Train Epoch: 1 [91520/110534 (83%)]\tAll Loss: 2.3808\tTriple Loss(1): 0.3919\tClassification Loss: 1.5970\n",
      "Train Epoch: 1 [91840/110534 (83%)]\tAll Loss: 1.7672\tTriple Loss(0): 0.0000\tClassification Loss: 1.7672\n",
      "Train Epoch: 1 [92160/110534 (83%)]\tAll Loss: 2.5439\tTriple Loss(1): 0.2743\tClassification Loss: 1.9953\n",
      "Train Epoch: 1 [92480/110534 (84%)]\tAll Loss: 2.3065\tTriple Loss(1): 0.3451\tClassification Loss: 1.6163\n",
      "\n",
      "Test set: Average loss: 1.7517, Accuracy: 532/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [92800/110534 (84%)]\tAll Loss: 1.6471\tTriple Loss(0): 0.0000\tClassification Loss: 1.6471\n",
      "Train Epoch: 1 [93120/110534 (84%)]\tAll Loss: 1.9948\tTriple Loss(0): 0.0000\tClassification Loss: 1.9948\n",
      "Train Epoch: 1 [93440/110534 (85%)]\tAll Loss: 2.1370\tTriple Loss(1): 0.1822\tClassification Loss: 1.7726\n",
      "Train Epoch: 1 [93760/110534 (85%)]\tAll Loss: 2.3059\tTriple Loss(1): 0.4311\tClassification Loss: 1.4438\n",
      "Train Epoch: 1 [94080/110534 (85%)]\tAll Loss: 2.5431\tTriple Loss(1): 0.4537\tClassification Loss: 1.6357\n",
      "Train Epoch: 1 [94400/110534 (85%)]\tAll Loss: 1.8640\tTriple Loss(1): 0.0899\tClassification Loss: 1.6843\n",
      "Train Epoch: 1 [94720/110534 (86%)]\tAll Loss: 2.0161\tTriple Loss(1): 0.1419\tClassification Loss: 1.7324\n",
      "Train Epoch: 1 [95040/110534 (86%)]\tAll Loss: 2.9017\tTriple Loss(1): 0.4830\tClassification Loss: 1.9358\n",
      "Train Epoch: 1 [95360/110534 (86%)]\tAll Loss: 2.5064\tTriple Loss(1): 0.3799\tClassification Loss: 1.7467\n",
      "Train Epoch: 1 [95680/110534 (87%)]\tAll Loss: 6.8117\tTriple Loss(0): 2.5527\tClassification Loss: 1.7063\n",
      "\n",
      "Test set: Average loss: 1.7453, Accuracy: 544/960 (57%)\n",
      "\n",
      "Train Epoch: 1 [96000/110534 (87%)]\tAll Loss: 1.4101\tTriple Loss(0): 0.0000\tClassification Loss: 1.4101\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_3000.pth.tar\n",
      "Train Epoch: 1 [96320/110534 (87%)]\tAll Loss: 1.8353\tTriple Loss(1): 0.1840\tClassification Loss: 1.4673\n",
      "Train Epoch: 1 [96640/110534 (87%)]\tAll Loss: 2.2191\tTriple Loss(1): 0.1817\tClassification Loss: 1.8557\n",
      "Train Epoch: 1 [96960/110534 (88%)]\tAll Loss: 1.3168\tTriple Loss(0): 0.0000\tClassification Loss: 1.3168\n",
      "Train Epoch: 1 [97280/110534 (88%)]\tAll Loss: 1.9920\tTriple Loss(1): 0.2517\tClassification Loss: 1.4887\n",
      "Train Epoch: 1 [97600/110534 (88%)]\tAll Loss: 2.3372\tTriple Loss(1): 0.1470\tClassification Loss: 2.0431\n",
      "Train Epoch: 1 [97920/110534 (89%)]\tAll Loss: 1.6884\tTriple Loss(1): 0.2043\tClassification Loss: 1.2799\n",
      "Train Epoch: 1 [98240/110534 (89%)]\tAll Loss: 2.0529\tTriple Loss(1): 0.3436\tClassification Loss: 1.3658\n",
      "Train Epoch: 1 [98560/110534 (89%)]\tAll Loss: 2.7592\tTriple Loss(1): 0.5253\tClassification Loss: 1.7086\n",
      "Train Epoch: 1 [98880/110534 (89%)]\tAll Loss: 2.2714\tTriple Loss(1): 0.3334\tClassification Loss: 1.6045\n",
      "\n",
      "Test set: Average loss: 1.7466, Accuracy: 531/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [99200/110534 (90%)]\tAll Loss: 1.4943\tTriple Loss(0): 0.0000\tClassification Loss: 1.4943\n",
      "Train Epoch: 1 [99520/110534 (90%)]\tAll Loss: 2.2640\tTriple Loss(1): 0.2768\tClassification Loss: 1.7104\n",
      "Train Epoch: 1 [99840/110534 (90%)]\tAll Loss: 2.4267\tTriple Loss(1): 0.3344\tClassification Loss: 1.7579\n",
      "Train Epoch: 1 [100160/110534 (91%)]\tAll Loss: 1.9971\tTriple Loss(0): 0.0000\tClassification Loss: 1.9971\n",
      "Train Epoch: 1 [100480/110534 (91%)]\tAll Loss: 2.1782\tTriple Loss(1): 0.2529\tClassification Loss: 1.6725\n",
      "Train Epoch: 1 [100800/110534 (91%)]\tAll Loss: 2.7019\tTriple Loss(1): 0.1748\tClassification Loss: 2.3522\n",
      "Train Epoch: 1 [101120/110534 (91%)]\tAll Loss: 1.4711\tTriple Loss(0): 0.0000\tClassification Loss: 1.4711\n",
      "Train Epoch: 1 [101440/110534 (92%)]\tAll Loss: 2.0412\tTriple Loss(1): 0.3027\tClassification Loss: 1.4359\n",
      "Train Epoch: 1 [101760/110534 (92%)]\tAll Loss: 1.8082\tTriple Loss(1): 0.0902\tClassification Loss: 1.6278\n",
      "Train Epoch: 1 [102080/110534 (92%)]\tAll Loss: 2.6796\tTriple Loss(1): 0.2749\tClassification Loss: 2.1299\n",
      "\n",
      "Test set: Average loss: 1.7372, Accuracy: 530/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [102400/110534 (93%)]\tAll Loss: 2.4854\tTriple Loss(1): 0.3328\tClassification Loss: 1.8197\n",
      "Train Epoch: 1 [102720/110534 (93%)]\tAll Loss: 2.5434\tTriple Loss(1): 0.3558\tClassification Loss: 1.8319\n",
      "Train Epoch: 1 [103040/110534 (93%)]\tAll Loss: 2.0624\tTriple Loss(1): 0.2261\tClassification Loss: 1.6101\n",
      "Train Epoch: 1 [103360/110534 (93%)]\tAll Loss: 2.2817\tTriple Loss(1): 0.2097\tClassification Loss: 1.8623\n",
      "Train Epoch: 1 [103680/110534 (94%)]\tAll Loss: 2.1291\tTriple Loss(1): 0.1359\tClassification Loss: 1.8572\n",
      "Train Epoch: 1 [104000/110534 (94%)]\tAll Loss: 1.6326\tTriple Loss(0): 0.0000\tClassification Loss: 1.6326\n",
      "Train Epoch: 1 [104320/110534 (94%)]\tAll Loss: 2.5769\tTriple Loss(1): 0.2595\tClassification Loss: 2.0580\n",
      "Train Epoch: 1 [104640/110534 (95%)]\tAll Loss: 1.9418\tTriple Loss(0): 0.0000\tClassification Loss: 1.9418\n",
      "Train Epoch: 1 [104960/110534 (95%)]\tAll Loss: 2.2493\tTriple Loss(1): 0.3140\tClassification Loss: 1.6213\n",
      "Train Epoch: 1 [105280/110534 (95%)]\tAll Loss: 2.4247\tTriple Loss(1): 0.3199\tClassification Loss: 1.7849\n",
      "\n",
      "Test set: Average loss: 1.7575, Accuracy: 517/960 (54%)\n",
      "\n",
      "Train Epoch: 1 [105600/110534 (96%)]\tAll Loss: 2.3755\tTriple Loss(1): 0.3085\tClassification Loss: 1.7585\n",
      "Train Epoch: 1 [105920/110534 (96%)]\tAll Loss: 2.2612\tTriple Loss(1): 0.2635\tClassification Loss: 1.7341\n",
      "Train Epoch: 1 [106240/110534 (96%)]\tAll Loss: 2.2239\tTriple Loss(1): 0.3401\tClassification Loss: 1.5436\n",
      "Train Epoch: 1 [106560/110534 (96%)]\tAll Loss: 2.0847\tTriple Loss(1): 0.2904\tClassification Loss: 1.5039\n",
      "Train Epoch: 1 [106880/110534 (97%)]\tAll Loss: 2.3152\tTriple Loss(1): 0.1991\tClassification Loss: 1.9169\n",
      "Train Epoch: 1 [107200/110534 (97%)]\tAll Loss: 2.6478\tTriple Loss(1): 0.4249\tClassification Loss: 1.7981\n",
      "Train Epoch: 1 [107520/110534 (97%)]\tAll Loss: 2.9075\tTriple Loss(1): 0.4104\tClassification Loss: 2.0868\n",
      "Train Epoch: 1 [107840/110534 (98%)]\tAll Loss: 2.3895\tTriple Loss(1): 0.4341\tClassification Loss: 1.5214\n",
      "Train Epoch: 1 [108160/110534 (98%)]\tAll Loss: 2.0814\tTriple Loss(1): 0.2965\tClassification Loss: 1.4883\n",
      "Train Epoch: 1 [108480/110534 (98%)]\tAll Loss: 2.5762\tTriple Loss(1): 0.4362\tClassification Loss: 1.7038\n",
      "\n",
      "Test set: Average loss: 1.7241, Accuracy: 535/960 (56%)\n",
      "\n",
      "Train Epoch: 1 [108800/110534 (98%)]\tAll Loss: 2.6288\tTriple Loss(1): 0.4828\tClassification Loss: 1.6632\n",
      "Train Epoch: 1 [109120/110534 (99%)]\tAll Loss: 2.3780\tTriple Loss(1): 0.3193\tClassification Loss: 1.7395\n",
      "Train Epoch: 1 [109440/110534 (99%)]\tAll Loss: 1.6101\tTriple Loss(0): 0.0000\tClassification Loss: 1.6101\n",
      "Train Epoch: 1 [109760/110534 (99%)]\tAll Loss: 2.0934\tTriple Loss(1): 0.2363\tClassification Loss: 1.6209\n",
      "Train Epoch: 1 [110080/110534 (100%)]\tAll Loss: 2.1771\tTriple Loss(1): 0.2957\tClassification Loss: 1.5857\n",
      "Train Epoch: 1 [110400/110534 (100%)]\tAll Loss: 2.1458\tTriple Loss(1): 0.2415\tClassification Loss: 1.6629\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_final.pth.tar\n",
      "\n",
      "Test set: Average loss: 1.7276, Accuracy: 535/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [0/110534 (0%)]\tAll Loss: 2.4888\tTriple Loss(1): 0.4119\tClassification Loss: 1.6651\n",
      "Train Epoch: 2 [320/110534 (0%)]\tAll Loss: 1.9379\tTriple Loss(1): 0.1140\tClassification Loss: 1.7098\n",
      "Train Epoch: 2 [640/110534 (1%)]\tAll Loss: 3.1061\tTriple Loss(0): 1.0354\tClassification Loss: 1.0353\n",
      "Train Epoch: 2 [960/110534 (1%)]\tAll Loss: 2.6403\tTriple Loss(1): 0.3697\tClassification Loss: 1.9010\n",
      "Train Epoch: 2 [1280/110534 (1%)]\tAll Loss: 2.5230\tTriple Loss(1): 0.4533\tClassification Loss: 1.6164\n",
      "Train Epoch: 2 [1600/110534 (1%)]\tAll Loss: 2.4727\tTriple Loss(1): 0.3389\tClassification Loss: 1.7949\n",
      "Train Epoch: 2 [1920/110534 (2%)]\tAll Loss: 1.8828\tTriple Loss(1): 0.0665\tClassification Loss: 1.7497\n",
      "Train Epoch: 2 [2240/110534 (2%)]\tAll Loss: 2.1663\tTriple Loss(1): 0.2365\tClassification Loss: 1.6934\n",
      "Train Epoch: 2 [2560/110534 (2%)]\tAll Loss: 1.6943\tTriple Loss(0): 0.0000\tClassification Loss: 1.6943\n",
      "Train Epoch: 2 [2880/110534 (3%)]\tAll Loss: 2.3294\tTriple Loss(1): 0.1955\tClassification Loss: 1.9384\n",
      "\n",
      "Test set: Average loss: 1.7290, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [3200/110534 (3%)]\tAll Loss: 2.8168\tTriple Loss(1): 0.2830\tClassification Loss: 2.2508\n",
      "Train Epoch: 2 [3520/110534 (3%)]\tAll Loss: 1.6901\tTriple Loss(1): 0.2318\tClassification Loss: 1.2266\n",
      "Train Epoch: 2 [3840/110534 (3%)]\tAll Loss: 2.3281\tTriple Loss(1): 0.3439\tClassification Loss: 1.6402\n",
      "Train Epoch: 2 [4160/110534 (4%)]\tAll Loss: 2.7172\tTriple Loss(1): 0.5102\tClassification Loss: 1.6969\n",
      "Train Epoch: 2 [4480/110534 (4%)]\tAll Loss: 2.1177\tTriple Loss(1): 0.3157\tClassification Loss: 1.4864\n",
      "Train Epoch: 2 [4800/110534 (4%)]\tAll Loss: 1.9950\tTriple Loss(1): 0.2141\tClassification Loss: 1.5669\n",
      "Train Epoch: 2 [5120/110534 (5%)]\tAll Loss: 2.8651\tTriple Loss(1): 0.4585\tClassification Loss: 1.9481\n",
      "Train Epoch: 2 [5440/110534 (5%)]\tAll Loss: 2.1426\tTriple Loss(1): 0.1962\tClassification Loss: 1.7502\n",
      "Train Epoch: 2 [5760/110534 (5%)]\tAll Loss: 1.9910\tTriple Loss(1): 0.2595\tClassification Loss: 1.4720\n",
      "Train Epoch: 2 [6080/110534 (5%)]\tAll Loss: 1.6211\tTriple Loss(0): 0.0000\tClassification Loss: 1.6211\n",
      "\n",
      "Test set: Average loss: 1.7271, Accuracy: 538/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [6400/110534 (6%)]\tAll Loss: 2.5488\tTriple Loss(1): 0.2871\tClassification Loss: 1.9746\n",
      "Train Epoch: 2 [6720/110534 (6%)]\tAll Loss: 2.0933\tTriple Loss(1): 0.1458\tClassification Loss: 1.8016\n",
      "Train Epoch: 2 [7040/110534 (6%)]\tAll Loss: 2.2270\tTriple Loss(1): 0.2193\tClassification Loss: 1.7884\n",
      "Train Epoch: 2 [7360/110534 (7%)]\tAll Loss: 1.7071\tTriple Loss(0): 0.0000\tClassification Loss: 1.7071\n",
      "Train Epoch: 2 [7680/110534 (7%)]\tAll Loss: 2.0665\tTriple Loss(1): 0.2850\tClassification Loss: 1.4966\n",
      "Train Epoch: 2 [8000/110534 (7%)]\tAll Loss: 1.9871\tTriple Loss(1): 0.3577\tClassification Loss: 1.2716\n",
      "Train Epoch: 2 [8320/110534 (8%)]\tAll Loss: 1.6625\tTriple Loss(0): 0.0000\tClassification Loss: 1.6625\n",
      "Train Epoch: 2 [8640/110534 (8%)]\tAll Loss: 1.9762\tTriple Loss(1): 0.2428\tClassification Loss: 1.4906\n",
      "Train Epoch: 2 [8960/110534 (8%)]\tAll Loss: 1.8285\tTriple Loss(1): 0.1404\tClassification Loss: 1.5476\n",
      "Train Epoch: 2 [9280/110534 (8%)]\tAll Loss: 5.3859\tTriple Loss(0): 1.9683\tClassification Loss: 1.4494\n",
      "\n",
      "Test set: Average loss: 1.7165, Accuracy: 544/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [9600/110534 (9%)]\tAll Loss: 2.5125\tTriple Loss(1): 0.2882\tClassification Loss: 1.9361\n",
      "Train Epoch: 2 [9920/110534 (9%)]\tAll Loss: 2.1329\tTriple Loss(1): 0.1695\tClassification Loss: 1.7939\n",
      "Train Epoch: 2 [10240/110534 (9%)]\tAll Loss: 1.8770\tTriple Loss(0): 0.0000\tClassification Loss: 1.8770\n",
      "Train Epoch: 2 [10560/110534 (10%)]\tAll Loss: 2.6242\tTriple Loss(1): 0.3769\tClassification Loss: 1.8704\n",
      "Train Epoch: 2 [10880/110534 (10%)]\tAll Loss: 2.4676\tTriple Loss(1): 0.2982\tClassification Loss: 1.8711\n",
      "Train Epoch: 2 [11200/110534 (10%)]\tAll Loss: 1.9896\tTriple Loss(1): 0.2266\tClassification Loss: 1.5365\n",
      "Train Epoch: 2 [11520/110534 (10%)]\tAll Loss: 2.1402\tTriple Loss(1): 0.2774\tClassification Loss: 1.5854\n",
      "Train Epoch: 2 [11840/110534 (11%)]\tAll Loss: 1.9730\tTriple Loss(1): 0.1723\tClassification Loss: 1.6283\n",
      "Train Epoch: 2 [12160/110534 (11%)]\tAll Loss: 2.3370\tTriple Loss(1): 0.3032\tClassification Loss: 1.7306\n",
      "Train Epoch: 2 [12480/110534 (11%)]\tAll Loss: 1.7091\tTriple Loss(0): 0.0000\tClassification Loss: 1.7091\n",
      "\n",
      "Test set: Average loss: 1.7131, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [12800/110534 (12%)]\tAll Loss: 1.8863\tTriple Loss(1): 0.1178\tClassification Loss: 1.6507\n",
      "Train Epoch: 2 [13120/110534 (12%)]\tAll Loss: 1.7322\tTriple Loss(1): 0.2247\tClassification Loss: 1.2828\n",
      "Train Epoch: 2 [13440/110534 (12%)]\tAll Loss: 1.8523\tTriple Loss(0): 0.0000\tClassification Loss: 1.8523\n",
      "Train Epoch: 2 [13760/110534 (12%)]\tAll Loss: 2.2200\tTriple Loss(1): 0.2416\tClassification Loss: 1.7368\n",
      "Train Epoch: 2 [14080/110534 (13%)]\tAll Loss: 1.5162\tTriple Loss(0): 0.0000\tClassification Loss: 1.5162\n",
      "Train Epoch: 2 [14400/110534 (13%)]\tAll Loss: 2.7163\tTriple Loss(1): 0.2974\tClassification Loss: 2.1216\n",
      "Train Epoch: 2 [14720/110534 (13%)]\tAll Loss: 1.7607\tTriple Loss(0): 0.0000\tClassification Loss: 1.7607\n",
      "Train Epoch: 2 [15040/110534 (14%)]\tAll Loss: 2.2110\tTriple Loss(0): 0.2735\tClassification Loss: 1.6640\n",
      "Train Epoch: 2 [15360/110534 (14%)]\tAll Loss: 2.1503\tTriple Loss(1): 0.2862\tClassification Loss: 1.5779\n",
      "Train Epoch: 2 [15680/110534 (14%)]\tAll Loss: 2.1043\tTriple Loss(1): 0.2909\tClassification Loss: 1.5226\n",
      "\n",
      "Test set: Average loss: 1.7034, Accuracy: 541/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [16000/110534 (14%)]\tAll Loss: 2.3310\tTriple Loss(1): 0.2466\tClassification Loss: 1.8378\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_500.pth.tar\n",
      "Train Epoch: 2 [16320/110534 (15%)]\tAll Loss: 2.0527\tTriple Loss(1): 0.3712\tClassification Loss: 1.3103\n",
      "Train Epoch: 2 [16640/110534 (15%)]\tAll Loss: 2.6672\tTriple Loss(1): 0.3718\tClassification Loss: 1.9235\n",
      "Train Epoch: 2 [16960/110534 (15%)]\tAll Loss: 2.6399\tTriple Loss(1): 0.3046\tClassification Loss: 2.0308\n",
      "Train Epoch: 2 [17280/110534 (16%)]\tAll Loss: 1.6875\tTriple Loss(1): 0.0874\tClassification Loss: 1.5126\n",
      "Train Epoch: 2 [17600/110534 (16%)]\tAll Loss: 2.4644\tTriple Loss(1): 0.4327\tClassification Loss: 1.5990\n",
      "Train Epoch: 2 [17920/110534 (16%)]\tAll Loss: 1.8505\tTriple Loss(0): 0.0000\tClassification Loss: 1.8505\n",
      "Train Epoch: 2 [18240/110534 (16%)]\tAll Loss: 2.0013\tTriple Loss(0): 0.0000\tClassification Loss: 2.0013\n",
      "Train Epoch: 2 [18560/110534 (17%)]\tAll Loss: 1.5661\tTriple Loss(0): 0.0000\tClassification Loss: 1.5661\n",
      "Train Epoch: 2 [18880/110534 (17%)]\tAll Loss: 2.3244\tTriple Loss(1): 0.3121\tClassification Loss: 1.7002\n",
      "\n",
      "Test set: Average loss: 1.7087, Accuracy: 538/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [19200/110534 (17%)]\tAll Loss: 1.9395\tTriple Loss(1): 0.2556\tClassification Loss: 1.4283\n",
      "Train Epoch: 2 [19520/110534 (18%)]\tAll Loss: 2.4110\tTriple Loss(1): 0.2813\tClassification Loss: 1.8483\n",
      "Train Epoch: 2 [19840/110534 (18%)]\tAll Loss: 2.1709\tTriple Loss(1): 0.2929\tClassification Loss: 1.5851\n",
      "Train Epoch: 2 [20160/110534 (18%)]\tAll Loss: 2.0533\tTriple Loss(1): 0.2123\tClassification Loss: 1.6286\n",
      "Train Epoch: 2 [20480/110534 (19%)]\tAll Loss: 2.1315\tTriple Loss(1): 0.2673\tClassification Loss: 1.5970\n",
      "Train Epoch: 2 [20800/110534 (19%)]\tAll Loss: 2.6052\tTriple Loss(1): 0.2684\tClassification Loss: 2.0684\n",
      "Train Epoch: 2 [21120/110534 (19%)]\tAll Loss: 1.6049\tTriple Loss(0): 0.0000\tClassification Loss: 1.6049\n",
      "Train Epoch: 2 [21440/110534 (19%)]\tAll Loss: 2.0198\tTriple Loss(1): 0.2723\tClassification Loss: 1.4751\n",
      "Train Epoch: 2 [21760/110534 (20%)]\tAll Loss: 2.1268\tTriple Loss(0): 0.0000\tClassification Loss: 2.1268\n",
      "Train Epoch: 2 [22080/110534 (20%)]\tAll Loss: 2.3836\tTriple Loss(1): 0.3423\tClassification Loss: 1.6990\n",
      "\n",
      "Test set: Average loss: 1.7116, Accuracy: 519/960 (54%)\n",
      "\n",
      "Train Epoch: 2 [22400/110534 (20%)]\tAll Loss: 2.2553\tTriple Loss(1): 0.3756\tClassification Loss: 1.5042\n",
      "Train Epoch: 2 [22720/110534 (21%)]\tAll Loss: 1.7874\tTriple Loss(0): 0.0000\tClassification Loss: 1.7874\n",
      "Train Epoch: 2 [23040/110534 (21%)]\tAll Loss: 2.2437\tTriple Loss(1): 0.2144\tClassification Loss: 1.8149\n",
      "Train Epoch: 2 [23360/110534 (21%)]\tAll Loss: 2.0689\tTriple Loss(1): 0.1629\tClassification Loss: 1.7432\n",
      "Train Epoch: 2 [23680/110534 (21%)]\tAll Loss: 2.5378\tTriple Loss(1): 0.3068\tClassification Loss: 1.9241\n",
      "Train Epoch: 2 [24000/110534 (22%)]\tAll Loss: 2.6956\tTriple Loss(1): 0.5635\tClassification Loss: 1.5685\n",
      "Train Epoch: 2 [24320/110534 (22%)]\tAll Loss: 2.0538\tTriple Loss(1): 0.1398\tClassification Loss: 1.7742\n",
      "Train Epoch: 2 [24640/110534 (22%)]\tAll Loss: 2.5665\tTriple Loss(1): 0.1888\tClassification Loss: 2.1890\n",
      "Train Epoch: 2 [24960/110534 (23%)]\tAll Loss: 1.8926\tTriple Loss(1): 0.1344\tClassification Loss: 1.6238\n",
      "Train Epoch: 2 [25280/110534 (23%)]\tAll Loss: 2.3642\tTriple Loss(1): 0.3091\tClassification Loss: 1.7461\n",
      "\n",
      "Test set: Average loss: 1.6995, Accuracy: 537/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [25600/110534 (23%)]\tAll Loss: 2.0844\tTriple Loss(1): 0.1718\tClassification Loss: 1.7408\n",
      "Train Epoch: 2 [25920/110534 (23%)]\tAll Loss: 1.8263\tTriple Loss(0): 0.0000\tClassification Loss: 1.8263\n",
      "Train Epoch: 2 [26240/110534 (24%)]\tAll Loss: 1.8329\tTriple Loss(1): 0.0921\tClassification Loss: 1.6486\n",
      "Train Epoch: 2 [26560/110534 (24%)]\tAll Loss: 2.8687\tTriple Loss(1): 0.4491\tClassification Loss: 1.9704\n",
      "Train Epoch: 2 [26880/110534 (24%)]\tAll Loss: 2.3955\tTriple Loss(1): 0.2196\tClassification Loss: 1.9563\n",
      "Train Epoch: 2 [27200/110534 (25%)]\tAll Loss: 3.0978\tTriple Loss(1): 0.5665\tClassification Loss: 1.9648\n",
      "Train Epoch: 2 [27520/110534 (25%)]\tAll Loss: 2.1992\tTriple Loss(1): 0.2747\tClassification Loss: 1.6498\n",
      "Train Epoch: 2 [27840/110534 (25%)]\tAll Loss: 2.0458\tTriple Loss(1): 0.2615\tClassification Loss: 1.5229\n",
      "Train Epoch: 2 [28160/110534 (25%)]\tAll Loss: 2.6621\tTriple Loss(1): 0.3085\tClassification Loss: 2.0452\n",
      "Train Epoch: 2 [28480/110534 (26%)]\tAll Loss: 2.4246\tTriple Loss(0): 0.2080\tClassification Loss: 2.0085\n",
      "\n",
      "Test set: Average loss: 1.6955, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [28800/110534 (26%)]\tAll Loss: 1.4340\tTriple Loss(0): 0.0000\tClassification Loss: 1.4340\n",
      "Train Epoch: 2 [29120/110534 (26%)]\tAll Loss: 1.9399\tTriple Loss(1): 0.0777\tClassification Loss: 1.7846\n",
      "Train Epoch: 2 [29440/110534 (27%)]\tAll Loss: 2.5564\tTriple Loss(1): 0.4713\tClassification Loss: 1.6137\n",
      "Train Epoch: 2 [29760/110534 (27%)]\tAll Loss: 1.7505\tTriple Loss(1): 0.1493\tClassification Loss: 1.4520\n",
      "Train Epoch: 2 [30080/110534 (27%)]\tAll Loss: 1.9909\tTriple Loss(1): 0.2490\tClassification Loss: 1.4928\n",
      "Train Epoch: 2 [30400/110534 (27%)]\tAll Loss: 1.5536\tTriple Loss(0): 0.0000\tClassification Loss: 1.5536\n",
      "Train Epoch: 2 [30720/110534 (28%)]\tAll Loss: 2.2994\tTriple Loss(1): 0.4106\tClassification Loss: 1.4783\n",
      "Train Epoch: 2 [31040/110534 (28%)]\tAll Loss: 2.3579\tTriple Loss(1): 0.2380\tClassification Loss: 1.8820\n",
      "Train Epoch: 2 [31360/110534 (28%)]\tAll Loss: 2.3309\tTriple Loss(1): 0.2575\tClassification Loss: 1.8158\n",
      "Train Epoch: 2 [31680/110534 (29%)]\tAll Loss: 2.0479\tTriple Loss(1): 0.1818\tClassification Loss: 1.6843\n",
      "\n",
      "Test set: Average loss: 1.6989, Accuracy: 533/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [32000/110534 (29%)]\tAll Loss: 2.2790\tTriple Loss(1): 0.2495\tClassification Loss: 1.7801\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_1000.pth.tar\n",
      "Train Epoch: 2 [32320/110534 (29%)]\tAll Loss: 2.2293\tTriple Loss(1): 0.3772\tClassification Loss: 1.4748\n",
      "Train Epoch: 2 [32640/110534 (30%)]\tAll Loss: 2.1376\tTriple Loss(1): 0.1651\tClassification Loss: 1.8075\n",
      "Train Epoch: 2 [32960/110534 (30%)]\tAll Loss: 2.6559\tTriple Loss(1): 0.4026\tClassification Loss: 1.8507\n",
      "Train Epoch: 2 [33280/110534 (30%)]\tAll Loss: 2.2985\tTriple Loss(1): 0.2356\tClassification Loss: 1.8273\n",
      "Train Epoch: 2 [33600/110534 (30%)]\tAll Loss: 1.9524\tTriple Loss(1): 0.1834\tClassification Loss: 1.5856\n",
      "Train Epoch: 2 [33920/110534 (31%)]\tAll Loss: 7.8739\tTriple Loss(0): 3.1530\tClassification Loss: 1.5679\n",
      "Train Epoch: 2 [34240/110534 (31%)]\tAll Loss: 2.7509\tTriple Loss(1): 0.5702\tClassification Loss: 1.6105\n",
      "Train Epoch: 2 [34560/110534 (31%)]\tAll Loss: 2.4724\tTriple Loss(1): 0.4983\tClassification Loss: 1.4758\n",
      "Train Epoch: 2 [34880/110534 (32%)]\tAll Loss: 1.4401\tTriple Loss(0): 0.0000\tClassification Loss: 1.4401\n",
      "\n",
      "Test set: Average loss: 1.6903, Accuracy: 539/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [35200/110534 (32%)]\tAll Loss: 2.7976\tTriple Loss(1): 0.3994\tClassification Loss: 1.9987\n",
      "Train Epoch: 2 [35520/110534 (32%)]\tAll Loss: 2.1194\tTriple Loss(1): 0.1015\tClassification Loss: 1.9164\n",
      "Train Epoch: 2 [35840/110534 (32%)]\tAll Loss: 1.7293\tTriple Loss(1): 0.1504\tClassification Loss: 1.4285\n",
      "Train Epoch: 2 [36160/110534 (33%)]\tAll Loss: 1.8832\tTriple Loss(1): 0.1570\tClassification Loss: 1.5693\n",
      "Train Epoch: 2 [36480/110534 (33%)]\tAll Loss: 2.5406\tTriple Loss(1): 0.3438\tClassification Loss: 1.8531\n",
      "Train Epoch: 2 [36800/110534 (33%)]\tAll Loss: 2.0727\tTriple Loss(1): 0.2235\tClassification Loss: 1.6256\n",
      "Train Epoch: 2 [37120/110534 (34%)]\tAll Loss: 2.2950\tTriple Loss(1): 0.2119\tClassification Loss: 1.8713\n",
      "Train Epoch: 2 [37440/110534 (34%)]\tAll Loss: 2.0083\tTriple Loss(0): 0.0000\tClassification Loss: 2.0083\n",
      "Train Epoch: 2 [37760/110534 (34%)]\tAll Loss: 2.5735\tTriple Loss(1): 0.4206\tClassification Loss: 1.7324\n",
      "Train Epoch: 2 [38080/110534 (34%)]\tAll Loss: 2.3746\tTriple Loss(1): 0.3393\tClassification Loss: 1.6959\n",
      "\n",
      "Test set: Average loss: 1.6885, Accuracy: 535/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [38400/110534 (35%)]\tAll Loss: 1.7433\tTriple Loss(1): 0.1770\tClassification Loss: 1.3892\n",
      "Train Epoch: 2 [38720/110534 (35%)]\tAll Loss: 1.8362\tTriple Loss(0): 0.0000\tClassification Loss: 1.8362\n",
      "Train Epoch: 2 [39040/110534 (35%)]\tAll Loss: 1.8537\tTriple Loss(1): 0.1941\tClassification Loss: 1.4656\n",
      "Train Epoch: 2 [39360/110534 (36%)]\tAll Loss: 2.1808\tTriple Loss(1): 0.2845\tClassification Loss: 1.6119\n",
      "Train Epoch: 2 [39680/110534 (36%)]\tAll Loss: 2.3698\tTriple Loss(1): 0.1858\tClassification Loss: 1.9981\n",
      "Train Epoch: 2 [40000/110534 (36%)]\tAll Loss: 1.9526\tTriple Loss(1): 0.3570\tClassification Loss: 1.2386\n",
      "Train Epoch: 2 [40320/110534 (36%)]\tAll Loss: 2.5555\tTriple Loss(1): 0.3686\tClassification Loss: 1.8184\n",
      "Train Epoch: 2 [40640/110534 (37%)]\tAll Loss: 2.5359\tTriple Loss(1): 0.3273\tClassification Loss: 1.8813\n",
      "Train Epoch: 2 [40960/110534 (37%)]\tAll Loss: 2.0179\tTriple Loss(1): 0.2364\tClassification Loss: 1.5450\n",
      "Train Epoch: 2 [41280/110534 (37%)]\tAll Loss: 2.3799\tTriple Loss(1): 0.2943\tClassification Loss: 1.7914\n",
      "\n",
      "Test set: Average loss: 1.6858, Accuracy: 535/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [41600/110534 (38%)]\tAll Loss: 1.8126\tTriple Loss(0): 0.0000\tClassification Loss: 1.8126\n",
      "Train Epoch: 2 [41920/110534 (38%)]\tAll Loss: 1.8717\tTriple Loss(1): 0.1132\tClassification Loss: 1.6454\n",
      "Train Epoch: 2 [42240/110534 (38%)]\tAll Loss: 2.3829\tTriple Loss(1): 0.3631\tClassification Loss: 1.6566\n",
      "Train Epoch: 2 [42560/110534 (38%)]\tAll Loss: 1.8253\tTriple Loss(0): 0.0000\tClassification Loss: 1.8253\n",
      "Train Epoch: 2 [42880/110534 (39%)]\tAll Loss: 1.8487\tTriple Loss(0): 0.0000\tClassification Loss: 1.8487\n",
      "Train Epoch: 2 [43200/110534 (39%)]\tAll Loss: 2.2524\tTriple Loss(1): 0.2966\tClassification Loss: 1.6592\n",
      "Train Epoch: 2 [43520/110534 (39%)]\tAll Loss: 1.9347\tTriple Loss(1): 0.1892\tClassification Loss: 1.5563\n",
      "Train Epoch: 2 [43840/110534 (40%)]\tAll Loss: 2.0369\tTriple Loss(1): 0.2353\tClassification Loss: 1.5662\n",
      "Train Epoch: 2 [44160/110534 (40%)]\tAll Loss: 2.7770\tTriple Loss(1): 0.3737\tClassification Loss: 2.0296\n",
      "Train Epoch: 2 [44480/110534 (40%)]\tAll Loss: 1.6665\tTriple Loss(0): 0.0000\tClassification Loss: 1.6665\n",
      "\n",
      "Test set: Average loss: 1.6857, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [44800/110534 (41%)]\tAll Loss: 1.2702\tTriple Loss(0): 0.0000\tClassification Loss: 1.2702\n",
      "Train Epoch: 2 [45120/110534 (41%)]\tAll Loss: 2.2318\tTriple Loss(1): 0.3212\tClassification Loss: 1.5894\n",
      "Train Epoch: 2 [45440/110534 (41%)]\tAll Loss: 2.1643\tTriple Loss(1): 0.2339\tClassification Loss: 1.6964\n",
      "Train Epoch: 2 [45760/110534 (41%)]\tAll Loss: 1.4610\tTriple Loss(0): 0.0000\tClassification Loss: 1.4610\n",
      "Train Epoch: 2 [46080/110534 (42%)]\tAll Loss: 1.2680\tTriple Loss(0): 0.0000\tClassification Loss: 1.2680\n",
      "Train Epoch: 2 [46400/110534 (42%)]\tAll Loss: 2.4933\tTriple Loss(1): 0.3189\tClassification Loss: 1.8555\n",
      "Train Epoch: 2 [46720/110534 (42%)]\tAll Loss: 1.7976\tTriple Loss(0): 0.0000\tClassification Loss: 1.7976\n",
      "Train Epoch: 2 [47040/110534 (43%)]\tAll Loss: 2.4857\tTriple Loss(1): 0.3821\tClassification Loss: 1.7216\n",
      "Train Epoch: 2 [47360/110534 (43%)]\tAll Loss: 2.1261\tTriple Loss(1): 0.2403\tClassification Loss: 1.6455\n",
      "Train Epoch: 2 [47680/110534 (43%)]\tAll Loss: 1.6445\tTriple Loss(1): 0.1569\tClassification Loss: 1.3307\n",
      "\n",
      "Test set: Average loss: 1.6887, Accuracy: 539/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [48000/110534 (43%)]\tAll Loss: 4.4430\tTriple Loss(0): 1.2317\tClassification Loss: 1.9797\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_1500.pth.tar\n",
      "Train Epoch: 2 [48320/110534 (44%)]\tAll Loss: 2.3963\tTriple Loss(1): 0.3189\tClassification Loss: 1.7585\n",
      "Train Epoch: 2 [48640/110534 (44%)]\tAll Loss: 1.8761\tTriple Loss(0): 0.0000\tClassification Loss: 1.8761\n",
      "Train Epoch: 2 [48960/110534 (44%)]\tAll Loss: 2.5714\tTriple Loss(1): 0.3741\tClassification Loss: 1.8231\n",
      "Train Epoch: 2 [49280/110534 (45%)]\tAll Loss: 2.1606\tTriple Loss(1): 0.3252\tClassification Loss: 1.5103\n",
      "Train Epoch: 2 [49600/110534 (45%)]\tAll Loss: 2.5213\tTriple Loss(1): 0.3579\tClassification Loss: 1.8055\n",
      "Train Epoch: 2 [49920/110534 (45%)]\tAll Loss: 1.9394\tTriple Loss(1): 0.2814\tClassification Loss: 1.3767\n",
      "Train Epoch: 2 [50240/110534 (45%)]\tAll Loss: 1.8231\tTriple Loss(1): 0.1122\tClassification Loss: 1.5988\n",
      "Train Epoch: 2 [50560/110534 (46%)]\tAll Loss: 2.0492\tTriple Loss(1): 0.1633\tClassification Loss: 1.7226\n",
      "Train Epoch: 2 [50880/110534 (46%)]\tAll Loss: 2.4563\tTriple Loss(1): 0.3262\tClassification Loss: 1.8039\n",
      "\n",
      "Test set: Average loss: 1.6805, Accuracy: 544/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [51200/110534 (46%)]\tAll Loss: 5.4395\tTriple Loss(0): 1.9318\tClassification Loss: 1.5760\n",
      "Train Epoch: 2 [51520/110534 (47%)]\tAll Loss: 2.5007\tTriple Loss(1): 0.4199\tClassification Loss: 1.6609\n",
      "Train Epoch: 2 [51840/110534 (47%)]\tAll Loss: 2.3323\tTriple Loss(1): 0.3514\tClassification Loss: 1.6295\n",
      "Train Epoch: 2 [52160/110534 (47%)]\tAll Loss: 2.8511\tTriple Loss(1): 0.4236\tClassification Loss: 2.0039\n",
      "Train Epoch: 2 [52480/110534 (47%)]\tAll Loss: 2.3624\tTriple Loss(1): 0.0829\tClassification Loss: 2.1966\n",
      "Train Epoch: 2 [52800/110534 (48%)]\tAll Loss: 1.9530\tTriple Loss(1): 0.2018\tClassification Loss: 1.5494\n",
      "Train Epoch: 2 [53120/110534 (48%)]\tAll Loss: 1.4486\tTriple Loss(0): 0.0000\tClassification Loss: 1.4486\n",
      "Train Epoch: 2 [53440/110534 (48%)]\tAll Loss: 8.3666\tTriple Loss(0): 3.2471\tClassification Loss: 1.8724\n",
      "Train Epoch: 2 [53760/110534 (49%)]\tAll Loss: 2.3406\tTriple Loss(1): 0.2747\tClassification Loss: 1.7912\n",
      "Train Epoch: 2 [54080/110534 (49%)]\tAll Loss: 1.7550\tTriple Loss(0): 0.0000\tClassification Loss: 1.7550\n",
      "\n",
      "Test set: Average loss: 1.6849, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [54400/110534 (49%)]\tAll Loss: 2.6238\tTriple Loss(1): 0.4617\tClassification Loss: 1.7004\n",
      "Train Epoch: 2 [54720/110534 (49%)]\tAll Loss: 2.3234\tTriple Loss(1): 0.3148\tClassification Loss: 1.6937\n",
      "Train Epoch: 2 [55040/110534 (50%)]\tAll Loss: 2.7421\tTriple Loss(1): 0.3915\tClassification Loss: 1.9591\n",
      "Train Epoch: 2 [55360/110534 (50%)]\tAll Loss: 1.4227\tTriple Loss(0): 0.0000\tClassification Loss: 1.4227\n",
      "Train Epoch: 2 [55680/110534 (50%)]\tAll Loss: 2.3809\tTriple Loss(1): 0.2776\tClassification Loss: 1.8257\n",
      "Train Epoch: 2 [56000/110534 (51%)]\tAll Loss: 2.5533\tTriple Loss(1): 0.2423\tClassification Loss: 2.0687\n",
      "Train Epoch: 2 [56320/110534 (51%)]\tAll Loss: 1.8539\tTriple Loss(0): 0.0000\tClassification Loss: 1.8539\n",
      "Train Epoch: 2 [56640/110534 (51%)]\tAll Loss: 1.8054\tTriple Loss(1): 0.2720\tClassification Loss: 1.2613\n",
      "Train Epoch: 2 [56960/110534 (52%)]\tAll Loss: 2.1948\tTriple Loss(1): 0.2064\tClassification Loss: 1.7820\n",
      "Train Epoch: 2 [57280/110534 (52%)]\tAll Loss: 2.4135\tTriple Loss(1): 0.2962\tClassification Loss: 1.8211\n",
      "\n",
      "Test set: Average loss: 1.6769, Accuracy: 552/960 (58%)\n",
      "\n",
      "Train Epoch: 2 [57600/110534 (52%)]\tAll Loss: 2.3116\tTriple Loss(1): 0.2254\tClassification Loss: 1.8609\n",
      "Train Epoch: 2 [57920/110534 (52%)]\tAll Loss: 2.5277\tTriple Loss(1): 0.3809\tClassification Loss: 1.7659\n",
      "Train Epoch: 2 [58240/110534 (53%)]\tAll Loss: 1.8676\tTriple Loss(1): 0.2463\tClassification Loss: 1.3750\n",
      "Train Epoch: 2 [58560/110534 (53%)]\tAll Loss: 1.5860\tTriple Loss(0): 0.0000\tClassification Loss: 1.5860\n",
      "Train Epoch: 2 [58880/110534 (53%)]\tAll Loss: 2.2577\tTriple Loss(1): 0.2192\tClassification Loss: 1.8193\n",
      "Train Epoch: 2 [59200/110534 (54%)]\tAll Loss: 2.2929\tTriple Loss(1): 0.2316\tClassification Loss: 1.8298\n",
      "Train Epoch: 2 [59520/110534 (54%)]\tAll Loss: 1.3778\tTriple Loss(0): 0.0000\tClassification Loss: 1.3778\n",
      "Train Epoch: 2 [59840/110534 (54%)]\tAll Loss: 2.3819\tTriple Loss(1): 0.4661\tClassification Loss: 1.4497\n",
      "Train Epoch: 2 [60160/110534 (54%)]\tAll Loss: 2.0080\tTriple Loss(1): 0.2097\tClassification Loss: 1.5886\n",
      "Train Epoch: 2 [60480/110534 (55%)]\tAll Loss: 1.7734\tTriple Loss(1): 0.0735\tClassification Loss: 1.6264\n",
      "\n",
      "Test set: Average loss: 1.6746, Accuracy: 540/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [60800/110534 (55%)]\tAll Loss: 1.9851\tTriple Loss(1): 0.0935\tClassification Loss: 1.7982\n",
      "Train Epoch: 2 [61120/110534 (55%)]\tAll Loss: 2.4575\tTriple Loss(1): 0.3659\tClassification Loss: 1.7257\n",
      "Train Epoch: 2 [61440/110534 (56%)]\tAll Loss: 1.8211\tTriple Loss(1): 0.3792\tClassification Loss: 1.0626\n",
      "Train Epoch: 2 [61760/110534 (56%)]\tAll Loss: 2.1943\tTriple Loss(1): 0.2128\tClassification Loss: 1.7688\n",
      "Train Epoch: 2 [62080/110534 (56%)]\tAll Loss: 2.3574\tTriple Loss(1): 0.3177\tClassification Loss: 1.7219\n",
      "Train Epoch: 2 [62400/110534 (56%)]\tAll Loss: 2.4445\tTriple Loss(0): 0.4804\tClassification Loss: 1.4837\n",
      "Train Epoch: 2 [62720/110534 (57%)]\tAll Loss: 1.4021\tTriple Loss(0): 0.0000\tClassification Loss: 1.4021\n",
      "Train Epoch: 2 [63040/110534 (57%)]\tAll Loss: 3.1305\tTriple Loss(1): 0.5339\tClassification Loss: 2.0627\n",
      "Train Epoch: 2 [63360/110534 (57%)]\tAll Loss: 2.1954\tTriple Loss(1): 0.2520\tClassification Loss: 1.6914\n",
      "Train Epoch: 2 [63680/110534 (58%)]\tAll Loss: 1.4770\tTriple Loss(0): 0.0000\tClassification Loss: 1.4770\n",
      "\n",
      "Test set: Average loss: 1.6816, Accuracy: 541/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [64000/110534 (58%)]\tAll Loss: 2.4947\tTriple Loss(1): 0.1955\tClassification Loss: 2.1038\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_2000.pth.tar\n",
      "Train Epoch: 2 [64320/110534 (58%)]\tAll Loss: 2.1477\tTriple Loss(1): 0.3229\tClassification Loss: 1.5019\n",
      "Train Epoch: 2 [64640/110534 (58%)]\tAll Loss: 4.8599\tTriple Loss(0): 1.3121\tClassification Loss: 2.2358\n",
      "Train Epoch: 2 [64960/110534 (59%)]\tAll Loss: 2.3308\tTriple Loss(1): 0.3097\tClassification Loss: 1.7113\n",
      "Train Epoch: 2 [65280/110534 (59%)]\tAll Loss: 1.8602\tTriple Loss(1): 0.0377\tClassification Loss: 1.7848\n",
      "Train Epoch: 2 [65600/110534 (59%)]\tAll Loss: 1.9804\tTriple Loss(1): 0.1440\tClassification Loss: 1.6924\n",
      "Train Epoch: 2 [65920/110534 (60%)]\tAll Loss: 1.9103\tTriple Loss(1): 0.1011\tClassification Loss: 1.7081\n",
      "Train Epoch: 2 [66240/110534 (60%)]\tAll Loss: 1.7736\tTriple Loss(0): 0.0000\tClassification Loss: 1.7736\n",
      "Train Epoch: 2 [66560/110534 (60%)]\tAll Loss: 1.9558\tTriple Loss(1): 0.2270\tClassification Loss: 1.5019\n",
      "Train Epoch: 2 [66880/110534 (60%)]\tAll Loss: 1.7467\tTriple Loss(0): 0.0000\tClassification Loss: 1.7467\n",
      "\n",
      "Test set: Average loss: 1.6729, Accuracy: 533/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [67200/110534 (61%)]\tAll Loss: 2.2452\tTriple Loss(1): 0.2022\tClassification Loss: 1.8409\n",
      "Train Epoch: 2 [67520/110534 (61%)]\tAll Loss: 2.4317\tTriple Loss(1): 0.2716\tClassification Loss: 1.8886\n",
      "Train Epoch: 2 [67840/110534 (61%)]\tAll Loss: 2.3753\tTriple Loss(1): 0.2353\tClassification Loss: 1.9047\n",
      "Train Epoch: 2 [68160/110534 (62%)]\tAll Loss: 2.1274\tTriple Loss(1): 0.3165\tClassification Loss: 1.4944\n",
      "Train Epoch: 2 [68480/110534 (62%)]\tAll Loss: 1.4172\tTriple Loss(0): 0.0000\tClassification Loss: 1.4172\n",
      "Train Epoch: 2 [68800/110534 (62%)]\tAll Loss: 1.9005\tTriple Loss(1): 0.1482\tClassification Loss: 1.6042\n",
      "Train Epoch: 2 [69120/110534 (63%)]\tAll Loss: 2.1510\tTriple Loss(0): 0.2272\tClassification Loss: 1.6966\n",
      "Train Epoch: 2 [69440/110534 (63%)]\tAll Loss: 2.2385\tTriple Loss(1): 0.2939\tClassification Loss: 1.6507\n",
      "Train Epoch: 2 [69760/110534 (63%)]\tAll Loss: 2.4104\tTriple Loss(1): 0.3484\tClassification Loss: 1.7135\n",
      "Train Epoch: 2 [70080/110534 (63%)]\tAll Loss: 2.0236\tTriple Loss(1): 0.3436\tClassification Loss: 1.3364\n",
      "\n",
      "Test set: Average loss: 1.6682, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [70400/110534 (64%)]\tAll Loss: 2.3131\tTriple Loss(1): 0.3779\tClassification Loss: 1.5573\n",
      "Train Epoch: 2 [70720/110534 (64%)]\tAll Loss: 1.7775\tTriple Loss(0): 0.2021\tClassification Loss: 1.3732\n",
      "Train Epoch: 2 [71040/110534 (64%)]\tAll Loss: 2.4137\tTriple Loss(1): 0.4493\tClassification Loss: 1.5151\n",
      "Train Epoch: 2 [71360/110534 (65%)]\tAll Loss: 2.4237\tTriple Loss(1): 0.2843\tClassification Loss: 1.8552\n",
      "Train Epoch: 2 [71680/110534 (65%)]\tAll Loss: 2.5274\tTriple Loss(1): 0.3993\tClassification Loss: 1.7289\n",
      "Train Epoch: 2 [72000/110534 (65%)]\tAll Loss: 2.0057\tTriple Loss(1): 0.2138\tClassification Loss: 1.5780\n",
      "Train Epoch: 2 [72320/110534 (65%)]\tAll Loss: 1.9913\tTriple Loss(1): 0.2056\tClassification Loss: 1.5800\n",
      "Train Epoch: 2 [72640/110534 (66%)]\tAll Loss: 1.9437\tTriple Loss(1): 0.2373\tClassification Loss: 1.4691\n",
      "Train Epoch: 2 [72960/110534 (66%)]\tAll Loss: 1.6841\tTriple Loss(1): 0.1537\tClassification Loss: 1.3767\n",
      "Train Epoch: 2 [73280/110534 (66%)]\tAll Loss: 1.2847\tTriple Loss(0): 0.0000\tClassification Loss: 1.2847\n",
      "\n",
      "Test set: Average loss: 1.6652, Accuracy: 545/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [73600/110534 (67%)]\tAll Loss: 2.8814\tTriple Loss(1): 0.3406\tClassification Loss: 2.2002\n",
      "Train Epoch: 2 [73920/110534 (67%)]\tAll Loss: 2.2439\tTriple Loss(1): 0.1486\tClassification Loss: 1.9466\n",
      "Train Epoch: 2 [74240/110534 (67%)]\tAll Loss: 1.8759\tTriple Loss(1): 0.2104\tClassification Loss: 1.4550\n",
      "Train Epoch: 2 [74560/110534 (67%)]\tAll Loss: 2.3478\tTriple Loss(1): 0.1687\tClassification Loss: 2.0105\n",
      "Train Epoch: 2 [74880/110534 (68%)]\tAll Loss: 2.6002\tTriple Loss(1): 0.4244\tClassification Loss: 1.7513\n",
      "Train Epoch: 2 [75200/110534 (68%)]\tAll Loss: 1.5798\tTriple Loss(0): 0.0000\tClassification Loss: 1.5798\n",
      "Train Epoch: 2 [75520/110534 (68%)]\tAll Loss: 3.7064\tTriple Loss(0): 1.1333\tClassification Loss: 1.4397\n",
      "Train Epoch: 2 [75840/110534 (69%)]\tAll Loss: 2.1227\tTriple Loss(1): 0.2768\tClassification Loss: 1.5691\n",
      "Train Epoch: 2 [76160/110534 (69%)]\tAll Loss: 2.2644\tTriple Loss(1): 0.2883\tClassification Loss: 1.6877\n",
      "Train Epoch: 2 [76480/110534 (69%)]\tAll Loss: 2.0898\tTriple Loss(1): 0.1945\tClassification Loss: 1.7009\n",
      "\n",
      "Test set: Average loss: 1.6621, Accuracy: 542/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [76800/110534 (69%)]\tAll Loss: 1.9161\tTriple Loss(1): 0.2286\tClassification Loss: 1.4590\n",
      "Train Epoch: 2 [77120/110534 (70%)]\tAll Loss: 2.3094\tTriple Loss(1): 0.3386\tClassification Loss: 1.6322\n",
      "Train Epoch: 2 [77440/110534 (70%)]\tAll Loss: 2.4436\tTriple Loss(1): 0.4432\tClassification Loss: 1.5572\n",
      "Train Epoch: 2 [77760/110534 (70%)]\tAll Loss: 1.6590\tTriple Loss(0): 0.0000\tClassification Loss: 1.6590\n",
      "Train Epoch: 2 [78080/110534 (71%)]\tAll Loss: 2.3398\tTriple Loss(1): 0.1994\tClassification Loss: 1.9410\n",
      "Train Epoch: 2 [78400/110534 (71%)]\tAll Loss: 2.2804\tTriple Loss(1): 0.3473\tClassification Loss: 1.5858\n",
      "Train Epoch: 2 [78720/110534 (71%)]\tAll Loss: 1.9721\tTriple Loss(1): 0.2674\tClassification Loss: 1.4373\n",
      "Train Epoch: 2 [79040/110534 (71%)]\tAll Loss: 1.8302\tTriple Loss(0): 0.0000\tClassification Loss: 1.8302\n",
      "Train Epoch: 2 [79360/110534 (72%)]\tAll Loss: 3.2934\tTriple Loss(1): 0.6495\tClassification Loss: 1.9943\n",
      "Train Epoch: 2 [79680/110534 (72%)]\tAll Loss: 1.7346\tTriple Loss(0): 0.1125\tClassification Loss: 1.5096\n",
      "\n",
      "Test set: Average loss: 1.6705, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [80000/110534 (72%)]\tAll Loss: 1.7868\tTriple Loss(1): 0.1214\tClassification Loss: 1.5439\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_2500.pth.tar\n",
      "Train Epoch: 2 [80320/110534 (73%)]\tAll Loss: 1.7362\tTriple Loss(1): 0.2156\tClassification Loss: 1.3050\n",
      "Train Epoch: 2 [80640/110534 (73%)]\tAll Loss: 2.0687\tTriple Loss(1): 0.2768\tClassification Loss: 1.5151\n",
      "Train Epoch: 2 [80960/110534 (73%)]\tAll Loss: 2.0660\tTriple Loss(1): 0.1528\tClassification Loss: 1.7603\n",
      "Train Epoch: 2 [81280/110534 (74%)]\tAll Loss: 2.2158\tTriple Loss(1): 0.3962\tClassification Loss: 1.4235\n",
      "Train Epoch: 2 [81600/110534 (74%)]\tAll Loss: 2.0526\tTriple Loss(1): 0.3006\tClassification Loss: 1.4513\n",
      "Train Epoch: 2 [81920/110534 (74%)]\tAll Loss: 1.7403\tTriple Loss(0): 0.0000\tClassification Loss: 1.7403\n",
      "Train Epoch: 2 [82240/110534 (74%)]\tAll Loss: 2.0119\tTriple Loss(0): 0.0000\tClassification Loss: 2.0119\n",
      "Train Epoch: 2 [82560/110534 (75%)]\tAll Loss: 2.1282\tTriple Loss(1): 0.2630\tClassification Loss: 1.6023\n",
      "Train Epoch: 2 [82880/110534 (75%)]\tAll Loss: 2.9401\tTriple Loss(1): 0.4661\tClassification Loss: 2.0079\n",
      "\n",
      "Test set: Average loss: 1.6642, Accuracy: 547/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [83200/110534 (75%)]\tAll Loss: 2.6491\tTriple Loss(1): 0.4791\tClassification Loss: 1.6909\n",
      "Train Epoch: 2 [83520/110534 (76%)]\tAll Loss: 2.1388\tTriple Loss(1): 0.2522\tClassification Loss: 1.6344\n",
      "Train Epoch: 2 [83840/110534 (76%)]\tAll Loss: 1.5501\tTriple Loss(1): 0.1077\tClassification Loss: 1.3348\n",
      "Train Epoch: 2 [84160/110534 (76%)]\tAll Loss: 1.5154\tTriple Loss(1): 0.0899\tClassification Loss: 1.3357\n",
      "Train Epoch: 2 [84480/110534 (76%)]\tAll Loss: 2.1333\tTriple Loss(1): 0.4090\tClassification Loss: 1.3153\n",
      "Train Epoch: 2 [84800/110534 (77%)]\tAll Loss: 2.4755\tTriple Loss(1): 0.3304\tClassification Loss: 1.8147\n",
      "Train Epoch: 2 [85120/110534 (77%)]\tAll Loss: 1.6974\tTriple Loss(1): 0.1493\tClassification Loss: 1.3989\n",
      "Train Epoch: 2 [85440/110534 (77%)]\tAll Loss: 1.3685\tTriple Loss(0): 0.0000\tClassification Loss: 1.3685\n",
      "Train Epoch: 2 [85760/110534 (78%)]\tAll Loss: 2.0540\tTriple Loss(1): 0.1693\tClassification Loss: 1.7154\n",
      "Train Epoch: 2 [86080/110534 (78%)]\tAll Loss: 2.1369\tTriple Loss(1): 0.2520\tClassification Loss: 1.6329\n",
      "\n",
      "Test set: Average loss: 1.6589, Accuracy: 542/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [86400/110534 (78%)]\tAll Loss: 2.7954\tTriple Loss(1): 0.3633\tClassification Loss: 2.0689\n",
      "Train Epoch: 2 [86720/110534 (78%)]\tAll Loss: 2.0131\tTriple Loss(1): 0.2909\tClassification Loss: 1.4313\n",
      "Train Epoch: 2 [87040/110534 (79%)]\tAll Loss: 1.9479\tTriple Loss(1): 0.2629\tClassification Loss: 1.4221\n",
      "Train Epoch: 2 [87360/110534 (79%)]\tAll Loss: 2.2029\tTriple Loss(1): 0.3202\tClassification Loss: 1.5624\n",
      "Train Epoch: 2 [87680/110534 (79%)]\tAll Loss: 1.9986\tTriple Loss(1): 0.1565\tClassification Loss: 1.6856\n",
      "Train Epoch: 2 [88000/110534 (80%)]\tAll Loss: 2.7150\tTriple Loss(1): 0.2276\tClassification Loss: 2.2598\n",
      "Train Epoch: 2 [88320/110534 (80%)]\tAll Loss: 2.0369\tTriple Loss(1): 0.1559\tClassification Loss: 1.7251\n",
      "Train Epoch: 2 [88640/110534 (80%)]\tAll Loss: 2.4387\tTriple Loss(1): 0.2317\tClassification Loss: 1.9752\n",
      "Train Epoch: 2 [88960/110534 (80%)]\tAll Loss: 1.7794\tTriple Loss(0): 0.0000\tClassification Loss: 1.7794\n",
      "Train Epoch: 2 [89280/110534 (81%)]\tAll Loss: 2.6597\tTriple Loss(1): 0.4533\tClassification Loss: 1.7531\n",
      "\n",
      "Test set: Average loss: 1.6613, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [89600/110534 (81%)]\tAll Loss: 2.5266\tTriple Loss(1): 0.1955\tClassification Loss: 2.1357\n",
      "Train Epoch: 2 [89920/110534 (81%)]\tAll Loss: 2.5861\tTriple Loss(1): 0.4182\tClassification Loss: 1.7497\n",
      "Train Epoch: 2 [90240/110534 (82%)]\tAll Loss: 2.0395\tTriple Loss(1): 0.1985\tClassification Loss: 1.6424\n",
      "Train Epoch: 2 [90560/110534 (82%)]\tAll Loss: 1.6235\tTriple Loss(1): 0.1489\tClassification Loss: 1.3257\n",
      "Train Epoch: 2 [90880/110534 (82%)]\tAll Loss: 2.1334\tTriple Loss(1): 0.2267\tClassification Loss: 1.6801\n",
      "Train Epoch: 2 [91200/110534 (82%)]\tAll Loss: 1.8708\tTriple Loss(1): 0.2210\tClassification Loss: 1.4289\n",
      "Train Epoch: 2 [91520/110534 (83%)]\tAll Loss: 1.6401\tTriple Loss(0): 0.0000\tClassification Loss: 1.6401\n",
      "Train Epoch: 2 [91840/110534 (83%)]\tAll Loss: 2.6120\tTriple Loss(1): 0.5362\tClassification Loss: 1.5396\n",
      "Train Epoch: 2 [92160/110534 (83%)]\tAll Loss: 2.7132\tTriple Loss(1): 0.3545\tClassification Loss: 2.0042\n",
      "Train Epoch: 2 [92480/110534 (84%)]\tAll Loss: 1.8850\tTriple Loss(1): 0.1350\tClassification Loss: 1.6151\n",
      "\n",
      "Test set: Average loss: 1.6691, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [92800/110534 (84%)]\tAll Loss: 1.9706\tTriple Loss(1): 0.1624\tClassification Loss: 1.6457\n",
      "Train Epoch: 2 [93120/110534 (84%)]\tAll Loss: 1.9647\tTriple Loss(1): 0.0951\tClassification Loss: 1.7745\n",
      "Train Epoch: 2 [93440/110534 (85%)]\tAll Loss: 3.0173\tTriple Loss(0): 0.6316\tClassification Loss: 1.7541\n",
      "Train Epoch: 2 [93760/110534 (85%)]\tAll Loss: 2.2309\tTriple Loss(1): 0.3585\tClassification Loss: 1.5138\n",
      "Train Epoch: 2 [94080/110534 (85%)]\tAll Loss: 1.7631\tTriple Loss(1): 0.1097\tClassification Loss: 1.5437\n",
      "Train Epoch: 2 [94400/110534 (85%)]\tAll Loss: 2.2216\tTriple Loss(1): 0.2614\tClassification Loss: 1.6988\n",
      "Train Epoch: 2 [94720/110534 (86%)]\tAll Loss: 1.7035\tTriple Loss(0): 0.0000\tClassification Loss: 1.7035\n",
      "Train Epoch: 2 [95040/110534 (86%)]\tAll Loss: 1.9317\tTriple Loss(1): 0.1473\tClassification Loss: 1.6370\n",
      "Train Epoch: 2 [95360/110534 (86%)]\tAll Loss: 2.1842\tTriple Loss(1): 0.2473\tClassification Loss: 1.6895\n",
      "Train Epoch: 2 [95680/110534 (87%)]\tAll Loss: 1.8858\tTriple Loss(1): 0.1593\tClassification Loss: 1.5672\n",
      "\n",
      "Test set: Average loss: 1.6595, Accuracy: 542/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [96000/110534 (87%)]\tAll Loss: 1.8131\tTriple Loss(1): 0.1966\tClassification Loss: 1.4199\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_3000.pth.tar\n",
      "Train Epoch: 2 [96320/110534 (87%)]\tAll Loss: 1.8410\tTriple Loss(1): 0.1606\tClassification Loss: 1.5199\n",
      "Train Epoch: 2 [96640/110534 (87%)]\tAll Loss: 1.7218\tTriple Loss(0): 0.0000\tClassification Loss: 1.7218\n",
      "Train Epoch: 2 [96960/110534 (88%)]\tAll Loss: 1.3942\tTriple Loss(1): 0.0839\tClassification Loss: 1.2265\n",
      "Train Epoch: 2 [97280/110534 (88%)]\tAll Loss: 2.0034\tTriple Loss(1): 0.3788\tClassification Loss: 1.2457\n",
      "Train Epoch: 2 [97600/110534 (88%)]\tAll Loss: 1.9115\tTriple Loss(0): 0.0000\tClassification Loss: 1.9115\n",
      "Train Epoch: 2 [97920/110534 (89%)]\tAll Loss: 1.1860\tTriple Loss(0): 0.0000\tClassification Loss: 1.1860\n",
      "Train Epoch: 2 [98240/110534 (89%)]\tAll Loss: 2.2573\tTriple Loss(0): 0.4676\tClassification Loss: 1.3220\n",
      "Train Epoch: 2 [98560/110534 (89%)]\tAll Loss: 1.9454\tTriple Loss(1): 0.2523\tClassification Loss: 1.4408\n",
      "Train Epoch: 2 [98880/110534 (89%)]\tAll Loss: 2.0493\tTriple Loss(1): 0.2397\tClassification Loss: 1.5700\n",
      "\n",
      "Test set: Average loss: 1.6667, Accuracy: 537/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [99200/110534 (90%)]\tAll Loss: 1.9327\tTriple Loss(1): 0.2137\tClassification Loss: 1.5053\n",
      "Train Epoch: 2 [99520/110534 (90%)]\tAll Loss: 2.1136\tTriple Loss(1): 0.2694\tClassification Loss: 1.5748\n",
      "Train Epoch: 2 [99840/110534 (90%)]\tAll Loss: 2.6177\tTriple Loss(1): 0.4630\tClassification Loss: 1.6916\n",
      "Train Epoch: 2 [100160/110534 (91%)]\tAll Loss: 2.4375\tTriple Loss(1): 0.2947\tClassification Loss: 1.8480\n",
      "Train Epoch: 2 [100480/110534 (91%)]\tAll Loss: 2.3060\tTriple Loss(1): 0.3379\tClassification Loss: 1.6301\n",
      "Train Epoch: 2 [100800/110534 (91%)]\tAll Loss: 2.9281\tTriple Loss(1): 0.3593\tClassification Loss: 2.2094\n",
      "Train Epoch: 2 [101120/110534 (91%)]\tAll Loss: 2.1426\tTriple Loss(1): 0.3471\tClassification Loss: 1.4484\n",
      "Train Epoch: 2 [101440/110534 (92%)]\tAll Loss: 1.8111\tTriple Loss(1): 0.1888\tClassification Loss: 1.4334\n",
      "Train Epoch: 2 [101760/110534 (92%)]\tAll Loss: 2.3895\tTriple Loss(1): 0.3468\tClassification Loss: 1.6958\n",
      "Train Epoch: 2 [102080/110534 (92%)]\tAll Loss: 2.2525\tTriple Loss(1): 0.1657\tClassification Loss: 1.9212\n",
      "\n",
      "Test set: Average loss: 1.6635, Accuracy: 541/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [102400/110534 (93%)]\tAll Loss: 2.3588\tTriple Loss(1): 0.2714\tClassification Loss: 1.8161\n",
      "Train Epoch: 2 [102720/110534 (93%)]\tAll Loss: 2.5350\tTriple Loss(1): 0.3770\tClassification Loss: 1.7811\n",
      "Train Epoch: 2 [103040/110534 (93%)]\tAll Loss: 2.1051\tTriple Loss(1): 0.3401\tClassification Loss: 1.4248\n",
      "Train Epoch: 2 [103360/110534 (93%)]\tAll Loss: 1.9985\tTriple Loss(1): 0.0618\tClassification Loss: 1.8750\n",
      "Train Epoch: 2 [103680/110534 (94%)]\tAll Loss: 2.6616\tTriple Loss(1): 0.5040\tClassification Loss: 1.6536\n",
      "Train Epoch: 2 [104000/110534 (94%)]\tAll Loss: 1.5379\tTriple Loss(0): 0.0000\tClassification Loss: 1.5379\n",
      "Train Epoch: 2 [104320/110534 (94%)]\tAll Loss: 2.2485\tTriple Loss(1): 0.1496\tClassification Loss: 1.9494\n",
      "Train Epoch: 2 [104640/110534 (95%)]\tAll Loss: 2.3869\tTriple Loss(1): 0.1854\tClassification Loss: 2.0161\n",
      "Train Epoch: 2 [104960/110534 (95%)]\tAll Loss: 1.9741\tTriple Loss(1): 0.2553\tClassification Loss: 1.4635\n",
      "Train Epoch: 2 [105280/110534 (95%)]\tAll Loss: 2.1159\tTriple Loss(1): 0.2185\tClassification Loss: 1.6789\n",
      "\n",
      "Test set: Average loss: 1.6629, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [105600/110534 (96%)]\tAll Loss: 2.0852\tTriple Loss(1): 0.1616\tClassification Loss: 1.7619\n",
      "Train Epoch: 2 [105920/110534 (96%)]\tAll Loss: 2.0030\tTriple Loss(1): 0.1505\tClassification Loss: 1.7021\n",
      "Train Epoch: 2 [106240/110534 (96%)]\tAll Loss: 1.4003\tTriple Loss(0): 0.0000\tClassification Loss: 1.4003\n",
      "Train Epoch: 2 [106560/110534 (96%)]\tAll Loss: 1.6857\tTriple Loss(0): 0.0000\tClassification Loss: 1.6857\n",
      "Train Epoch: 2 [106880/110534 (97%)]\tAll Loss: 2.1564\tTriple Loss(0): 0.0000\tClassification Loss: 2.1564\n",
      "Train Epoch: 2 [107200/110534 (97%)]\tAll Loss: 3.1570\tTriple Loss(0): 0.6883\tClassification Loss: 1.7805\n",
      "Train Epoch: 2 [107520/110534 (97%)]\tAll Loss: 2.1602\tTriple Loss(1): 0.1613\tClassification Loss: 1.8377\n",
      "Train Epoch: 2 [107840/110534 (98%)]\tAll Loss: 2.2330\tTriple Loss(1): 0.3723\tClassification Loss: 1.4883\n",
      "Train Epoch: 2 [108160/110534 (98%)]\tAll Loss: 1.6095\tTriple Loss(1): 0.1682\tClassification Loss: 1.2731\n",
      "Train Epoch: 2 [108480/110534 (98%)]\tAll Loss: 2.2882\tTriple Loss(1): 0.3563\tClassification Loss: 1.5756\n",
      "\n",
      "Test set: Average loss: 1.6581, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [108800/110534 (98%)]\tAll Loss: 3.6565\tTriple Loss(0): 1.0185\tClassification Loss: 1.6195\n",
      "Train Epoch: 2 [109120/110534 (99%)]\tAll Loss: 2.5592\tTriple Loss(1): 0.2760\tClassification Loss: 2.0072\n",
      "Train Epoch: 2 [109440/110534 (99%)]\tAll Loss: 1.6302\tTriple Loss(0): 0.1109\tClassification Loss: 1.4083\n",
      "Train Epoch: 2 [109760/110534 (99%)]\tAll Loss: 1.8644\tTriple Loss(1): 0.1104\tClassification Loss: 1.6436\n",
      "Train Epoch: 2 [110080/110534 (100%)]\tAll Loss: 2.2714\tTriple Loss(1): 0.2779\tClassification Loss: 1.7155\n",
      "Train Epoch: 2 [110400/110534 (100%)]\tAll Loss: 2.0645\tTriple Loss(1): 0.2581\tClassification Loss: 1.5484\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_final.pth.tar\n",
      "\n",
      "Test set: Average loss: 1.6647, Accuracy: 532/960 (55%)\n",
      "\n",
      "Train Epoch: 3 [0/110534 (0%)]\tAll Loss: 1.9444\tTriple Loss(1): 0.1538\tClassification Loss: 1.6367\n",
      "Train Epoch: 3 [320/110534 (0%)]\tAll Loss: 1.9898\tTriple Loss(1): 0.2035\tClassification Loss: 1.5829\n",
      "Train Epoch: 3 [640/110534 (1%)]\tAll Loss: 1.8764\tTriple Loss(1): 0.4137\tClassification Loss: 1.0490\n",
      "Train Epoch: 3 [960/110534 (1%)]\tAll Loss: 2.5638\tTriple Loss(1): 0.2467\tClassification Loss: 2.0703\n",
      "Train Epoch: 3 [1280/110534 (1%)]\tAll Loss: 2.4402\tTriple Loss(1): 0.4695\tClassification Loss: 1.5012\n",
      "Train Epoch: 3 [1600/110534 (1%)]\tAll Loss: 2.3215\tTriple Loss(1): 0.2782\tClassification Loss: 1.7652\n",
      "Train Epoch: 3 [1920/110534 (2%)]\tAll Loss: 2.1047\tTriple Loss(1): 0.1371\tClassification Loss: 1.8304\n",
      "Train Epoch: 3 [2240/110534 (2%)]\tAll Loss: 1.7270\tTriple Loss(0): 0.0000\tClassification Loss: 1.7270\n",
      "Train Epoch: 3 [2560/110534 (2%)]\tAll Loss: 2.3596\tTriple Loss(1): 0.3298\tClassification Loss: 1.6999\n",
      "Train Epoch: 3 [2880/110534 (3%)]\tAll Loss: 2.0704\tTriple Loss(1): 0.1513\tClassification Loss: 1.7679\n",
      "\n",
      "Test set: Average loss: 1.6640, Accuracy: 541/960 (56%)\n",
      "\n",
      "Train Epoch: 3 [3200/110534 (3%)]\tAll Loss: 1.9580\tTriple Loss(0): 0.0000\tClassification Loss: 1.9580\n",
      "Train Epoch: 3 [3520/110534 (3%)]\tAll Loss: 1.6650\tTriple Loss(1): 0.1892\tClassification Loss: 1.2867\n",
      "Train Epoch: 3 [3840/110534 (3%)]\tAll Loss: 1.9112\tTriple Loss(1): 0.1232\tClassification Loss: 1.6649\n",
      "Train Epoch: 3 [4160/110534 (4%)]\tAll Loss: 2.2322\tTriple Loss(1): 0.3181\tClassification Loss: 1.5960\n",
      "Train Epoch: 3 [4480/110534 (4%)]\tAll Loss: 2.0191\tTriple Loss(1): 0.2481\tClassification Loss: 1.5228\n",
      "Train Epoch: 3 [4800/110534 (4%)]\tAll Loss: 1.5659\tTriple Loss(0): 0.0000\tClassification Loss: 1.5659\n",
      "Train Epoch: 3 [5120/110534 (5%)]\tAll Loss: 1.9423\tTriple Loss(1): 0.1386\tClassification Loss: 1.6650\n",
      "Train Epoch: 3 [5440/110534 (5%)]\tAll Loss: 2.2206\tTriple Loss(1): 0.2513\tClassification Loss: 1.7181\n",
      "Train Epoch: 3 [5760/110534 (5%)]\tAll Loss: 1.9764\tTriple Loss(1): 0.2503\tClassification Loss: 1.4758\n",
      "Train Epoch: 3 [6080/110534 (5%)]\tAll Loss: 2.1138\tTriple Loss(1): 0.2574\tClassification Loss: 1.5990\n",
      "\n",
      "Test set: Average loss: 1.6543, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [6400/110534 (6%)]\tAll Loss: 2.2415\tTriple Loss(1): 0.2315\tClassification Loss: 1.7785\n",
      "Train Epoch: 3 [6720/110534 (6%)]\tAll Loss: 1.9133\tTriple Loss(1): 0.1847\tClassification Loss: 1.5440\n",
      "Train Epoch: 3 [7040/110534 (6%)]\tAll Loss: 1.8251\tTriple Loss(0): 0.0000\tClassification Loss: 1.8251\n",
      "Train Epoch: 3 [7360/110534 (7%)]\tAll Loss: 2.0961\tTriple Loss(1): 0.2942\tClassification Loss: 1.5077\n",
      "Train Epoch: 3 [7680/110534 (7%)]\tAll Loss: 1.2267\tTriple Loss(0): 0.0000\tClassification Loss: 1.2267\n",
      "Train Epoch: 3 [8000/110534 (7%)]\tAll Loss: 2.3039\tTriple Loss(1): 0.4791\tClassification Loss: 1.3456\n",
      "Train Epoch: 3 [8320/110534 (8%)]\tAll Loss: 1.7519\tTriple Loss(1): 0.1040\tClassification Loss: 1.5439\n",
      "Train Epoch: 3 [8640/110534 (8%)]\tAll Loss: 1.9910\tTriple Loss(1): 0.3813\tClassification Loss: 1.2284\n",
      "Train Epoch: 3 [8960/110534 (8%)]\tAll Loss: 1.9546\tTriple Loss(1): 0.2521\tClassification Loss: 1.4503\n",
      "Train Epoch: 3 [9280/110534 (8%)]\tAll Loss: 1.7522\tTriple Loss(1): 0.2007\tClassification Loss: 1.3508\n",
      "\n",
      "Test set: Average loss: 1.6493, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [9600/110534 (9%)]\tAll Loss: 2.3714\tTriple Loss(1): 0.3017\tClassification Loss: 1.7680\n",
      "Train Epoch: 3 [9920/110534 (9%)]\tAll Loss: 2.1995\tTriple Loss(1): 0.2789\tClassification Loss: 1.6416\n",
      "Train Epoch: 3 [10240/110534 (9%)]\tAll Loss: 2.3498\tTriple Loss(1): 0.2461\tClassification Loss: 1.8576\n",
      "Train Epoch: 3 [10560/110534 (10%)]\tAll Loss: 2.1456\tTriple Loss(1): 0.1719\tClassification Loss: 1.8018\n",
      "Train Epoch: 3 [10880/110534 (10%)]\tAll Loss: 2.6118\tTriple Loss(1): 0.3696\tClassification Loss: 1.8726\n",
      "Train Epoch: 3 [11200/110534 (10%)]\tAll Loss: 1.7860\tTriple Loss(1): 0.2594\tClassification Loss: 1.2672\n",
      "Train Epoch: 3 [11520/110534 (10%)]\tAll Loss: 1.5803\tTriple Loss(0): 0.0000\tClassification Loss: 1.5803\n",
      "Train Epoch: 3 [11840/110534 (11%)]\tAll Loss: 2.0584\tTriple Loss(1): 0.1707\tClassification Loss: 1.7170\n",
      "Train Epoch: 3 [12160/110534 (11%)]\tAll Loss: 1.8099\tTriple Loss(0): 0.0000\tClassification Loss: 1.8099\n",
      "Train Epoch: 3 [12480/110534 (11%)]\tAll Loss: 2.2176\tTriple Loss(1): 0.2333\tClassification Loss: 1.7510\n",
      "\n",
      "Test set: Average loss: 1.6532, Accuracy: 551/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [12800/110534 (12%)]\tAll Loss: 2.1384\tTriple Loss(1): 0.3221\tClassification Loss: 1.4943\n",
      "Train Epoch: 3 [13120/110534 (12%)]\tAll Loss: 1.3973\tTriple Loss(0): 0.0000\tClassification Loss: 1.3973\n",
      "Train Epoch: 3 [13440/110534 (12%)]\tAll Loss: 1.9962\tTriple Loss(0): 0.0000\tClassification Loss: 1.9962\n",
      "Train Epoch: 3 [13760/110534 (12%)]\tAll Loss: 2.0375\tTriple Loss(1): 0.1760\tClassification Loss: 1.6855\n",
      "Train Epoch: 3 [14080/110534 (13%)]\tAll Loss: 2.3512\tTriple Loss(1): 0.3113\tClassification Loss: 1.7287\n",
      "Train Epoch: 3 [14400/110534 (13%)]\tAll Loss: 2.6253\tTriple Loss(1): 0.2240\tClassification Loss: 2.1773\n",
      "Train Epoch: 3 [14720/110534 (13%)]\tAll Loss: 2.2869\tTriple Loss(1): 0.2412\tClassification Loss: 1.8046\n",
      "Train Epoch: 3 [15040/110534 (14%)]\tAll Loss: 2.0509\tTriple Loss(1): 0.3294\tClassification Loss: 1.3922\n",
      "Train Epoch: 3 [15360/110534 (14%)]\tAll Loss: 1.8597\tTriple Loss(1): 0.1985\tClassification Loss: 1.4626\n",
      "Train Epoch: 3 [15680/110534 (14%)]\tAll Loss: 1.4384\tTriple Loss(0): 0.0000\tClassification Loss: 1.4384\n",
      "\n",
      "Test set: Average loss: 1.6466, Accuracy: 544/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [16000/110534 (14%)]\tAll Loss: 5.7329\tTriple Loss(0): 1.9399\tClassification Loss: 1.8530\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_500.pth.tar\n",
      "Train Epoch: 3 [16320/110534 (15%)]\tAll Loss: 1.8269\tTriple Loss(1): 0.2669\tClassification Loss: 1.2931\n",
      "Train Epoch: 3 [16640/110534 (15%)]\tAll Loss: 1.9150\tTriple Loss(1): 0.1821\tClassification Loss: 1.5508\n",
      "Train Epoch: 3 [16960/110534 (15%)]\tAll Loss: 1.9914\tTriple Loss(0): 0.0000\tClassification Loss: 1.9914\n",
      "Train Epoch: 3 [17280/110534 (16%)]\tAll Loss: 1.6781\tTriple Loss(1): 0.1296\tClassification Loss: 1.4189\n",
      "Train Epoch: 3 [17600/110534 (16%)]\tAll Loss: 2.4527\tTriple Loss(1): 0.3734\tClassification Loss: 1.7059\n",
      "Train Epoch: 3 [17920/110534 (16%)]\tAll Loss: 2.0821\tTriple Loss(1): 0.1518\tClassification Loss: 1.7784\n",
      "Train Epoch: 3 [18240/110534 (16%)]\tAll Loss: 2.0339\tTriple Loss(1): 0.0604\tClassification Loss: 1.9131\n",
      "Train Epoch: 3 [18560/110534 (17%)]\tAll Loss: 1.9909\tTriple Loss(1): 0.2292\tClassification Loss: 1.5326\n",
      "Train Epoch: 3 [18880/110534 (17%)]\tAll Loss: 2.1103\tTriple Loss(1): 0.2532\tClassification Loss: 1.6040\n",
      "\n",
      "Test set: Average loss: 1.6454, Accuracy: 552/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [19200/110534 (17%)]\tAll Loss: 1.4262\tTriple Loss(0): 0.0000\tClassification Loss: 1.4262\n",
      "Train Epoch: 3 [19520/110534 (18%)]\tAll Loss: 2.1427\tTriple Loss(1): 0.2295\tClassification Loss: 1.6836\n",
      "Train Epoch: 3 [19840/110534 (18%)]\tAll Loss: 2.3921\tTriple Loss(1): 0.3755\tClassification Loss: 1.6411\n",
      "Train Epoch: 3 [20160/110534 (18%)]\tAll Loss: 1.9291\tTriple Loss(1): 0.1303\tClassification Loss: 1.6686\n",
      "Train Epoch: 3 [20480/110534 (19%)]\tAll Loss: 1.9943\tTriple Loss(1): 0.2876\tClassification Loss: 1.4191\n",
      "Train Epoch: 3 [20800/110534 (19%)]\tAll Loss: 3.3002\tTriple Loss(1): 0.5478\tClassification Loss: 2.2047\n",
      "Train Epoch: 3 [21120/110534 (19%)]\tAll Loss: 1.9359\tTriple Loss(1): 0.2321\tClassification Loss: 1.4717\n",
      "Train Epoch: 3 [21440/110534 (19%)]\tAll Loss: 2.3040\tTriple Loss(1): 0.4554\tClassification Loss: 1.3932\n",
      "Train Epoch: 3 [21760/110534 (20%)]\tAll Loss: 2.4705\tTriple Loss(1): 0.2163\tClassification Loss: 2.0378\n",
      "Train Epoch: 3 [22080/110534 (20%)]\tAll Loss: 2.0128\tTriple Loss(1): 0.1486\tClassification Loss: 1.7155\n",
      "\n",
      "Test set: Average loss: 1.6504, Accuracy: 529/960 (55%)\n",
      "\n",
      "Train Epoch: 3 [22400/110534 (20%)]\tAll Loss: 2.2688\tTriple Loss(1): 0.3205\tClassification Loss: 1.6279\n",
      "Train Epoch: 3 [22720/110534 (21%)]\tAll Loss: 1.6511\tTriple Loss(0): 0.0000\tClassification Loss: 1.6511\n",
      "Train Epoch: 3 [23040/110534 (21%)]\tAll Loss: 1.6268\tTriple Loss(0): 0.0000\tClassification Loss: 1.6268\n",
      "Train Epoch: 3 [23360/110534 (21%)]\tAll Loss: 1.6899\tTriple Loss(1): 0.0578\tClassification Loss: 1.5742\n",
      "Train Epoch: 3 [23680/110534 (21%)]\tAll Loss: 2.2949\tTriple Loss(1): 0.2079\tClassification Loss: 1.8791\n",
      "Train Epoch: 3 [24000/110534 (22%)]\tAll Loss: 2.3342\tTriple Loss(1): 0.4290\tClassification Loss: 1.4762\n",
      "Train Epoch: 3 [24320/110534 (22%)]\tAll Loss: 2.2253\tTriple Loss(1): 0.2651\tClassification Loss: 1.6951\n",
      "Train Epoch: 3 [24640/110534 (22%)]\tAll Loss: 2.0580\tTriple Loss(0): 0.0000\tClassification Loss: 2.0580\n",
      "Train Epoch: 3 [24960/110534 (23%)]\tAll Loss: 1.9726\tTriple Loss(1): 0.2246\tClassification Loss: 1.5233\n",
      "Train Epoch: 3 [25280/110534 (23%)]\tAll Loss: 2.2613\tTriple Loss(1): 0.3067\tClassification Loss: 1.6479\n",
      "\n",
      "Test set: Average loss: 1.6415, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [25600/110534 (23%)]\tAll Loss: 1.5874\tTriple Loss(0): 0.0000\tClassification Loss: 1.5874\n",
      "Train Epoch: 3 [25920/110534 (23%)]\tAll Loss: 2.3986\tTriple Loss(1): 0.3505\tClassification Loss: 1.6977\n",
      "Train Epoch: 3 [26240/110534 (24%)]\tAll Loss: 2.6749\tTriple Loss(1): 0.5807\tClassification Loss: 1.5135\n",
      "Train Epoch: 3 [26560/110534 (24%)]\tAll Loss: 2.4483\tTriple Loss(1): 0.3346\tClassification Loss: 1.7791\n",
      "Train Epoch: 3 [26880/110534 (24%)]\tAll Loss: 1.8399\tTriple Loss(0): 0.0000\tClassification Loss: 1.8399\n",
      "Train Epoch: 3 [27200/110534 (25%)]\tAll Loss: 2.4215\tTriple Loss(1): 0.2254\tClassification Loss: 1.9707\n",
      "Train Epoch: 3 [27520/110534 (25%)]\tAll Loss: 1.8356\tTriple Loss(1): 0.1488\tClassification Loss: 1.5380\n",
      "Train Epoch: 3 [27840/110534 (25%)]\tAll Loss: 1.8149\tTriple Loss(1): 0.1800\tClassification Loss: 1.4548\n",
      "Train Epoch: 3 [28160/110534 (25%)]\tAll Loss: 2.3969\tTriple Loss(1): 0.2692\tClassification Loss: 1.8585\n",
      "Train Epoch: 3 [28480/110534 (26%)]\tAll Loss: 2.3744\tTriple Loss(1): 0.2819\tClassification Loss: 1.8106\n",
      "\n",
      "Test set: Average loss: 1.6448, Accuracy: 557/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [28800/110534 (26%)]\tAll Loss: 1.6487\tTriple Loss(1): 0.1860\tClassification Loss: 1.2767\n",
      "Train Epoch: 3 [29120/110534 (26%)]\tAll Loss: 2.2537\tTriple Loss(1): 0.2628\tClassification Loss: 1.7282\n",
      "Train Epoch: 3 [29440/110534 (27%)]\tAll Loss: 1.4078\tTriple Loss(0): 0.0000\tClassification Loss: 1.4078\n",
      "Train Epoch: 3 [29760/110534 (27%)]\tAll Loss: 1.6080\tTriple Loss(1): 0.1991\tClassification Loss: 1.2098\n",
      "Train Epoch: 3 [30080/110534 (27%)]\tAll Loss: 1.5150\tTriple Loss(1): 0.0758\tClassification Loss: 1.3634\n",
      "Train Epoch: 3 [30400/110534 (27%)]\tAll Loss: 1.7987\tTriple Loss(1): 0.2249\tClassification Loss: 1.3489\n",
      "Train Epoch: 3 [30720/110534 (28%)]\tAll Loss: 2.1277\tTriple Loss(1): 0.4177\tClassification Loss: 1.2922\n",
      "Train Epoch: 3 [31040/110534 (28%)]\tAll Loss: 2.1116\tTriple Loss(1): 0.1590\tClassification Loss: 1.7937\n",
      "Train Epoch: 3 [31360/110534 (28%)]\tAll Loss: 2.2025\tTriple Loss(1): 0.2723\tClassification Loss: 1.6578\n",
      "Train Epoch: 3 [31680/110534 (29%)]\tAll Loss: 1.8642\tTriple Loss(1): 0.1463\tClassification Loss: 1.5716\n",
      "\n",
      "Test set: Average loss: 1.6380, Accuracy: 550/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [32000/110534 (29%)]\tAll Loss: 1.9004\tTriple Loss(1): 0.0000\tClassification Loss: 1.9004\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_1000.pth.tar\n",
      "Train Epoch: 3 [32320/110534 (29%)]\tAll Loss: 1.9250\tTriple Loss(1): 0.1913\tClassification Loss: 1.5425\n",
      "Train Epoch: 3 [32640/110534 (30%)]\tAll Loss: 1.9585\tTriple Loss(1): 0.2242\tClassification Loss: 1.5100\n",
      "Train Epoch: 3 [32960/110534 (30%)]\tAll Loss: 1.9648\tTriple Loss(1): 0.1368\tClassification Loss: 1.6911\n",
      "Train Epoch: 3 [33280/110534 (30%)]\tAll Loss: 2.2617\tTriple Loss(1): 0.2602\tClassification Loss: 1.7412\n",
      "Train Epoch: 3 [33600/110534 (30%)]\tAll Loss: 1.5912\tTriple Loss(0): 0.0000\tClassification Loss: 1.5912\n",
      "Train Epoch: 3 [33920/110534 (31%)]\tAll Loss: 2.0048\tTriple Loss(1): 0.2263\tClassification Loss: 1.5522\n",
      "Train Epoch: 3 [34240/110534 (31%)]\tAll Loss: 2.5789\tTriple Loss(1): 0.3772\tClassification Loss: 1.8244\n",
      "Train Epoch: 3 [34560/110534 (31%)]\tAll Loss: 2.0613\tTriple Loss(1): 0.3154\tClassification Loss: 1.4305\n",
      "Train Epoch: 3 [34880/110534 (32%)]\tAll Loss: 1.7031\tTriple Loss(1): 0.0676\tClassification Loss: 1.5680\n",
      "\n",
      "Test set: Average loss: 1.6343, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [35200/110534 (32%)]\tAll Loss: 2.4243\tTriple Loss(1): 0.1646\tClassification Loss: 2.0950\n",
      "Train Epoch: 3 [35520/110534 (32%)]\tAll Loss: 1.6794\tTriple Loss(0): 0.0000\tClassification Loss: 1.6794\n",
      "Train Epoch: 3 [35840/110534 (32%)]\tAll Loss: 1.6273\tTriple Loss(1): 0.1516\tClassification Loss: 1.3240\n",
      "Train Epoch: 3 [36160/110534 (33%)]\tAll Loss: 2.2452\tTriple Loss(1): 0.3345\tClassification Loss: 1.5762\n",
      "Train Epoch: 3 [36480/110534 (33%)]\tAll Loss: 2.0733\tTriple Loss(1): 0.1947\tClassification Loss: 1.6839\n",
      "Train Epoch: 3 [36800/110534 (33%)]\tAll Loss: 2.4671\tTriple Loss(1): 0.3269\tClassification Loss: 1.8133\n",
      "Train Epoch: 3 [37120/110534 (34%)]\tAll Loss: 2.2441\tTriple Loss(1): 0.1563\tClassification Loss: 1.9315\n",
      "Train Epoch: 3 [37440/110534 (34%)]\tAll Loss: 1.9050\tTriple Loss(1): 0.1263\tClassification Loss: 1.6523\n",
      "Train Epoch: 3 [37760/110534 (34%)]\tAll Loss: 1.6936\tTriple Loss(1): 0.0529\tClassification Loss: 1.5879\n",
      "Train Epoch: 3 [38080/110534 (34%)]\tAll Loss: 1.9887\tTriple Loss(1): 0.0907\tClassification Loss: 1.8073\n",
      "\n",
      "Test set: Average loss: 1.6415, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [38400/110534 (35%)]\tAll Loss: 1.3891\tTriple Loss(0): 0.0000\tClassification Loss: 1.3891\n",
      "Train Epoch: 3 [38720/110534 (35%)]\tAll Loss: 2.5951\tTriple Loss(1): 0.3112\tClassification Loss: 1.9727\n",
      "Train Epoch: 3 [39040/110534 (35%)]\tAll Loss: 1.4274\tTriple Loss(0): 0.0000\tClassification Loss: 1.4274\n",
      "Train Epoch: 3 [39360/110534 (36%)]\tAll Loss: 1.3725\tTriple Loss(0): 0.0000\tClassification Loss: 1.3725\n",
      "Train Epoch: 3 [39680/110534 (36%)]\tAll Loss: 2.1414\tTriple Loss(1): 0.1849\tClassification Loss: 1.7715\n",
      "Train Epoch: 3 [40000/110534 (36%)]\tAll Loss: 1.7204\tTriple Loss(1): 0.2208\tClassification Loss: 1.2789\n",
      "Train Epoch: 3 [40320/110534 (36%)]\tAll Loss: 2.0371\tTriple Loss(1): 0.1190\tClassification Loss: 1.7991\n",
      "Train Epoch: 3 [40640/110534 (37%)]\tAll Loss: 2.2603\tTriple Loss(1): 0.2372\tClassification Loss: 1.7858\n",
      "Train Epoch: 3 [40960/110534 (37%)]\tAll Loss: 1.5412\tTriple Loss(0): 0.0000\tClassification Loss: 1.5412\n",
      "Train Epoch: 3 [41280/110534 (37%)]\tAll Loss: 2.0678\tTriple Loss(1): 0.2143\tClassification Loss: 1.6391\n",
      "\n",
      "Test set: Average loss: 1.6333, Accuracy: 547/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [41600/110534 (38%)]\tAll Loss: 1.6474\tTriple Loss(1): 0.0368\tClassification Loss: 1.5737\n",
      "Train Epoch: 3 [41920/110534 (38%)]\tAll Loss: 1.9990\tTriple Loss(1): 0.1882\tClassification Loss: 1.6227\n",
      "Train Epoch: 3 [42240/110534 (38%)]\tAll Loss: 1.7048\tTriple Loss(0): 0.0000\tClassification Loss: 1.7048\n",
      "Train Epoch: 3 [42560/110534 (38%)]\tAll Loss: 1.7313\tTriple Loss(1): 0.1665\tClassification Loss: 1.3983\n",
      "Train Epoch: 3 [42880/110534 (39%)]\tAll Loss: 1.6392\tTriple Loss(0): 0.0000\tClassification Loss: 1.6392\n",
      "Train Epoch: 3 [43200/110534 (39%)]\tAll Loss: 1.7118\tTriple Loss(0): 0.0000\tClassification Loss: 1.7118\n",
      "Train Epoch: 3 [43520/110534 (39%)]\tAll Loss: 1.9168\tTriple Loss(1): 0.2374\tClassification Loss: 1.4420\n",
      "Train Epoch: 3 [43840/110534 (40%)]\tAll Loss: 2.2104\tTriple Loss(1): 0.2632\tClassification Loss: 1.6840\n",
      "Train Epoch: 3 [44160/110534 (40%)]\tAll Loss: 2.5213\tTriple Loss(1): 0.2113\tClassification Loss: 2.0987\n",
      "Train Epoch: 3 [44480/110534 (40%)]\tAll Loss: 1.6990\tTriple Loss(0): 0.0000\tClassification Loss: 1.6990\n",
      "\n",
      "Test set: Average loss: 1.6327, Accuracy: 562/960 (59%)\n",
      "\n",
      "Train Epoch: 3 [44800/110534 (41%)]\tAll Loss: 1.8694\tTriple Loss(1): 0.2851\tClassification Loss: 1.2992\n",
      "Train Epoch: 3 [45120/110534 (41%)]\tAll Loss: 1.8155\tTriple Loss(1): 0.0417\tClassification Loss: 1.7322\n",
      "Train Epoch: 3 [45440/110534 (41%)]\tAll Loss: 1.6589\tTriple Loss(1): 0.1390\tClassification Loss: 1.3808\n",
      "Train Epoch: 3 [45760/110534 (41%)]\tAll Loss: 1.6444\tTriple Loss(1): 0.1431\tClassification Loss: 1.3582\n",
      "Train Epoch: 3 [46080/110534 (42%)]\tAll Loss: 1.8285\tTriple Loss(1): 0.2568\tClassification Loss: 1.3149\n",
      "Train Epoch: 3 [46400/110534 (42%)]\tAll Loss: 2.0277\tTriple Loss(0): 0.0000\tClassification Loss: 2.0277\n",
      "Train Epoch: 3 [46720/110534 (42%)]\tAll Loss: 2.4568\tTriple Loss(1): 0.2478\tClassification Loss: 1.9612\n",
      "Train Epoch: 3 [47040/110534 (43%)]\tAll Loss: 2.2700\tTriple Loss(1): 0.3820\tClassification Loss: 1.5059\n",
      "Train Epoch: 3 [47360/110534 (43%)]\tAll Loss: 2.3403\tTriple Loss(1): 0.3601\tClassification Loss: 1.6201\n",
      "Train Epoch: 3 [47680/110534 (43%)]\tAll Loss: 1.6766\tTriple Loss(1): 0.2061\tClassification Loss: 1.2645\n",
      "\n",
      "Test set: Average loss: 1.6363, Accuracy: 541/960 (56%)\n",
      "\n",
      "Train Epoch: 3 [48000/110534 (43%)]\tAll Loss: 2.3369\tTriple Loss(1): 0.1846\tClassification Loss: 1.9678\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_1500.pth.tar\n",
      "Train Epoch: 3 [48320/110534 (44%)]\tAll Loss: 2.0344\tTriple Loss(1): 0.2491\tClassification Loss: 1.5362\n",
      "Train Epoch: 3 [48640/110534 (44%)]\tAll Loss: 2.5994\tTriple Loss(1): 0.3193\tClassification Loss: 1.9608\n",
      "Train Epoch: 3 [48960/110534 (44%)]\tAll Loss: 2.0912\tTriple Loss(1): 0.3516\tClassification Loss: 1.3881\n",
      "Train Epoch: 3 [49280/110534 (45%)]\tAll Loss: 1.9475\tTriple Loss(1): 0.2019\tClassification Loss: 1.5438\n",
      "Train Epoch: 3 [49600/110534 (45%)]\tAll Loss: 3.9717\tTriple Loss(0): 1.1959\tClassification Loss: 1.5799\n",
      "Train Epoch: 3 [49920/110534 (45%)]\tAll Loss: 1.9204\tTriple Loss(1): 0.3578\tClassification Loss: 1.2049\n",
      "Train Epoch: 3 [50240/110534 (45%)]\tAll Loss: 1.9564\tTriple Loss(1): 0.3390\tClassification Loss: 1.2785\n",
      "Train Epoch: 3 [50560/110534 (46%)]\tAll Loss: 2.3836\tTriple Loss(1): 0.3028\tClassification Loss: 1.7781\n",
      "Train Epoch: 3 [50880/110534 (46%)]\tAll Loss: 2.3294\tTriple Loss(1): 0.3235\tClassification Loss: 1.6824\n",
      "\n",
      "Test set: Average loss: 1.6281, Accuracy: 560/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [51200/110534 (46%)]\tAll Loss: 1.4515\tTriple Loss(0): 0.0000\tClassification Loss: 1.4515\n",
      "Train Epoch: 3 [51520/110534 (47%)]\tAll Loss: 2.0303\tTriple Loss(1): 0.3244\tClassification Loss: 1.3816\n",
      "Train Epoch: 3 [51840/110534 (47%)]\tAll Loss: 1.9317\tTriple Loss(1): 0.1772\tClassification Loss: 1.5773\n",
      "Train Epoch: 3 [52160/110534 (47%)]\tAll Loss: 2.1229\tTriple Loss(1): 0.2072\tClassification Loss: 1.7084\n",
      "Train Epoch: 3 [52480/110534 (47%)]\tAll Loss: 2.8164\tTriple Loss(1): 0.2314\tClassification Loss: 2.3536\n",
      "Train Epoch: 3 [52800/110534 (48%)]\tAll Loss: 1.3932\tTriple Loss(0): 0.0000\tClassification Loss: 1.3932\n",
      "Train Epoch: 3 [53120/110534 (48%)]\tAll Loss: 2.0384\tTriple Loss(1): 0.2116\tClassification Loss: 1.6152\n",
      "Train Epoch: 3 [53440/110534 (48%)]\tAll Loss: 2.2906\tTriple Loss(1): 0.2513\tClassification Loss: 1.7880\n",
      "Train Epoch: 3 [53760/110534 (49%)]\tAll Loss: 1.9553\tTriple Loss(1): 0.1013\tClassification Loss: 1.7526\n",
      "Train Epoch: 3 [54080/110534 (49%)]\tAll Loss: 2.4975\tTriple Loss(1): 0.2097\tClassification Loss: 2.0781\n",
      "\n",
      "Test set: Average loss: 1.6343, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [54400/110534 (49%)]\tAll Loss: 2.2396\tTriple Loss(1): 0.1844\tClassification Loss: 1.8708\n",
      "Train Epoch: 3 [54720/110534 (49%)]\tAll Loss: 2.0620\tTriple Loss(1): 0.1597\tClassification Loss: 1.7426\n",
      "Train Epoch: 3 [55040/110534 (50%)]\tAll Loss: 2.2182\tTriple Loss(1): 0.1242\tClassification Loss: 1.9698\n",
      "Train Epoch: 3 [55360/110534 (50%)]\tAll Loss: 2.2291\tTriple Loss(1): 0.3018\tClassification Loss: 1.6255\n",
      "Train Epoch: 3 [55680/110534 (50%)]\tAll Loss: 2.3113\tTriple Loss(1): 0.2009\tClassification Loss: 1.9096\n",
      "Train Epoch: 3 [56000/110534 (51%)]\tAll Loss: 2.5859\tTriple Loss(1): 0.2457\tClassification Loss: 2.0945\n",
      "Train Epoch: 3 [56320/110534 (51%)]\tAll Loss: 2.3593\tTriple Loss(1): 0.3034\tClassification Loss: 1.7525\n",
      "Train Epoch: 3 [56640/110534 (51%)]\tAll Loss: 1.6820\tTriple Loss(1): 0.2259\tClassification Loss: 1.2303\n",
      "Train Epoch: 3 [56960/110534 (52%)]\tAll Loss: 1.5436\tTriple Loss(0): 0.0000\tClassification Loss: 1.5436\n",
      "Train Epoch: 3 [57280/110534 (52%)]\tAll Loss: 2.0458\tTriple Loss(1): 0.0676\tClassification Loss: 1.9107\n",
      "\n",
      "Test set: Average loss: 1.6301, Accuracy: 555/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [57600/110534 (52%)]\tAll Loss: 2.2502\tTriple Loss(1): 0.2137\tClassification Loss: 1.8229\n",
      "Train Epoch: 3 [57920/110534 (52%)]\tAll Loss: 1.7763\tTriple Loss(1): 0.0711\tClassification Loss: 1.6341\n",
      "Train Epoch: 3 [58240/110534 (53%)]\tAll Loss: 2.2550\tTriple Loss(1): 0.4140\tClassification Loss: 1.4270\n",
      "Train Epoch: 3 [58560/110534 (53%)]\tAll Loss: 2.1723\tTriple Loss(1): 0.3453\tClassification Loss: 1.4817\n",
      "Train Epoch: 3 [58880/110534 (53%)]\tAll Loss: 1.6535\tTriple Loss(0): 0.0000\tClassification Loss: 1.6535\n",
      "Train Epoch: 3 [59200/110534 (54%)]\tAll Loss: 2.2643\tTriple Loss(1): 0.1647\tClassification Loss: 1.9349\n",
      "Train Epoch: 3 [59520/110534 (54%)]\tAll Loss: 2.0145\tTriple Loss(0): 0.2686\tClassification Loss: 1.4773\n",
      "Train Epoch: 3 [59840/110534 (54%)]\tAll Loss: 2.2136\tTriple Loss(1): 0.3250\tClassification Loss: 1.5636\n",
      "Train Epoch: 3 [60160/110534 (54%)]\tAll Loss: 2.4810\tTriple Loss(0): 0.5369\tClassification Loss: 1.4072\n",
      "Train Epoch: 3 [60480/110534 (55%)]\tAll Loss: 1.6357\tTriple Loss(0): 0.0000\tClassification Loss: 1.6357\n",
      "\n",
      "Test set: Average loss: 1.6252, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [60800/110534 (55%)]\tAll Loss: 2.0973\tTriple Loss(1): 0.1624\tClassification Loss: 1.7725\n",
      "Train Epoch: 3 [61120/110534 (55%)]\tAll Loss: 2.3301\tTriple Loss(1): 0.2503\tClassification Loss: 1.8295\n",
      "Train Epoch: 3 [61440/110534 (56%)]\tAll Loss: 1.4669\tTriple Loss(1): 0.1950\tClassification Loss: 1.0768\n",
      "Train Epoch: 3 [61760/110534 (56%)]\tAll Loss: 2.2899\tTriple Loss(1): 0.2767\tClassification Loss: 1.7364\n",
      "Train Epoch: 3 [62080/110534 (56%)]\tAll Loss: 2.1694\tTriple Loss(1): 0.3168\tClassification Loss: 1.5358\n",
      "Train Epoch: 3 [62400/110534 (56%)]\tAll Loss: 2.1228\tTriple Loss(1): 0.1726\tClassification Loss: 1.7776\n",
      "Train Epoch: 3 [62720/110534 (57%)]\tAll Loss: 2.0449\tTriple Loss(1): 0.2825\tClassification Loss: 1.4800\n",
      "Train Epoch: 3 [63040/110534 (57%)]\tAll Loss: 2.3214\tTriple Loss(1): 0.2305\tClassification Loss: 1.8605\n",
      "Train Epoch: 3 [63360/110534 (57%)]\tAll Loss: 1.5930\tTriple Loss(0): 0.0000\tClassification Loss: 1.5930\n",
      "Train Epoch: 3 [63680/110534 (58%)]\tAll Loss: 1.6754\tTriple Loss(1): 0.0742\tClassification Loss: 1.5271\n",
      "\n",
      "Test set: Average loss: 1.6292, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [64000/110534 (58%)]\tAll Loss: 3.0538\tTriple Loss(1): 0.3916\tClassification Loss: 2.2706\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_2000.pth.tar\n",
      "Train Epoch: 3 [64320/110534 (58%)]\tAll Loss: 1.7263\tTriple Loss(1): 0.2333\tClassification Loss: 1.2598\n",
      "Train Epoch: 3 [64640/110534 (58%)]\tAll Loss: 3.1154\tTriple Loss(1): 0.3322\tClassification Loss: 2.4511\n",
      "Train Epoch: 3 [64960/110534 (59%)]\tAll Loss: 2.0358\tTriple Loss(1): 0.2198\tClassification Loss: 1.5961\n",
      "Train Epoch: 3 [65280/110534 (59%)]\tAll Loss: 2.3008\tTriple Loss(1): 0.2593\tClassification Loss: 1.7821\n",
      "Train Epoch: 3 [65600/110534 (59%)]\tAll Loss: 1.9665\tTriple Loss(1): 0.1795\tClassification Loss: 1.6074\n",
      "Train Epoch: 3 [65920/110534 (60%)]\tAll Loss: 2.3238\tTriple Loss(1): 0.3190\tClassification Loss: 1.6857\n",
      "Train Epoch: 3 [66240/110534 (60%)]\tAll Loss: 1.5704\tTriple Loss(0): 0.0000\tClassification Loss: 1.5704\n",
      "Train Epoch: 3 [66560/110534 (60%)]\tAll Loss: 1.5376\tTriple Loss(1): 0.1062\tClassification Loss: 1.3253\n",
      "Train Epoch: 3 [66880/110534 (60%)]\tAll Loss: 2.0282\tTriple Loss(1): 0.1186\tClassification Loss: 1.7910\n",
      "\n",
      "Test set: Average loss: 1.6257, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [67200/110534 (61%)]\tAll Loss: 2.1903\tTriple Loss(1): 0.2226\tClassification Loss: 1.7452\n",
      "Train Epoch: 3 [67520/110534 (61%)]\tAll Loss: 2.4715\tTriple Loss(1): 0.2599\tClassification Loss: 1.9517\n",
      "Train Epoch: 3 [67840/110534 (61%)]\tAll Loss: 1.9117\tTriple Loss(0): 0.0000\tClassification Loss: 1.9117\n",
      "Train Epoch: 3 [68160/110534 (62%)]\tAll Loss: 1.5613\tTriple Loss(1): 0.0740\tClassification Loss: 1.4133\n",
      "Train Epoch: 3 [68480/110534 (62%)]\tAll Loss: 1.8814\tTriple Loss(1): 0.2353\tClassification Loss: 1.4107\n",
      "Train Epoch: 3 [68800/110534 (62%)]\tAll Loss: 2.3777\tTriple Loss(0): 0.5468\tClassification Loss: 1.2841\n",
      "Train Epoch: 3 [69120/110534 (63%)]\tAll Loss: 11.8949\tTriple Loss(0): 5.1917\tClassification Loss: 1.5115\n",
      "Train Epoch: 3 [69440/110534 (63%)]\tAll Loss: 2.0683\tTriple Loss(1): 0.2568\tClassification Loss: 1.5547\n",
      "Train Epoch: 3 [69760/110534 (63%)]\tAll Loss: 2.0952\tTriple Loss(1): 0.1475\tClassification Loss: 1.8003\n",
      "Train Epoch: 3 [70080/110534 (63%)]\tAll Loss: 1.5824\tTriple Loss(0): 0.0000\tClassification Loss: 1.5824\n",
      "\n",
      "Test set: Average loss: 1.6151, Accuracy: 560/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [70400/110534 (64%)]\tAll Loss: 1.7463\tTriple Loss(1): 0.1076\tClassification Loss: 1.5311\n",
      "Train Epoch: 3 [70720/110534 (64%)]\tAll Loss: 1.3627\tTriple Loss(0): 0.0000\tClassification Loss: 1.3627\n",
      "Train Epoch: 3 [71040/110534 (64%)]\tAll Loss: 1.9133\tTriple Loss(1): 0.1860\tClassification Loss: 1.5414\n",
      "Train Epoch: 3 [71360/110534 (65%)]\tAll Loss: 2.1963\tTriple Loss(1): 0.2752\tClassification Loss: 1.6460\n",
      "Train Epoch: 3 [71680/110534 (65%)]\tAll Loss: 1.8167\tTriple Loss(1): 0.1437\tClassification Loss: 1.5293\n",
      "Train Epoch: 3 [72000/110534 (65%)]\tAll Loss: 2.1869\tTriple Loss(1): 0.2321\tClassification Loss: 1.7227\n",
      "Train Epoch: 3 [72320/110534 (65%)]\tAll Loss: 1.4786\tTriple Loss(0): 0.0000\tClassification Loss: 1.4786\n",
      "Train Epoch: 3 [72640/110534 (66%)]\tAll Loss: 1.8234\tTriple Loss(1): 0.2448\tClassification Loss: 1.3338\n",
      "Train Epoch: 3 [72960/110534 (66%)]\tAll Loss: 1.6790\tTriple Loss(1): 0.1109\tClassification Loss: 1.4571\n",
      "Train Epoch: 3 [73280/110534 (66%)]\tAll Loss: 1.6978\tTriple Loss(1): 0.2081\tClassification Loss: 1.2816\n",
      "\n",
      "Test set: Average loss: 1.6185, Accuracy: 550/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [73600/110534 (67%)]\tAll Loss: 2.8201\tTriple Loss(1): 0.2554\tClassification Loss: 2.3093\n",
      "Train Epoch: 3 [73920/110534 (67%)]\tAll Loss: 2.2153\tTriple Loss(1): 0.1019\tClassification Loss: 2.0114\n",
      "Train Epoch: 3 [74240/110534 (67%)]\tAll Loss: 1.3148\tTriple Loss(0): 0.0000\tClassification Loss: 1.3148\n",
      "Train Epoch: 3 [74560/110534 (67%)]\tAll Loss: 2.0693\tTriple Loss(1): 0.2190\tClassification Loss: 1.6312\n",
      "Train Epoch: 3 [74880/110534 (68%)]\tAll Loss: 1.8192\tTriple Loss(0): 0.0000\tClassification Loss: 1.8192\n",
      "Train Epoch: 3 [75200/110534 (68%)]\tAll Loss: 1.9503\tTriple Loss(1): 0.2487\tClassification Loss: 1.4530\n",
      "Train Epoch: 3 [75520/110534 (68%)]\tAll Loss: 1.8273\tTriple Loss(1): 0.1392\tClassification Loss: 1.5489\n",
      "Train Epoch: 3 [75840/110534 (69%)]\tAll Loss: 1.6608\tTriple Loss(0): 0.0000\tClassification Loss: 1.6608\n",
      "Train Epoch: 3 [76160/110534 (69%)]\tAll Loss: 1.8226\tTriple Loss(1): 0.1005\tClassification Loss: 1.6215\n",
      "Train Epoch: 3 [76480/110534 (69%)]\tAll Loss: 2.0707\tTriple Loss(1): 0.3536\tClassification Loss: 1.3635\n",
      "\n",
      "Test set: Average loss: 1.6147, Accuracy: 554/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [76800/110534 (69%)]\tAll Loss: 2.1622\tTriple Loss(1): 0.3161\tClassification Loss: 1.5301\n",
      "Train Epoch: 3 [77120/110534 (70%)]\tAll Loss: 1.9641\tTriple Loss(1): 0.1861\tClassification Loss: 1.5919\n",
      "Train Epoch: 3 [77440/110534 (70%)]\tAll Loss: 2.0775\tTriple Loss(1): 0.1514\tClassification Loss: 1.7746\n",
      "Train Epoch: 3 [77760/110534 (70%)]\tAll Loss: 1.8946\tTriple Loss(1): 0.2338\tClassification Loss: 1.4271\n",
      "Train Epoch: 3 [78080/110534 (71%)]\tAll Loss: 2.7158\tTriple Loss(1): 0.3252\tClassification Loss: 2.0653\n",
      "Train Epoch: 3 [78400/110534 (71%)]\tAll Loss: 1.8315\tTriple Loss(1): 0.1976\tClassification Loss: 1.4363\n",
      "Train Epoch: 3 [78720/110534 (71%)]\tAll Loss: 1.2295\tTriple Loss(0): 0.0000\tClassification Loss: 1.2295\n",
      "Train Epoch: 3 [79040/110534 (71%)]\tAll Loss: 2.2809\tTriple Loss(1): 0.2479\tClassification Loss: 1.7852\n",
      "Train Epoch: 3 [79360/110534 (72%)]\tAll Loss: 1.9516\tTriple Loss(0): 0.0000\tClassification Loss: 1.9516\n",
      "Train Epoch: 3 [79680/110534 (72%)]\tAll Loss: 1.5644\tTriple Loss(1): 0.0594\tClassification Loss: 1.4456\n",
      "\n",
      "Test set: Average loss: 1.6144, Accuracy: 547/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [80000/110534 (72%)]\tAll Loss: 2.0505\tTriple Loss(1): 0.2476\tClassification Loss: 1.5553\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_2500.pth.tar\n",
      "Train Epoch: 3 [80320/110534 (73%)]\tAll Loss: 1.1478\tTriple Loss(0): 0.0000\tClassification Loss: 1.1478\n",
      "Train Epoch: 3 [80640/110534 (73%)]\tAll Loss: 1.7865\tTriple Loss(1): 0.1950\tClassification Loss: 1.3965\n",
      "Train Epoch: 3 [80960/110534 (73%)]\tAll Loss: 2.0770\tTriple Loss(1): 0.2439\tClassification Loss: 1.5893\n",
      "Train Epoch: 3 [81280/110534 (74%)]\tAll Loss: 1.6787\tTriple Loss(1): 0.1545\tClassification Loss: 1.3697\n",
      "Train Epoch: 3 [81600/110534 (74%)]\tAll Loss: 1.9507\tTriple Loss(1): 0.2588\tClassification Loss: 1.4331\n",
      "Train Epoch: 3 [81920/110534 (74%)]\tAll Loss: 2.1382\tTriple Loss(1): 0.1786\tClassification Loss: 1.7810\n",
      "Train Epoch: 3 [82240/110534 (74%)]\tAll Loss: 1.9644\tTriple Loss(1): 0.1600\tClassification Loss: 1.6444\n",
      "Train Epoch: 3 [82560/110534 (75%)]\tAll Loss: 1.9499\tTriple Loss(1): 0.1929\tClassification Loss: 1.5642\n",
      "Train Epoch: 3 [82880/110534 (75%)]\tAll Loss: 2.2308\tTriple Loss(1): 0.1992\tClassification Loss: 1.8324\n",
      "\n",
      "Test set: Average loss: 1.6172, Accuracy: 550/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [83200/110534 (75%)]\tAll Loss: 2.1292\tTriple Loss(1): 0.2177\tClassification Loss: 1.6938\n",
      "Train Epoch: 3 [83520/110534 (76%)]\tAll Loss: 1.4743\tTriple Loss(0): 0.0000\tClassification Loss: 1.4743\n",
      "Train Epoch: 3 [83840/110534 (76%)]\tAll Loss: 2.4492\tTriple Loss(1): 0.4035\tClassification Loss: 1.6422\n",
      "Train Epoch: 3 [84160/110534 (76%)]\tAll Loss: 1.7572\tTriple Loss(1): 0.2667\tClassification Loss: 1.2238\n",
      "Train Epoch: 3 [84480/110534 (76%)]\tAll Loss: 1.4341\tTriple Loss(0): 0.0000\tClassification Loss: 1.4341\n",
      "Train Epoch: 3 [84800/110534 (77%)]\tAll Loss: 2.0831\tTriple Loss(1): 0.1803\tClassification Loss: 1.7226\n",
      "Train Epoch: 3 [85120/110534 (77%)]\tAll Loss: 2.1895\tTriple Loss(1): 0.4047\tClassification Loss: 1.3800\n",
      "Train Epoch: 3 [85440/110534 (77%)]\tAll Loss: 1.1450\tTriple Loss(0): 0.0000\tClassification Loss: 1.1450\n",
      "Train Epoch: 3 [85760/110534 (78%)]\tAll Loss: 2.0557\tTriple Loss(1): 0.2168\tClassification Loss: 1.6220\n",
      "Train Epoch: 3 [86080/110534 (78%)]\tAll Loss: 1.7505\tTriple Loss(0): 0.0000\tClassification Loss: 1.7505\n",
      "\n",
      "Test set: Average loss: 1.6118, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [86400/110534 (78%)]\tAll Loss: 2.3783\tTriple Loss(1): 0.1696\tClassification Loss: 2.0392\n",
      "Train Epoch: 3 [86720/110534 (78%)]\tAll Loss: 1.2384\tTriple Loss(0): 0.0000\tClassification Loss: 1.2384\n",
      "Train Epoch: 3 [87040/110534 (79%)]\tAll Loss: 1.5438\tTriple Loss(0): 0.0000\tClassification Loss: 1.5438\n",
      "Train Epoch: 3 [87360/110534 (79%)]\tAll Loss: 2.3095\tTriple Loss(1): 0.2727\tClassification Loss: 1.7641\n",
      "Train Epoch: 3 [87680/110534 (79%)]\tAll Loss: 1.9177\tTriple Loss(1): 0.2096\tClassification Loss: 1.4984\n",
      "Train Epoch: 3 [88000/110534 (80%)]\tAll Loss: 2.0831\tTriple Loss(0): 0.0000\tClassification Loss: 2.0831\n",
      "Train Epoch: 3 [88320/110534 (80%)]\tAll Loss: 1.8857\tTriple Loss(1): 0.1446\tClassification Loss: 1.5965\n",
      "Train Epoch: 3 [88640/110534 (80%)]\tAll Loss: 1.9323\tTriple Loss(0): 0.0000\tClassification Loss: 1.9323\n",
      "Train Epoch: 3 [88960/110534 (80%)]\tAll Loss: 2.5407\tTriple Loss(1): 0.3541\tClassification Loss: 1.8324\n",
      "Train Epoch: 3 [89280/110534 (81%)]\tAll Loss: 1.5860\tTriple Loss(1): 0.0843\tClassification Loss: 1.4173\n",
      "\n",
      "Test set: Average loss: 1.6076, Accuracy: 555/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [89600/110534 (81%)]\tAll Loss: 2.0985\tTriple Loss(0): 0.0000\tClassification Loss: 2.0985\n",
      "Train Epoch: 3 [89920/110534 (81%)]\tAll Loss: 2.3212\tTriple Loss(1): 0.2344\tClassification Loss: 1.8523\n",
      "Train Epoch: 3 [90240/110534 (82%)]\tAll Loss: 1.6913\tTriple Loss(1): 0.1502\tClassification Loss: 1.3908\n",
      "Train Epoch: 3 [90560/110534 (82%)]\tAll Loss: 1.7004\tTriple Loss(1): 0.1354\tClassification Loss: 1.4296\n",
      "Train Epoch: 3 [90880/110534 (82%)]\tAll Loss: 2.5980\tTriple Loss(1): 0.4080\tClassification Loss: 1.7819\n",
      "Train Epoch: 3 [91200/110534 (82%)]\tAll Loss: 2.1935\tTriple Loss(1): 0.3464\tClassification Loss: 1.5006\n",
      "Train Epoch: 3 [91520/110534 (83%)]\tAll Loss: 2.7347\tTriple Loss(1): 0.5830\tClassification Loss: 1.5688\n",
      "Train Epoch: 3 [91840/110534 (83%)]\tAll Loss: 2.1010\tTriple Loss(1): 0.2340\tClassification Loss: 1.6331\n",
      "Train Epoch: 3 [92160/110534 (83%)]\tAll Loss: 2.0085\tTriple Loss(0): 0.0000\tClassification Loss: 2.0085\n",
      "Train Epoch: 3 [92480/110534 (84%)]\tAll Loss: 1.9461\tTriple Loss(1): 0.1932\tClassification Loss: 1.5598\n",
      "\n",
      "Test set: Average loss: 1.6155, Accuracy: 551/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [92800/110534 (84%)]\tAll Loss: 1.5008\tTriple Loss(0): 0.0000\tClassification Loss: 1.5008\n",
      "Train Epoch: 3 [93120/110534 (84%)]\tAll Loss: 2.3300\tTriple Loss(1): 0.2869\tClassification Loss: 1.7563\n",
      "Train Epoch: 3 [93440/110534 (85%)]\tAll Loss: 2.2402\tTriple Loss(1): 0.3373\tClassification Loss: 1.5655\n",
      "Train Epoch: 3 [93760/110534 (85%)]\tAll Loss: 1.4289\tTriple Loss(0): 0.0000\tClassification Loss: 1.4289\n",
      "Train Epoch: 3 [94080/110534 (85%)]\tAll Loss: 1.9068\tTriple Loss(1): 0.1801\tClassification Loss: 1.5466\n",
      "Train Epoch: 3 [94400/110534 (85%)]\tAll Loss: 2.2672\tTriple Loss(1): 0.2430\tClassification Loss: 1.7813\n",
      "Train Epoch: 3 [94720/110534 (86%)]\tAll Loss: 1.9643\tTriple Loss(1): 0.1864\tClassification Loss: 1.5915\n",
      "Train Epoch: 3 [95040/110534 (86%)]\tAll Loss: 2.0011\tTriple Loss(1): 0.1701\tClassification Loss: 1.6609\n",
      "Train Epoch: 3 [95360/110534 (86%)]\tAll Loss: 2.4574\tTriple Loss(1): 0.4822\tClassification Loss: 1.4931\n",
      "Train Epoch: 3 [95680/110534 (87%)]\tAll Loss: 2.1804\tTriple Loss(1): 0.2329\tClassification Loss: 1.7146\n",
      "\n",
      "Test set: Average loss: 1.6164, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [96000/110534 (87%)]\tAll Loss: 1.6168\tTriple Loss(1): 0.1377\tClassification Loss: 1.3414\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_3000.pth.tar\n",
      "Train Epoch: 3 [96320/110534 (87%)]\tAll Loss: 1.4745\tTriple Loss(0): 0.0000\tClassification Loss: 1.4745\n",
      "Train Epoch: 3 [96640/110534 (87%)]\tAll Loss: 1.8507\tTriple Loss(1): 0.0667\tClassification Loss: 1.7172\n",
      "Train Epoch: 3 [96960/110534 (88%)]\tAll Loss: 1.8136\tTriple Loss(1): 0.2362\tClassification Loss: 1.3411\n",
      "Train Epoch: 3 [97280/110534 (88%)]\tAll Loss: 1.6458\tTriple Loss(1): 0.1205\tClassification Loss: 1.4048\n",
      "Train Epoch: 3 [97600/110534 (88%)]\tAll Loss: 1.7890\tTriple Loss(0): 0.0763\tClassification Loss: 1.6364\n",
      "Train Epoch: 3 [97920/110534 (89%)]\tAll Loss: 1.2719\tTriple Loss(0): 0.0000\tClassification Loss: 1.2719\n",
      "Train Epoch: 3 [98240/110534 (89%)]\tAll Loss: 1.4392\tTriple Loss(1): 0.0829\tClassification Loss: 1.2735\n",
      "Train Epoch: 3 [98560/110534 (89%)]\tAll Loss: 1.3552\tTriple Loss(0): 0.0000\tClassification Loss: 1.3552\n",
      "Train Epoch: 3 [98880/110534 (89%)]\tAll Loss: 2.1221\tTriple Loss(1): 0.3400\tClassification Loss: 1.4421\n",
      "\n",
      "Test set: Average loss: 1.6239, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [99200/110534 (90%)]\tAll Loss: 2.6382\tTriple Loss(1): 0.5282\tClassification Loss: 1.5817\n",
      "Train Epoch: 3 [99520/110534 (90%)]\tAll Loss: 1.8999\tTriple Loss(1): 0.1222\tClassification Loss: 1.6554\n",
      "Train Epoch: 3 [99840/110534 (90%)]\tAll Loss: 2.0371\tTriple Loss(1): 0.2075\tClassification Loss: 1.6221\n",
      "Train Epoch: 3 [100160/110534 (91%)]\tAll Loss: 2.5638\tTriple Loss(1): 0.3251\tClassification Loss: 1.9136\n",
      "Train Epoch: 3 [100480/110534 (91%)]\tAll Loss: 2.0411\tTriple Loss(1): 0.3208\tClassification Loss: 1.3995\n",
      "Train Epoch: 3 [100800/110534 (91%)]\tAll Loss: 2.6828\tTriple Loss(1): 0.3388\tClassification Loss: 2.0052\n",
      "Train Epoch: 3 [101120/110534 (91%)]\tAll Loss: 1.8462\tTriple Loss(1): 0.1878\tClassification Loss: 1.4707\n",
      "Train Epoch: 3 [101440/110534 (92%)]\tAll Loss: 1.6994\tTriple Loss(1): 0.1926\tClassification Loss: 1.3142\n",
      "Train Epoch: 3 [101760/110534 (92%)]\tAll Loss: 2.0764\tTriple Loss(1): 0.1943\tClassification Loss: 1.6878\n",
      "Train Epoch: 3 [102080/110534 (92%)]\tAll Loss: 2.6985\tTriple Loss(1): 0.3695\tClassification Loss: 1.9595\n",
      "\n",
      "Test set: Average loss: 1.6157, Accuracy: 542/960 (56%)\n",
      "\n",
      "Train Epoch: 3 [102400/110534 (93%)]\tAll Loss: 1.9388\tTriple Loss(1): 0.0979\tClassification Loss: 1.7431\n",
      "Train Epoch: 3 [102720/110534 (93%)]\tAll Loss: 2.2306\tTriple Loss(1): 0.2005\tClassification Loss: 1.8295\n",
      "Train Epoch: 3 [103040/110534 (93%)]\tAll Loss: 2.1076\tTriple Loss(1): 0.2692\tClassification Loss: 1.5693\n",
      "Train Epoch: 3 [103360/110534 (93%)]\tAll Loss: 1.9942\tTriple Loss(1): 0.1480\tClassification Loss: 1.6983\n",
      "Train Epoch: 3 [103680/110534 (94%)]\tAll Loss: 2.4466\tTriple Loss(1): 0.3272\tClassification Loss: 1.7922\n",
      "Train Epoch: 3 [104000/110534 (94%)]\tAll Loss: 2.1344\tTriple Loss(1): 0.3220\tClassification Loss: 1.4903\n",
      "Train Epoch: 3 [104320/110534 (94%)]\tAll Loss: 2.1739\tTriple Loss(0): 0.0000\tClassification Loss: 2.1739\n",
      "Train Epoch: 3 [104640/110534 (95%)]\tAll Loss: 1.9766\tTriple Loss(0): 0.0000\tClassification Loss: 1.9766\n",
      "Train Epoch: 3 [104960/110534 (95%)]\tAll Loss: 1.9880\tTriple Loss(1): 0.2906\tClassification Loss: 1.4069\n",
      "Train Epoch: 3 [105280/110534 (95%)]\tAll Loss: 2.5649\tTriple Loss(1): 0.4854\tClassification Loss: 1.5940\n",
      "\n",
      "Test set: Average loss: 1.6166, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [105600/110534 (96%)]\tAll Loss: 2.0278\tTriple Loss(1): 0.1926\tClassification Loss: 1.6426\n",
      "Train Epoch: 3 [105920/110534 (96%)]\tAll Loss: 2.0284\tTriple Loss(1): 0.1864\tClassification Loss: 1.6557\n",
      "Train Epoch: 3 [106240/110534 (96%)]\tAll Loss: 1.5826\tTriple Loss(1): 0.1594\tClassification Loss: 1.2639\n",
      "Train Epoch: 3 [106560/110534 (96%)]\tAll Loss: 2.1635\tTriple Loss(1): 0.2631\tClassification Loss: 1.6373\n",
      "Train Epoch: 3 [106880/110534 (97%)]\tAll Loss: 2.3258\tTriple Loss(1): 0.1864\tClassification Loss: 1.9529\n",
      "Train Epoch: 3 [107200/110534 (97%)]\tAll Loss: 1.7433\tTriple Loss(0): 0.0000\tClassification Loss: 1.7433\n",
      "Train Epoch: 3 [107520/110534 (97%)]\tAll Loss: 1.7301\tTriple Loss(0): 0.0000\tClassification Loss: 1.7301\n",
      "Train Epoch: 3 [107840/110534 (98%)]\tAll Loss: 1.4623\tTriple Loss(0): 0.0000\tClassification Loss: 1.4623\n",
      "Train Epoch: 3 [108160/110534 (98%)]\tAll Loss: 1.7753\tTriple Loss(1): 0.2587\tClassification Loss: 1.2580\n",
      "Train Epoch: 3 [108480/110534 (98%)]\tAll Loss: 2.4207\tTriple Loss(1): 0.4230\tClassification Loss: 1.5748\n",
      "\n",
      "Test set: Average loss: 1.6027, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [108800/110534 (98%)]\tAll Loss: 1.6664\tTriple Loss(1): 0.1057\tClassification Loss: 1.4551\n",
      "Train Epoch: 3 [109120/110534 (99%)]\tAll Loss: 2.1947\tTriple Loss(1): 0.1654\tClassification Loss: 1.8640\n",
      "Train Epoch: 3 [109440/110534 (99%)]\tAll Loss: 1.6944\tTriple Loss(1): 0.1878\tClassification Loss: 1.3188\n",
      "Train Epoch: 3 [109760/110534 (99%)]\tAll Loss: 1.9214\tTriple Loss(1): 0.1521\tClassification Loss: 1.6173\n",
      "Train Epoch: 3 [110080/110534 (100%)]\tAll Loss: 1.8071\tTriple Loss(1): 0.1050\tClassification Loss: 1.5970\n",
      "Train Epoch: 3 [110400/110534 (100%)]\tAll Loss: 2.4242\tTriple Loss(1): 0.3726\tClassification Loss: 1.6790\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_final.pth.tar\n",
      "\n",
      "Test set: Average loss: 1.6079, Accuracy: 550/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [0/110534 (0%)]\tAll Loss: 1.6143\tTriple Loss(0): 0.0000\tClassification Loss: 1.6143\n",
      "Train Epoch: 4 [320/110534 (0%)]\tAll Loss: 1.5282\tTriple Loss(0): 0.0000\tClassification Loss: 1.5282\n",
      "Train Epoch: 4 [640/110534 (1%)]\tAll Loss: 1.4718\tTriple Loss(1): 0.2255\tClassification Loss: 1.0208\n",
      "Train Epoch: 4 [960/110534 (1%)]\tAll Loss: 2.0784\tTriple Loss(0): 0.0000\tClassification Loss: 2.0784\n",
      "Train Epoch: 4 [1280/110534 (1%)]\tAll Loss: 2.0765\tTriple Loss(1): 0.2275\tClassification Loss: 1.6215\n",
      "Train Epoch: 4 [1600/110534 (1%)]\tAll Loss: 2.2020\tTriple Loss(1): 0.1992\tClassification Loss: 1.8037\n",
      "Train Epoch: 4 [1920/110534 (2%)]\tAll Loss: 2.2470\tTriple Loss(1): 0.1846\tClassification Loss: 1.8777\n",
      "Train Epoch: 4 [2240/110534 (2%)]\tAll Loss: 2.0864\tTriple Loss(1): 0.2609\tClassification Loss: 1.5647\n",
      "Train Epoch: 4 [2560/110534 (2%)]\tAll Loss: 1.7710\tTriple Loss(1): 0.0825\tClassification Loss: 1.6060\n",
      "Train Epoch: 4 [2880/110534 (3%)]\tAll Loss: 2.4915\tTriple Loss(1): 0.3874\tClassification Loss: 1.7167\n",
      "\n",
      "Test set: Average loss: 1.6108, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [3200/110534 (3%)]\tAll Loss: 2.2865\tTriple Loss(1): 0.1099\tClassification Loss: 2.0667\n",
      "Train Epoch: 4 [3520/110534 (3%)]\tAll Loss: 1.6985\tTriple Loss(1): 0.2248\tClassification Loss: 1.2490\n",
      "Train Epoch: 4 [3840/110534 (3%)]\tAll Loss: 1.9458\tTriple Loss(1): 0.1119\tClassification Loss: 1.7220\n",
      "Train Epoch: 4 [4160/110534 (4%)]\tAll Loss: 1.9680\tTriple Loss(1): 0.1429\tClassification Loss: 1.6822\n",
      "Train Epoch: 4 [4480/110534 (4%)]\tAll Loss: 1.9162\tTriple Loss(1): 0.2272\tClassification Loss: 1.4618\n",
      "Train Epoch: 4 [4800/110534 (4%)]\tAll Loss: 1.9294\tTriple Loss(1): 0.2557\tClassification Loss: 1.4180\n",
      "Train Epoch: 4 [5120/110534 (5%)]\tAll Loss: 2.0178\tTriple Loss(1): 0.0698\tClassification Loss: 1.8782\n",
      "Train Epoch: 4 [5440/110534 (5%)]\tAll Loss: 2.5363\tTriple Loss(1): 0.5070\tClassification Loss: 1.5224\n",
      "Train Epoch: 4 [5760/110534 (5%)]\tAll Loss: 1.7934\tTriple Loss(1): 0.2674\tClassification Loss: 1.2586\n",
      "Train Epoch: 4 [6080/110534 (5%)]\tAll Loss: 2.6046\tTriple Loss(1): 0.4923\tClassification Loss: 1.6200\n",
      "\n",
      "Test set: Average loss: 1.6040, Accuracy: 551/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [6400/110534 (6%)]\tAll Loss: 2.2226\tTriple Loss(1): 0.3075\tClassification Loss: 1.6076\n",
      "Train Epoch: 4 [6720/110534 (6%)]\tAll Loss: 2.1916\tTriple Loss(1): 0.2620\tClassification Loss: 1.6677\n",
      "Train Epoch: 4 [7040/110534 (6%)]\tAll Loss: 2.1920\tTriple Loss(1): 0.2000\tClassification Loss: 1.7921\n",
      "Train Epoch: 4 [7360/110534 (7%)]\tAll Loss: 1.8703\tTriple Loss(1): 0.2057\tClassification Loss: 1.4590\n",
      "Train Epoch: 4 [7680/110534 (7%)]\tAll Loss: 1.3664\tTriple Loss(1): 0.0864\tClassification Loss: 1.1935\n",
      "Train Epoch: 4 [8000/110534 (7%)]\tAll Loss: 1.9324\tTriple Loss(1): 0.3025\tClassification Loss: 1.3275\n",
      "Train Epoch: 4 [8320/110534 (8%)]\tAll Loss: 1.5880\tTriple Loss(1): 0.0443\tClassification Loss: 1.4994\n",
      "Train Epoch: 4 [8640/110534 (8%)]\tAll Loss: 1.2107\tTriple Loss(0): 0.0000\tClassification Loss: 1.2107\n",
      "Train Epoch: 4 [8960/110534 (8%)]\tAll Loss: 1.2963\tTriple Loss(0): 0.0000\tClassification Loss: 1.2963\n",
      "Train Epoch: 4 [9280/110534 (8%)]\tAll Loss: 1.3921\tTriple Loss(1): 0.0349\tClassification Loss: 1.3223\n",
      "\n",
      "Test set: Average loss: 1.6016, Accuracy: 554/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [9600/110534 (9%)]\tAll Loss: 1.9484\tTriple Loss(1): 0.0618\tClassification Loss: 1.8248\n",
      "Train Epoch: 4 [9920/110534 (9%)]\tAll Loss: 1.6882\tTriple Loss(0): 0.0000\tClassification Loss: 1.6882\n",
      "Train Epoch: 4 [10240/110534 (9%)]\tAll Loss: 2.3149\tTriple Loss(1): 0.2613\tClassification Loss: 1.7924\n",
      "Train Epoch: 4 [10560/110534 (10%)]\tAll Loss: 2.0079\tTriple Loss(1): 0.1805\tClassification Loss: 1.6469\n",
      "Train Epoch: 4 [10880/110534 (10%)]\tAll Loss: 2.1541\tTriple Loss(1): 0.1742\tClassification Loss: 1.8058\n",
      "Train Epoch: 4 [11200/110534 (10%)]\tAll Loss: 1.2090\tTriple Loss(0): 0.0000\tClassification Loss: 1.2090\n",
      "Train Epoch: 4 [11520/110534 (10%)]\tAll Loss: 1.6949\tTriple Loss(1): 0.1355\tClassification Loss: 1.4240\n",
      "Train Epoch: 4 [11840/110534 (11%)]\tAll Loss: 2.2563\tTriple Loss(1): 0.2764\tClassification Loss: 1.7035\n",
      "Train Epoch: 4 [12160/110534 (11%)]\tAll Loss: 1.9195\tTriple Loss(1): 0.1727\tClassification Loss: 1.5741\n",
      "Train Epoch: 4 [12480/110534 (11%)]\tAll Loss: 1.7369\tTriple Loss(0): 0.0000\tClassification Loss: 1.7369\n",
      "\n",
      "Test set: Average loss: 1.6025, Accuracy: 547/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [12800/110534 (12%)]\tAll Loss: 1.9491\tTriple Loss(1): 0.2992\tClassification Loss: 1.3506\n",
      "Train Epoch: 4 [13120/110534 (12%)]\tAll Loss: 1.6719\tTriple Loss(1): 0.1450\tClassification Loss: 1.3819\n",
      "Train Epoch: 4 [13440/110534 (12%)]\tAll Loss: 2.2059\tTriple Loss(1): 0.1689\tClassification Loss: 1.8681\n",
      "Train Epoch: 4 [13760/110534 (12%)]\tAll Loss: 1.9861\tTriple Loss(1): 0.1073\tClassification Loss: 1.7715\n",
      "Train Epoch: 4 [14080/110534 (13%)]\tAll Loss: 1.8783\tTriple Loss(0): 0.0000\tClassification Loss: 1.8783\n",
      "Train Epoch: 4 [14400/110534 (13%)]\tAll Loss: 2.7916\tTriple Loss(1): 0.3747\tClassification Loss: 2.0423\n",
      "Train Epoch: 4 [14720/110534 (13%)]\tAll Loss: 1.9012\tTriple Loss(1): 0.1365\tClassification Loss: 1.6282\n",
      "Train Epoch: 4 [15040/110534 (14%)]\tAll Loss: 2.0235\tTriple Loss(1): 0.2773\tClassification Loss: 1.4689\n",
      "Train Epoch: 4 [15360/110534 (14%)]\tAll Loss: 2.2557\tTriple Loss(1): 0.3413\tClassification Loss: 1.5732\n",
      "Train Epoch: 4 [15680/110534 (14%)]\tAll Loss: 1.6727\tTriple Loss(1): 0.2108\tClassification Loss: 1.2511\n",
      "\n",
      "Test set: Average loss: 1.6021, Accuracy: 544/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [16000/110534 (14%)]\tAll Loss: 1.9459\tTriple Loss(1): 0.1248\tClassification Loss: 1.6963\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_500.pth.tar\n",
      "Train Epoch: 4 [16320/110534 (15%)]\tAll Loss: 1.2675\tTriple Loss(0): 0.0000\tClassification Loss: 1.2675\n",
      "Train Epoch: 4 [16640/110534 (15%)]\tAll Loss: 1.9627\tTriple Loss(1): 0.1616\tClassification Loss: 1.6395\n",
      "Train Epoch: 4 [16960/110534 (15%)]\tAll Loss: 2.0852\tTriple Loss(1): 0.1504\tClassification Loss: 1.7844\n",
      "Train Epoch: 4 [17280/110534 (16%)]\tAll Loss: 1.7734\tTriple Loss(1): 0.1713\tClassification Loss: 1.4308\n",
      "Train Epoch: 4 [17600/110534 (16%)]\tAll Loss: 2.0336\tTriple Loss(1): 0.1905\tClassification Loss: 1.6527\n",
      "Train Epoch: 4 [17920/110534 (16%)]\tAll Loss: 2.0750\tTriple Loss(1): 0.1942\tClassification Loss: 1.6865\n",
      "Train Epoch: 4 [18240/110534 (16%)]\tAll Loss: 7.0800\tTriple Loss(0): 2.5153\tClassification Loss: 2.0494\n",
      "Train Epoch: 4 [18560/110534 (17%)]\tAll Loss: 1.5806\tTriple Loss(0): 0.0000\tClassification Loss: 1.5806\n",
      "Train Epoch: 4 [18880/110534 (17%)]\tAll Loss: 2.3235\tTriple Loss(1): 0.2706\tClassification Loss: 1.7824\n",
      "\n",
      "Test set: Average loss: 1.6059, Accuracy: 556/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [19200/110534 (17%)]\tAll Loss: 1.9615\tTriple Loss(1): 0.2957\tClassification Loss: 1.3700\n",
      "Train Epoch: 4 [19520/110534 (18%)]\tAll Loss: 1.5681\tTriple Loss(0): 0.0000\tClassification Loss: 1.5681\n",
      "Train Epoch: 4 [19840/110534 (18%)]\tAll Loss: 2.7177\tTriple Loss(0): 0.5612\tClassification Loss: 1.5954\n",
      "Train Epoch: 4 [20160/110534 (18%)]\tAll Loss: 1.3343\tTriple Loss(0): 0.0000\tClassification Loss: 1.3343\n",
      "Train Epoch: 4 [20480/110534 (19%)]\tAll Loss: 2.0395\tTriple Loss(1): 0.2844\tClassification Loss: 1.4708\n",
      "Train Epoch: 4 [20800/110534 (19%)]\tAll Loss: 2.4581\tTriple Loss(1): 0.2440\tClassification Loss: 1.9700\n",
      "Train Epoch: 4 [21120/110534 (19%)]\tAll Loss: 2.0580\tTriple Loss(1): 0.2701\tClassification Loss: 1.5178\n",
      "Train Epoch: 4 [21440/110534 (19%)]\tAll Loss: 1.7876\tTriple Loss(1): 0.1790\tClassification Loss: 1.4296\n",
      "Train Epoch: 4 [21760/110534 (20%)]\tAll Loss: 2.6684\tTriple Loss(1): 0.3029\tClassification Loss: 2.0626\n",
      "Train Epoch: 4 [22080/110534 (20%)]\tAll Loss: 1.9059\tTriple Loss(1): 0.1170\tClassification Loss: 1.6719\n",
      "\n",
      "Test set: Average loss: 1.6078, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [22400/110534 (20%)]\tAll Loss: 1.5224\tTriple Loss(0): 0.0000\tClassification Loss: 1.5224\n",
      "Train Epoch: 4 [22720/110534 (21%)]\tAll Loss: 1.9223\tTriple Loss(1): 0.1637\tClassification Loss: 1.5950\n",
      "Train Epoch: 4 [23040/110534 (21%)]\tAll Loss: 2.0793\tTriple Loss(1): 0.1404\tClassification Loss: 1.7986\n",
      "Train Epoch: 4 [23360/110534 (21%)]\tAll Loss: 1.8507\tTriple Loss(1): 0.2032\tClassification Loss: 1.4443\n",
      "Train Epoch: 4 [23680/110534 (21%)]\tAll Loss: 2.2691\tTriple Loss(1): 0.2072\tClassification Loss: 1.8546\n",
      "Train Epoch: 4 [24000/110534 (22%)]\tAll Loss: 1.9754\tTriple Loss(1): 0.1977\tClassification Loss: 1.5801\n",
      "Train Epoch: 4 [24320/110534 (22%)]\tAll Loss: 2.3338\tTriple Loss(1): 0.3313\tClassification Loss: 1.6712\n",
      "Train Epoch: 4 [24640/110534 (22%)]\tAll Loss: 2.4249\tTriple Loss(1): 0.2195\tClassification Loss: 1.9858\n",
      "Train Epoch: 4 [24960/110534 (23%)]\tAll Loss: 1.8664\tTriple Loss(1): 0.2435\tClassification Loss: 1.3795\n",
      "Train Epoch: 4 [25280/110534 (23%)]\tAll Loss: 1.6723\tTriple Loss(1): 0.0686\tClassification Loss: 1.5351\n",
      "\n",
      "Test set: Average loss: 1.6048, Accuracy: 555/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [25600/110534 (23%)]\tAll Loss: 1.5907\tTriple Loss(0): 0.0000\tClassification Loss: 1.5907\n",
      "Train Epoch: 4 [25920/110534 (23%)]\tAll Loss: 2.3169\tTriple Loss(1): 0.2936\tClassification Loss: 1.7297\n",
      "Train Epoch: 4 [26240/110534 (24%)]\tAll Loss: 2.2649\tTriple Loss(1): 0.3589\tClassification Loss: 1.5471\n",
      "Train Epoch: 4 [26560/110534 (24%)]\tAll Loss: 2.1117\tTriple Loss(1): 0.1522\tClassification Loss: 1.8073\n",
      "Train Epoch: 4 [26880/110534 (24%)]\tAll Loss: 2.2916\tTriple Loss(1): 0.2714\tClassification Loss: 1.7487\n",
      "Train Epoch: 4 [27200/110534 (25%)]\tAll Loss: 2.2312\tTriple Loss(1): 0.1760\tClassification Loss: 1.8793\n",
      "Train Epoch: 4 [27520/110534 (25%)]\tAll Loss: 1.7053\tTriple Loss(1): 0.0000\tClassification Loss: 1.7053\n",
      "Train Epoch: 4 [27840/110534 (25%)]\tAll Loss: 1.5078\tTriple Loss(0): 0.0000\tClassification Loss: 1.5078\n",
      "Train Epoch: 4 [28160/110534 (25%)]\tAll Loss: 2.1821\tTriple Loss(1): 0.1941\tClassification Loss: 1.7939\n",
      "Train Epoch: 4 [28480/110534 (26%)]\tAll Loss: 1.9387\tTriple Loss(1): 0.2361\tClassification Loss: 1.4665\n",
      "\n",
      "Test set: Average loss: 1.6056, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [28800/110534 (26%)]\tAll Loss: 1.4205\tTriple Loss(0): 0.0000\tClassification Loss: 1.4205\n",
      "Train Epoch: 4 [29120/110534 (26%)]\tAll Loss: 2.0927\tTriple Loss(1): 0.2764\tClassification Loss: 1.5399\n",
      "Train Epoch: 4 [29440/110534 (27%)]\tAll Loss: 1.3972\tTriple Loss(0): 0.0000\tClassification Loss: 1.3972\n",
      "Train Epoch: 4 [29760/110534 (27%)]\tAll Loss: 1.7598\tTriple Loss(1): 0.2205\tClassification Loss: 1.3188\n",
      "Train Epoch: 4 [30080/110534 (27%)]\tAll Loss: 1.7648\tTriple Loss(1): 0.1728\tClassification Loss: 1.4191\n",
      "Train Epoch: 4 [30400/110534 (27%)]\tAll Loss: 2.0758\tTriple Loss(1): 0.1662\tClassification Loss: 1.7433\n",
      "Train Epoch: 4 [30720/110534 (28%)]\tAll Loss: 1.6051\tTriple Loss(1): 0.1708\tClassification Loss: 1.2636\n",
      "Train Epoch: 4 [31040/110534 (28%)]\tAll Loss: 2.6178\tTriple Loss(1): 0.3544\tClassification Loss: 1.9090\n",
      "Train Epoch: 4 [31360/110534 (28%)]\tAll Loss: 1.7841\tTriple Loss(1): 0.0783\tClassification Loss: 1.6275\n",
      "Train Epoch: 4 [31680/110534 (29%)]\tAll Loss: 2.1278\tTriple Loss(1): 0.2509\tClassification Loss: 1.6260\n",
      "\n",
      "Test set: Average loss: 1.5984, Accuracy: 560/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [32000/110534 (29%)]\tAll Loss: 2.3783\tTriple Loss(1): 0.3408\tClassification Loss: 1.6968\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_1000.pth.tar\n",
      "Train Epoch: 4 [32320/110534 (29%)]\tAll Loss: 1.5942\tTriple Loss(1): 0.1384\tClassification Loss: 1.3174\n",
      "Train Epoch: 4 [32640/110534 (30%)]\tAll Loss: 1.6929\tTriple Loss(0): 0.0000\tClassification Loss: 1.6929\n",
      "Train Epoch: 4 [32960/110534 (30%)]\tAll Loss: 2.1175\tTriple Loss(1): 0.1803\tClassification Loss: 1.7569\n",
      "Train Epoch: 4 [33280/110534 (30%)]\tAll Loss: 2.5035\tTriple Loss(1): 0.2684\tClassification Loss: 1.9666\n",
      "Train Epoch: 4 [33600/110534 (30%)]\tAll Loss: 1.8624\tTriple Loss(1): 0.1163\tClassification Loss: 1.6297\n",
      "Train Epoch: 4 [33920/110534 (31%)]\tAll Loss: 1.5929\tTriple Loss(0): 0.0000\tClassification Loss: 1.5929\n",
      "Train Epoch: 4 [34240/110534 (31%)]\tAll Loss: 1.9849\tTriple Loss(1): 0.2240\tClassification Loss: 1.5369\n",
      "Train Epoch: 4 [34560/110534 (31%)]\tAll Loss: 2.0687\tTriple Loss(1): 0.2806\tClassification Loss: 1.5074\n",
      "Train Epoch: 4 [34880/110534 (32%)]\tAll Loss: 1.7505\tTriple Loss(1): 0.2626\tClassification Loss: 1.2252\n",
      "\n",
      "Test set: Average loss: 1.6050, Accuracy: 557/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [35200/110534 (32%)]\tAll Loss: 2.4097\tTriple Loss(1): 0.2287\tClassification Loss: 1.9523\n",
      "Train Epoch: 4 [35520/110534 (32%)]\tAll Loss: 2.0083\tTriple Loss(1): 0.1816\tClassification Loss: 1.6451\n",
      "Train Epoch: 4 [35840/110534 (32%)]\tAll Loss: 1.6150\tTriple Loss(1): 0.1367\tClassification Loss: 1.3416\n",
      "Train Epoch: 4 [36160/110534 (33%)]\tAll Loss: 2.1299\tTriple Loss(1): 0.1693\tClassification Loss: 1.7913\n",
      "Train Epoch: 4 [36480/110534 (33%)]\tAll Loss: 2.1198\tTriple Loss(1): 0.1773\tClassification Loss: 1.7653\n",
      "Train Epoch: 4 [36800/110534 (33%)]\tAll Loss: 2.0883\tTriple Loss(1): 0.2867\tClassification Loss: 1.5149\n",
      "Train Epoch: 4 [37120/110534 (34%)]\tAll Loss: 2.3692\tTriple Loss(1): 0.2538\tClassification Loss: 1.8615\n",
      "Train Epoch: 4 [37440/110534 (34%)]\tAll Loss: 2.1092\tTriple Loss(1): 0.2229\tClassification Loss: 1.6635\n",
      "Train Epoch: 4 [37760/110534 (34%)]\tAll Loss: 1.7955\tTriple Loss(1): 0.1184\tClassification Loss: 1.5586\n",
      "Train Epoch: 4 [38080/110534 (34%)]\tAll Loss: 2.2771\tTriple Loss(0): 0.2525\tClassification Loss: 1.7720\n",
      "\n",
      "Test set: Average loss: 1.5971, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [38400/110534 (35%)]\tAll Loss: 1.9470\tTriple Loss(1): 0.2871\tClassification Loss: 1.3728\n",
      "Train Epoch: 4 [38720/110534 (35%)]\tAll Loss: 1.7556\tTriple Loss(0): 0.0000\tClassification Loss: 1.7556\n",
      "Train Epoch: 4 [39040/110534 (35%)]\tAll Loss: 1.7056\tTriple Loss(1): 0.1890\tClassification Loss: 1.3276\n",
      "Train Epoch: 4 [39360/110534 (36%)]\tAll Loss: 1.5900\tTriple Loss(1): 0.0680\tClassification Loss: 1.4541\n",
      "Train Epoch: 4 [39680/110534 (36%)]\tAll Loss: 2.4338\tTriple Loss(1): 0.2951\tClassification Loss: 1.8436\n",
      "Train Epoch: 4 [40000/110534 (36%)]\tAll Loss: 1.2722\tTriple Loss(0): 0.0000\tClassification Loss: 1.2722\n",
      "Train Epoch: 4 [40320/110534 (36%)]\tAll Loss: 2.4052\tTriple Loss(1): 0.2999\tClassification Loss: 1.8054\n",
      "Train Epoch: 4 [40640/110534 (37%)]\tAll Loss: 1.9097\tTriple Loss(1): 0.1354\tClassification Loss: 1.6389\n",
      "Train Epoch: 4 [40960/110534 (37%)]\tAll Loss: 1.4005\tTriple Loss(0): 0.0000\tClassification Loss: 1.4005\n",
      "Train Epoch: 4 [41280/110534 (37%)]\tAll Loss: 2.0128\tTriple Loss(1): 0.2322\tClassification Loss: 1.5485\n",
      "\n",
      "Test set: Average loss: 1.5955, Accuracy: 557/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [41600/110534 (38%)]\tAll Loss: 1.6653\tTriple Loss(0): 0.0000\tClassification Loss: 1.6653\n",
      "Train Epoch: 4 [41920/110534 (38%)]\tAll Loss: 2.0519\tTriple Loss(1): 0.2597\tClassification Loss: 1.5326\n",
      "Train Epoch: 4 [42240/110534 (38%)]\tAll Loss: 1.9780\tTriple Loss(1): 0.1133\tClassification Loss: 1.7514\n",
      "Train Epoch: 4 [42560/110534 (38%)]\tAll Loss: 1.9826\tTriple Loss(1): 0.2425\tClassification Loss: 1.4977\n",
      "Train Epoch: 4 [42880/110534 (39%)]\tAll Loss: 2.1550\tTriple Loss(1): 0.2615\tClassification Loss: 1.6320\n",
      "Train Epoch: 4 [43200/110534 (39%)]\tAll Loss: 2.3601\tTriple Loss(1): 0.3899\tClassification Loss: 1.5803\n",
      "Train Epoch: 4 [43520/110534 (39%)]\tAll Loss: 1.3831\tTriple Loss(1): 0.0393\tClassification Loss: 1.3044\n",
      "Train Epoch: 4 [43840/110534 (40%)]\tAll Loss: 2.1792\tTriple Loss(1): 0.2076\tClassification Loss: 1.7639\n",
      "Train Epoch: 4 [44160/110534 (40%)]\tAll Loss: 2.4917\tTriple Loss(1): 0.3037\tClassification Loss: 1.8843\n",
      "Train Epoch: 4 [44480/110534 (40%)]\tAll Loss: 2.0384\tTriple Loss(1): 0.2393\tClassification Loss: 1.5597\n",
      "\n",
      "Test set: Average loss: 1.5973, Accuracy: 556/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [44800/110534 (41%)]\tAll Loss: 1.1836\tTriple Loss(1): 0.0557\tClassification Loss: 1.0722\n",
      "Train Epoch: 4 [45120/110534 (41%)]\tAll Loss: 1.8973\tTriple Loss(1): 0.1777\tClassification Loss: 1.5420\n",
      "Train Epoch: 4 [45440/110534 (41%)]\tAll Loss: 1.8518\tTriple Loss(1): 0.1733\tClassification Loss: 1.5051\n",
      "Train Epoch: 4 [45760/110534 (41%)]\tAll Loss: 1.8246\tTriple Loss(1): 0.1285\tClassification Loss: 1.5676\n",
      "Train Epoch: 4 [46080/110534 (42%)]\tAll Loss: 1.8610\tTriple Loss(1): 0.3239\tClassification Loss: 1.2131\n",
      "Train Epoch: 4 [46400/110534 (42%)]\tAll Loss: 2.9003\tTriple Loss(1): 0.4369\tClassification Loss: 2.0265\n",
      "Train Epoch: 4 [46720/110534 (42%)]\tAll Loss: 2.4275\tTriple Loss(1): 0.2438\tClassification Loss: 1.9398\n",
      "Train Epoch: 4 [47040/110534 (43%)]\tAll Loss: 2.2211\tTriple Loss(1): 0.3706\tClassification Loss: 1.4798\n",
      "Train Epoch: 4 [47360/110534 (43%)]\tAll Loss: 2.1354\tTriple Loss(1): 0.2548\tClassification Loss: 1.6257\n",
      "Train Epoch: 4 [47680/110534 (43%)]\tAll Loss: 1.1829\tTriple Loss(0): 0.0000\tClassification Loss: 1.1829\n",
      "\n",
      "Test set: Average loss: 1.6000, Accuracy: 551/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [48000/110534 (43%)]\tAll Loss: 2.3523\tTriple Loss(1): 0.2275\tClassification Loss: 1.8974\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_1500.pth.tar\n",
      "Train Epoch: 4 [48320/110534 (44%)]\tAll Loss: 2.6035\tTriple Loss(1): 0.3631\tClassification Loss: 1.8773\n",
      "Train Epoch: 4 [48640/110534 (44%)]\tAll Loss: 2.3342\tTriple Loss(1): 0.2337\tClassification Loss: 1.8669\n",
      "Train Epoch: 4 [48960/110534 (44%)]\tAll Loss: 2.1643\tTriple Loss(1): 0.3470\tClassification Loss: 1.4702\n",
      "Train Epoch: 4 [49280/110534 (45%)]\tAll Loss: 2.5824\tTriple Loss(1): 0.5587\tClassification Loss: 1.4649\n",
      "Train Epoch: 4 [49600/110534 (45%)]\tAll Loss: 1.7900\tTriple Loss(0): 0.0000\tClassification Loss: 1.7900\n",
      "Train Epoch: 4 [49920/110534 (45%)]\tAll Loss: 1.6180\tTriple Loss(1): 0.1099\tClassification Loss: 1.3982\n",
      "Train Epoch: 4 [50240/110534 (45%)]\tAll Loss: 1.8281\tTriple Loss(1): 0.2966\tClassification Loss: 1.2350\n",
      "Train Epoch: 4 [50560/110534 (46%)]\tAll Loss: 2.1639\tTriple Loss(1): 0.1529\tClassification Loss: 1.8580\n",
      "Train Epoch: 4 [50880/110534 (46%)]\tAll Loss: 2.8016\tTriple Loss(1): 0.4540\tClassification Loss: 1.8936\n",
      "\n",
      "Test set: Average loss: 1.5952, Accuracy: 552/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [51200/110534 (46%)]\tAll Loss: 2.0792\tTriple Loss(1): 0.2656\tClassification Loss: 1.5480\n",
      "Train Epoch: 4 [51520/110534 (47%)]\tAll Loss: 1.3915\tTriple Loss(0): 0.0000\tClassification Loss: 1.3915\n",
      "Train Epoch: 4 [51840/110534 (47%)]\tAll Loss: 1.6864\tTriple Loss(0): 0.0000\tClassification Loss: 1.6864\n",
      "Train Epoch: 4 [52160/110534 (47%)]\tAll Loss: 2.3159\tTriple Loss(1): 0.2844\tClassification Loss: 1.7472\n",
      "Train Epoch: 4 [52480/110534 (47%)]\tAll Loss: 2.4306\tTriple Loss(1): 0.1389\tClassification Loss: 2.1529\n",
      "Train Epoch: 4 [52800/110534 (48%)]\tAll Loss: 2.0399\tTriple Loss(1): 0.2355\tClassification Loss: 1.5690\n",
      "Train Epoch: 4 [53120/110534 (48%)]\tAll Loss: 2.1957\tTriple Loss(1): 0.2986\tClassification Loss: 1.5985\n",
      "Train Epoch: 4 [53440/110534 (48%)]\tAll Loss: 2.3623\tTriple Loss(1): 0.2389\tClassification Loss: 1.8846\n",
      "Train Epoch: 4 [53760/110534 (49%)]\tAll Loss: 2.0617\tTriple Loss(1): 0.1761\tClassification Loss: 1.7096\n",
      "Train Epoch: 4 [54080/110534 (49%)]\tAll Loss: 2.5485\tTriple Loss(1): 0.2507\tClassification Loss: 2.0471\n",
      "\n",
      "Test set: Average loss: 1.5985, Accuracy: 554/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [54400/110534 (49%)]\tAll Loss: 2.7689\tTriple Loss(1): 0.5512\tClassification Loss: 1.6665\n",
      "Train Epoch: 4 [54720/110534 (49%)]\tAll Loss: 2.0710\tTriple Loss(1): 0.1850\tClassification Loss: 1.7009\n",
      "Train Epoch: 4 [55040/110534 (50%)]\tAll Loss: 2.5161\tTriple Loss(1): 0.2355\tClassification Loss: 2.0451\n",
      "Train Epoch: 4 [55360/110534 (50%)]\tAll Loss: 1.4399\tTriple Loss(0): 0.0435\tClassification Loss: 1.3529\n",
      "Train Epoch: 4 [55680/110534 (50%)]\tAll Loss: 2.3011\tTriple Loss(1): 0.2409\tClassification Loss: 1.8192\n",
      "Train Epoch: 4 [56000/110534 (51%)]\tAll Loss: 2.2018\tTriple Loss(0): 0.0000\tClassification Loss: 2.2018\n",
      "Train Epoch: 4 [56320/110534 (51%)]\tAll Loss: 1.8208\tTriple Loss(0): 0.0000\tClassification Loss: 1.8208\n",
      "Train Epoch: 4 [56640/110534 (51%)]\tAll Loss: 1.0498\tTriple Loss(0): 0.0000\tClassification Loss: 1.0498\n",
      "Train Epoch: 4 [56960/110534 (52%)]\tAll Loss: 2.2406\tTriple Loss(1): 0.2633\tClassification Loss: 1.7141\n",
      "Train Epoch: 4 [57280/110534 (52%)]\tAll Loss: 2.1007\tTriple Loss(1): 0.1892\tClassification Loss: 1.7223\n",
      "\n",
      "Test set: Average loss: 1.5972, Accuracy: 554/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [57600/110534 (52%)]\tAll Loss: 1.8066\tTriple Loss(0): 0.0000\tClassification Loss: 1.8066\n",
      "Train Epoch: 4 [57920/110534 (52%)]\tAll Loss: 1.9905\tTriple Loss(1): 0.1581\tClassification Loss: 1.6743\n",
      "Train Epoch: 4 [58240/110534 (53%)]\tAll Loss: 1.4896\tTriple Loss(1): 0.1581\tClassification Loss: 1.1733\n",
      "Train Epoch: 4 [58560/110534 (53%)]\tAll Loss: 1.2871\tTriple Loss(1): 0.0000\tClassification Loss: 1.2871\n",
      "Train Epoch: 4 [58880/110534 (53%)]\tAll Loss: 2.4145\tTriple Loss(1): 0.3666\tClassification Loss: 1.6814\n",
      "Train Epoch: 4 [59200/110534 (54%)]\tAll Loss: 2.0576\tTriple Loss(1): 0.0994\tClassification Loss: 1.8588\n",
      "Train Epoch: 4 [59520/110534 (54%)]\tAll Loss: 1.8965\tTriple Loss(1): 0.1339\tClassification Loss: 1.6287\n",
      "Train Epoch: 4 [59840/110534 (54%)]\tAll Loss: 1.9590\tTriple Loss(1): 0.2384\tClassification Loss: 1.4822\n",
      "Train Epoch: 4 [60160/110534 (54%)]\tAll Loss: 1.5201\tTriple Loss(0): 0.0000\tClassification Loss: 1.5201\n",
      "Train Epoch: 4 [60480/110534 (55%)]\tAll Loss: 1.5668\tTriple Loss(1): 0.0986\tClassification Loss: 1.3697\n",
      "\n",
      "Test set: Average loss: 1.5963, Accuracy: 554/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [60800/110534 (55%)]\tAll Loss: 2.0602\tTriple Loss(1): 0.1946\tClassification Loss: 1.6709\n",
      "Train Epoch: 4 [61120/110534 (55%)]\tAll Loss: 2.1042\tTriple Loss(1): 0.2008\tClassification Loss: 1.7026\n",
      "Train Epoch: 4 [61440/110534 (56%)]\tAll Loss: 1.6207\tTriple Loss(1): 0.2812\tClassification Loss: 1.0583\n",
      "Train Epoch: 4 [61760/110534 (56%)]\tAll Loss: 2.1675\tTriple Loss(1): 0.2654\tClassification Loss: 1.6368\n",
      "Train Epoch: 4 [62080/110534 (56%)]\tAll Loss: 2.1382\tTriple Loss(1): 0.3114\tClassification Loss: 1.5154\n",
      "Train Epoch: 4 [62400/110534 (56%)]\tAll Loss: 1.2154\tTriple Loss(0): 0.0000\tClassification Loss: 1.2154\n",
      "Train Epoch: 4 [62720/110534 (57%)]\tAll Loss: 1.6270\tTriple Loss(1): 0.1103\tClassification Loss: 1.4063\n",
      "Train Epoch: 4 [63040/110534 (57%)]\tAll Loss: 2.0711\tTriple Loss(1): 0.1132\tClassification Loss: 1.8447\n",
      "Train Epoch: 4 [63360/110534 (57%)]\tAll Loss: 1.8845\tTriple Loss(1): 0.2035\tClassification Loss: 1.4775\n",
      "Train Epoch: 4 [63680/110534 (58%)]\tAll Loss: 1.7647\tTriple Loss(1): 0.1691\tClassification Loss: 1.4265\n",
      "\n",
      "Test set: Average loss: 1.6047, Accuracy: 547/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [64000/110534 (58%)]\tAll Loss: 2.3576\tTriple Loss(1): 0.0760\tClassification Loss: 2.2056\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_2000.pth.tar\n",
      "Train Epoch: 4 [64320/110534 (58%)]\tAll Loss: 1.6223\tTriple Loss(1): 0.1551\tClassification Loss: 1.3121\n",
      "Train Epoch: 4 [64640/110534 (58%)]\tAll Loss: 2.2186\tTriple Loss(0): 0.0000\tClassification Loss: 2.2186\n",
      "Train Epoch: 4 [64960/110534 (59%)]\tAll Loss: 2.2444\tTriple Loss(1): 0.3298\tClassification Loss: 1.5847\n",
      "Train Epoch: 4 [65280/110534 (59%)]\tAll Loss: 2.2175\tTriple Loss(1): 0.2350\tClassification Loss: 1.7475\n",
      "Train Epoch: 4 [65600/110534 (59%)]\tAll Loss: 2.2488\tTriple Loss(1): 0.2247\tClassification Loss: 1.7994\n",
      "Train Epoch: 4 [65920/110534 (60%)]\tAll Loss: 1.5568\tTriple Loss(0): 0.0000\tClassification Loss: 1.5568\n",
      "Train Epoch: 4 [66240/110534 (60%)]\tAll Loss: 1.7678\tTriple Loss(1): 0.0361\tClassification Loss: 1.6956\n",
      "Train Epoch: 4 [66560/110534 (60%)]\tAll Loss: 1.7393\tTriple Loss(1): 0.1750\tClassification Loss: 1.3892\n",
      "Train Epoch: 4 [66880/110534 (60%)]\tAll Loss: 2.3561\tTriple Loss(1): 0.3850\tClassification Loss: 1.5861\n",
      "\n",
      "Test set: Average loss: 1.6003, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [67200/110534 (61%)]\tAll Loss: 2.1307\tTriple Loss(1): 0.1551\tClassification Loss: 1.8205\n",
      "Train Epoch: 4 [67520/110534 (61%)]\tAll Loss: 1.8261\tTriple Loss(0): 0.0000\tClassification Loss: 1.8261\n",
      "Train Epoch: 4 [67840/110534 (61%)]\tAll Loss: 2.3735\tTriple Loss(1): 0.2610\tClassification Loss: 1.8516\n",
      "Train Epoch: 4 [68160/110534 (62%)]\tAll Loss: 1.4197\tTriple Loss(0): 0.0000\tClassification Loss: 1.4197\n",
      "Train Epoch: 4 [68480/110534 (62%)]\tAll Loss: 2.1250\tTriple Loss(1): 0.3298\tClassification Loss: 1.4655\n",
      "Train Epoch: 4 [68800/110534 (62%)]\tAll Loss: 1.8819\tTriple Loss(1): 0.2419\tClassification Loss: 1.3981\n",
      "Train Epoch: 4 [69120/110534 (63%)]\tAll Loss: 1.9601\tTriple Loss(1): 0.1386\tClassification Loss: 1.6828\n",
      "Train Epoch: 4 [69440/110534 (63%)]\tAll Loss: 1.4799\tTriple Loss(0): 0.0000\tClassification Loss: 1.4799\n",
      "Train Epoch: 4 [69760/110534 (63%)]\tAll Loss: 1.9940\tTriple Loss(1): 0.2697\tClassification Loss: 1.4545\n",
      "Train Epoch: 4 [70080/110534 (63%)]\tAll Loss: 1.8492\tTriple Loss(1): 0.1692\tClassification Loss: 1.5109\n",
      "\n",
      "Test set: Average loss: 1.5942, Accuracy: 563/960 (59%)\n",
      "\n",
      "Train Epoch: 4 [70400/110534 (64%)]\tAll Loss: 1.7876\tTriple Loss(1): 0.1457\tClassification Loss: 1.4963\n",
      "Train Epoch: 4 [70720/110534 (64%)]\tAll Loss: 1.9347\tTriple Loss(1): 0.2729\tClassification Loss: 1.3889\n",
      "Train Epoch: 4 [71040/110534 (64%)]\tAll Loss: 1.8869\tTriple Loss(1): 0.2414\tClassification Loss: 1.4041\n",
      "Train Epoch: 4 [71360/110534 (65%)]\tAll Loss: 2.2123\tTriple Loss(1): 0.2217\tClassification Loss: 1.7688\n",
      "Train Epoch: 4 [71680/110534 (65%)]\tAll Loss: 2.1073\tTriple Loss(1): 0.2413\tClassification Loss: 1.6246\n",
      "Train Epoch: 4 [72000/110534 (65%)]\tAll Loss: 2.4729\tTriple Loss(1): 0.3830\tClassification Loss: 1.7069\n",
      "Train Epoch: 4 [72320/110534 (65%)]\tAll Loss: 1.5412\tTriple Loss(0): 0.0000\tClassification Loss: 1.5412\n",
      "Train Epoch: 4 [72640/110534 (66%)]\tAll Loss: 1.5324\tTriple Loss(1): 0.1142\tClassification Loss: 1.3040\n",
      "Train Epoch: 4 [72960/110534 (66%)]\tAll Loss: 1.5052\tTriple Loss(0): 0.0000\tClassification Loss: 1.5052\n",
      "Train Epoch: 4 [73280/110534 (66%)]\tAll Loss: 1.6882\tTriple Loss(1): 0.2256\tClassification Loss: 1.2370\n",
      "\n",
      "Test set: Average loss: 1.5875, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [73600/110534 (67%)]\tAll Loss: 2.4388\tTriple Loss(1): 0.1108\tClassification Loss: 2.2172\n",
      "Train Epoch: 4 [73920/110534 (67%)]\tAll Loss: 2.2566\tTriple Loss(1): 0.2039\tClassification Loss: 1.8487\n",
      "Train Epoch: 4 [74240/110534 (67%)]\tAll Loss: 2.0129\tTriple Loss(1): 0.3629\tClassification Loss: 1.2870\n",
      "Train Epoch: 4 [74560/110534 (67%)]\tAll Loss: 1.9548\tTriple Loss(1): 0.1028\tClassification Loss: 1.7491\n",
      "Train Epoch: 4 [74880/110534 (68%)]\tAll Loss: 1.8811\tTriple Loss(1): 0.1631\tClassification Loss: 1.5549\n",
      "Train Epoch: 4 [75200/110534 (68%)]\tAll Loss: 1.4489\tTriple Loss(0): 0.0000\tClassification Loss: 1.4489\n",
      "Train Epoch: 4 [75520/110534 (68%)]\tAll Loss: 1.9243\tTriple Loss(1): 0.1764\tClassification Loss: 1.5715\n",
      "Train Epoch: 4 [75840/110534 (69%)]\tAll Loss: 2.3496\tTriple Loss(1): 0.4115\tClassification Loss: 1.5265\n",
      "Train Epoch: 4 [76160/110534 (69%)]\tAll Loss: 1.9182\tTriple Loss(1): 0.1355\tClassification Loss: 1.6472\n",
      "Train Epoch: 4 [76480/110534 (69%)]\tAll Loss: 1.6719\tTriple Loss(1): 0.1429\tClassification Loss: 1.3862\n",
      "\n",
      "Test set: Average loss: 1.5884, Accuracy: 552/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [76800/110534 (69%)]\tAll Loss: 1.4688\tTriple Loss(0): 0.0000\tClassification Loss: 1.4688\n",
      "Train Epoch: 4 [77120/110534 (70%)]\tAll Loss: 1.7325\tTriple Loss(1): 0.0892\tClassification Loss: 1.5541\n",
      "Train Epoch: 4 [77440/110534 (70%)]\tAll Loss: 2.1859\tTriple Loss(1): 0.3290\tClassification Loss: 1.5278\n",
      "Train Epoch: 4 [77760/110534 (70%)]\tAll Loss: 1.6206\tTriple Loss(0): 0.0000\tClassification Loss: 1.6206\n",
      "Train Epoch: 4 [78080/110534 (71%)]\tAll Loss: 2.4688\tTriple Loss(1): 0.1314\tClassification Loss: 2.2060\n",
      "Train Epoch: 4 [78400/110534 (71%)]\tAll Loss: 2.0627\tTriple Loss(1): 0.2360\tClassification Loss: 1.5907\n",
      "Train Epoch: 4 [78720/110534 (71%)]\tAll Loss: 1.6236\tTriple Loss(1): 0.2676\tClassification Loss: 1.0885\n",
      "Train Epoch: 4 [79040/110534 (71%)]\tAll Loss: 6.2384\tTriple Loss(0): 2.2640\tClassification Loss: 1.7103\n",
      "Train Epoch: 4 [79360/110534 (72%)]\tAll Loss: 2.5946\tTriple Loss(1): 0.3844\tClassification Loss: 1.8257\n",
      "Train Epoch: 4 [79680/110534 (72%)]\tAll Loss: 2.3705\tTriple Loss(1): 0.4390\tClassification Loss: 1.4924\n",
      "\n",
      "Test set: Average loss: 1.5919, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [80000/110534 (72%)]\tAll Loss: 1.6160\tTriple Loss(1): 0.1650\tClassification Loss: 1.2859\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_2500.pth.tar\n",
      "Train Epoch: 4 [80320/110534 (73%)]\tAll Loss: 1.5677\tTriple Loss(1): 0.2212\tClassification Loss: 1.1252\n",
      "Train Epoch: 4 [80640/110534 (73%)]\tAll Loss: 1.7319\tTriple Loss(1): 0.2649\tClassification Loss: 1.2021\n",
      "Train Epoch: 4 [80960/110534 (73%)]\tAll Loss: 2.0456\tTriple Loss(1): 0.3152\tClassification Loss: 1.4152\n",
      "Train Epoch: 4 [81280/110534 (74%)]\tAll Loss: 1.9366\tTriple Loss(1): 0.2964\tClassification Loss: 1.3437\n",
      "Train Epoch: 4 [81600/110534 (74%)]\tAll Loss: 1.6872\tTriple Loss(1): 0.1420\tClassification Loss: 1.4032\n",
      "Train Epoch: 4 [81920/110534 (74%)]\tAll Loss: 2.2540\tTriple Loss(1): 0.3059\tClassification Loss: 1.6423\n",
      "Train Epoch: 4 [82240/110534 (74%)]\tAll Loss: 2.6418\tTriple Loss(1): 0.3864\tClassification Loss: 1.8690\n",
      "Train Epoch: 4 [82560/110534 (75%)]\tAll Loss: 2.2861\tTriple Loss(1): 0.3289\tClassification Loss: 1.6283\n",
      "Train Epoch: 4 [82880/110534 (75%)]\tAll Loss: 2.8237\tTriple Loss(1): 0.3248\tClassification Loss: 2.1741\n",
      "\n",
      "Test set: Average loss: 1.5875, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [83200/110534 (75%)]\tAll Loss: 1.8082\tTriple Loss(1): 0.1407\tClassification Loss: 1.5268\n",
      "Train Epoch: 4 [83520/110534 (76%)]\tAll Loss: 1.5433\tTriple Loss(0): 0.0252\tClassification Loss: 1.4929\n",
      "Train Epoch: 4 [83840/110534 (76%)]\tAll Loss: 1.3094\tTriple Loss(1): 0.0280\tClassification Loss: 1.2534\n",
      "Train Epoch: 4 [84160/110534 (76%)]\tAll Loss: 1.7579\tTriple Loss(1): 0.3026\tClassification Loss: 1.1527\n",
      "Train Epoch: 4 [84480/110534 (76%)]\tAll Loss: 1.6448\tTriple Loss(1): 0.1885\tClassification Loss: 1.2678\n",
      "Train Epoch: 4 [84800/110534 (77%)]\tAll Loss: 2.3269\tTriple Loss(1): 0.3589\tClassification Loss: 1.6091\n",
      "Train Epoch: 4 [85120/110534 (77%)]\tAll Loss: 1.4429\tTriple Loss(0): 0.0000\tClassification Loss: 1.4429\n",
      "Train Epoch: 4 [85440/110534 (77%)]\tAll Loss: 1.8710\tTriple Loss(1): 0.3793\tClassification Loss: 1.1124\n",
      "Train Epoch: 4 [85760/110534 (78%)]\tAll Loss: 1.6768\tTriple Loss(0): 0.0000\tClassification Loss: 1.6768\n",
      "Train Epoch: 4 [86080/110534 (78%)]\tAll Loss: 1.9893\tTriple Loss(0): 0.0000\tClassification Loss: 1.9893\n",
      "\n",
      "Test set: Average loss: 1.5859, Accuracy: 559/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [86400/110534 (78%)]\tAll Loss: 2.3442\tTriple Loss(1): 0.1932\tClassification Loss: 1.9577\n",
      "Train Epoch: 4 [86720/110534 (78%)]\tAll Loss: 1.7570\tTriple Loss(1): 0.1755\tClassification Loss: 1.4060\n",
      "Train Epoch: 4 [87040/110534 (79%)]\tAll Loss: 2.0247\tTriple Loss(1): 0.2774\tClassification Loss: 1.4700\n",
      "Train Epoch: 4 [87360/110534 (79%)]\tAll Loss: 2.2441\tTriple Loss(1): 0.2272\tClassification Loss: 1.7898\n",
      "Train Epoch: 4 [87680/110534 (79%)]\tAll Loss: 2.0789\tTriple Loss(1): 0.1759\tClassification Loss: 1.7271\n",
      "Train Epoch: 4 [88000/110534 (80%)]\tAll Loss: 2.9043\tTriple Loss(1): 0.2816\tClassification Loss: 2.3411\n",
      "Train Epoch: 4 [88320/110534 (80%)]\tAll Loss: 1.6383\tTriple Loss(1): 0.1182\tClassification Loss: 1.4020\n",
      "Train Epoch: 4 [88640/110534 (80%)]\tAll Loss: 2.0327\tTriple Loss(0): 0.0000\tClassification Loss: 2.0327\n",
      "Train Epoch: 4 [88960/110534 (80%)]\tAll Loss: 2.8804\tTriple Loss(1): 0.5624\tClassification Loss: 1.7556\n",
      "Train Epoch: 4 [89280/110534 (81%)]\tAll Loss: 2.4753\tTriple Loss(1): 0.4196\tClassification Loss: 1.6360\n",
      "\n",
      "Test set: Average loss: 1.5858, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [89600/110534 (81%)]\tAll Loss: 2.2284\tTriple Loss(0): 0.0000\tClassification Loss: 2.2284\n",
      "Train Epoch: 4 [89920/110534 (81%)]\tAll Loss: 2.3901\tTriple Loss(1): 0.3145\tClassification Loss: 1.7610\n",
      "Train Epoch: 4 [90240/110534 (82%)]\tAll Loss: 2.0021\tTriple Loss(1): 0.3006\tClassification Loss: 1.4008\n",
      "Train Epoch: 4 [90560/110534 (82%)]\tAll Loss: 1.6123\tTriple Loss(1): 0.1997\tClassification Loss: 1.2130\n",
      "Train Epoch: 4 [90880/110534 (82%)]\tAll Loss: 2.2769\tTriple Loss(1): 0.3266\tClassification Loss: 1.6237\n",
      "Train Epoch: 4 [91200/110534 (82%)]\tAll Loss: 1.7026\tTriple Loss(1): 0.1548\tClassification Loss: 1.3931\n",
      "Train Epoch: 4 [91520/110534 (83%)]\tAll Loss: 2.6605\tTriple Loss(1): 0.5365\tClassification Loss: 1.5876\n",
      "Train Epoch: 4 [91840/110534 (83%)]\tAll Loss: 1.4709\tTriple Loss(0): 0.0000\tClassification Loss: 1.4709\n",
      "Train Epoch: 4 [92160/110534 (83%)]\tAll Loss: 2.6662\tTriple Loss(1): 0.3617\tClassification Loss: 1.9427\n",
      "Train Epoch: 4 [92480/110534 (84%)]\tAll Loss: 1.7738\tTriple Loss(1): 0.0993\tClassification Loss: 1.5752\n",
      "\n",
      "Test set: Average loss: 1.5925, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [92800/110534 (84%)]\tAll Loss: 1.9677\tTriple Loss(1): 0.1546\tClassification Loss: 1.6585\n",
      "Train Epoch: 4 [93120/110534 (84%)]\tAll Loss: 1.7432\tTriple Loss(0): 0.0000\tClassification Loss: 1.7432\n",
      "Train Epoch: 4 [93440/110534 (85%)]\tAll Loss: 1.8013\tTriple Loss(1): 0.1865\tClassification Loss: 1.4282\n",
      "Train Epoch: 4 [93760/110534 (85%)]\tAll Loss: 5.7776\tTriple Loss(0): 2.1513\tClassification Loss: 1.4751\n",
      "Train Epoch: 4 [94080/110534 (85%)]\tAll Loss: 6.7598\tTriple Loss(0): 2.6934\tClassification Loss: 1.3730\n",
      "Train Epoch: 4 [94400/110534 (85%)]\tAll Loss: 1.9653\tTriple Loss(1): 0.1789\tClassification Loss: 1.6075\n",
      "Train Epoch: 4 [94720/110534 (86%)]\tAll Loss: 2.0206\tTriple Loss(1): 0.1857\tClassification Loss: 1.6493\n",
      "Train Epoch: 4 [95040/110534 (86%)]\tAll Loss: 1.8099\tTriple Loss(1): 0.0704\tClassification Loss: 1.6692\n",
      "Train Epoch: 4 [95360/110534 (86%)]\tAll Loss: 2.0932\tTriple Loss(1): 0.2776\tClassification Loss: 1.5380\n",
      "Train Epoch: 4 [95680/110534 (87%)]\tAll Loss: 2.0644\tTriple Loss(1): 0.2134\tClassification Loss: 1.6375\n",
      "\n",
      "Test set: Average loss: 1.5857, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [96000/110534 (87%)]\tAll Loss: 1.9258\tTriple Loss(1): 0.2760\tClassification Loss: 1.3739\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_3000.pth.tar\n",
      "Train Epoch: 4 [96320/110534 (87%)]\tAll Loss: 1.7938\tTriple Loss(1): 0.1750\tClassification Loss: 1.4438\n",
      "Train Epoch: 4 [96640/110534 (87%)]\tAll Loss: 1.7434\tTriple Loss(0): 0.0000\tClassification Loss: 1.7434\n",
      "Train Epoch: 4 [96960/110534 (88%)]\tAll Loss: 1.9789\tTriple Loss(1): 0.2907\tClassification Loss: 1.3976\n",
      "Train Epoch: 4 [97280/110534 (88%)]\tAll Loss: 1.5676\tTriple Loss(1): 0.1746\tClassification Loss: 1.2184\n",
      "Train Epoch: 4 [97600/110534 (88%)]\tAll Loss: 2.1359\tTriple Loss(1): 0.2092\tClassification Loss: 1.7174\n",
      "Train Epoch: 4 [97920/110534 (89%)]\tAll Loss: 1.1293\tTriple Loss(0): 0.0000\tClassification Loss: 1.1293\n",
      "Train Epoch: 4 [98240/110534 (89%)]\tAll Loss: 1.6372\tTriple Loss(1): 0.2127\tClassification Loss: 1.2119\n",
      "Train Epoch: 4 [98560/110534 (89%)]\tAll Loss: 1.1898\tTriple Loss(0): 0.0000\tClassification Loss: 1.1898\n",
      "Train Epoch: 4 [98880/110534 (89%)]\tAll Loss: 1.4673\tTriple Loss(0): 0.0000\tClassification Loss: 1.4673\n",
      "\n",
      "Test set: Average loss: 1.6001, Accuracy: 555/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [99200/110534 (90%)]\tAll Loss: 1.9585\tTriple Loss(1): 0.2448\tClassification Loss: 1.4690\n",
      "Train Epoch: 4 [99520/110534 (90%)]\tAll Loss: 1.8197\tTriple Loss(1): 0.1254\tClassification Loss: 1.5689\n",
      "Train Epoch: 4 [99840/110534 (90%)]\tAll Loss: 2.0553\tTriple Loss(1): 0.1998\tClassification Loss: 1.6556\n",
      "Train Epoch: 4 [100160/110534 (91%)]\tAll Loss: 4.3528\tTriple Loss(0): 1.2153\tClassification Loss: 1.9223\n",
      "Train Epoch: 4 [100480/110534 (91%)]\tAll Loss: 2.0049\tTriple Loss(1): 0.2379\tClassification Loss: 1.5290\n",
      "Train Epoch: 4 [100800/110534 (91%)]\tAll Loss: 3.4454\tTriple Loss(0): 0.8193\tClassification Loss: 1.8068\n",
      "Train Epoch: 4 [101120/110534 (91%)]\tAll Loss: 1.8647\tTriple Loss(1): 0.2451\tClassification Loss: 1.3744\n",
      "Train Epoch: 4 [101440/110534 (92%)]\tAll Loss: 2.0374\tTriple Loss(1): 0.3677\tClassification Loss: 1.3021\n",
      "Train Epoch: 4 [101760/110534 (92%)]\tAll Loss: 1.7292\tTriple Loss(1): 0.0663\tClassification Loss: 1.5965\n",
      "Train Epoch: 4 [102080/110534 (92%)]\tAll Loss: 2.8579\tTriple Loss(1): 0.3550\tClassification Loss: 2.1479\n",
      "\n",
      "Test set: Average loss: 1.5898, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [102400/110534 (93%)]\tAll Loss: 1.7546\tTriple Loss(1): 0.1591\tClassification Loss: 1.4363\n",
      "Train Epoch: 4 [102720/110534 (93%)]\tAll Loss: 2.2690\tTriple Loss(1): 0.3175\tClassification Loss: 1.6341\n",
      "Train Epoch: 4 [103040/110534 (93%)]\tAll Loss: 2.0679\tTriple Loss(1): 0.2930\tClassification Loss: 1.4818\n",
      "Train Epoch: 4 [103360/110534 (93%)]\tAll Loss: 1.9058\tTriple Loss(0): 0.0000\tClassification Loss: 1.9058\n",
      "Train Epoch: 4 [103680/110534 (94%)]\tAll Loss: 2.3772\tTriple Loss(1): 0.3019\tClassification Loss: 1.7735\n",
      "Train Epoch: 4 [104000/110534 (94%)]\tAll Loss: 1.7711\tTriple Loss(1): 0.1266\tClassification Loss: 1.5179\n",
      "Train Epoch: 4 [104320/110534 (94%)]\tAll Loss: 1.9167\tTriple Loss(0): 0.0000\tClassification Loss: 1.9167\n",
      "Train Epoch: 4 [104640/110534 (95%)]\tAll Loss: 2.2616\tTriple Loss(1): 0.2138\tClassification Loss: 1.8341\n",
      "Train Epoch: 4 [104960/110534 (95%)]\tAll Loss: 1.5719\tTriple Loss(0): 0.0000\tClassification Loss: 1.5719\n",
      "Train Epoch: 4 [105280/110534 (95%)]\tAll Loss: 1.9879\tTriple Loss(1): 0.1800\tClassification Loss: 1.6280\n",
      "\n",
      "Test set: Average loss: 1.5918, Accuracy: 560/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [105600/110534 (96%)]\tAll Loss: 2.0039\tTriple Loss(1): 0.1176\tClassification Loss: 1.7687\n",
      "Train Epoch: 4 [105920/110534 (96%)]\tAll Loss: 1.7262\tTriple Loss(0): 0.0000\tClassification Loss: 1.7262\n",
      "Train Epoch: 4 [106240/110534 (96%)]\tAll Loss: 1.6088\tTriple Loss(1): 0.1576\tClassification Loss: 1.2937\n",
      "Train Epoch: 4 [106560/110534 (96%)]\tAll Loss: 1.8804\tTriple Loss(1): 0.1281\tClassification Loss: 1.6243\n",
      "Train Epoch: 4 [106880/110534 (97%)]\tAll Loss: 2.9208\tTriple Loss(1): 0.4500\tClassification Loss: 2.0208\n",
      "Train Epoch: 4 [107200/110534 (97%)]\tAll Loss: 1.8484\tTriple Loss(0): 0.0000\tClassification Loss: 1.8484\n",
      "Train Epoch: 4 [107520/110534 (97%)]\tAll Loss: 1.9060\tTriple Loss(1): 0.1496\tClassification Loss: 1.6068\n",
      "Train Epoch: 4 [107840/110534 (98%)]\tAll Loss: 1.5530\tTriple Loss(0): 0.0000\tClassification Loss: 1.5530\n",
      "Train Epoch: 4 [108160/110534 (98%)]\tAll Loss: 1.5517\tTriple Loss(1): 0.1518\tClassification Loss: 1.2481\n",
      "Train Epoch: 4 [108480/110534 (98%)]\tAll Loss: 1.8281\tTriple Loss(1): 0.0946\tClassification Loss: 1.6390\n",
      "\n",
      "Test set: Average loss: 1.5840, Accuracy: 557/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [108800/110534 (98%)]\tAll Loss: 1.6886\tTriple Loss(0): 0.0000\tClassification Loss: 1.6886\n",
      "Train Epoch: 4 [109120/110534 (99%)]\tAll Loss: 2.2969\tTriple Loss(1): 0.2016\tClassification Loss: 1.8937\n",
      "Train Epoch: 4 [109440/110534 (99%)]\tAll Loss: 1.8607\tTriple Loss(1): 0.2129\tClassification Loss: 1.4349\n",
      "Train Epoch: 4 [109760/110534 (99%)]\tAll Loss: 1.5134\tTriple Loss(0): 0.0000\tClassification Loss: 1.5134\n",
      "Train Epoch: 4 [110080/110534 (100%)]\tAll Loss: 2.1339\tTriple Loss(1): 0.2114\tClassification Loss: 1.7110\n",
      "Train Epoch: 4 [110400/110534 (100%)]\tAll Loss: 1.9492\tTriple Loss(1): 0.1944\tClassification Loss: 1.5605\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_final.pth.tar\n",
      "\n",
      "Test set: Average loss: 1.5863, Accuracy: 556/960 (58%)\n",
      "\n",
      "Train Epoch: 5 [0/110534 (0%)]\tAll Loss: 1.9346\tTriple Loss(1): 0.2073\tClassification Loss: 1.5200\n",
      "Train Epoch: 5 [320/110534 (0%)]\tAll Loss: 2.3173\tTriple Loss(1): 0.4272\tClassification Loss: 1.4629\n",
      "Train Epoch: 5 [640/110534 (1%)]\tAll Loss: 1.3295\tTriple Loss(1): 0.1510\tClassification Loss: 1.0275\n",
      "Train Epoch: 5 [960/110534 (1%)]\tAll Loss: 2.3740\tTriple Loss(1): 0.2690\tClassification Loss: 1.8360\n",
      "Train Epoch: 5 [1280/110534 (1%)]\tAll Loss: 1.6855\tTriple Loss(1): 0.1196\tClassification Loss: 1.4463\n",
      "Train Epoch: 5 [1600/110534 (1%)]\tAll Loss: 2.0910\tTriple Loss(1): 0.1966\tClassification Loss: 1.6978\n",
      "Train Epoch: 5 [1920/110534 (2%)]\tAll Loss: 1.8110\tTriple Loss(1): 0.0815\tClassification Loss: 1.6479\n",
      "Train Epoch: 5 [2240/110534 (2%)]\tAll Loss: 1.8682\tTriple Loss(1): 0.1483\tClassification Loss: 1.5715\n",
      "Train Epoch: 5 [2560/110534 (2%)]\tAll Loss: 1.8474\tTriple Loss(1): 0.1536\tClassification Loss: 1.5401\n",
      "Train Epoch: 5 [2880/110534 (3%)]\tAll Loss: 2.1520\tTriple Loss(1): 0.0997\tClassification Loss: 1.9525\n",
      "\n",
      "Test set: Average loss: 1.5915, Accuracy: 557/960 (58%)\n",
      "\n",
      "Train Epoch: 5 [3200/110534 (3%)]\tAll Loss: 2.2608\tTriple Loss(1): 0.0764\tClassification Loss: 2.1080\n",
      "Train Epoch: 5 [3520/110534 (3%)]\tAll Loss: 1.2783\tTriple Loss(0): 0.0000\tClassification Loss: 1.2783\n",
      "Train Epoch: 5 [3840/110534 (3%)]\tAll Loss: 2.3105\tTriple Loss(1): 0.3141\tClassification Loss: 1.6823\n",
      "Train Epoch: 5 [4160/110534 (4%)]\tAll Loss: 1.9516\tTriple Loss(1): 0.1785\tClassification Loss: 1.5946\n",
      "Train Epoch: 5 [4480/110534 (4%)]\tAll Loss: 1.9282\tTriple Loss(1): 0.2533\tClassification Loss: 1.4215\n",
      "Train Epoch: 5 [4800/110534 (4%)]\tAll Loss: 1.6674\tTriple Loss(1): 0.1065\tClassification Loss: 1.4543\n",
      "Train Epoch: 5 [5120/110534 (5%)]\tAll Loss: 2.0875\tTriple Loss(1): 0.1981\tClassification Loss: 1.6913\n",
      "Train Epoch: 5 [5440/110534 (5%)]\tAll Loss: 2.0870\tTriple Loss(1): 0.1956\tClassification Loss: 1.6959\n",
      "Train Epoch: 5 [5760/110534 (5%)]\tAll Loss: 1.8451\tTriple Loss(1): 0.3835\tClassification Loss: 1.0781\n",
      "Train Epoch: 5 [6080/110534 (5%)]\tAll Loss: 1.4283\tTriple Loss(0): 0.0000\tClassification Loss: 1.4283\n",
      "\n",
      "Test set: Average loss: 1.5851, Accuracy: 552/960 (58%)\n",
      "\n",
      "Train Epoch: 5 [6400/110534 (6%)]\tAll Loss: 2.6505\tTriple Loss(1): 0.4293\tClassification Loss: 1.7919\n",
      "Train Epoch: 5 [6720/110534 (6%)]\tAll Loss: 1.6735\tTriple Loss(0): 0.0000\tClassification Loss: 1.6735\n",
      "Train Epoch: 5 [7040/110534 (6%)]\tAll Loss: 2.4707\tTriple Loss(1): 0.2980\tClassification Loss: 1.8746\n",
      "Train Epoch: 5 [7360/110534 (7%)]\tAll Loss: 2.0783\tTriple Loss(1): 0.3011\tClassification Loss: 1.4761\n",
      "Train Epoch: 5 [7680/110534 (7%)]\tAll Loss: 1.7756\tTriple Loss(1): 0.2950\tClassification Loss: 1.1856\n",
      "Train Epoch: 5 [8000/110534 (7%)]\tAll Loss: 1.5714\tTriple Loss(1): 0.1494\tClassification Loss: 1.2726\n",
      "Train Epoch: 5 [8320/110534 (8%)]\tAll Loss: 2.2170\tTriple Loss(1): 0.3513\tClassification Loss: 1.5143\n",
      "Train Epoch: 5 [8640/110534 (8%)]\tAll Loss: 1.6244\tTriple Loss(1): 0.1581\tClassification Loss: 1.3083\n",
      "Train Epoch: 5 [8960/110534 (8%)]\tAll Loss: 13.5483\tTriple Loss(0): 6.0888\tClassification Loss: 1.3707\n",
      "Train Epoch: 5 [9280/110534 (8%)]\tAll Loss: 1.2703\tTriple Loss(0): 0.0000\tClassification Loss: 1.2703\n",
      "\n",
      "Test set: Average loss: 1.5826, Accuracy: 551/960 (57%)\n",
      "\n",
      "Train Epoch: 5 [9600/110534 (9%)]\tAll Loss: 2.4587\tTriple Loss(1): 0.2710\tClassification Loss: 1.9167\n",
      "Train Epoch: 5 [9920/110534 (9%)]\tAll Loss: 1.6368\tTriple Loss(1): 0.0935\tClassification Loss: 1.4497\n",
      "Train Epoch: 5 [10240/110534 (9%)]\tAll Loss: 1.8395\tTriple Loss(0): 0.0000\tClassification Loss: 1.8395\n",
      "Train Epoch: 5 [10560/110534 (10%)]\tAll Loss: 1.7452\tTriple Loss(0): 0.0000\tClassification Loss: 1.7452\n",
      "Train Epoch: 5 [10880/110534 (10%)]\tAll Loss: 1.9553\tTriple Loss(1): 0.1227\tClassification Loss: 1.7098\n",
      "Train Epoch: 5 [11200/110534 (10%)]\tAll Loss: 1.5803\tTriple Loss(1): 0.1332\tClassification Loss: 1.3139\n",
      "Train Epoch: 5 [11520/110534 (10%)]\tAll Loss: 2.0895\tTriple Loss(1): 0.2813\tClassification Loss: 1.5270\n",
      "Train Epoch: 5 [11840/110534 (11%)]\tAll Loss: 2.0519\tTriple Loss(1): 0.2374\tClassification Loss: 1.5772\n",
      "Train Epoch: 5 [12160/110534 (11%)]\tAll Loss: 2.3497\tTriple Loss(1): 0.3123\tClassification Loss: 1.7251\n",
      "Train Epoch: 5 [12480/110534 (11%)]\tAll Loss: 2.0096\tTriple Loss(1): 0.1812\tClassification Loss: 1.6472\n",
      "\n",
      "Test set: Average loss: 1.5827, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 5 [12800/110534 (12%)]\tAll Loss: 1.4241\tTriple Loss(0): 0.0000\tClassification Loss: 1.4241\n",
      "Train Epoch: 5 [13120/110534 (12%)]\tAll Loss: 1.3893\tTriple Loss(0): 0.0000\tClassification Loss: 1.3893\n",
      "Train Epoch: 5 [13440/110534 (12%)]\tAll Loss: 2.5202\tTriple Loss(1): 0.1951\tClassification Loss: 2.1300\n",
      "Train Epoch: 5 [13760/110534 (12%)]\tAll Loss: 3.0111\tTriple Loss(1): 0.6506\tClassification Loss: 1.7100\n",
      "Train Epoch: 5 [14080/110534 (13%)]\tAll Loss: 1.9223\tTriple Loss(1): 0.1785\tClassification Loss: 1.5652\n",
      "Train Epoch: 5 [14400/110534 (13%)]\tAll Loss: 2.2244\tTriple Loss(1): 0.0635\tClassification Loss: 2.0973\n",
      "Train Epoch: 5 [14720/110534 (13%)]\tAll Loss: 2.0267\tTriple Loss(1): 0.1697\tClassification Loss: 1.6873\n",
      "Train Epoch: 5 [15040/110534 (14%)]\tAll Loss: 1.7934\tTriple Loss(1): 0.1364\tClassification Loss: 1.5206\n",
      "Train Epoch: 5 [15360/110534 (14%)]\tAll Loss: 1.7923\tTriple Loss(1): 0.1004\tClassification Loss: 1.5915\n",
      "Train Epoch: 5 [15680/110534 (14%)]\tAll Loss: 1.8293\tTriple Loss(1): 0.2257\tClassification Loss: 1.3779\n",
      "\n",
      "Test set: Average loss: 1.5820, Accuracy: 551/960 (57%)\n",
      "\n",
      "Train Epoch: 5 [16000/110534 (14%)]\tAll Loss: 3.5146\tTriple Loss(0): 0.9210\tClassification Loss: 1.6725\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_5_500.pth.tar\n",
      "Train Epoch: 5 [16320/110534 (15%)]\tAll Loss: 1.8803\tTriple Loss(1): 0.2743\tClassification Loss: 1.3317\n",
      "Train Epoch: 5 [16640/110534 (15%)]\tAll Loss: 2.0335\tTriple Loss(1): 0.1485\tClassification Loss: 1.7366\n",
      "Train Epoch: 5 [16960/110534 (15%)]\tAll Loss: 2.3462\tTriple Loss(1): 0.1616\tClassification Loss: 2.0230\n",
      "Train Epoch: 5 [17280/110534 (16%)]\tAll Loss: 1.7425\tTriple Loss(1): 0.1579\tClassification Loss: 1.4266\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WQN1zCcsuzua",
    "colab_type": "code",
    "outputId": "56702ff0-f0a8-40bb-f7f0-d2a4bba654e0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "# From scratch. FREEZE = False. LR=0.01\n",
    "! python train.py"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:220: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:704: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  \"please use transforms.RandomResizedCrop instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "train.py:132: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "\n",
      "Test set: Average loss: 3.4774, Accuracy: 58/960 (6%)\n",
      "\n",
      "Train Epoch: 1 [0/110534 (0%)]\tAll Loss: 6.3927\tTriple Loss(0): 1.5768\tClassification Loss: 3.2391\n",
      "Train Epoch: 1 [320/110534 (0%)]\tAll Loss: 7.2953\tTriple Loss(0): 1.1788\tClassification Loss: 4.9378\n",
      "Train Epoch: 1 [640/110534 (1%)]\tAll Loss: 4.4997\tTriple Loss(1): 0.8896\tClassification Loss: 2.7204\n",
      "Train Epoch: 1 [960/110534 (1%)]\tAll Loss: 2.4944\tTriple Loss(0): 0.0000\tClassification Loss: 2.4944\n",
      "Train Epoch: 1 [1280/110534 (1%)]\tAll Loss: 4.5276\tTriple Loss(1): 0.9104\tClassification Loss: 2.7068\n",
      "Train Epoch: 1 [1600/110534 (1%)]\tAll Loss: 4.2570\tTriple Loss(1): 0.7107\tClassification Loss: 2.8356\n",
      "Train Epoch: 1 [1920/110534 (2%)]\tAll Loss: 5.3400\tTriple Loss(0): 1.5198\tClassification Loss: 2.3005\n",
      "Train Epoch: 1 [2240/110534 (2%)]\tAll Loss: 2.5340\tTriple Loss(0): 0.0000\tClassification Loss: 2.5340\n",
      "Train Epoch: 1 [2560/110534 (2%)]\tAll Loss: 4.3180\tTriple Loss(1): 0.9147\tClassification Loss: 2.4887\n",
      "Train Epoch: 1 [2880/110534 (3%)]\tAll Loss: 4.2571\tTriple Loss(1): 0.9409\tClassification Loss: 2.3753\n",
      "\n",
      "Test set: Average loss: 2.6772, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [3200/110534 (3%)]\tAll Loss: 4.1243\tTriple Loss(1): 0.7547\tClassification Loss: 2.6149\n",
      "Train Epoch: 1 [3520/110534 (3%)]\tAll Loss: 4.4523\tTriple Loss(1): 0.9022\tClassification Loss: 2.6479\n",
      "Train Epoch: 1 [3840/110534 (3%)]\tAll Loss: 4.3290\tTriple Loss(1): 0.9194\tClassification Loss: 2.4903\n",
      "Train Epoch: 1 [4160/110534 (4%)]\tAll Loss: 6.0292\tTriple Loss(0): 1.6875\tClassification Loss: 2.6541\n",
      "Train Epoch: 1 [4480/110534 (4%)]\tAll Loss: 5.3994\tTriple Loss(0): 1.4073\tClassification Loss: 2.5848\n",
      "Train Epoch: 1 [4800/110534 (4%)]\tAll Loss: 4.2473\tTriple Loss(1): 0.9426\tClassification Loss: 2.3621\n",
      "Train Epoch: 1 [5120/110534 (5%)]\tAll Loss: 4.4257\tTriple Loss(1): 0.9199\tClassification Loss: 2.5860\n",
      "Train Epoch: 1 [5440/110534 (5%)]\tAll Loss: 5.1151\tTriple Loss(1): 0.9369\tClassification Loss: 3.2413\n",
      "Train Epoch: 1 [5760/110534 (5%)]\tAll Loss: 4.1016\tTriple Loss(1): 0.7977\tClassification Loss: 2.5062\n",
      "Train Epoch: 1 [6080/110534 (5%)]\tAll Loss: 3.8709\tTriple Loss(1): 0.7892\tClassification Loss: 2.2924\n",
      "\n",
      "Test set: Average loss: 2.6767, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [6400/110534 (6%)]\tAll Loss: 4.0436\tTriple Loss(1): 0.7719\tClassification Loss: 2.4999\n",
      "Train Epoch: 1 [6720/110534 (6%)]\tAll Loss: 3.9948\tTriple Loss(1): 0.7379\tClassification Loss: 2.5191\n",
      "Train Epoch: 1 [7040/110534 (6%)]\tAll Loss: 3.9228\tTriple Loss(1): 0.8700\tClassification Loss: 2.1828\n",
      "Train Epoch: 1 [7360/110534 (7%)]\tAll Loss: 4.3355\tTriple Loss(0): 0.8877\tClassification Loss: 2.5601\n",
      "Train Epoch: 1 [7680/110534 (7%)]\tAll Loss: 4.0670\tTriple Loss(1): 0.8836\tClassification Loss: 2.2997\n",
      "Train Epoch: 1 [8000/110534 (7%)]\tAll Loss: 4.2738\tTriple Loss(1): 0.9201\tClassification Loss: 2.4335\n",
      "Train Epoch: 1 [8320/110534 (8%)]\tAll Loss: 4.7312\tTriple Loss(0): 1.0168\tClassification Loss: 2.6977\n",
      "Train Epoch: 1 [8640/110534 (8%)]\tAll Loss: 4.3484\tTriple Loss(1): 0.9238\tClassification Loss: 2.5008\n",
      "Train Epoch: 1 [8960/110534 (8%)]\tAll Loss: 4.0268\tTriple Loss(1): 0.7372\tClassification Loss: 2.5524\n",
      "Train Epoch: 1 [9280/110534 (8%)]\tAll Loss: 7.4774\tTriple Loss(0): 2.4656\tClassification Loss: 2.5462\n",
      "\n",
      "Test set: Average loss: 2.8447, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [9600/110534 (9%)]\tAll Loss: 4.7577\tTriple Loss(1): 0.9924\tClassification Loss: 2.7729\n",
      "Train Epoch: 1 [9920/110534 (9%)]\tAll Loss: 4.8479\tTriple Loss(0): 1.1232\tClassification Loss: 2.6015\n",
      "Train Epoch: 1 [10240/110534 (9%)]\tAll Loss: 4.1653\tTriple Loss(1): 0.8588\tClassification Loss: 2.4477\n",
      "Train Epoch: 1 [10560/110534 (10%)]\tAll Loss: 4.1695\tTriple Loss(1): 0.7784\tClassification Loss: 2.6127\n",
      "Train Epoch: 1 [10880/110534 (10%)]\tAll Loss: 3.3668\tTriple Loss(1): 0.6423\tClassification Loss: 2.0822\n",
      "Train Epoch: 1 [11200/110534 (10%)]\tAll Loss: 4.0505\tTriple Loss(1): 0.7542\tClassification Loss: 2.5421\n",
      "Train Epoch: 1 [11520/110534 (10%)]\tAll Loss: 4.2915\tTriple Loss(1): 0.8644\tClassification Loss: 2.5628\n",
      "Train Epoch: 1 [11840/110534 (11%)]\tAll Loss: 4.5104\tTriple Loss(1): 0.9290\tClassification Loss: 2.6525\n",
      "Train Epoch: 1 [12160/110534 (11%)]\tAll Loss: 4.0403\tTriple Loss(1): 0.8604\tClassification Loss: 2.3194\n",
      "Train Epoch: 1 [12480/110534 (11%)]\tAll Loss: 4.4361\tTriple Loss(1): 0.9970\tClassification Loss: 2.4421\n",
      "\n",
      "Test set: Average loss: 2.6686, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [12800/110534 (12%)]\tAll Loss: 4.2094\tTriple Loss(1): 0.8399\tClassification Loss: 2.5296\n",
      "Train Epoch: 1 [13120/110534 (12%)]\tAll Loss: 4.4838\tTriple Loss(1): 1.0555\tClassification Loss: 2.3728\n",
      "Train Epoch: 1 [13440/110534 (12%)]\tAll Loss: 4.5072\tTriple Loss(1): 0.9801\tClassification Loss: 2.5470\n",
      "Train Epoch: 1 [13760/110534 (12%)]\tAll Loss: 3.4201\tTriple Loss(0): 0.4881\tClassification Loss: 2.4438\n",
      "Train Epoch: 1 [14080/110534 (13%)]\tAll Loss: 4.2018\tTriple Loss(1): 0.8508\tClassification Loss: 2.5002\n",
      "Train Epoch: 1 [14400/110534 (13%)]\tAll Loss: 4.2747\tTriple Loss(1): 0.9568\tClassification Loss: 2.3611\n",
      "Train Epoch: 1 [14720/110534 (13%)]\tAll Loss: 8.5445\tTriple Loss(0): 3.1487\tClassification Loss: 2.2470\n",
      "Train Epoch: 1 [15040/110534 (14%)]\tAll Loss: 4.1940\tTriple Loss(1): 0.9116\tClassification Loss: 2.3708\n",
      "Train Epoch: 1 [15360/110534 (14%)]\tAll Loss: 4.3293\tTriple Loss(1): 0.8798\tClassification Loss: 2.5697\n",
      "Train Epoch: 1 [15680/110534 (14%)]\tAll Loss: 4.8355\tTriple Loss(0): 1.0902\tClassification Loss: 2.6550\n",
      "\n",
      "Test set: Average loss: 2.6613, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [16000/110534 (14%)]\tAll Loss: 4.3279\tTriple Loss(1): 0.9446\tClassification Loss: 2.4386\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_500.pth.tar\n",
      "Train Epoch: 1 [16320/110534 (15%)]\tAll Loss: 4.5907\tTriple Loss(1): 0.9076\tClassification Loss: 2.7754\n",
      "Train Epoch: 1 [16640/110534 (15%)]\tAll Loss: 5.5341\tTriple Loss(0): 1.4708\tClassification Loss: 2.5926\n",
      "Train Epoch: 1 [16960/110534 (15%)]\tAll Loss: 2.4883\tTriple Loss(0): 0.0000\tClassification Loss: 2.4883\n",
      "Train Epoch: 1 [17280/110534 (16%)]\tAll Loss: 4.1963\tTriple Loss(1): 0.8973\tClassification Loss: 2.4017\n",
      "Train Epoch: 1 [17600/110534 (16%)]\tAll Loss: 3.9172\tTriple Loss(1): 0.6945\tClassification Loss: 2.5282\n",
      "Train Epoch: 1 [17920/110534 (16%)]\tAll Loss: 4.1890\tTriple Loss(1): 0.8385\tClassification Loss: 2.5119\n",
      "Train Epoch: 1 [18240/110534 (16%)]\tAll Loss: 4.4191\tTriple Loss(1): 0.9389\tClassification Loss: 2.5413\n",
      "Train Epoch: 1 [18560/110534 (17%)]\tAll Loss: 4.6381\tTriple Loss(1): 0.9491\tClassification Loss: 2.7399\n",
      "Train Epoch: 1 [18880/110534 (17%)]\tAll Loss: 4.3851\tTriple Loss(1): 0.8349\tClassification Loss: 2.7153\n",
      "\n",
      "Test set: Average loss: 2.6528, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [19200/110534 (17%)]\tAll Loss: 4.4306\tTriple Loss(1): 0.9319\tClassification Loss: 2.5668\n",
      "Train Epoch: 1 [19520/110534 (18%)]\tAll Loss: 2.5804\tTriple Loss(0): 0.0000\tClassification Loss: 2.5804\n",
      "Train Epoch: 1 [19840/110534 (18%)]\tAll Loss: 4.1453\tTriple Loss(1): 0.8753\tClassification Loss: 2.3946\n",
      "Train Epoch: 1 [20160/110534 (18%)]\tAll Loss: 4.0131\tTriple Loss(1): 0.8551\tClassification Loss: 2.3028\n",
      "Train Epoch: 1 [20480/110534 (19%)]\tAll Loss: 4.2994\tTriple Loss(1): 0.8849\tClassification Loss: 2.5296\n",
      "Train Epoch: 1 [20800/110534 (19%)]\tAll Loss: 4.4528\tTriple Loss(1): 0.9643\tClassification Loss: 2.5241\n",
      "Train Epoch: 1 [21120/110534 (19%)]\tAll Loss: 4.5310\tTriple Loss(1): 0.8650\tClassification Loss: 2.8009\n",
      "Train Epoch: 1 [21440/110534 (19%)]\tAll Loss: 4.4944\tTriple Loss(1): 0.9457\tClassification Loss: 2.6029\n",
      "Train Epoch: 1 [21760/110534 (20%)]\tAll Loss: 4.1482\tTriple Loss(1): 0.7665\tClassification Loss: 2.6153\n",
      "Train Epoch: 1 [22080/110534 (20%)]\tAll Loss: 4.1255\tTriple Loss(1): 0.7416\tClassification Loss: 2.6424\n",
      "\n",
      "Test set: Average loss: 2.6748, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [22400/110534 (20%)]\tAll Loss: 4.1520\tTriple Loss(1): 0.7861\tClassification Loss: 2.5798\n",
      "Train Epoch: 1 [22720/110534 (21%)]\tAll Loss: 4.3277\tTriple Loss(1): 0.8814\tClassification Loss: 2.5649\n",
      "Train Epoch: 1 [23040/110534 (21%)]\tAll Loss: 4.1481\tTriple Loss(1): 0.8958\tClassification Loss: 2.3566\n",
      "Train Epoch: 1 [23360/110534 (21%)]\tAll Loss: 3.9202\tTriple Loss(1): 0.7689\tClassification Loss: 2.3824\n",
      "Train Epoch: 1 [23680/110534 (21%)]\tAll Loss: 8.2987\tTriple Loss(0): 2.8458\tClassification Loss: 2.6071\n",
      "Train Epoch: 1 [24000/110534 (22%)]\tAll Loss: 4.5714\tTriple Loss(1): 0.9867\tClassification Loss: 2.5980\n",
      "Train Epoch: 1 [24320/110534 (22%)]\tAll Loss: 4.1334\tTriple Loss(1): 0.7681\tClassification Loss: 2.5972\n",
      "Train Epoch: 1 [24640/110534 (22%)]\tAll Loss: 3.8031\tTriple Loss(1): 0.7846\tClassification Loss: 2.2338\n",
      "Train Epoch: 1 [24960/110534 (23%)]\tAll Loss: 3.7348\tTriple Loss(1): 0.6410\tClassification Loss: 2.4527\n",
      "Train Epoch: 1 [25280/110534 (23%)]\tAll Loss: 4.1063\tTriple Loss(1): 0.8097\tClassification Loss: 2.4869\n",
      "\n",
      "Test set: Average loss: 2.6601, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [25600/110534 (23%)]\tAll Loss: 3.9465\tTriple Loss(1): 0.7276\tClassification Loss: 2.4914\n",
      "Train Epoch: 1 [25920/110534 (23%)]\tAll Loss: 5.7636\tTriple Loss(0): 1.5520\tClassification Loss: 2.6596\n",
      "Train Epoch: 1 [26240/110534 (24%)]\tAll Loss: 3.8178\tTriple Loss(1): 0.8391\tClassification Loss: 2.1396\n",
      "Train Epoch: 1 [26560/110534 (24%)]\tAll Loss: 3.7539\tTriple Loss(1): 0.5853\tClassification Loss: 2.5832\n",
      "Train Epoch: 1 [26880/110534 (24%)]\tAll Loss: 3.8732\tTriple Loss(1): 0.6777\tClassification Loss: 2.5177\n",
      "Train Epoch: 1 [27200/110534 (25%)]\tAll Loss: 4.8000\tTriple Loss(0): 1.1752\tClassification Loss: 2.4496\n",
      "Train Epoch: 1 [27520/110534 (25%)]\tAll Loss: 4.1132\tTriple Loss(1): 0.7470\tClassification Loss: 2.6192\n",
      "Train Epoch: 1 [27840/110534 (25%)]\tAll Loss: 4.1018\tTriple Loss(1): 0.8068\tClassification Loss: 2.4883\n",
      "Train Epoch: 1 [28160/110534 (25%)]\tAll Loss: 7.0002\tTriple Loss(0): 2.2984\tClassification Loss: 2.4034\n",
      "Train Epoch: 1 [28480/110534 (26%)]\tAll Loss: 3.9736\tTriple Loss(1): 0.7858\tClassification Loss: 2.4020\n",
      "\n",
      "Test set: Average loss: 2.6639, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [28800/110534 (26%)]\tAll Loss: 3.7584\tTriple Loss(1): 0.6495\tClassification Loss: 2.4594\n",
      "Train Epoch: 1 [29120/110534 (26%)]\tAll Loss: 4.0681\tTriple Loss(1): 0.6573\tClassification Loss: 2.7535\n",
      "Train Epoch: 1 [29440/110534 (27%)]\tAll Loss: 4.4222\tTriple Loss(1): 0.8457\tClassification Loss: 2.7307\n",
      "Train Epoch: 1 [29760/110534 (27%)]\tAll Loss: 4.9471\tTriple Loss(0): 0.9854\tClassification Loss: 2.9762\n",
      "Train Epoch: 1 [30080/110534 (27%)]\tAll Loss: 3.7203\tTriple Loss(1): 0.6304\tClassification Loss: 2.4595\n",
      "Train Epoch: 1 [30400/110534 (27%)]\tAll Loss: 3.6259\tTriple Loss(1): 0.5765\tClassification Loss: 2.4729\n",
      "Train Epoch: 1 [30720/110534 (28%)]\tAll Loss: 4.2980\tTriple Loss(1): 0.8256\tClassification Loss: 2.6469\n",
      "Train Epoch: 1 [31040/110534 (28%)]\tAll Loss: 3.6839\tTriple Loss(1): 0.6456\tClassification Loss: 2.3928\n",
      "Train Epoch: 1 [31360/110534 (28%)]\tAll Loss: 4.0375\tTriple Loss(1): 0.8145\tClassification Loss: 2.4084\n",
      "Train Epoch: 1 [31680/110534 (29%)]\tAll Loss: 4.4286\tTriple Loss(1): 0.8084\tClassification Loss: 2.8117\n",
      "\n",
      "Test set: Average loss: 2.6668, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [32000/110534 (29%)]\tAll Loss: 3.9235\tTriple Loss(1): 0.6228\tClassification Loss: 2.6779\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_1000.pth.tar\n",
      "Train Epoch: 1 [32320/110534 (29%)]\tAll Loss: 4.0697\tTriple Loss(1): 0.8481\tClassification Loss: 2.3736\n",
      "Train Epoch: 1 [32640/110534 (30%)]\tAll Loss: 3.7210\tTriple Loss(1): 0.6839\tClassification Loss: 2.3531\n",
      "Train Epoch: 1 [32960/110534 (30%)]\tAll Loss: 3.4258\tTriple Loss(0): 0.4476\tClassification Loss: 2.5306\n",
      "Train Epoch: 1 [33280/110534 (30%)]\tAll Loss: 4.2453\tTriple Loss(1): 0.8276\tClassification Loss: 2.5901\n",
      "Train Epoch: 1 [33600/110534 (30%)]\tAll Loss: 3.7739\tTriple Loss(1): 0.7161\tClassification Loss: 2.3417\n",
      "Train Epoch: 1 [33920/110534 (31%)]\tAll Loss: 3.8801\tTriple Loss(1): 0.6531\tClassification Loss: 2.5739\n",
      "Train Epoch: 1 [34240/110534 (31%)]\tAll Loss: 3.6513\tTriple Loss(1): 0.7075\tClassification Loss: 2.2363\n",
      "Train Epoch: 1 [34560/110534 (31%)]\tAll Loss: 3.6162\tTriple Loss(0): 0.5754\tClassification Loss: 2.4654\n",
      "Train Epoch: 1 [34880/110534 (32%)]\tAll Loss: 4.5402\tTriple Loss(0): 0.9832\tClassification Loss: 2.5738\n",
      "\n",
      "Test set: Average loss: 2.6561, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [35200/110534 (32%)]\tAll Loss: 3.9922\tTriple Loss(1): 0.6541\tClassification Loss: 2.6840\n",
      "Train Epoch: 1 [35520/110534 (32%)]\tAll Loss: 3.9051\tTriple Loss(0): 0.7399\tClassification Loss: 2.4252\n",
      "Train Epoch: 1 [35840/110534 (32%)]\tAll Loss: 4.0492\tTriple Loss(1): 0.8603\tClassification Loss: 2.3287\n",
      "Train Epoch: 1 [36160/110534 (33%)]\tAll Loss: 4.4272\tTriple Loss(0): 0.9735\tClassification Loss: 2.4803\n",
      "Train Epoch: 1 [36480/110534 (33%)]\tAll Loss: 4.1439\tTriple Loss(1): 0.8121\tClassification Loss: 2.5197\n",
      "Train Epoch: 1 [36800/110534 (33%)]\tAll Loss: 2.7120\tTriple Loss(0): 0.0000\tClassification Loss: 2.7120\n",
      "Train Epoch: 1 [37120/110534 (34%)]\tAll Loss: 4.2137\tTriple Loss(1): 0.7058\tClassification Loss: 2.8021\n",
      "Train Epoch: 1 [37440/110534 (34%)]\tAll Loss: 4.2286\tTriple Loss(1): 0.7150\tClassification Loss: 2.7986\n",
      "Train Epoch: 1 [37760/110534 (34%)]\tAll Loss: 3.9963\tTriple Loss(1): 0.6717\tClassification Loss: 2.6529\n",
      "Train Epoch: 1 [38080/110534 (34%)]\tAll Loss: 4.2253\tTriple Loss(1): 0.8379\tClassification Loss: 2.5496\n",
      "\n",
      "Test set: Average loss: 2.6629, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [38400/110534 (35%)]\tAll Loss: 3.7411\tTriple Loss(1): 0.6992\tClassification Loss: 2.3426\n",
      "Train Epoch: 1 [38720/110534 (35%)]\tAll Loss: 3.3764\tTriple Loss(1): 0.4097\tClassification Loss: 2.5570\n",
      "Train Epoch: 1 [39040/110534 (35%)]\tAll Loss: 4.1509\tTriple Loss(1): 0.8638\tClassification Loss: 2.4232\n",
      "Train Epoch: 1 [39360/110534 (36%)]\tAll Loss: 4.2628\tTriple Loss(1): 0.9046\tClassification Loss: 2.4536\n",
      "Train Epoch: 1 [39680/110534 (36%)]\tAll Loss: 4.2391\tTriple Loss(1): 0.7547\tClassification Loss: 2.7298\n",
      "Train Epoch: 1 [40000/110534 (36%)]\tAll Loss: 2.6321\tTriple Loss(0): 0.0000\tClassification Loss: 2.6321\n",
      "Train Epoch: 1 [40320/110534 (36%)]\tAll Loss: 3.8283\tTriple Loss(1): 0.7154\tClassification Loss: 2.3975\n",
      "Train Epoch: 1 [40640/110534 (37%)]\tAll Loss: 3.8307\tTriple Loss(1): 0.7573\tClassification Loss: 2.3162\n",
      "Train Epoch: 1 [40960/110534 (37%)]\tAll Loss: 3.9246\tTriple Loss(1): 0.7688\tClassification Loss: 2.3869\n",
      "Train Epoch: 1 [41280/110534 (37%)]\tAll Loss: 4.4439\tTriple Loss(1): 0.8794\tClassification Loss: 2.6850\n",
      "\n",
      "Test set: Average loss: 2.7437, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [41600/110534 (38%)]\tAll Loss: 3.8282\tTriple Loss(1): 0.7124\tClassification Loss: 2.4033\n",
      "Train Epoch: 1 [41920/110534 (38%)]\tAll Loss: 3.9216\tTriple Loss(1): 0.7975\tClassification Loss: 2.3266\n",
      "Train Epoch: 1 [42240/110534 (38%)]\tAll Loss: 3.9059\tTriple Loss(1): 0.7218\tClassification Loss: 2.4622\n",
      "Train Epoch: 1 [42560/110534 (38%)]\tAll Loss: 4.2621\tTriple Loss(1): 0.8165\tClassification Loss: 2.6290\n",
      "Train Epoch: 1 [42880/110534 (39%)]\tAll Loss: 3.9384\tTriple Loss(1): 0.6800\tClassification Loss: 2.5784\n",
      "Train Epoch: 1 [43200/110534 (39%)]\tAll Loss: 4.0537\tTriple Loss(1): 0.7590\tClassification Loss: 2.5357\n",
      "Train Epoch: 1 [43520/110534 (39%)]\tAll Loss: 3.8508\tTriple Loss(1): 0.6374\tClassification Loss: 2.5761\n",
      "Train Epoch: 1 [43840/110534 (40%)]\tAll Loss: 3.9722\tTriple Loss(1): 0.7587\tClassification Loss: 2.4548\n",
      "Train Epoch: 1 [44160/110534 (40%)]\tAll Loss: 4.4477\tTriple Loss(1): 0.9011\tClassification Loss: 2.6455\n",
      "Train Epoch: 1 [44480/110534 (40%)]\tAll Loss: 3.9055\tTriple Loss(1): 0.8302\tClassification Loss: 2.2450\n",
      "\n",
      "Test set: Average loss: 2.6481, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [44800/110534 (41%)]\tAll Loss: 4.1332\tTriple Loss(1): 0.7882\tClassification Loss: 2.5567\n",
      "Train Epoch: 1 [45120/110534 (41%)]\tAll Loss: 3.7593\tTriple Loss(1): 0.7328\tClassification Loss: 2.2937\n",
      "Train Epoch: 1 [45440/110534 (41%)]\tAll Loss: 3.8391\tTriple Loss(1): 0.7869\tClassification Loss: 2.2652\n",
      "Train Epoch: 1 [45760/110534 (41%)]\tAll Loss: 4.1812\tTriple Loss(1): 0.8330\tClassification Loss: 2.5152\n",
      "Train Epoch: 1 [46080/110534 (42%)]\tAll Loss: 4.0878\tTriple Loss(1): 0.8500\tClassification Loss: 2.3877\n",
      "Train Epoch: 1 [46400/110534 (42%)]\tAll Loss: 4.2643\tTriple Loss(1): 0.9003\tClassification Loss: 2.4637\n",
      "Train Epoch: 1 [46720/110534 (42%)]\tAll Loss: 3.5854\tTriple Loss(1): 0.7438\tClassification Loss: 2.0979\n",
      "Train Epoch: 1 [47040/110534 (43%)]\tAll Loss: 3.7833\tTriple Loss(1): 0.6576\tClassification Loss: 2.4681\n",
      "Train Epoch: 1 [47360/110534 (43%)]\tAll Loss: 3.9693\tTriple Loss(1): 0.8942\tClassification Loss: 2.1810\n",
      "Train Epoch: 1 [47680/110534 (43%)]\tAll Loss: 3.7576\tTriple Loss(1): 0.5797\tClassification Loss: 2.5983\n",
      "\n",
      "Test set: Average loss: 2.6315, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [48000/110534 (43%)]\tAll Loss: 8.5209\tTriple Loss(0): 3.1098\tClassification Loss: 2.3013\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_1500.pth.tar\n",
      "Train Epoch: 1 [48320/110534 (44%)]\tAll Loss: 4.0806\tTriple Loss(1): 0.7510\tClassification Loss: 2.5787\n",
      "Train Epoch: 1 [48640/110534 (44%)]\tAll Loss: 3.6743\tTriple Loss(1): 0.6843\tClassification Loss: 2.3057\n",
      "Train Epoch: 1 [48960/110534 (44%)]\tAll Loss: 4.1766\tTriple Loss(1): 0.9917\tClassification Loss: 2.1933\n",
      "Train Epoch: 1 [49280/110534 (45%)]\tAll Loss: 4.1863\tTriple Loss(1): 0.8764\tClassification Loss: 2.4335\n",
      "Train Epoch: 1 [49600/110534 (45%)]\tAll Loss: 4.3330\tTriple Loss(1): 0.7780\tClassification Loss: 2.7771\n",
      "Train Epoch: 1 [49920/110534 (45%)]\tAll Loss: 4.0618\tTriple Loss(1): 0.7741\tClassification Loss: 2.5135\n",
      "Train Epoch: 1 [50240/110534 (45%)]\tAll Loss: 3.6110\tTriple Loss(1): 0.5645\tClassification Loss: 2.4819\n",
      "Train Epoch: 1 [50560/110534 (46%)]\tAll Loss: 4.0616\tTriple Loss(1): 0.8380\tClassification Loss: 2.3856\n",
      "Train Epoch: 1 [50880/110534 (46%)]\tAll Loss: 4.4979\tTriple Loss(0): 0.9976\tClassification Loss: 2.5027\n",
      "\n",
      "Test set: Average loss: 2.6499, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [51200/110534 (46%)]\tAll Loss: 4.2981\tTriple Loss(1): 0.8312\tClassification Loss: 2.6357\n",
      "Train Epoch: 1 [51520/110534 (47%)]\tAll Loss: 12.6927\tTriple Loss(0): 5.1161\tClassification Loss: 2.4605\n",
      "Train Epoch: 1 [51840/110534 (47%)]\tAll Loss: 4.2003\tTriple Loss(1): 0.8325\tClassification Loss: 2.5353\n",
      "Train Epoch: 1 [52160/110534 (47%)]\tAll Loss: 3.9495\tTriple Loss(1): 0.7075\tClassification Loss: 2.5345\n",
      "Train Epoch: 1 [52480/110534 (47%)]\tAll Loss: 4.1363\tTriple Loss(1): 0.8198\tClassification Loss: 2.4968\n",
      "Train Epoch: 1 [52800/110534 (48%)]\tAll Loss: 3.8626\tTriple Loss(1): 0.7561\tClassification Loss: 2.3505\n",
      "Train Epoch: 1 [53120/110534 (48%)]\tAll Loss: 4.5070\tTriple Loss(1): 1.0835\tClassification Loss: 2.3401\n",
      "Train Epoch: 1 [53440/110534 (48%)]\tAll Loss: 3.9245\tTriple Loss(1): 0.7964\tClassification Loss: 2.3317\n",
      "Train Epoch: 1 [53760/110534 (49%)]\tAll Loss: 3.6909\tTriple Loss(1): 0.5869\tClassification Loss: 2.5171\n",
      "Train Epoch: 1 [54080/110534 (49%)]\tAll Loss: 3.9717\tTriple Loss(1): 0.8395\tClassification Loss: 2.2927\n",
      "\n",
      "Test set: Average loss: 2.7334, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [54400/110534 (49%)]\tAll Loss: 5.2474\tTriple Loss(0): 1.4444\tClassification Loss: 2.3587\n",
      "Train Epoch: 1 [54720/110534 (49%)]\tAll Loss: 4.4407\tTriple Loss(1): 0.8215\tClassification Loss: 2.7978\n",
      "Train Epoch: 1 [55040/110534 (50%)]\tAll Loss: 3.7474\tTriple Loss(1): 0.6906\tClassification Loss: 2.3662\n",
      "Train Epoch: 1 [55360/110534 (50%)]\tAll Loss: 4.1838\tTriple Loss(0): 0.7159\tClassification Loss: 2.7520\n",
      "Train Epoch: 1 [55680/110534 (50%)]\tAll Loss: 2.4238\tTriple Loss(0): 0.0000\tClassification Loss: 2.4238\n",
      "Train Epoch: 1 [56000/110534 (51%)]\tAll Loss: 3.2547\tTriple Loss(1): 0.4922\tClassification Loss: 2.2703\n",
      "Train Epoch: 1 [56320/110534 (51%)]\tAll Loss: 4.0683\tTriple Loss(1): 0.8153\tClassification Loss: 2.4377\n",
      "Train Epoch: 1 [56640/110534 (51%)]\tAll Loss: 4.3793\tTriple Loss(1): 0.8783\tClassification Loss: 2.6226\n",
      "Train Epoch: 1 [56960/110534 (52%)]\tAll Loss: 4.1905\tTriple Loss(1): 0.7679\tClassification Loss: 2.6548\n",
      "Train Epoch: 1 [57280/110534 (52%)]\tAll Loss: 3.9424\tTriple Loss(1): 0.8441\tClassification Loss: 2.2543\n",
      "\n",
      "Test set: Average loss: 2.6730, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [57600/110534 (52%)]\tAll Loss: 3.8567\tTriple Loss(1): 0.7495\tClassification Loss: 2.3577\n",
      "Train Epoch: 1 [57920/110534 (52%)]\tAll Loss: 3.5804\tTriple Loss(1): 0.6242\tClassification Loss: 2.3320\n",
      "Train Epoch: 1 [58240/110534 (53%)]\tAll Loss: 6.8750\tTriple Loss(0): 2.1449\tClassification Loss: 2.5852\n",
      "Train Epoch: 1 [58560/110534 (53%)]\tAll Loss: 6.0188\tTriple Loss(0): 1.8324\tClassification Loss: 2.3540\n",
      "Train Epoch: 1 [58880/110534 (53%)]\tAll Loss: 3.9976\tTriple Loss(1): 0.8488\tClassification Loss: 2.2999\n",
      "Train Epoch: 1 [59200/110534 (54%)]\tAll Loss: 4.1748\tTriple Loss(1): 0.7894\tClassification Loss: 2.5960\n",
      "Train Epoch: 1 [59520/110534 (54%)]\tAll Loss: 3.9409\tTriple Loss(1): 0.7467\tClassification Loss: 2.4474\n",
      "Train Epoch: 1 [59840/110534 (54%)]\tAll Loss: 4.1466\tTriple Loss(1): 0.7673\tClassification Loss: 2.6120\n",
      "Train Epoch: 1 [60160/110534 (54%)]\tAll Loss: 9.7092\tTriple Loss(0): 3.5342\tClassification Loss: 2.6408\n",
      "Train Epoch: 1 [60480/110534 (55%)]\tAll Loss: 4.5505\tTriple Loss(1): 0.9712\tClassification Loss: 2.6081\n",
      "\n",
      "Test set: Average loss: 2.7275, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [60800/110534 (55%)]\tAll Loss: 4.0273\tTriple Loss(1): 0.6688\tClassification Loss: 2.6897\n",
      "Train Epoch: 1 [61120/110534 (55%)]\tAll Loss: 2.5612\tTriple Loss(0): 0.0000\tClassification Loss: 2.5612\n",
      "Train Epoch: 1 [61440/110534 (56%)]\tAll Loss: 6.3996\tTriple Loss(0): 1.9380\tClassification Loss: 2.5237\n",
      "Train Epoch: 1 [61760/110534 (56%)]\tAll Loss: 3.9192\tTriple Loss(1): 0.5812\tClassification Loss: 2.7568\n",
      "Train Epoch: 1 [62080/110534 (56%)]\tAll Loss: 4.1631\tTriple Loss(1): 0.8311\tClassification Loss: 2.5008\n",
      "Train Epoch: 1 [62400/110534 (56%)]\tAll Loss: 3.9093\tTriple Loss(1): 0.6345\tClassification Loss: 2.6403\n",
      "Train Epoch: 1 [62720/110534 (57%)]\tAll Loss: 3.7834\tTriple Loss(1): 0.6801\tClassification Loss: 2.4232\n",
      "Train Epoch: 1 [63040/110534 (57%)]\tAll Loss: 7.7268\tTriple Loss(0): 2.5676\tClassification Loss: 2.5916\n",
      "Train Epoch: 1 [63360/110534 (57%)]\tAll Loss: 3.9846\tTriple Loss(1): 0.7991\tClassification Loss: 2.3863\n",
      "Train Epoch: 1 [63680/110534 (58%)]\tAll Loss: 6.2936\tTriple Loss(0): 2.0286\tClassification Loss: 2.2364\n",
      "\n",
      "Test set: Average loss: 2.6635, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [64000/110534 (58%)]\tAll Loss: 3.9434\tTriple Loss(1): 0.7060\tClassification Loss: 2.5315\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_2000.pth.tar\n",
      "Train Epoch: 1 [64320/110534 (58%)]\tAll Loss: 4.6048\tTriple Loss(0): 1.0081\tClassification Loss: 2.5886\n",
      "Train Epoch: 1 [64640/110534 (58%)]\tAll Loss: 3.8410\tTriple Loss(1): 0.7692\tClassification Loss: 2.3027\n",
      "Train Epoch: 1 [64960/110534 (59%)]\tAll Loss: 4.0947\tTriple Loss(1): 0.7699\tClassification Loss: 2.5548\n",
      "Train Epoch: 1 [65280/110534 (59%)]\tAll Loss: 3.8123\tTriple Loss(1): 0.6383\tClassification Loss: 2.5357\n",
      "Train Epoch: 1 [65600/110534 (59%)]\tAll Loss: 6.1475\tTriple Loss(0): 1.8844\tClassification Loss: 2.3786\n",
      "Train Epoch: 1 [65920/110534 (60%)]\tAll Loss: 4.0878\tTriple Loss(1): 0.8280\tClassification Loss: 2.4319\n",
      "Train Epoch: 1 [66240/110534 (60%)]\tAll Loss: 3.9971\tTriple Loss(1): 0.8480\tClassification Loss: 2.3010\n",
      "Train Epoch: 1 [66560/110534 (60%)]\tAll Loss: 4.1392\tTriple Loss(1): 0.9196\tClassification Loss: 2.3000\n",
      "Train Epoch: 1 [66880/110534 (60%)]\tAll Loss: 3.9952\tTriple Loss(1): 0.6688\tClassification Loss: 2.6576\n",
      "\n",
      "Test set: Average loss: 2.7002, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [67200/110534 (61%)]\tAll Loss: 4.0636\tTriple Loss(1): 0.8800\tClassification Loss: 2.3036\n",
      "Train Epoch: 1 [67520/110534 (61%)]\tAll Loss: 4.3451\tTriple Loss(1): 0.8504\tClassification Loss: 2.6442\n",
      "Train Epoch: 1 [67840/110534 (61%)]\tAll Loss: 3.9375\tTriple Loss(1): 0.6755\tClassification Loss: 2.5865\n",
      "Train Epoch: 1 [68160/110534 (62%)]\tAll Loss: 4.3661\tTriple Loss(1): 0.8514\tClassification Loss: 2.6634\n",
      "Train Epoch: 1 [68480/110534 (62%)]\tAll Loss: 4.2320\tTriple Loss(1): 0.8666\tClassification Loss: 2.4987\n",
      "Train Epoch: 1 [68800/110534 (62%)]\tAll Loss: 3.7889\tTriple Loss(1): 0.7018\tClassification Loss: 2.3853\n",
      "Train Epoch: 1 [69120/110534 (63%)]\tAll Loss: 4.2493\tTriple Loss(1): 0.8332\tClassification Loss: 2.5828\n",
      "Train Epoch: 1 [69440/110534 (63%)]\tAll Loss: 4.3882\tTriple Loss(1): 0.9122\tClassification Loss: 2.5638\n",
      "Train Epoch: 1 [69760/110534 (63%)]\tAll Loss: 4.1909\tTriple Loss(1): 0.7531\tClassification Loss: 2.6846\n",
      "Train Epoch: 1 [70080/110534 (63%)]\tAll Loss: 3.6834\tTriple Loss(1): 0.7582\tClassification Loss: 2.1669\n",
      "\n",
      "Test set: Average loss: 2.6748, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [70400/110534 (64%)]\tAll Loss: 3.7322\tTriple Loss(1): 0.8063\tClassification Loss: 2.1195\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEDtAX9gj2Tq",
    "colab_type": "text"
   },
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VQMr5jgwNBsT",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "! python train.py"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c4w2MEm5U8R3",
    "colab_type": "code",
    "outputId": "d781e6f7-ce04-4faf-eabe-11dfc63f1f84",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1586704220059,
     "user_tz": -300,
     "elapsed": 726830,
     "user": {
      "displayName": "Muhammad Ali",
      "photoUrl": "",
      "userId": "15673831022739340207"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "from config import *\n",
    "from plotcm import plot_confusion_matrix\n",
    "from train import get_conf_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names = ['Anorak', 'Blazer', 'Bomber', 'Button-Down', 'Cardigan', \n",
    "              'Flannel', 'Henley', 'Hoodie', 'Jacket', 'Jersey', 'Parka', \n",
    "              'Peacoat', 'Sweater', 'Tank', 'Tee', 'Top', 'Turtleneck', \n",
    "              'Chinos','Jeans', 'Joggers', 'Shorts', 'Sweatpants', \n",
    "              'Sweatshorts', 'Trunks', 'Coat', 'Robe']\n",
    "\n",
    "cm = get_conf_matrix()\n",
    "print(cm.shape)\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plot_confusion_matrix(cm, names)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:220: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:220: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:704: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  \"please use transforms.RandomResizedCrop instead.\")\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Loading model model_5_1500.pth.tar\n",
      "dataset: <data.Fashion_attr_prediction object at 0x7fcee6ff0f28>\n",
      "dataset len: 42305\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "batch_idx: 0\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Deep Fashion Retrieval/deep-fashion-retrieval/train.py:171: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "batch_idx: 5\n",
      "batch_idx: 10\n",
      "batch_idx: 15\n",
      "batch_idx: 20\n",
      "batch_idx: 25\n",
      "batch_idx: 30\n",
      "batch_idx: 35\n",
      "batch_idx: 40\n",
      "batch_idx: 45\n",
      "batch_idx: 50\n",
      "batch_idx: 55\n",
      "batch_idx: 60\n",
      "batch_idx: 65\n",
      "batch_idx: 70\n",
      "batch_idx: 75\n",
      "batch_idx: 80\n",
      "batch_idx: 85\n",
      "batch_idx: 90\n",
      "batch_idx: 95\n",
      "batch_idx: 100\n",
      "batch_idx: 105\n",
      "batch_idx: 110\n",
      "batch_idx: 115\n",
      "batch_idx: 120\n",
      "batch_idx: 125\n",
      "batch_idx: 130\n",
      "batch_idx: 135\n",
      "batch_idx: 140\n",
      "batch_idx: 145\n",
      "batch_idx: 150\n",
      "batch_idx: 155\n",
      "batch_idx: 160\n",
      "batch_idx: 165\n",
      "batch_idx: 170\n",
      "batch_idx: 175\n",
      "batch_idx: 180\n",
      "batch_idx: 185\n",
      "batch_idx: 190\n",
      "batch_idx: 195\n",
      "batch_idx: 200\n",
      "batch_idx: 205\n",
      "batch_idx: 210\n",
      "batch_idx: 215\n",
      "batch_idx: 220\n",
      "batch_idx: 225\n",
      "batch_idx: 230\n",
      "batch_idx: 235\n",
      "batch_idx: 240\n",
      "batch_idx: 245\n",
      "batch_idx: 250\n",
      "batch_idx: 255\n",
      "batch_idx: 260\n",
      "batch_idx: 265\n",
      "batch_idx: 270\n",
      "batch_idx: 275\n",
      "batch_idx: 280\n",
      "batch_idx: 285\n",
      "batch_idx: 290\n",
      "batch_idx: 295\n",
      "batch_idx: 300\n",
      "batch_idx: 305\n",
      "batch_idx: 310\n",
      "batch_idx: 315\n",
      "batch_idx: 320\n",
      "batch_idx: 325\n",
      "batch_idx: 330\n",
      "batch_idx: 335\n",
      "batch_idx: 340\n",
      "batch_idx: 345\n",
      "batch_idx: 350\n",
      "batch_idx: 355\n",
      "batch_idx: 360\n",
      "batch_idx: 365\n",
      "batch_idx: 370\n",
      "batch_idx: 375\n",
      "batch_idx: 380\n",
      "batch_idx: 385\n",
      "batch_idx: 390\n",
      "batch_idx: 395\n",
      "batch_idx: 400\n",
      "batch_idx: 405\n",
      "batch_idx: 410\n",
      "batch_idx: 415\n",
      "batch_idx: 420\n",
      "batch_idx: 425\n",
      "batch_idx: 430\n",
      "batch_idx: 435\n",
      "batch_idx: 440\n",
      "batch_idx: 445\n",
      "batch_idx: 450\n",
      "batch_idx: 455\n",
      "batch_idx: 460\n",
      "batch_idx: 465\n",
      "batch_idx: 470\n",
      "batch_idx: 475\n",
      "batch_idx: 480\n",
      "batch_idx: 485\n",
      "batch_idx: 490\n",
      "batch_idx: 495\n",
      "batch_idx: 500\n",
      "batch_idx: 505\n",
      "batch_idx: 510\n",
      "batch_idx: 515\n",
      "batch_idx: 520\n",
      "batch_idx: 525\n",
      "batch_idx: 530\n",
      "batch_idx: 535\n",
      "batch_idx: 540\n",
      "batch_idx: 545\n",
      "batch_idx: 550\n",
      "batch_idx: 555\n",
      "batch_idx: 560\n",
      "batch_idx: 565\n",
      "batch_idx: 570\n",
      "batch_idx: 575\n",
      "batch_idx: 580\n",
      "batch_idx: 585\n",
      "batch_idx: 590\n",
      "batch_idx: 595\n",
      "batch_idx: 600\n",
      "batch_idx: 605\n",
      "batch_idx: 610\n",
      "batch_idx: 615\n",
      "batch_idx: 620\n",
      "batch_idx: 625\n",
      "batch_idx: 630\n",
      "batch_idx: 635\n",
      "batch_idx: 640\n",
      "batch_idx: 645\n",
      "batch_idx: 650\n",
      "batch_idx: 655\n",
      "batch_idx: 660\n",
      "batch_idx: 665\n",
      "batch_idx: 670\n",
      "batch_idx: 675\n",
      "batch_idx: 680\n",
      "batch_idx: 685\n",
      "batch_idx: 690\n",
      "batch_idx: 695\n",
      "batch_idx: 700\n",
      "batch_idx: 705\n",
      "batch_idx: 710\n",
      "batch_idx: 715\n",
      "batch_idx: 720\n",
      "batch_idx: 725\n",
      "batch_idx: 730\n",
      "batch_idx: 735\n",
      "batch_idx: 740\n",
      "batch_idx: 745\n",
      "batch_idx: 750\n",
      "batch_idx: 755\n",
      "batch_idx: 760\n",
      "batch_idx: 765\n",
      "batch_idx: 770\n",
      "batch_idx: 775\n",
      "batch_idx: 780\n",
      "batch_idx: 785\n",
      "batch_idx: 790\n",
      "batch_idx: 795\n",
      "batch_idx: 800\n",
      "batch_idx: 805\n",
      "batch_idx: 810\n",
      "batch_idx: 815\n",
      "batch_idx: 820\n",
      "batch_idx: 825\n",
      "batch_idx: 830\n",
      "batch_idx: 835\n",
      "batch_idx: 840\n",
      "batch_idx: 845\n",
      "batch_idx: 850\n",
      "batch_idx: 855\n",
      "batch_idx: 860\n",
      "batch_idx: 865\n",
      "batch_idx: 870\n",
      "batch_idx: 875\n",
      "batch_idx: 880\n",
      "batch_idx: 885\n",
      "batch_idx: 890\n",
      "batch_idx: 895\n",
      "batch_idx: 900\n",
      "batch_idx: 905\n",
      "batch_idx: 910\n",
      "batch_idx: 915\n",
      "batch_idx: 920\n",
      "batch_idx: 925\n",
      "batch_idx: 930\n",
      "batch_idx: 935\n",
      "batch_idx: 940\n",
      "batch_idx: 945\n",
      "batch_idx: 950\n",
      "batch_idx: 955\n",
      "batch_idx: 960\n",
      "batch_idx: 965\n",
      "batch_idx: 970\n",
      "batch_idx: 975\n",
      "batch_idx: 980\n",
      "batch_idx: 985\n",
      "batch_idx: 990\n",
      "batch_idx: 995\n",
      "batch_idx: 1000\n",
      "batch_idx: 1005\n",
      "batch_idx: 1010\n",
      "batch_idx: 1015\n",
      "batch_idx: 1020\n",
      "batch_idx: 1025\n",
      "batch_idx: 1030\n",
      "batch_idx: 1035\n",
      "batch_idx: 1040\n",
      "batch_idx: 1045\n",
      "batch_idx: 1050\n",
      "batch_idx: 1055\n",
      "batch_idx: 1060\n",
      "batch_idx: 1065\n",
      "batch_idx: 1070\n",
      "batch_idx: 1075\n",
      "batch_idx: 1080\n",
      "batch_idx: 1085\n",
      "batch_idx: 1090\n",
      "batch_idx: 1095\n",
      "batch_idx: 1100\n",
      "batch_idx: 1105\n",
      "batch_idx: 1110\n",
      "batch_idx: 1115\n",
      "batch_idx: 1120\n",
      "batch_idx: 1125\n",
      "batch_idx: 1130\n",
      "batch_idx: 1135\n",
      "batch_idx: 1140\n",
      "batch_idx: 1145\n",
      "batch_idx: 1150\n",
      "batch_idx: 1155\n",
      "batch_idx: 1160\n",
      "batch_idx: 1165\n",
      "batch_idx: 1170\n",
      "batch_idx: 1175\n",
      "batch_idx: 1180\n",
      "batch_idx: 1185\n",
      "batch_idx: 1190\n",
      "batch_idx: 1195\n",
      "batch_idx: 1200\n",
      "batch_idx: 1205\n",
      "batch_idx: 1210\n",
      "batch_idx: 1215\n",
      "batch_idx: 1220\n",
      "batch_idx: 1225\n",
      "batch_idx: 1230\n",
      "batch_idx: 1235\n",
      "batch_idx: 1240\n",
      "batch_idx: 1245\n",
      "batch_idx: 1250\n",
      "batch_idx: 1255\n",
      "batch_idx: 1260\n",
      "batch_idx: 1265\n",
      "batch_idx: 1270\n",
      "batch_idx: 1275\n",
      "batch_idx: 1280\n",
      "batch_idx: 1285\n",
      "batch_idx: 1290\n",
      "batch_idx: 1295\n",
      "batch_idx: 1300\n",
      "batch_idx: 1305\n",
      "batch_idx: 1310\n",
      "batch_idx: 1315\n",
      "batch_idx: 1320\n",
      "batch_idx: 1325\n",
      "batch_idx: 1330\n",
      "batch_idx: 1335\n",
      "batch_idx: 1340\n",
      "batch_idx: 1345\n",
      "batch_idx: 1350\n",
      "batch_idx: 1355\n",
      "batch_idx: 1360\n",
      "batch_idx: 1365\n",
      "batch_idx: 1370\n",
      "batch_idx: 1375\n",
      "batch_idx: 1380\n",
      "batch_idx: 1385\n",
      "batch_idx: 1390\n",
      "batch_idx: 1395\n",
      "batch_idx: 1400\n",
      "batch_idx: 1405\n",
      "batch_idx: 1410\n",
      "batch_idx: 1415\n",
      "batch_idx: 1420\n",
      "batch_idx: 1425\n",
      "batch_idx: 1430\n",
      "batch_idx: 1435\n",
      "batch_idx: 1440\n",
      "batch_idx: 1445\n",
      "batch_idx: 1450\n",
      "batch_idx: 1455\n",
      "batch_idx: 1460\n",
      "batch_idx: 1465\n",
      "batch_idx: 1470\n",
      "batch_idx: 1475\n",
      "batch_idx: 1480\n",
      "batch_idx: 1485\n",
      "batch_idx: 1490\n",
      "batch_idx: 1495\n",
      "batch_idx: 1500\n",
      "batch_idx: 1505\n",
      "batch_idx: 1510\n",
      "batch_idx: 1515\n",
      "batch_idx: 1520\n",
      "batch_idx: 1525\n",
      "batch_idx: 1530\n",
      "batch_idx: 1535\n",
      "batch_idx: 1540\n",
      "batch_idx: 1545\n",
      "batch_idx: 1550\n",
      "batch_idx: 1555\n",
      "batch_idx: 1560\n",
      "batch_idx: 1565\n",
      "batch_idx: 1570\n",
      "batch_idx: 1575\n",
      "batch_idx: 1580\n",
      "batch_idx: 1585\n",
      "batch_idx: 1590\n",
      "batch_idx: 1595\n",
      "batch_idx: 1600\n",
      "batch_idx: 1605\n",
      "batch_idx: 1610\n",
      "batch_idx: 1615\n",
      "batch_idx: 1620\n",
      "batch_idx: 1625\n",
      "batch_idx: 1630\n",
      "batch_idx: 1635\n",
      "batch_idx: 1640\n",
      "batch_idx: 1645\n",
      "batch_idx: 1650\n",
      "batch_idx: 1655\n",
      "batch_idx: 1660\n",
      "batch_idx: 1665\n",
      "batch_idx: 1670\n",
      "batch_idx: 1675\n",
      "batch_idx: 1680\n",
      "batch_idx: 1685\n",
      "batch_idx: 1690\n",
      "batch_idx: 1695\n",
      "batch_idx: 1700\n",
      "batch_idx: 1705\n",
      "batch_idx: 1710\n",
      "batch_idx: 1715\n",
      "batch_idx: 1720\n",
      "batch_idx: 1725\n",
      "batch_idx: 1730\n",
      "batch_idx: 1735\n",
      "batch_idx: 1740\n",
      "batch_idx: 1745\n",
      "batch_idx: 1750\n",
      "batch_idx: 1755\n",
      "batch_idx: 1760\n",
      "batch_idx: 1765\n",
      "batch_idx: 1770\n",
      "batch_idx: 1775\n",
      "batch_idx: 1780\n",
      "batch_idx: 1785\n",
      "batch_idx: 1790\n",
      "batch_idx: 1795\n",
      "batch_idx: 1800\n",
      "batch_idx: 1805\n",
      "batch_idx: 1810\n",
      "batch_idx: 1815\n",
      "batch_idx: 1820\n",
      "batch_idx: 1825\n",
      "batch_idx: 1830\n",
      "batch_idx: 1835\n",
      "batch_idx: 1840\n",
      "batch_idx: 1845\n",
      "batch_idx: 1850\n",
      "batch_idx: 1855\n",
      "batch_idx: 1860\n",
      "batch_idx: 1865\n",
      "batch_idx: 1870\n",
      "batch_idx: 1875\n",
      "batch_idx: 1880\n",
      "batch_idx: 1885\n",
      "batch_idx: 1890\n",
      "batch_idx: 1895\n",
      "batch_idx: 1900\n",
      "batch_idx: 1905\n",
      "batch_idx: 1910\n",
      "batch_idx: 1915\n",
      "batch_idx: 1920\n",
      "batch_idx: 1925\n",
      "batch_idx: 1930\n",
      "batch_idx: 1935\n",
      "batch_idx: 1940\n",
      "batch_idx: 1945\n",
      "batch_idx: 1950\n",
      "batch_idx: 1955\n",
      "batch_idx: 1960\n",
      "batch_idx: 1965\n",
      "batch_idx: 1970\n",
      "batch_idx: 1975\n",
      "batch_idx: 1980\n",
      "batch_idx: 1985\n",
      "batch_idx: 1990\n",
      "batch_idx: 1995\n",
      "batch_idx: 2000\n",
      "batch_idx: 2005\n",
      "batch_idx: 2010\n",
      "batch_idx: 2015\n",
      "batch_idx: 2020\n",
      "batch_idx: 2025\n",
      "batch_idx: 2030\n",
      "batch_idx: 2035\n",
      "batch_idx: 2040\n",
      "batch_idx: 2045\n",
      "batch_idx: 2050\n",
      "batch_idx: 2055\n",
      "batch_idx: 2060\n",
      "batch_idx: 2065\n",
      "batch_idx: 2070\n",
      "batch_idx: 2075\n",
      "batch_idx: 2080\n",
      "batch_idx: 2085\n",
      "batch_idx: 2090\n",
      "batch_idx: 2095\n",
      "batch_idx: 2100\n",
      "batch_idx: 2105\n",
      "batch_idx: 2110\n",
      "batch_idx: 2115\n",
      "batch_idx: 2120\n",
      "batch_idx: 2125\n",
      "batch_idx: 2130\n",
      "batch_idx: 2135\n",
      "batch_idx: 2140\n",
      "batch_idx: 2145\n",
      "batch_idx: 2150\n",
      "batch_idx: 2155\n",
      "batch_idx: 2160\n",
      "batch_idx: 2165\n",
      "batch_idx: 2170\n",
      "batch_idx: 2175\n",
      "batch_idx: 2180\n",
      "batch_idx: 2185\n",
      "batch_idx: 2190\n",
      "batch_idx: 2195\n",
      "batch_idx: 2200\n",
      "batch_idx: 2205\n",
      "batch_idx: 2210\n",
      "batch_idx: 2215\n",
      "batch_idx: 2220\n",
      "batch_idx: 2225\n",
      "batch_idx: 2230\n",
      "batch_idx: 2235\n",
      "batch_idx: 2240\n",
      "batch_idx: 2245\n",
      "batch_idx: 2250\n",
      "batch_idx: 2255\n",
      "batch_idx: 2260\n",
      "batch_idx: 2265\n",
      "batch_idx: 2270\n",
      "batch_idx: 2275\n",
      "batch_idx: 2280\n",
      "batch_idx: 2285\n",
      "batch_idx: 2290\n",
      "batch_idx: 2295\n",
      "batch_idx: 2300\n",
      "batch_idx: 2305\n",
      "batch_idx: 2310\n",
      "batch_idx: 2315\n",
      "batch_idx: 2320\n",
      "batch_idx: 2325\n",
      "batch_idx: 2330\n",
      "batch_idx: 2335\n",
      "batch_idx: 2340\n",
      "batch_idx: 2345\n",
      "batch_idx: 2350\n",
      "batch_idx: 2355\n",
      "batch_idx: 2360\n",
      "batch_idx: 2365\n",
      "batch_idx: 2370\n",
      "batch_idx: 2375\n",
      "batch_idx: 2380\n",
      "batch_idx: 2385\n",
      "batch_idx: 2390\n",
      "batch_idx: 2395\n",
      "batch_idx: 2400\n",
      "batch_idx: 2405\n",
      "batch_idx: 2410\n",
      "batch_idx: 2415\n",
      "batch_idx: 2420\n",
      "batch_idx: 2425\n",
      "batch_idx: 2430\n",
      "batch_idx: 2435\n",
      "batch_idx: 2440\n",
      "batch_idx: 2445\n",
      "batch_idx: 2450\n",
      "batch_idx: 2455\n",
      "batch_idx: 2460\n",
      "batch_idx: 2465\n",
      "batch_idx: 2470\n",
      "batch_idx: 2475\n",
      "batch_idx: 2480\n",
      "batch_idx: 2485\n",
      "batch_idx: 2490\n",
      "batch_idx: 2495\n",
      "batch_idx: 2500\n",
      "batch_idx: 2505\n",
      "batch_idx: 2510\n",
      "batch_idx: 2515\n",
      "batch_idx: 2520\n",
      "batch_idx: 2525\n",
      "batch_idx: 2530\n",
      "batch_idx: 2535\n",
      "batch_idx: 2540\n",
      "batch_idx: 2545\n",
      "batch_idx: 2550\n",
      "batch_idx: 2555\n",
      "batch_idx: 2560\n",
      "batch_idx: 2565\n",
      "batch_idx: 2570\n",
      "batch_idx: 2575\n",
      "batch_idx: 2580\n",
      "batch_idx: 2585\n",
      "batch_idx: 2590\n",
      "batch_idx: 2595\n",
      "batch_idx: 2600\n",
      "batch_idx: 2605\n",
      "batch_idx: 2610\n",
      "batch_idx: 2615\n",
      "batch_idx: 2620\n",
      "batch_idx: 2625\n",
      "batch_idx: 2630\n",
      "batch_idx: 2635\n",
      "batch_idx: 2640\n",
      "\n",
      "Test set: Average loss: 1.4276, Accuracy: 22872/42320 (54%)\n",
      "\n",
      "(26, 26)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HLtMI6lYCGip",
    "colab_type": "code",
    "outputId": "4a176329-4b70-43c8-d737-a215fc2d3bbb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1586706743938,
     "user_tz": -300,
     "elapsed": 4738,
     "user": {
      "displayName": "Muhammad Ali",
      "photoUrl": "",
      "userId": "15673831022739340207"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cm, names)\n",
    "plt.savefig('conf_matrix.png')"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[   0    0    0    0    1    0    0    1   35    0    0    0    0    0\n",
      "     1    0    0    0    0    0    0    0    0    0    1    0]\n",
      " [   0  590    0    0  294    1    0    0  691    0    0    0   19   37\n",
      "   317   15    0    0   26    6   79    0    0    0   12    0]\n",
      " [   0    1    0    0    3    0    0    0   64    0    0    0    0    0\n",
      "     8    0    0    0    1    0    2    0    0    0    1    0]\n",
      " [   0    0    0    3    5    2    0    0   21    0    0    0    2    4\n",
      "    39    1    0    0    2    0    6    0    0    0    2    0]\n",
      " [   0   73    0    0 1756    0    0    5  521    0    0    0  261   76\n",
      "   772   50    0    0   31   18  128    1    0    0   13    0]\n",
      " [   0    0    0    2    8    5    0    1   10    0    0    0    3    1\n",
      "    58    3    0    0    0    2    7    0    0    0    0    0]\n",
      " [   0    5    0    0    9    0    0    8   15    0    0    0    9    1\n",
      "   138    1    0    0    2    4    3    0    0    0    0    0]\n",
      " [   0    2    0    0   89    0    0  188  211    0    0    0   72   24\n",
      "   506    6    0    0    6    9   25    0    0    0    0    0]\n",
      " [   0  147    0    0  322    0    0   19 1792    0    3    0   21   35\n",
      "   391   29    0    0   37   16   73    0    0    0   34    0]\n",
      " [   0    1    0    0    2    0    0    1   14    0    0    0    0   20\n",
      "   174    0    0    0    0    2    0    0    0    0    0    0]\n",
      " [   0    2    0    0   11    0    0    0  136    0    6    0    2    0\n",
      "     5    0    0    0    1    0    3    0    0    0   19    0]\n",
      " [   0    4    0    0    3    0    0    0   19    0    0    0    0    0\n",
      "     2    0    0    0    0    0    1    0    0    0    5    0]\n",
      " [   0   19    0    0  671    0    0   15  196    0    0    0 1140   81\n",
      "  1308   42    0    0   33    9   89    0    0    0    3    0]\n",
      " [   0    8    0    0   46    0    0    1   36    0    0    0   18 2499\n",
      "  1295   40    0    0   20   14  246    0    0    0    2    0]\n",
      " [   0   22    0    3  160    0    0   17  222    0    0    0  111  665\n",
      "  8501   64    0    0   75   37  353    0    0    0    4    0]\n",
      " [   0   11    0    0  144    0    0    1  102    1    0    0   73  553\n",
      "  1492  124    0    0   21   37  246    1    0    0    2    0]\n",
      " [   0    0    0    0    7    0    0    1    1    0    0    0   14    1\n",
      "    17    2    0    0    0    0    4    0    0    0    0    0]\n",
      " [   0    0    0    0    1    0    0    0    2    0    0    0    0    1\n",
      "    11    0    0   19   29   65   24    0    0    0    1    0]\n",
      " [   0    1    0    0   22    0    0    0   61    0    0    0   10   13\n",
      "   208    2    0    2 1368  204   54    5    0    0    0    0]\n",
      " [   0    5    0    0   23    0    0    0   40    0    0    0    4   14\n",
      "   170    6    0    5  184  617   79    9    0    0    0    0]\n",
      " [   0    9    0    0   49    0    0    0   94    0    0    0   22  295\n",
      "   772   21    0    1   77   86 4037    4    0    2    2    0]\n",
      " [   0    3    0    0   13    0    0    1   19    0    0    0    2    6\n",
      "   130    0    0    8  106  419   62   55    0    0    0    0]\n",
      " [   0    0    0    0    8    0    0    0    4    0    0    0    4    2\n",
      "    61    0    0    0    6   69  163    6    2    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
      "     5    0    0    0    0    0   87    0    0    6    0    0]\n",
      " [   0   28    0    0   90    0    0    0  251    0    1    0    2    2\n",
      "    30    2    0    0    2    1    8    0    0    0  164    0]\n",
      " [   0    1    0    1   10    0    0    0    5    0    0    0    0    5\n",
      "    12    5    0    0    0    0    3    0    0    0    1    0]]\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "16Q2YK_uS-jI",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# os.path.exists('//content/drive/My Drive/Deep Fashion Retrieval/base/img/Leaf_Print-Sleeve_Tee/img_00000031.jpg')\n"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'May30_00-44-53'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  }
 ]
}