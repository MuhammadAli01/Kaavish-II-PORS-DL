{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "train",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZhSsDYSf2L20",
    "colab_type": "code",
    "outputId": "25c0f9ec-d660-4c9f-ada3-5d5b23b82e82",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1589192274956,
     "user_tz": -300,
     "elapsed": 1110,
     "user": {
      "displayName": "Muhammad Ali",
      "photoUrl": "",
      "userId": "15673831022739340207"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import os\n",
    "# os.chdir('/content/drive/My Drive/Deep Fashion Retrieval/deep-fashion-retrieval')\n",
    "# os.chdir(\"/home/ma02526/ResNet/deep-fashion-retrieval\")"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-JtZQgArAF9",
    "colab_type": "text"
   },
   "source": [
    "# Training with 26 most relevant categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Train Epoch: 1 [0/209222 (0%)]\tClassification Loss: 3.9848\r\n",
      "train.py:178: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 3.9490\r\n",
      "Top 1 Accuracy: 1108/80000 (1%)\r\n",
      "Top 3 Accuracy: 3293/80000 (4%)\r\n",
      "Top 5 Accuracy: 6107/80000 (8%)\r\n",
      " \r\n",
      "Train Epoch: 1 [6400/209222 (3%)]\tClassification Loss: 2.2343\r\n",
      "Train Epoch: 1 [12800/209222 (6%)]\tClassification Loss: 1.5551\r\n",
      "Train Epoch: 1 [19200/209222 (9%)]\tClassification Loss: 1.9574\r\n",
      "Train Epoch: 1 [25600/209222 (12%)]\tClassification Loss: 1.7489\r\n",
      "Train Epoch: 1 [32000/209222 (15%)]\tClassification Loss: 1.8780\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_500.pth.tar\r\n",
      "Train Epoch: 1 [38400/209222 (18%)]\tClassification Loss: 2.0246\r\n",
      "Train Epoch: 1 [44800/209222 (21%)]\tClassification Loss: 1.5618\r\n",
      "Train Epoch: 1 [51200/209222 (24%)]\tClassification Loss: 1.6724\r\n",
      "Train Epoch: 1 [57600/209222 (28%)]\tClassification Loss: 1.6888\r\n",
      "Train Epoch: 1 [64000/209222 (31%)]\tClassification Loss: 1.5357\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1000.pth.tar\r\n",
      "Train Epoch: 1 [70400/209222 (34%)]\tClassification Loss: 1.3968\r\n",
      "Train Epoch: 1 [76800/209222 (37%)]\tClassification Loss: 1.6153\r\n",
      "Train Epoch: 1 [83200/209222 (40%)]\tClassification Loss: 1.7009\r\n",
      "Train Epoch: 1 [89600/209222 (43%)]\tClassification Loss: 1.6309\r\n",
      "Train Epoch: 1 [96000/209222 (46%)]\tClassification Loss: 1.5827\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1500.pth.tar\r\n",
      "Train Epoch: 1 [102400/209222 (49%)]\tClassification Loss: 1.6751\r\n",
      "Train Epoch: 1 [108800/209222 (52%)]\tClassification Loss: 1.4357\r\n",
      "\r\n",
      "Test set: Average loss: 1.3943\r\n",
      "Top 1 Accuracy: 47677/80000 (60%)\r\n",
      "Top 3 Accuracy: 65045/80000 (81%)\r\n",
      "Top 5 Accuracy: 71398/80000 (89%)\r\n",
      " \r\n",
      "Train Epoch: 1 [115200/209222 (55%)]\tClassification Loss: 1.7770\r\n",
      "Train Epoch: 1 [121600/209222 (58%)]\tClassification Loss: 1.5367\r\n",
      "Train Epoch: 1 [128000/209222 (61%)]\tClassification Loss: 1.5969\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_2000.pth.tar\r\n",
      "Train Epoch: 1 [134400/209222 (64%)]\tClassification Loss: 1.4417\r\n",
      "Train Epoch: 1 [140800/209222 (67%)]\tClassification Loss: 1.3437\r\n",
      "Train Epoch: 1 [147200/209222 (70%)]\tClassification Loss: 1.5423\r\n",
      "Train Epoch: 1 [153600/209222 (73%)]\tClassification Loss: 1.6283\r\n",
      "Train Epoch: 1 [160000/209222 (76%)]\tClassification Loss: 1.7851\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_2500.pth.tar\r\n",
      "Train Epoch: 1 [166400/209222 (80%)]\tClassification Loss: 1.5461\r\n",
      "Train Epoch: 1 [172800/209222 (83%)]\tClassification Loss: 1.3214\r\n",
      "Train Epoch: 1 [179200/209222 (86%)]\tClassification Loss: 1.4210\r\n",
      "Train Epoch: 1 [185600/209222 (89%)]\tClassification Loss: 1.3464\r\n",
      "Train Epoch: 1 [192000/209222 (92%)]\tClassification Loss: 1.4946\r\n"
     ]
    }
   ],
   "source": [
    "! python train.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uoTUVg6grWZ0",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "outputId": "e68b2245-67c8-4f72-d1e2-4e9b1aa60bf4"
   },
   "source": [
    "# Freeze=True. LR=0.01. In-shop=False\n",
    "! python train.py"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Train Epoch: 1 [0/110534 (0%)]\tClassification Loss: 3.2551\r\n",
      "Test() called at step_no: 0\r\n",
      "train.py:163: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 3.4344, Accuracy: 20/1920 (1%)\r\n",
      "\r\n",
      "Train Epoch: 1 [640/110534 (1%)]\tClassification Loss: 2.9939\r\n",
      "Train Epoch: 1 [1280/110534 (1%)]\tClassification Loss: 2.8167\r\n",
      "Train Epoch: 1 [1920/110534 (2%)]\tClassification Loss: 2.7070\r\n",
      "Train Epoch: 1 [2560/110534 (2%)]\tClassification Loss: 2.6303\r\n",
      "Train Epoch: 1 [3200/110534 (3%)]\tClassification Loss: 2.5271\r\n",
      "Train Epoch: 1 [3840/110534 (3%)]\tClassification Loss: 2.5832\r\n",
      "Train Epoch: 1 [4480/110534 (4%)]\tClassification Loss: 2.6724\r\n",
      "Train Epoch: 1 [5120/110534 (5%)]\tClassification Loss: 2.6078\r\n",
      "Train Epoch: 1 [5760/110534 (5%)]\tClassification Loss: 2.5708\r\n",
      "Train Epoch: 1 [6400/110534 (6%)]\tClassification Loss: 2.3925\r\n",
      "Test() called at step_no: 100\r\n",
      "\r\n",
      "Test set: Average loss: 2.5902, Accuracy: 511/1920 (27%)\r\n",
      "\r\n",
      "Train Epoch: 1 [7040/110534 (6%)]\tClassification Loss: 2.5046\r\n",
      "Train Epoch: 1 [7680/110534 (7%)]\tClassification Loss: 2.5380\r\n",
      "Train Epoch: 1 [8320/110534 (8%)]\tClassification Loss: 2.3953\r\n",
      "Train Epoch: 1 [8960/110534 (8%)]\tClassification Loss: 2.4406\r\n",
      "Train Epoch: 1 [9600/110534 (9%)]\tClassification Loss: 2.3945\r\n",
      "Train Epoch: 1 [10240/110534 (9%)]\tClassification Loss: 2.3660\r\n",
      "Train Epoch: 1 [10880/110534 (10%)]\tClassification Loss: 2.4298\r\n",
      "Train Epoch: 1 [11520/110534 (10%)]\tClassification Loss: 2.4177\r\n",
      "Train Epoch: 1 [12160/110534 (11%)]\tClassification Loss: 2.4805\r\n",
      "Train Epoch: 1 [12800/110534 (12%)]\tClassification Loss: 2.3700\r\n",
      "Test() called at step_no: 200\r\n",
      "\r\n",
      "Test set: Average loss: 2.4417, Accuracy: 547/1920 (28%)\r\n",
      "\r\n",
      "Train Epoch: 1 [13440/110534 (12%)]\tClassification Loss: 2.2498\r\n",
      "Train Epoch: 1 [14080/110534 (13%)]\tClassification Loss: 2.1636\r\n",
      "Train Epoch: 1 [14720/110534 (13%)]\tClassification Loss: 2.2703\r\n",
      "Train Epoch: 1 [15360/110534 (14%)]\tClassification Loss: 2.4436\r\n",
      "Train Epoch: 1 [16000/110534 (14%)]\tClassification Loss: 2.3448\r\n",
      "Train Epoch: 1 [16640/110534 (15%)]\tClassification Loss: 2.3144\r\n",
      "Train Epoch: 1 [17280/110534 (16%)]\tClassification Loss: 2.3612\r\n",
      "Train Epoch: 1 [17920/110534 (16%)]\tClassification Loss: 2.1631\r\n",
      "Train Epoch: 1 [18560/110534 (17%)]\tClassification Loss: 2.2082\r\n",
      "Train Epoch: 1 [19200/110534 (17%)]\tClassification Loss: 2.2089\r\n",
      "Test() called at step_no: 300\r\n",
      "\r\n",
      "Test set: Average loss: 2.3385, Accuracy: 601/1920 (31%)\r\n",
      "\r\n",
      "Train Epoch: 1 [19840/110534 (18%)]\tClassification Loss: 2.2307\r\n",
      "Train Epoch: 1 [20480/110534 (19%)]\tClassification Loss: 2.1508\r\n",
      "Train Epoch: 1 [21120/110534 (19%)]\tClassification Loss: 2.1002\r\n",
      "Train Epoch: 1 [21760/110534 (20%)]\tClassification Loss: 2.1807\r\n",
      "Train Epoch: 1 [22400/110534 (20%)]\tClassification Loss: 2.2636\r\n",
      "Train Epoch: 1 [23040/110534 (21%)]\tClassification Loss: 2.1108\r\n",
      "Train Epoch: 1 [23680/110534 (21%)]\tClassification Loss: 2.1969\r\n",
      "Train Epoch: 1 [24320/110534 (22%)]\tClassification Loss: 2.1099\r\n",
      "Train Epoch: 1 [24960/110534 (23%)]\tClassification Loss: 1.8936\r\n",
      "Train Epoch: 1 [25600/110534 (23%)]\tClassification Loss: 2.4549\r\n",
      "Test() called at step_no: 400\r\n",
      "\r\n",
      "Test set: Average loss: 2.2552, Accuracy: 733/1920 (38%)\r\n",
      "\r\n",
      "Train Epoch: 1 [26240/110534 (24%)]\tClassification Loss: 2.1399\r\n",
      "Train Epoch: 1 [26880/110534 (24%)]\tClassification Loss: 2.1464\r\n",
      "Train Epoch: 1 [27520/110534 (25%)]\tClassification Loss: 1.8899\r\n",
      "Train Epoch: 1 [28160/110534 (25%)]\tClassification Loss: 2.0277\r\n",
      "Train Epoch: 1 [28800/110534 (26%)]\tClassification Loss: 2.2300\r\n",
      "Train Epoch: 1 [29440/110534 (27%)]\tClassification Loss: 2.1036\r\n",
      "Train Epoch: 1 [30080/110534 (27%)]\tClassification Loss: 2.0996\r\n",
      "Train Epoch: 1 [30720/110534 (28%)]\tClassification Loss: 2.0948\r\n",
      "Train Epoch: 1 [31360/110534 (28%)]\tClassification Loss: 2.0692\r\n",
      "Train Epoch: 1 [32000/110534 (29%)]\tClassification Loss: 2.1721\r\n",
      "Test() called at step_no: 500\r\n",
      "\r\n",
      "Test set: Average loss: 2.1870, Accuracy: 828/1920 (43%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_500.pth.tar\r\n",
      "Train Epoch: 1 [32640/110534 (30%)]\tClassification Loss: 2.0384\r\n",
      "Train Epoch: 1 [33280/110534 (30%)]\tClassification Loss: 1.8231\r\n",
      "Train Epoch: 1 [33920/110534 (31%)]\tClassification Loss: 2.1738\r\n",
      "Train Epoch: 1 [34560/110534 (31%)]\tClassification Loss: 2.1805\r\n",
      "Train Epoch: 1 [35200/110534 (32%)]\tClassification Loss: 2.0349\r\n",
      "Train Epoch: 1 [35840/110534 (32%)]\tClassification Loss: 1.8516\r\n",
      "Train Epoch: 1 [36480/110534 (33%)]\tClassification Loss: 1.9630\r\n",
      "Train Epoch: 1 [37120/110534 (34%)]\tClassification Loss: 2.0086\r\n",
      "Train Epoch: 1 [37760/110534 (34%)]\tClassification Loss: 1.9877\r\n",
      "Train Epoch: 1 [38400/110534 (35%)]\tClassification Loss: 2.1610\r\n",
      "Test() called at step_no: 600\r\n",
      "\r\n",
      "Test set: Average loss: 2.1245, Accuracy: 855/1920 (45%)\r\n",
      "\r\n",
      "Train Epoch: 1 [39040/110534 (35%)]\tClassification Loss: 1.8356\r\n",
      "Train Epoch: 1 [39680/110534 (36%)]\tClassification Loss: 2.2976\r\n",
      "Train Epoch: 1 [40320/110534 (36%)]\tClassification Loss: 2.0719\r\n",
      "Train Epoch: 1 [40960/110534 (37%)]\tClassification Loss: 1.8911\r\n",
      "Train Epoch: 1 [41600/110534 (38%)]\tClassification Loss: 2.1227\r\n",
      "Train Epoch: 1 [42240/110534 (38%)]\tClassification Loss: 1.9395\r\n",
      "Train Epoch: 1 [42880/110534 (39%)]\tClassification Loss: 1.9431\r\n",
      "Train Epoch: 1 [43520/110534 (39%)]\tClassification Loss: 2.0866\r\n",
      "Train Epoch: 1 [44160/110534 (40%)]\tClassification Loss: 1.9226\r\n",
      "Train Epoch: 1 [44800/110534 (41%)]\tClassification Loss: 1.8732\r\n",
      "Test() called at step_no: 700\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "\r\n",
      "Test set: Average loss: 2.0742, Accuracy: 907/1920 (47%)\r\n",
      "\r\n",
      "Train Epoch: 1 [45440/110534 (41%)]\tClassification Loss: 2.1108\r\n",
      "Train Epoch: 1 [46080/110534 (42%)]\tClassification Loss: 1.8534\r\n",
      "Train Epoch: 1 [46720/110534 (42%)]\tClassification Loss: 2.1422\r\n",
      "Train Epoch: 1 [47360/110534 (43%)]\tClassification Loss: 2.1509\r\n",
      "Train Epoch: 1 [48000/110534 (43%)]\tClassification Loss: 1.9987\r\n",
      "Train Epoch: 1 [48640/110534 (44%)]\tClassification Loss: 1.9383\r\n",
      "Train Epoch: 1 [49280/110534 (45%)]\tClassification Loss: 1.6299\r\n",
      "Train Epoch: 1 [49920/110534 (45%)]\tClassification Loss: 1.8168\r\n",
      "Train Epoch: 1 [50560/110534 (46%)]\tClassification Loss: 2.0715\r\n",
      "Train Epoch: 1 [51200/110534 (46%)]\tClassification Loss: 1.9643\r\n",
      "Test() called at step_no: 800\r\n",
      "\r\n",
      "Test set: Average loss: 2.0302, Accuracy: 915/1920 (48%)\r\n",
      "\r\n",
      "Train Epoch: 1 [51840/110534 (47%)]\tClassification Loss: 1.6330\r\n",
      "Train Epoch: 1 [52480/110534 (47%)]\tClassification Loss: 1.9027\r\n",
      "Train Epoch: 1 [53120/110534 (48%)]\tClassification Loss: 2.0473\r\n",
      "Train Epoch: 1 [53760/110534 (49%)]\tClassification Loss: 1.7538\r\n",
      "Train Epoch: 1 [54400/110534 (49%)]\tClassification Loss: 2.1074\r\n",
      "Train Epoch: 1 [55040/110534 (50%)]\tClassification Loss: 1.7861\r\n",
      "Train Epoch: 1 [55680/110534 (50%)]\tClassification Loss: 2.1171\r\n",
      "Train Epoch: 1 [56320/110534 (51%)]\tClassification Loss: 1.7808\r\n",
      "Train Epoch: 1 [56960/110534 (52%)]\tClassification Loss: 1.8689\r\n",
      "Train Epoch: 1 [57600/110534 (52%)]\tClassification Loss: 1.9704\r\n",
      "Test() called at step_no: 900\r\n",
      "\r\n",
      "Test set: Average loss: 1.9941, Accuracy: 941/1920 (49%)\r\n",
      "\r\n",
      "Train Epoch: 1 [58240/110534 (53%)]\tClassification Loss: 1.7775\r\n",
      "Train Epoch: 1 [58880/110534 (53%)]\tClassification Loss: 2.0835\r\n",
      "Train Epoch: 1 [59520/110534 (54%)]\tClassification Loss: 1.9822\r\n",
      "Train Epoch: 1 [60160/110534 (54%)]\tClassification Loss: 1.9752\r\n",
      "Train Epoch: 1 [60800/110534 (55%)]\tClassification Loss: 2.3291\r\n",
      "Train Epoch: 1 [61440/110534 (56%)]\tClassification Loss: 1.8478\r\n",
      "Train Epoch: 1 [62080/110534 (56%)]\tClassification Loss: 2.2193\r\n",
      "Train Epoch: 1 [62720/110534 (57%)]\tClassification Loss: 1.9576\r\n",
      "Train Epoch: 1 [63360/110534 (57%)]\tClassification Loss: 2.0516\r\n",
      "Train Epoch: 1 [64000/110534 (58%)]\tClassification Loss: 1.9364\r\n",
      "Test() called at step_no: 1000\r\n",
      "\r\n",
      "Test set: Average loss: 1.9617, Accuracy: 975/1920 (51%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1000.pth.tar\r\n",
      "Train Epoch: 1 [64640/110534 (58%)]\tClassification Loss: 1.9434\r\n",
      "Train Epoch: 1 [65280/110534 (59%)]\tClassification Loss: 1.8668\r\n",
      "Train Epoch: 1 [65920/110534 (60%)]\tClassification Loss: 1.7191\r\n",
      "Train Epoch: 1 [66560/110534 (60%)]\tClassification Loss: 1.8294\r\n",
      "Train Epoch: 1 [67200/110534 (61%)]\tClassification Loss: 2.0352\r\n",
      "Train Epoch: 1 [67840/110534 (61%)]\tClassification Loss: 1.6578\r\n",
      "Train Epoch: 1 [68480/110534 (62%)]\tClassification Loss: 1.7404\r\n",
      "Train Epoch: 1 [69120/110534 (63%)]\tClassification Loss: 1.7488\r\n",
      "Train Epoch: 1 [69760/110534 (63%)]\tClassification Loss: 1.8071\r\n",
      "Train Epoch: 1 [70400/110534 (64%)]\tClassification Loss: 1.9007\r\n",
      "Test() called at step_no: 1100\r\n",
      "\r\n",
      "Test set: Average loss: 1.9393, Accuracy: 955/1920 (50%)\r\n",
      "\r\n",
      "Train Epoch: 1 [71040/110534 (64%)]\tClassification Loss: 1.8689\r\n",
      "Train Epoch: 1 [71680/110534 (65%)]\tClassification Loss: 1.6614\r\n",
      "Train Epoch: 1 [72320/110534 (65%)]\tClassification Loss: 1.7960\r\n",
      "Train Epoch: 1 [72960/110534 (66%)]\tClassification Loss: 1.7591\r\n",
      "Train Epoch: 1 [73600/110534 (67%)]\tClassification Loss: 1.8273\r\n",
      "Train Epoch: 1 [74240/110534 (67%)]\tClassification Loss: 1.9240\r\n",
      "Train Epoch: 1 [74880/110534 (68%)]\tClassification Loss: 1.7521\r\n",
      "Train Epoch: 1 [75520/110534 (68%)]\tClassification Loss: 1.9369\r\n",
      "Train Epoch: 1 [76160/110534 (69%)]\tClassification Loss: 1.8471\r\n",
      "Train Epoch: 1 [76800/110534 (69%)]\tClassification Loss: 1.7909\r\n",
      "Test() called at step_no: 1200\r\n",
      "\r\n",
      "Test set: Average loss: 1.9071, Accuracy: 971/1920 (51%)\r\n",
      "\r\n",
      "Train Epoch: 1 [77440/110534 (70%)]\tClassification Loss: 2.2319\r\n",
      "Train Epoch: 1 [78080/110534 (71%)]\tClassification Loss: 1.9769\r\n",
      "Train Epoch: 1 [78720/110534 (71%)]\tClassification Loss: 1.9073\r\n",
      "Train Epoch: 1 [79360/110534 (72%)]\tClassification Loss: 2.0520\r\n",
      "Train Epoch: 1 [80000/110534 (72%)]\tClassification Loss: 2.0125\r\n",
      "Train Epoch: 1 [80640/110534 (73%)]\tClassification Loss: 1.8970\r\n",
      "Train Epoch: 1 [81280/110534 (74%)]\tClassification Loss: 2.1608\r\n",
      "Train Epoch: 1 [81920/110534 (74%)]\tClassification Loss: 1.6204\r\n",
      "Train Epoch: 1 [82560/110534 (75%)]\tClassification Loss: 2.0641\r\n",
      "Train Epoch: 1 [83200/110534 (75%)]\tClassification Loss: 1.5953\r\n",
      "Test() called at step_no: 1300\r\n",
      "\r\n",
      "Test set: Average loss: 1.8877, Accuracy: 967/1920 (50%)\r\n",
      "\r\n",
      "Train Epoch: 1 [83840/110534 (76%)]\tClassification Loss: 2.0409\r\n",
      "Train Epoch: 1 [84480/110534 (76%)]\tClassification Loss: 1.8261\r\n",
      "Train Epoch: 1 [85120/110534 (77%)]\tClassification Loss: 1.8317\r\n",
      "Train Epoch: 1 [85760/110534 (78%)]\tClassification Loss: 2.0998\r\n",
      "Train Epoch: 1 [86400/110534 (78%)]\tClassification Loss: 1.9269\r\n",
      "Train Epoch: 1 [87040/110534 (79%)]\tClassification Loss: 1.5620\r\n",
      "Train Epoch: 1 [87680/110534 (79%)]\tClassification Loss: 1.5855\r\n",
      "Train Epoch: 1 [88320/110534 (80%)]\tClassification Loss: 1.8076\r\n",
      "Train Epoch: 1 [88960/110534 (80%)]\tClassification Loss: 1.5897\r\n",
      "Train Epoch: 1 [89600/110534 (81%)]\tClassification Loss: 1.7628\r\n",
      "Test() called at step_no: 1400\r\n",
      "\r\n",
      "Test set: Average loss: 1.8677, Accuracy: 977/1920 (51%)\r\n",
      "\r\n",
      "Train Epoch: 1 [90240/110534 (82%)]\tClassification Loss: 1.8988\r\n",
      "Train Epoch: 1 [90880/110534 (82%)]\tClassification Loss: 2.2512\r\n",
      "Train Epoch: 1 [91520/110534 (83%)]\tClassification Loss: 1.5833\r\n",
      "Train Epoch: 1 [92160/110534 (83%)]\tClassification Loss: 1.8878\r\n",
      "Train Epoch: 1 [92800/110534 (84%)]\tClassification Loss: 1.5036\r\n",
      "Train Epoch: 1 [93440/110534 (85%)]\tClassification Loss: 1.7095\r\n",
      "Train Epoch: 1 [94080/110534 (85%)]\tClassification Loss: 1.9480\r\n",
      "Train Epoch: 1 [94720/110534 (86%)]\tClassification Loss: 1.7390\r\n",
      "Train Epoch: 1 [95360/110534 (86%)]\tClassification Loss: 1.7180\r\n",
      "Train Epoch: 1 [96000/110534 (87%)]\tClassification Loss: 1.6105\r\n",
      "Test() called at step_no: 1500\r\n",
      "\r\n",
      "Test set: Average loss: 1.8500, Accuracy: 970/1920 (51%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1500.pth.tar\r\n",
      "Train Epoch: 1 [96640/110534 (87%)]\tClassification Loss: 1.9181\r\n",
      "Train Epoch: 1 [97280/110534 (88%)]\tClassification Loss: 1.6656\r\n",
      "Train Epoch: 1 [97920/110534 (89%)]\tClassification Loss: 1.8339\r\n",
      "Train Epoch: 1 [98560/110534 (89%)]\tClassification Loss: 1.8624\r\n",
      "Train Epoch: 1 [99200/110534 (90%)]\tClassification Loss: 1.8666\r\n",
      "Train Epoch: 1 [99840/110534 (90%)]\tClassification Loss: 1.8527\r\n",
      "Train Epoch: 1 [100480/110534 (91%)]\tClassification Loss: 1.7926\r\n",
      "Train Epoch: 1 [101120/110534 (91%)]\tClassification Loss: 1.8798\r\n",
      "Train Epoch: 1 [101760/110534 (92%)]\tClassification Loss: 1.6806\r\n",
      "Train Epoch: 1 [102400/110534 (93%)]\tClassification Loss: 1.7350\r\n",
      "Test() called at step_no: 1600\r\n",
      "\r\n",
      "Test set: Average loss: 1.8343, Accuracy: 995/1920 (52%)\r\n",
      "\r\n",
      "Train Epoch: 1 [103040/110534 (93%)]\tClassification Loss: 1.9959\r\n",
      "Train Epoch: 1 [103680/110534 (94%)]\tClassification Loss: 1.6528\r\n",
      "Train Epoch: 1 [104320/110534 (94%)]\tClassification Loss: 1.5352\r\n",
      "Train Epoch: 1 [104960/110534 (95%)]\tClassification Loss: 1.7784\r\n",
      "Train Epoch: 1 [105600/110534 (96%)]\tClassification Loss: 1.6264\r\n",
      "Train Epoch: 1 [106240/110534 (96%)]\tClassification Loss: 1.8381\r\n",
      "Train Epoch: 1 [106880/110534 (97%)]\tClassification Loss: 1.5564\r\n",
      "Train Epoch: 1 [107520/110534 (97%)]\tClassification Loss: 1.7385\r\n",
      "Train Epoch: 1 [108160/110534 (98%)]\tClassification Loss: 1.7784\r\n",
      "Train Epoch: 1 [108800/110534 (98%)]\tClassification Loss: 1.7989\r\n",
      "Test() called at step_no: 1700\r\n",
      "\r\n",
      "Test set: Average loss: 1.8208, Accuracy: 996/1920 (52%)\r\n",
      "\r\n",
      "Train Epoch: 1 [109440/110534 (99%)]\tClassification Loss: 1.9371\r\n",
      "Train Epoch: 1 [110080/110534 (100%)]\tClassification Loss: 1.7945\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_final.pth.tar\r\n",
      "Train Epoch: 2 [0/110534 (0%)]\tClassification Loss: 1.9682\r\n",
      "Test() called at step_no: 1727\r\n",
      "\r\n",
      "Test set: Average loss: 1.8192, Accuracy: 1002/1920 (52%)\r\n",
      "\r\n",
      "Train Epoch: 2 [640/110534 (1%)]\tClassification Loss: 1.7681\r\n",
      "Train Epoch: 2 [1280/110534 (1%)]\tClassification Loss: 1.7166\r\n",
      "Train Epoch: 2 [1920/110534 (2%)]\tClassification Loss: 1.6789\r\n",
      "Train Epoch: 2 [2560/110534 (2%)]\tClassification Loss: 1.7281\r\n",
      "Train Epoch: 2 [3200/110534 (3%)]\tClassification Loss: 1.7424\r\n",
      "Train Epoch: 2 [3840/110534 (3%)]\tClassification Loss: 1.7880\r\n",
      "Train Epoch: 2 [4480/110534 (4%)]\tClassification Loss: 2.0945\r\n",
      "Train Epoch: 2 [5120/110534 (5%)]\tClassification Loss: 1.8115\r\n",
      "Train Epoch: 2 [5760/110534 (5%)]\tClassification Loss: 1.8072\r\n",
      "Train Epoch: 2 [6400/110534 (6%)]\tClassification Loss: 1.7863\r\n",
      "Test() called at step_no: 1827\r\n",
      "\r\n",
      "Test set: Average loss: 1.7992, Accuracy: 992/1920 (52%)\r\n",
      "\r\n",
      "Train Epoch: 2 [7040/110534 (6%)]\tClassification Loss: 1.9719\r\n",
      "Train Epoch: 2 [7680/110534 (7%)]\tClassification Loss: 1.8087\r\n",
      "Train Epoch: 2 [8320/110534 (8%)]\tClassification Loss: 1.7765\r\n",
      "Train Epoch: 2 [8960/110534 (8%)]\tClassification Loss: 1.8655\r\n",
      "Train Epoch: 2 [9600/110534 (9%)]\tClassification Loss: 1.8182\r\n",
      "Train Epoch: 2 [10240/110534 (9%)]\tClassification Loss: 1.8352\r\n",
      "Train Epoch: 2 [10880/110534 (10%)]\tClassification Loss: 1.8640\r\n",
      "Train Epoch: 2 [11520/110534 (10%)]\tClassification Loss: 1.8821\r\n",
      "Train Epoch: 2 [12160/110534 (11%)]\tClassification Loss: 1.8865\r\n",
      "Train Epoch: 2 [12800/110534 (12%)]\tClassification Loss: 2.0242\r\n",
      "Test() called at step_no: 1927\r\n",
      "\r\n",
      "Test set: Average loss: 1.7912, Accuracy: 983/1920 (51%)\r\n",
      "\r\n",
      "Train Epoch: 2 [13440/110534 (12%)]\tClassification Loss: 1.9130\r\n",
      "Train Epoch: 2 [14080/110534 (13%)]\tClassification Loss: 1.5641\r\n",
      "Train Epoch: 2 [14720/110534 (13%)]\tClassification Loss: 1.7410\r\n",
      "Train Epoch: 2 [15360/110534 (14%)]\tClassification Loss: 1.8744\r\n",
      "Train Epoch: 2 [16000/110534 (14%)]\tClassification Loss: 2.1016\r\n",
      "Train Epoch: 2 [16640/110534 (15%)]\tClassification Loss: 1.8358\r\n",
      "Train Epoch: 2 [17280/110534 (16%)]\tClassification Loss: 1.9986\r\n",
      "Train Epoch: 2 [17920/110534 (16%)]\tClassification Loss: 1.6860\r\n",
      "Train Epoch: 2 [18560/110534 (17%)]\tClassification Loss: 1.9345\r\n",
      "Train Epoch: 2 [19200/110534 (17%)]\tClassification Loss: 1.8236\r\n",
      "Test() called at step_no: 2027\r\n",
      "\r\n",
      "Test set: Average loss: 1.7783, Accuracy: 1006/1920 (52%)\r\n",
      "\r\n",
      "Train Epoch: 2 [19840/110534 (18%)]\tClassification Loss: 1.8794\r\n",
      "Train Epoch: 2 [20480/110534 (19%)]\tClassification Loss: 1.7740\r\n",
      "Train Epoch: 2 [21120/110534 (19%)]\tClassification Loss: 1.7314\r\n",
      "Train Epoch: 2 [21760/110534 (20%)]\tClassification Loss: 1.7789\r\n",
      "Train Epoch: 2 [22400/110534 (20%)]\tClassification Loss: 2.0558\r\n",
      "Train Epoch: 2 [23040/110534 (21%)]\tClassification Loss: 1.8238\r\n",
      "Train Epoch: 2 [23680/110534 (21%)]\tClassification Loss: 1.7322\r\n",
      "Train Epoch: 2 [24320/110534 (22%)]\tClassification Loss: 1.5474\r\n",
      "Train Epoch: 2 [24960/110534 (23%)]\tClassification Loss: 1.4767\r\n",
      "Train Epoch: 2 [25600/110534 (23%)]\tClassification Loss: 2.2381\r\n",
      "Test() called at step_no: 2127\r\n",
      "\r\n",
      "Test set: Average loss: 1.7713, Accuracy: 1012/1920 (53%)\r\n",
      "\r\n",
      "Train Epoch: 2 [26240/110534 (24%)]\tClassification Loss: 1.7124\r\n",
      "Train Epoch: 2 [26880/110534 (24%)]\tClassification Loss: 1.8222\r\n",
      "Train Epoch: 2 [27520/110534 (25%)]\tClassification Loss: 1.5205\r\n",
      "Train Epoch: 2 [28160/110534 (25%)]\tClassification Loss: 1.7859\r\n",
      "Train Epoch: 2 [28800/110534 (26%)]\tClassification Loss: 2.0189\r\n",
      "Train Epoch: 2 [29440/110534 (27%)]\tClassification Loss: 1.6275\r\n",
      "Train Epoch: 2 [30080/110534 (27%)]\tClassification Loss: 1.9243\r\n",
      "Train Epoch: 2 [30720/110534 (28%)]\tClassification Loss: 1.6605\r\n",
      "Train Epoch: 2 [31360/110534 (28%)]\tClassification Loss: 1.9420\r\n",
      "Train Epoch: 2 [32000/110534 (29%)]\tClassification Loss: 1.7582\r\n",
      "Test() called at step_no: 2227\r\n",
      "\r\n",
      "Test set: Average loss: 1.7626, Accuracy: 1021/1920 (53%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_500.pth.tar\r\n",
      "Train Epoch: 2 [32640/110534 (30%)]\tClassification Loss: 1.7224\r\n",
      "Train Epoch: 2 [33280/110534 (30%)]\tClassification Loss: 1.5683\r\n",
      "Train Epoch: 2 [33920/110534 (31%)]\tClassification Loss: 1.8717\r\n",
      "Train Epoch: 2 [34560/110534 (31%)]\tClassification Loss: 1.8545\r\n",
      "Train Epoch: 2 [35200/110534 (32%)]\tClassification Loss: 1.8261\r\n",
      "Train Epoch: 2 [35840/110534 (32%)]\tClassification Loss: 1.4637\r\n",
      "Train Epoch: 2 [36480/110534 (33%)]\tClassification Loss: 1.6434\r\n",
      "Train Epoch: 2 [37120/110534 (34%)]\tClassification Loss: 1.8764\r\n",
      "Train Epoch: 2 [37760/110534 (34%)]\tClassification Loss: 1.6776\r\n",
      "Train Epoch: 2 [38400/110534 (35%)]\tClassification Loss: 1.8068\r\n",
      "Test() called at step_no: 2327\r\n",
      "\r\n",
      "Test set: Average loss: 1.7520, Accuracy: 1016/1920 (53%)\r\n",
      "\r\n",
      "Train Epoch: 2 [39040/110534 (35%)]\tClassification Loss: 1.4713\r\n",
      "Train Epoch: 2 [39680/110534 (36%)]\tClassification Loss: 1.9927\r\n",
      "Train Epoch: 2 [40320/110534 (36%)]\tClassification Loss: 1.8082\r\n",
      "Train Epoch: 2 [40960/110534 (37%)]\tClassification Loss: 1.5326\r\n",
      "Train Epoch: 2 [41600/110534 (38%)]\tClassification Loss: 1.8624\r\n",
      "Train Epoch: 2 [42240/110534 (38%)]\tClassification Loss: 1.5603\r\n",
      "Train Epoch: 2 [42880/110534 (39%)]\tClassification Loss: 1.6697\r\n",
      "Train Epoch: 2 [43520/110534 (39%)]\tClassification Loss: 1.9160\r\n",
      "Train Epoch: 2 [44160/110534 (40%)]\tClassification Loss: 1.6428\r\n",
      "Train Epoch: 2 [44800/110534 (41%)]\tClassification Loss: 1.5424\r\n",
      "Test() called at step_no: 2427\r\n",
      "\r\n",
      "Test set: Average loss: 1.7446, Accuracy: 1020/1920 (53%)\r\n",
      "\r\n",
      "Train Epoch: 2 [45440/110534 (41%)]\tClassification Loss: 2.0003\r\n",
      "Train Epoch: 2 [46080/110534 (42%)]\tClassification Loss: 1.7010\r\n",
      "Train Epoch: 2 [46720/110534 (42%)]\tClassification Loss: 1.8115\r\n",
      "Train Epoch: 2 [47360/110534 (43%)]\tClassification Loss: 1.8601\r\n",
      "Train Epoch: 2 [48000/110534 (43%)]\tClassification Loss: 1.7956\r\n",
      "Train Epoch: 2 [48640/110534 (44%)]\tClassification Loss: 1.6321\r\n",
      "Train Epoch: 2 [49280/110534 (45%)]\tClassification Loss: 1.4114\r\n",
      "Train Epoch: 2 [49920/110534 (45%)]\tClassification Loss: 1.5354\r\n",
      "Train Epoch: 2 [50560/110534 (46%)]\tClassification Loss: 1.7449\r\n",
      "Train Epoch: 2 [51200/110534 (46%)]\tClassification Loss: 1.7897\r\n",
      "Test() called at step_no: 2527\r\n",
      "\r\n",
      "Test set: Average loss: 1.7353, Accuracy: 1021/1920 (53%)\r\n",
      "\r\n",
      "Train Epoch: 2 [51840/110534 (47%)]\tClassification Loss: 1.4529\r\n",
      "Train Epoch: 2 [52480/110534 (47%)]\tClassification Loss: 1.6111\r\n",
      "Train Epoch: 2 [53120/110534 (48%)]\tClassification Loss: 1.7754\r\n",
      "Train Epoch: 2 [53760/110534 (49%)]\tClassification Loss: 1.6127\r\n",
      "Train Epoch: 2 [54400/110534 (49%)]\tClassification Loss: 1.8811\r\n",
      "Train Epoch: 2 [55040/110534 (50%)]\tClassification Loss: 1.6211\r\n",
      "Train Epoch: 2 [55680/110534 (50%)]\tClassification Loss: 1.9302\r\n",
      "Train Epoch: 2 [56320/110534 (51%)]\tClassification Loss: 1.6360\r\n",
      "Train Epoch: 2 [56960/110534 (52%)]\tClassification Loss: 1.6531\r\n",
      "Train Epoch: 2 [57600/110534 (52%)]\tClassification Loss: 1.8188\r\n",
      "Test() called at step_no: 2627\r\n",
      "\r\n",
      "Test set: Average loss: 1.7297, Accuracy: 1025/1920 (53%)\r\n",
      "\r\n",
      "Train Epoch: 2 [58240/110534 (53%)]\tClassification Loss: 1.4741\r\n",
      "Train Epoch: 2 [58880/110534 (53%)]\tClassification Loss: 1.8650\r\n",
      "Train Epoch: 2 [59520/110534 (54%)]\tClassification Loss: 1.7541\r\n",
      "Train Epoch: 2 [60160/110534 (54%)]\tClassification Loss: 1.9641\r\n",
      "Train Epoch: 2 [60800/110534 (55%)]\tClassification Loss: 2.1204\r\n",
      "Train Epoch: 2 [61440/110534 (56%)]\tClassification Loss: 1.6895\r\n",
      "Train Epoch: 2 [62080/110534 (56%)]\tClassification Loss: 2.0898\r\n",
      "Train Epoch: 2 [62720/110534 (57%)]\tClassification Loss: 1.7411\r\n",
      "Train Epoch: 2 [63360/110534 (57%)]\tClassification Loss: 1.9688\r\n",
      "Train Epoch: 2 [64000/110534 (58%)]\tClassification Loss: 1.7493\r\n",
      "Test() called at step_no: 2727\r\n",
      "\r\n",
      "Test set: Average loss: 1.7229, Accuracy: 1030/1920 (54%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1000.pth.tar\r\n",
      "Train Epoch: 2 [64640/110534 (58%)]\tClassification Loss: 1.7824\r\n",
      "Train Epoch: 2 [65280/110534 (59%)]\tClassification Loss: 1.8142\r\n",
      "Train Epoch: 2 [65920/110534 (60%)]\tClassification Loss: 1.4356\r\n",
      "Train Epoch: 2 [66560/110534 (60%)]\tClassification Loss: 1.7349\r\n",
      "Train Epoch: 2 [67200/110534 (61%)]\tClassification Loss: 1.9038\r\n",
      "Train Epoch: 2 [67840/110534 (61%)]\tClassification Loss: 1.4113\r\n",
      "Train Epoch: 2 [68480/110534 (62%)]\tClassification Loss: 1.5666\r\n",
      "Train Epoch: 2 [69120/110534 (63%)]\tClassification Loss: 1.6539\r\n",
      "Train Epoch: 2 [69760/110534 (63%)]\tClassification Loss: 1.6511\r\n",
      "Train Epoch: 2 [70400/110534 (64%)]\tClassification Loss: 1.8177\r\n",
      "Test() called at step_no: 2827\r\n",
      "\r\n",
      "Test set: Average loss: 1.7237, Accuracy: 1009/1920 (53%)\r\n",
      "\r\n",
      "Train Epoch: 2 [71040/110534 (64%)]\tClassification Loss: 1.7084\r\n",
      "Train Epoch: 2 [71680/110534 (65%)]\tClassification Loss: 1.5160\r\n",
      "Train Epoch: 2 [72320/110534 (65%)]\tClassification Loss: 1.6922\r\n",
      "Train Epoch: 2 [72960/110534 (66%)]\tClassification Loss: 1.7535\r\n",
      "Train Epoch: 2 [73600/110534 (67%)]\tClassification Loss: 1.6306\r\n",
      "Train Epoch: 2 [74240/110534 (67%)]\tClassification Loss: 1.6348\r\n",
      "Train Epoch: 2 [74880/110534 (68%)]\tClassification Loss: 1.5231\r\n",
      "Train Epoch: 2 [75520/110534 (68%)]\tClassification Loss: 1.7642\r\n",
      "Train Epoch: 2 [76160/110534 (69%)]\tClassification Loss: 1.6325\r\n",
      "Train Epoch: 2 [76800/110534 (69%)]\tClassification Loss: 1.5579\r\n",
      "Test() called at step_no: 2927\r\n",
      "\r\n",
      "Test set: Average loss: 1.7118, Accuracy: 1029/1920 (54%)\r\n",
      "\r\n",
      "Train Epoch: 2 [77440/110534 (70%)]\tClassification Loss: 1.8057\r\n",
      "Train Epoch: 2 [78080/110534 (71%)]\tClassification Loss: 1.7435\r\n",
      "Train Epoch: 2 [78720/110534 (71%)]\tClassification Loss: 1.6538\r\n",
      "Train Epoch: 2 [79360/110534 (72%)]\tClassification Loss: 1.9719\r\n",
      "Train Epoch: 2 [80000/110534 (72%)]\tClassification Loss: 1.7325\r\n",
      "Train Epoch: 2 [80640/110534 (73%)]\tClassification Loss: 1.7103\r\n",
      "Train Epoch: 2 [81280/110534 (74%)]\tClassification Loss: 2.1305\r\n",
      "Train Epoch: 2 [81920/110534 (74%)]\tClassification Loss: 1.4358\r\n",
      "Train Epoch: 2 [82560/110534 (75%)]\tClassification Loss: 2.0793\r\n",
      "Train Epoch: 2 [83200/110534 (75%)]\tClassification Loss: 1.5107\r\n",
      "Test() called at step_no: 3027\r\n",
      "\r\n",
      "Test set: Average loss: 1.7075, Accuracy: 1021/1920 (53%)\r\n",
      "\r\n",
      "Train Epoch: 2 [83840/110534 (76%)]\tClassification Loss: 1.8968\r\n",
      "Train Epoch: 2 [84480/110534 (76%)]\tClassification Loss: 1.5635\r\n",
      "Train Epoch: 2 [85120/110534 (77%)]\tClassification Loss: 1.7934\r\n",
      "Train Epoch: 2 [85760/110534 (78%)]\tClassification Loss: 1.9133\r\n",
      "Train Epoch: 2 [86400/110534 (78%)]\tClassification Loss: 1.8902\r\n",
      "Train Epoch: 2 [87040/110534 (79%)]\tClassification Loss: 1.5133\r\n",
      "Train Epoch: 2 [87680/110534 (79%)]\tClassification Loss: 1.4868\r\n",
      "Train Epoch: 2 [88320/110534 (80%)]\tClassification Loss: 1.7175\r\n",
      "Train Epoch: 2 [88960/110534 (80%)]\tClassification Loss: 1.4179\r\n",
      "Train Epoch: 2 [89600/110534 (81%)]\tClassification Loss: 1.7315\r\n",
      "Test() called at step_no: 3127\r\n",
      "\r\n",
      "Test set: Average loss: 1.7039, Accuracy: 1022/1920 (53%)\r\n",
      "\r\n",
      "Train Epoch: 2 [90240/110534 (82%)]\tClassification Loss: 1.6913\r\n",
      "Train Epoch: 2 [90880/110534 (82%)]\tClassification Loss: 2.0900\r\n",
      "Train Epoch: 2 [91520/110534 (83%)]\tClassification Loss: 1.5950\r\n",
      "Train Epoch: 2 [92160/110534 (83%)]\tClassification Loss: 1.6458\r\n",
      "Train Epoch: 2 [92800/110534 (84%)]\tClassification Loss: 1.4415\r\n",
      "Train Epoch: 2 [93440/110534 (85%)]\tClassification Loss: 1.5036\r\n",
      "Train Epoch: 2 [94080/110534 (85%)]\tClassification Loss: 1.9014\r\n",
      "Train Epoch: 2 [94720/110534 (86%)]\tClassification Loss: 1.5805\r\n",
      "Train Epoch: 2 [95360/110534 (86%)]\tClassification Loss: 1.6312\r\n",
      "Train Epoch: 2 [96000/110534 (87%)]\tClassification Loss: 1.4984\r\n",
      "Test() called at step_no: 3227\r\n",
      "\r\n",
      "Test set: Average loss: 1.7000, Accuracy: 1017/1920 (53%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1500.pth.tar\r\n",
      "Train Epoch: 2 [96640/110534 (87%)]\tClassification Loss: 1.8832\r\n",
      "Train Epoch: 2 [97280/110534 (88%)]\tClassification Loss: 1.5067\r\n",
      "Train Epoch: 2 [97920/110534 (89%)]\tClassification Loss: 1.7781\r\n",
      "Train Epoch: 2 [98560/110534 (89%)]\tClassification Loss: 1.8227\r\n",
      "Train Epoch: 2 [99200/110534 (90%)]\tClassification Loss: 1.6141\r\n",
      "Train Epoch: 2 [99840/110534 (90%)]\tClassification Loss: 1.7003\r\n",
      "Train Epoch: 2 [100480/110534 (91%)]\tClassification Loss: 1.8377\r\n",
      "Train Epoch: 2 [101120/110534 (91%)]\tClassification Loss: 1.7036\r\n",
      "Train Epoch: 2 [101760/110534 (92%)]\tClassification Loss: 1.5110\r\n",
      "Train Epoch: 2 [102400/110534 (93%)]\tClassification Loss: 1.6725\r\n",
      "Test() called at step_no: 3327\r\n",
      "\r\n",
      "Test set: Average loss: 1.6938, Accuracy: 1033/1920 (54%)\r\n",
      "\r\n",
      "Train Epoch: 2 [103040/110534 (93%)]\tClassification Loss: 1.8459\r\n",
      "Train Epoch: 2 [103680/110534 (94%)]\tClassification Loss: 1.6879\r\n",
      "Train Epoch: 2 [104320/110534 (94%)]\tClassification Loss: 1.5422\r\n",
      "Train Epoch: 2 [104960/110534 (95%)]\tClassification Loss: 1.5295\r\n",
      "Train Epoch: 2 [105600/110534 (96%)]\tClassification Loss: 1.5056\r\n",
      "Train Epoch: 2 [106240/110534 (96%)]\tClassification Loss: 1.7199\r\n",
      "Train Epoch: 2 [106880/110534 (97%)]\tClassification Loss: 1.3134\r\n",
      "Train Epoch: 2 [107520/110534 (97%)]\tClassification Loss: 1.6715\r\n",
      "Train Epoch: 2 [108160/110534 (98%)]\tClassification Loss: 1.5388\r\n",
      "Train Epoch: 2 [108800/110534 (98%)]\tClassification Loss: 1.7623\r\n",
      "Test() called at step_no: 3427\r\n",
      "\r\n",
      "Test set: Average loss: 1.6931, Accuracy: 1029/1920 (54%)\r\n",
      "\r\n",
      "Train Epoch: 2 [109440/110534 (99%)]\tClassification Loss: 1.7171\r\n",
      "Train Epoch: 2 [110080/110534 (100%)]\tClassification Loss: 1.7325\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_final.pth.tar\r\n",
      "Train Epoch: 3 [0/110534 (0%)]\tClassification Loss: 1.9036\r\n",
      "Test() called at step_no: 3454\r\n",
      "\r\n",
      "Test set: Average loss: 1.6925, Accuracy: 1026/1920 (53%)\r\n",
      "\r\n",
      "Train Epoch: 3 [640/110534 (1%)]\tClassification Loss: 1.6025\r\n",
      "Train Epoch: 3 [1280/110534 (1%)]\tClassification Loss: 1.4339\r\n",
      "Train Epoch: 3 [1920/110534 (2%)]\tClassification Loss: 1.6623\r\n",
      "Train Epoch: 3 [2560/110534 (2%)]\tClassification Loss: 1.6892\r\n",
      "Train Epoch: 3 [3200/110534 (3%)]\tClassification Loss: 1.5451\r\n",
      "Train Epoch: 3 [3840/110534 (3%)]\tClassification Loss: 1.6788\r\n",
      "Train Epoch: 3 [4480/110534 (4%)]\tClassification Loss: 1.9142\r\n",
      "Train Epoch: 3 [5120/110534 (5%)]\tClassification Loss: 1.7867\r\n",
      "Train Epoch: 3 [5760/110534 (5%)]\tClassification Loss: 1.8160\r\n",
      "Train Epoch: 3 [6400/110534 (6%)]\tClassification Loss: 1.7782\r\n",
      "Test() called at step_no: 3554\r\n",
      "\r\n",
      "Test set: Average loss: 1.6805, Accuracy: 1040/1920 (54%)\r\n",
      "\r\n",
      "Train Epoch: 3 [7040/110534 (6%)]\tClassification Loss: 1.9299\r\n",
      "Train Epoch: 3 [7680/110534 (7%)]\tClassification Loss: 1.8060\r\n",
      "Train Epoch: 3 [8320/110534 (8%)]\tClassification Loss: 1.5936\r\n",
      "Train Epoch: 3 [8960/110534 (8%)]\tClassification Loss: 1.7031\r\n",
      "Train Epoch: 3 [9600/110534 (9%)]\tClassification Loss: 1.6852\r\n",
      "Train Epoch: 3 [10240/110534 (9%)]\tClassification Loss: 1.7519\r\n",
      "Train Epoch: 3 [10880/110534 (10%)]\tClassification Loss: 1.6993\r\n",
      "Train Epoch: 3 [11520/110534 (10%)]\tClassification Loss: 1.8268\r\n",
      "Train Epoch: 3 [12160/110534 (11%)]\tClassification Loss: 1.8948\r\n",
      "Train Epoch: 3 [12800/110534 (12%)]\tClassification Loss: 1.8661\r\n",
      "Test() called at step_no: 3654\r\n",
      "\r\n",
      "Test set: Average loss: 1.6809, Accuracy: 1037/1920 (54%)\r\n",
      "\r\n",
      "Train Epoch: 3 [13440/110534 (12%)]\tClassification Loss: 1.7199\r\n",
      "Train Epoch: 3 [14080/110534 (13%)]\tClassification Loss: 1.5064\r\n",
      "Train Epoch: 3 [14720/110534 (13%)]\tClassification Loss: 1.5750\r\n",
      "Train Epoch: 3 [15360/110534 (14%)]\tClassification Loss: 1.8421\r\n",
      "Train Epoch: 3 [16000/110534 (14%)]\tClassification Loss: 1.9899\r\n",
      "Train Epoch: 3 [16640/110534 (15%)]\tClassification Loss: 1.7851\r\n",
      "Train Epoch: 3 [17280/110534 (16%)]\tClassification Loss: 1.7884\r\n",
      "Train Epoch: 3 [17920/110534 (16%)]\tClassification Loss: 1.6859\r\n",
      "Train Epoch: 3 [18560/110534 (17%)]\tClassification Loss: 1.8360\r\n",
      "Train Epoch: 3 [19200/110534 (17%)]\tClassification Loss: 1.7194\r\n",
      "Test() called at step_no: 3754\r\n",
      "\r\n",
      "Test set: Average loss: 1.6742, Accuracy: 1044/1920 (54%)\r\n",
      "\r\n",
      "Train Epoch: 3 [19840/110534 (18%)]\tClassification Loss: 1.8359\r\n",
      "Train Epoch: 3 [20480/110534 (19%)]\tClassification Loss: 1.7447\r\n",
      "Train Epoch: 3 [21120/110534 (19%)]\tClassification Loss: 1.5939\r\n",
      "Train Epoch: 3 [21760/110534 (20%)]\tClassification Loss: 1.7541\r\n",
      "Train Epoch: 3 [22400/110534 (20%)]\tClassification Loss: 1.9417\r\n",
      "Train Epoch: 3 [23040/110534 (21%)]\tClassification Loss: 1.6776\r\n",
      "Train Epoch: 3 [23680/110534 (21%)]\tClassification Loss: 1.6396\r\n",
      "Train Epoch: 3 [24320/110534 (22%)]\tClassification Loss: 1.5190\r\n",
      "Train Epoch: 3 [24960/110534 (23%)]\tClassification Loss: 1.5939\r\n",
      "Train Epoch: 3 [25600/110534 (23%)]\tClassification Loss: 2.0663\r\n",
      "Test() called at step_no: 3854\r\n",
      "\r\n",
      "Test set: Average loss: 1.6733, Accuracy: 1035/1920 (54%)\r\n",
      "\r\n",
      "Train Epoch: 3 [26240/110534 (24%)]\tClassification Loss: 1.6501\r\n",
      "Train Epoch: 3 [26880/110534 (24%)]\tClassification Loss: 1.7148\r\n",
      "Train Epoch: 3 [27520/110534 (25%)]\tClassification Loss: 1.3659\r\n",
      "Train Epoch: 3 [28160/110534 (25%)]\tClassification Loss: 1.7343\r\n",
      "Train Epoch: 3 [28800/110534 (26%)]\tClassification Loss: 1.8492\r\n",
      "Train Epoch: 3 [29440/110534 (27%)]\tClassification Loss: 1.5188\r\n",
      "Train Epoch: 3 [30080/110534 (27%)]\tClassification Loss: 1.7545\r\n",
      "Train Epoch: 3 [30720/110534 (28%)]\tClassification Loss: 1.5403\r\n",
      "Train Epoch: 3 [31360/110534 (28%)]\tClassification Loss: 1.8269\r\n",
      "Train Epoch: 3 [32000/110534 (29%)]\tClassification Loss: 1.6451\r\n",
      "Test() called at step_no: 3954\r\n",
      "\r\n",
      "Test set: Average loss: 1.6709, Accuracy: 1042/1920 (54%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_500.pth.tar\r\n",
      "Train Epoch: 3 [32640/110534 (30%)]\tClassification Loss: 1.6417\r\n",
      "Train Epoch: 3 [33280/110534 (30%)]\tClassification Loss: 1.4534\r\n",
      "Train Epoch: 3 [33920/110534 (31%)]\tClassification Loss: 1.7932\r\n",
      "Train Epoch: 3 [34560/110534 (31%)]\tClassification Loss: 1.8444\r\n",
      "Train Epoch: 3 [35200/110534 (32%)]\tClassification Loss: 1.5684\r\n",
      "Train Epoch: 3 [35840/110534 (32%)]\tClassification Loss: 1.3746\r\n",
      "Train Epoch: 3 [36480/110534 (33%)]\tClassification Loss: 1.5549\r\n",
      "Train Epoch: 3 [37120/110534 (34%)]\tClassification Loss: 1.7236\r\n",
      "Train Epoch: 3 [37760/110534 (34%)]\tClassification Loss: 1.6154\r\n",
      "Train Epoch: 3 [38400/110534 (35%)]\tClassification Loss: 1.6997\r\n",
      "Test() called at step_no: 4054\r\n",
      "\r\n",
      "Test set: Average loss: 1.6663, Accuracy: 1038/1920 (54%)\r\n",
      "\r\n",
      "Train Epoch: 3 [39040/110534 (35%)]\tClassification Loss: 1.3345\r\n",
      "Train Epoch: 3 [39680/110534 (36%)]\tClassification Loss: 1.9093\r\n",
      "Train Epoch: 3 [40320/110534 (36%)]\tClassification Loss: 1.8292\r\n",
      "Train Epoch: 3 [40960/110534 (37%)]\tClassification Loss: 1.4422\r\n",
      "Train Epoch: 3 [41600/110534 (38%)]\tClassification Loss: 1.7499\r\n",
      "Train Epoch: 3 [42240/110534 (38%)]\tClassification Loss: 1.6107\r\n",
      "Train Epoch: 3 [42880/110534 (39%)]\tClassification Loss: 1.6878\r\n",
      "Train Epoch: 3 [43520/110534 (39%)]\tClassification Loss: 1.9191\r\n",
      "Train Epoch: 3 [44160/110534 (40%)]\tClassification Loss: 1.6682\r\n",
      "Train Epoch: 3 [44800/110534 (41%)]\tClassification Loss: 1.5578\r\n",
      "Test() called at step_no: 4154\r\n",
      "\r\n",
      "Test set: Average loss: 1.6624, Accuracy: 1045/1920 (54%)\r\n",
      "\r\n",
      "Train Epoch: 3 [45440/110534 (41%)]\tClassification Loss: 1.9557\r\n",
      "Train Epoch: 3 [46080/110534 (42%)]\tClassification Loss: 1.5999\r\n",
      "Train Epoch: 3 [46720/110534 (42%)]\tClassification Loss: 1.9053\r\n",
      "Train Epoch: 3 [47360/110534 (43%)]\tClassification Loss: 1.6763\r\n",
      "Train Epoch: 3 [48000/110534 (43%)]\tClassification Loss: 1.7667\r\n",
      "Train Epoch: 3 [48640/110534 (44%)]\tClassification Loss: 1.5610\r\n",
      "Train Epoch: 3 [49280/110534 (45%)]\tClassification Loss: 1.4709\r\n",
      "Train Epoch: 3 [49920/110534 (45%)]\tClassification Loss: 1.4449\r\n",
      "Train Epoch: 3 [50560/110534 (46%)]\tClassification Loss: 1.6828\r\n",
      "Train Epoch: 3 [51200/110534 (46%)]\tClassification Loss: 1.5829\r\n",
      "Test() called at step_no: 4254\r\n",
      "\r\n",
      "Test set: Average loss: 1.6585, Accuracy: 1043/1920 (54%)\r\n",
      "\r\n",
      "Train Epoch: 3 [51840/110534 (47%)]\tClassification Loss: 1.4600\r\n",
      "Train Epoch: 3 [52480/110534 (47%)]\tClassification Loss: 1.6869\r\n",
      "Train Epoch: 3 [53120/110534 (48%)]\tClassification Loss: 1.8303\r\n",
      "Train Epoch: 3 [53760/110534 (49%)]\tClassification Loss: 1.5019\r\n",
      "Train Epoch: 3 [54400/110534 (49%)]\tClassification Loss: 1.8446\r\n",
      "Train Epoch: 3 [55040/110534 (50%)]\tClassification Loss: 1.4401\r\n",
      "Train Epoch: 3 [55680/110534 (50%)]\tClassification Loss: 2.0538\r\n",
      "Train Epoch: 3 [56320/110534 (51%)]\tClassification Loss: 1.5904\r\n",
      "Train Epoch: 3 [56960/110534 (52%)]\tClassification Loss: 1.5128\r\n",
      "Train Epoch: 3 [57600/110534 (52%)]\tClassification Loss: 1.8485\r\n",
      "Test() called at step_no: 4354\r\n",
      "\r\n",
      "Test set: Average loss: 1.6562, Accuracy: 1055/1920 (55%)\r\n",
      "\r\n",
      "Train Epoch: 3 [58240/110534 (53%)]\tClassification Loss: 1.4732\r\n",
      "Train Epoch: 3 [58880/110534 (53%)]\tClassification Loss: 1.7872\r\n",
      "Train Epoch: 3 [59520/110534 (54%)]\tClassification Loss: 1.7313\r\n",
      "Train Epoch: 3 [60160/110534 (54%)]\tClassification Loss: 1.8068\r\n",
      "Train Epoch: 3 [60800/110534 (55%)]\tClassification Loss: 2.0269\r\n",
      "Train Epoch: 3 [61440/110534 (56%)]\tClassification Loss: 1.6226\r\n",
      "Train Epoch: 3 [62080/110534 (56%)]\tClassification Loss: 2.1739\r\n",
      "Train Epoch: 3 [62720/110534 (57%)]\tClassification Loss: 1.8908\r\n",
      "Train Epoch: 3 [63360/110534 (57%)]\tClassification Loss: 1.9516\r\n",
      "Train Epoch: 3 [64000/110534 (58%)]\tClassification Loss: 1.6049\r\n",
      "Test() called at step_no: 4454\r\n",
      "\r\n",
      "Test set: Average loss: 1.6526, Accuracy: 1056/1920 (55%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1000.pth.tar\r\n",
      "Train Epoch: 3 [64640/110534 (58%)]\tClassification Loss: 1.7780\r\n",
      "Train Epoch: 3 [65280/110534 (59%)]\tClassification Loss: 1.6522\r\n",
      "Train Epoch: 3 [65920/110534 (60%)]\tClassification Loss: 1.4165\r\n",
      "Train Epoch: 3 [66560/110534 (60%)]\tClassification Loss: 1.6222\r\n",
      "Train Epoch: 3 [67200/110534 (61%)]\tClassification Loss: 1.8287\r\n",
      "Train Epoch: 3 [67840/110534 (61%)]\tClassification Loss: 1.3629\r\n",
      "Train Epoch: 3 [68480/110534 (62%)]\tClassification Loss: 1.7261\r\n",
      "Train Epoch: 3 [69120/110534 (63%)]\tClassification Loss: 1.5109\r\n",
      "Train Epoch: 3 [69760/110534 (63%)]\tClassification Loss: 1.5624\r\n",
      "Train Epoch: 3 [70400/110534 (64%)]\tClassification Loss: 1.8214\r\n",
      "Test() called at step_no: 4554\r\n",
      "\r\n",
      "Test set: Average loss: 1.6570, Accuracy: 1046/1920 (54%)\r\n",
      "\r\n",
      "Train Epoch: 3 [71040/110534 (64%)]\tClassification Loss: 1.7204\r\n",
      "Train Epoch: 3 [71680/110534 (65%)]\tClassification Loss: 1.5889\r\n",
      "Train Epoch: 3 [72320/110534 (65%)]\tClassification Loss: 1.7090\r\n",
      "Train Epoch: 3 [72960/110534 (66%)]\tClassification Loss: 1.5728\r\n",
      "Train Epoch: 3 [73600/110534 (67%)]\tClassification Loss: 1.6325\r\n",
      "Train Epoch: 3 [74240/110534 (67%)]\tClassification Loss: 1.4635\r\n",
      "Train Epoch: 3 [74880/110534 (68%)]\tClassification Loss: 1.6095\r\n",
      "Train Epoch: 3 [75520/110534 (68%)]\tClassification Loss: 1.6089\r\n",
      "Train Epoch: 3 [76160/110534 (69%)]\tClassification Loss: 1.7839\r\n",
      "Train Epoch: 3 [76800/110534 (69%)]\tClassification Loss: 1.5598\r\n",
      "Test() called at step_no: 4654\r\n",
      "\r\n",
      "Test set: Average loss: 1.6463, Accuracy: 1053/1920 (55%)\r\n",
      "\r\n",
      "Train Epoch: 3 [77440/110534 (70%)]\tClassification Loss: 1.8827\r\n",
      "Train Epoch: 3 [78080/110534 (71%)]\tClassification Loss: 1.7215\r\n",
      "Train Epoch: 3 [78720/110534 (71%)]\tClassification Loss: 1.7001\r\n",
      "Train Epoch: 3 [79360/110534 (72%)]\tClassification Loss: 2.0061\r\n",
      "Train Epoch: 3 [80000/110534 (72%)]\tClassification Loss: 1.7287\r\n",
      "Train Epoch: 3 [80640/110534 (73%)]\tClassification Loss: 1.7930\r\n",
      "Train Epoch: 3 [81280/110534 (74%)]\tClassification Loss: 2.0565\r\n",
      "Train Epoch: 3 [81920/110534 (74%)]\tClassification Loss: 1.3913\r\n",
      "Train Epoch: 3 [82560/110534 (75%)]\tClassification Loss: 1.8642\r\n",
      "Train Epoch: 3 [83200/110534 (75%)]\tClassification Loss: 1.4369\r\n",
      "Test() called at step_no: 4754\r\n",
      "\r\n",
      "Test set: Average loss: 1.6462, Accuracy: 1053/1920 (55%)\r\n",
      "\r\n",
      "Train Epoch: 3 [83840/110534 (76%)]\tClassification Loss: 1.8668\r\n",
      "Train Epoch: 3 [84480/110534 (76%)]\tClassification Loss: 1.6631\r\n",
      "Train Epoch: 3 [85120/110534 (77%)]\tClassification Loss: 1.8060\r\n",
      "Train Epoch: 3 [85760/110534 (78%)]\tClassification Loss: 1.9194\r\n",
      "Train Epoch: 3 [86400/110534 (78%)]\tClassification Loss: 1.7785\r\n",
      "Train Epoch: 3 [87040/110534 (79%)]\tClassification Loss: 1.4999\r\n",
      "Train Epoch: 3 [87680/110534 (79%)]\tClassification Loss: 1.3845\r\n",
      "Train Epoch: 3 [88320/110534 (80%)]\tClassification Loss: 1.6863\r\n",
      "Train Epoch: 3 [88960/110534 (80%)]\tClassification Loss: 1.4081\r\n",
      "Train Epoch: 3 [89600/110534 (81%)]\tClassification Loss: 1.6848\r\n",
      "Test() called at step_no: 4854\r\n",
      "\r\n",
      "Test set: Average loss: 1.6450, Accuracy: 1052/1920 (55%)\r\n",
      "\r\n",
      "Train Epoch: 3 [90240/110534 (82%)]\tClassification Loss: 1.7194\r\n",
      "Train Epoch: 3 [90880/110534 (82%)]\tClassification Loss: 2.0552\r\n",
      "Train Epoch: 3 [91520/110534 (83%)]\tClassification Loss: 1.5130\r\n",
      "Train Epoch: 3 [92160/110534 (83%)]\tClassification Loss: 1.7100\r\n",
      "Train Epoch: 3 [92800/110534 (84%)]\tClassification Loss: 1.3826\r\n",
      "Train Epoch: 3 [93440/110534 (85%)]\tClassification Loss: 1.4212\r\n",
      "Train Epoch: 3 [94080/110534 (85%)]\tClassification Loss: 1.7455\r\n",
      "Train Epoch: 3 [94720/110534 (86%)]\tClassification Loss: 1.5604\r\n",
      "Train Epoch: 3 [95360/110534 (86%)]\tClassification Loss: 1.5567\r\n",
      "Train Epoch: 3 [96000/110534 (87%)]\tClassification Loss: 1.5006\r\n",
      "Test() called at step_no: 4954\r\n",
      "\r\n",
      "Test set: Average loss: 1.6422, Accuracy: 1047/1920 (55%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1500.pth.tar\r\n",
      "Train Epoch: 3 [96640/110534 (87%)]\tClassification Loss: 1.7401\r\n",
      "Train Epoch: 3 [97280/110534 (88%)]\tClassification Loss: 1.4675\r\n",
      "Train Epoch: 3 [97920/110534 (89%)]\tClassification Loss: 1.6791\r\n",
      "Train Epoch: 3 [98560/110534 (89%)]\tClassification Loss: 1.9717\r\n",
      "Train Epoch: 3 [99200/110534 (90%)]\tClassification Loss: 1.6178\r\n",
      "Train Epoch: 3 [99840/110534 (90%)]\tClassification Loss: 1.7119\r\n",
      "Train Epoch: 3 [100480/110534 (91%)]\tClassification Loss: 1.7800\r\n",
      "Train Epoch: 3 [101120/110534 (91%)]\tClassification Loss: 1.6780\r\n",
      "Train Epoch: 3 [101760/110534 (92%)]\tClassification Loss: 1.5727\r\n",
      "Train Epoch: 3 [102400/110534 (93%)]\tClassification Loss: 1.6605\r\n",
      "Test() called at step_no: 5054\r\n",
      "\r\n",
      "Test set: Average loss: 1.6398, Accuracy: 1062/1920 (55%)\r\n",
      "\r\n",
      "Train Epoch: 3 [103040/110534 (93%)]\tClassification Loss: 1.6877\r\n",
      "Train Epoch: 3 [103680/110534 (94%)]\tClassification Loss: 1.5835\r\n",
      "Train Epoch: 3 [104320/110534 (94%)]\tClassification Loss: 1.4507\r\n",
      "Train Epoch: 3 [104960/110534 (95%)]\tClassification Loss: 1.6273\r\n",
      "Train Epoch: 3 [105600/110534 (96%)]\tClassification Loss: 1.3877\r\n",
      "Train Epoch: 3 [106240/110534 (96%)]\tClassification Loss: 1.5952\r\n",
      "Train Epoch: 3 [106880/110534 (97%)]\tClassification Loss: 1.3126\r\n",
      "Train Epoch: 3 [107520/110534 (97%)]\tClassification Loss: 1.7348\r\n",
      "Train Epoch: 3 [108160/110534 (98%)]\tClassification Loss: 1.5485\r\n",
      "Train Epoch: 3 [108800/110534 (98%)]\tClassification Loss: 1.7201\r\n",
      "Test() called at step_no: 5154\r\n",
      "\r\n",
      "Test set: Average loss: 1.6417, Accuracy: 1060/1920 (55%)\r\n",
      "\r\n",
      "Train Epoch: 3 [109440/110534 (99%)]\tClassification Loss: 1.7810\r\n",
      "Train Epoch: 3 [110080/110534 (100%)]\tClassification Loss: 1.6135\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_final.pth.tar\r\n",
      "Train Epoch: 4 [0/110534 (0%)]\tClassification Loss: 1.8481\r\n",
      "Test() called at step_no: 5181\r\n",
      "\r\n",
      "Test set: Average loss: 1.6433, Accuracy: 1057/1920 (55%)\r\n",
      "\r\n",
      "Train Epoch: 4 [640/110534 (1%)]\tClassification Loss: 1.6383\r\n",
      "Train Epoch: 4 [1280/110534 (1%)]\tClassification Loss: 1.4694\r\n",
      "Train Epoch: 4 [1920/110534 (2%)]\tClassification Loss: 1.6091\r\n",
      "Train Epoch: 4 [2560/110534 (2%)]\tClassification Loss: 1.5501\r\n",
      "Train Epoch: 4 [3200/110534 (3%)]\tClassification Loss: 1.4760\r\n",
      "Train Epoch: 4 [3840/110534 (3%)]\tClassification Loss: 1.6759\r\n",
      "Train Epoch: 4 [4480/110534 (4%)]\tClassification Loss: 2.0378\r\n",
      "Train Epoch: 4 [5120/110534 (5%)]\tClassification Loss: 1.7345\r\n",
      "Train Epoch: 4 [5760/110534 (5%)]\tClassification Loss: 1.8048\r\n",
      "Train Epoch: 4 [6400/110534 (6%)]\tClassification Loss: 1.5762\r\n",
      "Test() called at step_no: 5281\r\n",
      "\r\n",
      "Test set: Average loss: 1.6314, Accuracy: 1059/1920 (55%)\r\n",
      "\r\n",
      "Train Epoch: 4 [7040/110534 (6%)]\tClassification Loss: 1.8659\r\n",
      "Train Epoch: 4 [7680/110534 (7%)]\tClassification Loss: 1.6431\r\n",
      "Train Epoch: 4 [8320/110534 (8%)]\tClassification Loss: 1.5907\r\n",
      "Train Epoch: 4 [8960/110534 (8%)]\tClassification Loss: 1.7672\r\n",
      "Train Epoch: 4 [9600/110534 (9%)]\tClassification Loss: 1.6664\r\n",
      "Train Epoch: 4 [10240/110534 (9%)]\tClassification Loss: 1.7378\r\n",
      "Train Epoch: 4 [10880/110534 (10%)]\tClassification Loss: 1.7295\r\n",
      "Train Epoch: 4 [11520/110534 (10%)]\tClassification Loss: 1.8983\r\n",
      "Train Epoch: 4 [12160/110534 (11%)]\tClassification Loss: 1.8816\r\n",
      "Train Epoch: 4 [12800/110534 (12%)]\tClassification Loss: 1.9590\r\n",
      "Test() called at step_no: 5381\r\n",
      "\r\n",
      "Test set: Average loss: 1.6344, Accuracy: 1061/1920 (55%)\r\n",
      "\r\n",
      "Train Epoch: 4 [13440/110534 (12%)]\tClassification Loss: 1.7757\r\n",
      "Train Epoch: 4 [14080/110534 (13%)]\tClassification Loss: 1.5026\r\n",
      "Train Epoch: 4 [14720/110534 (13%)]\tClassification Loss: 1.5678\r\n",
      "Train Epoch: 4 [15360/110534 (14%)]\tClassification Loss: 1.6870\r\n",
      "Train Epoch: 4 [16000/110534 (14%)]\tClassification Loss: 1.9377\r\n",
      "Train Epoch: 4 [16640/110534 (15%)]\tClassification Loss: 1.6529\r\n",
      "Train Epoch: 4 [17280/110534 (16%)]\tClassification Loss: 1.7969\r\n",
      "Train Epoch: 4 [17920/110534 (16%)]\tClassification Loss: 1.4822\r\n",
      "Train Epoch: 4 [18560/110534 (17%)]\tClassification Loss: 1.7831\r\n",
      "Train Epoch: 4 [19200/110534 (17%)]\tClassification Loss: 1.7505\r\n",
      "Test() called at step_no: 5481\r\n",
      "\r\n",
      "Test set: Average loss: 1.6286, Accuracy: 1059/1920 (55%)\r\n",
      "\r\n",
      "Train Epoch: 4 [19840/110534 (18%)]\tClassification Loss: 1.6679\r\n",
      "Train Epoch: 4 [20480/110534 (19%)]\tClassification Loss: 1.8421\r\n",
      "Train Epoch: 4 [21120/110534 (19%)]\tClassification Loss: 1.5620\r\n",
      "Train Epoch: 4 [21760/110534 (20%)]\tClassification Loss: 1.7297\r\n",
      "Train Epoch: 4 [22400/110534 (20%)]\tClassification Loss: 1.8521\r\n",
      "Train Epoch: 4 [23040/110534 (21%)]\tClassification Loss: 1.6457\r\n",
      "Train Epoch: 4 [23680/110534 (21%)]\tClassification Loss: 1.6867\r\n",
      "Train Epoch: 4 [24320/110534 (22%)]\tClassification Loss: 1.4350\r\n",
      "Train Epoch: 4 [24960/110534 (23%)]\tClassification Loss: 1.4140\r\n",
      "Train Epoch: 4 [25600/110534 (23%)]\tClassification Loss: 1.9514\r\n",
      "Test() called at step_no: 5581\r\n",
      "\r\n",
      "Test set: Average loss: 1.6295, Accuracy: 1067/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 4 [26240/110534 (24%)]\tClassification Loss: 1.5230\r\n",
      "Train Epoch: 4 [26880/110534 (24%)]\tClassification Loss: 1.7133\r\n",
      "Train Epoch: 4 [27520/110534 (25%)]\tClassification Loss: 1.3454\r\n",
      "Train Epoch: 4 [28160/110534 (25%)]\tClassification Loss: 1.5973\r\n",
      "Train Epoch: 4 [28800/110534 (26%)]\tClassification Loss: 1.9573\r\n",
      "Train Epoch: 4 [29440/110534 (27%)]\tClassification Loss: 1.5844\r\n",
      "Train Epoch: 4 [30080/110534 (27%)]\tClassification Loss: 1.7346\r\n",
      "Train Epoch: 4 [30720/110534 (28%)]\tClassification Loss: 1.5737\r\n",
      "Train Epoch: 4 [31360/110534 (28%)]\tClassification Loss: 1.7180\r\n",
      "Train Epoch: 4 [32000/110534 (29%)]\tClassification Loss: 1.5947\r\n",
      "Test() called at step_no: 5681\r\n",
      "\r\n",
      "Test set: Average loss: 1.6292, Accuracy: 1061/1920 (55%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_500.pth.tar\r\n",
      "Train Epoch: 4 [32640/110534 (30%)]\tClassification Loss: 1.5682\r\n",
      "Train Epoch: 4 [33280/110534 (30%)]\tClassification Loss: 1.4637\r\n",
      "Train Epoch: 4 [33920/110534 (31%)]\tClassification Loss: 1.7077\r\n",
      "Train Epoch: 4 [34560/110534 (31%)]\tClassification Loss: 1.6159\r\n",
      "Train Epoch: 4 [35200/110534 (32%)]\tClassification Loss: 1.4598\r\n",
      "Train Epoch: 4 [35840/110534 (32%)]\tClassification Loss: 1.4256\r\n",
      "Train Epoch: 4 [36480/110534 (33%)]\tClassification Loss: 1.5276\r\n",
      "Train Epoch: 4 [37120/110534 (34%)]\tClassification Loss: 1.7285\r\n",
      "Train Epoch: 4 [37760/110534 (34%)]\tClassification Loss: 1.6316\r\n",
      "Train Epoch: 4 [38400/110534 (35%)]\tClassification Loss: 1.6186\r\n",
      "Test() called at step_no: 5781\r\n",
      "\r\n",
      "Test set: Average loss: 1.6242, Accuracy: 1067/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 4 [39040/110534 (35%)]\tClassification Loss: 1.3350\r\n",
      "Train Epoch: 4 [39680/110534 (36%)]\tClassification Loss: 1.8029\r\n",
      "Train Epoch: 4 [40320/110534 (36%)]\tClassification Loss: 1.7671\r\n",
      "Train Epoch: 4 [40960/110534 (37%)]\tClassification Loss: 1.4528\r\n",
      "Train Epoch: 4 [41600/110534 (38%)]\tClassification Loss: 1.6676\r\n",
      "Train Epoch: 4 [42240/110534 (38%)]\tClassification Loss: 1.4121\r\n",
      "Train Epoch: 4 [42880/110534 (39%)]\tClassification Loss: 1.7219\r\n",
      "Train Epoch: 4 [43520/110534 (39%)]\tClassification Loss: 1.7439\r\n",
      "Train Epoch: 4 [44160/110534 (40%)]\tClassification Loss: 1.4555\r\n",
      "Train Epoch: 4 [44800/110534 (41%)]\tClassification Loss: 1.3701\r\n",
      "Test() called at step_no: 5881\r\n",
      "\r\n",
      "Test set: Average loss: 1.6243, Accuracy: 1064/1920 (55%)\r\n",
      "\r\n",
      "Train Epoch: 4 [45440/110534 (41%)]\tClassification Loss: 1.7627\r\n",
      "Train Epoch: 4 [46080/110534 (42%)]\tClassification Loss: 1.5958\r\n",
      "Train Epoch: 4 [46720/110534 (42%)]\tClassification Loss: 1.8385\r\n",
      "Train Epoch: 4 [47360/110534 (43%)]\tClassification Loss: 1.7933\r\n",
      "Train Epoch: 4 [48000/110534 (43%)]\tClassification Loss: 1.7803\r\n",
      "Train Epoch: 4 [48640/110534 (44%)]\tClassification Loss: 1.4848\r\n",
      "Train Epoch: 4 [49280/110534 (45%)]\tClassification Loss: 1.3219\r\n",
      "Train Epoch: 4 [49920/110534 (45%)]\tClassification Loss: 1.4447\r\n",
      "Train Epoch: 4 [50560/110534 (46%)]\tClassification Loss: 1.6482\r\n",
      "Train Epoch: 4 [51200/110534 (46%)]\tClassification Loss: 1.5004\r\n",
      "Test() called at step_no: 5981\r\n",
      "\r\n",
      "Test set: Average loss: 1.6194, Accuracy: 1068/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 4 [51840/110534 (47%)]\tClassification Loss: 1.3419\r\n",
      "Train Epoch: 4 [52480/110534 (47%)]\tClassification Loss: 1.5943\r\n",
      "Train Epoch: 4 [53120/110534 (48%)]\tClassification Loss: 1.6508\r\n",
      "Train Epoch: 4 [53760/110534 (49%)]\tClassification Loss: 1.5908\r\n",
      "Train Epoch: 4 [54400/110534 (49%)]\tClassification Loss: 1.8682\r\n",
      "Train Epoch: 4 [55040/110534 (50%)]\tClassification Loss: 1.3493\r\n",
      "Train Epoch: 4 [55680/110534 (50%)]\tClassification Loss: 1.8650\r\n",
      "Train Epoch: 4 [56320/110534 (51%)]\tClassification Loss: 1.5760\r\n",
      "Train Epoch: 4 [56960/110534 (52%)]\tClassification Loss: 1.5662\r\n",
      "Train Epoch: 4 [57600/110534 (52%)]\tClassification Loss: 1.8196\r\n",
      "Test() called at step_no: 6081\r\n",
      "\r\n",
      "Test set: Average loss: 1.6200, Accuracy: 1067/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 4 [58240/110534 (53%)]\tClassification Loss: 1.4459\r\n",
      "Train Epoch: 4 [58880/110534 (53%)]\tClassification Loss: 1.8375\r\n",
      "Train Epoch: 4 [59520/110534 (54%)]\tClassification Loss: 1.7093\r\n",
      "Train Epoch: 4 [60160/110534 (54%)]\tClassification Loss: 1.9390\r\n",
      "Train Epoch: 4 [60800/110534 (55%)]\tClassification Loss: 2.1361\r\n",
      "Train Epoch: 4 [61440/110534 (56%)]\tClassification Loss: 1.4170\r\n",
      "Train Epoch: 4 [62080/110534 (56%)]\tClassification Loss: 2.0791\r\n",
      "Train Epoch: 4 [62720/110534 (57%)]\tClassification Loss: 1.6186\r\n",
      "Train Epoch: 4 [63360/110534 (57%)]\tClassification Loss: 1.7356\r\n",
      "Train Epoch: 4 [64000/110534 (58%)]\tClassification Loss: 1.7540\r\n",
      "Test() called at step_no: 6181\r\n",
      "\r\n",
      "Test set: Average loss: 1.6183, Accuracy: 1063/1920 (55%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1000.pth.tar\r\n",
      "Train Epoch: 4 [64640/110534 (58%)]\tClassification Loss: 1.7350\r\n",
      "Train Epoch: 4 [65280/110534 (59%)]\tClassification Loss: 1.7956\r\n",
      "Train Epoch: 4 [65920/110534 (60%)]\tClassification Loss: 1.5140\r\n",
      "Train Epoch: 4 [66560/110534 (60%)]\tClassification Loss: 1.6406\r\n",
      "Train Epoch: 4 [67200/110534 (61%)]\tClassification Loss: 1.7399\r\n",
      "Train Epoch: 4 [67840/110534 (61%)]\tClassification Loss: 1.3289\r\n",
      "Train Epoch: 4 [68480/110534 (62%)]\tClassification Loss: 1.3917\r\n",
      "Train Epoch: 4 [69120/110534 (63%)]\tClassification Loss: 1.5926\r\n",
      "Train Epoch: 4 [69760/110534 (63%)]\tClassification Loss: 1.6052\r\n",
      "Train Epoch: 4 [70400/110534 (64%)]\tClassification Loss: 1.6843\r\n",
      "Test() called at step_no: 6281\r\n",
      "\r\n",
      "Test set: Average loss: 1.6233, Accuracy: 1066/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 4 [71040/110534 (64%)]\tClassification Loss: 1.5364\r\n",
      "Train Epoch: 4 [71680/110534 (65%)]\tClassification Loss: 1.6648\r\n",
      "Train Epoch: 4 [72320/110534 (65%)]\tClassification Loss: 1.5661\r\n",
      "Train Epoch: 4 [72960/110534 (66%)]\tClassification Loss: 1.5257\r\n",
      "Train Epoch: 4 [73600/110534 (67%)]\tClassification Loss: 1.5554\r\n",
      "Train Epoch: 4 [74240/110534 (67%)]\tClassification Loss: 1.6448\r\n",
      "Train Epoch: 4 [74880/110534 (68%)]\tClassification Loss: 1.6028\r\n",
      "Train Epoch: 4 [75520/110534 (68%)]\tClassification Loss: 1.6624\r\n",
      "Train Epoch: 4 [76160/110534 (69%)]\tClassification Loss: 1.5875\r\n",
      "Train Epoch: 4 [76800/110534 (69%)]\tClassification Loss: 1.5998\r\n",
      "Test() called at step_no: 6381\r\n",
      "\r\n",
      "Test set: Average loss: 1.6139, Accuracy: 1075/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 4 [77440/110534 (70%)]\tClassification Loss: 1.7900\r\n",
      "Train Epoch: 4 [78080/110534 (71%)]\tClassification Loss: 1.6669\r\n",
      "Train Epoch: 4 [78720/110534 (71%)]\tClassification Loss: 1.6019\r\n",
      "Train Epoch: 4 [79360/110534 (72%)]\tClassification Loss: 2.0295\r\n",
      "Train Epoch: 4 [80000/110534 (72%)]\tClassification Loss: 1.6516\r\n",
      "Train Epoch: 4 [80640/110534 (73%)]\tClassification Loss: 1.7987\r\n",
      "Train Epoch: 4 [81280/110534 (74%)]\tClassification Loss: 1.7803\r\n",
      "Train Epoch: 4 [81920/110534 (74%)]\tClassification Loss: 1.3839\r\n",
      "Train Epoch: 4 [82560/110534 (75%)]\tClassification Loss: 1.8060\r\n",
      "Train Epoch: 4 [83200/110534 (75%)]\tClassification Loss: 1.5260\r\n",
      "Test() called at step_no: 6481\r\n",
      "\r\n",
      "Test set: Average loss: 1.6129, Accuracy: 1072/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 4 [83840/110534 (76%)]\tClassification Loss: 1.8379\r\n",
      "Train Epoch: 4 [84480/110534 (76%)]\tClassification Loss: 1.6262\r\n",
      "Train Epoch: 4 [85120/110534 (77%)]\tClassification Loss: 1.7239\r\n",
      "Train Epoch: 4 [85760/110534 (78%)]\tClassification Loss: 2.0712\r\n",
      "Train Epoch: 4 [86400/110534 (78%)]\tClassification Loss: 1.7613\r\n",
      "Train Epoch: 4 [87040/110534 (79%)]\tClassification Loss: 1.4312\r\n",
      "Train Epoch: 4 [87680/110534 (79%)]\tClassification Loss: 1.5363\r\n",
      "Train Epoch: 4 [88320/110534 (80%)]\tClassification Loss: 1.5995\r\n",
      "Train Epoch: 4 [88960/110534 (80%)]\tClassification Loss: 1.3196\r\n",
      "Train Epoch: 4 [89600/110534 (81%)]\tClassification Loss: 1.4750\r\n",
      "Test() called at step_no: 6581\r\n",
      "\r\n",
      "Test set: Average loss: 1.6119, Accuracy: 1073/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 4 [90240/110534 (82%)]\tClassification Loss: 1.5699\r\n",
      "Train Epoch: 4 [90880/110534 (82%)]\tClassification Loss: 2.0506\r\n",
      "Train Epoch: 4 [91520/110534 (83%)]\tClassification Loss: 1.5287\r\n",
      "Train Epoch: 4 [92160/110534 (83%)]\tClassification Loss: 1.5817\r\n",
      "Train Epoch: 4 [92800/110534 (84%)]\tClassification Loss: 1.2573\r\n",
      "Train Epoch: 4 [93440/110534 (85%)]\tClassification Loss: 1.4087\r\n",
      "Train Epoch: 4 [94080/110534 (85%)]\tClassification Loss: 1.7184\r\n",
      "Train Epoch: 4 [94720/110534 (86%)]\tClassification Loss: 1.5009\r\n",
      "Train Epoch: 4 [95360/110534 (86%)]\tClassification Loss: 1.5709\r\n",
      "Train Epoch: 4 [96000/110534 (87%)]\tClassification Loss: 1.3221\r\n",
      "Test() called at step_no: 6681\r\n",
      "\r\n",
      "Test set: Average loss: 1.6115, Accuracy: 1067/1920 (56%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1500.pth.tar\r\n",
      "Train Epoch: 4 [96640/110534 (87%)]\tClassification Loss: 1.7218\r\n",
      "Train Epoch: 4 [97280/110534 (88%)]\tClassification Loss: 1.5803\r\n",
      "Train Epoch: 4 [97920/110534 (89%)]\tClassification Loss: 1.6900\r\n",
      "Train Epoch: 4 [98560/110534 (89%)]\tClassification Loss: 1.6482\r\n",
      "Train Epoch: 4 [99200/110534 (90%)]\tClassification Loss: 1.6489\r\n",
      "Train Epoch: 4 [99840/110534 (90%)]\tClassification Loss: 1.5591\r\n",
      "Train Epoch: 4 [100480/110534 (91%)]\tClassification Loss: 1.8311\r\n",
      "Train Epoch: 4 [101120/110534 (91%)]\tClassification Loss: 1.5698\r\n",
      "Train Epoch: 4 [101760/110534 (92%)]\tClassification Loss: 1.5972\r\n",
      "Train Epoch: 4 [102400/110534 (93%)]\tClassification Loss: 1.6804\r\n",
      "Test() called at step_no: 6781\r\n",
      "\r\n",
      "Test set: Average loss: 1.6098, Accuracy: 1077/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 4 [103040/110534 (93%)]\tClassification Loss: 1.7475\r\n",
      "Train Epoch: 4 [103680/110534 (94%)]\tClassification Loss: 1.4868\r\n",
      "Train Epoch: 4 [104320/110534 (94%)]\tClassification Loss: 1.3830\r\n",
      "Train Epoch: 4 [104960/110534 (95%)]\tClassification Loss: 1.6722\r\n",
      "Train Epoch: 4 [105600/110534 (96%)]\tClassification Loss: 1.4200\r\n",
      "Train Epoch: 4 [106240/110534 (96%)]\tClassification Loss: 1.6593\r\n",
      "Train Epoch: 4 [106880/110534 (97%)]\tClassification Loss: 1.4267\r\n",
      "Train Epoch: 4 [107520/110534 (97%)]\tClassification Loss: 1.6620\r\n",
      "Train Epoch: 4 [108160/110534 (98%)]\tClassification Loss: 1.6132\r\n",
      "Train Epoch: 4 [108800/110534 (98%)]\tClassification Loss: 1.7228\r\n",
      "Test() called at step_no: 6881\r\n",
      "\r\n",
      "Test set: Average loss: 1.6131, Accuracy: 1079/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 4 [109440/110534 (99%)]\tClassification Loss: 1.7770\r\n",
      "Train Epoch: 4 [110080/110534 (100%)]\tClassification Loss: 1.6604\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_final.pth.tar\r\n",
      "Train Epoch: 5 [0/110534 (0%)]\tClassification Loss: 1.6960\r\n",
      "Test() called at step_no: 6908\r\n",
      "\r\n",
      "Test set: Average loss: 1.6144, Accuracy: 1074/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 5 [640/110534 (1%)]\tClassification Loss: 1.6568\r\n",
      "Train Epoch: 5 [1280/110534 (1%)]\tClassification Loss: 1.5606\r\n",
      "Train Epoch: 5 [1920/110534 (2%)]\tClassification Loss: 1.4741\r\n",
      "Train Epoch: 5 [2560/110534 (2%)]\tClassification Loss: 1.6052\r\n",
      "Train Epoch: 5 [3200/110534 (3%)]\tClassification Loss: 1.5250\r\n",
      "Train Epoch: 5 [3840/110534 (3%)]\tClassification Loss: 1.5635\r\n",
      "Train Epoch: 5 [4480/110534 (4%)]\tClassification Loss: 1.9280\r\n",
      "Train Epoch: 5 [5120/110534 (5%)]\tClassification Loss: 1.6920\r\n",
      "Train Epoch: 5 [5760/110534 (5%)]\tClassification Loss: 1.6621\r\n",
      "Train Epoch: 5 [6400/110534 (6%)]\tClassification Loss: 1.7494\r\n",
      "Test() called at step_no: 7008\r\n",
      "\r\n",
      "Test set: Average loss: 1.6051, Accuracy: 1081/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 5 [7040/110534 (6%)]\tClassification Loss: 1.9046\r\n",
      "Train Epoch: 5 [7680/110534 (7%)]\tClassification Loss: 1.6359\r\n",
      "Train Epoch: 5 [8320/110534 (8%)]\tClassification Loss: 1.6753\r\n",
      "Train Epoch: 5 [8960/110534 (8%)]\tClassification Loss: 1.7832\r\n",
      "Train Epoch: 5 [9600/110534 (9%)]\tClassification Loss: 1.7981\r\n",
      "Train Epoch: 5 [10240/110534 (9%)]\tClassification Loss: 1.8535\r\n",
      "Train Epoch: 5 [10880/110534 (10%)]\tClassification Loss: 1.8005\r\n",
      "Train Epoch: 5 [11520/110534 (10%)]\tClassification Loss: 1.8134\r\n",
      "Train Epoch: 5 [12160/110534 (11%)]\tClassification Loss: 1.8219\r\n",
      "Train Epoch: 5 [12800/110534 (12%)]\tClassification Loss: 1.8529\r\n",
      "Test() called at step_no: 7108\r\n",
      "\r\n",
      "Test set: Average loss: 1.6082, Accuracy: 1069/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 5 [13440/110534 (12%)]\tClassification Loss: 1.7688\r\n",
      "Train Epoch: 5 [14080/110534 (13%)]\tClassification Loss: 1.5887\r\n",
      "Train Epoch: 5 [14720/110534 (13%)]\tClassification Loss: 1.6762\r\n",
      "Train Epoch: 5 [15360/110534 (14%)]\tClassification Loss: 1.6917\r\n",
      "Train Epoch: 5 [16000/110534 (14%)]\tClassification Loss: 1.9409\r\n",
      "Train Epoch: 5 [16640/110534 (15%)]\tClassification Loss: 1.6902\r\n",
      "Train Epoch: 5 [17280/110534 (16%)]\tClassification Loss: 1.7932\r\n",
      "Train Epoch: 5 [17920/110534 (16%)]\tClassification Loss: 1.6269\r\n",
      "Train Epoch: 5 [18560/110534 (17%)]\tClassification Loss: 1.8493\r\n",
      "Train Epoch: 5 [19200/110534 (17%)]\tClassification Loss: 1.7162\r\n",
      "Test() called at step_no: 7208\r\n",
      "\r\n",
      "Test set: Average loss: 1.6047, Accuracy: 1076/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 5 [19840/110534 (18%)]\tClassification Loss: 1.7095\r\n",
      "Train Epoch: 5 [20480/110534 (19%)]\tClassification Loss: 1.6194\r\n",
      "Train Epoch: 5 [21120/110534 (19%)]\tClassification Loss: 1.5849\r\n",
      "Train Epoch: 5 [21760/110534 (20%)]\tClassification Loss: 1.7746\r\n",
      "Train Epoch: 5 [22400/110534 (20%)]\tClassification Loss: 1.8941\r\n",
      "Train Epoch: 5 [23040/110534 (21%)]\tClassification Loss: 1.6096\r\n",
      "Train Epoch: 5 [23680/110534 (21%)]\tClassification Loss: 1.6013\r\n",
      "Train Epoch: 5 [24320/110534 (22%)]\tClassification Loss: 1.3811\r\n",
      "Train Epoch: 5 [24960/110534 (23%)]\tClassification Loss: 1.3352\r\n",
      "Train Epoch: 5 [25600/110534 (23%)]\tClassification Loss: 2.0708\r\n",
      "Test() called at step_no: 7308\r\n",
      "\r\n",
      "Test set: Average loss: 1.6033, Accuracy: 1073/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 5 [26240/110534 (24%)]\tClassification Loss: 1.5887\r\n",
      "Train Epoch: 5 [26880/110534 (24%)]\tClassification Loss: 1.7372\r\n",
      "Train Epoch: 5 [27520/110534 (25%)]\tClassification Loss: 1.3534\r\n",
      "Train Epoch: 5 [28160/110534 (25%)]\tClassification Loss: 1.7155\r\n",
      "Train Epoch: 5 [28800/110534 (26%)]\tClassification Loss: 1.8584\r\n",
      "Train Epoch: 5 [29440/110534 (27%)]\tClassification Loss: 1.5115\r\n",
      "Train Epoch: 5 [30080/110534 (27%)]\tClassification Loss: 1.7333\r\n",
      "Train Epoch: 5 [30720/110534 (28%)]\tClassification Loss: 1.4017\r\n",
      "Train Epoch: 5 [31360/110534 (28%)]\tClassification Loss: 1.7816\r\n",
      "Train Epoch: 5 [32000/110534 (29%)]\tClassification Loss: 1.4606\r\n",
      "Test() called at step_no: 7408\r\n",
      "\r\n",
      "Test set: Average loss: 1.6032, Accuracy: 1072/1920 (56%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_500.pth.tar\r\n",
      "Train Epoch: 5 [32640/110534 (30%)]\tClassification Loss: 1.5873\r\n",
      "Train Epoch: 5 [33280/110534 (30%)]\tClassification Loss: 1.3801\r\n",
      "Train Epoch: 5 [33920/110534 (31%)]\tClassification Loss: 1.6134\r\n",
      "Train Epoch: 5 [34560/110534 (31%)]\tClassification Loss: 1.6582\r\n",
      "Train Epoch: 5 [35200/110534 (32%)]\tClassification Loss: 1.5349\r\n",
      "Train Epoch: 5 [35840/110534 (32%)]\tClassification Loss: 1.3718\r\n",
      "Train Epoch: 5 [36480/110534 (33%)]\tClassification Loss: 1.4009\r\n",
      "Train Epoch: 5 [37120/110534 (34%)]\tClassification Loss: 1.6273\r\n",
      "Train Epoch: 5 [37760/110534 (34%)]\tClassification Loss: 1.6077\r\n",
      "Train Epoch: 5 [38400/110534 (35%)]\tClassification Loss: 1.7164\r\n",
      "Test() called at step_no: 7508\r\n",
      "\r\n",
      "Test set: Average loss: 1.6010, Accuracy: 1079/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 5 [39040/110534 (35%)]\tClassification Loss: 1.4312\r\n",
      "Train Epoch: 5 [39680/110534 (36%)]\tClassification Loss: 1.7623\r\n",
      "Train Epoch: 5 [40320/110534 (36%)]\tClassification Loss: 1.8292\r\n",
      "Train Epoch: 5 [40960/110534 (37%)]\tClassification Loss: 1.4826\r\n",
      "Train Epoch: 5 [41600/110534 (38%)]\tClassification Loss: 1.7396\r\n",
      "Train Epoch: 5 [42240/110534 (38%)]\tClassification Loss: 1.3692\r\n",
      "Train Epoch: 5 [42880/110534 (39%)]\tClassification Loss: 1.6127\r\n",
      "Train Epoch: 5 [43520/110534 (39%)]\tClassification Loss: 1.8937\r\n",
      "Train Epoch: 5 [44160/110534 (40%)]\tClassification Loss: 1.5680\r\n",
      "Train Epoch: 5 [44800/110534 (41%)]\tClassification Loss: 1.4403\r\n",
      "Test() called at step_no: 7608\r\n",
      "\r\n",
      "Test set: Average loss: 1.5992, Accuracy: 1072/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 5 [45440/110534 (41%)]\tClassification Loss: 1.6901\r\n",
      "Train Epoch: 5 [46080/110534 (42%)]\tClassification Loss: 1.7361\r\n",
      "Train Epoch: 5 [46720/110534 (42%)]\tClassification Loss: 1.9010\r\n",
      "Train Epoch: 5 [47360/110534 (43%)]\tClassification Loss: 1.7122\r\n",
      "Train Epoch: 5 [48000/110534 (43%)]\tClassification Loss: 1.7038\r\n",
      "Train Epoch: 5 [48640/110534 (44%)]\tClassification Loss: 1.6076\r\n",
      "Train Epoch: 5 [49280/110534 (45%)]\tClassification Loss: 1.2394\r\n",
      "Train Epoch: 5 [49920/110534 (45%)]\tClassification Loss: 1.5096\r\n",
      "Train Epoch: 5 [50560/110534 (46%)]\tClassification Loss: 1.7095\r\n",
      "Train Epoch: 5 [51200/110534 (46%)]\tClassification Loss: 1.6175\r\n",
      "Test() called at step_no: 7708\r\n",
      "\r\n",
      "Test set: Average loss: 1.5979, Accuracy: 1080/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 5 [51840/110534 (47%)]\tClassification Loss: 1.3430\r\n",
      "Train Epoch: 5 [52480/110534 (47%)]\tClassification Loss: 1.4753\r\n",
      "Train Epoch: 5 [53120/110534 (48%)]\tClassification Loss: 1.6831\r\n",
      "Train Epoch: 5 [53760/110534 (49%)]\tClassification Loss: 1.5889\r\n",
      "Train Epoch: 5 [54400/110534 (49%)]\tClassification Loss: 1.8544\r\n",
      "Train Epoch: 5 [55040/110534 (50%)]\tClassification Loss: 1.3222\r\n",
      "Train Epoch: 5 [55680/110534 (50%)]\tClassification Loss: 1.8309\r\n",
      "Train Epoch: 5 [56320/110534 (51%)]\tClassification Loss: 1.5095\r\n",
      "Train Epoch: 5 [56960/110534 (52%)]\tClassification Loss: 1.6903\r\n",
      "Train Epoch: 5 [57600/110534 (52%)]\tClassification Loss: 1.7509\r\n",
      "Test() called at step_no: 7808\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "\r\n",
      "Test set: Average loss: 1.5978, Accuracy: 1086/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 5 [58240/110534 (53%)]\tClassification Loss: 1.3361\r\n",
      "Train Epoch: 5 [58880/110534 (53%)]\tClassification Loss: 1.8610\r\n",
      "Train Epoch: 5 [59520/110534 (54%)]\tClassification Loss: 1.7155\r\n",
      "Train Epoch: 5 [60160/110534 (54%)]\tClassification Loss: 1.7815\r\n",
      "Train Epoch: 5 [60800/110534 (55%)]\tClassification Loss: 2.0222\r\n",
      "Train Epoch: 5 [61440/110534 (56%)]\tClassification Loss: 1.5212\r\n",
      "Train Epoch: 5 [62080/110534 (56%)]\tClassification Loss: 2.1518\r\n",
      "Train Epoch: 5 [62720/110534 (57%)]\tClassification Loss: 1.5965\r\n",
      "Train Epoch: 5 [63360/110534 (57%)]\tClassification Loss: 1.8503\r\n",
      "Train Epoch: 5 [64000/110534 (58%)]\tClassification Loss: 1.7405\r\n",
      "Test() called at step_no: 7908\r\n",
      "\r\n",
      "Test set: Average loss: 1.5944, Accuracy: 1078/1920 (56%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_1000.pth.tar\r\n",
      "Train Epoch: 5 [64640/110534 (58%)]\tClassification Loss: 1.7824\r\n",
      "Train Epoch: 5 [65280/110534 (59%)]\tClassification Loss: 1.7522\r\n",
      "Train Epoch: 5 [65920/110534 (60%)]\tClassification Loss: 1.5073\r\n",
      "Train Epoch: 5 [66560/110534 (60%)]\tClassification Loss: 1.5566\r\n",
      "Train Epoch: 5 [67200/110534 (61%)]\tClassification Loss: 1.7844\r\n",
      "Train Epoch: 5 [67840/110534 (61%)]\tClassification Loss: 1.3759\r\n",
      "Train Epoch: 5 [68480/110534 (62%)]\tClassification Loss: 1.4105\r\n",
      "Train Epoch: 5 [69120/110534 (63%)]\tClassification Loss: 1.6053\r\n",
      "Train Epoch: 5 [69760/110534 (63%)]\tClassification Loss: 1.5433\r\n",
      "Train Epoch: 5 [70400/110534 (64%)]\tClassification Loss: 1.5444\r\n",
      "Test() called at step_no: 8008\r\n",
      "\r\n",
      "Test set: Average loss: 1.6003, Accuracy: 1078/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 5 [71040/110534 (64%)]\tClassification Loss: 1.7401\r\n",
      "Train Epoch: 5 [71680/110534 (65%)]\tClassification Loss: 1.5969\r\n",
      "Train Epoch: 5 [72320/110534 (65%)]\tClassification Loss: 1.4329\r\n",
      "Train Epoch: 5 [72960/110534 (66%)]\tClassification Loss: 1.5916\r\n",
      "Train Epoch: 5 [73600/110534 (67%)]\tClassification Loss: 1.5728\r\n",
      "Train Epoch: 5 [74240/110534 (67%)]\tClassification Loss: 1.5026\r\n",
      "Train Epoch: 5 [74880/110534 (68%)]\tClassification Loss: 1.7609\r\n",
      "Train Epoch: 5 [75520/110534 (68%)]\tClassification Loss: 1.8338\r\n",
      "Train Epoch: 5 [76160/110534 (69%)]\tClassification Loss: 1.6127\r\n",
      "Train Epoch: 5 [76800/110534 (69%)]\tClassification Loss: 1.5830\r\n",
      "Test() called at step_no: 8108\r\n",
      "\r\n",
      "Test set: Average loss: 1.5932, Accuracy: 1079/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 5 [77440/110534 (70%)]\tClassification Loss: 1.8918\r\n",
      "Train Epoch: 5 [78080/110534 (71%)]\tClassification Loss: 1.6241\r\n",
      "Train Epoch: 5 [78720/110534 (71%)]\tClassification Loss: 1.5862\r\n",
      "Train Epoch: 5 [79360/110534 (72%)]\tClassification Loss: 2.0841\r\n",
      "Train Epoch: 5 [80000/110534 (72%)]\tClassification Loss: 1.6449\r\n",
      "Train Epoch: 5 [80640/110534 (73%)]\tClassification Loss: 1.8771\r\n",
      "Train Epoch: 5 [81280/110534 (74%)]\tClassification Loss: 1.9522\r\n",
      "Train Epoch: 5 [81920/110534 (74%)]\tClassification Loss: 1.4109\r\n",
      "Train Epoch: 5 [82560/110534 (75%)]\tClassification Loss: 1.8637\r\n",
      "Train Epoch: 5 [83200/110534 (75%)]\tClassification Loss: 1.4853\r\n",
      "Test() called at step_no: 8208\r\n",
      "\r\n",
      "Test set: Average loss: 1.5934, Accuracy: 1082/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 5 [83840/110534 (76%)]\tClassification Loss: 1.8647\r\n",
      "Train Epoch: 5 [84480/110534 (76%)]\tClassification Loss: 1.6186\r\n",
      "Train Epoch: 5 [85120/110534 (77%)]\tClassification Loss: 1.7915\r\n",
      "Train Epoch: 5 [85760/110534 (78%)]\tClassification Loss: 1.8857\r\n",
      "Train Epoch: 5 [86400/110534 (78%)]\tClassification Loss: 1.8741\r\n",
      "Train Epoch: 5 [87040/110534 (79%)]\tClassification Loss: 1.4978\r\n",
      "Train Epoch: 5 [87680/110534 (79%)]\tClassification Loss: 1.4085\r\n",
      "Train Epoch: 5 [88320/110534 (80%)]\tClassification Loss: 1.6135\r\n",
      "Train Epoch: 5 [88960/110534 (80%)]\tClassification Loss: 1.3960\r\n",
      "Train Epoch: 5 [89600/110534 (81%)]\tClassification Loss: 1.6278\r\n",
      "Test() called at step_no: 8308\r\n",
      "\r\n",
      "Test set: Average loss: 1.5932, Accuracy: 1084/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 5 [90240/110534 (82%)]\tClassification Loss: 1.6107\r\n",
      "Train Epoch: 5 [90880/110534 (82%)]\tClassification Loss: 2.0443\r\n",
      "Train Epoch: 5 [91520/110534 (83%)]\tClassification Loss: 1.3788\r\n",
      "Train Epoch: 5 [92160/110534 (83%)]\tClassification Loss: 1.6886\r\n",
      "Train Epoch: 5 [92800/110534 (84%)]\tClassification Loss: 1.1899\r\n",
      "Train Epoch: 5 [93440/110534 (85%)]\tClassification Loss: 1.4547\r\n",
      "Train Epoch: 5 [94080/110534 (85%)]\tClassification Loss: 1.8158\r\n",
      "Train Epoch: 5 [94720/110534 (86%)]\tClassification Loss: 1.4594\r\n",
      "Train Epoch: 5 [95360/110534 (86%)]\tClassification Loss: 1.5154\r\n",
      "Train Epoch: 5 [96000/110534 (87%)]\tClassification Loss: 1.4021\r\n",
      "Test() called at step_no: 8408\r\n",
      "\r\n",
      "Test set: Average loss: 1.5915, Accuracy: 1080/1920 (56%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_1500.pth.tar\r\n",
      "Train Epoch: 5 [96640/110534 (87%)]\tClassification Loss: 1.7007\r\n",
      "Train Epoch: 5 [97280/110534 (88%)]\tClassification Loss: 1.4573\r\n",
      "Train Epoch: 5 [97920/110534 (89%)]\tClassification Loss: 1.6726\r\n",
      "Train Epoch: 5 [98560/110534 (89%)]\tClassification Loss: 1.7520\r\n",
      "Train Epoch: 5 [99200/110534 (90%)]\tClassification Loss: 1.5625\r\n",
      "Train Epoch: 5 [99840/110534 (90%)]\tClassification Loss: 1.6850\r\n",
      "Train Epoch: 5 [100480/110534 (91%)]\tClassification Loss: 1.7011\r\n",
      "Train Epoch: 5 [101120/110534 (91%)]\tClassification Loss: 1.6285\r\n",
      "Train Epoch: 5 [101760/110534 (92%)]\tClassification Loss: 1.5348\r\n",
      "Train Epoch: 5 [102400/110534 (93%)]\tClassification Loss: 1.6337\r\n",
      "Test() called at step_no: 8508\r\n",
      "\r\n",
      "Test set: Average loss: 1.5933, Accuracy: 1085/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 5 [103040/110534 (93%)]\tClassification Loss: 1.7683\r\n",
      "Train Epoch: 5 [103680/110534 (94%)]\tClassification Loss: 1.5693\r\n",
      "Train Epoch: 5 [104320/110534 (94%)]\tClassification Loss: 1.5761\r\n",
      "Train Epoch: 5 [104960/110534 (95%)]\tClassification Loss: 1.5753\r\n",
      "Train Epoch: 5 [105600/110534 (96%)]\tClassification Loss: 1.3715\r\n",
      "Train Epoch: 5 [106240/110534 (96%)]\tClassification Loss: 1.5032\r\n",
      "Train Epoch: 5 [106880/110534 (97%)]\tClassification Loss: 1.2764\r\n",
      "Train Epoch: 5 [107520/110534 (97%)]\tClassification Loss: 1.4654\r\n",
      "Train Epoch: 5 [108160/110534 (98%)]\tClassification Loss: 1.5597\r\n",
      "Train Epoch: 5 [108800/110534 (98%)]\tClassification Loss: 1.7139\r\n",
      "Test() called at step_no: 8608\r\n",
      "\r\n",
      "Test set: Average loss: 1.5942, Accuracy: 1082/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 5 [109440/110534 (99%)]\tClassification Loss: 1.7402\r\n",
      "Train Epoch: 5 [110080/110534 (100%)]\tClassification Loss: 1.6670\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_final.pth.tar\r\n",
      "Train Epoch: 6 [0/110534 (0%)]\tClassification Loss: 1.7949\r\n",
      "Test() called at step_no: 8635\r\n",
      "\r\n",
      "Test set: Average loss: 1.5946, Accuracy: 1078/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 6 [640/110534 (1%)]\tClassification Loss: 1.5155\r\n",
      "Train Epoch: 6 [1280/110534 (1%)]\tClassification Loss: 1.4270\r\n",
      "Train Epoch: 6 [1920/110534 (2%)]\tClassification Loss: 1.3646\r\n",
      "Train Epoch: 6 [2560/110534 (2%)]\tClassification Loss: 1.5203\r\n",
      "Train Epoch: 6 [3200/110534 (3%)]\tClassification Loss: 1.5904\r\n",
      "Train Epoch: 6 [3840/110534 (3%)]\tClassification Loss: 1.6545\r\n",
      "Train Epoch: 6 [4480/110534 (4%)]\tClassification Loss: 1.8810\r\n",
      "Train Epoch: 6 [5120/110534 (5%)]\tClassification Loss: 1.7119\r\n",
      "Train Epoch: 6 [5760/110534 (5%)]\tClassification Loss: 1.6947\r\n",
      "Train Epoch: 6 [6400/110534 (6%)]\tClassification Loss: 1.6488\r\n",
      "Test() called at step_no: 8735\r\n",
      "\r\n",
      "Test set: Average loss: 1.5860, Accuracy: 1087/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 6 [7040/110534 (6%)]\tClassification Loss: 1.8656\r\n",
      "Train Epoch: 6 [7680/110534 (7%)]\tClassification Loss: 1.4572\r\n",
      "Train Epoch: 6 [8320/110534 (8%)]\tClassification Loss: 1.7653\r\n",
      "Train Epoch: 6 [8960/110534 (8%)]\tClassification Loss: 1.6468\r\n",
      "Train Epoch: 6 [9600/110534 (9%)]\tClassification Loss: 1.7492\r\n",
      "Train Epoch: 6 [10240/110534 (9%)]\tClassification Loss: 1.7198\r\n",
      "Train Epoch: 6 [10880/110534 (10%)]\tClassification Loss: 1.7912\r\n",
      "Train Epoch: 6 [11520/110534 (10%)]\tClassification Loss: 1.9215\r\n",
      "Train Epoch: 6 [12160/110534 (11%)]\tClassification Loss: 1.9102\r\n",
      "Train Epoch: 6 [12800/110534 (12%)]\tClassification Loss: 1.8989\r\n",
      "Test() called at step_no: 8835\r\n",
      "\r\n",
      "Test set: Average loss: 1.5901, Accuracy: 1088/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 6 [13440/110534 (12%)]\tClassification Loss: 1.8225\r\n",
      "Train Epoch: 6 [14080/110534 (13%)]\tClassification Loss: 1.3461\r\n",
      "Train Epoch: 6 [14720/110534 (13%)]\tClassification Loss: 1.4693\r\n",
      "Train Epoch: 6 [15360/110534 (14%)]\tClassification Loss: 1.7347\r\n",
      "Train Epoch: 6 [16000/110534 (14%)]\tClassification Loss: 1.9359\r\n",
      "Train Epoch: 6 [16640/110534 (15%)]\tClassification Loss: 1.6581\r\n",
      "Train Epoch: 6 [17280/110534 (16%)]\tClassification Loss: 1.8054\r\n",
      "Train Epoch: 6 [17920/110534 (16%)]\tClassification Loss: 1.5293\r\n",
      "Train Epoch: 6 [18560/110534 (17%)]\tClassification Loss: 1.7957\r\n",
      "Train Epoch: 6 [19200/110534 (17%)]\tClassification Loss: 1.6809\r\n",
      "Test() called at step_no: 8935\r\n",
      "\r\n",
      "Test set: Average loss: 1.5863, Accuracy: 1087/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 6 [19840/110534 (18%)]\tClassification Loss: 1.6743\r\n",
      "Train Epoch: 6 [20480/110534 (19%)]\tClassification Loss: 1.6910\r\n",
      "Train Epoch: 6 [21120/110534 (19%)]\tClassification Loss: 1.4996\r\n",
      "Train Epoch: 6 [21760/110534 (20%)]\tClassification Loss: 1.7471\r\n",
      "Train Epoch: 6 [22400/110534 (20%)]\tClassification Loss: 1.9270\r\n",
      "Train Epoch: 6 [23040/110534 (21%)]\tClassification Loss: 1.5321\r\n",
      "Train Epoch: 6 [23680/110534 (21%)]\tClassification Loss: 1.6896\r\n",
      "Train Epoch: 6 [24320/110534 (22%)]\tClassification Loss: 1.4743\r\n",
      "Train Epoch: 6 [24960/110534 (23%)]\tClassification Loss: 1.4392\r\n",
      "Train Epoch: 6 [25600/110534 (23%)]\tClassification Loss: 1.8955\r\n",
      "Test() called at step_no: 9035\r\n",
      "\r\n",
      "Test set: Average loss: 1.5869, Accuracy: 1081/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 6 [26240/110534 (24%)]\tClassification Loss: 1.7293\r\n",
      "Train Epoch: 6 [26880/110534 (24%)]\tClassification Loss: 1.6882\r\n",
      "Train Epoch: 6 [27520/110534 (25%)]\tClassification Loss: 1.3133\r\n",
      "Train Epoch: 6 [28160/110534 (25%)]\tClassification Loss: 1.6485\r\n",
      "Train Epoch: 6 [28800/110534 (26%)]\tClassification Loss: 1.7591\r\n",
      "Train Epoch: 6 [29440/110534 (27%)]\tClassification Loss: 1.5440\r\n",
      "Train Epoch: 6 [30080/110534 (27%)]\tClassification Loss: 1.5198\r\n",
      "Train Epoch: 6 [30720/110534 (28%)]\tClassification Loss: 1.7552\r\n",
      "Train Epoch: 6 [31360/110534 (28%)]\tClassification Loss: 1.7234\r\n",
      "Train Epoch: 6 [32000/110534 (29%)]\tClassification Loss: 1.4748\r\n",
      "Test() called at step_no: 9135\r\n",
      "\r\n",
      "Test set: Average loss: 1.5883, Accuracy: 1077/1920 (56%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_500.pth.tar\r\n",
      "Train Epoch: 6 [32640/110534 (30%)]\tClassification Loss: 1.4658\r\n",
      "Train Epoch: 6 [33280/110534 (30%)]\tClassification Loss: 1.4849\r\n",
      "Train Epoch: 6 [33920/110534 (31%)]\tClassification Loss: 1.7174\r\n",
      "Train Epoch: 6 [34560/110534 (31%)]\tClassification Loss: 1.7231\r\n",
      "Train Epoch: 6 [35200/110534 (32%)]\tClassification Loss: 1.5191\r\n",
      "Train Epoch: 6 [35840/110534 (32%)]\tClassification Loss: 1.3469\r\n",
      "Train Epoch: 6 [36480/110534 (33%)]\tClassification Loss: 1.5990\r\n",
      "Train Epoch: 6 [37120/110534 (34%)]\tClassification Loss: 1.5803\r\n",
      "Train Epoch: 6 [37760/110534 (34%)]\tClassification Loss: 1.6234\r\n",
      "Train Epoch: 6 [38400/110534 (35%)]\tClassification Loss: 1.5137\r\n",
      "Test() called at step_no: 9235\r\n",
      "\r\n",
      "Test set: Average loss: 1.5850, Accuracy: 1082/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 6 [39040/110534 (35%)]\tClassification Loss: 1.3770\r\n",
      "Train Epoch: 6 [39680/110534 (36%)]\tClassification Loss: 1.6550\r\n",
      "Train Epoch: 6 [40320/110534 (36%)]\tClassification Loss: 1.7109\r\n",
      "Train Epoch: 6 [40960/110534 (37%)]\tClassification Loss: 1.5260\r\n",
      "Train Epoch: 6 [41600/110534 (38%)]\tClassification Loss: 1.6725\r\n",
      "Train Epoch: 6 [42240/110534 (38%)]\tClassification Loss: 1.4454\r\n",
      "Train Epoch: 6 [42880/110534 (39%)]\tClassification Loss: 1.5857\r\n",
      "Train Epoch: 6 [43520/110534 (39%)]\tClassification Loss: 1.6688\r\n",
      "Train Epoch: 6 [44160/110534 (40%)]\tClassification Loss: 1.4804\r\n",
      "Train Epoch: 6 [44800/110534 (41%)]\tClassification Loss: 1.3424\r\n",
      "Test() called at step_no: 9335\r\n",
      "\r\n",
      "Test set: Average loss: 1.5849, Accuracy: 1085/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 6 [45440/110534 (41%)]\tClassification Loss: 1.7749\r\n",
      "Train Epoch: 6 [46080/110534 (42%)]\tClassification Loss: 1.6620\r\n",
      "Train Epoch: 6 [46720/110534 (42%)]\tClassification Loss: 1.9218\r\n",
      "Train Epoch: 6 [47360/110534 (43%)]\tClassification Loss: 1.6951\r\n",
      "Train Epoch: 6 [48000/110534 (43%)]\tClassification Loss: 1.6991\r\n",
      "Train Epoch: 6 [48640/110534 (44%)]\tClassification Loss: 1.4770\r\n",
      "Train Epoch: 6 [49280/110534 (45%)]\tClassification Loss: 1.3373\r\n",
      "Train Epoch: 6 [49920/110534 (45%)]\tClassification Loss: 1.3090\r\n",
      "Train Epoch: 6 [50560/110534 (46%)]\tClassification Loss: 1.6606\r\n",
      "Train Epoch: 6 [51200/110534 (46%)]\tClassification Loss: 1.6053\r\n",
      "Test() called at step_no: 9435\r\n",
      "\r\n",
      "Test set: Average loss: 1.5817, Accuracy: 1094/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 6 [51840/110534 (47%)]\tClassification Loss: 1.3580\r\n",
      "Train Epoch: 6 [52480/110534 (47%)]\tClassification Loss: 1.6107\r\n",
      "Train Epoch: 6 [53120/110534 (48%)]\tClassification Loss: 1.6522\r\n",
      "Train Epoch: 6 [53760/110534 (49%)]\tClassification Loss: 1.3819\r\n",
      "Train Epoch: 6 [54400/110534 (49%)]\tClassification Loss: 1.8634\r\n",
      "Train Epoch: 6 [55040/110534 (50%)]\tClassification Loss: 1.4388\r\n",
      "Train Epoch: 6 [55680/110534 (50%)]\tClassification Loss: 1.8892\r\n",
      "Train Epoch: 6 [56320/110534 (51%)]\tClassification Loss: 1.5970\r\n",
      "Train Epoch: 6 [56960/110534 (52%)]\tClassification Loss: 1.5206\r\n",
      "Train Epoch: 6 [57600/110534 (52%)]\tClassification Loss: 1.7359\r\n",
      "Test() called at step_no: 9535\r\n",
      "\r\n",
      "Test set: Average loss: 1.5852, Accuracy: 1091/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 6 [58240/110534 (53%)]\tClassification Loss: 1.4582\r\n",
      "Train Epoch: 6 [58880/110534 (53%)]\tClassification Loss: 1.8987\r\n",
      "Train Epoch: 6 [59520/110534 (54%)]\tClassification Loss: 1.6618\r\n",
      "Train Epoch: 6 [60160/110534 (54%)]\tClassification Loss: 1.8503\r\n",
      "Train Epoch: 6 [60800/110534 (55%)]\tClassification Loss: 1.9322\r\n",
      "Train Epoch: 6 [61440/110534 (56%)]\tClassification Loss: 1.5406\r\n",
      "Train Epoch: 6 [62080/110534 (56%)]\tClassification Loss: 2.0338\r\n",
      "Train Epoch: 6 [62720/110534 (57%)]\tClassification Loss: 1.7261\r\n",
      "Train Epoch: 6 [63360/110534 (57%)]\tClassification Loss: 1.7779\r\n",
      "Train Epoch: 6 [64000/110534 (58%)]\tClassification Loss: 1.6990\r\n",
      "Test() called at step_no: 9635\r\n",
      "\r\n",
      "Test set: Average loss: 1.5797, Accuracy: 1097/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_1000.pth.tar\r\n",
      "Train Epoch: 6 [64640/110534 (58%)]\tClassification Loss: 1.6643\r\n",
      "Train Epoch: 6 [65280/110534 (59%)]\tClassification Loss: 1.6112\r\n",
      "Train Epoch: 6 [65920/110534 (60%)]\tClassification Loss: 1.4573\r\n",
      "Train Epoch: 6 [66560/110534 (60%)]\tClassification Loss: 1.6611\r\n",
      "Train Epoch: 6 [67200/110534 (61%)]\tClassification Loss: 1.7299\r\n",
      "Train Epoch: 6 [67840/110534 (61%)]\tClassification Loss: 1.3405\r\n",
      "Train Epoch: 6 [68480/110534 (62%)]\tClassification Loss: 1.4912\r\n",
      "Train Epoch: 6 [69120/110534 (63%)]\tClassification Loss: 1.4500\r\n",
      "Train Epoch: 6 [69760/110534 (63%)]\tClassification Loss: 1.6555\r\n",
      "Train Epoch: 6 [70400/110534 (64%)]\tClassification Loss: 1.6941\r\n",
      "Test() called at step_no: 9735\r\n",
      "\r\n",
      "Test set: Average loss: 1.5855, Accuracy: 1083/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 6 [71040/110534 (64%)]\tClassification Loss: 1.5862\r\n",
      "Train Epoch: 6 [71680/110534 (65%)]\tClassification Loss: 1.5733\r\n",
      "Train Epoch: 6 [72320/110534 (65%)]\tClassification Loss: 1.5170\r\n",
      "Train Epoch: 6 [72960/110534 (66%)]\tClassification Loss: 1.5262\r\n",
      "Train Epoch: 6 [73600/110534 (67%)]\tClassification Loss: 1.5795\r\n",
      "Train Epoch: 6 [74240/110534 (67%)]\tClassification Loss: 1.5468\r\n",
      "Train Epoch: 6 [74880/110534 (68%)]\tClassification Loss: 1.4790\r\n",
      "Train Epoch: 6 [75520/110534 (68%)]\tClassification Loss: 1.6267\r\n",
      "Train Epoch: 6 [76160/110534 (69%)]\tClassification Loss: 1.5583\r\n",
      "Train Epoch: 6 [76800/110534 (69%)]\tClassification Loss: 1.4730\r\n",
      "Test() called at step_no: 9835\r\n",
      "\r\n",
      "Test set: Average loss: 1.5790, Accuracy: 1091/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 6 [77440/110534 (70%)]\tClassification Loss: 1.8423\r\n",
      "Train Epoch: 6 [78080/110534 (71%)]\tClassification Loss: 1.5995\r\n",
      "Train Epoch: 6 [78720/110534 (71%)]\tClassification Loss: 1.5152\r\n",
      "Train Epoch: 6 [79360/110534 (72%)]\tClassification Loss: 2.0021\r\n",
      "Train Epoch: 6 [80000/110534 (72%)]\tClassification Loss: 1.5663\r\n",
      "Train Epoch: 6 [80640/110534 (73%)]\tClassification Loss: 1.7837\r\n",
      "Train Epoch: 6 [81280/110534 (74%)]\tClassification Loss: 1.9587\r\n",
      "Train Epoch: 6 [81920/110534 (74%)]\tClassification Loss: 1.2947\r\n",
      "Train Epoch: 6 [82560/110534 (75%)]\tClassification Loss: 1.9018\r\n",
      "Train Epoch: 6 [83200/110534 (75%)]\tClassification Loss: 1.3776\r\n",
      "Test() called at step_no: 9935\r\n",
      "\r\n",
      "Test set: Average loss: 1.5790, Accuracy: 1091/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 6 [83840/110534 (76%)]\tClassification Loss: 1.9239\r\n",
      "Train Epoch: 6 [84480/110534 (76%)]\tClassification Loss: 1.6224\r\n",
      "Train Epoch: 6 [85120/110534 (77%)]\tClassification Loss: 1.7603\r\n",
      "Train Epoch: 6 [85760/110534 (78%)]\tClassification Loss: 2.0067\r\n",
      "Train Epoch: 6 [86400/110534 (78%)]\tClassification Loss: 1.8261\r\n",
      "Train Epoch: 6 [87040/110534 (79%)]\tClassification Loss: 1.6476\r\n",
      "Train Epoch: 6 [87680/110534 (79%)]\tClassification Loss: 1.6018\r\n",
      "Train Epoch: 6 [88320/110534 (80%)]\tClassification Loss: 1.5502\r\n",
      "Train Epoch: 6 [88960/110534 (80%)]\tClassification Loss: 1.3755\r\n",
      "Train Epoch: 6 [89600/110534 (81%)]\tClassification Loss: 1.6379\r\n",
      "Test() called at step_no: 10035\r\n",
      "\r\n",
      "Test set: Average loss: 1.5807, Accuracy: 1087/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 6 [90240/110534 (82%)]\tClassification Loss: 1.6920\r\n",
      "Train Epoch: 6 [90880/110534 (82%)]\tClassification Loss: 2.0048\r\n",
      "Train Epoch: 6 [91520/110534 (83%)]\tClassification Loss: 1.4369\r\n",
      "Train Epoch: 6 [92160/110534 (83%)]\tClassification Loss: 1.5559\r\n",
      "Train Epoch: 6 [92800/110534 (84%)]\tClassification Loss: 1.2736\r\n",
      "Train Epoch: 6 [93440/110534 (85%)]\tClassification Loss: 1.3062\r\n",
      "Train Epoch: 6 [94080/110534 (85%)]\tClassification Loss: 1.8332\r\n",
      "Train Epoch: 6 [94720/110534 (86%)]\tClassification Loss: 1.4193\r\n",
      "Train Epoch: 6 [95360/110534 (86%)]\tClassification Loss: 1.5166\r\n",
      "Train Epoch: 6 [96000/110534 (87%)]\tClassification Loss: 1.3853\r\n",
      "Test() called at step_no: 10135\r\n",
      "\r\n",
      "Test set: Average loss: 1.5782, Accuracy: 1085/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_1500.pth.tar\r\n",
      "Train Epoch: 6 [96640/110534 (87%)]\tClassification Loss: 1.6832\r\n",
      "Train Epoch: 6 [97280/110534 (88%)]\tClassification Loss: 1.5145\r\n",
      "Train Epoch: 6 [97920/110534 (89%)]\tClassification Loss: 1.7501\r\n",
      "Train Epoch: 6 [98560/110534 (89%)]\tClassification Loss: 1.8174\r\n",
      "Train Epoch: 6 [99200/110534 (90%)]\tClassification Loss: 1.5267\r\n",
      "Train Epoch: 6 [99840/110534 (90%)]\tClassification Loss: 1.5524\r\n",
      "Train Epoch: 6 [100480/110534 (91%)]\tClassification Loss: 1.7670\r\n",
      "Train Epoch: 6 [101120/110534 (91%)]\tClassification Loss: 1.6086\r\n",
      "Train Epoch: 6 [101760/110534 (92%)]\tClassification Loss: 1.5686\r\n",
      "Train Epoch: 6 [102400/110534 (93%)]\tClassification Loss: 1.6725\r\n",
      "Test() called at step_no: 10235\r\n",
      "\r\n",
      "Test set: Average loss: 1.5785, Accuracy: 1096/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 6 [103040/110534 (93%)]\tClassification Loss: 1.5955\r\n",
      "Train Epoch: 6 [103680/110534 (94%)]\tClassification Loss: 1.4569\r\n",
      "Train Epoch: 6 [104320/110534 (94%)]\tClassification Loss: 1.3809\r\n",
      "Train Epoch: 6 [104960/110534 (95%)]\tClassification Loss: 1.6516\r\n",
      "Train Epoch: 6 [105600/110534 (96%)]\tClassification Loss: 1.5595\r\n",
      "Train Epoch: 6 [106240/110534 (96%)]\tClassification Loss: 1.4975\r\n",
      "Train Epoch: 6 [106880/110534 (97%)]\tClassification Loss: 1.2319\r\n",
      "Train Epoch: 6 [107520/110534 (97%)]\tClassification Loss: 1.8033\r\n",
      "Train Epoch: 6 [108160/110534 (98%)]\tClassification Loss: 1.5589\r\n",
      "Train Epoch: 6 [108800/110534 (98%)]\tClassification Loss: 1.7616\r\n",
      "Test() called at step_no: 10335\r\n",
      "\r\n",
      "Test set: Average loss: 1.5810, Accuracy: 1088/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 6 [109440/110534 (99%)]\tClassification Loss: 1.5311\r\n",
      "Train Epoch: 6 [110080/110534 (100%)]\tClassification Loss: 1.5664\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_final.pth.tar\r\n",
      "Train Epoch: 7 [0/110534 (0%)]\tClassification Loss: 1.7246\r\n",
      "Test() called at step_no: 10362\r\n",
      "\r\n",
      "Test set: Average loss: 1.5808, Accuracy: 1085/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [640/110534 (1%)]\tClassification Loss: 1.6124\r\n",
      "Train Epoch: 7 [1280/110534 (1%)]\tClassification Loss: 1.7114\r\n",
      "Train Epoch: 7 [1920/110534 (2%)]\tClassification Loss: 1.4798\r\n",
      "Train Epoch: 7 [2560/110534 (2%)]\tClassification Loss: 1.4690\r\n",
      "Train Epoch: 7 [3200/110534 (3%)]\tClassification Loss: 1.5633\r\n",
      "Train Epoch: 7 [3840/110534 (3%)]\tClassification Loss: 1.6195\r\n",
      "Train Epoch: 7 [4480/110534 (4%)]\tClassification Loss: 1.8240\r\n",
      "Train Epoch: 7 [5120/110534 (5%)]\tClassification Loss: 1.6746\r\n",
      "Train Epoch: 7 [5760/110534 (5%)]\tClassification Loss: 1.5834\r\n",
      "Train Epoch: 7 [6400/110534 (6%)]\tClassification Loss: 1.6532\r\n",
      "Test() called at step_no: 10462\r\n",
      "\r\n",
      "Test set: Average loss: 1.5745, Accuracy: 1096/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [7040/110534 (6%)]\tClassification Loss: 1.8090\r\n",
      "Train Epoch: 7 [7680/110534 (7%)]\tClassification Loss: 1.4927\r\n",
      "Train Epoch: 7 [8320/110534 (8%)]\tClassification Loss: 1.6569\r\n",
      "Train Epoch: 7 [8960/110534 (8%)]\tClassification Loss: 1.7118\r\n",
      "Train Epoch: 7 [9600/110534 (9%)]\tClassification Loss: 1.7145\r\n",
      "Train Epoch: 7 [10240/110534 (9%)]\tClassification Loss: 1.7929\r\n",
      "Train Epoch: 7 [10880/110534 (10%)]\tClassification Loss: 1.8036\r\n",
      "Train Epoch: 7 [11520/110534 (10%)]\tClassification Loss: 1.9652\r\n",
      "Train Epoch: 7 [12160/110534 (11%)]\tClassification Loss: 1.9137\r\n",
      "Train Epoch: 7 [12800/110534 (12%)]\tClassification Loss: 1.9612\r\n",
      "Test() called at step_no: 10562\r\n",
      "\r\n",
      "Test set: Average loss: 1.5779, Accuracy: 1095/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [13440/110534 (12%)]\tClassification Loss: 1.6632\r\n",
      "Train Epoch: 7 [14080/110534 (13%)]\tClassification Loss: 1.4816\r\n",
      "Train Epoch: 7 [14720/110534 (13%)]\tClassification Loss: 1.6423\r\n",
      "Train Epoch: 7 [15360/110534 (14%)]\tClassification Loss: 1.6229\r\n",
      "Train Epoch: 7 [16000/110534 (14%)]\tClassification Loss: 2.0606\r\n",
      "Train Epoch: 7 [16640/110534 (15%)]\tClassification Loss: 1.6324\r\n",
      "Train Epoch: 7 [17280/110534 (16%)]\tClassification Loss: 1.6380\r\n",
      "Train Epoch: 7 [17920/110534 (16%)]\tClassification Loss: 1.6692\r\n",
      "Train Epoch: 7 [18560/110534 (17%)]\tClassification Loss: 1.7647\r\n",
      "Train Epoch: 7 [19200/110534 (17%)]\tClassification Loss: 1.6927\r\n",
      "Test() called at step_no: 10662\r\n",
      "\r\n",
      "Test set: Average loss: 1.5747, Accuracy: 1098/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [19840/110534 (18%)]\tClassification Loss: 1.4791\r\n",
      "Train Epoch: 7 [20480/110534 (19%)]\tClassification Loss: 1.6427\r\n",
      "Train Epoch: 7 [21120/110534 (19%)]\tClassification Loss: 1.5858\r\n",
      "Train Epoch: 7 [21760/110534 (20%)]\tClassification Loss: 1.6028\r\n",
      "Train Epoch: 7 [22400/110534 (20%)]\tClassification Loss: 1.8672\r\n",
      "Train Epoch: 7 [23040/110534 (21%)]\tClassification Loss: 1.4920\r\n",
      "Train Epoch: 7 [23680/110534 (21%)]\tClassification Loss: 1.5965\r\n",
      "Train Epoch: 7 [24320/110534 (22%)]\tClassification Loss: 1.4278\r\n",
      "Train Epoch: 7 [24960/110534 (23%)]\tClassification Loss: 1.4345\r\n",
      "Train Epoch: 7 [25600/110534 (23%)]\tClassification Loss: 1.9732\r\n",
      "Test() called at step_no: 10762\r\n",
      "\r\n",
      "Test set: Average loss: 1.5750, Accuracy: 1096/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [26240/110534 (24%)]\tClassification Loss: 1.6073\r\n",
      "Train Epoch: 7 [26880/110534 (24%)]\tClassification Loss: 1.5999\r\n",
      "Train Epoch: 7 [27520/110534 (25%)]\tClassification Loss: 1.2750\r\n",
      "Train Epoch: 7 [28160/110534 (25%)]\tClassification Loss: 1.5859\r\n",
      "Train Epoch: 7 [28800/110534 (26%)]\tClassification Loss: 1.8283\r\n",
      "Train Epoch: 7 [29440/110534 (27%)]\tClassification Loss: 1.5025\r\n",
      "Train Epoch: 7 [30080/110534 (27%)]\tClassification Loss: 1.8279\r\n",
      "Train Epoch: 7 [30720/110534 (28%)]\tClassification Loss: 1.6060\r\n",
      "Train Epoch: 7 [31360/110534 (28%)]\tClassification Loss: 1.6941\r\n",
      "Train Epoch: 7 [32000/110534 (29%)]\tClassification Loss: 1.4549\r\n",
      "Test() called at step_no: 10862\r\n",
      "\r\n",
      "Test set: Average loss: 1.5747, Accuracy: 1095/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_500.pth.tar\r\n",
      "Train Epoch: 7 [32640/110534 (30%)]\tClassification Loss: 1.5300\r\n",
      "Train Epoch: 7 [33280/110534 (30%)]\tClassification Loss: 1.3199\r\n",
      "Train Epoch: 7 [33920/110534 (31%)]\tClassification Loss: 1.7655\r\n",
      "Train Epoch: 7 [34560/110534 (31%)]\tClassification Loss: 1.7229\r\n",
      "Train Epoch: 7 [35200/110534 (32%)]\tClassification Loss: 1.5428\r\n",
      "Train Epoch: 7 [35840/110534 (32%)]\tClassification Loss: 1.3366\r\n",
      "Train Epoch: 7 [36480/110534 (33%)]\tClassification Loss: 1.5730\r\n",
      "Train Epoch: 7 [37120/110534 (34%)]\tClassification Loss: 1.5242\r\n",
      "Train Epoch: 7 [37760/110534 (34%)]\tClassification Loss: 1.7750\r\n",
      "Train Epoch: 7 [38400/110534 (35%)]\tClassification Loss: 1.6359\r\n",
      "Test() called at step_no: 10962\r\n",
      "\r\n",
      "Test set: Average loss: 1.5734, Accuracy: 1091/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [39040/110534 (35%)]\tClassification Loss: 1.2936\r\n",
      "Train Epoch: 7 [39680/110534 (36%)]\tClassification Loss: 1.7802\r\n",
      "Train Epoch: 7 [40320/110534 (36%)]\tClassification Loss: 1.7241\r\n",
      "Train Epoch: 7 [40960/110534 (37%)]\tClassification Loss: 1.4221\r\n",
      "Train Epoch: 7 [41600/110534 (38%)]\tClassification Loss: 1.6078\r\n",
      "Train Epoch: 7 [42240/110534 (38%)]\tClassification Loss: 1.5727\r\n",
      "Train Epoch: 7 [42880/110534 (39%)]\tClassification Loss: 1.6075\r\n",
      "Train Epoch: 7 [43520/110534 (39%)]\tClassification Loss: 1.5883\r\n",
      "Train Epoch: 7 [44160/110534 (40%)]\tClassification Loss: 1.5664\r\n",
      "Train Epoch: 7 [44800/110534 (41%)]\tClassification Loss: 1.3666\r\n",
      "Test() called at step_no: 11062\r\n",
      "\r\n",
      "Test set: Average loss: 1.5739, Accuracy: 1094/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [45440/110534 (41%)]\tClassification Loss: 1.7552\r\n",
      "Train Epoch: 7 [46080/110534 (42%)]\tClassification Loss: 1.6913\r\n",
      "Train Epoch: 7 [46720/110534 (42%)]\tClassification Loss: 1.9497\r\n",
      "Train Epoch: 7 [47360/110534 (43%)]\tClassification Loss: 1.7052\r\n",
      "Train Epoch: 7 [48000/110534 (43%)]\tClassification Loss: 1.7174\r\n",
      "Train Epoch: 7 [48640/110534 (44%)]\tClassification Loss: 1.6311\r\n",
      "Train Epoch: 7 [49280/110534 (45%)]\tClassification Loss: 1.3809\r\n",
      "Train Epoch: 7 [49920/110534 (45%)]\tClassification Loss: 1.2196\r\n",
      "Train Epoch: 7 [50560/110534 (46%)]\tClassification Loss: 1.7362\r\n",
      "Train Epoch: 7 [51200/110534 (46%)]\tClassification Loss: 1.5739\r\n",
      "Test() called at step_no: 11162\r\n",
      "\r\n",
      "Test set: Average loss: 1.5731, Accuracy: 1093/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [51840/110534 (47%)]\tClassification Loss: 1.3527\r\n",
      "Train Epoch: 7 [52480/110534 (47%)]\tClassification Loss: 1.5070\r\n",
      "Train Epoch: 7 [53120/110534 (48%)]\tClassification Loss: 1.6376\r\n",
      "Train Epoch: 7 [53760/110534 (49%)]\tClassification Loss: 1.6026\r\n",
      "Train Epoch: 7 [54400/110534 (49%)]\tClassification Loss: 1.8512\r\n",
      "Train Epoch: 7 [55040/110534 (50%)]\tClassification Loss: 1.4349\r\n",
      "Train Epoch: 7 [55680/110534 (50%)]\tClassification Loss: 1.7370\r\n",
      "Train Epoch: 7 [56320/110534 (51%)]\tClassification Loss: 1.4420\r\n",
      "Train Epoch: 7 [56960/110534 (52%)]\tClassification Loss: 1.6031\r\n",
      "Train Epoch: 7 [57600/110534 (52%)]\tClassification Loss: 1.7231\r\n",
      "Test() called at step_no: 11262\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\r\n",
      "    self._send(header + buf)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 368, in _send\r\n",
      "    n = write(self._handle, buf)\r\n",
      "BrokenPipeError: [Errno 32] Broken pipe\r\n",
      "\r\n",
      "Test set: Average loss: 1.5730, Accuracy: 1092/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [58240/110534 (53%)]\tClassification Loss: 1.4523\r\n",
      "Train Epoch: 7 [58880/110534 (53%)]\tClassification Loss: 1.8338\r\n",
      "Train Epoch: 7 [59520/110534 (54%)]\tClassification Loss: 1.7392\r\n",
      "Train Epoch: 7 [60160/110534 (54%)]\tClassification Loss: 1.8247\r\n",
      "Train Epoch: 7 [60800/110534 (55%)]\tClassification Loss: 1.9024\r\n",
      "Train Epoch: 7 [61440/110534 (56%)]\tClassification Loss: 1.6193\r\n",
      "Train Epoch: 7 [62080/110534 (56%)]\tClassification Loss: 2.0708\r\n",
      "Train Epoch: 7 [62720/110534 (57%)]\tClassification Loss: 1.5067\r\n",
      "Train Epoch: 7 [63360/110534 (57%)]\tClassification Loss: 1.7674\r\n",
      "Train Epoch: 7 [64000/110534 (58%)]\tClassification Loss: 1.5958\r\n",
      "Test() called at step_no: 11362\r\n",
      "\r\n",
      "Test set: Average loss: 1.5701, Accuracy: 1090/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_1000.pth.tar\r\n",
      "Train Epoch: 7 [64640/110534 (58%)]\tClassification Loss: 1.6101\r\n",
      "Train Epoch: 7 [65280/110534 (59%)]\tClassification Loss: 1.6324\r\n",
      "Train Epoch: 7 [65920/110534 (60%)]\tClassification Loss: 1.5042\r\n",
      "Train Epoch: 7 [66560/110534 (60%)]\tClassification Loss: 1.6265\r\n",
      "Train Epoch: 7 [67200/110534 (61%)]\tClassification Loss: 1.6909\r\n",
      "Train Epoch: 7 [67840/110534 (61%)]\tClassification Loss: 1.3502\r\n",
      "Train Epoch: 7 [68480/110534 (62%)]\tClassification Loss: 1.3618\r\n",
      "Train Epoch: 7 [69120/110534 (63%)]\tClassification Loss: 1.6537\r\n",
      "Train Epoch: 7 [69760/110534 (63%)]\tClassification Loss: 1.5166\r\n",
      "Train Epoch: 7 [70400/110534 (64%)]\tClassification Loss: 1.6849\r\n",
      "Test() called at step_no: 11462\r\n",
      "\r\n",
      "Test set: Average loss: 1.5740, Accuracy: 1083/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 7 [71040/110534 (64%)]\tClassification Loss: 1.7559\r\n",
      "Train Epoch: 7 [71680/110534 (65%)]\tClassification Loss: 1.5905\r\n",
      "Train Epoch: 7 [72320/110534 (65%)]\tClassification Loss: 1.5793\r\n",
      "Train Epoch: 7 [72960/110534 (66%)]\tClassification Loss: 1.5233\r\n",
      "Train Epoch: 7 [73600/110534 (67%)]\tClassification Loss: 1.6223\r\n",
      "Train Epoch: 7 [74240/110534 (67%)]\tClassification Loss: 1.4545\r\n",
      "Train Epoch: 7 [74880/110534 (68%)]\tClassification Loss: 1.5426\r\n",
      "Train Epoch: 7 [75520/110534 (68%)]\tClassification Loss: 1.5609\r\n",
      "Train Epoch: 7 [76160/110534 (69%)]\tClassification Loss: 1.5132\r\n",
      "Train Epoch: 7 [76800/110534 (69%)]\tClassification Loss: 1.4411\r\n",
      "Test() called at step_no: 11562\r\n",
      "\r\n",
      "Test set: Average loss: 1.5690, Accuracy: 1097/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [77440/110534 (70%)]\tClassification Loss: 1.8095\r\n",
      "Train Epoch: 7 [78080/110534 (71%)]\tClassification Loss: 1.7892\r\n",
      "Train Epoch: 7 [78720/110534 (71%)]\tClassification Loss: 1.6844\r\n",
      "Train Epoch: 7 [79360/110534 (72%)]\tClassification Loss: 1.9834\r\n",
      "Train Epoch: 7 [80000/110534 (72%)]\tClassification Loss: 1.5620\r\n",
      "Train Epoch: 7 [80640/110534 (73%)]\tClassification Loss: 1.6954\r\n",
      "Train Epoch: 7 [81280/110534 (74%)]\tClassification Loss: 1.9714\r\n",
      "Train Epoch: 7 [81920/110534 (74%)]\tClassification Loss: 1.2768\r\n",
      "Train Epoch: 7 [82560/110534 (75%)]\tClassification Loss: 1.8244\r\n",
      "Train Epoch: 7 [83200/110534 (75%)]\tClassification Loss: 1.5845\r\n",
      "Test() called at step_no: 11662\r\n",
      "\r\n",
      "Test set: Average loss: 1.5692, Accuracy: 1099/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [83840/110534 (76%)]\tClassification Loss: 1.7906\r\n",
      "Train Epoch: 7 [84480/110534 (76%)]\tClassification Loss: 1.6285\r\n",
      "Train Epoch: 7 [85120/110534 (77%)]\tClassification Loss: 1.7892\r\n",
      "Train Epoch: 7 [85760/110534 (78%)]\tClassification Loss: 1.9608\r\n",
      "Train Epoch: 7 [86400/110534 (78%)]\tClassification Loss: 1.7096\r\n",
      "Train Epoch: 7 [87040/110534 (79%)]\tClassification Loss: 1.3358\r\n",
      "Train Epoch: 7 [87680/110534 (79%)]\tClassification Loss: 1.3170\r\n",
      "Train Epoch: 7 [88320/110534 (80%)]\tClassification Loss: 1.5954\r\n",
      "Train Epoch: 7 [88960/110534 (80%)]\tClassification Loss: 1.3639\r\n",
      "Train Epoch: 7 [89600/110534 (81%)]\tClassification Loss: 1.4152\r\n",
      "Test() called at step_no: 11762\r\n",
      "\r\n",
      "Test set: Average loss: 1.5702, Accuracy: 1096/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [90240/110534 (82%)]\tClassification Loss: 1.5602\r\n",
      "Train Epoch: 7 [90880/110534 (82%)]\tClassification Loss: 1.9534\r\n",
      "Train Epoch: 7 [91520/110534 (83%)]\tClassification Loss: 1.4019\r\n",
      "Train Epoch: 7 [92160/110534 (83%)]\tClassification Loss: 1.6315\r\n",
      "Train Epoch: 7 [92800/110534 (84%)]\tClassification Loss: 1.3493\r\n",
      "Train Epoch: 7 [93440/110534 (85%)]\tClassification Loss: 1.3304\r\n",
      "Train Epoch: 7 [94080/110534 (85%)]\tClassification Loss: 1.6247\r\n",
      "Train Epoch: 7 [94720/110534 (86%)]\tClassification Loss: 1.3312\r\n",
      "Train Epoch: 7 [95360/110534 (86%)]\tClassification Loss: 1.5384\r\n",
      "Train Epoch: 7 [96000/110534 (87%)]\tClassification Loss: 1.1812\r\n",
      "Test() called at step_no: 11862\r\n",
      "\r\n",
      "Test set: Average loss: 1.5680, Accuracy: 1087/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_1500.pth.tar\r\n",
      "Train Epoch: 7 [96640/110534 (87%)]\tClassification Loss: 1.6748\r\n",
      "Train Epoch: 7 [97280/110534 (88%)]\tClassification Loss: 1.4148\r\n",
      "Train Epoch: 7 [97920/110534 (89%)]\tClassification Loss: 1.7038\r\n",
      "Train Epoch: 7 [98560/110534 (89%)]\tClassification Loss: 1.7349\r\n",
      "Train Epoch: 7 [99200/110534 (90%)]\tClassification Loss: 1.6237\r\n",
      "Train Epoch: 7 [99840/110534 (90%)]\tClassification Loss: 1.6425\r\n",
      "Train Epoch: 7 [100480/110534 (91%)]\tClassification Loss: 1.7035\r\n",
      "Train Epoch: 7 [101120/110534 (91%)]\tClassification Loss: 1.5761\r\n",
      "Train Epoch: 7 [101760/110534 (92%)]\tClassification Loss: 1.5480\r\n",
      "Train Epoch: 7 [102400/110534 (93%)]\tClassification Loss: 1.6700\r\n",
      "Test() called at step_no: 11962\r\n",
      "\r\n",
      "Test set: Average loss: 1.5741, Accuracy: 1096/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [103040/110534 (93%)]\tClassification Loss: 1.8258\r\n",
      "Train Epoch: 7 [103680/110534 (94%)]\tClassification Loss: 1.3578\r\n",
      "Train Epoch: 7 [104320/110534 (94%)]\tClassification Loss: 1.3920\r\n",
      "Train Epoch: 7 [104960/110534 (95%)]\tClassification Loss: 1.4312\r\n",
      "Train Epoch: 7 [105600/110534 (96%)]\tClassification Loss: 1.4413\r\n",
      "Train Epoch: 7 [106240/110534 (96%)]\tClassification Loss: 1.5702\r\n",
      "Train Epoch: 7 [106880/110534 (97%)]\tClassification Loss: 1.2811\r\n",
      "Train Epoch: 7 [107520/110534 (97%)]\tClassification Loss: 1.5726\r\n",
      "Train Epoch: 7 [108160/110534 (98%)]\tClassification Loss: 1.4562\r\n",
      "Train Epoch: 7 [108800/110534 (98%)]\tClassification Loss: 1.7200\r\n",
      "Test() called at step_no: 12062\r\n",
      "\r\n",
      "Test set: Average loss: 1.5722, Accuracy: 1090/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 7 [109440/110534 (99%)]\tClassification Loss: 1.6064\r\n",
      "Train Epoch: 7 [110080/110534 (100%)]\tClassification Loss: 1.6654\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_final.pth.tar\r\n",
      "Train Epoch: 8 [0/110534 (0%)]\tClassification Loss: 1.6108\r\n",
      "Test() called at step_no: 12089\r\n",
      "\r\n",
      "Test set: Average loss: 1.5765, Accuracy: 1097/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 8 [640/110534 (1%)]\tClassification Loss: 1.6249\r\n",
      "Train Epoch: 8 [1280/110534 (1%)]\tClassification Loss: 1.4976\r\n",
      "Train Epoch: 8 [1920/110534 (2%)]\tClassification Loss: 1.5674\r\n",
      "Train Epoch: 8 [2560/110534 (2%)]\tClassification Loss: 1.4505\r\n",
      "Train Epoch: 8 [3200/110534 (3%)]\tClassification Loss: 1.4751\r\n",
      "Train Epoch: 8 [3840/110534 (3%)]\tClassification Loss: 1.6334\r\n",
      "Train Epoch: 8 [4480/110534 (4%)]\tClassification Loss: 1.9187\r\n",
      "Train Epoch: 8 [5120/110534 (5%)]\tClassification Loss: 1.5396\r\n",
      "Train Epoch: 8 [5760/110534 (5%)]\tClassification Loss: 1.5564\r\n",
      "Train Epoch: 8 [6400/110534 (6%)]\tClassification Loss: 1.6778\r\n",
      "Test() called at step_no: 12189\r\n",
      "\r\n",
      "Test set: Average loss: 1.5673, Accuracy: 1098/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 8 [7040/110534 (6%)]\tClassification Loss: 1.7709\r\n",
      "Train Epoch: 8 [7680/110534 (7%)]\tClassification Loss: 1.6047\r\n",
      "Train Epoch: 8 [8320/110534 (8%)]\tClassification Loss: 1.6467\r\n",
      "Train Epoch: 8 [8960/110534 (8%)]\tClassification Loss: 1.8276\r\n",
      "Train Epoch: 8 [9600/110534 (9%)]\tClassification Loss: 1.5163\r\n",
      "Train Epoch: 8 [10240/110534 (9%)]\tClassification Loss: 1.6500\r\n",
      "Train Epoch: 8 [10880/110534 (10%)]\tClassification Loss: 1.6466\r\n",
      "Train Epoch: 8 [11520/110534 (10%)]\tClassification Loss: 1.8740\r\n",
      "Train Epoch: 8 [12160/110534 (11%)]\tClassification Loss: 1.7449\r\n",
      "Train Epoch: 8 [12800/110534 (12%)]\tClassification Loss: 1.8515\r\n",
      "Test() called at step_no: 12289\r\n",
      "\r\n",
      "Test set: Average loss: 1.5733, Accuracy: 1084/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 8 [13440/110534 (12%)]\tClassification Loss: 1.8338\r\n",
      "Train Epoch: 8 [14080/110534 (13%)]\tClassification Loss: 1.5334\r\n",
      "Train Epoch: 8 [14720/110534 (13%)]\tClassification Loss: 1.4930\r\n",
      "Train Epoch: 8 [15360/110534 (14%)]\tClassification Loss: 1.5989\r\n",
      "Train Epoch: 8 [16000/110534 (14%)]\tClassification Loss: 1.9052\r\n",
      "Train Epoch: 8 [16640/110534 (15%)]\tClassification Loss: 1.6542\r\n",
      "Train Epoch: 8 [17280/110534 (16%)]\tClassification Loss: 1.6758\r\n",
      "Train Epoch: 8 [17920/110534 (16%)]\tClassification Loss: 1.4898\r\n",
      "Train Epoch: 8 [18560/110534 (17%)]\tClassification Loss: 1.8914\r\n",
      "Train Epoch: 8 [19200/110534 (17%)]\tClassification Loss: 1.6372\r\n",
      "Test() called at step_no: 12389\r\n",
      "\r\n",
      "Test set: Average loss: 1.5676, Accuracy: 1090/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 8 [19840/110534 (18%)]\tClassification Loss: 1.6330\r\n",
      "Train Epoch: 8 [20480/110534 (19%)]\tClassification Loss: 1.6058\r\n",
      "Train Epoch: 8 [21120/110534 (19%)]\tClassification Loss: 1.4996\r\n",
      "Train Epoch: 8 [21760/110534 (20%)]\tClassification Loss: 1.7465\r\n",
      "Train Epoch: 8 [22400/110534 (20%)]\tClassification Loss: 1.9017\r\n",
      "Train Epoch: 8 [23040/110534 (21%)]\tClassification Loss: 1.5722\r\n",
      "Train Epoch: 8 [23680/110534 (21%)]\tClassification Loss: 1.7593\r\n",
      "Train Epoch: 8 [24320/110534 (22%)]\tClassification Loss: 1.3563\r\n",
      "Train Epoch: 8 [24960/110534 (23%)]\tClassification Loss: 1.3808\r\n",
      "Train Epoch: 8 [25600/110534 (23%)]\tClassification Loss: 1.9397\r\n",
      "Test() called at step_no: 12489\r\n",
      "\r\n",
      "Test set: Average loss: 1.5692, Accuracy: 1088/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 8 [26240/110534 (24%)]\tClassification Loss: 1.5688\r\n",
      "Train Epoch: 8 [26880/110534 (24%)]\tClassification Loss: 1.6303\r\n",
      "Train Epoch: 8 [27520/110534 (25%)]\tClassification Loss: 1.3863\r\n",
      "Train Epoch: 8 [28160/110534 (25%)]\tClassification Loss: 1.5602\r\n",
      "Train Epoch: 8 [28800/110534 (26%)]\tClassification Loss: 1.6765\r\n",
      "Train Epoch: 8 [29440/110534 (27%)]\tClassification Loss: 1.4750\r\n",
      "Train Epoch: 8 [30080/110534 (27%)]\tClassification Loss: 1.8450\r\n",
      "Train Epoch: 8 [30720/110534 (28%)]\tClassification Loss: 1.6065\r\n",
      "Train Epoch: 8 [31360/110534 (28%)]\tClassification Loss: 1.7072\r\n",
      "Train Epoch: 8 [32000/110534 (29%)]\tClassification Loss: 1.6423\r\n",
      "Test() called at step_no: 12589\r\n",
      "\r\n",
      "Test set: Average loss: 1.5684, Accuracy: 1097/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_500.pth.tar\r\n",
      "Train Epoch: 8 [32640/110534 (30%)]\tClassification Loss: 1.5165\r\n",
      "Train Epoch: 8 [33280/110534 (30%)]\tClassification Loss: 1.3563\r\n",
      "Train Epoch: 8 [33920/110534 (31%)]\tClassification Loss: 1.7530\r\n",
      "Train Epoch: 8 [34560/110534 (31%)]\tClassification Loss: 1.5718\r\n",
      "Train Epoch: 8 [35200/110534 (32%)]\tClassification Loss: 1.3875\r\n",
      "Train Epoch: 8 [35840/110534 (32%)]\tClassification Loss: 1.3157\r\n",
      "Train Epoch: 8 [36480/110534 (33%)]\tClassification Loss: 1.6460\r\n",
      "Train Epoch: 8 [37120/110534 (34%)]\tClassification Loss: 1.5757\r\n",
      "Train Epoch: 8 [37760/110534 (34%)]\tClassification Loss: 1.7511\r\n",
      "Train Epoch: 8 [38400/110534 (35%)]\tClassification Loss: 1.6238\r\n",
      "Test() called at step_no: 12689\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "\r\n",
      "Test set: Average loss: 1.5667, Accuracy: 1094/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 8 [39040/110534 (35%)]\tClassification Loss: 1.3045\r\n",
      "Train Epoch: 8 [39680/110534 (36%)]\tClassification Loss: 1.7859\r\n",
      "Train Epoch: 8 [40320/110534 (36%)]\tClassification Loss: 1.7310\r\n",
      "Train Epoch: 8 [40960/110534 (37%)]\tClassification Loss: 1.3919\r\n",
      "Train Epoch: 8 [41600/110534 (38%)]\tClassification Loss: 1.7569\r\n",
      "Train Epoch: 8 [42240/110534 (38%)]\tClassification Loss: 1.3819\r\n",
      "Train Epoch: 8 [42880/110534 (39%)]\tClassification Loss: 1.7531\r\n",
      "Train Epoch: 8 [43520/110534 (39%)]\tClassification Loss: 1.6784\r\n",
      "Train Epoch: 8 [44160/110534 (40%)]\tClassification Loss: 1.5103\r\n",
      "Train Epoch: 8 [44800/110534 (41%)]\tClassification Loss: 1.4380\r\n",
      "Test() called at step_no: 12789\r\n",
      "\r\n",
      "Test set: Average loss: 1.5666, Accuracy: 1092/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 8 [45440/110534 (41%)]\tClassification Loss: 1.8085\r\n",
      "Train Epoch: 8 [46080/110534 (42%)]\tClassification Loss: 1.5253\r\n",
      "Train Epoch: 8 [46720/110534 (42%)]\tClassification Loss: 1.8716\r\n",
      "Train Epoch: 8 [47360/110534 (43%)]\tClassification Loss: 1.7364\r\n",
      "Train Epoch: 8 [48000/110534 (43%)]\tClassification Loss: 1.8078\r\n",
      "Train Epoch: 8 [48640/110534 (44%)]\tClassification Loss: 1.6247\r\n",
      "Train Epoch: 8 [49280/110534 (45%)]\tClassification Loss: 1.3501\r\n",
      "Train Epoch: 8 [49920/110534 (45%)]\tClassification Loss: 1.3409\r\n",
      "Train Epoch: 8 [50560/110534 (46%)]\tClassification Loss: 1.8473\r\n",
      "Train Epoch: 8 [51200/110534 (46%)]\tClassification Loss: 1.6289\r\n",
      "Test() called at step_no: 12889\r\n",
      "\r\n",
      "Test set: Average loss: 1.5650, Accuracy: 1097/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 8 [51840/110534 (47%)]\tClassification Loss: 1.3647\r\n",
      "Train Epoch: 8 [52480/110534 (47%)]\tClassification Loss: 1.4811\r\n",
      "Train Epoch: 8 [53120/110534 (48%)]\tClassification Loss: 1.6811\r\n",
      "Train Epoch: 8 [53760/110534 (49%)]\tClassification Loss: 1.6088\r\n",
      "Train Epoch: 8 [54400/110534 (49%)]\tClassification Loss: 1.9186\r\n",
      "Train Epoch: 8 [55040/110534 (50%)]\tClassification Loss: 1.3409\r\n",
      "Train Epoch: 8 [55680/110534 (50%)]\tClassification Loss: 1.8691\r\n",
      "Train Epoch: 8 [56320/110534 (51%)]\tClassification Loss: 1.5648\r\n",
      "Train Epoch: 8 [56960/110534 (52%)]\tClassification Loss: 1.4994\r\n",
      "Train Epoch: 8 [57600/110534 (52%)]\tClassification Loss: 1.5712\r\n",
      "Test() called at step_no: 12989\r\n",
      "\r\n",
      "Test set: Average loss: 1.5666, Accuracy: 1086/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 8 [58240/110534 (53%)]\tClassification Loss: 1.5469\r\n",
      "Train Epoch: 8 [58880/110534 (53%)]\tClassification Loss: 1.7473\r\n",
      "Train Epoch: 8 [59520/110534 (54%)]\tClassification Loss: 1.7567\r\n",
      "Train Epoch: 8 [60160/110534 (54%)]\tClassification Loss: 1.8237\r\n",
      "Train Epoch: 8 [60800/110534 (55%)]\tClassification Loss: 1.8451\r\n",
      "Train Epoch: 8 [61440/110534 (56%)]\tClassification Loss: 1.5270\r\n",
      "Train Epoch: 8 [62080/110534 (56%)]\tClassification Loss: 2.0238\r\n",
      "Train Epoch: 8 [62720/110534 (57%)]\tClassification Loss: 1.6613\r\n",
      "Train Epoch: 8 [63360/110534 (57%)]\tClassification Loss: 1.7268\r\n",
      "Train Epoch: 8 [64000/110534 (58%)]\tClassification Loss: 1.6211\r\n",
      "Test() called at step_no: 13089\r\n",
      "\r\n",
      "Test set: Average loss: 1.5621, Accuracy: 1096/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_1000.pth.tar\r\n",
      "Train Epoch: 8 [64640/110534 (58%)]\tClassification Loss: 1.6626\r\n",
      "Train Epoch: 8 [65280/110534 (59%)]\tClassification Loss: 1.6639\r\n",
      "Train Epoch: 8 [65920/110534 (60%)]\tClassification Loss: 1.3967\r\n",
      "Train Epoch: 8 [66560/110534 (60%)]\tClassification Loss: 1.6681\r\n",
      "Train Epoch: 8 [67200/110534 (61%)]\tClassification Loss: 1.8868\r\n",
      "Train Epoch: 8 [67840/110534 (61%)]\tClassification Loss: 1.2204\r\n",
      "Train Epoch: 8 [68480/110534 (62%)]\tClassification Loss: 1.4808\r\n",
      "Train Epoch: 8 [69120/110534 (63%)]\tClassification Loss: 1.4283\r\n",
      "Train Epoch: 8 [69760/110534 (63%)]\tClassification Loss: 1.5826\r\n",
      "Train Epoch: 8 [70400/110534 (64%)]\tClassification Loss: 1.5946\r\n",
      "Test() called at step_no: 13189\r\n",
      "\r\n",
      "Test set: Average loss: 1.5702, Accuracy: 1082/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 8 [71040/110534 (64%)]\tClassification Loss: 1.5720\r\n",
      "Train Epoch: 8 [71680/110534 (65%)]\tClassification Loss: 1.4844\r\n",
      "Train Epoch: 8 [72320/110534 (65%)]\tClassification Loss: 1.5671\r\n",
      "Train Epoch: 8 [72960/110534 (66%)]\tClassification Loss: 1.5262\r\n",
      "Train Epoch: 8 [73600/110534 (67%)]\tClassification Loss: 1.4783\r\n",
      "Train Epoch: 8 [74240/110534 (67%)]\tClassification Loss: 1.4069\r\n",
      "Train Epoch: 8 [74880/110534 (68%)]\tClassification Loss: 1.5985\r\n",
      "Train Epoch: 8 [75520/110534 (68%)]\tClassification Loss: 1.7166\r\n",
      "Train Epoch: 8 [76160/110534 (69%)]\tClassification Loss: 1.4382\r\n",
      "Train Epoch: 8 [76800/110534 (69%)]\tClassification Loss: 1.5159\r\n",
      "Test() called at step_no: 13289\r\n",
      "\r\n",
      "Test set: Average loss: 1.5639, Accuracy: 1095/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 8 [77440/110534 (70%)]\tClassification Loss: 1.8374\r\n",
      "Train Epoch: 8 [78080/110534 (71%)]\tClassification Loss: 1.7210\r\n",
      "Train Epoch: 8 [78720/110534 (71%)]\tClassification Loss: 1.6704\r\n",
      "Train Epoch: 8 [79360/110534 (72%)]\tClassification Loss: 2.0100\r\n",
      "Train Epoch: 8 [80000/110534 (72%)]\tClassification Loss: 1.6410\r\n",
      "Train Epoch: 8 [80640/110534 (73%)]\tClassification Loss: 1.6875\r\n",
      "Train Epoch: 8 [81280/110534 (74%)]\tClassification Loss: 1.9302\r\n",
      "Train Epoch: 8 [81920/110534 (74%)]\tClassification Loss: 1.3126\r\n",
      "Train Epoch: 8 [82560/110534 (75%)]\tClassification Loss: 1.8142\r\n",
      "Train Epoch: 8 [83200/110534 (75%)]\tClassification Loss: 1.4578\r\n",
      "Test() called at step_no: 13389\r\n",
      "\r\n",
      "Test set: Average loss: 1.5610, Accuracy: 1100/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 8 [83840/110534 (76%)]\tClassification Loss: 1.8458\r\n",
      "Train Epoch: 8 [84480/110534 (76%)]\tClassification Loss: 1.6640\r\n",
      "Train Epoch: 8 [85120/110534 (77%)]\tClassification Loss: 1.7692\r\n",
      "Train Epoch: 8 [85760/110534 (78%)]\tClassification Loss: 1.9106\r\n",
      "Train Epoch: 8 [86400/110534 (78%)]\tClassification Loss: 1.6446\r\n",
      "Train Epoch: 8 [87040/110534 (79%)]\tClassification Loss: 1.4629\r\n",
      "Train Epoch: 8 [87680/110534 (79%)]\tClassification Loss: 1.5509\r\n",
      "Train Epoch: 8 [88320/110534 (80%)]\tClassification Loss: 1.4952\r\n",
      "Train Epoch: 8 [88960/110534 (80%)]\tClassification Loss: 1.4512\r\n",
      "Train Epoch: 8 [89600/110534 (81%)]\tClassification Loss: 1.4573\r\n",
      "Test() called at step_no: 13489\r\n",
      "\r\n",
      "Test set: Average loss: 1.5653, Accuracy: 1101/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 8 [90240/110534 (82%)]\tClassification Loss: 1.6537\r\n",
      "Train Epoch: 8 [90880/110534 (82%)]\tClassification Loss: 1.9670\r\n",
      "Train Epoch: 8 [91520/110534 (83%)]\tClassification Loss: 1.4972\r\n",
      "Train Epoch: 8 [92160/110534 (83%)]\tClassification Loss: 1.5550\r\n",
      "Train Epoch: 8 [92800/110534 (84%)]\tClassification Loss: 1.1893\r\n",
      "Train Epoch: 8 [93440/110534 (85%)]\tClassification Loss: 1.4895\r\n",
      "Train Epoch: 8 [94080/110534 (85%)]\tClassification Loss: 1.6235\r\n",
      "Train Epoch: 8 [94720/110534 (86%)]\tClassification Loss: 1.5568\r\n",
      "Train Epoch: 8 [95360/110534 (86%)]\tClassification Loss: 1.5256\r\n",
      "Train Epoch: 8 [96000/110534 (87%)]\tClassification Loss: 1.4313\r\n",
      "Test() called at step_no: 13589\r\n",
      "\r\n",
      "Test set: Average loss: 1.5625, Accuracy: 1094/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_1500.pth.tar\r\n",
      "Train Epoch: 8 [96640/110534 (87%)]\tClassification Loss: 1.7566\r\n",
      "Train Epoch: 8 [97280/110534 (88%)]\tClassification Loss: 1.3809\r\n",
      "Train Epoch: 8 [97920/110534 (89%)]\tClassification Loss: 1.6583\r\n",
      "Train Epoch: 8 [98560/110534 (89%)]\tClassification Loss: 1.6138\r\n",
      "Train Epoch: 8 [99200/110534 (90%)]\tClassification Loss: 1.6302\r\n",
      "Train Epoch: 8 [99840/110534 (90%)]\tClassification Loss: 1.6101\r\n",
      "Train Epoch: 8 [100480/110534 (91%)]\tClassification Loss: 1.8001\r\n",
      "Train Epoch: 8 [101120/110534 (91%)]\tClassification Loss: 1.5670\r\n",
      "Train Epoch: 8 [101760/110534 (92%)]\tClassification Loss: 1.4950\r\n",
      "Train Epoch: 8 [102400/110534 (93%)]\tClassification Loss: 1.6498\r\n",
      "Test() called at step_no: 13689\r\n",
      "\r\n",
      "Test set: Average loss: 1.5669, Accuracy: 1106/1920 (58%)\r\n",
      "\r\n",
      "Train Epoch: 8 [103040/110534 (93%)]\tClassification Loss: 1.5736\r\n",
      "Train Epoch: 8 [103680/110534 (94%)]\tClassification Loss: 1.5217\r\n",
      "Train Epoch: 8 [104320/110534 (94%)]\tClassification Loss: 1.4442\r\n",
      "Train Epoch: 8 [104960/110534 (95%)]\tClassification Loss: 1.5942\r\n",
      "Train Epoch: 8 [105600/110534 (96%)]\tClassification Loss: 1.3595\r\n",
      "Train Epoch: 8 [106240/110534 (96%)]\tClassification Loss: 1.5376\r\n",
      "Train Epoch: 8 [106880/110534 (97%)]\tClassification Loss: 1.1847\r\n",
      "Train Epoch: 8 [107520/110534 (97%)]\tClassification Loss: 1.4967\r\n",
      "Train Epoch: 8 [108160/110534 (98%)]\tClassification Loss: 1.6282\r\n",
      "Train Epoch: 8 [108800/110534 (98%)]\tClassification Loss: 1.8236\r\n",
      "Test() called at step_no: 13789\r\n",
      "\r\n",
      "Test set: Average loss: 1.5660, Accuracy: 1097/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 8 [109440/110534 (99%)]\tClassification Loss: 1.5207\r\n",
      "Train Epoch: 8 [110080/110534 (100%)]\tClassification Loss: 1.5939\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_final.pth.tar\r\n",
      "Train Epoch: 9 [0/110534 (0%)]\tClassification Loss: 1.8242\r\n",
      "Test() called at step_no: 13816\r\n",
      "\r\n",
      "Test set: Average loss: 1.5700, Accuracy: 1100/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 9 [640/110534 (1%)]\tClassification Loss: 1.6804\r\n",
      "Train Epoch: 9 [1280/110534 (1%)]\tClassification Loss: 1.4426\r\n",
      "Train Epoch: 9 [1920/110534 (2%)]\tClassification Loss: 1.5289\r\n",
      "Train Epoch: 9 [2560/110534 (2%)]\tClassification Loss: 1.4679\r\n",
      "Train Epoch: 9 [3200/110534 (3%)]\tClassification Loss: 1.5370\r\n",
      "Train Epoch: 9 [3840/110534 (3%)]\tClassification Loss: 1.6712\r\n",
      "Train Epoch: 9 [4480/110534 (4%)]\tClassification Loss: 1.8238\r\n",
      "Train Epoch: 9 [5120/110534 (5%)]\tClassification Loss: 1.7110\r\n",
      "Train Epoch: 9 [5760/110534 (5%)]\tClassification Loss: 1.6438\r\n",
      "Train Epoch: 9 [6400/110534 (6%)]\tClassification Loss: 1.6654\r\n",
      "Test() called at step_no: 13916\r\n",
      "\r\n",
      "Test set: Average loss: 1.5621, Accuracy: 1100/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 9 [7040/110534 (6%)]\tClassification Loss: 1.9765\r\n",
      "Train Epoch: 9 [7680/110534 (7%)]\tClassification Loss: 1.5553\r\n",
      "Train Epoch: 9 [8320/110534 (8%)]\tClassification Loss: 1.6039\r\n",
      "Train Epoch: 9 [8960/110534 (8%)]\tClassification Loss: 1.7178\r\n",
      "Train Epoch: 9 [9600/110534 (9%)]\tClassification Loss: 1.6375\r\n",
      "Train Epoch: 9 [10240/110534 (9%)]\tClassification Loss: 1.6262\r\n",
      "Train Epoch: 9 [10880/110534 (10%)]\tClassification Loss: 1.6151\r\n",
      "Train Epoch: 9 [11520/110534 (10%)]\tClassification Loss: 1.8319\r\n",
      "Train Epoch: 9 [12160/110534 (11%)]\tClassification Loss: 1.8417\r\n",
      "Train Epoch: 9 [12800/110534 (12%)]\tClassification Loss: 1.8650\r\n",
      "Test() called at step_no: 14016\r\n",
      "\r\n",
      "Test set: Average loss: 1.5670, Accuracy: 1082/1920 (56%)\r\n",
      "\r\n",
      "Train Epoch: 9 [13440/110534 (12%)]\tClassification Loss: 1.8098\r\n",
      "Train Epoch: 9 [14080/110534 (13%)]\tClassification Loss: 1.4816\r\n",
      "Train Epoch: 9 [14720/110534 (13%)]\tClassification Loss: 1.5849\r\n",
      "Train Epoch: 9 [15360/110534 (14%)]\tClassification Loss: 1.5905\r\n",
      "Train Epoch: 9 [16000/110534 (14%)]\tClassification Loss: 1.8998\r\n",
      "Train Epoch: 9 [16640/110534 (15%)]\tClassification Loss: 1.8188\r\n",
      "Train Epoch: 9 [17280/110534 (16%)]\tClassification Loss: 1.6998\r\n",
      "Train Epoch: 9 [17920/110534 (16%)]\tClassification Loss: 1.5206\r\n",
      "Train Epoch: 9 [18560/110534 (17%)]\tClassification Loss: 1.7528\r\n",
      "Train Epoch: 9 [19200/110534 (17%)]\tClassification Loss: 1.5993\r\n",
      "Test() called at step_no: 14116\r\n",
      "\r\n",
      "Test set: Average loss: 1.5626, Accuracy: 1086/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 9 [19840/110534 (18%)]\tClassification Loss: 1.6653\r\n",
      "Train Epoch: 9 [20480/110534 (19%)]\tClassification Loss: 1.7227\r\n",
      "Train Epoch: 9 [21120/110534 (19%)]\tClassification Loss: 1.5094\r\n",
      "Train Epoch: 9 [21760/110534 (20%)]\tClassification Loss: 1.6854\r\n",
      "Train Epoch: 9 [22400/110534 (20%)]\tClassification Loss: 1.9119\r\n",
      "Train Epoch: 9 [23040/110534 (21%)]\tClassification Loss: 1.4416\r\n",
      "Train Epoch: 9 [23680/110534 (21%)]\tClassification Loss: 1.6260\r\n",
      "Train Epoch: 9 [24320/110534 (22%)]\tClassification Loss: 1.4729\r\n",
      "Train Epoch: 9 [24960/110534 (23%)]\tClassification Loss: 1.4268\r\n",
      "Train Epoch: 9 [25600/110534 (23%)]\tClassification Loss: 1.8227\r\n",
      "Test() called at step_no: 14216\r\n",
      "\r\n",
      "Test set: Average loss: 1.5631, Accuracy: 1091/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 9 [26240/110534 (24%)]\tClassification Loss: 1.5375\r\n",
      "Train Epoch: 9 [26880/110534 (24%)]\tClassification Loss: 1.6019\r\n",
      "Train Epoch: 9 [27520/110534 (25%)]\tClassification Loss: 1.3010\r\n",
      "Train Epoch: 9 [28160/110534 (25%)]\tClassification Loss: 1.6898\r\n",
      "Train Epoch: 9 [28800/110534 (26%)]\tClassification Loss: 1.5927\r\n",
      "Train Epoch: 9 [29440/110534 (27%)]\tClassification Loss: 1.5072\r\n",
      "Train Epoch: 9 [30080/110534 (27%)]\tClassification Loss: 1.9032\r\n",
      "Train Epoch: 9 [30720/110534 (28%)]\tClassification Loss: 1.6463\r\n",
      "Train Epoch: 9 [31360/110534 (28%)]\tClassification Loss: 1.6749\r\n",
      "Train Epoch: 9 [32000/110534 (29%)]\tClassification Loss: 1.5194\r\n",
      "Test() called at step_no: 14316\r\n",
      "\r\n",
      "Test set: Average loss: 1.5634, Accuracy: 1099/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_500.pth.tar\r\n",
      "Train Epoch: 9 [32640/110534 (30%)]\tClassification Loss: 1.5252\r\n",
      "Train Epoch: 9 [33280/110534 (30%)]\tClassification Loss: 1.3534\r\n",
      "Train Epoch: 9 [33920/110534 (31%)]\tClassification Loss: 1.7145\r\n",
      "Train Epoch: 9 [34560/110534 (31%)]\tClassification Loss: 1.6617\r\n",
      "Train Epoch: 9 [35200/110534 (32%)]\tClassification Loss: 1.5136\r\n",
      "Train Epoch: 9 [35840/110534 (32%)]\tClassification Loss: 1.2817\r\n",
      "Train Epoch: 9 [36480/110534 (33%)]\tClassification Loss: 1.5145\r\n",
      "Train Epoch: 9 [37120/110534 (34%)]\tClassification Loss: 1.6589\r\n",
      "Train Epoch: 9 [37760/110534 (34%)]\tClassification Loss: 1.6477\r\n",
      "Train Epoch: 9 [38400/110534 (35%)]\tClassification Loss: 1.5206\r\n",
      "Test() called at step_no: 14416\r\n",
      "\r\n",
      "Test set: Average loss: 1.5622, Accuracy: 1095/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 9 [39040/110534 (35%)]\tClassification Loss: 1.4487\r\n",
      "Train Epoch: 9 [39680/110534 (36%)]\tClassification Loss: 1.7077\r\n",
      "Train Epoch: 9 [40320/110534 (36%)]\tClassification Loss: 1.6399\r\n",
      "Train Epoch: 9 [40960/110534 (37%)]\tClassification Loss: 1.3092\r\n",
      "Train Epoch: 9 [41600/110534 (38%)]\tClassification Loss: 1.7036\r\n",
      "Train Epoch: 9 [42240/110534 (38%)]\tClassification Loss: 1.4535\r\n",
      "Train Epoch: 9 [42880/110534 (39%)]\tClassification Loss: 1.4559\r\n",
      "Train Epoch: 9 [43520/110534 (39%)]\tClassification Loss: 1.8271\r\n",
      "Train Epoch: 9 [44160/110534 (40%)]\tClassification Loss: 1.5656\r\n",
      "Train Epoch: 9 [44800/110534 (41%)]\tClassification Loss: 1.2734\r\n",
      "Test() called at step_no: 14516\r\n",
      "\r\n",
      "Test set: Average loss: 1.5615, Accuracy: 1089/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 9 [45440/110534 (41%)]\tClassification Loss: 1.7024\r\n",
      "Train Epoch: 9 [46080/110534 (42%)]\tClassification Loss: 1.5520\r\n",
      "Train Epoch: 9 [46720/110534 (42%)]\tClassification Loss: 1.8798\r\n",
      "Train Epoch: 9 [47360/110534 (43%)]\tClassification Loss: 1.6229\r\n",
      "Train Epoch: 9 [48000/110534 (43%)]\tClassification Loss: 1.7115\r\n",
      "Train Epoch: 9 [48640/110534 (44%)]\tClassification Loss: 1.4696\r\n",
      "Train Epoch: 9 [49280/110534 (45%)]\tClassification Loss: 1.3351\r\n",
      "Train Epoch: 9 [49920/110534 (45%)]\tClassification Loss: 1.2646\r\n",
      "Train Epoch: 9 [50560/110534 (46%)]\tClassification Loss: 1.7044\r\n",
      "Train Epoch: 9 [51200/110534 (46%)]\tClassification Loss: 1.5195\r\n",
      "Test() called at step_no: 14616\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/queues.py\", line 245, in _feed\r\n",
      "    send_bytes(obj)\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 200, in send_bytes\r\n",
      "    self._send_bytes(m[offset:offset + size])\r\n",
      "  File \"/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/multiprocessing/connection.py\", line 411, in _send_bytes\r\n",
      "    self._send(header + buf)\r\n",
      "\r\n",
      "Test set: Average loss: 1.5609, Accuracy: 1104/1920 (58%)\r\n",
      "\r\n",
      "Train Epoch: 9 [51840/110534 (47%)]\tClassification Loss: 1.4025\r\n",
      "Train Epoch: 9 [52480/110534 (47%)]\tClassification Loss: 1.4288\r\n",
      "Train Epoch: 9 [53120/110534 (48%)]\tClassification Loss: 1.6655\r\n",
      "Train Epoch: 9 [53760/110534 (49%)]\tClassification Loss: 1.6954\r\n",
      "Train Epoch: 9 [54400/110534 (49%)]\tClassification Loss: 1.9645\r\n",
      "Train Epoch: 9 [55040/110534 (50%)]\tClassification Loss: 1.3121\r\n",
      "Train Epoch: 9 [55680/110534 (50%)]\tClassification Loss: 1.8211\r\n",
      "Train Epoch: 9 [56320/110534 (51%)]\tClassification Loss: 1.5695\r\n",
      "Train Epoch: 9 [56960/110534 (52%)]\tClassification Loss: 1.4107\r\n",
      "Train Epoch: 9 [57600/110534 (52%)]\tClassification Loss: 1.6338\r\n",
      "Test() called at step_no: 14716\r\n",
      "\r\n",
      "Test set: Average loss: 1.5613, Accuracy: 1100/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 9 [58240/110534 (53%)]\tClassification Loss: 1.2129\r\n",
      "Train Epoch: 9 [58880/110534 (53%)]\tClassification Loss: 1.7888\r\n",
      "Train Epoch: 9 [59520/110534 (54%)]\tClassification Loss: 1.7089\r\n",
      "Train Epoch: 9 [60160/110534 (54%)]\tClassification Loss: 1.9251\r\n",
      "Train Epoch: 9 [60800/110534 (55%)]\tClassification Loss: 1.9135\r\n",
      "Train Epoch: 9 [61440/110534 (56%)]\tClassification Loss: 1.4867\r\n",
      "Train Epoch: 9 [62080/110534 (56%)]\tClassification Loss: 2.0857\r\n",
      "Train Epoch: 9 [62720/110534 (57%)]\tClassification Loss: 1.6237\r\n",
      "Train Epoch: 9 [63360/110534 (57%)]\tClassification Loss: 1.7600\r\n",
      "Train Epoch: 9 [64000/110534 (58%)]\tClassification Loss: 1.7087\r\n",
      "Test() called at step_no: 14816\r\n",
      "\r\n",
      "Test set: Average loss: 1.5582, Accuracy: 1096/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_1000.pth.tar\r\n",
      "Train Epoch: 9 [64640/110534 (58%)]\tClassification Loss: 1.7138\r\n",
      "Train Epoch: 9 [65280/110534 (59%)]\tClassification Loss: 1.6703\r\n",
      "Train Epoch: 9 [65920/110534 (60%)]\tClassification Loss: 1.4292\r\n",
      "Train Epoch: 9 [66560/110534 (60%)]\tClassification Loss: 1.5866\r\n",
      "Train Epoch: 9 [67200/110534 (61%)]\tClassification Loss: 1.7922\r\n",
      "Train Epoch: 9 [67840/110534 (61%)]\tClassification Loss: 1.2834\r\n",
      "Train Epoch: 9 [68480/110534 (62%)]\tClassification Loss: 1.5204\r\n",
      "Train Epoch: 9 [69120/110534 (63%)]\tClassification Loss: 1.5396\r\n",
      "Train Epoch: 9 [69760/110534 (63%)]\tClassification Loss: 1.3895\r\n",
      "Train Epoch: 9 [70400/110534 (64%)]\tClassification Loss: 1.7181\r\n",
      "Test() called at step_no: 14916\r\n",
      "\r\n",
      "Test set: Average loss: 1.5631, Accuracy: 1093/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 9 [71040/110534 (64%)]\tClassification Loss: 1.6661\r\n",
      "Train Epoch: 9 [71680/110534 (65%)]\tClassification Loss: 1.5895\r\n",
      "Train Epoch: 9 [72320/110534 (65%)]\tClassification Loss: 1.5205\r\n",
      "Train Epoch: 9 [72960/110534 (66%)]\tClassification Loss: 1.6419\r\n",
      "Train Epoch: 9 [73600/110534 (67%)]\tClassification Loss: 1.6996\r\n",
      "Train Epoch: 9 [74240/110534 (67%)]\tClassification Loss: 1.5748\r\n",
      "Train Epoch: 9 [74880/110534 (68%)]\tClassification Loss: 1.4875\r\n",
      "Train Epoch: 9 [75520/110534 (68%)]\tClassification Loss: 1.6974\r\n",
      "Train Epoch: 9 [76160/110534 (69%)]\tClassification Loss: 1.4572\r\n",
      "Train Epoch: 9 [76800/110534 (69%)]\tClassification Loss: 1.6222\r\n",
      "Test() called at step_no: 15016\r\n",
      "\r\n",
      "Test set: Average loss: 1.5593, Accuracy: 1095/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 9 [77440/110534 (70%)]\tClassification Loss: 1.6606\r\n",
      "Train Epoch: 9 [78080/110534 (71%)]\tClassification Loss: 1.7379\r\n",
      "Train Epoch: 9 [78720/110534 (71%)]\tClassification Loss: 1.6798\r\n",
      "Train Epoch: 9 [79360/110534 (72%)]\tClassification Loss: 2.0425\r\n",
      "Train Epoch: 9 [80000/110534 (72%)]\tClassification Loss: 1.6335\r\n",
      "Train Epoch: 9 [80640/110534 (73%)]\tClassification Loss: 1.6026\r\n",
      "Train Epoch: 9 [81280/110534 (74%)]\tClassification Loss: 1.8210\r\n",
      "Train Epoch: 9 [81920/110534 (74%)]\tClassification Loss: 1.5217\r\n",
      "Train Epoch: 9 [82560/110534 (75%)]\tClassification Loss: 1.7878\r\n",
      "Train Epoch: 9 [83200/110534 (75%)]\tClassification Loss: 1.3615\r\n",
      "Test() called at step_no: 15116\r\n",
      "\r\n",
      "Test set: Average loss: 1.5580, Accuracy: 1103/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 9 [83840/110534 (76%)]\tClassification Loss: 1.9458\r\n",
      "Train Epoch: 9 [84480/110534 (76%)]\tClassification Loss: 1.7970\r\n",
      "Train Epoch: 9 [85120/110534 (77%)]\tClassification Loss: 1.5827\r\n",
      "Train Epoch: 9 [85760/110534 (78%)]\tClassification Loss: 2.0008\r\n",
      "Train Epoch: 9 [86400/110534 (78%)]\tClassification Loss: 1.7751\r\n",
      "Train Epoch: 9 [87040/110534 (79%)]\tClassification Loss: 1.4230\r\n",
      "Train Epoch: 9 [87680/110534 (79%)]\tClassification Loss: 1.3929\r\n",
      "Train Epoch: 9 [88320/110534 (80%)]\tClassification Loss: 1.5542\r\n",
      "Train Epoch: 9 [88960/110534 (80%)]\tClassification Loss: 1.4258\r\n",
      "Train Epoch: 9 [89600/110534 (81%)]\tClassification Loss: 1.4500\r\n",
      "Test() called at step_no: 15216\r\n",
      "\r\n",
      "Test set: Average loss: 1.5614, Accuracy: 1104/1920 (58%)\r\n",
      "\r\n",
      "Train Epoch: 9 [90240/110534 (82%)]\tClassification Loss: 1.5914\r\n",
      "Train Epoch: 9 [90880/110534 (82%)]\tClassification Loss: 1.8207\r\n",
      "Train Epoch: 9 [91520/110534 (83%)]\tClassification Loss: 1.5758\r\n",
      "Train Epoch: 9 [92160/110534 (83%)]\tClassification Loss: 1.5473\r\n",
      "Train Epoch: 9 [92800/110534 (84%)]\tClassification Loss: 1.1718\r\n",
      "Train Epoch: 9 [93440/110534 (85%)]\tClassification Loss: 1.3264\r\n",
      "Train Epoch: 9 [94080/110534 (85%)]\tClassification Loss: 1.8022\r\n",
      "Train Epoch: 9 [94720/110534 (86%)]\tClassification Loss: 1.4681\r\n",
      "Train Epoch: 9 [95360/110534 (86%)]\tClassification Loss: 1.5665\r\n",
      "Train Epoch: 9 [96000/110534 (87%)]\tClassification Loss: 1.4154\r\n",
      "Test() called at step_no: 15316\r\n",
      "\r\n",
      "Test set: Average loss: 1.5583, Accuracy: 1096/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_1500.pth.tar\r\n",
      "Train Epoch: 9 [96640/110534 (87%)]\tClassification Loss: 1.7507\r\n",
      "Train Epoch: 9 [97280/110534 (88%)]\tClassification Loss: 1.4218\r\n",
      "Train Epoch: 9 [97920/110534 (89%)]\tClassification Loss: 1.5243\r\n",
      "Train Epoch: 9 [98560/110534 (89%)]\tClassification Loss: 1.5503\r\n",
      "Train Epoch: 9 [99200/110534 (90%)]\tClassification Loss: 1.4399\r\n",
      "Train Epoch: 9 [99840/110534 (90%)]\tClassification Loss: 1.6119\r\n",
      "Train Epoch: 9 [100480/110534 (91%)]\tClassification Loss: 1.7111\r\n",
      "Train Epoch: 9 [101120/110534 (91%)]\tClassification Loss: 1.6434\r\n",
      "Train Epoch: 9 [101760/110534 (92%)]\tClassification Loss: 1.4850\r\n",
      "Train Epoch: 9 [102400/110534 (93%)]\tClassification Loss: 1.5767\r\n",
      "Test() called at step_no: 15416\r\n",
      "\r\n",
      "Test set: Average loss: 1.5609, Accuracy: 1099/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 9 [103040/110534 (93%)]\tClassification Loss: 1.6593\r\n",
      "Train Epoch: 9 [103680/110534 (94%)]\tClassification Loss: 1.3866\r\n",
      "Train Epoch: 9 [104320/110534 (94%)]\tClassification Loss: 1.3943\r\n",
      "Train Epoch: 9 [104960/110534 (95%)]\tClassification Loss: 1.5933\r\n",
      "Train Epoch: 9 [105600/110534 (96%)]\tClassification Loss: 1.3697\r\n",
      "Train Epoch: 9 [106240/110534 (96%)]\tClassification Loss: 1.5444\r\n",
      "Train Epoch: 9 [106880/110534 (97%)]\tClassification Loss: 1.3174\r\n",
      "Train Epoch: 9 [107520/110534 (97%)]\tClassification Loss: 1.6371\r\n",
      "Train Epoch: 9 [108160/110534 (98%)]\tClassification Loss: 1.3342\r\n",
      "Train Epoch: 9 [108800/110534 (98%)]\tClassification Loss: 1.8222\r\n",
      "Test() called at step_no: 15516\r\n",
      "\r\n",
      "Test set: Average loss: 1.5613, Accuracy: 1098/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 9 [109440/110534 (99%)]\tClassification Loss: 1.6232\r\n",
      "Train Epoch: 9 [110080/110534 (100%)]\tClassification Loss: 1.5634\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_final.pth.tar\r\n",
      "Train Epoch: 10 [0/110534 (0%)]\tClassification Loss: 1.6439\r\n",
      "Test() called at step_no: 15543\r\n",
      "\r\n",
      "Test set: Average loss: 1.5648, Accuracy: 1093/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 10 [640/110534 (1%)]\tClassification Loss: 1.6585\r\n",
      "Train Epoch: 10 [1280/110534 (1%)]\tClassification Loss: 1.4468\r\n",
      "Train Epoch: 10 [1920/110534 (2%)]\tClassification Loss: 1.4633\r\n",
      "Train Epoch: 10 [2560/110534 (2%)]\tClassification Loss: 1.5855\r\n",
      "Train Epoch: 10 [3200/110534 (3%)]\tClassification Loss: 1.5533\r\n",
      "Train Epoch: 10 [3840/110534 (3%)]\tClassification Loss: 1.4888\r\n",
      "Train Epoch: 10 [4480/110534 (4%)]\tClassification Loss: 1.8515\r\n",
      "Train Epoch: 10 [5120/110534 (5%)]\tClassification Loss: 1.7320\r\n",
      "Train Epoch: 10 [5760/110534 (5%)]\tClassification Loss: 1.6197\r\n",
      "Train Epoch: 10 [6400/110534 (6%)]\tClassification Loss: 1.5797\r\n",
      "Test() called at step_no: 15643\r\n",
      "\r\n",
      "Test set: Average loss: 1.5579, Accuracy: 1094/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 10 [7040/110534 (6%)]\tClassification Loss: 1.9121\r\n",
      "Train Epoch: 10 [7680/110534 (7%)]\tClassification Loss: 1.7218\r\n",
      "Train Epoch: 10 [8320/110534 (8%)]\tClassification Loss: 1.5529\r\n",
      "Train Epoch: 10 [8960/110534 (8%)]\tClassification Loss: 1.6676\r\n",
      "Train Epoch: 10 [9600/110534 (9%)]\tClassification Loss: 1.6354\r\n",
      "Train Epoch: 10 [10240/110534 (9%)]\tClassification Loss: 1.6064\r\n",
      "Train Epoch: 10 [10880/110534 (10%)]\tClassification Loss: 1.5300\r\n",
      "Train Epoch: 10 [11520/110534 (10%)]\tClassification Loss: 1.8895\r\n",
      "Train Epoch: 10 [12160/110534 (11%)]\tClassification Loss: 1.9691\r\n",
      "Train Epoch: 10 [12800/110534 (12%)]\tClassification Loss: 1.7019\r\n",
      "Test() called at step_no: 15743\r\n",
      "\r\n",
      "Test set: Average loss: 1.5630, Accuracy: 1094/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 10 [13440/110534 (12%)]\tClassification Loss: 1.7144\r\n",
      "Train Epoch: 10 [14080/110534 (13%)]\tClassification Loss: 1.5309\r\n",
      "Train Epoch: 10 [14720/110534 (13%)]\tClassification Loss: 1.6534\r\n",
      "Train Epoch: 10 [15360/110534 (14%)]\tClassification Loss: 1.5762\r\n",
      "Train Epoch: 10 [16000/110534 (14%)]\tClassification Loss: 1.9002\r\n",
      "Train Epoch: 10 [16640/110534 (15%)]\tClassification Loss: 1.7665\r\n",
      "Train Epoch: 10 [17280/110534 (16%)]\tClassification Loss: 1.7542\r\n",
      "Train Epoch: 10 [17920/110534 (16%)]\tClassification Loss: 1.4868\r\n",
      "Train Epoch: 10 [18560/110534 (17%)]\tClassification Loss: 1.7164\r\n",
      "Train Epoch: 10 [19200/110534 (17%)]\tClassification Loss: 1.5949\r\n",
      "Test() called at step_no: 15843\r\n",
      "\r\n",
      "Test set: Average loss: 1.5584, Accuracy: 1085/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 10 [19840/110534 (18%)]\tClassification Loss: 1.6225\r\n",
      "Train Epoch: 10 [20480/110534 (19%)]\tClassification Loss: 1.7508\r\n",
      "Train Epoch: 10 [21120/110534 (19%)]\tClassification Loss: 1.5413\r\n",
      "Train Epoch: 10 [21760/110534 (20%)]\tClassification Loss: 1.5765\r\n",
      "Train Epoch: 10 [22400/110534 (20%)]\tClassification Loss: 1.8548\r\n",
      "Train Epoch: 10 [23040/110534 (21%)]\tClassification Loss: 1.5553\r\n",
      "Train Epoch: 10 [23680/110534 (21%)]\tClassification Loss: 1.5065\r\n",
      "Train Epoch: 10 [24320/110534 (22%)]\tClassification Loss: 1.3928\r\n",
      "Train Epoch: 10 [24960/110534 (23%)]\tClassification Loss: 1.5030\r\n",
      "Train Epoch: 10 [25600/110534 (23%)]\tClassification Loss: 2.0062\r\n",
      "Test() called at step_no: 15943\r\n",
      "\r\n",
      "Test set: Average loss: 1.5588, Accuracy: 1095/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 10 [26240/110534 (24%)]\tClassification Loss: 1.5909\r\n",
      "Train Epoch: 10 [26880/110534 (24%)]\tClassification Loss: 1.6420\r\n",
      "Train Epoch: 10 [27520/110534 (25%)]\tClassification Loss: 1.4457\r\n",
      "Train Epoch: 10 [28160/110534 (25%)]\tClassification Loss: 1.5755\r\n",
      "Train Epoch: 10 [28800/110534 (26%)]\tClassification Loss: 1.6669\r\n",
      "Train Epoch: 10 [29440/110534 (27%)]\tClassification Loss: 1.4563\r\n",
      "Train Epoch: 10 [30080/110534 (27%)]\tClassification Loss: 1.6971\r\n",
      "Train Epoch: 10 [30720/110534 (28%)]\tClassification Loss: 1.7127\r\n",
      "Train Epoch: 10 [31360/110534 (28%)]\tClassification Loss: 1.7479\r\n",
      "Train Epoch: 10 [32000/110534 (29%)]\tClassification Loss: 1.6388\r\n",
      "Test() called at step_no: 16043\r\n",
      "\r\n",
      "Test set: Average loss: 1.5618, Accuracy: 1094/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_500.pth.tar\r\n",
      "Train Epoch: 10 [32640/110534 (30%)]\tClassification Loss: 1.5121\r\n",
      "Train Epoch: 10 [33280/110534 (30%)]\tClassification Loss: 1.3642\r\n",
      "Train Epoch: 10 [33920/110534 (31%)]\tClassification Loss: 1.7284\r\n",
      "Train Epoch: 10 [34560/110534 (31%)]\tClassification Loss: 1.7910\r\n",
      "Train Epoch: 10 [35200/110534 (32%)]\tClassification Loss: 1.4589\r\n",
      "Train Epoch: 10 [35840/110534 (32%)]\tClassification Loss: 1.2404\r\n",
      "Train Epoch: 10 [36480/110534 (33%)]\tClassification Loss: 1.5199\r\n",
      "Train Epoch: 10 [37120/110534 (34%)]\tClassification Loss: 1.7482\r\n",
      "Train Epoch: 10 [37760/110534 (34%)]\tClassification Loss: 1.6631\r\n",
      "Train Epoch: 10 [38400/110534 (35%)]\tClassification Loss: 1.5659\r\n",
      "Test() called at step_no: 16143\r\n",
      "\r\n",
      "Test set: Average loss: 1.5579, Accuracy: 1096/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 10 [39040/110534 (35%)]\tClassification Loss: 1.2634\r\n",
      "Train Epoch: 10 [39680/110534 (36%)]\tClassification Loss: 1.8153\r\n",
      "Train Epoch: 10 [40320/110534 (36%)]\tClassification Loss: 1.7590\r\n",
      "Train Epoch: 10 [40960/110534 (37%)]\tClassification Loss: 1.2362\r\n",
      "Train Epoch: 10 [41600/110534 (38%)]\tClassification Loss: 1.7508\r\n",
      "Train Epoch: 10 [42240/110534 (38%)]\tClassification Loss: 1.4205\r\n",
      "Train Epoch: 10 [42880/110534 (39%)]\tClassification Loss: 1.5895\r\n",
      "Train Epoch: 10 [43520/110534 (39%)]\tClassification Loss: 1.7765\r\n",
      "Train Epoch: 10 [44160/110534 (40%)]\tClassification Loss: 1.4723\r\n",
      "Train Epoch: 10 [44800/110534 (41%)]\tClassification Loss: 1.3459\r\n",
      "Test() called at step_no: 16243\r\n",
      "\r\n",
      "Test set: Average loss: 1.5588, Accuracy: 1090/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 10 [45440/110534 (41%)]\tClassification Loss: 1.6998\r\n",
      "Train Epoch: 10 [46080/110534 (42%)]\tClassification Loss: 1.5870\r\n",
      "Train Epoch: 10 [46720/110534 (42%)]\tClassification Loss: 1.7424\r\n",
      "Train Epoch: 10 [47360/110534 (43%)]\tClassification Loss: 1.8178\r\n",
      "Train Epoch: 10 [48000/110534 (43%)]\tClassification Loss: 1.7850\r\n",
      "Train Epoch: 10 [48640/110534 (44%)]\tClassification Loss: 1.4788\r\n",
      "Train Epoch: 10 [49280/110534 (45%)]\tClassification Loss: 1.2906\r\n",
      "Train Epoch: 10 [49920/110534 (45%)]\tClassification Loss: 1.3514\r\n",
      "Train Epoch: 10 [50560/110534 (46%)]\tClassification Loss: 1.7415\r\n",
      "Train Epoch: 10 [51200/110534 (46%)]\tClassification Loss: 1.5177\r\n",
      "Test() called at step_no: 16343\r\n",
      "\r\n",
      "Test set: Average loss: 1.5577, Accuracy: 1107/1920 (58%)\r\n",
      "\r\n",
      "Train Epoch: 10 [51840/110534 (47%)]\tClassification Loss: 1.1641\r\n",
      "Train Epoch: 10 [52480/110534 (47%)]\tClassification Loss: 1.6603\r\n",
      "Train Epoch: 10 [53120/110534 (48%)]\tClassification Loss: 1.5450\r\n",
      "Train Epoch: 10 [53760/110534 (49%)]\tClassification Loss: 1.5658\r\n",
      "Train Epoch: 10 [54400/110534 (49%)]\tClassification Loss: 1.9675\r\n",
      "Train Epoch: 10 [55040/110534 (50%)]\tClassification Loss: 1.2859\r\n",
      "Train Epoch: 10 [55680/110534 (50%)]\tClassification Loss: 1.8664\r\n",
      "Train Epoch: 10 [56320/110534 (51%)]\tClassification Loss: 1.4239\r\n",
      "Train Epoch: 10 [56960/110534 (52%)]\tClassification Loss: 1.5382\r\n",
      "Train Epoch: 10 [57600/110534 (52%)]\tClassification Loss: 1.5773\r\n",
      "Test() called at step_no: 16443\r\n",
      "\r\n",
      "Test set: Average loss: 1.5583, Accuracy: 1096/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 10 [58240/110534 (53%)]\tClassification Loss: 1.3846\r\n",
      "Train Epoch: 10 [58880/110534 (53%)]\tClassification Loss: 1.7542\r\n",
      "Train Epoch: 10 [59520/110534 (54%)]\tClassification Loss: 1.7253\r\n",
      "Train Epoch: 10 [60160/110534 (54%)]\tClassification Loss: 1.7647\r\n",
      "Train Epoch: 10 [60800/110534 (55%)]\tClassification Loss: 2.0027\r\n",
      "Train Epoch: 10 [61440/110534 (56%)]\tClassification Loss: 1.5601\r\n",
      "Train Epoch: 10 [62080/110534 (56%)]\tClassification Loss: 2.1453\r\n",
      "Train Epoch: 10 [62720/110534 (57%)]\tClassification Loss: 1.4862\r\n",
      "Train Epoch: 10 [63360/110534 (57%)]\tClassification Loss: 1.7136\r\n",
      "Train Epoch: 10 [64000/110534 (58%)]\tClassification Loss: 1.6896\r\n",
      "Test() called at step_no: 16543\r\n",
      "\r\n",
      "Test set: Average loss: 1.5542, Accuracy: 1098/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_1000.pth.tar\r\n",
      "Train Epoch: 10 [64640/110534 (58%)]\tClassification Loss: 1.7820\r\n",
      "Train Epoch: 10 [65280/110534 (59%)]\tClassification Loss: 1.6938\r\n",
      "Train Epoch: 10 [65920/110534 (60%)]\tClassification Loss: 1.4535\r\n",
      "Train Epoch: 10 [66560/110534 (60%)]\tClassification Loss: 1.5959\r\n",
      "Train Epoch: 10 [67200/110534 (61%)]\tClassification Loss: 1.7915\r\n",
      "Train Epoch: 10 [67840/110534 (61%)]\tClassification Loss: 1.3073\r\n",
      "Train Epoch: 10 [68480/110534 (62%)]\tClassification Loss: 1.4977\r\n",
      "Train Epoch: 10 [69120/110534 (63%)]\tClassification Loss: 1.3852\r\n",
      "Train Epoch: 10 [69760/110534 (63%)]\tClassification Loss: 1.5898\r\n",
      "Train Epoch: 10 [70400/110534 (64%)]\tClassification Loss: 1.6082\r\n",
      "Test() called at step_no: 16643\r\n",
      "\r\n",
      "Test set: Average loss: 1.5598, Accuracy: 1091/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 10 [71040/110534 (64%)]\tClassification Loss: 1.5493\r\n",
      "Train Epoch: 10 [71680/110534 (65%)]\tClassification Loss: 1.4647\r\n",
      "Train Epoch: 10 [72320/110534 (65%)]\tClassification Loss: 1.7086\r\n",
      "Train Epoch: 10 [72960/110534 (66%)]\tClassification Loss: 1.6677\r\n",
      "Train Epoch: 10 [73600/110534 (67%)]\tClassification Loss: 1.6159\r\n",
      "Train Epoch: 10 [74240/110534 (67%)]\tClassification Loss: 1.4970\r\n",
      "Train Epoch: 10 [74880/110534 (68%)]\tClassification Loss: 1.5209\r\n",
      "Train Epoch: 10 [75520/110534 (68%)]\tClassification Loss: 1.6572\r\n",
      "Train Epoch: 10 [76160/110534 (69%)]\tClassification Loss: 1.4107\r\n",
      "Train Epoch: 10 [76800/110534 (69%)]\tClassification Loss: 1.4922\r\n",
      "Test() called at step_no: 16743\r\n",
      "\r\n",
      "Test set: Average loss: 1.5557, Accuracy: 1100/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 10 [77440/110534 (70%)]\tClassification Loss: 1.6655\r\n",
      "Train Epoch: 10 [78080/110534 (71%)]\tClassification Loss: 1.6178\r\n",
      "Train Epoch: 10 [78720/110534 (71%)]\tClassification Loss: 1.8056\r\n",
      "Train Epoch: 10 [79360/110534 (72%)]\tClassification Loss: 1.9211\r\n",
      "Train Epoch: 10 [80000/110534 (72%)]\tClassification Loss: 1.5455\r\n",
      "Train Epoch: 10 [80640/110534 (73%)]\tClassification Loss: 1.7310\r\n",
      "Train Epoch: 10 [81280/110534 (74%)]\tClassification Loss: 1.9274\r\n",
      "Train Epoch: 10 [81920/110534 (74%)]\tClassification Loss: 1.2654\r\n",
      "Train Epoch: 10 [82560/110534 (75%)]\tClassification Loss: 1.8985\r\n",
      "Train Epoch: 10 [83200/110534 (75%)]\tClassification Loss: 1.4504\r\n",
      "Test() called at step_no: 16843\r\n",
      "\r\n",
      "Test set: Average loss: 1.5551, Accuracy: 1108/1920 (58%)\r\n",
      "\r\n",
      "Train Epoch: 10 [83840/110534 (76%)]\tClassification Loss: 1.8593\r\n",
      "Train Epoch: 10 [84480/110534 (76%)]\tClassification Loss: 1.6317\r\n",
      "Train Epoch: 10 [85120/110534 (77%)]\tClassification Loss: 1.6050\r\n",
      "Train Epoch: 10 [85760/110534 (78%)]\tClassification Loss: 1.9230\r\n",
      "Train Epoch: 10 [86400/110534 (78%)]\tClassification Loss: 1.8047\r\n",
      "Train Epoch: 10 [87040/110534 (79%)]\tClassification Loss: 1.3679\r\n",
      "Train Epoch: 10 [87680/110534 (79%)]\tClassification Loss: 1.4350\r\n",
      "Train Epoch: 10 [88320/110534 (80%)]\tClassification Loss: 1.5501\r\n",
      "Train Epoch: 10 [88960/110534 (80%)]\tClassification Loss: 1.3619\r\n",
      "Train Epoch: 10 [89600/110534 (81%)]\tClassification Loss: 1.5445\r\n",
      "Test() called at step_no: 16943\r\n",
      "\r\n",
      "Test set: Average loss: 1.5555, Accuracy: 1098/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 10 [90240/110534 (82%)]\tClassification Loss: 1.6330\r\n",
      "Train Epoch: 10 [90880/110534 (82%)]\tClassification Loss: 2.0018\r\n",
      "Train Epoch: 10 [91520/110534 (83%)]\tClassification Loss: 1.5211\r\n",
      "Train Epoch: 10 [92160/110534 (83%)]\tClassification Loss: 1.5420\r\n",
      "Train Epoch: 10 [92800/110534 (84%)]\tClassification Loss: 1.3321\r\n",
      "Train Epoch: 10 [93440/110534 (85%)]\tClassification Loss: 1.1238\r\n",
      "Train Epoch: 10 [94080/110534 (85%)]\tClassification Loss: 1.7529\r\n",
      "Train Epoch: 10 [94720/110534 (86%)]\tClassification Loss: 1.5348\r\n",
      "Train Epoch: 10 [95360/110534 (86%)]\tClassification Loss: 1.4874\r\n",
      "Train Epoch: 10 [96000/110534 (87%)]\tClassification Loss: 1.1469\r\n",
      "Test() called at step_no: 17043\r\n",
      "\r\n",
      "Test set: Average loss: 1.5559, Accuracy: 1091/1920 (57%)\r\n",
      "\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_1500.pth.tar\r\n",
      "Train Epoch: 10 [96640/110534 (87%)]\tClassification Loss: 1.8166\r\n",
      "Train Epoch: 10 [97280/110534 (88%)]\tClassification Loss: 1.4730\r\n",
      "Train Epoch: 10 [97920/110534 (89%)]\tClassification Loss: 1.6443\r\n",
      "Train Epoch: 10 [98560/110534 (89%)]\tClassification Loss: 1.5991\r\n",
      "Train Epoch: 10 [99200/110534 (90%)]\tClassification Loss: 1.6311\r\n",
      "Train Epoch: 10 [99840/110534 (90%)]\tClassification Loss: 1.7491\r\n",
      "Train Epoch: 10 [100480/110534 (91%)]\tClassification Loss: 1.5967\r\n",
      "Train Epoch: 10 [101120/110534 (91%)]\tClassification Loss: 1.6719\r\n",
      "Train Epoch: 10 [101760/110534 (92%)]\tClassification Loss: 1.5786\r\n",
      "Train Epoch: 10 [102400/110534 (93%)]\tClassification Loss: 1.6361\r\n",
      "Test() called at step_no: 17143\r\n",
      "\r\n",
      "Test set: Average loss: 1.5586, Accuracy: 1101/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 10 [103040/110534 (93%)]\tClassification Loss: 1.5391\r\n",
      "Train Epoch: 10 [103680/110534 (94%)]\tClassification Loss: 1.3602\r\n",
      "Train Epoch: 10 [104320/110534 (94%)]\tClassification Loss: 1.4696\r\n",
      "Train Epoch: 10 [104960/110534 (95%)]\tClassification Loss: 1.4826\r\n",
      "Train Epoch: 10 [105600/110534 (96%)]\tClassification Loss: 1.5218\r\n",
      "Train Epoch: 10 [106240/110534 (96%)]\tClassification Loss: 1.5147\r\n",
      "Train Epoch: 10 [106880/110534 (97%)]\tClassification Loss: 1.2417\r\n",
      "Train Epoch: 10 [107520/110534 (97%)]\tClassification Loss: 1.4929\r\n",
      "Train Epoch: 10 [108160/110534 (98%)]\tClassification Loss: 1.6548\r\n",
      "Train Epoch: 10 [108800/110534 (98%)]\tClassification Loss: 1.5614\r\n",
      "Test() called at step_no: 17243\r\n",
      "\r\n",
      "Test set: Average loss: 1.5604, Accuracy: 1095/1920 (57%)\r\n",
      "\r\n",
      "Train Epoch: 10 [109440/110534 (99%)]\tClassification Loss: 1.5382\r\n",
      "Train Epoch: 10 [110080/110534 (100%)]\tClassification Loss: 1.6347\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_final.pth.tar\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jydikJ4fdXdf",
    "colab_type": "code",
    "outputId": "253d2624-ba17-4fef-8bea-4eda61707948",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1584862857505,
     "user_tz": -300,
     "elapsed": 669079,
     "user": {
      "displayName": "Muhammad Ali",
      "photoUrl": "",
      "userId": "15673831022739340207"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "# Freeze=True. LR=0.02. transfer/inshop=False/lr=0.002/May30_13-11-32\n",
    "! python train.py"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Train Epoch: 1 [0/110534 (0%)]\tClassification Loss: 3.2679\r\n",
      "train.py:166: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 3.2928, Accuracy: 894/12800 (7%)\r\n",
      "\r\n",
      "Train Epoch: 1 [640/110534 (1%)]\tClassification Loss: 2.9009\r\n",
      "Train Epoch: 1 [1280/110534 (1%)]\tClassification Loss: 2.7474\r\n",
      "Train Epoch: 1 [1920/110534 (2%)]\tClassification Loss: 2.6479\r\n",
      "Train Epoch: 1 [2560/110534 (2%)]\tClassification Loss: 2.5800\r\n",
      "Train Epoch: 1 [3200/110534 (3%)]\tClassification Loss: 2.2845\r\n",
      "Train Epoch: 1 [3840/110534 (3%)]\tClassification Loss: 2.4172\r\n",
      "Train Epoch: 1 [4480/110534 (4%)]\tClassification Loss: 2.5752\r\n",
      "Train Epoch: 1 [5120/110534 (5%)]\tClassification Loss: 2.3015\r\n",
      "Train Epoch: 1 [5760/110534 (5%)]\tClassification Loss: 2.4090\r\n",
      "Train Epoch: 1 [6400/110534 (6%)]\tClassification Loss: 2.4540\r\n",
      "Train Epoch: 1 [7040/110534 (6%)]\tClassification Loss: 2.3917\r\n",
      "Train Epoch: 1 [7680/110534 (7%)]\tClassification Loss: 2.1372\r\n",
      "Train Epoch: 1 [8320/110534 (8%)]\tClassification Loss: 2.4351\r\n",
      "Train Epoch: 1 [8960/110534 (8%)]\tClassification Loss: 2.1608\r\n",
      "Train Epoch: 1 [9600/110534 (9%)]\tClassification Loss: 2.1623\r\n",
      "Train Epoch: 1 [10240/110534 (9%)]\tClassification Loss: 2.0228\r\n",
      "Train Epoch: 1 [10880/110534 (10%)]\tClassification Loss: 2.2473\r\n",
      "Train Epoch: 1 [11520/110534 (10%)]\tClassification Loss: 2.2258\r\n",
      "Train Epoch: 1 [12160/110534 (11%)]\tClassification Loss: 2.1558\r\n",
      "Train Epoch: 1 [12800/110534 (12%)]\tClassification Loss: 2.1298\r\n",
      "Train Epoch: 1 [13440/110534 (12%)]\tClassification Loss: 2.1383\r\n",
      "Train Epoch: 1 [14080/110534 (13%)]\tClassification Loss: 2.2301\r\n",
      "Train Epoch: 1 [14720/110534 (13%)]\tClassification Loss: 2.3022\r\n",
      "Train Epoch: 1 [15360/110534 (14%)]\tClassification Loss: 2.0419\r\n",
      "Train Epoch: 1 [16000/110534 (14%)]\tClassification Loss: 2.2972\r\n",
      "Train Epoch: 1 [16640/110534 (15%)]\tClassification Loss: 2.2647\r\n",
      "Train Epoch: 1 [17280/110534 (16%)]\tClassification Loss: 2.2355\r\n",
      "Train Epoch: 1 [17920/110534 (16%)]\tClassification Loss: 2.0930\r\n",
      "Train Epoch: 1 [18560/110534 (17%)]\tClassification Loss: 2.0965\r\n",
      "Train Epoch: 1 [19200/110534 (17%)]\tClassification Loss: 1.9741\r\n",
      "Train Epoch: 1 [19840/110534 (18%)]\tClassification Loss: 2.0466\r\n",
      "Train Epoch: 1 [20480/110534 (19%)]\tClassification Loss: 2.1861\r\n",
      "Train Epoch: 1 [21120/110534 (19%)]\tClassification Loss: 1.9595\r\n",
      "Train Epoch: 1 [21760/110534 (20%)]\tClassification Loss: 1.9802\r\n",
      "Train Epoch: 1 [22400/110534 (20%)]\tClassification Loss: 2.1562\r\n",
      "Train Epoch: 1 [23040/110534 (21%)]\tClassification Loss: 1.9745\r\n",
      "Train Epoch: 1 [23680/110534 (21%)]\tClassification Loss: 1.8629\r\n",
      "Train Epoch: 1 [24320/110534 (22%)]\tClassification Loss: 2.0361\r\n",
      "Train Epoch: 1 [24960/110534 (23%)]\tClassification Loss: 2.0497\r\n",
      "Train Epoch: 1 [25600/110534 (23%)]\tClassification Loss: 1.7165\r\n",
      "Train Epoch: 1 [26240/110534 (24%)]\tClassification Loss: 1.9424\r\n",
      "Train Epoch: 1 [26880/110534 (24%)]\tClassification Loss: 2.0970\r\n",
      "Train Epoch: 1 [27520/110534 (25%)]\tClassification Loss: 1.9966\r\n",
      "Train Epoch: 1 [28160/110534 (25%)]\tClassification Loss: 2.0391\r\n",
      "Train Epoch: 1 [28800/110534 (26%)]\tClassification Loss: 1.9477\r\n",
      "Train Epoch: 1 [29440/110534 (27%)]\tClassification Loss: 1.6874\r\n",
      "Train Epoch: 1 [30080/110534 (27%)]\tClassification Loss: 1.9972\r\n",
      "Train Epoch: 1 [30720/110534 (28%)]\tClassification Loss: 1.8603\r\n",
      "Train Epoch: 1 [31360/110534 (28%)]\tClassification Loss: 1.6031\r\n",
      "Train Epoch: 1 [32000/110534 (29%)]\tClassification Loss: 1.9814\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_500.pth.tar\r\n",
      "Train Epoch: 1 [32640/110534 (30%)]\tClassification Loss: 1.8368\r\n",
      "Train Epoch: 1 [33280/110534 (30%)]\tClassification Loss: 1.8970\r\n",
      "Train Epoch: 1 [33920/110534 (31%)]\tClassification Loss: 1.9030\r\n",
      "Train Epoch: 1 [34560/110534 (31%)]\tClassification Loss: 1.9892\r\n",
      "Train Epoch: 1 [35200/110534 (32%)]\tClassification Loss: 1.8536\r\n",
      "Train Epoch: 1 [35840/110534 (32%)]\tClassification Loss: 1.8469\r\n",
      "Train Epoch: 1 [36480/110534 (33%)]\tClassification Loss: 1.7337\r\n",
      "Train Epoch: 1 [37120/110534 (34%)]\tClassification Loss: 2.1609\r\n",
      "Train Epoch: 1 [37760/110534 (34%)]\tClassification Loss: 1.5346\r\n",
      "Train Epoch: 1 [38400/110534 (35%)]\tClassification Loss: 2.0680\r\n",
      "\r\n",
      "Test set: Average loss: 1.8067, Accuracy: 6147/12800 (48%)\r\n",
      "\r\n",
      "Train Epoch: 1 [39040/110534 (35%)]\tClassification Loss: 1.7486\r\n",
      "Train Epoch: 1 [39680/110534 (36%)]\tClassification Loss: 1.9776\r\n",
      "Train Epoch: 1 [40320/110534 (36%)]\tClassification Loss: 2.0124\r\n",
      "Train Epoch: 1 [40960/110534 (37%)]\tClassification Loss: 1.6338\r\n",
      "Train Epoch: 1 [41600/110534 (38%)]\tClassification Loss: 2.0317\r\n",
      "Train Epoch: 1 [42240/110534 (38%)]\tClassification Loss: 2.0157\r\n",
      "Train Epoch: 1 [42880/110534 (39%)]\tClassification Loss: 1.7802\r\n",
      "Train Epoch: 1 [43520/110534 (39%)]\tClassification Loss: 1.9276\r\n",
      "Train Epoch: 1 [44160/110534 (40%)]\tClassification Loss: 1.9493\r\n",
      "Train Epoch: 1 [44800/110534 (41%)]\tClassification Loss: 1.7392\r\n",
      "Train Epoch: 1 [45440/110534 (41%)]\tClassification Loss: 1.6225\r\n",
      "Train Epoch: 1 [46080/110534 (42%)]\tClassification Loss: 1.8829\r\n",
      "Train Epoch: 1 [46720/110534 (42%)]\tClassification Loss: 1.7566\r\n",
      "Train Epoch: 1 [47360/110534 (43%)]\tClassification Loss: 1.6614\r\n",
      "Train Epoch: 1 [48000/110534 (43%)]\tClassification Loss: 2.0309\r\n",
      "Train Epoch: 1 [48640/110534 (44%)]\tClassification Loss: 1.8619\r\n",
      "Train Epoch: 1 [49280/110534 (45%)]\tClassification Loss: 1.7733\r\n",
      "Train Epoch: 1 [49920/110534 (45%)]\tClassification Loss: 1.7521\r\n",
      "Train Epoch: 1 [50560/110534 (46%)]\tClassification Loss: 2.0084\r\n",
      "Train Epoch: 1 [51200/110534 (46%)]\tClassification Loss: 1.7530\r\n",
      "Train Epoch: 1 [51840/110534 (47%)]\tClassification Loss: 1.6871\r\n",
      "Train Epoch: 1 [52480/110534 (47%)]\tClassification Loss: 1.5449\r\n",
      "Train Epoch: 1 [53120/110534 (48%)]\tClassification Loss: 1.8449\r\n",
      "Train Epoch: 1 [53760/110534 (49%)]\tClassification Loss: 1.8938\r\n",
      "Train Epoch: 1 [54400/110534 (49%)]\tClassification Loss: 1.7222\r\n",
      "Train Epoch: 1 [55040/110534 (50%)]\tClassification Loss: 1.4862\r\n",
      "Train Epoch: 1 [55680/110534 (50%)]\tClassification Loss: 1.7425\r\n",
      "Train Epoch: 1 [56320/110534 (51%)]\tClassification Loss: 1.8037\r\n",
      "Train Epoch: 1 [56960/110534 (52%)]\tClassification Loss: 1.8706\r\n",
      "Train Epoch: 1 [57600/110534 (52%)]\tClassification Loss: 1.8010\r\n",
      "Train Epoch: 1 [58240/110534 (53%)]\tClassification Loss: 1.7474\r\n",
      "Train Epoch: 1 [58880/110534 (53%)]\tClassification Loss: 1.7486\r\n",
      "Train Epoch: 1 [59520/110534 (54%)]\tClassification Loss: 1.7496\r\n",
      "Train Epoch: 1 [60160/110534 (54%)]\tClassification Loss: 1.7276\r\n",
      "Train Epoch: 1 [60800/110534 (55%)]\tClassification Loss: 1.7427\r\n",
      "Train Epoch: 1 [61440/110534 (56%)]\tClassification Loss: 1.8570\r\n",
      "Train Epoch: 1 [62080/110534 (56%)]\tClassification Loss: 1.6863\r\n",
      "Train Epoch: 1 [62720/110534 (57%)]\tClassification Loss: 1.8463\r\n",
      "Train Epoch: 1 [63360/110534 (57%)]\tClassification Loss: 1.8705\r\n",
      "Train Epoch: 1 [64000/110534 (58%)]\tClassification Loss: 1.7824\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1000.pth.tar\r\n",
      "Train Epoch: 1 [64640/110534 (58%)]\tClassification Loss: 1.8631\r\n",
      "Train Epoch: 1 [65280/110534 (59%)]\tClassification Loss: 1.8076\r\n",
      "Train Epoch: 1 [65920/110534 (60%)]\tClassification Loss: 1.6302\r\n",
      "Train Epoch: 1 [66560/110534 (60%)]\tClassification Loss: 1.6812\r\n",
      "Train Epoch: 1 [67200/110534 (61%)]\tClassification Loss: 1.9014\r\n",
      "Train Epoch: 1 [67840/110534 (61%)]\tClassification Loss: 1.7857\r\n",
      "Train Epoch: 1 [68480/110534 (62%)]\tClassification Loss: 1.7948\r\n",
      "Train Epoch: 1 [69120/110534 (63%)]\tClassification Loss: 1.8055\r\n",
      "Train Epoch: 1 [69760/110534 (63%)]\tClassification Loss: 1.6733\r\n",
      "Train Epoch: 1 [70400/110534 (64%)]\tClassification Loss: 1.8280\r\n",
      "Train Epoch: 1 [71040/110534 (64%)]\tClassification Loss: 1.8012\r\n",
      "Train Epoch: 1 [71680/110534 (65%)]\tClassification Loss: 1.6780\r\n",
      "Train Epoch: 1 [72320/110534 (65%)]\tClassification Loss: 1.7167\r\n",
      "Train Epoch: 1 [72960/110534 (66%)]\tClassification Loss: 1.5884\r\n",
      "Train Epoch: 1 [73600/110534 (67%)]\tClassification Loss: 1.7533\r\n",
      "Train Epoch: 1 [74240/110534 (67%)]\tClassification Loss: 1.6751\r\n",
      "Train Epoch: 1 [74880/110534 (68%)]\tClassification Loss: 1.6556\r\n",
      "Train Epoch: 1 [75520/110534 (68%)]\tClassification Loss: 1.7860\r\n",
      "Train Epoch: 1 [76160/110534 (69%)]\tClassification Loss: 1.7704\r\n",
      "Train Epoch: 1 [76800/110534 (69%)]\tClassification Loss: 2.0020\r\n",
      "\r\n",
      "Test set: Average loss: 1.6636, Accuracy: 6420/12800 (50%)\r\n",
      "\r\n",
      "Train Epoch: 1 [77440/110534 (70%)]\tClassification Loss: 1.9900\r\n",
      "Train Epoch: 1 [78080/110534 (71%)]\tClassification Loss: 1.5463\r\n",
      "Train Epoch: 1 [78720/110534 (71%)]\tClassification Loss: 1.8302\r\n",
      "Train Epoch: 1 [79360/110534 (72%)]\tClassification Loss: 1.8223\r\n",
      "Train Epoch: 1 [80000/110534 (72%)]\tClassification Loss: 1.6503\r\n",
      "Train Epoch: 1 [80640/110534 (73%)]\tClassification Loss: 1.8623\r\n",
      "Train Epoch: 1 [81280/110534 (74%)]\tClassification Loss: 1.5479\r\n",
      "Train Epoch: 1 [81920/110534 (74%)]\tClassification Loss: 1.7199\r\n",
      "Train Epoch: 1 [82560/110534 (75%)]\tClassification Loss: 1.9109\r\n",
      "Train Epoch: 1 [83200/110534 (75%)]\tClassification Loss: 1.5877\r\n",
      "Train Epoch: 1 [83840/110534 (76%)]\tClassification Loss: 1.9510\r\n",
      "Train Epoch: 1 [84480/110534 (76%)]\tClassification Loss: 1.6249\r\n",
      "Train Epoch: 1 [85120/110534 (77%)]\tClassification Loss: 1.9546\r\n",
      "Train Epoch: 1 [85760/110534 (78%)]\tClassification Loss: 1.5823\r\n",
      "Train Epoch: 1 [86400/110534 (78%)]\tClassification Loss: 1.6613\r\n",
      "Train Epoch: 1 [87040/110534 (79%)]\tClassification Loss: 1.7361\r\n",
      "Train Epoch: 1 [87680/110534 (79%)]\tClassification Loss: 1.8200\r\n",
      "Train Epoch: 1 [88320/110534 (80%)]\tClassification Loss: 1.5666\r\n",
      "Train Epoch: 1 [88960/110534 (80%)]\tClassification Loss: 1.4920\r\n",
      "Train Epoch: 1 [89600/110534 (81%)]\tClassification Loss: 1.7261\r\n",
      "Train Epoch: 1 [90240/110534 (82%)]\tClassification Loss: 1.8982\r\n",
      "Train Epoch: 1 [90880/110534 (82%)]\tClassification Loss: 1.6394\r\n",
      "Train Epoch: 1 [91520/110534 (83%)]\tClassification Loss: 1.7602\r\n",
      "Train Epoch: 1 [92160/110534 (83%)]\tClassification Loss: 1.5793\r\n",
      "Train Epoch: 1 [92800/110534 (84%)]\tClassification Loss: 1.7609\r\n",
      "Train Epoch: 1 [93440/110534 (85%)]\tClassification Loss: 1.8983\r\n",
      "Train Epoch: 1 [94080/110534 (85%)]\tClassification Loss: 1.5569\r\n",
      "Train Epoch: 1 [94720/110534 (86%)]\tClassification Loss: 1.8234\r\n",
      "Train Epoch: 1 [95360/110534 (86%)]\tClassification Loss: 1.7003\r\n",
      "Train Epoch: 1 [96000/110534 (87%)]\tClassification Loss: 2.0311\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1500.pth.tar\r\n",
      "Train Epoch: 1 [96640/110534 (87%)]\tClassification Loss: 1.7165\r\n",
      "Train Epoch: 1 [97280/110534 (88%)]\tClassification Loss: 1.7868\r\n",
      "Train Epoch: 1 [97920/110534 (89%)]\tClassification Loss: 1.7128\r\n",
      "Train Epoch: 1 [98560/110534 (89%)]\tClassification Loss: 1.6310\r\n",
      "Train Epoch: 1 [99200/110534 (90%)]\tClassification Loss: 2.1099\r\n",
      "Train Epoch: 1 [99840/110534 (90%)]\tClassification Loss: 1.5209\r\n",
      "Train Epoch: 1 [100480/110534 (91%)]\tClassification Loss: 1.6938\r\n",
      "Train Epoch: 1 [101120/110534 (91%)]\tClassification Loss: 1.4934\r\n",
      "Train Epoch: 1 [101760/110534 (92%)]\tClassification Loss: 1.8635\r\n",
      "Train Epoch: 1 [102400/110534 (93%)]\tClassification Loss: 1.7441\r\n",
      "Train Epoch: 1 [103040/110534 (93%)]\tClassification Loss: 1.7902\r\n",
      "Train Epoch: 1 [103680/110534 (94%)]\tClassification Loss: 1.5305\r\n",
      "Train Epoch: 1 [104320/110534 (94%)]\tClassification Loss: 1.7179\r\n",
      "Train Epoch: 1 [104960/110534 (95%)]\tClassification Loss: 1.7825\r\n",
      "Train Epoch: 1 [105600/110534 (96%)]\tClassification Loss: 1.9764\r\n",
      "Train Epoch: 1 [106240/110534 (96%)]\tClassification Loss: 1.5947\r\n",
      "Train Epoch: 1 [106880/110534 (97%)]\tClassification Loss: 1.6483\r\n",
      "Train Epoch: 1 [107520/110534 (97%)]\tClassification Loss: 1.5427\r\n",
      "Train Epoch: 1 [108160/110534 (98%)]\tClassification Loss: 1.4528\r\n",
      "Train Epoch: 1 [108800/110534 (98%)]\tClassification Loss: 1.6255\r\n",
      "Train Epoch: 1 [109440/110534 (99%)]\tClassification Loss: 1.6735\r\n",
      "Train Epoch: 1 [110080/110534 (100%)]\tClassification Loss: 1.8213\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_final.pth.tar\r\n",
      "Train Epoch: 2 [0/110534 (0%)]\tClassification Loss: 1.8696\r\n",
      "\r\n",
      "Test set: Average loss: 1.6082, Accuracy: 6568/12800 (51%)\r\n",
      "\r\n",
      "Train Epoch: 2 [640/110534 (1%)]\tClassification Loss: 1.6381\r\n",
      "Train Epoch: 2 [1280/110534 (1%)]\tClassification Loss: 1.6336\r\n",
      "Train Epoch: 2 [1920/110534 (2%)]\tClassification Loss: 1.5522\r\n",
      "Train Epoch: 2 [2560/110534 (2%)]\tClassification Loss: 1.7431\r\n",
      "Train Epoch: 2 [3200/110534 (3%)]\tClassification Loss: 1.4232\r\n",
      "Train Epoch: 2 [3840/110534 (3%)]\tClassification Loss: 1.6941\r\n",
      "Train Epoch: 2 [4480/110534 (4%)]\tClassification Loss: 1.7525\r\n",
      "Train Epoch: 2 [5120/110534 (5%)]\tClassification Loss: 1.6729\r\n",
      "Train Epoch: 2 [5760/110534 (5%)]\tClassification Loss: 1.7878\r\n",
      "Train Epoch: 2 [6400/110534 (6%)]\tClassification Loss: 1.9934\r\n",
      "Train Epoch: 2 [7040/110534 (6%)]\tClassification Loss: 1.8064\r\n",
      "Train Epoch: 2 [7680/110534 (7%)]\tClassification Loss: 1.5712\r\n",
      "Train Epoch: 2 [8320/110534 (8%)]\tClassification Loss: 1.8679\r\n",
      "Train Epoch: 2 [8960/110534 (8%)]\tClassification Loss: 1.6601\r\n",
      "Train Epoch: 2 [9600/110534 (9%)]\tClassification Loss: 1.5964\r\n",
      "Train Epoch: 2 [10240/110534 (9%)]\tClassification Loss: 1.4847\r\n",
      "Train Epoch: 2 [10880/110534 (10%)]\tClassification Loss: 1.7499\r\n",
      "Train Epoch: 2 [11520/110534 (10%)]\tClassification Loss: 1.6758\r\n",
      "Train Epoch: 2 [12160/110534 (11%)]\tClassification Loss: 1.7803\r\n",
      "Train Epoch: 2 [12800/110534 (12%)]\tClassification Loss: 1.7281\r\n",
      "Train Epoch: 2 [13440/110534 (12%)]\tClassification Loss: 1.5687\r\n",
      "Train Epoch: 2 [14080/110534 (13%)]\tClassification Loss: 1.6920\r\n",
      "Train Epoch: 2 [14720/110534 (13%)]\tClassification Loss: 1.7066\r\n",
      "Train Epoch: 2 [15360/110534 (14%)]\tClassification Loss: 1.7933\r\n",
      "Train Epoch: 2 [16000/110534 (14%)]\tClassification Loss: 1.7959\r\n",
      "Train Epoch: 2 [16640/110534 (15%)]\tClassification Loss: 1.6829\r\n",
      "Train Epoch: 2 [17280/110534 (16%)]\tClassification Loss: 1.9056\r\n",
      "Train Epoch: 2 [17920/110534 (16%)]\tClassification Loss: 1.7673\r\n",
      "Train Epoch: 2 [18560/110534 (17%)]\tClassification Loss: 1.6741\r\n",
      "Train Epoch: 2 [19200/110534 (17%)]\tClassification Loss: 1.7321\r\n",
      "Train Epoch: 2 [19840/110534 (18%)]\tClassification Loss: 1.6456\r\n",
      "Train Epoch: 2 [20480/110534 (19%)]\tClassification Loss: 1.8896\r\n",
      "Train Epoch: 2 [21120/110534 (19%)]\tClassification Loss: 1.6731\r\n",
      "Train Epoch: 2 [21760/110534 (20%)]\tClassification Loss: 1.7015\r\n",
      "Train Epoch: 2 [22400/110534 (20%)]\tClassification Loss: 1.7091\r\n",
      "Train Epoch: 2 [23040/110534 (21%)]\tClassification Loss: 1.6586\r\n",
      "Train Epoch: 2 [23680/110534 (21%)]\tClassification Loss: 1.5734\r\n",
      "Train Epoch: 2 [24320/110534 (22%)]\tClassification Loss: 1.7137\r\n",
      "Train Epoch: 2 [24960/110534 (23%)]\tClassification Loss: 1.7685\r\n",
      "Train Epoch: 2 [25600/110534 (23%)]\tClassification Loss: 1.5098\r\n",
      "Train Epoch: 2 [26240/110534 (24%)]\tClassification Loss: 1.5844\r\n",
      "Train Epoch: 2 [26880/110534 (24%)]\tClassification Loss: 1.8445\r\n",
      "Train Epoch: 2 [27520/110534 (25%)]\tClassification Loss: 1.7598\r\n",
      "Train Epoch: 2 [28160/110534 (25%)]\tClassification Loss: 1.6757\r\n",
      "Train Epoch: 2 [28800/110534 (26%)]\tClassification Loss: 1.7359\r\n",
      "Train Epoch: 2 [29440/110534 (27%)]\tClassification Loss: 1.5862\r\n",
      "Train Epoch: 2 [30080/110534 (27%)]\tClassification Loss: 1.7149\r\n",
      "Train Epoch: 2 [30720/110534 (28%)]\tClassification Loss: 1.5072\r\n",
      "Train Epoch: 2 [31360/110534 (28%)]\tClassification Loss: 1.3453\r\n",
      "Train Epoch: 2 [32000/110534 (29%)]\tClassification Loss: 1.7023\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_500.pth.tar\r\n",
      "Train Epoch: 2 [32640/110534 (30%)]\tClassification Loss: 1.6145\r\n",
      "Train Epoch: 2 [33280/110534 (30%)]\tClassification Loss: 1.7126\r\n",
      "Train Epoch: 2 [33920/110534 (31%)]\tClassification Loss: 1.7997\r\n",
      "Train Epoch: 2 [34560/110534 (31%)]\tClassification Loss: 1.6610\r\n",
      "Train Epoch: 2 [35200/110534 (32%)]\tClassification Loss: 1.5761\r\n",
      "Train Epoch: 2 [35840/110534 (32%)]\tClassification Loss: 1.5322\r\n",
      "Train Epoch: 2 [36480/110534 (33%)]\tClassification Loss: 1.6403\r\n",
      "Train Epoch: 2 [37120/110534 (34%)]\tClassification Loss: 1.7844\r\n",
      "Train Epoch: 2 [37760/110534 (34%)]\tClassification Loss: 1.3418\r\n",
      "Train Epoch: 2 [38400/110534 (35%)]\tClassification Loss: 1.8942\r\n",
      "\r\n",
      "Test set: Average loss: 1.5781, Accuracy: 6669/12800 (52%)\r\n",
      "\r\n",
      "Train Epoch: 2 [39040/110534 (35%)]\tClassification Loss: 1.4095\r\n",
      "Train Epoch: 2 [39680/110534 (36%)]\tClassification Loss: 1.7040\r\n",
      "Train Epoch: 2 [40320/110534 (36%)]\tClassification Loss: 1.8798\r\n",
      "Train Epoch: 2 [40960/110534 (37%)]\tClassification Loss: 1.4187\r\n",
      "Train Epoch: 2 [41600/110534 (38%)]\tClassification Loss: 1.8288\r\n",
      "Train Epoch: 2 [42240/110534 (38%)]\tClassification Loss: 1.9589\r\n",
      "Train Epoch: 2 [42880/110534 (39%)]\tClassification Loss: 1.7017\r\n",
      "Train Epoch: 2 [43520/110534 (39%)]\tClassification Loss: 1.4984\r\n",
      "Train Epoch: 2 [44160/110534 (40%)]\tClassification Loss: 1.7672\r\n",
      "Train Epoch: 2 [44800/110534 (41%)]\tClassification Loss: 1.7378\r\n",
      "Train Epoch: 2 [45440/110534 (41%)]\tClassification Loss: 1.4317\r\n",
      "Train Epoch: 2 [46080/110534 (42%)]\tClassification Loss: 1.6747\r\n",
      "Train Epoch: 2 [46720/110534 (42%)]\tClassification Loss: 1.5728\r\n",
      "Train Epoch: 2 [47360/110534 (43%)]\tClassification Loss: 1.6065\r\n",
      "Train Epoch: 2 [48000/110534 (43%)]\tClassification Loss: 1.7330\r\n",
      "Train Epoch: 2 [48640/110534 (44%)]\tClassification Loss: 1.6325\r\n",
      "Train Epoch: 2 [49280/110534 (45%)]\tClassification Loss: 1.5092\r\n",
      "Train Epoch: 2 [49920/110534 (45%)]\tClassification Loss: 1.4679\r\n",
      "Train Epoch: 2 [50560/110534 (46%)]\tClassification Loss: 2.0419\r\n",
      "Train Epoch: 2 [51200/110534 (46%)]\tClassification Loss: 1.7274\r\n",
      "Train Epoch: 2 [51840/110534 (47%)]\tClassification Loss: 1.6747\r\n",
      "Train Epoch: 2 [52480/110534 (47%)]\tClassification Loss: 1.5470\r\n",
      "Train Epoch: 2 [53120/110534 (48%)]\tClassification Loss: 1.6702\r\n",
      "Train Epoch: 2 [53760/110534 (49%)]\tClassification Loss: 1.7623\r\n",
      "Train Epoch: 2 [54400/110534 (49%)]\tClassification Loss: 1.6119\r\n",
      "Train Epoch: 2 [55040/110534 (50%)]\tClassification Loss: 1.5240\r\n",
      "Train Epoch: 2 [55680/110534 (50%)]\tClassification Loss: 1.6537\r\n",
      "Train Epoch: 2 [56320/110534 (51%)]\tClassification Loss: 1.7097\r\n",
      "Train Epoch: 2 [56960/110534 (52%)]\tClassification Loss: 1.9190\r\n",
      "Train Epoch: 2 [57600/110534 (52%)]\tClassification Loss: 1.6122\r\n",
      "Train Epoch: 2 [58240/110534 (53%)]\tClassification Loss: 1.5785\r\n",
      "Train Epoch: 2 [58880/110534 (53%)]\tClassification Loss: 1.4981\r\n",
      "Train Epoch: 2 [59520/110534 (54%)]\tClassification Loss: 1.5343\r\n",
      "Train Epoch: 2 [60160/110534 (54%)]\tClassification Loss: 1.6292\r\n",
      "Train Epoch: 2 [60800/110534 (55%)]\tClassification Loss: 1.5015\r\n",
      "Train Epoch: 2 [61440/110534 (56%)]\tClassification Loss: 1.8984\r\n",
      "Train Epoch: 2 [62080/110534 (56%)]\tClassification Loss: 1.6121\r\n",
      "Train Epoch: 2 [62720/110534 (57%)]\tClassification Loss: 1.7371\r\n",
      "Train Epoch: 2 [63360/110534 (57%)]\tClassification Loss: 1.7367\r\n",
      "Train Epoch: 2 [64000/110534 (58%)]\tClassification Loss: 1.6994\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1000.pth.tar\r\n",
      "Train Epoch: 2 [64640/110534 (58%)]\tClassification Loss: 1.7402\r\n",
      "Train Epoch: 2 [65280/110534 (59%)]\tClassification Loss: 1.8163\r\n",
      "Train Epoch: 2 [65920/110534 (60%)]\tClassification Loss: 1.4465\r\n",
      "Train Epoch: 2 [66560/110534 (60%)]\tClassification Loss: 1.4723\r\n",
      "Train Epoch: 2 [67200/110534 (61%)]\tClassification Loss: 1.6958\r\n",
      "Train Epoch: 2 [67840/110534 (61%)]\tClassification Loss: 1.6440\r\n",
      "Train Epoch: 2 [68480/110534 (62%)]\tClassification Loss: 1.6262\r\n",
      "Train Epoch: 2 [69120/110534 (63%)]\tClassification Loss: 1.3994\r\n",
      "Train Epoch: 2 [69760/110534 (63%)]\tClassification Loss: 1.5170\r\n",
      "Train Epoch: 2 [70400/110534 (64%)]\tClassification Loss: 2.0093\r\n",
      "Train Epoch: 2 [71040/110534 (64%)]\tClassification Loss: 1.6815\r\n",
      "Train Epoch: 2 [71680/110534 (65%)]\tClassification Loss: 1.5982\r\n",
      "Train Epoch: 2 [72320/110534 (65%)]\tClassification Loss: 1.5837\r\n",
      "Train Epoch: 2 [72960/110534 (66%)]\tClassification Loss: 1.3978\r\n",
      "Train Epoch: 2 [73600/110534 (67%)]\tClassification Loss: 1.6808\r\n",
      "Train Epoch: 2 [74240/110534 (67%)]\tClassification Loss: 1.4630\r\n",
      "Train Epoch: 2 [74880/110534 (68%)]\tClassification Loss: 1.5412\r\n",
      "Train Epoch: 2 [75520/110534 (68%)]\tClassification Loss: 1.7690\r\n",
      "Train Epoch: 2 [76160/110534 (69%)]\tClassification Loss: 1.7036\r\n",
      "Train Epoch: 2 [76800/110534 (69%)]\tClassification Loss: 1.9199\r\n",
      "\r\n",
      "Test set: Average loss: 1.5511, Accuracy: 6723/12800 (53%)\r\n",
      "\r\n",
      "Train Epoch: 2 [77440/110534 (70%)]\tClassification Loss: 1.7983\r\n",
      "Train Epoch: 2 [78080/110534 (71%)]\tClassification Loss: 1.5601\r\n",
      "Train Epoch: 2 [78720/110534 (71%)]\tClassification Loss: 1.8029\r\n",
      "Train Epoch: 2 [79360/110534 (72%)]\tClassification Loss: 1.5934\r\n",
      "Train Epoch: 2 [80000/110534 (72%)]\tClassification Loss: 1.5390\r\n",
      "Train Epoch: 2 [80640/110534 (73%)]\tClassification Loss: 1.6967\r\n",
      "Train Epoch: 2 [81280/110534 (74%)]\tClassification Loss: 1.4074\r\n",
      "Train Epoch: 2 [81920/110534 (74%)]\tClassification Loss: 1.6033\r\n",
      "Train Epoch: 2 [82560/110534 (75%)]\tClassification Loss: 1.9315\r\n",
      "Train Epoch: 2 [83200/110534 (75%)]\tClassification Loss: 1.5671\r\n",
      "Train Epoch: 2 [83840/110534 (76%)]\tClassification Loss: 1.8703\r\n",
      "Train Epoch: 2 [84480/110534 (76%)]\tClassification Loss: 1.5683\r\n",
      "Train Epoch: 2 [85120/110534 (77%)]\tClassification Loss: 1.8474\r\n",
      "Train Epoch: 2 [85760/110534 (78%)]\tClassification Loss: 1.5733\r\n",
      "Train Epoch: 2 [86400/110534 (78%)]\tClassification Loss: 1.5858\r\n",
      "Train Epoch: 2 [87040/110534 (79%)]\tClassification Loss: 1.5975\r\n",
      "Train Epoch: 2 [87680/110534 (79%)]\tClassification Loss: 1.7630\r\n",
      "Train Epoch: 2 [88320/110534 (80%)]\tClassification Loss: 1.4008\r\n",
      "Train Epoch: 2 [88960/110534 (80%)]\tClassification Loss: 1.3157\r\n",
      "Train Epoch: 2 [89600/110534 (81%)]\tClassification Loss: 1.5420\r\n",
      "Train Epoch: 2 [90240/110534 (82%)]\tClassification Loss: 1.8362\r\n",
      "Train Epoch: 2 [90880/110534 (82%)]\tClassification Loss: 1.4717\r\n",
      "Train Epoch: 2 [91520/110534 (83%)]\tClassification Loss: 1.6802\r\n",
      "Train Epoch: 2 [92160/110534 (83%)]\tClassification Loss: 1.6064\r\n",
      "Train Epoch: 2 [92800/110534 (84%)]\tClassification Loss: 1.6350\r\n",
      "Train Epoch: 2 [93440/110534 (85%)]\tClassification Loss: 1.5665\r\n",
      "Train Epoch: 2 [94080/110534 (85%)]\tClassification Loss: 1.5381\r\n",
      "Train Epoch: 2 [94720/110534 (86%)]\tClassification Loss: 1.8732\r\n",
      "Train Epoch: 2 [95360/110534 (86%)]\tClassification Loss: 1.5993\r\n",
      "Train Epoch: 2 [96000/110534 (87%)]\tClassification Loss: 1.8951\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1500.pth.tar\r\n",
      "Train Epoch: 2 [96640/110534 (87%)]\tClassification Loss: 1.8386\r\n",
      "Train Epoch: 2 [97280/110534 (88%)]\tClassification Loss: 1.6479\r\n",
      "Train Epoch: 2 [97920/110534 (89%)]\tClassification Loss: 1.4895\r\n",
      "Train Epoch: 2 [98560/110534 (89%)]\tClassification Loss: 1.4055\r\n",
      "Train Epoch: 2 [99200/110534 (90%)]\tClassification Loss: 2.1273\r\n",
      "Train Epoch: 2 [99840/110534 (90%)]\tClassification Loss: 1.4750\r\n",
      "Train Epoch: 2 [100480/110534 (91%)]\tClassification Loss: 1.5409\r\n",
      "Train Epoch: 2 [101120/110534 (91%)]\tClassification Loss: 1.2810\r\n",
      "Train Epoch: 2 [101760/110534 (92%)]\tClassification Loss: 1.8029\r\n",
      "Train Epoch: 2 [102400/110534 (93%)]\tClassification Loss: 1.6882\r\n",
      "Train Epoch: 2 [103040/110534 (93%)]\tClassification Loss: 1.5735\r\n",
      "Train Epoch: 2 [103680/110534 (94%)]\tClassification Loss: 1.4465\r\n",
      "Train Epoch: 2 [104320/110534 (94%)]\tClassification Loss: 1.5304\r\n",
      "Train Epoch: 2 [104960/110534 (95%)]\tClassification Loss: 1.6027\r\n",
      "Train Epoch: 2 [105600/110534 (96%)]\tClassification Loss: 1.8718\r\n",
      "Train Epoch: 2 [106240/110534 (96%)]\tClassification Loss: 1.4760\r\n",
      "Train Epoch: 2 [106880/110534 (97%)]\tClassification Loss: 1.5893\r\n",
      "Train Epoch: 2 [107520/110534 (97%)]\tClassification Loss: 1.5508\r\n",
      "Train Epoch: 2 [108160/110534 (98%)]\tClassification Loss: 1.5251\r\n",
      "Train Epoch: 2 [108800/110534 (98%)]\tClassification Loss: 1.4721\r\n",
      "Train Epoch: 2 [109440/110534 (99%)]\tClassification Loss: 1.6109\r\n",
      "Train Epoch: 2 [110080/110534 (100%)]\tClassification Loss: 1.7367\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_final.pth.tar\r\n",
      "Train Epoch: 3 [0/110534 (0%)]\tClassification Loss: 1.8121\r\n",
      "\r\n",
      "Test set: Average loss: 1.5347, Accuracy: 6817/12800 (53%)\r\n",
      "\r\n",
      "Train Epoch: 3 [640/110534 (1%)]\tClassification Loss: 1.6663\r\n",
      "Train Epoch: 3 [1280/110534 (1%)]\tClassification Loss: 1.6187\r\n",
      "Train Epoch: 3 [1920/110534 (2%)]\tClassification Loss: 1.5529\r\n",
      "Train Epoch: 3 [2560/110534 (2%)]\tClassification Loss: 1.7089\r\n",
      "Train Epoch: 3 [3200/110534 (3%)]\tClassification Loss: 1.4335\r\n",
      "Train Epoch: 3 [3840/110534 (3%)]\tClassification Loss: 1.7929\r\n",
      "Train Epoch: 3 [4480/110534 (4%)]\tClassification Loss: 1.5573\r\n",
      "Train Epoch: 3 [5120/110534 (5%)]\tClassification Loss: 1.5439\r\n",
      "Train Epoch: 3 [5760/110534 (5%)]\tClassification Loss: 1.8023\r\n",
      "Train Epoch: 3 [6400/110534 (6%)]\tClassification Loss: 1.9647\r\n",
      "Train Epoch: 3 [7040/110534 (6%)]\tClassification Loss: 1.7807\r\n",
      "Train Epoch: 3 [7680/110534 (7%)]\tClassification Loss: 1.4606\r\n",
      "Train Epoch: 3 [8320/110534 (8%)]\tClassification Loss: 1.8194\r\n",
      "Train Epoch: 3 [8960/110534 (8%)]\tClassification Loss: 1.5578\r\n",
      "Train Epoch: 3 [9600/110534 (9%)]\tClassification Loss: 1.5697\r\n",
      "Train Epoch: 3 [10240/110534 (9%)]\tClassification Loss: 1.3667\r\n",
      "Train Epoch: 3 [10880/110534 (10%)]\tClassification Loss: 1.5864\r\n",
      "Train Epoch: 3 [11520/110534 (10%)]\tClassification Loss: 1.5191\r\n",
      "Train Epoch: 3 [12160/110534 (11%)]\tClassification Loss: 1.7034\r\n",
      "Train Epoch: 3 [12800/110534 (12%)]\tClassification Loss: 1.8075\r\n",
      "Train Epoch: 3 [13440/110534 (12%)]\tClassification Loss: 1.4480\r\n",
      "Train Epoch: 3 [14080/110534 (13%)]\tClassification Loss: 1.6833\r\n",
      "Train Epoch: 3 [14720/110534 (13%)]\tClassification Loss: 1.6819\r\n",
      "Train Epoch: 3 [15360/110534 (14%)]\tClassification Loss: 1.6858\r\n",
      "Train Epoch: 3 [16000/110534 (14%)]\tClassification Loss: 1.6806\r\n",
      "Train Epoch: 3 [16640/110534 (15%)]\tClassification Loss: 1.6243\r\n",
      "Train Epoch: 3 [17280/110534 (16%)]\tClassification Loss: 1.9996\r\n",
      "Train Epoch: 3 [17920/110534 (16%)]\tClassification Loss: 1.7990\r\n",
      "Train Epoch: 3 [18560/110534 (17%)]\tClassification Loss: 1.6761\r\n",
      "Train Epoch: 3 [19200/110534 (17%)]\tClassification Loss: 1.6026\r\n",
      "Train Epoch: 3 [19840/110534 (18%)]\tClassification Loss: 1.6224\r\n",
      "Train Epoch: 3 [20480/110534 (19%)]\tClassification Loss: 1.6898\r\n",
      "Train Epoch: 3 [21120/110534 (19%)]\tClassification Loss: 1.5476\r\n",
      "Train Epoch: 3 [21760/110534 (20%)]\tClassification Loss: 1.5858\r\n",
      "Train Epoch: 3 [22400/110534 (20%)]\tClassification Loss: 1.5819\r\n",
      "Train Epoch: 3 [23040/110534 (21%)]\tClassification Loss: 1.6029\r\n",
      "Train Epoch: 3 [23680/110534 (21%)]\tClassification Loss: 1.4458\r\n",
      "Train Epoch: 3 [24320/110534 (22%)]\tClassification Loss: 1.7519\r\n",
      "Train Epoch: 3 [24960/110534 (23%)]\tClassification Loss: 1.6170\r\n",
      "Train Epoch: 3 [25600/110534 (23%)]\tClassification Loss: 1.2702\r\n",
      "Train Epoch: 3 [26240/110534 (24%)]\tClassification Loss: 1.6893\r\n",
      "Train Epoch: 3 [26880/110534 (24%)]\tClassification Loss: 1.6770\r\n",
      "Train Epoch: 3 [27520/110534 (25%)]\tClassification Loss: 1.6887\r\n",
      "Train Epoch: 3 [28160/110534 (25%)]\tClassification Loss: 1.7520\r\n",
      "Train Epoch: 3 [28800/110534 (26%)]\tClassification Loss: 1.6118\r\n",
      "Train Epoch: 3 [29440/110534 (27%)]\tClassification Loss: 1.3867\r\n",
      "Train Epoch: 3 [30080/110534 (27%)]\tClassification Loss: 1.6032\r\n",
      "Train Epoch: 3 [30720/110534 (28%)]\tClassification Loss: 1.3384\r\n",
      "Train Epoch: 3 [31360/110534 (28%)]\tClassification Loss: 1.2673\r\n",
      "Train Epoch: 3 [32000/110534 (29%)]\tClassification Loss: 1.8090\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_500.pth.tar\r\n",
      "Train Epoch: 3 [32640/110534 (30%)]\tClassification Loss: 1.6125\r\n",
      "Train Epoch: 3 [33280/110534 (30%)]\tClassification Loss: 1.6048\r\n",
      "Train Epoch: 3 [33920/110534 (31%)]\tClassification Loss: 1.8699\r\n",
      "Train Epoch: 3 [34560/110534 (31%)]\tClassification Loss: 1.7520\r\n",
      "Train Epoch: 3 [35200/110534 (32%)]\tClassification Loss: 1.5988\r\n",
      "Train Epoch: 3 [35840/110534 (32%)]\tClassification Loss: 1.5702\r\n",
      "Train Epoch: 3 [36480/110534 (33%)]\tClassification Loss: 1.5104\r\n",
      "Train Epoch: 3 [37120/110534 (34%)]\tClassification Loss: 1.9001\r\n",
      "Train Epoch: 3 [37760/110534 (34%)]\tClassification Loss: 1.4469\r\n",
      "Train Epoch: 3 [38400/110534 (35%)]\tClassification Loss: 1.6737\r\n",
      "\r\n",
      "Test set: Average loss: 1.5281, Accuracy: 6871/12800 (54%)\r\n",
      "\r\n",
      "Train Epoch: 3 [39040/110534 (35%)]\tClassification Loss: 1.4275\r\n",
      "Train Epoch: 3 [39680/110534 (36%)]\tClassification Loss: 1.6666\r\n",
      "Train Epoch: 3 [40320/110534 (36%)]\tClassification Loss: 1.8151\r\n",
      "Train Epoch: 3 [40960/110534 (37%)]\tClassification Loss: 1.5256\r\n",
      "Train Epoch: 3 [41600/110534 (38%)]\tClassification Loss: 1.9676\r\n",
      "Train Epoch: 3 [42240/110534 (38%)]\tClassification Loss: 1.7756\r\n",
      "Train Epoch: 3 [42880/110534 (39%)]\tClassification Loss: 1.5135\r\n",
      "Train Epoch: 3 [43520/110534 (39%)]\tClassification Loss: 1.5481\r\n",
      "Train Epoch: 3 [44160/110534 (40%)]\tClassification Loss: 1.7500\r\n",
      "Train Epoch: 3 [44800/110534 (41%)]\tClassification Loss: 1.6053\r\n",
      "Train Epoch: 3 [45440/110534 (41%)]\tClassification Loss: 1.3851\r\n",
      "Train Epoch: 3 [46080/110534 (42%)]\tClassification Loss: 1.7134\r\n",
      "Train Epoch: 3 [46720/110534 (42%)]\tClassification Loss: 1.5499\r\n",
      "Train Epoch: 3 [47360/110534 (43%)]\tClassification Loss: 1.5811\r\n",
      "Train Epoch: 3 [48000/110534 (43%)]\tClassification Loss: 1.7339\r\n",
      "Train Epoch: 3 [48640/110534 (44%)]\tClassification Loss: 1.6576\r\n",
      "Train Epoch: 3 [49280/110534 (45%)]\tClassification Loss: 1.4814\r\n",
      "Train Epoch: 3 [49920/110534 (45%)]\tClassification Loss: 1.4766\r\n",
      "Train Epoch: 3 [50560/110534 (46%)]\tClassification Loss: 1.8728\r\n",
      "Train Epoch: 3 [51200/110534 (46%)]\tClassification Loss: 1.5878\r\n",
      "Train Epoch: 3 [51840/110534 (47%)]\tClassification Loss: 1.5968\r\n",
      "Train Epoch: 3 [52480/110534 (47%)]\tClassification Loss: 1.4484\r\n",
      "Train Epoch: 3 [53120/110534 (48%)]\tClassification Loss: 1.6000\r\n",
      "Train Epoch: 3 [53760/110534 (49%)]\tClassification Loss: 1.6944\r\n",
      "Train Epoch: 3 [54400/110534 (49%)]\tClassification Loss: 1.4922\r\n",
      "Train Epoch: 3 [55040/110534 (50%)]\tClassification Loss: 1.3386\r\n",
      "Train Epoch: 3 [55680/110534 (50%)]\tClassification Loss: 1.6611\r\n",
      "Train Epoch: 3 [56320/110534 (51%)]\tClassification Loss: 1.6464\r\n",
      "Train Epoch: 3 [56960/110534 (52%)]\tClassification Loss: 1.8192\r\n",
      "Train Epoch: 3 [57600/110534 (52%)]\tClassification Loss: 1.5832\r\n",
      "Train Epoch: 3 [58240/110534 (53%)]\tClassification Loss: 1.5771\r\n",
      "Train Epoch: 3 [58880/110534 (53%)]\tClassification Loss: 1.4999\r\n",
      "Train Epoch: 3 [59520/110534 (54%)]\tClassification Loss: 1.5620\r\n",
      "Train Epoch: 3 [60160/110534 (54%)]\tClassification Loss: 1.4225\r\n",
      "Train Epoch: 3 [60800/110534 (55%)]\tClassification Loss: 1.5953\r\n",
      "Train Epoch: 3 [61440/110534 (56%)]\tClassification Loss: 1.7862\r\n",
      "Train Epoch: 3 [62080/110534 (56%)]\tClassification Loss: 1.5956\r\n",
      "Train Epoch: 3 [62720/110534 (57%)]\tClassification Loss: 1.6407\r\n",
      "Train Epoch: 3 [63360/110534 (57%)]\tClassification Loss: 1.8428\r\n",
      "Train Epoch: 3 [64000/110534 (58%)]\tClassification Loss: 1.7141\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1000.pth.tar\r\n",
      "Train Epoch: 3 [64640/110534 (58%)]\tClassification Loss: 1.7488\r\n",
      "Train Epoch: 3 [65280/110534 (59%)]\tClassification Loss: 1.7034\r\n",
      "Train Epoch: 3 [65920/110534 (60%)]\tClassification Loss: 1.5159\r\n",
      "Train Epoch: 3 [66560/110534 (60%)]\tClassification Loss: 1.4837\r\n",
      "Train Epoch: 3 [67200/110534 (61%)]\tClassification Loss: 1.7620\r\n",
      "Train Epoch: 3 [67840/110534 (61%)]\tClassification Loss: 1.7134\r\n",
      "Train Epoch: 3 [68480/110534 (62%)]\tClassification Loss: 1.6399\r\n",
      "Train Epoch: 3 [69120/110534 (63%)]\tClassification Loss: 1.4811\r\n",
      "Train Epoch: 3 [69760/110534 (63%)]\tClassification Loss: 1.5561\r\n",
      "Train Epoch: 3 [70400/110534 (64%)]\tClassification Loss: 1.9280\r\n",
      "Train Epoch: 3 [71040/110534 (64%)]\tClassification Loss: 1.6590\r\n",
      "Train Epoch: 3 [71680/110534 (65%)]\tClassification Loss: 1.5554\r\n",
      "Train Epoch: 3 [72320/110534 (65%)]\tClassification Loss: 1.5680\r\n",
      "Train Epoch: 3 [72960/110534 (66%)]\tClassification Loss: 1.4187\r\n",
      "Train Epoch: 3 [73600/110534 (67%)]\tClassification Loss: 1.7105\r\n",
      "Train Epoch: 3 [74240/110534 (67%)]\tClassification Loss: 1.5043\r\n",
      "Train Epoch: 3 [74880/110534 (68%)]\tClassification Loss: 1.5979\r\n",
      "Train Epoch: 3 [75520/110534 (68%)]\tClassification Loss: 1.6982\r\n",
      "Train Epoch: 3 [76160/110534 (69%)]\tClassification Loss: 1.5845\r\n",
      "Train Epoch: 3 [76800/110534 (69%)]\tClassification Loss: 1.8446\r\n",
      "\r\n",
      "Test set: Average loss: 1.5112, Accuracy: 6905/12800 (54%)\r\n",
      "\r\n",
      "Train Epoch: 3 [77440/110534 (70%)]\tClassification Loss: 1.5924\r\n",
      "Train Epoch: 3 [78080/110534 (71%)]\tClassification Loss: 1.5634\r\n",
      "Train Epoch: 3 [78720/110534 (71%)]\tClassification Loss: 1.7891\r\n",
      "Train Epoch: 3 [79360/110534 (72%)]\tClassification Loss: 1.6160\r\n",
      "Train Epoch: 3 [80000/110534 (72%)]\tClassification Loss: 1.4600\r\n",
      "Train Epoch: 3 [80640/110534 (73%)]\tClassification Loss: 1.5171\r\n",
      "Train Epoch: 3 [81280/110534 (74%)]\tClassification Loss: 1.3467\r\n",
      "Train Epoch: 3 [81920/110534 (74%)]\tClassification Loss: 1.6303\r\n",
      "Train Epoch: 3 [82560/110534 (75%)]\tClassification Loss: 1.8360\r\n",
      "Train Epoch: 3 [83200/110534 (75%)]\tClassification Loss: 1.4850\r\n",
      "Train Epoch: 3 [83840/110534 (76%)]\tClassification Loss: 1.8899\r\n",
      "Train Epoch: 3 [84480/110534 (76%)]\tClassification Loss: 1.5666\r\n",
      "Train Epoch: 3 [85120/110534 (77%)]\tClassification Loss: 1.8356\r\n",
      "Train Epoch: 3 [85760/110534 (78%)]\tClassification Loss: 1.4830\r\n",
      "Train Epoch: 3 [86400/110534 (78%)]\tClassification Loss: 1.5488\r\n",
      "Train Epoch: 3 [87040/110534 (79%)]\tClassification Loss: 1.5684\r\n",
      "Train Epoch: 3 [87680/110534 (79%)]\tClassification Loss: 1.5506\r\n",
      "Train Epoch: 3 [88320/110534 (80%)]\tClassification Loss: 1.4298\r\n",
      "Train Epoch: 3 [88960/110534 (80%)]\tClassification Loss: 1.3079\r\n",
      "Train Epoch: 3 [89600/110534 (81%)]\tClassification Loss: 1.5259\r\n",
      "Train Epoch: 3 [90240/110534 (82%)]\tClassification Loss: 1.8207\r\n",
      "Train Epoch: 3 [90880/110534 (82%)]\tClassification Loss: 1.5499\r\n",
      "Train Epoch: 3 [91520/110534 (83%)]\tClassification Loss: 1.5609\r\n",
      "Train Epoch: 3 [92160/110534 (83%)]\tClassification Loss: 1.5795\r\n",
      "Train Epoch: 3 [92800/110534 (84%)]\tClassification Loss: 1.6081\r\n",
      "Train Epoch: 3 [93440/110534 (85%)]\tClassification Loss: 1.6262\r\n",
      "Train Epoch: 3 [94080/110534 (85%)]\tClassification Loss: 1.4451\r\n",
      "Train Epoch: 3 [94720/110534 (86%)]\tClassification Loss: 1.8947\r\n",
      "Train Epoch: 3 [95360/110534 (86%)]\tClassification Loss: 1.4726\r\n",
      "Train Epoch: 3 [96000/110534 (87%)]\tClassification Loss: 2.0023\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1500.pth.tar\r\n",
      "Train Epoch: 3 [96640/110534 (87%)]\tClassification Loss: 1.6881\r\n",
      "Train Epoch: 3 [97280/110534 (88%)]\tClassification Loss: 1.7487\r\n",
      "Train Epoch: 3 [97920/110534 (89%)]\tClassification Loss: 1.5220\r\n",
      "Train Epoch: 3 [98560/110534 (89%)]\tClassification Loss: 1.4847\r\n",
      "Train Epoch: 3 [99200/110534 (90%)]\tClassification Loss: 1.9700\r\n",
      "Train Epoch: 3 [99840/110534 (90%)]\tClassification Loss: 1.4615\r\n",
      "Train Epoch: 3 [100480/110534 (91%)]\tClassification Loss: 1.5882\r\n",
      "Train Epoch: 3 [101120/110534 (91%)]\tClassification Loss: 1.5276\r\n",
      "Train Epoch: 3 [101760/110534 (92%)]\tClassification Loss: 1.8355\r\n",
      "Train Epoch: 3 [102400/110534 (93%)]\tClassification Loss: 1.7532\r\n",
      "Train Epoch: 3 [103040/110534 (93%)]\tClassification Loss: 1.6453\r\n",
      "Train Epoch: 3 [103680/110534 (94%)]\tClassification Loss: 1.3789\r\n",
      "Train Epoch: 3 [104320/110534 (94%)]\tClassification Loss: 1.5645\r\n",
      "Train Epoch: 3 [104960/110534 (95%)]\tClassification Loss: 1.7747\r\n",
      "Train Epoch: 3 [105600/110534 (96%)]\tClassification Loss: 1.9508\r\n",
      "Train Epoch: 3 [106240/110534 (96%)]\tClassification Loss: 1.4584\r\n",
      "Train Epoch: 3 [106880/110534 (97%)]\tClassification Loss: 1.4641\r\n",
      "Train Epoch: 3 [107520/110534 (97%)]\tClassification Loss: 1.4379\r\n",
      "Train Epoch: 3 [108160/110534 (98%)]\tClassification Loss: 1.4483\r\n",
      "Train Epoch: 3 [108800/110534 (98%)]\tClassification Loss: 1.4517\r\n",
      "Train Epoch: 3 [109440/110534 (99%)]\tClassification Loss: 1.4507\r\n",
      "Train Epoch: 3 [110080/110534 (100%)]\tClassification Loss: 1.7606\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_final.pth.tar\r\n",
      "Train Epoch: 4 [0/110534 (0%)]\tClassification Loss: 1.8712\r\n",
      "\r\n",
      "Test set: Average loss: 1.5038, Accuracy: 6919/12800 (54%)\r\n",
      "\r\n",
      "Train Epoch: 4 [640/110534 (1%)]\tClassification Loss: 1.6690\r\n",
      "Train Epoch: 4 [1280/110534 (1%)]\tClassification Loss: 1.6371\r\n",
      "Train Epoch: 4 [1920/110534 (2%)]\tClassification Loss: 1.4580\r\n",
      "Train Epoch: 4 [2560/110534 (2%)]\tClassification Loss: 1.7443\r\n",
      "Train Epoch: 4 [3200/110534 (3%)]\tClassification Loss: 1.4313\r\n",
      "Train Epoch: 4 [3840/110534 (3%)]\tClassification Loss: 1.6095\r\n",
      "Train Epoch: 4 [4480/110534 (4%)]\tClassification Loss: 1.4483\r\n",
      "Train Epoch: 4 [5120/110534 (5%)]\tClassification Loss: 1.6530\r\n",
      "Train Epoch: 4 [5760/110534 (5%)]\tClassification Loss: 1.6468\r\n",
      "Train Epoch: 4 [6400/110534 (6%)]\tClassification Loss: 1.8228\r\n",
      "Train Epoch: 4 [7040/110534 (6%)]\tClassification Loss: 1.8083\r\n",
      "Train Epoch: 4 [7680/110534 (7%)]\tClassification Loss: 1.3829\r\n",
      "Train Epoch: 4 [8320/110534 (8%)]\tClassification Loss: 1.7513\r\n",
      "Train Epoch: 4 [8960/110534 (8%)]\tClassification Loss: 1.5160\r\n",
      "Train Epoch: 4 [9600/110534 (9%)]\tClassification Loss: 1.5919\r\n",
      "Train Epoch: 4 [10240/110534 (9%)]\tClassification Loss: 1.2773\r\n",
      "Train Epoch: 4 [10880/110534 (10%)]\tClassification Loss: 1.6060\r\n",
      "Train Epoch: 4 [11520/110534 (10%)]\tClassification Loss: 1.5930\r\n",
      "Train Epoch: 4 [12160/110534 (11%)]\tClassification Loss: 1.6681\r\n",
      "Train Epoch: 4 [12800/110534 (12%)]\tClassification Loss: 1.7862\r\n",
      "Train Epoch: 4 [13440/110534 (12%)]\tClassification Loss: 1.6122\r\n",
      "Train Epoch: 4 [14080/110534 (13%)]\tClassification Loss: 1.6045\r\n",
      "Train Epoch: 4 [14720/110534 (13%)]\tClassification Loss: 1.5475\r\n",
      "Train Epoch: 4 [15360/110534 (14%)]\tClassification Loss: 1.6439\r\n",
      "Train Epoch: 4 [16000/110534 (14%)]\tClassification Loss: 1.7424\r\n",
      "Train Epoch: 4 [16640/110534 (15%)]\tClassification Loss: 1.6284\r\n",
      "Train Epoch: 4 [17280/110534 (16%)]\tClassification Loss: 1.8090\r\n",
      "Train Epoch: 4 [17920/110534 (16%)]\tClassification Loss: 1.7138\r\n",
      "Train Epoch: 4 [18560/110534 (17%)]\tClassification Loss: 1.6184\r\n",
      "Train Epoch: 4 [19200/110534 (17%)]\tClassification Loss: 1.5087\r\n",
      "Train Epoch: 4 [19840/110534 (18%)]\tClassification Loss: 1.5637\r\n",
      "Train Epoch: 4 [20480/110534 (19%)]\tClassification Loss: 1.8096\r\n",
      "Train Epoch: 4 [21120/110534 (19%)]\tClassification Loss: 1.6160\r\n",
      "Train Epoch: 4 [21760/110534 (20%)]\tClassification Loss: 1.5649\r\n",
      "Train Epoch: 4 [22400/110534 (20%)]\tClassification Loss: 1.5621\r\n",
      "Train Epoch: 4 [23040/110534 (21%)]\tClassification Loss: 1.4290\r\n",
      "Train Epoch: 4 [23680/110534 (21%)]\tClassification Loss: 1.6765\r\n",
      "Train Epoch: 4 [24320/110534 (22%)]\tClassification Loss: 1.5694\r\n",
      "Train Epoch: 4 [24960/110534 (23%)]\tClassification Loss: 1.6575\r\n",
      "Train Epoch: 4 [25600/110534 (23%)]\tClassification Loss: 1.4505\r\n",
      "Train Epoch: 4 [26240/110534 (24%)]\tClassification Loss: 1.6735\r\n",
      "Train Epoch: 4 [26880/110534 (24%)]\tClassification Loss: 1.6410\r\n",
      "Train Epoch: 4 [27520/110534 (25%)]\tClassification Loss: 1.5682\r\n",
      "Train Epoch: 4 [28160/110534 (25%)]\tClassification Loss: 1.5398\r\n",
      "Train Epoch: 4 [28800/110534 (26%)]\tClassification Loss: 1.7008\r\n",
      "Train Epoch: 4 [29440/110534 (27%)]\tClassification Loss: 1.5424\r\n",
      "Train Epoch: 4 [30080/110534 (27%)]\tClassification Loss: 1.7187\r\n",
      "Train Epoch: 4 [30720/110534 (28%)]\tClassification Loss: 1.4209\r\n",
      "Train Epoch: 4 [31360/110534 (28%)]\tClassification Loss: 1.1948\r\n",
      "Train Epoch: 4 [32000/110534 (29%)]\tClassification Loss: 1.6864\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_500.pth.tar\r\n",
      "Train Epoch: 4 [32640/110534 (30%)]\tClassification Loss: 1.6283\r\n",
      "Train Epoch: 4 [33280/110534 (30%)]\tClassification Loss: 1.5347\r\n",
      "Train Epoch: 4 [33920/110534 (31%)]\tClassification Loss: 1.6435\r\n",
      "Train Epoch: 4 [34560/110534 (31%)]\tClassification Loss: 1.7287\r\n",
      "Train Epoch: 4 [35200/110534 (32%)]\tClassification Loss: 1.5312\r\n",
      "Train Epoch: 4 [35840/110534 (32%)]\tClassification Loss: 1.4644\r\n",
      "Train Epoch: 4 [36480/110534 (33%)]\tClassification Loss: 1.6031\r\n",
      "Train Epoch: 4 [37120/110534 (34%)]\tClassification Loss: 1.7895\r\n",
      "Train Epoch: 4 [37760/110534 (34%)]\tClassification Loss: 1.3327\r\n",
      "Train Epoch: 4 [38400/110534 (35%)]\tClassification Loss: 1.7945\r\n",
      "\r\n",
      "Test set: Average loss: 1.5013, Accuracy: 6916/12800 (54%)\r\n",
      "\r\n",
      "Train Epoch: 4 [39040/110534 (35%)]\tClassification Loss: 1.5041\r\n",
      "Train Epoch: 4 [39680/110534 (36%)]\tClassification Loss: 1.6146\r\n",
      "Train Epoch: 4 [40320/110534 (36%)]\tClassification Loss: 1.7640\r\n",
      "Train Epoch: 4 [40960/110534 (37%)]\tClassification Loss: 1.4953\r\n",
      "Train Epoch: 4 [41600/110534 (38%)]\tClassification Loss: 1.9657\r\n",
      "Train Epoch: 4 [42240/110534 (38%)]\tClassification Loss: 1.6379\r\n",
      "Train Epoch: 4 [42880/110534 (39%)]\tClassification Loss: 1.5399\r\n",
      "Train Epoch: 4 [43520/110534 (39%)]\tClassification Loss: 1.4768\r\n",
      "Train Epoch: 4 [44160/110534 (40%)]\tClassification Loss: 1.7077\r\n",
      "Train Epoch: 4 [44800/110534 (41%)]\tClassification Loss: 1.5914\r\n",
      "Train Epoch: 4 [45440/110534 (41%)]\tClassification Loss: 1.3880\r\n",
      "Train Epoch: 4 [46080/110534 (42%)]\tClassification Loss: 1.7867\r\n",
      "Train Epoch: 4 [46720/110534 (42%)]\tClassification Loss: 1.6979\r\n",
      "Train Epoch: 4 [47360/110534 (43%)]\tClassification Loss: 1.3734\r\n",
      "Train Epoch: 4 [48000/110534 (43%)]\tClassification Loss: 1.7220\r\n",
      "Train Epoch: 4 [48640/110534 (44%)]\tClassification Loss: 1.6582\r\n",
      "Train Epoch: 4 [49280/110534 (45%)]\tClassification Loss: 1.5676\r\n",
      "Train Epoch: 4 [49920/110534 (45%)]\tClassification Loss: 1.4188\r\n",
      "Train Epoch: 4 [50560/110534 (46%)]\tClassification Loss: 1.8486\r\n",
      "Train Epoch: 4 [51200/110534 (46%)]\tClassification Loss: 1.5920\r\n",
      "Train Epoch: 4 [51840/110534 (47%)]\tClassification Loss: 1.6555\r\n",
      "Train Epoch: 4 [52480/110534 (47%)]\tClassification Loss: 1.4804\r\n",
      "Train Epoch: 4 [53120/110534 (48%)]\tClassification Loss: 1.5790\r\n",
      "Train Epoch: 4 [53760/110534 (49%)]\tClassification Loss: 1.7002\r\n",
      "Train Epoch: 4 [54400/110534 (49%)]\tClassification Loss: 1.3558\r\n",
      "Train Epoch: 4 [55040/110534 (50%)]\tClassification Loss: 1.3250\r\n",
      "Train Epoch: 4 [55680/110534 (50%)]\tClassification Loss: 1.6900\r\n",
      "Train Epoch: 4 [56320/110534 (51%)]\tClassification Loss: 1.5574\r\n",
      "Train Epoch: 4 [56960/110534 (52%)]\tClassification Loss: 1.9247\r\n",
      "Train Epoch: 4 [57600/110534 (52%)]\tClassification Loss: 1.4979\r\n",
      "Train Epoch: 4 [58240/110534 (53%)]\tClassification Loss: 1.4515\r\n",
      "Train Epoch: 4 [58880/110534 (53%)]\tClassification Loss: 1.4789\r\n",
      "Train Epoch: 4 [59520/110534 (54%)]\tClassification Loss: 1.6339\r\n",
      "Train Epoch: 4 [60160/110534 (54%)]\tClassification Loss: 1.3992\r\n",
      "Train Epoch: 4 [60800/110534 (55%)]\tClassification Loss: 1.6112\r\n",
      "Train Epoch: 4 [61440/110534 (56%)]\tClassification Loss: 1.7713\r\n",
      "Train Epoch: 4 [62080/110534 (56%)]\tClassification Loss: 1.7002\r\n",
      "Train Epoch: 4 [62720/110534 (57%)]\tClassification Loss: 1.4638\r\n",
      "Train Epoch: 4 [63360/110534 (57%)]\tClassification Loss: 1.8725\r\n",
      "Train Epoch: 4 [64000/110534 (58%)]\tClassification Loss: 1.6414\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1000.pth.tar\r\n",
      "Train Epoch: 4 [64640/110534 (58%)]\tClassification Loss: 1.8405\r\n",
      "Train Epoch: 4 [65280/110534 (59%)]\tClassification Loss: 1.7262\r\n",
      "Train Epoch: 4 [65920/110534 (60%)]\tClassification Loss: 1.3784\r\n",
      "Train Epoch: 4 [66560/110534 (60%)]\tClassification Loss: 1.5564\r\n",
      "Train Epoch: 4 [67200/110534 (61%)]\tClassification Loss: 1.6894\r\n",
      "Train Epoch: 4 [67840/110534 (61%)]\tClassification Loss: 1.5692\r\n",
      "Train Epoch: 4 [68480/110534 (62%)]\tClassification Loss: 1.6833\r\n",
      "Train Epoch: 4 [69120/110534 (63%)]\tClassification Loss: 1.3543\r\n",
      "Train Epoch: 4 [69760/110534 (63%)]\tClassification Loss: 1.3418\r\n",
      "Train Epoch: 4 [70400/110534 (64%)]\tClassification Loss: 1.7348\r\n",
      "Train Epoch: 4 [71040/110534 (64%)]\tClassification Loss: 1.7913\r\n",
      "Train Epoch: 4 [71680/110534 (65%)]\tClassification Loss: 1.4603\r\n",
      "Train Epoch: 4 [72320/110534 (65%)]\tClassification Loss: 1.5299\r\n",
      "Train Epoch: 4 [72960/110534 (66%)]\tClassification Loss: 1.4923\r\n",
      "Train Epoch: 4 [73600/110534 (67%)]\tClassification Loss: 1.7303\r\n",
      "Train Epoch: 4 [74240/110534 (67%)]\tClassification Loss: 1.3927\r\n",
      "Train Epoch: 4 [74880/110534 (68%)]\tClassification Loss: 1.4597\r\n",
      "Train Epoch: 4 [75520/110534 (68%)]\tClassification Loss: 1.6714\r\n",
      "Train Epoch: 4 [76160/110534 (69%)]\tClassification Loss: 1.5457\r\n",
      "Train Epoch: 4 [76800/110534 (69%)]\tClassification Loss: 1.7814\r\n",
      "\r\n",
      "Test set: Average loss: 1.4869, Accuracy: 6951/12800 (54%)\r\n",
      "\r\n",
      "Train Epoch: 4 [77440/110534 (70%)]\tClassification Loss: 1.7929\r\n",
      "Train Epoch: 4 [78080/110534 (71%)]\tClassification Loss: 1.5262\r\n",
      "Train Epoch: 4 [78720/110534 (71%)]\tClassification Loss: 1.6598\r\n",
      "Train Epoch: 4 [79360/110534 (72%)]\tClassification Loss: 1.5925\r\n",
      "Train Epoch: 4 [80000/110534 (72%)]\tClassification Loss: 1.4012\r\n",
      "Train Epoch: 4 [80640/110534 (73%)]\tClassification Loss: 1.6292\r\n",
      "Train Epoch: 4 [81280/110534 (74%)]\tClassification Loss: 1.2236\r\n",
      "Train Epoch: 4 [81920/110534 (74%)]\tClassification Loss: 1.4620\r\n",
      "Train Epoch: 4 [82560/110534 (75%)]\tClassification Loss: 1.7491\r\n",
      "Train Epoch: 4 [83200/110534 (75%)]\tClassification Loss: 1.5679\r\n",
      "Train Epoch: 4 [83840/110534 (76%)]\tClassification Loss: 1.8288\r\n",
      "Train Epoch: 4 [84480/110534 (76%)]\tClassification Loss: 1.4304\r\n",
      "Train Epoch: 4 [85120/110534 (77%)]\tClassification Loss: 1.8323\r\n",
      "Train Epoch: 4 [85760/110534 (78%)]\tClassification Loss: 1.6266\r\n",
      "Train Epoch: 4 [86400/110534 (78%)]\tClassification Loss: 1.5919\r\n",
      "Train Epoch: 4 [87040/110534 (79%)]\tClassification Loss: 1.4712\r\n",
      "Train Epoch: 4 [87680/110534 (79%)]\tClassification Loss: 1.5945\r\n",
      "Train Epoch: 4 [88320/110534 (80%)]\tClassification Loss: 1.4022\r\n",
      "Train Epoch: 4 [88960/110534 (80%)]\tClassification Loss: 1.3909\r\n",
      "Train Epoch: 4 [89600/110534 (81%)]\tClassification Loss: 1.5974\r\n",
      "Train Epoch: 4 [90240/110534 (82%)]\tClassification Loss: 1.7137\r\n",
      "Train Epoch: 4 [90880/110534 (82%)]\tClassification Loss: 1.5408\r\n",
      "Train Epoch: 4 [91520/110534 (83%)]\tClassification Loss: 1.6097\r\n",
      "Train Epoch: 4 [92160/110534 (83%)]\tClassification Loss: 1.5321\r\n",
      "Train Epoch: 4 [92800/110534 (84%)]\tClassification Loss: 1.4742\r\n",
      "Train Epoch: 4 [93440/110534 (85%)]\tClassification Loss: 1.4779\r\n",
      "Train Epoch: 4 [94080/110534 (85%)]\tClassification Loss: 1.4898\r\n",
      "Train Epoch: 4 [94720/110534 (86%)]\tClassification Loss: 1.7185\r\n",
      "Train Epoch: 4 [95360/110534 (86%)]\tClassification Loss: 1.4619\r\n",
      "Train Epoch: 4 [96000/110534 (87%)]\tClassification Loss: 1.9488\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1500.pth.tar\r\n",
      "Train Epoch: 4 [96640/110534 (87%)]\tClassification Loss: 1.5873\r\n",
      "Train Epoch: 4 [97280/110534 (88%)]\tClassification Loss: 1.5428\r\n",
      "Train Epoch: 4 [97920/110534 (89%)]\tClassification Loss: 1.5035\r\n",
      "Train Epoch: 4 [98560/110534 (89%)]\tClassification Loss: 1.5009\r\n",
      "Train Epoch: 4 [99200/110534 (90%)]\tClassification Loss: 2.0697\r\n",
      "Train Epoch: 4 [99840/110534 (90%)]\tClassification Loss: 1.4832\r\n",
      "Train Epoch: 4 [100480/110534 (91%)]\tClassification Loss: 1.5010\r\n",
      "Train Epoch: 4 [101120/110534 (91%)]\tClassification Loss: 1.3656\r\n",
      "Train Epoch: 4 [101760/110534 (92%)]\tClassification Loss: 1.7536\r\n",
      "Train Epoch: 4 [102400/110534 (93%)]\tClassification Loss: 1.6937\r\n",
      "Train Epoch: 4 [103040/110534 (93%)]\tClassification Loss: 1.6053\r\n",
      "Train Epoch: 4 [103680/110534 (94%)]\tClassification Loss: 1.4654\r\n",
      "Train Epoch: 4 [104320/110534 (94%)]\tClassification Loss: 1.5187\r\n",
      "Train Epoch: 4 [104960/110534 (95%)]\tClassification Loss: 1.7187\r\n",
      "Train Epoch: 4 [105600/110534 (96%)]\tClassification Loss: 1.8623\r\n",
      "Train Epoch: 4 [106240/110534 (96%)]\tClassification Loss: 1.4524\r\n",
      "Train Epoch: 4 [106880/110534 (97%)]\tClassification Loss: 1.5042\r\n",
      "Train Epoch: 4 [107520/110534 (97%)]\tClassification Loss: 1.4582\r\n",
      "Train Epoch: 4 [108160/110534 (98%)]\tClassification Loss: 1.3222\r\n",
      "Train Epoch: 4 [108800/110534 (98%)]\tClassification Loss: 1.4881\r\n",
      "Train Epoch: 4 [109440/110534 (99%)]\tClassification Loss: 1.6348\r\n",
      "Train Epoch: 4 [110080/110534 (100%)]\tClassification Loss: 1.6868\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_final.pth.tar\r\n",
      "Train Epoch: 5 [0/110534 (0%)]\tClassification Loss: 1.8114\r\n",
      "\r\n",
      "Test set: Average loss: 1.4842, Accuracy: 6949/12800 (54%)\r\n",
      "\r\n",
      "Train Epoch: 5 [640/110534 (1%)]\tClassification Loss: 1.6458\r\n",
      "Train Epoch: 5 [1280/110534 (1%)]\tClassification Loss: 1.5799\r\n",
      "Train Epoch: 5 [1920/110534 (2%)]\tClassification Loss: 1.5884\r\n",
      "Train Epoch: 5 [2560/110534 (2%)]\tClassification Loss: 1.6837\r\n",
      "Train Epoch: 5 [3200/110534 (3%)]\tClassification Loss: 1.3734\r\n",
      "Train Epoch: 5 [3840/110534 (3%)]\tClassification Loss: 1.6885\r\n",
      "Train Epoch: 5 [4480/110534 (4%)]\tClassification Loss: 1.5184\r\n",
      "Train Epoch: 5 [5120/110534 (5%)]\tClassification Loss: 1.6721\r\n",
      "Train Epoch: 5 [5760/110534 (5%)]\tClassification Loss: 1.7874\r\n",
      "Train Epoch: 5 [6400/110534 (6%)]\tClassification Loss: 1.9466\r\n",
      "Train Epoch: 5 [7040/110534 (6%)]\tClassification Loss: 1.6834\r\n",
      "Train Epoch: 5 [7680/110534 (7%)]\tClassification Loss: 1.5006\r\n",
      "Train Epoch: 5 [8320/110534 (8%)]\tClassification Loss: 1.7935\r\n",
      "Train Epoch: 5 [8960/110534 (8%)]\tClassification Loss: 1.5589\r\n",
      "Train Epoch: 5 [9600/110534 (9%)]\tClassification Loss: 1.4459\r\n",
      "Train Epoch: 5 [10240/110534 (9%)]\tClassification Loss: 1.3968\r\n",
      "Train Epoch: 5 [10880/110534 (10%)]\tClassification Loss: 1.5087\r\n",
      "Train Epoch: 5 [11520/110534 (10%)]\tClassification Loss: 1.6825\r\n",
      "Train Epoch: 5 [12160/110534 (11%)]\tClassification Loss: 1.6153\r\n",
      "Train Epoch: 5 [12800/110534 (12%)]\tClassification Loss: 1.5334\r\n",
      "Train Epoch: 5 [13440/110534 (12%)]\tClassification Loss: 1.6082\r\n",
      "Train Epoch: 5 [14080/110534 (13%)]\tClassification Loss: 1.5804\r\n",
      "Train Epoch: 5 [14720/110534 (13%)]\tClassification Loss: 1.5098\r\n",
      "Train Epoch: 5 [15360/110534 (14%)]\tClassification Loss: 1.5684\r\n",
      "Train Epoch: 5 [16000/110534 (14%)]\tClassification Loss: 1.8597\r\n",
      "Train Epoch: 5 [16640/110534 (15%)]\tClassification Loss: 1.5610\r\n",
      "Train Epoch: 5 [17280/110534 (16%)]\tClassification Loss: 1.8374\r\n",
      "Train Epoch: 5 [17920/110534 (16%)]\tClassification Loss: 1.7810\r\n",
      "Train Epoch: 5 [18560/110534 (17%)]\tClassification Loss: 1.6242\r\n",
      "Train Epoch: 5 [19200/110534 (17%)]\tClassification Loss: 1.3922\r\n",
      "Train Epoch: 5 [19840/110534 (18%)]\tClassification Loss: 1.4885\r\n",
      "Train Epoch: 5 [20480/110534 (19%)]\tClassification Loss: 1.6284\r\n",
      "Train Epoch: 5 [21120/110534 (19%)]\tClassification Loss: 1.4710\r\n",
      "Train Epoch: 5 [21760/110534 (20%)]\tClassification Loss: 1.5116\r\n",
      "Train Epoch: 5 [22400/110534 (20%)]\tClassification Loss: 1.6047\r\n",
      "Train Epoch: 5 [23040/110534 (21%)]\tClassification Loss: 1.5885\r\n",
      "Train Epoch: 5 [23680/110534 (21%)]\tClassification Loss: 1.4822\r\n",
      "Train Epoch: 5 [24320/110534 (22%)]\tClassification Loss: 1.5581\r\n",
      "Train Epoch: 5 [24960/110534 (23%)]\tClassification Loss: 1.5999\r\n",
      "Train Epoch: 5 [25600/110534 (23%)]\tClassification Loss: 1.2585\r\n",
      "Train Epoch: 5 [26240/110534 (24%)]\tClassification Loss: 1.6131\r\n",
      "Train Epoch: 5 [26880/110534 (24%)]\tClassification Loss: 1.7050\r\n",
      "Train Epoch: 5 [27520/110534 (25%)]\tClassification Loss: 1.6484\r\n",
      "Train Epoch: 5 [28160/110534 (25%)]\tClassification Loss: 1.7070\r\n",
      "Train Epoch: 5 [28800/110534 (26%)]\tClassification Loss: 1.6300\r\n",
      "Train Epoch: 5 [29440/110534 (27%)]\tClassification Loss: 1.5062\r\n",
      "Train Epoch: 5 [30080/110534 (27%)]\tClassification Loss: 1.5947\r\n",
      "Train Epoch: 5 [30720/110534 (28%)]\tClassification Loss: 1.3920\r\n",
      "Train Epoch: 5 [31360/110534 (28%)]\tClassification Loss: 1.3371\r\n",
      "Train Epoch: 5 [32000/110534 (29%)]\tClassification Loss: 1.6820\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_500.pth.tar\r\n",
      "Train Epoch: 5 [32640/110534 (30%)]\tClassification Loss: 1.5071\r\n",
      "Train Epoch: 5 [33280/110534 (30%)]\tClassification Loss: 1.4869\r\n",
      "Train Epoch: 5 [33920/110534 (31%)]\tClassification Loss: 1.8050\r\n",
      "Train Epoch: 5 [34560/110534 (31%)]\tClassification Loss: 1.6730\r\n",
      "Train Epoch: 5 [35200/110534 (32%)]\tClassification Loss: 1.6121\r\n",
      "Train Epoch: 5 [35840/110534 (32%)]\tClassification Loss: 1.5300\r\n",
      "Train Epoch: 5 [36480/110534 (33%)]\tClassification Loss: 1.5524\r\n",
      "Train Epoch: 5 [37120/110534 (34%)]\tClassification Loss: 1.7696\r\n",
      "Train Epoch: 5 [37760/110534 (34%)]\tClassification Loss: 1.4122\r\n",
      "Train Epoch: 5 [38400/110534 (35%)]\tClassification Loss: 1.7665\r\n",
      "\r\n",
      "Test set: Average loss: 1.4860, Accuracy: 6949/12800 (54%)\r\n",
      "\r\n",
      "Train Epoch: 5 [39040/110534 (35%)]\tClassification Loss: 1.3854\r\n",
      "Train Epoch: 5 [39680/110534 (36%)]\tClassification Loss: 1.7998\r\n",
      "Train Epoch: 5 [40320/110534 (36%)]\tClassification Loss: 1.7741\r\n",
      "Train Epoch: 5 [40960/110534 (37%)]\tClassification Loss: 1.3165\r\n",
      "Train Epoch: 5 [41600/110534 (38%)]\tClassification Loss: 1.8483\r\n",
      "Train Epoch: 5 [42240/110534 (38%)]\tClassification Loss: 1.7749\r\n",
      "Train Epoch: 5 [42880/110534 (39%)]\tClassification Loss: 1.5881\r\n",
      "Train Epoch: 5 [43520/110534 (39%)]\tClassification Loss: 1.4332\r\n",
      "Train Epoch: 5 [44160/110534 (40%)]\tClassification Loss: 1.5963\r\n",
      "Train Epoch: 5 [44800/110534 (41%)]\tClassification Loss: 1.5080\r\n",
      "Train Epoch: 5 [45440/110534 (41%)]\tClassification Loss: 1.4344\r\n",
      "Train Epoch: 5 [46080/110534 (42%)]\tClassification Loss: 1.7065\r\n",
      "Train Epoch: 5 [46720/110534 (42%)]\tClassification Loss: 1.4982\r\n",
      "Train Epoch: 5 [47360/110534 (43%)]\tClassification Loss: 1.4457\r\n",
      "Train Epoch: 5 [48000/110534 (43%)]\tClassification Loss: 1.7363\r\n",
      "Train Epoch: 5 [48640/110534 (44%)]\tClassification Loss: 1.6950\r\n",
      "Train Epoch: 5 [49280/110534 (45%)]\tClassification Loss: 1.5265\r\n",
      "Train Epoch: 5 [49920/110534 (45%)]\tClassification Loss: 1.4482\r\n",
      "Train Epoch: 5 [50560/110534 (46%)]\tClassification Loss: 1.8368\r\n",
      "Train Epoch: 5 [51200/110534 (46%)]\tClassification Loss: 1.6001\r\n",
      "Train Epoch: 5 [51840/110534 (47%)]\tClassification Loss: 1.6085\r\n",
      "Train Epoch: 5 [52480/110534 (47%)]\tClassification Loss: 1.4641\r\n",
      "Train Epoch: 5 [53120/110534 (48%)]\tClassification Loss: 1.5747\r\n",
      "Train Epoch: 5 [53760/110534 (49%)]\tClassification Loss: 1.7890\r\n",
      "Train Epoch: 5 [54400/110534 (49%)]\tClassification Loss: 1.5903\r\n",
      "Train Epoch: 5 [55040/110534 (50%)]\tClassification Loss: 1.3484\r\n",
      "Train Epoch: 5 [55680/110534 (50%)]\tClassification Loss: 1.6406\r\n",
      "Train Epoch: 5 [56320/110534 (51%)]\tClassification Loss: 1.5599\r\n",
      "Train Epoch: 5 [56960/110534 (52%)]\tClassification Loss: 1.9094\r\n",
      "Train Epoch: 5 [57600/110534 (52%)]\tClassification Loss: 1.5674\r\n",
      "Train Epoch: 5 [58240/110534 (53%)]\tClassification Loss: 1.4716\r\n",
      "Train Epoch: 5 [58880/110534 (53%)]\tClassification Loss: 1.6348\r\n",
      "Train Epoch: 5 [59520/110534 (54%)]\tClassification Loss: 1.6959\r\n",
      "Train Epoch: 5 [60160/110534 (54%)]\tClassification Loss: 1.4075\r\n",
      "Train Epoch: 5 [60800/110534 (55%)]\tClassification Loss: 1.5349\r\n",
      "Train Epoch: 5 [61440/110534 (56%)]\tClassification Loss: 1.7207\r\n",
      "Train Epoch: 5 [62080/110534 (56%)]\tClassification Loss: 1.6134\r\n",
      "Train Epoch: 5 [62720/110534 (57%)]\tClassification Loss: 1.6306\r\n",
      "Train Epoch: 5 [63360/110534 (57%)]\tClassification Loss: 1.6866\r\n",
      "Train Epoch: 5 [64000/110534 (58%)]\tClassification Loss: 1.6900\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_1000.pth.tar\r\n",
      "Train Epoch: 5 [64640/110534 (58%)]\tClassification Loss: 1.7559\r\n",
      "Train Epoch: 5 [65280/110534 (59%)]\tClassification Loss: 1.7250\r\n",
      "Train Epoch: 5 [65920/110534 (60%)]\tClassification Loss: 1.5363\r\n",
      "Train Epoch: 5 [66560/110534 (60%)]\tClassification Loss: 1.3833\r\n",
      "Train Epoch: 5 [67200/110534 (61%)]\tClassification Loss: 1.6018\r\n",
      "Train Epoch: 5 [67840/110534 (61%)]\tClassification Loss: 1.5459\r\n",
      "Train Epoch: 5 [68480/110534 (62%)]\tClassification Loss: 1.6279\r\n",
      "Train Epoch: 5 [69120/110534 (63%)]\tClassification Loss: 1.4471\r\n",
      "Train Epoch: 5 [69760/110534 (63%)]\tClassification Loss: 1.3081\r\n",
      "Train Epoch: 5 [70400/110534 (64%)]\tClassification Loss: 1.9168\r\n",
      "Train Epoch: 5 [71040/110534 (64%)]\tClassification Loss: 1.6922\r\n",
      "Train Epoch: 5 [71680/110534 (65%)]\tClassification Loss: 1.2990\r\n",
      "Train Epoch: 5 [72320/110534 (65%)]\tClassification Loss: 1.4641\r\n",
      "Train Epoch: 5 [72960/110534 (66%)]\tClassification Loss: 1.3957\r\n",
      "Train Epoch: 5 [73600/110534 (67%)]\tClassification Loss: 1.7221\r\n",
      "Train Epoch: 5 [74240/110534 (67%)]\tClassification Loss: 1.5770\r\n",
      "Train Epoch: 5 [74880/110534 (68%)]\tClassification Loss: 1.4501\r\n",
      "Train Epoch: 5 [75520/110534 (68%)]\tClassification Loss: 1.7305\r\n",
      "Train Epoch: 5 [76160/110534 (69%)]\tClassification Loss: 1.6717\r\n",
      "Train Epoch: 5 [76800/110534 (69%)]\tClassification Loss: 1.7036\r\n",
      "\r\n",
      "Test set: Average loss: 1.4717, Accuracy: 6980/12800 (55%)\r\n",
      "\r\n",
      "Train Epoch: 5 [77440/110534 (70%)]\tClassification Loss: 1.6213\r\n",
      "Train Epoch: 5 [78080/110534 (71%)]\tClassification Loss: 1.5618\r\n",
      "Train Epoch: 5 [78720/110534 (71%)]\tClassification Loss: 1.5814\r\n",
      "Train Epoch: 5 [79360/110534 (72%)]\tClassification Loss: 1.8060\r\n",
      "Train Epoch: 5 [80000/110534 (72%)]\tClassification Loss: 1.4515\r\n",
      "Train Epoch: 5 [80640/110534 (73%)]\tClassification Loss: 1.3956\r\n",
      "Train Epoch: 5 [81280/110534 (74%)]\tClassification Loss: 1.2955\r\n",
      "Train Epoch: 5 [81920/110534 (74%)]\tClassification Loss: 1.6434\r\n",
      "Train Epoch: 5 [82560/110534 (75%)]\tClassification Loss: 1.9351\r\n",
      "Train Epoch: 5 [83200/110534 (75%)]\tClassification Loss: 1.3551\r\n",
      "Train Epoch: 5 [83840/110534 (76%)]\tClassification Loss: 1.8648\r\n",
      "Train Epoch: 5 [84480/110534 (76%)]\tClassification Loss: 1.3908\r\n",
      "Train Epoch: 5 [85120/110534 (77%)]\tClassification Loss: 1.7484\r\n",
      "Train Epoch: 5 [85760/110534 (78%)]\tClassification Loss: 1.6012\r\n",
      "Train Epoch: 5 [86400/110534 (78%)]\tClassification Loss: 1.6749\r\n",
      "Train Epoch: 5 [87040/110534 (79%)]\tClassification Loss: 1.4427\r\n",
      "Train Epoch: 5 [87680/110534 (79%)]\tClassification Loss: 1.6211\r\n",
      "Train Epoch: 5 [88320/110534 (80%)]\tClassification Loss: 1.4122\r\n",
      "Train Epoch: 5 [88960/110534 (80%)]\tClassification Loss: 1.2981\r\n",
      "Train Epoch: 5 [89600/110534 (81%)]\tClassification Loss: 1.4527\r\n",
      "Train Epoch: 5 [90240/110534 (82%)]\tClassification Loss: 1.7909\r\n",
      "Train Epoch: 5 [90880/110534 (82%)]\tClassification Loss: 1.5184\r\n",
      "Train Epoch: 5 [91520/110534 (83%)]\tClassification Loss: 1.4561\r\n",
      "Train Epoch: 5 [92160/110534 (83%)]\tClassification Loss: 1.4503\r\n",
      "Train Epoch: 5 [92800/110534 (84%)]\tClassification Loss: 1.4563\r\n",
      "Train Epoch: 5 [93440/110534 (85%)]\tClassification Loss: 1.5390\r\n",
      "Train Epoch: 5 [94080/110534 (85%)]\tClassification Loss: 1.3170\r\n",
      "Train Epoch: 5 [94720/110534 (86%)]\tClassification Loss: 1.7746\r\n",
      "Train Epoch: 5 [95360/110534 (86%)]\tClassification Loss: 1.5618\r\n",
      "Train Epoch: 5 [96000/110534 (87%)]\tClassification Loss: 1.8519\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_1500.pth.tar\r\n",
      "Train Epoch: 5 [96640/110534 (87%)]\tClassification Loss: 1.6642\r\n",
      "Train Epoch: 5 [97280/110534 (88%)]\tClassification Loss: 1.5074\r\n",
      "Train Epoch: 5 [97920/110534 (89%)]\tClassification Loss: 1.5561\r\n",
      "Train Epoch: 5 [98560/110534 (89%)]\tClassification Loss: 1.5241\r\n",
      "Train Epoch: 5 [99200/110534 (90%)]\tClassification Loss: 2.0007\r\n",
      "Train Epoch: 5 [99840/110534 (90%)]\tClassification Loss: 1.5811\r\n",
      "Train Epoch: 5 [100480/110534 (91%)]\tClassification Loss: 1.5638\r\n",
      "Train Epoch: 5 [101120/110534 (91%)]\tClassification Loss: 1.3257\r\n",
      "Train Epoch: 5 [101760/110534 (92%)]\tClassification Loss: 1.7551\r\n",
      "Train Epoch: 5 [102400/110534 (93%)]\tClassification Loss: 1.7804\r\n",
      "Train Epoch: 5 [103040/110534 (93%)]\tClassification Loss: 1.6864\r\n",
      "Train Epoch: 5 [103680/110534 (94%)]\tClassification Loss: 1.3796\r\n",
      "Train Epoch: 5 [104320/110534 (94%)]\tClassification Loss: 1.5287\r\n",
      "Train Epoch: 5 [104960/110534 (95%)]\tClassification Loss: 1.5855\r\n",
      "Train Epoch: 5 [105600/110534 (96%)]\tClassification Loss: 1.7431\r\n",
      "Train Epoch: 5 [106240/110534 (96%)]\tClassification Loss: 1.4128\r\n",
      "Train Epoch: 5 [106880/110534 (97%)]\tClassification Loss: 1.6600\r\n",
      "Train Epoch: 5 [107520/110534 (97%)]\tClassification Loss: 1.5873\r\n",
      "Train Epoch: 5 [108160/110534 (98%)]\tClassification Loss: 1.3598\r\n",
      "Train Epoch: 5 [108800/110534 (98%)]\tClassification Loss: 1.4435\r\n",
      "Train Epoch: 5 [109440/110534 (99%)]\tClassification Loss: 1.5342\r\n",
      "Train Epoch: 5 [110080/110534 (100%)]\tClassification Loss: 1.7033\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_final.pth.tar\r\n",
      "Train Epoch: 6 [0/110534 (0%)]\tClassification Loss: 1.6843\r\n",
      "\r\n",
      "Test set: Average loss: 1.4719, Accuracy: 6999/12800 (55%)\r\n",
      "\r\n",
      "Train Epoch: 6 [640/110534 (1%)]\tClassification Loss: 1.4710\r\n",
      "Train Epoch: 6 [1280/110534 (1%)]\tClassification Loss: 1.5371\r\n",
      "Train Epoch: 6 [1920/110534 (2%)]\tClassification Loss: 1.4618\r\n",
      "Train Epoch: 6 [2560/110534 (2%)]\tClassification Loss: 1.6009\r\n",
      "Train Epoch: 6 [3200/110534 (3%)]\tClassification Loss: 1.5540\r\n",
      "Train Epoch: 6 [3840/110534 (3%)]\tClassification Loss: 1.6807\r\n",
      "Train Epoch: 6 [4480/110534 (4%)]\tClassification Loss: 1.4920\r\n",
      "Train Epoch: 6 [5120/110534 (5%)]\tClassification Loss: 1.5078\r\n",
      "Train Epoch: 6 [5760/110534 (5%)]\tClassification Loss: 1.6671\r\n",
      "Train Epoch: 6 [6400/110534 (6%)]\tClassification Loss: 1.8100\r\n",
      "Train Epoch: 6 [7040/110534 (6%)]\tClassification Loss: 1.5860\r\n",
      "Train Epoch: 6 [7680/110534 (7%)]\tClassification Loss: 1.4342\r\n",
      "Train Epoch: 6 [8320/110534 (8%)]\tClassification Loss: 1.8101\r\n",
      "Train Epoch: 6 [8960/110534 (8%)]\tClassification Loss: 1.7884\r\n",
      "Train Epoch: 6 [9600/110534 (9%)]\tClassification Loss: 1.5128\r\n",
      "Train Epoch: 6 [10240/110534 (9%)]\tClassification Loss: 1.2832\r\n",
      "Train Epoch: 6 [10880/110534 (10%)]\tClassification Loss: 1.6077\r\n",
      "Train Epoch: 6 [11520/110534 (10%)]\tClassification Loss: 1.6084\r\n",
      "Train Epoch: 6 [12160/110534 (11%)]\tClassification Loss: 1.6122\r\n",
      "Train Epoch: 6 [12800/110534 (12%)]\tClassification Loss: 1.8295\r\n",
      "Train Epoch: 6 [13440/110534 (12%)]\tClassification Loss: 1.5038\r\n",
      "Train Epoch: 6 [14080/110534 (13%)]\tClassification Loss: 1.6289\r\n",
      "Train Epoch: 6 [14720/110534 (13%)]\tClassification Loss: 1.7322\r\n",
      "Train Epoch: 6 [15360/110534 (14%)]\tClassification Loss: 1.5348\r\n",
      "Train Epoch: 6 [16000/110534 (14%)]\tClassification Loss: 1.7773\r\n",
      "Train Epoch: 6 [16640/110534 (15%)]\tClassification Loss: 1.5264\r\n",
      "Train Epoch: 6 [17280/110534 (16%)]\tClassification Loss: 1.8894\r\n",
      "Train Epoch: 6 [17920/110534 (16%)]\tClassification Loss: 1.7591\r\n",
      "Train Epoch: 6 [18560/110534 (17%)]\tClassification Loss: 1.5688\r\n",
      "Train Epoch: 6 [19200/110534 (17%)]\tClassification Loss: 1.5238\r\n",
      "Train Epoch: 6 [19840/110534 (18%)]\tClassification Loss: 1.5180\r\n",
      "Train Epoch: 6 [20480/110534 (19%)]\tClassification Loss: 1.6262\r\n",
      "Train Epoch: 6 [21120/110534 (19%)]\tClassification Loss: 1.4053\r\n",
      "Train Epoch: 6 [21760/110534 (20%)]\tClassification Loss: 1.4326\r\n",
      "Train Epoch: 6 [22400/110534 (20%)]\tClassification Loss: 1.7540\r\n",
      "Train Epoch: 6 [23040/110534 (21%)]\tClassification Loss: 1.5478\r\n",
      "Train Epoch: 6 [23680/110534 (21%)]\tClassification Loss: 1.3752\r\n",
      "Train Epoch: 6 [24320/110534 (22%)]\tClassification Loss: 1.5781\r\n",
      "Train Epoch: 6 [24960/110534 (23%)]\tClassification Loss: 1.4492\r\n",
      "Train Epoch: 6 [25600/110534 (23%)]\tClassification Loss: 1.3418\r\n",
      "Train Epoch: 6 [26240/110534 (24%)]\tClassification Loss: 1.4903\r\n",
      "Train Epoch: 6 [26880/110534 (24%)]\tClassification Loss: 1.6512\r\n",
      "Train Epoch: 6 [27520/110534 (25%)]\tClassification Loss: 1.7008\r\n",
      "Train Epoch: 6 [28160/110534 (25%)]\tClassification Loss: 1.6954\r\n",
      "Train Epoch: 6 [28800/110534 (26%)]\tClassification Loss: 1.6607\r\n",
      "Train Epoch: 6 [29440/110534 (27%)]\tClassification Loss: 1.5456\r\n",
      "Train Epoch: 6 [30080/110534 (27%)]\tClassification Loss: 1.5481\r\n",
      "Train Epoch: 6 [30720/110534 (28%)]\tClassification Loss: 1.3945\r\n",
      "Train Epoch: 6 [31360/110534 (28%)]\tClassification Loss: 1.2637\r\n",
      "Train Epoch: 6 [32000/110534 (29%)]\tClassification Loss: 1.6962\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_500.pth.tar\r\n",
      "Train Epoch: 6 [32640/110534 (30%)]\tClassification Loss: 1.5040\r\n",
      "Train Epoch: 6 [33280/110534 (30%)]\tClassification Loss: 1.4171\r\n",
      "Train Epoch: 6 [33920/110534 (31%)]\tClassification Loss: 1.6197\r\n",
      "Train Epoch: 6 [34560/110534 (31%)]\tClassification Loss: 1.5574\r\n",
      "Train Epoch: 6 [35200/110534 (32%)]\tClassification Loss: 1.4533\r\n",
      "Train Epoch: 6 [35840/110534 (32%)]\tClassification Loss: 1.3630\r\n",
      "Train Epoch: 6 [36480/110534 (33%)]\tClassification Loss: 1.5489\r\n",
      "Train Epoch: 6 [37120/110534 (34%)]\tClassification Loss: 1.6637\r\n",
      "Train Epoch: 6 [37760/110534 (34%)]\tClassification Loss: 1.3356\r\n",
      "Train Epoch: 6 [38400/110534 (35%)]\tClassification Loss: 1.6989\r\n",
      "\r\n",
      "Test set: Average loss: 1.4791, Accuracy: 6973/12800 (54%)\r\n",
      "\r\n",
      "Train Epoch: 6 [39040/110534 (35%)]\tClassification Loss: 1.3854\r\n",
      "Train Epoch: 6 [39680/110534 (36%)]\tClassification Loss: 1.5694\r\n",
      "Train Epoch: 6 [40320/110534 (36%)]\tClassification Loss: 1.8227\r\n",
      "Train Epoch: 6 [40960/110534 (37%)]\tClassification Loss: 1.3631\r\n",
      "Train Epoch: 6 [41600/110534 (38%)]\tClassification Loss: 1.7622\r\n",
      "Train Epoch: 6 [42240/110534 (38%)]\tClassification Loss: 1.8333\r\n",
      "Train Epoch: 6 [42880/110534 (39%)]\tClassification Loss: 1.5830\r\n",
      "Train Epoch: 6 [43520/110534 (39%)]\tClassification Loss: 1.6168\r\n",
      "Train Epoch: 6 [44160/110534 (40%)]\tClassification Loss: 1.6518\r\n",
      "Train Epoch: 6 [44800/110534 (41%)]\tClassification Loss: 1.6732\r\n",
      "Train Epoch: 6 [45440/110534 (41%)]\tClassification Loss: 1.3699\r\n",
      "Train Epoch: 6 [46080/110534 (42%)]\tClassification Loss: 1.6968\r\n",
      "Train Epoch: 6 [46720/110534 (42%)]\tClassification Loss: 1.4030\r\n",
      "Train Epoch: 6 [47360/110534 (43%)]\tClassification Loss: 1.4210\r\n",
      "Train Epoch: 6 [48000/110534 (43%)]\tClassification Loss: 1.6459\r\n",
      "Train Epoch: 6 [48640/110534 (44%)]\tClassification Loss: 1.6249\r\n",
      "Train Epoch: 6 [49280/110534 (45%)]\tClassification Loss: 1.5010\r\n",
      "Train Epoch: 6 [49920/110534 (45%)]\tClassification Loss: 1.5307\r\n",
      "Train Epoch: 6 [50560/110534 (46%)]\tClassification Loss: 1.6732\r\n",
      "Train Epoch: 6 [51200/110534 (46%)]\tClassification Loss: 1.6797\r\n",
      "Train Epoch: 6 [51840/110534 (47%)]\tClassification Loss: 1.5356\r\n",
      "Train Epoch: 6 [52480/110534 (47%)]\tClassification Loss: 1.3215\r\n",
      "Train Epoch: 6 [53120/110534 (48%)]\tClassification Loss: 1.6128\r\n",
      "Train Epoch: 6 [53760/110534 (49%)]\tClassification Loss: 1.5774\r\n",
      "Train Epoch: 6 [54400/110534 (49%)]\tClassification Loss: 1.3939\r\n",
      "Train Epoch: 6 [55040/110534 (50%)]\tClassification Loss: 1.3064\r\n",
      "Train Epoch: 6 [55680/110534 (50%)]\tClassification Loss: 1.6337\r\n",
      "Train Epoch: 6 [56320/110534 (51%)]\tClassification Loss: 1.6188\r\n",
      "Train Epoch: 6 [56960/110534 (52%)]\tClassification Loss: 2.2147\r\n",
      "Train Epoch: 6 [57600/110534 (52%)]\tClassification Loss: 1.5383\r\n",
      "Train Epoch: 6 [58240/110534 (53%)]\tClassification Loss: 1.4784\r\n",
      "Train Epoch: 6 [58880/110534 (53%)]\tClassification Loss: 1.5821\r\n",
      "Train Epoch: 6 [59520/110534 (54%)]\tClassification Loss: 1.5394\r\n",
      "Train Epoch: 6 [60160/110534 (54%)]\tClassification Loss: 1.4784\r\n",
      "Train Epoch: 6 [60800/110534 (55%)]\tClassification Loss: 1.4703\r\n",
      "Train Epoch: 6 [61440/110534 (56%)]\tClassification Loss: 1.8180\r\n",
      "Train Epoch: 6 [62080/110534 (56%)]\tClassification Loss: 1.5880\r\n",
      "Train Epoch: 6 [62720/110534 (57%)]\tClassification Loss: 1.6792\r\n",
      "Train Epoch: 6 [63360/110534 (57%)]\tClassification Loss: 1.6120\r\n",
      "Train Epoch: 6 [64000/110534 (58%)]\tClassification Loss: 1.6592\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_1000.pth.tar\r\n",
      "Train Epoch: 6 [64640/110534 (58%)]\tClassification Loss: 1.7959\r\n",
      "Train Epoch: 6 [65280/110534 (59%)]\tClassification Loss: 1.7933\r\n",
      "Train Epoch: 6 [65920/110534 (60%)]\tClassification Loss: 1.5471\r\n",
      "Train Epoch: 6 [66560/110534 (60%)]\tClassification Loss: 1.3037\r\n",
      "Train Epoch: 6 [67200/110534 (61%)]\tClassification Loss: 1.7130\r\n",
      "Train Epoch: 6 [67840/110534 (61%)]\tClassification Loss: 1.7074\r\n",
      "Train Epoch: 6 [68480/110534 (62%)]\tClassification Loss: 1.5879\r\n",
      "Train Epoch: 6 [69120/110534 (63%)]\tClassification Loss: 1.3365\r\n",
      "Train Epoch: 6 [69760/110534 (63%)]\tClassification Loss: 1.4187\r\n",
      "Train Epoch: 6 [70400/110534 (64%)]\tClassification Loss: 1.6591\r\n",
      "Train Epoch: 6 [71040/110534 (64%)]\tClassification Loss: 1.7642\r\n",
      "Train Epoch: 6 [71680/110534 (65%)]\tClassification Loss: 1.3967\r\n",
      "Train Epoch: 6 [72320/110534 (65%)]\tClassification Loss: 1.4251\r\n",
      "Train Epoch: 6 [72960/110534 (66%)]\tClassification Loss: 1.4534\r\n",
      "Train Epoch: 6 [73600/110534 (67%)]\tClassification Loss: 1.5582\r\n",
      "Train Epoch: 6 [74240/110534 (67%)]\tClassification Loss: 1.6014\r\n",
      "Train Epoch: 6 [74880/110534 (68%)]\tClassification Loss: 1.4583\r\n",
      "Train Epoch: 6 [75520/110534 (68%)]\tClassification Loss: 1.6514\r\n",
      "Train Epoch: 6 [76160/110534 (69%)]\tClassification Loss: 1.5543\r\n",
      "Train Epoch: 6 [76800/110534 (69%)]\tClassification Loss: 1.8218\r\n",
      "\r\n",
      "Test set: Average loss: 1.4620, Accuracy: 7011/12800 (55%)\r\n",
      "\r\n",
      "Train Epoch: 6 [77440/110534 (70%)]\tClassification Loss: 1.5459\r\n",
      "Train Epoch: 6 [78080/110534 (71%)]\tClassification Loss: 1.5991\r\n",
      "Train Epoch: 6 [78720/110534 (71%)]\tClassification Loss: 1.5510\r\n",
      "Train Epoch: 6 [79360/110534 (72%)]\tClassification Loss: 1.6546\r\n",
      "Train Epoch: 6 [80000/110534 (72%)]\tClassification Loss: 1.4670\r\n",
      "Train Epoch: 6 [80640/110534 (73%)]\tClassification Loss: 1.3492\r\n",
      "Train Epoch: 6 [81280/110534 (74%)]\tClassification Loss: 1.4280\r\n",
      "Train Epoch: 6 [81920/110534 (74%)]\tClassification Loss: 1.6046\r\n",
      "Train Epoch: 6 [82560/110534 (75%)]\tClassification Loss: 1.8690\r\n",
      "Train Epoch: 6 [83200/110534 (75%)]\tClassification Loss: 1.3085\r\n",
      "Train Epoch: 6 [83840/110534 (76%)]\tClassification Loss: 1.9198\r\n",
      "Train Epoch: 6 [84480/110534 (76%)]\tClassification Loss: 1.4981\r\n",
      "Train Epoch: 6 [85120/110534 (77%)]\tClassification Loss: 1.7192\r\n",
      "Train Epoch: 6 [85760/110534 (78%)]\tClassification Loss: 1.5218\r\n",
      "Train Epoch: 6 [86400/110534 (78%)]\tClassification Loss: 1.4341\r\n",
      "Train Epoch: 6 [87040/110534 (79%)]\tClassification Loss: 1.5246\r\n",
      "Train Epoch: 6 [87680/110534 (79%)]\tClassification Loss: 1.6082\r\n",
      "Train Epoch: 6 [88320/110534 (80%)]\tClassification Loss: 1.3623\r\n",
      "Train Epoch: 6 [88960/110534 (80%)]\tClassification Loss: 1.4255\r\n",
      "Train Epoch: 6 [89600/110534 (81%)]\tClassification Loss: 1.6050\r\n",
      "Train Epoch: 6 [90240/110534 (82%)]\tClassification Loss: 1.7857\r\n",
      "Train Epoch: 6 [90880/110534 (82%)]\tClassification Loss: 1.4929\r\n",
      "Train Epoch: 6 [91520/110534 (83%)]\tClassification Loss: 1.5635\r\n",
      "Train Epoch: 6 [92160/110534 (83%)]\tClassification Loss: 1.4029\r\n",
      "Train Epoch: 6 [92800/110534 (84%)]\tClassification Loss: 1.5614\r\n",
      "Train Epoch: 6 [93440/110534 (85%)]\tClassification Loss: 1.5239\r\n",
      "Train Epoch: 6 [94080/110534 (85%)]\tClassification Loss: 1.4024\r\n",
      "Train Epoch: 6 [94720/110534 (86%)]\tClassification Loss: 1.6939\r\n",
      "Train Epoch: 6 [95360/110534 (86%)]\tClassification Loss: 1.6165\r\n",
      "Train Epoch: 6 [96000/110534 (87%)]\tClassification Loss: 1.8159\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_1500.pth.tar\r\n",
      "Train Epoch: 6 [96640/110534 (87%)]\tClassification Loss: 1.7094\r\n",
      "Train Epoch: 6 [97280/110534 (88%)]\tClassification Loss: 1.5954\r\n",
      "Train Epoch: 6 [97920/110534 (89%)]\tClassification Loss: 1.4320\r\n",
      "Train Epoch: 6 [98560/110534 (89%)]\tClassification Loss: 1.4329\r\n",
      "Train Epoch: 6 [99200/110534 (90%)]\tClassification Loss: 1.9000\r\n",
      "Train Epoch: 6 [99840/110534 (90%)]\tClassification Loss: 1.5865\r\n",
      "Train Epoch: 6 [100480/110534 (91%)]\tClassification Loss: 1.4623\r\n",
      "Train Epoch: 6 [101120/110534 (91%)]\tClassification Loss: 1.4026\r\n",
      "Train Epoch: 6 [101760/110534 (92%)]\tClassification Loss: 1.6044\r\n",
      "Train Epoch: 6 [102400/110534 (93%)]\tClassification Loss: 1.7196\r\n",
      "Train Epoch: 6 [103040/110534 (93%)]\tClassification Loss: 1.5798\r\n",
      "Train Epoch: 6 [103680/110534 (94%)]\tClassification Loss: 1.3640\r\n",
      "Train Epoch: 6 [104320/110534 (94%)]\tClassification Loss: 1.6407\r\n",
      "Train Epoch: 6 [104960/110534 (95%)]\tClassification Loss: 1.5626\r\n",
      "Train Epoch: 6 [105600/110534 (96%)]\tClassification Loss: 1.9055\r\n",
      "Train Epoch: 6 [106240/110534 (96%)]\tClassification Loss: 1.3643\r\n",
      "Train Epoch: 6 [106880/110534 (97%)]\tClassification Loss: 1.6431\r\n",
      "Train Epoch: 6 [107520/110534 (97%)]\tClassification Loss: 1.4159\r\n",
      "Train Epoch: 6 [108160/110534 (98%)]\tClassification Loss: 1.5322\r\n",
      "Train Epoch: 6 [108800/110534 (98%)]\tClassification Loss: 1.3650\r\n",
      "Train Epoch: 6 [109440/110534 (99%)]\tClassification Loss: 1.6030\r\n",
      "Train Epoch: 6 [110080/110534 (100%)]\tClassification Loss: 1.7033\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_final.pth.tar\r\n",
      "Train Epoch: 7 [0/110534 (0%)]\tClassification Loss: 1.6748\r\n",
      "\r\n",
      "Test set: Average loss: 1.4673, Accuracy: 6991/12800 (55%)\r\n",
      "\r\n",
      "Train Epoch: 7 [640/110534 (1%)]\tClassification Loss: 1.6461\r\n",
      "Train Epoch: 7 [1280/110534 (1%)]\tClassification Loss: 1.5118\r\n",
      "Train Epoch: 7 [1920/110534 (2%)]\tClassification Loss: 1.4461\r\n",
      "Train Epoch: 7 [2560/110534 (2%)]\tClassification Loss: 1.7618\r\n",
      "Train Epoch: 7 [3200/110534 (3%)]\tClassification Loss: 1.4568\r\n",
      "Train Epoch: 7 [3840/110534 (3%)]\tClassification Loss: 1.5257\r\n",
      "Train Epoch: 7 [4480/110534 (4%)]\tClassification Loss: 1.4707\r\n",
      "Train Epoch: 7 [5120/110534 (5%)]\tClassification Loss: 1.5603\r\n",
      "Train Epoch: 7 [5760/110534 (5%)]\tClassification Loss: 1.6239\r\n",
      "Train Epoch: 7 [6400/110534 (6%)]\tClassification Loss: 1.9003\r\n",
      "Train Epoch: 7 [7040/110534 (6%)]\tClassification Loss: 1.5749\r\n",
      "Train Epoch: 7 [7680/110534 (7%)]\tClassification Loss: 1.4713\r\n",
      "Train Epoch: 7 [8320/110534 (8%)]\tClassification Loss: 1.7336\r\n",
      "Train Epoch: 7 [8960/110534 (8%)]\tClassification Loss: 1.5129\r\n",
      "Train Epoch: 7 [9600/110534 (9%)]\tClassification Loss: 1.4182\r\n",
      "Train Epoch: 7 [10240/110534 (9%)]\tClassification Loss: 1.3589\r\n",
      "Train Epoch: 7 [10880/110534 (10%)]\tClassification Loss: 1.6818\r\n",
      "Train Epoch: 7 [11520/110534 (10%)]\tClassification Loss: 1.5336\r\n",
      "Train Epoch: 7 [12160/110534 (11%)]\tClassification Loss: 1.6397\r\n",
      "Train Epoch: 7 [12800/110534 (12%)]\tClassification Loss: 1.6662\r\n",
      "Train Epoch: 7 [13440/110534 (12%)]\tClassification Loss: 1.6064\r\n",
      "Train Epoch: 7 [14080/110534 (13%)]\tClassification Loss: 1.4831\r\n",
      "Train Epoch: 7 [14720/110534 (13%)]\tClassification Loss: 1.6523\r\n",
      "Train Epoch: 7 [15360/110534 (14%)]\tClassification Loss: 1.4534\r\n",
      "Train Epoch: 7 [16000/110534 (14%)]\tClassification Loss: 1.7635\r\n",
      "Train Epoch: 7 [16640/110534 (15%)]\tClassification Loss: 1.5809\r\n",
      "Train Epoch: 7 [17280/110534 (16%)]\tClassification Loss: 1.7837\r\n",
      "Train Epoch: 7 [17920/110534 (16%)]\tClassification Loss: 1.8090\r\n",
      "Train Epoch: 7 [18560/110534 (17%)]\tClassification Loss: 1.6559\r\n",
      "Train Epoch: 7 [19200/110534 (17%)]\tClassification Loss: 1.5650\r\n",
      "Train Epoch: 7 [19840/110534 (18%)]\tClassification Loss: 1.5460\r\n",
      "Train Epoch: 7 [20480/110534 (19%)]\tClassification Loss: 1.6214\r\n",
      "Train Epoch: 7 [21120/110534 (19%)]\tClassification Loss: 1.4254\r\n",
      "Train Epoch: 7 [21760/110534 (20%)]\tClassification Loss: 1.5739\r\n",
      "Train Epoch: 7 [22400/110534 (20%)]\tClassification Loss: 1.7033\r\n",
      "Train Epoch: 7 [23040/110534 (21%)]\tClassification Loss: 1.4828\r\n",
      "Train Epoch: 7 [23680/110534 (21%)]\tClassification Loss: 1.5185\r\n",
      "Train Epoch: 7 [24320/110534 (22%)]\tClassification Loss: 1.5887\r\n",
      "Train Epoch: 7 [24960/110534 (23%)]\tClassification Loss: 1.5880\r\n",
      "Train Epoch: 7 [25600/110534 (23%)]\tClassification Loss: 1.3746\r\n",
      "Train Epoch: 7 [26240/110534 (24%)]\tClassification Loss: 1.6237\r\n",
      "Train Epoch: 7 [26880/110534 (24%)]\tClassification Loss: 1.7049\r\n",
      "Train Epoch: 7 [27520/110534 (25%)]\tClassification Loss: 1.6037\r\n",
      "Train Epoch: 7 [28160/110534 (25%)]\tClassification Loss: 1.6045\r\n",
      "Train Epoch: 7 [28800/110534 (26%)]\tClassification Loss: 1.5182\r\n",
      "Train Epoch: 7 [29440/110534 (27%)]\tClassification Loss: 1.4250\r\n",
      "Train Epoch: 7 [30080/110534 (27%)]\tClassification Loss: 1.6090\r\n",
      "Train Epoch: 7 [30720/110534 (28%)]\tClassification Loss: 1.2842\r\n",
      "Train Epoch: 7 [31360/110534 (28%)]\tClassification Loss: 1.2868\r\n",
      "Train Epoch: 7 [32000/110534 (29%)]\tClassification Loss: 1.6887\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_500.pth.tar\r\n",
      "Train Epoch: 7 [32640/110534 (30%)]\tClassification Loss: 1.5307\r\n",
      "Train Epoch: 7 [33280/110534 (30%)]\tClassification Loss: 1.3444\r\n",
      "Train Epoch: 7 [33920/110534 (31%)]\tClassification Loss: 1.6779\r\n",
      "Train Epoch: 7 [34560/110534 (31%)]\tClassification Loss: 1.5695\r\n",
      "Train Epoch: 7 [35200/110534 (32%)]\tClassification Loss: 1.5678\r\n",
      "Train Epoch: 7 [35840/110534 (32%)]\tClassification Loss: 1.5640\r\n",
      "Train Epoch: 7 [36480/110534 (33%)]\tClassification Loss: 1.4564\r\n",
      "Train Epoch: 7 [37120/110534 (34%)]\tClassification Loss: 1.6683\r\n",
      "Train Epoch: 7 [37760/110534 (34%)]\tClassification Loss: 1.3653\r\n",
      "Train Epoch: 7 [38400/110534 (35%)]\tClassification Loss: 1.7720\r\n",
      "\r\n",
      "Test set: Average loss: 1.4690, Accuracy: 6997/12800 (55%)\r\n",
      "\r\n",
      "Train Epoch: 7 [39040/110534 (35%)]\tClassification Loss: 1.4267\r\n",
      "Train Epoch: 7 [39680/110534 (36%)]\tClassification Loss: 1.6586\r\n",
      "Train Epoch: 7 [40320/110534 (36%)]\tClassification Loss: 1.7634\r\n",
      "Train Epoch: 7 [40960/110534 (37%)]\tClassification Loss: 1.4705\r\n",
      "Train Epoch: 7 [41600/110534 (38%)]\tClassification Loss: 1.7130\r\n",
      "Train Epoch: 7 [42240/110534 (38%)]\tClassification Loss: 1.6433\r\n",
      "Train Epoch: 7 [42880/110534 (39%)]\tClassification Loss: 1.4067\r\n",
      "Train Epoch: 7 [43520/110534 (39%)]\tClassification Loss: 1.5779\r\n",
      "Train Epoch: 7 [44160/110534 (40%)]\tClassification Loss: 1.6495\r\n",
      "Train Epoch: 7 [44800/110534 (41%)]\tClassification Loss: 1.5704\r\n",
      "Train Epoch: 7 [45440/110534 (41%)]\tClassification Loss: 1.5113\r\n",
      "Train Epoch: 7 [46080/110534 (42%)]\tClassification Loss: 1.6531\r\n",
      "Train Epoch: 7 [46720/110534 (42%)]\tClassification Loss: 1.4017\r\n",
      "Train Epoch: 7 [47360/110534 (43%)]\tClassification Loss: 1.4353\r\n",
      "Train Epoch: 7 [48000/110534 (43%)]\tClassification Loss: 1.6372\r\n",
      "Train Epoch: 7 [48640/110534 (44%)]\tClassification Loss: 1.6945\r\n",
      "Train Epoch: 7 [49280/110534 (45%)]\tClassification Loss: 1.5239\r\n",
      "Train Epoch: 7 [49920/110534 (45%)]\tClassification Loss: 1.3616\r\n",
      "Train Epoch: 7 [50560/110534 (46%)]\tClassification Loss: 1.9200\r\n",
      "Train Epoch: 7 [51200/110534 (46%)]\tClassification Loss: 1.6332\r\n",
      "Train Epoch: 7 [51840/110534 (47%)]\tClassification Loss: 1.6388\r\n",
      "Train Epoch: 7 [52480/110534 (47%)]\tClassification Loss: 1.4424\r\n",
      "Train Epoch: 7 [53120/110534 (48%)]\tClassification Loss: 1.5807\r\n",
      "Train Epoch: 7 [53760/110534 (49%)]\tClassification Loss: 1.6973\r\n",
      "Train Epoch: 7 [54400/110534 (49%)]\tClassification Loss: 1.2776\r\n",
      "Train Epoch: 7 [55040/110534 (50%)]\tClassification Loss: 1.2367\r\n",
      "Train Epoch: 7 [55680/110534 (50%)]\tClassification Loss: 1.6729\r\n",
      "Train Epoch: 7 [56320/110534 (51%)]\tClassification Loss: 1.7257\r\n",
      "Train Epoch: 7 [56960/110534 (52%)]\tClassification Loss: 1.8682\r\n",
      "Train Epoch: 7 [57600/110534 (52%)]\tClassification Loss: 1.4175\r\n",
      "Train Epoch: 7 [58240/110534 (53%)]\tClassification Loss: 1.4520\r\n",
      "Train Epoch: 7 [58880/110534 (53%)]\tClassification Loss: 1.4807\r\n",
      "Train Epoch: 7 [59520/110534 (54%)]\tClassification Loss: 1.5033\r\n",
      "Train Epoch: 7 [60160/110534 (54%)]\tClassification Loss: 1.5035\r\n",
      "Train Epoch: 7 [60800/110534 (55%)]\tClassification Loss: 1.6491\r\n",
      "Train Epoch: 7 [61440/110534 (56%)]\tClassification Loss: 1.7976\r\n",
      "Train Epoch: 7 [62080/110534 (56%)]\tClassification Loss: 1.5857\r\n",
      "Train Epoch: 7 [62720/110534 (57%)]\tClassification Loss: 1.6028\r\n",
      "Train Epoch: 7 [63360/110534 (57%)]\tClassification Loss: 1.8207\r\n",
      "Train Epoch: 7 [64000/110534 (58%)]\tClassification Loss: 1.7207\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_1000.pth.tar\r\n",
      "Train Epoch: 7 [64640/110534 (58%)]\tClassification Loss: 1.7158\r\n",
      "Train Epoch: 7 [65280/110534 (59%)]\tClassification Loss: 1.7965\r\n",
      "Train Epoch: 7 [65920/110534 (60%)]\tClassification Loss: 1.3495\r\n",
      "Train Epoch: 7 [66560/110534 (60%)]\tClassification Loss: 1.2983\r\n",
      "Train Epoch: 7 [67200/110534 (61%)]\tClassification Loss: 1.5057\r\n",
      "Train Epoch: 7 [67840/110534 (61%)]\tClassification Loss: 1.6179\r\n",
      "Train Epoch: 7 [68480/110534 (62%)]\tClassification Loss: 1.6762\r\n",
      "Train Epoch: 7 [69120/110534 (63%)]\tClassification Loss: 1.4657\r\n",
      "Train Epoch: 7 [69760/110534 (63%)]\tClassification Loss: 1.3647\r\n",
      "Train Epoch: 7 [70400/110534 (64%)]\tClassification Loss: 1.6348\r\n",
      "Train Epoch: 7 [71040/110534 (64%)]\tClassification Loss: 1.7236\r\n",
      "Train Epoch: 7 [71680/110534 (65%)]\tClassification Loss: 1.3123\r\n",
      "Train Epoch: 7 [72320/110534 (65%)]\tClassification Loss: 1.4707\r\n",
      "Train Epoch: 7 [72960/110534 (66%)]\tClassification Loss: 1.5025\r\n",
      "Train Epoch: 7 [73600/110534 (67%)]\tClassification Loss: 1.6032\r\n",
      "Train Epoch: 7 [74240/110534 (67%)]\tClassification Loss: 1.4350\r\n",
      "Train Epoch: 7 [74880/110534 (68%)]\tClassification Loss: 1.2780\r\n",
      "Train Epoch: 7 [75520/110534 (68%)]\tClassification Loss: 1.8385\r\n",
      "Train Epoch: 7 [76160/110534 (69%)]\tClassification Loss: 1.6491\r\n",
      "Train Epoch: 7 [76800/110534 (69%)]\tClassification Loss: 1.9159\r\n",
      "\r\n",
      "Test set: Average loss: 1.4547, Accuracy: 7015/12800 (55%)\r\n",
      "\r\n",
      "Train Epoch: 7 [77440/110534 (70%)]\tClassification Loss: 1.5074\r\n",
      "Train Epoch: 7 [78080/110534 (71%)]\tClassification Loss: 1.4986\r\n",
      "Train Epoch: 7 [78720/110534 (71%)]\tClassification Loss: 1.7424\r\n",
      "Train Epoch: 7 [79360/110534 (72%)]\tClassification Loss: 1.6381\r\n",
      "Train Epoch: 7 [80000/110534 (72%)]\tClassification Loss: 1.4446\r\n",
      "Train Epoch: 7 [80640/110534 (73%)]\tClassification Loss: 1.5711\r\n",
      "Train Epoch: 7 [81280/110534 (74%)]\tClassification Loss: 1.3122\r\n",
      "Train Epoch: 7 [81920/110534 (74%)]\tClassification Loss: 1.5197\r\n",
      "Train Epoch: 7 [82560/110534 (75%)]\tClassification Loss: 1.7271\r\n",
      "Train Epoch: 7 [83200/110534 (75%)]\tClassification Loss: 1.3858\r\n",
      "Train Epoch: 7 [83840/110534 (76%)]\tClassification Loss: 1.5994\r\n",
      "Train Epoch: 7 [84480/110534 (76%)]\tClassification Loss: 1.4707\r\n",
      "Train Epoch: 7 [85120/110534 (77%)]\tClassification Loss: 1.7128\r\n",
      "Train Epoch: 7 [85760/110534 (78%)]\tClassification Loss: 1.4913\r\n",
      "Train Epoch: 7 [86400/110534 (78%)]\tClassification Loss: 1.6135\r\n",
      "Train Epoch: 7 [87040/110534 (79%)]\tClassification Loss: 1.5125\r\n",
      "Train Epoch: 7 [87680/110534 (79%)]\tClassification Loss: 1.6712\r\n",
      "Train Epoch: 7 [88320/110534 (80%)]\tClassification Loss: 1.4381\r\n",
      "Train Epoch: 7 [88960/110534 (80%)]\tClassification Loss: 1.3988\r\n",
      "Train Epoch: 7 [89600/110534 (81%)]\tClassification Loss: 1.4181\r\n",
      "Train Epoch: 7 [90240/110534 (82%)]\tClassification Loss: 1.7629\r\n",
      "Train Epoch: 7 [90880/110534 (82%)]\tClassification Loss: 1.4805\r\n",
      "Train Epoch: 7 [91520/110534 (83%)]\tClassification Loss: 1.5991\r\n",
      "Train Epoch: 7 [92160/110534 (83%)]\tClassification Loss: 1.4236\r\n",
      "Train Epoch: 7 [92800/110534 (84%)]\tClassification Loss: 1.5111\r\n",
      "Train Epoch: 7 [93440/110534 (85%)]\tClassification Loss: 1.4292\r\n",
      "Train Epoch: 7 [94080/110534 (85%)]\tClassification Loss: 1.3894\r\n",
      "Train Epoch: 7 [94720/110534 (86%)]\tClassification Loss: 1.6638\r\n",
      "Train Epoch: 7 [95360/110534 (86%)]\tClassification Loss: 1.4551\r\n",
      "Train Epoch: 7 [96000/110534 (87%)]\tClassification Loss: 1.8263\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_1500.pth.tar\r\n",
      "Train Epoch: 7 [96640/110534 (87%)]\tClassification Loss: 1.6366\r\n",
      "Train Epoch: 7 [97280/110534 (88%)]\tClassification Loss: 1.6096\r\n",
      "Train Epoch: 7 [97920/110534 (89%)]\tClassification Loss: 1.4781\r\n",
      "Train Epoch: 7 [98560/110534 (89%)]\tClassification Loss: 1.5123\r\n",
      "Train Epoch: 7 [99200/110534 (90%)]\tClassification Loss: 2.1465\r\n",
      "Train Epoch: 7 [99840/110534 (90%)]\tClassification Loss: 1.6105\r\n",
      "Train Epoch: 7 [100480/110534 (91%)]\tClassification Loss: 1.5315\r\n",
      "Train Epoch: 7 [101120/110534 (91%)]\tClassification Loss: 1.4524\r\n",
      "Train Epoch: 7 [101760/110534 (92%)]\tClassification Loss: 1.7134\r\n",
      "Train Epoch: 7 [102400/110534 (93%)]\tClassification Loss: 1.6708\r\n",
      "Train Epoch: 7 [103040/110534 (93%)]\tClassification Loss: 1.6189\r\n",
      "Train Epoch: 7 [103680/110534 (94%)]\tClassification Loss: 1.5079\r\n",
      "Train Epoch: 7 [104320/110534 (94%)]\tClassification Loss: 1.4440\r\n",
      "Train Epoch: 7 [104960/110534 (95%)]\tClassification Loss: 1.5986\r\n",
      "Train Epoch: 7 [105600/110534 (96%)]\tClassification Loss: 1.8200\r\n",
      "Train Epoch: 7 [106240/110534 (96%)]\tClassification Loss: 1.3021\r\n",
      "Train Epoch: 7 [106880/110534 (97%)]\tClassification Loss: 1.4408\r\n",
      "Train Epoch: 7 [107520/110534 (97%)]\tClassification Loss: 1.4668\r\n",
      "Train Epoch: 7 [108160/110534 (98%)]\tClassification Loss: 1.3624\r\n",
      "Train Epoch: 7 [108800/110534 (98%)]\tClassification Loss: 1.3907\r\n",
      "Train Epoch: 7 [109440/110534 (99%)]\tClassification Loss: 1.5187\r\n",
      "Train Epoch: 7 [110080/110534 (100%)]\tClassification Loss: 1.7083\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_final.pth.tar\r\n",
      "Train Epoch: 8 [0/110534 (0%)]\tClassification Loss: 1.8230\r\n",
      "\r\n",
      "Test set: Average loss: 1.4579, Accuracy: 7019/12800 (55%)\r\n",
      "\r\n",
      "Train Epoch: 8 [640/110534 (1%)]\tClassification Loss: 1.5144\r\n",
      "Train Epoch: 8 [1280/110534 (1%)]\tClassification Loss: 1.4324\r\n",
      "Train Epoch: 8 [1920/110534 (2%)]\tClassification Loss: 1.5313\r\n",
      "Train Epoch: 8 [2560/110534 (2%)]\tClassification Loss: 1.7101\r\n",
      "Train Epoch: 8 [3200/110534 (3%)]\tClassification Loss: 1.4841\r\n",
      "Train Epoch: 8 [3840/110534 (3%)]\tClassification Loss: 1.5110\r\n",
      "Train Epoch: 8 [4480/110534 (4%)]\tClassification Loss: 1.4099\r\n",
      "Train Epoch: 8 [5120/110534 (5%)]\tClassification Loss: 1.6157\r\n",
      "Train Epoch: 8 [5760/110534 (5%)]\tClassification Loss: 1.6311\r\n",
      "Train Epoch: 8 [6400/110534 (6%)]\tClassification Loss: 1.9560\r\n",
      "Train Epoch: 8 [7040/110534 (6%)]\tClassification Loss: 1.7378\r\n",
      "Train Epoch: 8 [7680/110534 (7%)]\tClassification Loss: 1.4288\r\n",
      "Train Epoch: 8 [8320/110534 (8%)]\tClassification Loss: 1.7732\r\n",
      "Train Epoch: 8 [8960/110534 (8%)]\tClassification Loss: 1.5443\r\n",
      "Train Epoch: 8 [9600/110534 (9%)]\tClassification Loss: 1.5849\r\n",
      "Train Epoch: 8 [10240/110534 (9%)]\tClassification Loss: 1.4038\r\n",
      "Train Epoch: 8 [10880/110534 (10%)]\tClassification Loss: 1.6187\r\n",
      "Train Epoch: 8 [11520/110534 (10%)]\tClassification Loss: 1.5786\r\n",
      "Train Epoch: 8 [12160/110534 (11%)]\tClassification Loss: 1.5673\r\n",
      "Train Epoch: 8 [12800/110534 (12%)]\tClassification Loss: 1.7059\r\n",
      "Train Epoch: 8 [13440/110534 (12%)]\tClassification Loss: 1.5752\r\n",
      "Train Epoch: 8 [14080/110534 (13%)]\tClassification Loss: 1.5522\r\n",
      "Train Epoch: 8 [14720/110534 (13%)]\tClassification Loss: 1.6804\r\n",
      "Train Epoch: 8 [15360/110534 (14%)]\tClassification Loss: 1.6648\r\n",
      "Train Epoch: 8 [16000/110534 (14%)]\tClassification Loss: 1.7602\r\n",
      "Train Epoch: 8 [16640/110534 (15%)]\tClassification Loss: 1.5519\r\n",
      "Train Epoch: 8 [17280/110534 (16%)]\tClassification Loss: 1.7684\r\n",
      "Train Epoch: 8 [17920/110534 (16%)]\tClassification Loss: 1.6957\r\n",
      "Train Epoch: 8 [18560/110534 (17%)]\tClassification Loss: 1.6061\r\n",
      "Train Epoch: 8 [19200/110534 (17%)]\tClassification Loss: 1.5821\r\n",
      "Train Epoch: 8 [19840/110534 (18%)]\tClassification Loss: 1.4941\r\n",
      "Train Epoch: 8 [20480/110534 (19%)]\tClassification Loss: 1.5814\r\n",
      "Train Epoch: 8 [21120/110534 (19%)]\tClassification Loss: 1.5480\r\n",
      "Train Epoch: 8 [21760/110534 (20%)]\tClassification Loss: 1.4165\r\n",
      "Train Epoch: 8 [22400/110534 (20%)]\tClassification Loss: 1.5646\r\n",
      "Train Epoch: 8 [23040/110534 (21%)]\tClassification Loss: 1.5469\r\n",
      "Train Epoch: 8 [23680/110534 (21%)]\tClassification Loss: 1.5000\r\n",
      "Train Epoch: 8 [24320/110534 (22%)]\tClassification Loss: 1.3759\r\n",
      "Train Epoch: 8 [24960/110534 (23%)]\tClassification Loss: 1.3818\r\n",
      "Train Epoch: 8 [25600/110534 (23%)]\tClassification Loss: 1.3070\r\n",
      "Train Epoch: 8 [26240/110534 (24%)]\tClassification Loss: 1.4664\r\n",
      "Train Epoch: 8 [26880/110534 (24%)]\tClassification Loss: 1.6482\r\n",
      "Train Epoch: 8 [27520/110534 (25%)]\tClassification Loss: 1.6461\r\n",
      "Train Epoch: 8 [28160/110534 (25%)]\tClassification Loss: 1.6253\r\n",
      "Train Epoch: 8 [28800/110534 (26%)]\tClassification Loss: 1.6522\r\n",
      "Train Epoch: 8 [29440/110534 (27%)]\tClassification Loss: 1.5410\r\n",
      "Train Epoch: 8 [30080/110534 (27%)]\tClassification Loss: 1.8457\r\n",
      "Train Epoch: 8 [30720/110534 (28%)]\tClassification Loss: 1.5112\r\n",
      "Train Epoch: 8 [31360/110534 (28%)]\tClassification Loss: 1.2542\r\n",
      "Train Epoch: 8 [32000/110534 (29%)]\tClassification Loss: 1.5590\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_500.pth.tar\r\n",
      "Train Epoch: 8 [32640/110534 (30%)]\tClassification Loss: 1.3962\r\n",
      "Train Epoch: 8 [33280/110534 (30%)]\tClassification Loss: 1.3199\r\n",
      "Train Epoch: 8 [33920/110534 (31%)]\tClassification Loss: 1.4568\r\n",
      "Train Epoch: 8 [34560/110534 (31%)]\tClassification Loss: 1.7216\r\n",
      "Train Epoch: 8 [35200/110534 (32%)]\tClassification Loss: 1.3630\r\n",
      "Train Epoch: 8 [35840/110534 (32%)]\tClassification Loss: 1.5338\r\n",
      "Train Epoch: 8 [36480/110534 (33%)]\tClassification Loss: 1.4405\r\n",
      "Train Epoch: 8 [37120/110534 (34%)]\tClassification Loss: 1.7208\r\n",
      "Train Epoch: 8 [37760/110534 (34%)]\tClassification Loss: 1.4489\r\n",
      "Train Epoch: 8 [38400/110534 (35%)]\tClassification Loss: 1.7572\r\n",
      "\r\n",
      "Test set: Average loss: 1.4646, Accuracy: 6984/12800 (55%)\r\n",
      "\r\n",
      "Train Epoch: 8 [39040/110534 (35%)]\tClassification Loss: 1.3752\r\n",
      "Train Epoch: 8 [39680/110534 (36%)]\tClassification Loss: 1.6158\r\n",
      "Train Epoch: 8 [40320/110534 (36%)]\tClassification Loss: 1.8435\r\n",
      "Train Epoch: 8 [40960/110534 (37%)]\tClassification Loss: 1.4469\r\n",
      "Train Epoch: 8 [41600/110534 (38%)]\tClassification Loss: 1.6588\r\n",
      "Train Epoch: 8 [42240/110534 (38%)]\tClassification Loss: 1.5770\r\n",
      "Train Epoch: 8 [42880/110534 (39%)]\tClassification Loss: 1.5171\r\n",
      "Train Epoch: 8 [43520/110534 (39%)]\tClassification Loss: 1.6952\r\n",
      "Train Epoch: 8 [44160/110534 (40%)]\tClassification Loss: 1.6584\r\n",
      "Train Epoch: 8 [44800/110534 (41%)]\tClassification Loss: 1.6942\r\n",
      "Train Epoch: 8 [45440/110534 (41%)]\tClassification Loss: 1.3521\r\n",
      "Train Epoch: 8 [46080/110534 (42%)]\tClassification Loss: 1.5165\r\n",
      "Train Epoch: 8 [46720/110534 (42%)]\tClassification Loss: 1.3740\r\n",
      "Train Epoch: 8 [47360/110534 (43%)]\tClassification Loss: 1.3272\r\n",
      "Train Epoch: 8 [48000/110534 (43%)]\tClassification Loss: 1.8531\r\n",
      "Train Epoch: 8 [48640/110534 (44%)]\tClassification Loss: 1.6347\r\n",
      "Train Epoch: 8 [49280/110534 (45%)]\tClassification Loss: 1.3975\r\n",
      "Train Epoch: 8 [49920/110534 (45%)]\tClassification Loss: 1.4118\r\n",
      "Train Epoch: 8 [50560/110534 (46%)]\tClassification Loss: 1.8047\r\n",
      "Train Epoch: 8 [51200/110534 (46%)]\tClassification Loss: 1.5498\r\n",
      "Train Epoch: 8 [51840/110534 (47%)]\tClassification Loss: 1.5684\r\n",
      "Train Epoch: 8 [52480/110534 (47%)]\tClassification Loss: 1.6017\r\n",
      "Train Epoch: 8 [53120/110534 (48%)]\tClassification Loss: 1.5661\r\n",
      "Train Epoch: 8 [53760/110534 (49%)]\tClassification Loss: 1.7087\r\n",
      "Train Epoch: 8 [54400/110534 (49%)]\tClassification Loss: 1.4864\r\n",
      "Train Epoch: 8 [55040/110534 (50%)]\tClassification Loss: 1.3375\r\n",
      "Train Epoch: 8 [55680/110534 (50%)]\tClassification Loss: 1.9180\r\n",
      "Train Epoch: 8 [56320/110534 (51%)]\tClassification Loss: 1.6028\r\n",
      "Train Epoch: 8 [56960/110534 (52%)]\tClassification Loss: 2.0038\r\n",
      "Train Epoch: 8 [57600/110534 (52%)]\tClassification Loss: 1.5072\r\n",
      "Train Epoch: 8 [58240/110534 (53%)]\tClassification Loss: 1.4572\r\n",
      "Train Epoch: 8 [58880/110534 (53%)]\tClassification Loss: 1.5056\r\n",
      "Train Epoch: 8 [59520/110534 (54%)]\tClassification Loss: 1.4718\r\n",
      "Train Epoch: 8 [60160/110534 (54%)]\tClassification Loss: 1.3991\r\n",
      "Train Epoch: 8 [60800/110534 (55%)]\tClassification Loss: 1.5494\r\n",
      "Train Epoch: 8 [61440/110534 (56%)]\tClassification Loss: 1.8312\r\n",
      "Train Epoch: 8 [62080/110534 (56%)]\tClassification Loss: 1.7401\r\n",
      "Train Epoch: 8 [62720/110534 (57%)]\tClassification Loss: 1.7054\r\n",
      "Train Epoch: 8 [63360/110534 (57%)]\tClassification Loss: 1.6217\r\n",
      "Train Epoch: 8 [64000/110534 (58%)]\tClassification Loss: 1.7110\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_1000.pth.tar\r\n",
      "Train Epoch: 8 [64640/110534 (58%)]\tClassification Loss: 1.8269\r\n",
      "Train Epoch: 8 [65280/110534 (59%)]\tClassification Loss: 1.6911\r\n",
      "Train Epoch: 8 [65920/110534 (60%)]\tClassification Loss: 1.5087\r\n",
      "Train Epoch: 8 [66560/110534 (60%)]\tClassification Loss: 1.4888\r\n",
      "Train Epoch: 8 [67200/110534 (61%)]\tClassification Loss: 1.6316\r\n",
      "Train Epoch: 8 [67840/110534 (61%)]\tClassification Loss: 1.6366\r\n",
      "Train Epoch: 8 [68480/110534 (62%)]\tClassification Loss: 1.5214\r\n",
      "Train Epoch: 8 [69120/110534 (63%)]\tClassification Loss: 1.5240\r\n",
      "Train Epoch: 8 [69760/110534 (63%)]\tClassification Loss: 1.3741\r\n",
      "Train Epoch: 8 [70400/110534 (64%)]\tClassification Loss: 1.9562\r\n",
      "Train Epoch: 8 [71040/110534 (64%)]\tClassification Loss: 1.5452\r\n",
      "Train Epoch: 8 [71680/110534 (65%)]\tClassification Loss: 1.3190\r\n",
      "Train Epoch: 8 [72320/110534 (65%)]\tClassification Loss: 1.4723\r\n",
      "Train Epoch: 8 [72960/110534 (66%)]\tClassification Loss: 1.3251\r\n",
      "Train Epoch: 8 [73600/110534 (67%)]\tClassification Loss: 1.6520\r\n",
      "Train Epoch: 8 [74240/110534 (67%)]\tClassification Loss: 1.5540\r\n",
      "Train Epoch: 8 [74880/110534 (68%)]\tClassification Loss: 1.4389\r\n",
      "Train Epoch: 8 [75520/110534 (68%)]\tClassification Loss: 1.7091\r\n",
      "Train Epoch: 8 [76160/110534 (69%)]\tClassification Loss: 1.6280\r\n",
      "Train Epoch: 8 [76800/110534 (69%)]\tClassification Loss: 1.7427\r\n",
      "\r\n",
      "Test set: Average loss: 1.4520, Accuracy: 7008/12800 (55%)\r\n",
      "\r\n",
      "Train Epoch: 8 [77440/110534 (70%)]\tClassification Loss: 1.6485\r\n",
      "Train Epoch: 8 [78080/110534 (71%)]\tClassification Loss: 1.4150\r\n",
      "Train Epoch: 8 [78720/110534 (71%)]\tClassification Loss: 1.6228\r\n",
      "Train Epoch: 8 [79360/110534 (72%)]\tClassification Loss: 1.7690\r\n",
      "Train Epoch: 8 [80000/110534 (72%)]\tClassification Loss: 1.4207\r\n",
      "Train Epoch: 8 [80640/110534 (73%)]\tClassification Loss: 1.4807\r\n",
      "Train Epoch: 8 [81280/110534 (74%)]\tClassification Loss: 1.4410\r\n",
      "Train Epoch: 8 [81920/110534 (74%)]\tClassification Loss: 1.4784\r\n",
      "Train Epoch: 8 [82560/110534 (75%)]\tClassification Loss: 1.8729\r\n",
      "Train Epoch: 8 [83200/110534 (75%)]\tClassification Loss: 1.3282\r\n",
      "Train Epoch: 8 [83840/110534 (76%)]\tClassification Loss: 1.7006\r\n",
      "Train Epoch: 8 [84480/110534 (76%)]\tClassification Loss: 1.3970\r\n",
      "Train Epoch: 8 [85120/110534 (77%)]\tClassification Loss: 1.8213\r\n",
      "Train Epoch: 8 [85760/110534 (78%)]\tClassification Loss: 1.6278\r\n",
      "Train Epoch: 8 [86400/110534 (78%)]\tClassification Loss: 1.4571\r\n",
      "Train Epoch: 8 [87040/110534 (79%)]\tClassification Loss: 1.3320\r\n",
      "Train Epoch: 8 [87680/110534 (79%)]\tClassification Loss: 1.7290\r\n",
      "Train Epoch: 8 [88320/110534 (80%)]\tClassification Loss: 1.4481\r\n",
      "Train Epoch: 8 [88960/110534 (80%)]\tClassification Loss: 1.3517\r\n",
      "Train Epoch: 8 [89600/110534 (81%)]\tClassification Loss: 1.5612\r\n",
      "Train Epoch: 8 [90240/110534 (82%)]\tClassification Loss: 1.7838\r\n",
      "Train Epoch: 8 [90880/110534 (82%)]\tClassification Loss: 1.4398\r\n",
      "Train Epoch: 8 [91520/110534 (83%)]\tClassification Loss: 1.5015\r\n",
      "Train Epoch: 8 [92160/110534 (83%)]\tClassification Loss: 1.4642\r\n",
      "Train Epoch: 8 [92800/110534 (84%)]\tClassification Loss: 1.5603\r\n",
      "Train Epoch: 8 [93440/110534 (85%)]\tClassification Loss: 1.5676\r\n",
      "Train Epoch: 8 [94080/110534 (85%)]\tClassification Loss: 1.3537\r\n",
      "Train Epoch: 8 [94720/110534 (86%)]\tClassification Loss: 1.6875\r\n",
      "Train Epoch: 8 [95360/110534 (86%)]\tClassification Loss: 1.3775\r\n",
      "Train Epoch: 8 [96000/110534 (87%)]\tClassification Loss: 1.7956\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_1500.pth.tar\r\n",
      "Train Epoch: 8 [96640/110534 (87%)]\tClassification Loss: 1.5365\r\n",
      "Train Epoch: 8 [97280/110534 (88%)]\tClassification Loss: 1.6076\r\n",
      "Train Epoch: 8 [97920/110534 (89%)]\tClassification Loss: 1.4269\r\n",
      "Train Epoch: 8 [98560/110534 (89%)]\tClassification Loss: 1.4184\r\n",
      "Train Epoch: 8 [99200/110534 (90%)]\tClassification Loss: 1.8420\r\n",
      "Train Epoch: 8 [99840/110534 (90%)]\tClassification Loss: 1.5391\r\n",
      "Train Epoch: 8 [100480/110534 (91%)]\tClassification Loss: 1.4615\r\n",
      "Train Epoch: 8 [101120/110534 (91%)]\tClassification Loss: 1.4830\r\n",
      "Train Epoch: 8 [101760/110534 (92%)]\tClassification Loss: 1.7547\r\n",
      "Train Epoch: 8 [102400/110534 (93%)]\tClassification Loss: 1.7420\r\n",
      "Train Epoch: 8 [103040/110534 (93%)]\tClassification Loss: 1.5876\r\n",
      "Train Epoch: 8 [103680/110534 (94%)]\tClassification Loss: 1.3693\r\n",
      "Train Epoch: 8 [104320/110534 (94%)]\tClassification Loss: 1.4697\r\n",
      "Train Epoch: 8 [104960/110534 (95%)]\tClassification Loss: 1.6054\r\n",
      "Train Epoch: 8 [105600/110534 (96%)]\tClassification Loss: 1.8082\r\n",
      "Train Epoch: 8 [106240/110534 (96%)]\tClassification Loss: 1.3315\r\n",
      "Train Epoch: 8 [106880/110534 (97%)]\tClassification Loss: 1.6067\r\n",
      "Train Epoch: 8 [107520/110534 (97%)]\tClassification Loss: 1.5660\r\n",
      "Train Epoch: 8 [108160/110534 (98%)]\tClassification Loss: 1.2918\r\n",
      "Train Epoch: 8 [108800/110534 (98%)]\tClassification Loss: 1.4409\r\n",
      "Train Epoch: 8 [109440/110534 (99%)]\tClassification Loss: 1.6022\r\n",
      "Train Epoch: 8 [110080/110534 (100%)]\tClassification Loss: 1.6211\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_final.pth.tar\r\n",
      "Train Epoch: 9 [0/110534 (0%)]\tClassification Loss: 1.8176\r\n",
      "\r\n",
      "Test set: Average loss: 1.4579, Accuracy: 6999/12800 (55%)\r\n",
      "\r\n",
      "Train Epoch: 9 [640/110534 (1%)]\tClassification Loss: 1.6426\r\n",
      "Train Epoch: 9 [1280/110534 (1%)]\tClassification Loss: 1.4364\r\n",
      "Train Epoch: 9 [1920/110534 (2%)]\tClassification Loss: 1.4120\r\n",
      "Train Epoch: 9 [2560/110534 (2%)]\tClassification Loss: 1.7332\r\n",
      "Train Epoch: 9 [3200/110534 (3%)]\tClassification Loss: 1.4926\r\n",
      "Train Epoch: 9 [3840/110534 (3%)]\tClassification Loss: 1.5384\r\n",
      "Train Epoch: 9 [4480/110534 (4%)]\tClassification Loss: 1.3855\r\n",
      "Train Epoch: 9 [5120/110534 (5%)]\tClassification Loss: 1.6640\r\n",
      "Train Epoch: 9 [5760/110534 (5%)]\tClassification Loss: 1.6157\r\n",
      "Train Epoch: 9 [6400/110534 (6%)]\tClassification Loss: 1.7778\r\n",
      "Train Epoch: 9 [7040/110534 (6%)]\tClassification Loss: 1.8447\r\n",
      "Train Epoch: 9 [7680/110534 (7%)]\tClassification Loss: 1.3151\r\n",
      "Train Epoch: 9 [8320/110534 (8%)]\tClassification Loss: 1.7440\r\n",
      "Train Epoch: 9 [8960/110534 (8%)]\tClassification Loss: 1.4514\r\n",
      "Train Epoch: 9 [9600/110534 (9%)]\tClassification Loss: 1.4763\r\n",
      "Train Epoch: 9 [10240/110534 (9%)]\tClassification Loss: 1.3171\r\n",
      "Train Epoch: 9 [10880/110534 (10%)]\tClassification Loss: 1.6294\r\n",
      "Train Epoch: 9 [11520/110534 (10%)]\tClassification Loss: 1.4179\r\n",
      "Train Epoch: 9 [12160/110534 (11%)]\tClassification Loss: 1.4411\r\n",
      "Train Epoch: 9 [12800/110534 (12%)]\tClassification Loss: 1.7229\r\n",
      "Train Epoch: 9 [13440/110534 (12%)]\tClassification Loss: 1.5063\r\n",
      "Train Epoch: 9 [14080/110534 (13%)]\tClassification Loss: 1.5619\r\n",
      "Train Epoch: 9 [14720/110534 (13%)]\tClassification Loss: 1.5755\r\n",
      "Train Epoch: 9 [15360/110534 (14%)]\tClassification Loss: 1.6574\r\n",
      "Train Epoch: 9 [16000/110534 (14%)]\tClassification Loss: 1.6326\r\n",
      "Train Epoch: 9 [16640/110534 (15%)]\tClassification Loss: 1.6378\r\n",
      "Train Epoch: 9 [17280/110534 (16%)]\tClassification Loss: 1.6761\r\n",
      "Train Epoch: 9 [17920/110534 (16%)]\tClassification Loss: 1.7378\r\n",
      "Train Epoch: 9 [18560/110534 (17%)]\tClassification Loss: 1.6040\r\n",
      "Train Epoch: 9 [19200/110534 (17%)]\tClassification Loss: 1.4844\r\n",
      "Train Epoch: 9 [19840/110534 (18%)]\tClassification Loss: 1.5125\r\n",
      "Train Epoch: 9 [20480/110534 (19%)]\tClassification Loss: 1.6679\r\n",
      "Train Epoch: 9 [21120/110534 (19%)]\tClassification Loss: 1.5435\r\n",
      "Train Epoch: 9 [21760/110534 (20%)]\tClassification Loss: 1.5646\r\n",
      "Train Epoch: 9 [22400/110534 (20%)]\tClassification Loss: 1.6081\r\n",
      "Train Epoch: 9 [23040/110534 (21%)]\tClassification Loss: 1.4467\r\n",
      "Train Epoch: 9 [23680/110534 (21%)]\tClassification Loss: 1.5269\r\n",
      "Train Epoch: 9 [24320/110534 (22%)]\tClassification Loss: 1.5922\r\n",
      "Train Epoch: 9 [24960/110534 (23%)]\tClassification Loss: 1.5125\r\n",
      "Train Epoch: 9 [25600/110534 (23%)]\tClassification Loss: 1.1917\r\n",
      "Train Epoch: 9 [26240/110534 (24%)]\tClassification Loss: 1.6620\r\n",
      "Train Epoch: 9 [26880/110534 (24%)]\tClassification Loss: 1.5774\r\n",
      "Train Epoch: 9 [27520/110534 (25%)]\tClassification Loss: 1.4661\r\n",
      "Train Epoch: 9 [28160/110534 (25%)]\tClassification Loss: 1.6596\r\n",
      "Train Epoch: 9 [28800/110534 (26%)]\tClassification Loss: 1.7004\r\n",
      "Train Epoch: 9 [29440/110534 (27%)]\tClassification Loss: 1.5957\r\n",
      "Train Epoch: 9 [30080/110534 (27%)]\tClassification Loss: 1.5791\r\n",
      "Train Epoch: 9 [30720/110534 (28%)]\tClassification Loss: 1.5895\r\n",
      "Train Epoch: 9 [31360/110534 (28%)]\tClassification Loss: 1.2096\r\n",
      "Train Epoch: 9 [32000/110534 (29%)]\tClassification Loss: 1.5203\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_500.pth.tar\r\n",
      "Train Epoch: 9 [32640/110534 (30%)]\tClassification Loss: 1.4761\r\n",
      "Train Epoch: 9 [33280/110534 (30%)]\tClassification Loss: 1.3875\r\n",
      "Train Epoch: 9 [33920/110534 (31%)]\tClassification Loss: 1.6964\r\n",
      "Train Epoch: 9 [34560/110534 (31%)]\tClassification Loss: 1.7061\r\n",
      "Train Epoch: 9 [35200/110534 (32%)]\tClassification Loss: 1.5502\r\n",
      "Train Epoch: 9 [35840/110534 (32%)]\tClassification Loss: 1.4766\r\n",
      "Train Epoch: 9 [36480/110534 (33%)]\tClassification Loss: 1.4140\r\n",
      "Train Epoch: 9 [37120/110534 (34%)]\tClassification Loss: 1.7458\r\n",
      "Train Epoch: 9 [37760/110534 (34%)]\tClassification Loss: 1.3217\r\n",
      "Train Epoch: 9 [38400/110534 (35%)]\tClassification Loss: 1.7873\r\n",
      "\r\n",
      "Test set: Average loss: 1.4639, Accuracy: 6970/12800 (54%)\r\n",
      "\r\n",
      "Train Epoch: 9 [39040/110534 (35%)]\tClassification Loss: 1.3831\r\n",
      "Train Epoch: 9 [39680/110534 (36%)]\tClassification Loss: 1.7683\r\n",
      "Train Epoch: 9 [40320/110534 (36%)]\tClassification Loss: 1.8625\r\n",
      "Train Epoch: 9 [40960/110534 (37%)]\tClassification Loss: 1.3461\r\n",
      "Train Epoch: 9 [41600/110534 (38%)]\tClassification Loss: 1.8129\r\n",
      "Train Epoch: 9 [42240/110534 (38%)]\tClassification Loss: 1.6612\r\n",
      "Train Epoch: 9 [42880/110534 (39%)]\tClassification Loss: 1.5515\r\n",
      "Train Epoch: 9 [43520/110534 (39%)]\tClassification Loss: 1.5712\r\n",
      "Train Epoch: 9 [44160/110534 (40%)]\tClassification Loss: 1.7709\r\n",
      "Train Epoch: 9 [44800/110534 (41%)]\tClassification Loss: 1.8187\r\n",
      "Train Epoch: 9 [45440/110534 (41%)]\tClassification Loss: 1.2124\r\n",
      "Train Epoch: 9 [46080/110534 (42%)]\tClassification Loss: 1.5905\r\n",
      "Train Epoch: 9 [46720/110534 (42%)]\tClassification Loss: 1.4026\r\n",
      "Train Epoch: 9 [47360/110534 (43%)]\tClassification Loss: 1.3945\r\n",
      "Train Epoch: 9 [48000/110534 (43%)]\tClassification Loss: 1.7152\r\n",
      "Train Epoch: 9 [48640/110534 (44%)]\tClassification Loss: 1.7390\r\n",
      "Train Epoch: 9 [49280/110534 (45%)]\tClassification Loss: 1.4310\r\n",
      "Train Epoch: 9 [49920/110534 (45%)]\tClassification Loss: 1.4244\r\n",
      "Train Epoch: 9 [50560/110534 (46%)]\tClassification Loss: 1.6604\r\n",
      "Train Epoch: 9 [51200/110534 (46%)]\tClassification Loss: 1.5123\r\n",
      "Train Epoch: 9 [51840/110534 (47%)]\tClassification Loss: 1.5151\r\n",
      "Train Epoch: 9 [52480/110534 (47%)]\tClassification Loss: 1.4539\r\n",
      "Train Epoch: 9 [53120/110534 (48%)]\tClassification Loss: 1.5802\r\n",
      "Train Epoch: 9 [53760/110534 (49%)]\tClassification Loss: 1.4901\r\n",
      "Train Epoch: 9 [54400/110534 (49%)]\tClassification Loss: 1.3666\r\n",
      "Train Epoch: 9 [55040/110534 (50%)]\tClassification Loss: 1.4149\r\n",
      "Train Epoch: 9 [55680/110534 (50%)]\tClassification Loss: 1.6583\r\n",
      "Train Epoch: 9 [56320/110534 (51%)]\tClassification Loss: 1.7129\r\n",
      "Train Epoch: 9 [56960/110534 (52%)]\tClassification Loss: 1.8450\r\n",
      "Train Epoch: 9 [57600/110534 (52%)]\tClassification Loss: 1.4951\r\n",
      "Train Epoch: 9 [58240/110534 (53%)]\tClassification Loss: 1.5295\r\n",
      "Train Epoch: 9 [58880/110534 (53%)]\tClassification Loss: 1.4322\r\n",
      "Train Epoch: 9 [59520/110534 (54%)]\tClassification Loss: 1.5967\r\n",
      "Train Epoch: 9 [60160/110534 (54%)]\tClassification Loss: 1.5644\r\n",
      "Train Epoch: 9 [60800/110534 (55%)]\tClassification Loss: 1.3908\r\n",
      "Train Epoch: 9 [61440/110534 (56%)]\tClassification Loss: 1.6799\r\n",
      "Train Epoch: 9 [62080/110534 (56%)]\tClassification Loss: 1.4458\r\n",
      "Train Epoch: 9 [62720/110534 (57%)]\tClassification Loss: 1.5711\r\n",
      "Train Epoch: 9 [63360/110534 (57%)]\tClassification Loss: 1.5580\r\n",
      "Train Epoch: 9 [64000/110534 (58%)]\tClassification Loss: 1.6762\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_1000.pth.tar\r\n",
      "Train Epoch: 9 [64640/110534 (58%)]\tClassification Loss: 1.7605\r\n",
      "Train Epoch: 9 [65280/110534 (59%)]\tClassification Loss: 1.8020\r\n",
      "Train Epoch: 9 [65920/110534 (60%)]\tClassification Loss: 1.3324\r\n",
      "Train Epoch: 9 [66560/110534 (60%)]\tClassification Loss: 1.4117\r\n",
      "Train Epoch: 9 [67200/110534 (61%)]\tClassification Loss: 1.5519\r\n",
      "Train Epoch: 9 [67840/110534 (61%)]\tClassification Loss: 1.6085\r\n",
      "Train Epoch: 9 [68480/110534 (62%)]\tClassification Loss: 1.5381\r\n",
      "Train Epoch: 9 [69120/110534 (63%)]\tClassification Loss: 1.6494\r\n",
      "Train Epoch: 9 [69760/110534 (63%)]\tClassification Loss: 1.3859\r\n",
      "Train Epoch: 9 [70400/110534 (64%)]\tClassification Loss: 1.6929\r\n",
      "Train Epoch: 9 [71040/110534 (64%)]\tClassification Loss: 1.7566\r\n",
      "Train Epoch: 9 [71680/110534 (65%)]\tClassification Loss: 1.3039\r\n",
      "Train Epoch: 9 [72320/110534 (65%)]\tClassification Loss: 1.5422\r\n",
      "Train Epoch: 9 [72960/110534 (66%)]\tClassification Loss: 1.4325\r\n",
      "Train Epoch: 9 [73600/110534 (67%)]\tClassification Loss: 1.7109\r\n",
      "Train Epoch: 9 [74240/110534 (67%)]\tClassification Loss: 1.4509\r\n",
      "Train Epoch: 9 [74880/110534 (68%)]\tClassification Loss: 1.5008\r\n",
      "Train Epoch: 9 [75520/110534 (68%)]\tClassification Loss: 1.6734\r\n",
      "Train Epoch: 9 [76160/110534 (69%)]\tClassification Loss: 1.6051\r\n",
      "Train Epoch: 9 [76800/110534 (69%)]\tClassification Loss: 1.9993\r\n",
      "\r\n",
      "Test set: Average loss: 1.4499, Accuracy: 6993/12800 (55%)\r\n",
      "\r\n",
      "Train Epoch: 9 [77440/110534 (70%)]\tClassification Loss: 1.6266\r\n",
      "Train Epoch: 9 [78080/110534 (71%)]\tClassification Loss: 1.4655\r\n",
      "Train Epoch: 9 [78720/110534 (71%)]\tClassification Loss: 1.6120\r\n",
      "Train Epoch: 9 [79360/110534 (72%)]\tClassification Loss: 1.8995\r\n",
      "Train Epoch: 9 [80000/110534 (72%)]\tClassification Loss: 1.3499\r\n",
      "Train Epoch: 9 [80640/110534 (73%)]\tClassification Loss: 1.5283\r\n",
      "Train Epoch: 9 [81280/110534 (74%)]\tClassification Loss: 1.2346\r\n",
      "Train Epoch: 9 [81920/110534 (74%)]\tClassification Loss: 1.5578\r\n",
      "Train Epoch: 9 [82560/110534 (75%)]\tClassification Loss: 1.7048\r\n",
      "Train Epoch: 9 [83200/110534 (75%)]\tClassification Loss: 1.4211\r\n",
      "Train Epoch: 9 [83840/110534 (76%)]\tClassification Loss: 1.7633\r\n",
      "Train Epoch: 9 [84480/110534 (76%)]\tClassification Loss: 1.3705\r\n",
      "Train Epoch: 9 [85120/110534 (77%)]\tClassification Loss: 1.7161\r\n",
      "Train Epoch: 9 [85760/110534 (78%)]\tClassification Loss: 1.4718\r\n",
      "Train Epoch: 9 [86400/110534 (78%)]\tClassification Loss: 1.5421\r\n",
      "Train Epoch: 9 [87040/110534 (79%)]\tClassification Loss: 1.4237\r\n",
      "Train Epoch: 9 [87680/110534 (79%)]\tClassification Loss: 1.5461\r\n",
      "Train Epoch: 9 [88320/110534 (80%)]\tClassification Loss: 1.3552\r\n",
      "Train Epoch: 9 [88960/110534 (80%)]\tClassification Loss: 1.3595\r\n",
      "Train Epoch: 9 [89600/110534 (81%)]\tClassification Loss: 1.3771\r\n",
      "Train Epoch: 9 [90240/110534 (82%)]\tClassification Loss: 1.7280\r\n",
      "Train Epoch: 9 [90880/110534 (82%)]\tClassification Loss: 1.5426\r\n",
      "Train Epoch: 9 [91520/110534 (83%)]\tClassification Loss: 1.5743\r\n",
      "Train Epoch: 9 [92160/110534 (83%)]\tClassification Loss: 1.3896\r\n",
      "Train Epoch: 9 [92800/110534 (84%)]\tClassification Loss: 1.4447\r\n",
      "Train Epoch: 9 [93440/110534 (85%)]\tClassification Loss: 1.5844\r\n",
      "Train Epoch: 9 [94080/110534 (85%)]\tClassification Loss: 1.5581\r\n",
      "Train Epoch: 9 [94720/110534 (86%)]\tClassification Loss: 1.7527\r\n",
      "Train Epoch: 9 [95360/110534 (86%)]\tClassification Loss: 1.5176\r\n",
      "Train Epoch: 9 [96000/110534 (87%)]\tClassification Loss: 1.8226\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_1500.pth.tar\r\n",
      "Train Epoch: 9 [96640/110534 (87%)]\tClassification Loss: 1.5335\r\n",
      "Train Epoch: 9 [97280/110534 (88%)]\tClassification Loss: 1.6355\r\n",
      "Train Epoch: 9 [97920/110534 (89%)]\tClassification Loss: 1.4470\r\n",
      "Train Epoch: 9 [98560/110534 (89%)]\tClassification Loss: 1.4308\r\n",
      "Train Epoch: 9 [99200/110534 (90%)]\tClassification Loss: 1.8958\r\n",
      "Train Epoch: 9 [99840/110534 (90%)]\tClassification Loss: 1.4947\r\n",
      "Train Epoch: 9 [100480/110534 (91%)]\tClassification Loss: 1.4946\r\n",
      "Train Epoch: 9 [101120/110534 (91%)]\tClassification Loss: 1.4241\r\n",
      "Train Epoch: 9 [101760/110534 (92%)]\tClassification Loss: 1.7226\r\n",
      "Train Epoch: 9 [102400/110534 (93%)]\tClassification Loss: 1.7232\r\n",
      "Train Epoch: 9 [103040/110534 (93%)]\tClassification Loss: 1.6170\r\n",
      "Train Epoch: 9 [103680/110534 (94%)]\tClassification Loss: 1.4459\r\n",
      "Train Epoch: 9 [104320/110534 (94%)]\tClassification Loss: 1.4316\r\n",
      "Train Epoch: 9 [104960/110534 (95%)]\tClassification Loss: 1.5773\r\n",
      "Train Epoch: 9 [105600/110534 (96%)]\tClassification Loss: 1.6858\r\n",
      "Train Epoch: 9 [106240/110534 (96%)]\tClassification Loss: 1.3412\r\n",
      "Train Epoch: 9 [106880/110534 (97%)]\tClassification Loss: 1.3984\r\n",
      "Train Epoch: 9 [107520/110534 (97%)]\tClassification Loss: 1.4580\r\n",
      "Train Epoch: 9 [108160/110534 (98%)]\tClassification Loss: 1.4885\r\n",
      "Train Epoch: 9 [108800/110534 (98%)]\tClassification Loss: 1.4542\r\n",
      "Train Epoch: 9 [109440/110534 (99%)]\tClassification Loss: 1.5720\r\n",
      "Train Epoch: 9 [110080/110534 (100%)]\tClassification Loss: 1.7546\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_final.pth.tar\r\n",
      "Train Epoch: 10 [0/110534 (0%)]\tClassification Loss: 1.7021\r\n",
      "\r\n",
      "Test set: Average loss: 1.4532, Accuracy: 6996/12800 (55%)\r\n",
      "\r\n",
      "Train Epoch: 10 [640/110534 (1%)]\tClassification Loss: 1.5539\r\n",
      "Train Epoch: 10 [1280/110534 (1%)]\tClassification Loss: 1.5793\r\n",
      "Train Epoch: 10 [1920/110534 (2%)]\tClassification Loss: 1.4151\r\n",
      "Train Epoch: 10 [2560/110534 (2%)]\tClassification Loss: 1.6979\r\n",
      "Train Epoch: 10 [3200/110534 (3%)]\tClassification Loss: 1.4584\r\n",
      "Train Epoch: 10 [3840/110534 (3%)]\tClassification Loss: 1.5937\r\n",
      "Train Epoch: 10 [4480/110534 (4%)]\tClassification Loss: 1.4691\r\n",
      "Train Epoch: 10 [5120/110534 (5%)]\tClassification Loss: 1.5988\r\n",
      "Train Epoch: 10 [5760/110534 (5%)]\tClassification Loss: 1.6338\r\n",
      "Train Epoch: 10 [6400/110534 (6%)]\tClassification Loss: 1.8471\r\n",
      "Train Epoch: 10 [7040/110534 (6%)]\tClassification Loss: 1.5691\r\n",
      "Train Epoch: 10 [7680/110534 (7%)]\tClassification Loss: 1.3834\r\n",
      "Train Epoch: 10 [8320/110534 (8%)]\tClassification Loss: 1.7093\r\n",
      "Train Epoch: 10 [8960/110534 (8%)]\tClassification Loss: 1.5583\r\n",
      "Train Epoch: 10 [9600/110534 (9%)]\tClassification Loss: 1.7220\r\n",
      "Train Epoch: 10 [10240/110534 (9%)]\tClassification Loss: 1.3299\r\n",
      "Train Epoch: 10 [10880/110534 (10%)]\tClassification Loss: 1.6322\r\n",
      "Train Epoch: 10 [11520/110534 (10%)]\tClassification Loss: 1.5173\r\n",
      "Train Epoch: 10 [12160/110534 (11%)]\tClassification Loss: 1.5135\r\n",
      "Train Epoch: 10 [12800/110534 (12%)]\tClassification Loss: 1.7048\r\n",
      "Train Epoch: 10 [13440/110534 (12%)]\tClassification Loss: 1.5407\r\n",
      "Train Epoch: 10 [14080/110534 (13%)]\tClassification Loss: 1.5288\r\n",
      "Train Epoch: 10 [14720/110534 (13%)]\tClassification Loss: 1.6860\r\n",
      "Train Epoch: 10 [15360/110534 (14%)]\tClassification Loss: 1.5284\r\n",
      "Train Epoch: 10 [16000/110534 (14%)]\tClassification Loss: 1.7639\r\n",
      "Train Epoch: 10 [16640/110534 (15%)]\tClassification Loss: 1.5572\r\n",
      "Train Epoch: 10 [17280/110534 (16%)]\tClassification Loss: 1.8139\r\n",
      "Train Epoch: 10 [17920/110534 (16%)]\tClassification Loss: 1.7756\r\n",
      "Train Epoch: 10 [18560/110534 (17%)]\tClassification Loss: 1.4661\r\n",
      "Train Epoch: 10 [19200/110534 (17%)]\tClassification Loss: 1.7394\r\n",
      "Train Epoch: 10 [19840/110534 (18%)]\tClassification Loss: 1.3590\r\n",
      "Train Epoch: 10 [20480/110534 (19%)]\tClassification Loss: 1.6981\r\n",
      "Train Epoch: 10 [21120/110534 (19%)]\tClassification Loss: 1.6109\r\n",
      "Train Epoch: 10 [21760/110534 (20%)]\tClassification Loss: 1.6443\r\n",
      "Train Epoch: 10 [22400/110534 (20%)]\tClassification Loss: 1.7120\r\n",
      "Train Epoch: 10 [23040/110534 (21%)]\tClassification Loss: 1.5503\r\n",
      "Train Epoch: 10 [23680/110534 (21%)]\tClassification Loss: 1.6646\r\n",
      "Train Epoch: 10 [24320/110534 (22%)]\tClassification Loss: 1.4140\r\n",
      "Train Epoch: 10 [24960/110534 (23%)]\tClassification Loss: 1.6201\r\n",
      "Train Epoch: 10 [25600/110534 (23%)]\tClassification Loss: 1.2302\r\n",
      "Train Epoch: 10 [26240/110534 (24%)]\tClassification Loss: 1.5753\r\n",
      "Train Epoch: 10 [26880/110534 (24%)]\tClassification Loss: 1.5645\r\n",
      "Train Epoch: 10 [27520/110534 (25%)]\tClassification Loss: 1.6483\r\n",
      "Train Epoch: 10 [28160/110534 (25%)]\tClassification Loss: 1.7133\r\n",
      "Train Epoch: 10 [28800/110534 (26%)]\tClassification Loss: 1.6878\r\n",
      "Train Epoch: 10 [29440/110534 (27%)]\tClassification Loss: 1.4878\r\n",
      "Train Epoch: 10 [30080/110534 (27%)]\tClassification Loss: 1.5993\r\n",
      "Train Epoch: 10 [30720/110534 (28%)]\tClassification Loss: 1.2348\r\n",
      "Train Epoch: 10 [31360/110534 (28%)]\tClassification Loss: 1.2257\r\n",
      "Train Epoch: 10 [32000/110534 (29%)]\tClassification Loss: 1.5703\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_500.pth.tar\r\n",
      "Train Epoch: 10 [32640/110534 (30%)]\tClassification Loss: 1.3939\r\n",
      "Train Epoch: 10 [33280/110534 (30%)]\tClassification Loss: 1.4449\r\n",
      "Train Epoch: 10 [33920/110534 (31%)]\tClassification Loss: 1.5347\r\n",
      "Train Epoch: 10 [34560/110534 (31%)]\tClassification Loss: 1.5231\r\n",
      "Train Epoch: 10 [35200/110534 (32%)]\tClassification Loss: 1.4727\r\n",
      "Train Epoch: 10 [35840/110534 (32%)]\tClassification Loss: 1.5021\r\n",
      "Train Epoch: 10 [36480/110534 (33%)]\tClassification Loss: 1.5905\r\n",
      "Train Epoch: 10 [37120/110534 (34%)]\tClassification Loss: 1.6916\r\n",
      "Train Epoch: 10 [37760/110534 (34%)]\tClassification Loss: 1.5227\r\n",
      "Train Epoch: 10 [38400/110534 (35%)]\tClassification Loss: 1.5778\r\n",
      "\r\n",
      "Test set: Average loss: 1.4599, Accuracy: 6952/12800 (54%)\r\n",
      "\r\n",
      "Train Epoch: 10 [39040/110534 (35%)]\tClassification Loss: 1.2795\r\n",
      "Train Epoch: 10 [39680/110534 (36%)]\tClassification Loss: 1.6940\r\n",
      "Train Epoch: 10 [40320/110534 (36%)]\tClassification Loss: 1.8536\r\n",
      "Train Epoch: 10 [40960/110534 (37%)]\tClassification Loss: 1.4469\r\n",
      "Train Epoch: 10 [41600/110534 (38%)]\tClassification Loss: 1.8386\r\n",
      "Train Epoch: 10 [42240/110534 (38%)]\tClassification Loss: 1.7778\r\n",
      "Train Epoch: 10 [42880/110534 (39%)]\tClassification Loss: 1.5178\r\n",
      "Train Epoch: 10 [43520/110534 (39%)]\tClassification Loss: 1.5481\r\n",
      "Train Epoch: 10 [44160/110534 (40%)]\tClassification Loss: 1.6275\r\n",
      "Train Epoch: 10 [44800/110534 (41%)]\tClassification Loss: 1.6533\r\n",
      "Train Epoch: 10 [45440/110534 (41%)]\tClassification Loss: 1.2852\r\n",
      "Train Epoch: 10 [46080/110534 (42%)]\tClassification Loss: 1.5120\r\n",
      "Train Epoch: 10 [46720/110534 (42%)]\tClassification Loss: 1.3922\r\n",
      "Train Epoch: 10 [47360/110534 (43%)]\tClassification Loss: 1.3756\r\n",
      "Train Epoch: 10 [48000/110534 (43%)]\tClassification Loss: 1.7205\r\n",
      "Train Epoch: 10 [48640/110534 (44%)]\tClassification Loss: 1.7498\r\n",
      "Train Epoch: 10 [49280/110534 (45%)]\tClassification Loss: 1.3623\r\n",
      "Train Epoch: 10 [49920/110534 (45%)]\tClassification Loss: 1.4057\r\n",
      "Train Epoch: 10 [50560/110534 (46%)]\tClassification Loss: 1.6677\r\n",
      "Train Epoch: 10 [51200/110534 (46%)]\tClassification Loss: 1.7118\r\n",
      "Train Epoch: 10 [51840/110534 (47%)]\tClassification Loss: 1.4365\r\n",
      "Train Epoch: 10 [52480/110534 (47%)]\tClassification Loss: 1.4535\r\n",
      "Train Epoch: 10 [53120/110534 (48%)]\tClassification Loss: 1.6275\r\n",
      "Train Epoch: 10 [53760/110534 (49%)]\tClassification Loss: 1.5968\r\n",
      "Train Epoch: 10 [54400/110534 (49%)]\tClassification Loss: 1.2944\r\n",
      "Train Epoch: 10 [55040/110534 (50%)]\tClassification Loss: 1.3351\r\n",
      "Train Epoch: 10 [55680/110534 (50%)]\tClassification Loss: 1.7324\r\n",
      "Train Epoch: 10 [56320/110534 (51%)]\tClassification Loss: 1.6608\r\n",
      "Train Epoch: 10 [56960/110534 (52%)]\tClassification Loss: 1.9055\r\n",
      "Train Epoch: 10 [57600/110534 (52%)]\tClassification Loss: 1.5021\r\n",
      "Train Epoch: 10 [58240/110534 (53%)]\tClassification Loss: 1.4775\r\n",
      "Train Epoch: 10 [58880/110534 (53%)]\tClassification Loss: 1.3938\r\n",
      "Train Epoch: 10 [59520/110534 (54%)]\tClassification Loss: 1.5228\r\n",
      "Train Epoch: 10 [60160/110534 (54%)]\tClassification Loss: 1.4223\r\n",
      "Train Epoch: 10 [60800/110534 (55%)]\tClassification Loss: 1.4072\r\n",
      "Train Epoch: 10 [61440/110534 (56%)]\tClassification Loss: 1.7944\r\n",
      "Train Epoch: 10 [62080/110534 (56%)]\tClassification Loss: 1.5684\r\n",
      "Train Epoch: 10 [62720/110534 (57%)]\tClassification Loss: 1.6030\r\n",
      "Train Epoch: 10 [63360/110534 (57%)]\tClassification Loss: 1.6879\r\n",
      "Train Epoch: 10 [64000/110534 (58%)]\tClassification Loss: 1.7436\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_1000.pth.tar\r\n",
      "Train Epoch: 10 [64640/110534 (58%)]\tClassification Loss: 1.7213\r\n",
      "Train Epoch: 10 [65280/110534 (59%)]\tClassification Loss: 1.8383\r\n",
      "Train Epoch: 10 [65920/110534 (60%)]\tClassification Loss: 1.4144\r\n",
      "Train Epoch: 10 [66560/110534 (60%)]\tClassification Loss: 1.3986\r\n",
      "Train Epoch: 10 [67200/110534 (61%)]\tClassification Loss: 1.6060\r\n",
      "Train Epoch: 10 [67840/110534 (61%)]\tClassification Loss: 1.5989\r\n",
      "Train Epoch: 10 [68480/110534 (62%)]\tClassification Loss: 1.6303\r\n",
      "Train Epoch: 10 [69120/110534 (63%)]\tClassification Loss: 1.3783\r\n",
      "Train Epoch: 10 [69760/110534 (63%)]\tClassification Loss: 1.3157\r\n",
      "Train Epoch: 10 [70400/110534 (64%)]\tClassification Loss: 1.6368\r\n",
      "Train Epoch: 10 [71040/110534 (64%)]\tClassification Loss: 1.8372\r\n",
      "Train Epoch: 10 [71680/110534 (65%)]\tClassification Loss: 1.5296\r\n",
      "Train Epoch: 10 [72320/110534 (65%)]\tClassification Loss: 1.5008\r\n",
      "Train Epoch: 10 [72960/110534 (66%)]\tClassification Loss: 1.4420\r\n",
      "Train Epoch: 10 [73600/110534 (67%)]\tClassification Loss: 1.7176\r\n",
      "Train Epoch: 10 [74240/110534 (67%)]\tClassification Loss: 1.5120\r\n",
      "Train Epoch: 10 [74880/110534 (68%)]\tClassification Loss: 1.5382\r\n",
      "Train Epoch: 10 [75520/110534 (68%)]\tClassification Loss: 1.5661\r\n",
      "Train Epoch: 10 [76160/110534 (69%)]\tClassification Loss: 1.6988\r\n",
      "Train Epoch: 10 [76800/110534 (69%)]\tClassification Loss: 1.7465\r\n",
      "\r\n",
      "Test set: Average loss: 1.4475, Accuracy: 6983/12800 (55%)\r\n",
      "\r\n",
      "Train Epoch: 10 [77440/110534 (70%)]\tClassification Loss: 1.4984\r\n",
      "Train Epoch: 10 [78080/110534 (71%)]\tClassification Loss: 1.6191\r\n",
      "Train Epoch: 10 [78720/110534 (71%)]\tClassification Loss: 1.5094\r\n",
      "Train Epoch: 10 [79360/110534 (72%)]\tClassification Loss: 1.6297\r\n",
      "Train Epoch: 10 [80000/110534 (72%)]\tClassification Loss: 1.4260\r\n",
      "Train Epoch: 10 [80640/110534 (73%)]\tClassification Loss: 1.4285\r\n",
      "Train Epoch: 10 [81280/110534 (74%)]\tClassification Loss: 1.2413\r\n",
      "Train Epoch: 10 [81920/110534 (74%)]\tClassification Loss: 1.6143\r\n",
      "Train Epoch: 10 [82560/110534 (75%)]\tClassification Loss: 1.6686\r\n",
      "Train Epoch: 10 [83200/110534 (75%)]\tClassification Loss: 1.3266\r\n",
      "Train Epoch: 10 [83840/110534 (76%)]\tClassification Loss: 1.7665\r\n",
      "Train Epoch: 10 [84480/110534 (76%)]\tClassification Loss: 1.4414\r\n",
      "Train Epoch: 10 [85120/110534 (77%)]\tClassification Loss: 1.7706\r\n",
      "Train Epoch: 10 [85760/110534 (78%)]\tClassification Loss: 1.6164\r\n",
      "Train Epoch: 10 [86400/110534 (78%)]\tClassification Loss: 1.6369\r\n",
      "Train Epoch: 10 [87040/110534 (79%)]\tClassification Loss: 1.6331\r\n",
      "Train Epoch: 10 [87680/110534 (79%)]\tClassification Loss: 1.6566\r\n",
      "Train Epoch: 10 [88320/110534 (80%)]\tClassification Loss: 1.3324\r\n",
      "Train Epoch: 10 [88960/110534 (80%)]\tClassification Loss: 1.2698\r\n",
      "Train Epoch: 10 [89600/110534 (81%)]\tClassification Loss: 1.3952\r\n",
      "Train Epoch: 10 [90240/110534 (82%)]\tClassification Loss: 1.8582\r\n",
      "Train Epoch: 10 [90880/110534 (82%)]\tClassification Loss: 1.3813\r\n",
      "Train Epoch: 10 [91520/110534 (83%)]\tClassification Loss: 1.6284\r\n",
      "Train Epoch: 10 [92160/110534 (83%)]\tClassification Loss: 1.5174\r\n",
      "Train Epoch: 10 [92800/110534 (84%)]\tClassification Loss: 1.7175\r\n",
      "Train Epoch: 10 [93440/110534 (85%)]\tClassification Loss: 1.5770\r\n",
      "Train Epoch: 10 [94080/110534 (85%)]\tClassification Loss: 1.3784\r\n",
      "Train Epoch: 10 [94720/110534 (86%)]\tClassification Loss: 1.6815\r\n",
      "Train Epoch: 10 [95360/110534 (86%)]\tClassification Loss: 1.4929\r\n",
      "Train Epoch: 10 [96000/110534 (87%)]\tClassification Loss: 1.8923\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_1500.pth.tar\r\n",
      "Train Epoch: 10 [96640/110534 (87%)]\tClassification Loss: 1.5387\r\n",
      "Train Epoch: 10 [97280/110534 (88%)]\tClassification Loss: 1.7101\r\n",
      "Train Epoch: 10 [97920/110534 (89%)]\tClassification Loss: 1.3628\r\n",
      "Train Epoch: 10 [98560/110534 (89%)]\tClassification Loss: 1.4915\r\n",
      "Train Epoch: 10 [99200/110534 (90%)]\tClassification Loss: 1.9198\r\n",
      "Train Epoch: 10 [99840/110534 (90%)]\tClassification Loss: 1.5843\r\n",
      "Train Epoch: 10 [100480/110534 (91%)]\tClassification Loss: 1.5543\r\n",
      "Train Epoch: 10 [101120/110534 (91%)]\tClassification Loss: 1.4130\r\n",
      "Train Epoch: 10 [101760/110534 (92%)]\tClassification Loss: 1.6391\r\n",
      "Train Epoch: 10 [102400/110534 (93%)]\tClassification Loss: 1.7455\r\n",
      "Train Epoch: 10 [103040/110534 (93%)]\tClassification Loss: 1.5771\r\n",
      "Train Epoch: 10 [103680/110534 (94%)]\tClassification Loss: 1.4421\r\n",
      "Train Epoch: 10 [104320/110534 (94%)]\tClassification Loss: 1.3573\r\n",
      "Train Epoch: 10 [104960/110534 (95%)]\tClassification Loss: 1.6280\r\n",
      "Train Epoch: 10 [105600/110534 (96%)]\tClassification Loss: 1.8501\r\n",
      "Train Epoch: 10 [106240/110534 (96%)]\tClassification Loss: 1.3375\r\n",
      "Train Epoch: 10 [106880/110534 (97%)]\tClassification Loss: 1.3487\r\n",
      "Train Epoch: 10 [107520/110534 (97%)]\tClassification Loss: 1.5015\r\n",
      "Train Epoch: 10 [108160/110534 (98%)]\tClassification Loss: 1.3892\r\n",
      "Train Epoch: 10 [108800/110534 (98%)]\tClassification Loss: 1.4274\r\n",
      "Train Epoch: 10 [109440/110534 (99%)]\tClassification Loss: 1.5980\r\n",
      "Train Epoch: 10 [110080/110534 (100%)]\tClassification Loss: 1.6989\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_final.pth.tar\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oFYsssLDaSDJ",
    "colab_type": "code",
    "outputId": "c8b0c1e4-9039-4b20-cef8-c971efa437aa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1584954545220,
     "user_tz": -300,
     "elapsed": 3922822,
     "user": {
      "displayName": "Muhammad Ali",
      "photoUrl": "",
      "userId": "15673831022739340207"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "# Freeze=True. LR=0.05\n",
    "! python train.py"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Train Epoch: 1 [0/110534 (0%)]\tClassification Loss: 3.2919\r\n",
      "train.py:172: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 3.2468, Accuracy: 257/42368 (1%)\r\n",
      "\r\n",
      "Train Epoch: 1 [640/110534 (1%)]\tClassification Loss: 2.5549\r\n",
      "Train Epoch: 1 [1280/110534 (1%)]\tClassification Loss: 2.5333\r\n",
      "Train Epoch: 1 [1920/110534 (2%)]\tClassification Loss: 2.2296\r\n",
      "Train Epoch: 1 [2560/110534 (2%)]\tClassification Loss: 2.1743\r\n",
      "Train Epoch: 1 [3200/110534 (3%)]\tClassification Loss: 2.2104\r\n",
      "Train Epoch: 1 [3840/110534 (3%)]\tClassification Loss: 2.5181\r\n",
      "Train Epoch: 1 [4480/110534 (4%)]\tClassification Loss: 2.0961\r\n",
      "Train Epoch: 1 [5120/110534 (5%)]\tClassification Loss: 2.2449\r\n",
      "Train Epoch: 1 [5760/110534 (5%)]\tClassification Loss: 2.1797\r\n",
      "Train Epoch: 1 [6400/110534 (6%)]\tClassification Loss: 2.1965\r\n",
      "Train Epoch: 1 [7040/110534 (6%)]\tClassification Loss: 1.9058\r\n",
      "Train Epoch: 1 [7680/110534 (7%)]\tClassification Loss: 1.9071\r\n",
      "Train Epoch: 1 [8320/110534 (8%)]\tClassification Loss: 2.2524\r\n",
      "Train Epoch: 1 [8960/110534 (8%)]\tClassification Loss: 1.8857\r\n",
      "Train Epoch: 1 [9600/110534 (9%)]\tClassification Loss: 2.0349\r\n",
      "Train Epoch: 1 [10240/110534 (9%)]\tClassification Loss: 1.7545\r\n",
      "Train Epoch: 1 [10880/110534 (10%)]\tClassification Loss: 1.8268\r\n",
      "Train Epoch: 1 [11520/110534 (10%)]\tClassification Loss: 1.8706\r\n",
      "Train Epoch: 1 [12160/110534 (11%)]\tClassification Loss: 1.8624\r\n",
      "Train Epoch: 1 [12800/110534 (12%)]\tClassification Loss: 2.1293\r\n",
      "Train Epoch: 1 [13440/110534 (12%)]\tClassification Loss: 2.0139\r\n",
      "Train Epoch: 1 [14080/110534 (13%)]\tClassification Loss: 1.9390\r\n",
      "Train Epoch: 1 [14720/110534 (13%)]\tClassification Loss: 1.8053\r\n",
      "Train Epoch: 1 [15360/110534 (14%)]\tClassification Loss: 1.7255\r\n",
      "Train Epoch: 1 [16000/110534 (14%)]\tClassification Loss: 1.9685\r\n",
      "Train Epoch: 1 [16640/110534 (15%)]\tClassification Loss: 1.7780\r\n",
      "Train Epoch: 1 [17280/110534 (16%)]\tClassification Loss: 2.1488\r\n",
      "Train Epoch: 1 [17920/110534 (16%)]\tClassification Loss: 1.9485\r\n",
      "Train Epoch: 1 [18560/110534 (17%)]\tClassification Loss: 1.7087\r\n",
      "Train Epoch: 1 [19200/110534 (17%)]\tClassification Loss: 1.6449\r\n",
      "Train Epoch: 1 [19840/110534 (18%)]\tClassification Loss: 1.5922\r\n",
      "Train Epoch: 1 [20480/110534 (19%)]\tClassification Loss: 1.5111\r\n",
      "Train Epoch: 1 [21120/110534 (19%)]\tClassification Loss: 1.6778\r\n",
      "Train Epoch: 1 [21760/110534 (20%)]\tClassification Loss: 1.9361\r\n",
      "Train Epoch: 1 [22400/110534 (20%)]\tClassification Loss: 1.8062\r\n",
      "Train Epoch: 1 [23040/110534 (21%)]\tClassification Loss: 1.6292\r\n",
      "Train Epoch: 1 [23680/110534 (21%)]\tClassification Loss: 1.7167\r\n",
      "Train Epoch: 1 [24320/110534 (22%)]\tClassification Loss: 1.8613\r\n",
      "Train Epoch: 1 [24960/110534 (23%)]\tClassification Loss: 1.6740\r\n",
      "Train Epoch: 1 [25600/110534 (23%)]\tClassification Loss: 1.7613\r\n",
      "Train Epoch: 1 [26240/110534 (24%)]\tClassification Loss: 2.0382\r\n",
      "Train Epoch: 1 [26880/110534 (24%)]\tClassification Loss: 1.7449\r\n",
      "Train Epoch: 1 [27520/110534 (25%)]\tClassification Loss: 1.7524\r\n",
      "Train Epoch: 1 [28160/110534 (25%)]\tClassification Loss: 1.4889\r\n",
      "Train Epoch: 1 [28800/110534 (26%)]\tClassification Loss: 1.8321\r\n",
      "Train Epoch: 1 [29440/110534 (27%)]\tClassification Loss: 1.6915\r\n",
      "Train Epoch: 1 [30080/110534 (27%)]\tClassification Loss: 2.0027\r\n",
      "Train Epoch: 1 [30720/110534 (28%)]\tClassification Loss: 1.5776\r\n",
      "Train Epoch: 1 [31360/110534 (28%)]\tClassification Loss: 1.5812\r\n",
      "Train Epoch: 1 [32000/110534 (29%)]\tClassification Loss: 1.5039\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_500.pth.tar\r\n",
      "Train Epoch: 1 [32640/110534 (30%)]\tClassification Loss: 2.0684\r\n",
      "Train Epoch: 1 [33280/110534 (30%)]\tClassification Loss: 1.8140\r\n",
      "Train Epoch: 1 [33920/110534 (31%)]\tClassification Loss: 1.6480\r\n",
      "Train Epoch: 1 [34560/110534 (31%)]\tClassification Loss: 1.6720\r\n",
      "Train Epoch: 1 [35200/110534 (32%)]\tClassification Loss: 1.6313\r\n",
      "Train Epoch: 1 [35840/110534 (32%)]\tClassification Loss: 1.8542\r\n",
      "Train Epoch: 1 [36480/110534 (33%)]\tClassification Loss: 1.9204\r\n",
      "Train Epoch: 1 [37120/110534 (34%)]\tClassification Loss: 1.5204\r\n",
      "Train Epoch: 1 [37760/110534 (34%)]\tClassification Loss: 1.6498\r\n",
      "Train Epoch: 1 [38400/110534 (35%)]\tClassification Loss: 1.6190\r\n",
      "Train Epoch: 1 [39040/110534 (35%)]\tClassification Loss: 1.4325\r\n",
      "Train Epoch: 1 [39680/110534 (36%)]\tClassification Loss: 1.7197\r\n",
      "Train Epoch: 1 [40320/110534 (36%)]\tClassification Loss: 1.7941\r\n",
      "Train Epoch: 1 [40960/110534 (37%)]\tClassification Loss: 1.7045\r\n",
      "Train Epoch: 1 [41600/110534 (38%)]\tClassification Loss: 1.8569\r\n",
      "Train Epoch: 1 [42240/110534 (38%)]\tClassification Loss: 1.8712\r\n",
      "Train Epoch: 1 [42880/110534 (39%)]\tClassification Loss: 1.6740\r\n",
      "Train Epoch: 1 [43520/110534 (39%)]\tClassification Loss: 1.7709\r\n",
      "Train Epoch: 1 [44160/110534 (40%)]\tClassification Loss: 1.7576\r\n",
      "Train Epoch: 1 [44800/110534 (41%)]\tClassification Loss: 1.5435\r\n",
      "Train Epoch: 1 [45440/110534 (41%)]\tClassification Loss: 1.6849\r\n",
      "Train Epoch: 1 [46080/110534 (42%)]\tClassification Loss: 1.7341\r\n",
      "Train Epoch: 1 [46720/110534 (42%)]\tClassification Loss: 1.5365\r\n",
      "Train Epoch: 1 [47360/110534 (43%)]\tClassification Loss: 1.5877\r\n",
      "Train Epoch: 1 [48000/110534 (43%)]\tClassification Loss: 1.8829\r\n",
      "Train Epoch: 1 [48640/110534 (44%)]\tClassification Loss: 1.7710\r\n",
      "Train Epoch: 1 [49280/110534 (45%)]\tClassification Loss: 1.7253\r\n",
      "Train Epoch: 1 [49920/110534 (45%)]\tClassification Loss: 1.4724\r\n",
      "Train Epoch: 1 [50560/110534 (46%)]\tClassification Loss: 1.7451\r\n",
      "Train Epoch: 1 [51200/110534 (46%)]\tClassification Loss: 1.3784\r\n",
      "Train Epoch: 1 [51840/110534 (47%)]\tClassification Loss: 1.5468\r\n",
      "Train Epoch: 1 [52480/110534 (47%)]\tClassification Loss: 1.6506\r\n",
      "Train Epoch: 1 [53120/110534 (48%)]\tClassification Loss: 2.0123\r\n",
      "Train Epoch: 1 [53760/110534 (49%)]\tClassification Loss: 1.6931\r\n",
      "Train Epoch: 1 [54400/110534 (49%)]\tClassification Loss: 1.9763\r\n",
      "Train Epoch: 1 [55040/110534 (50%)]\tClassification Loss: 1.7403\r\n",
      "Train Epoch: 1 [55680/110534 (50%)]\tClassification Loss: 1.9480\r\n",
      "Train Epoch: 1 [56320/110534 (51%)]\tClassification Loss: 1.6358\r\n",
      "Train Epoch: 1 [56960/110534 (52%)]\tClassification Loss: 1.7282\r\n",
      "Train Epoch: 1 [57600/110534 (52%)]\tClassification Loss: 1.8514\r\n",
      "Train Epoch: 1 [58240/110534 (53%)]\tClassification Loss: 1.7132\r\n",
      "Train Epoch: 1 [58880/110534 (53%)]\tClassification Loss: 1.2058\r\n",
      "Train Epoch: 1 [59520/110534 (54%)]\tClassification Loss: 1.6595\r\n",
      "Train Epoch: 1 [60160/110534 (54%)]\tClassification Loss: 1.4150\r\n",
      "Train Epoch: 1 [60800/110534 (55%)]\tClassification Loss: 1.6916\r\n",
      "Train Epoch: 1 [61440/110534 (56%)]\tClassification Loss: 1.5317\r\n",
      "Train Epoch: 1 [62080/110534 (56%)]\tClassification Loss: 1.6922\r\n",
      "Train Epoch: 1 [62720/110534 (57%)]\tClassification Loss: 1.6764\r\n",
      "Train Epoch: 1 [63360/110534 (57%)]\tClassification Loss: 1.7181\r\n",
      "Train Epoch: 1 [64000/110534 (58%)]\tClassification Loss: 1.4181\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1000.pth.tar\r\n",
      "Train Epoch: 1 [64640/110534 (58%)]\tClassification Loss: 1.8301\r\n",
      "Train Epoch: 1 [65280/110534 (59%)]\tClassification Loss: 1.6778\r\n",
      "Train Epoch: 1 [65920/110534 (60%)]\tClassification Loss: 1.7034\r\n",
      "Train Epoch: 1 [66560/110534 (60%)]\tClassification Loss: 1.6541\r\n",
      "Train Epoch: 1 [67200/110534 (61%)]\tClassification Loss: 1.4270\r\n",
      "Train Epoch: 1 [67840/110534 (61%)]\tClassification Loss: 1.5525\r\n",
      "Train Epoch: 1 [68480/110534 (62%)]\tClassification Loss: 1.7449\r\n",
      "Train Epoch: 1 [69120/110534 (63%)]\tClassification Loss: 1.3523\r\n",
      "Train Epoch: 1 [69760/110534 (63%)]\tClassification Loss: 1.7937\r\n",
      "Train Epoch: 1 [70400/110534 (64%)]\tClassification Loss: 1.4440\r\n",
      "Train Epoch: 1 [71040/110534 (64%)]\tClassification Loss: 1.7544\r\n",
      "Train Epoch: 1 [71680/110534 (65%)]\tClassification Loss: 1.9806\r\n",
      "Train Epoch: 1 [72320/110534 (65%)]\tClassification Loss: 1.6804\r\n",
      "Train Epoch: 1 [72960/110534 (66%)]\tClassification Loss: 1.5804\r\n",
      "Train Epoch: 1 [73600/110534 (67%)]\tClassification Loss: 1.6155\r\n",
      "Train Epoch: 1 [74240/110534 (67%)]\tClassification Loss: 1.5719\r\n",
      "Train Epoch: 1 [74880/110534 (68%)]\tClassification Loss: 1.8530\r\n",
      "Train Epoch: 1 [75520/110534 (68%)]\tClassification Loss: 1.6570\r\n",
      "Train Epoch: 1 [76160/110534 (69%)]\tClassification Loss: 1.4317\r\n",
      "Train Epoch: 1 [76800/110534 (69%)]\tClassification Loss: 1.7361\r\n",
      "Train Epoch: 1 [77440/110534 (70%)]\tClassification Loss: 1.9212\r\n",
      "Train Epoch: 1 [78080/110534 (71%)]\tClassification Loss: 1.7236\r\n",
      "Train Epoch: 1 [78720/110534 (71%)]\tClassification Loss: 1.5433\r\n",
      "Train Epoch: 1 [79360/110534 (72%)]\tClassification Loss: 1.6706\r\n",
      "Train Epoch: 1 [80000/110534 (72%)]\tClassification Loss: 1.6501\r\n",
      "Train Epoch: 1 [80640/110534 (73%)]\tClassification Loss: 1.6746\r\n",
      "Train Epoch: 1 [81280/110534 (74%)]\tClassification Loss: 1.5214\r\n",
      "Train Epoch: 1 [81920/110534 (74%)]\tClassification Loss: 1.8215\r\n",
      "Train Epoch: 1 [82560/110534 (75%)]\tClassification Loss: 1.9507\r\n",
      "Train Epoch: 1 [83200/110534 (75%)]\tClassification Loss: 1.6823\r\n",
      "Train Epoch: 1 [83840/110534 (76%)]\tClassification Loss: 1.6075\r\n",
      "Train Epoch: 1 [84480/110534 (76%)]\tClassification Loss: 1.4725\r\n",
      "Train Epoch: 1 [85120/110534 (77%)]\tClassification Loss: 1.5480\r\n",
      "Train Epoch: 1 [85760/110534 (78%)]\tClassification Loss: 1.4881\r\n",
      "Train Epoch: 1 [86400/110534 (78%)]\tClassification Loss: 1.5174\r\n",
      "Train Epoch: 1 [87040/110534 (79%)]\tClassification Loss: 1.6109\r\n",
      "Train Epoch: 1 [87680/110534 (79%)]\tClassification Loss: 1.9415\r\n",
      "Train Epoch: 1 [88320/110534 (80%)]\tClassification Loss: 1.7286\r\n",
      "Train Epoch: 1 [88960/110534 (80%)]\tClassification Loss: 1.5089\r\n",
      "Train Epoch: 1 [89600/110534 (81%)]\tClassification Loss: 1.6522\r\n",
      "Train Epoch: 1 [90240/110534 (82%)]\tClassification Loss: 1.7605\r\n",
      "Train Epoch: 1 [90880/110534 (82%)]\tClassification Loss: 1.7405\r\n",
      "Train Epoch: 1 [91520/110534 (83%)]\tClassification Loss: 1.7746\r\n",
      "Train Epoch: 1 [92160/110534 (83%)]\tClassification Loss: 1.4678\r\n",
      "Train Epoch: 1 [92800/110534 (84%)]\tClassification Loss: 1.5643\r\n",
      "Train Epoch: 1 [93440/110534 (85%)]\tClassification Loss: 1.7555\r\n",
      "Train Epoch: 1 [94080/110534 (85%)]\tClassification Loss: 1.5996\r\n",
      "Train Epoch: 1 [94720/110534 (86%)]\tClassification Loss: 1.5492\r\n",
      "Train Epoch: 1 [95360/110534 (86%)]\tClassification Loss: 1.6483\r\n",
      "Train Epoch: 1 [96000/110534 (87%)]\tClassification Loss: 1.6061\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1500.pth.tar\r\n",
      "Train Epoch: 1 [96640/110534 (87%)]\tClassification Loss: 1.5505\r\n",
      "Train Epoch: 1 [97280/110534 (88%)]\tClassification Loss: 1.4972\r\n",
      "Train Epoch: 1 [97920/110534 (89%)]\tClassification Loss: 1.8130\r\n",
      "Train Epoch: 1 [98560/110534 (89%)]\tClassification Loss: 1.8747\r\n",
      "Train Epoch: 1 [99200/110534 (90%)]\tClassification Loss: 1.3778\r\n",
      "Train Epoch: 1 [99840/110534 (90%)]\tClassification Loss: 1.6948\r\n",
      "Train Epoch: 1 [100480/110534 (91%)]\tClassification Loss: 1.5498\r\n",
      "Train Epoch: 1 [101120/110534 (91%)]\tClassification Loss: 1.6895\r\n",
      "Train Epoch: 1 [101760/110534 (92%)]\tClassification Loss: 1.3409\r\n",
      "Train Epoch: 1 [102400/110534 (93%)]\tClassification Loss: 1.5617\r\n",
      "Train Epoch: 1 [103040/110534 (93%)]\tClassification Loss: 1.7285\r\n",
      "Train Epoch: 1 [103680/110534 (94%)]\tClassification Loss: 1.7110\r\n",
      "Train Epoch: 1 [104320/110534 (94%)]\tClassification Loss: 1.6659\r\n",
      "Train Epoch: 1 [104960/110534 (95%)]\tClassification Loss: 1.7941\r\n",
      "Train Epoch: 1 [105600/110534 (96%)]\tClassification Loss: 1.5797\r\n",
      "Train Epoch: 1 [106240/110534 (96%)]\tClassification Loss: 1.6936\r\n",
      "Train Epoch: 1 [106880/110534 (97%)]\tClassification Loss: 1.6162\r\n",
      "Train Epoch: 1 [107520/110534 (97%)]\tClassification Loss: 1.5499\r\n",
      "Train Epoch: 1 [108160/110534 (98%)]\tClassification Loss: 1.5208\r\n",
      "Train Epoch: 1 [108800/110534 (98%)]\tClassification Loss: 1.3829\r\n",
      "Train Epoch: 1 [109440/110534 (99%)]\tClassification Loss: 1.7243\r\n",
      "Train Epoch: 1 [110080/110534 (100%)]\tClassification Loss: 1.9230\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_final.pth.tar\r\n",
      "Train Epoch: 2 [0/110534 (0%)]\tClassification Loss: 1.9899\r\n",
      "\r\n",
      "Test set: Average loss: 1.5006, Accuracy: 22516/42368 (53%)\r\n",
      "\r\n",
      "Train Epoch: 2 [640/110534 (1%)]\tClassification Loss: 1.6259\r\n",
      "Train Epoch: 2 [1280/110534 (1%)]\tClassification Loss: 1.5611\r\n",
      "Train Epoch: 2 [1920/110534 (2%)]\tClassification Loss: 1.6652\r\n",
      "Train Epoch: 2 [2560/110534 (2%)]\tClassification Loss: 1.7263\r\n",
      "Train Epoch: 2 [3200/110534 (3%)]\tClassification Loss: 1.5236\r\n",
      "Train Epoch: 2 [3840/110534 (3%)]\tClassification Loss: 1.9249\r\n",
      "Train Epoch: 2 [4480/110534 (4%)]\tClassification Loss: 1.4490\r\n",
      "Train Epoch: 2 [5120/110534 (5%)]\tClassification Loss: 1.6268\r\n",
      "Train Epoch: 2 [5760/110534 (5%)]\tClassification Loss: 1.6366\r\n",
      "Train Epoch: 2 [6400/110534 (6%)]\tClassification Loss: 1.6501\r\n",
      "Train Epoch: 2 [7040/110534 (6%)]\tClassification Loss: 1.4531\r\n",
      "Train Epoch: 2 [7680/110534 (7%)]\tClassification Loss: 1.7105\r\n",
      "Train Epoch: 2 [8320/110534 (8%)]\tClassification Loss: 1.9273\r\n",
      "Train Epoch: 2 [8960/110534 (8%)]\tClassification Loss: 1.5426\r\n",
      "Train Epoch: 2 [9600/110534 (9%)]\tClassification Loss: 1.5575\r\n",
      "Train Epoch: 2 [10240/110534 (9%)]\tClassification Loss: 1.3827\r\n",
      "Train Epoch: 2 [10880/110534 (10%)]\tClassification Loss: 1.4254\r\n",
      "Train Epoch: 2 [11520/110534 (10%)]\tClassification Loss: 1.6115\r\n",
      "Train Epoch: 2 [12160/110534 (11%)]\tClassification Loss: 1.4829\r\n",
      "Train Epoch: 2 [12800/110534 (12%)]\tClassification Loss: 1.8319\r\n",
      "Train Epoch: 2 [13440/110534 (12%)]\tClassification Loss: 1.8631\r\n",
      "Train Epoch: 2 [14080/110534 (13%)]\tClassification Loss: 1.5398\r\n",
      "Train Epoch: 2 [14720/110534 (13%)]\tClassification Loss: 1.4664\r\n",
      "Train Epoch: 2 [15360/110534 (14%)]\tClassification Loss: 1.4092\r\n",
      "Train Epoch: 2 [16000/110534 (14%)]\tClassification Loss: 1.7763\r\n",
      "Train Epoch: 2 [16640/110534 (15%)]\tClassification Loss: 1.5266\r\n",
      "Train Epoch: 2 [17280/110534 (16%)]\tClassification Loss: 1.7909\r\n",
      "Train Epoch: 2 [17920/110534 (16%)]\tClassification Loss: 1.8333\r\n",
      "Train Epoch: 2 [18560/110534 (17%)]\tClassification Loss: 1.6292\r\n",
      "Train Epoch: 2 [19200/110534 (17%)]\tClassification Loss: 1.4522\r\n",
      "Train Epoch: 2 [19840/110534 (18%)]\tClassification Loss: 1.4448\r\n",
      "Train Epoch: 2 [20480/110534 (19%)]\tClassification Loss: 1.2179\r\n",
      "Train Epoch: 2 [21120/110534 (19%)]\tClassification Loss: 1.3024\r\n",
      "Train Epoch: 2 [21760/110534 (20%)]\tClassification Loss: 1.5869\r\n",
      "Train Epoch: 2 [22400/110534 (20%)]\tClassification Loss: 1.4825\r\n",
      "Train Epoch: 2 [23040/110534 (21%)]\tClassification Loss: 1.5114\r\n",
      "Train Epoch: 2 [23680/110534 (21%)]\tClassification Loss: 1.4522\r\n",
      "Train Epoch: 2 [24320/110534 (22%)]\tClassification Loss: 1.6330\r\n",
      "Train Epoch: 2 [24960/110534 (23%)]\tClassification Loss: 1.4324\r\n",
      "Train Epoch: 2 [25600/110534 (23%)]\tClassification Loss: 1.6003\r\n",
      "Train Epoch: 2 [26240/110534 (24%)]\tClassification Loss: 1.9410\r\n",
      "Train Epoch: 2 [26880/110534 (24%)]\tClassification Loss: 1.4656\r\n",
      "Train Epoch: 2 [27520/110534 (25%)]\tClassification Loss: 1.7748\r\n",
      "Train Epoch: 2 [28160/110534 (25%)]\tClassification Loss: 1.4190\r\n",
      "Train Epoch: 2 [28800/110534 (26%)]\tClassification Loss: 1.6089\r\n",
      "Train Epoch: 2 [29440/110534 (27%)]\tClassification Loss: 1.5856\r\n",
      "Train Epoch: 2 [30080/110534 (27%)]\tClassification Loss: 1.7640\r\n",
      "Train Epoch: 2 [30720/110534 (28%)]\tClassification Loss: 1.3707\r\n",
      "Train Epoch: 2 [31360/110534 (28%)]\tClassification Loss: 1.3983\r\n",
      "Train Epoch: 2 [32000/110534 (29%)]\tClassification Loss: 1.4890\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_500.pth.tar\r\n",
      "Train Epoch: 2 [32640/110534 (30%)]\tClassification Loss: 2.0050\r\n",
      "Train Epoch: 2 [33280/110534 (30%)]\tClassification Loss: 1.5919\r\n",
      "Train Epoch: 2 [33920/110534 (31%)]\tClassification Loss: 1.5770\r\n",
      "Train Epoch: 2 [34560/110534 (31%)]\tClassification Loss: 1.6099\r\n",
      "Train Epoch: 2 [35200/110534 (32%)]\tClassification Loss: 1.3712\r\n",
      "Train Epoch: 2 [35840/110534 (32%)]\tClassification Loss: 1.6339\r\n",
      "Train Epoch: 2 [36480/110534 (33%)]\tClassification Loss: 1.7933\r\n",
      "Train Epoch: 2 [37120/110534 (34%)]\tClassification Loss: 1.2633\r\n",
      "Train Epoch: 2 [37760/110534 (34%)]\tClassification Loss: 1.6800\r\n",
      "Train Epoch: 2 [38400/110534 (35%)]\tClassification Loss: 1.4827\r\n",
      "Train Epoch: 2 [39040/110534 (35%)]\tClassification Loss: 1.2168\r\n",
      "Train Epoch: 2 [39680/110534 (36%)]\tClassification Loss: 1.4006\r\n",
      "Train Epoch: 2 [40320/110534 (36%)]\tClassification Loss: 1.7200\r\n",
      "Train Epoch: 2 [40960/110534 (37%)]\tClassification Loss: 1.6844\r\n",
      "Train Epoch: 2 [41600/110534 (38%)]\tClassification Loss: 1.7237\r\n",
      "Train Epoch: 2 [42240/110534 (38%)]\tClassification Loss: 1.9079\r\n",
      "Train Epoch: 2 [42880/110534 (39%)]\tClassification Loss: 1.4802\r\n",
      "Train Epoch: 2 [43520/110534 (39%)]\tClassification Loss: 1.6699\r\n",
      "Train Epoch: 2 [44160/110534 (40%)]\tClassification Loss: 1.7399\r\n",
      "Train Epoch: 2 [44800/110534 (41%)]\tClassification Loss: 1.5420\r\n",
      "Train Epoch: 2 [45440/110534 (41%)]\tClassification Loss: 1.5169\r\n",
      "Train Epoch: 2 [46080/110534 (42%)]\tClassification Loss: 1.7240\r\n",
      "Train Epoch: 2 [46720/110534 (42%)]\tClassification Loss: 1.4020\r\n",
      "Train Epoch: 2 [47360/110534 (43%)]\tClassification Loss: 1.5635\r\n",
      "Train Epoch: 2 [48000/110534 (43%)]\tClassification Loss: 1.5780\r\n",
      "Train Epoch: 2 [48640/110534 (44%)]\tClassification Loss: 1.7766\r\n",
      "Train Epoch: 2 [49280/110534 (45%)]\tClassification Loss: 1.5800\r\n",
      "Train Epoch: 2 [49920/110534 (45%)]\tClassification Loss: 1.3360\r\n",
      "Train Epoch: 2 [50560/110534 (46%)]\tClassification Loss: 1.5842\r\n",
      "Train Epoch: 2 [51200/110534 (46%)]\tClassification Loss: 1.3023\r\n",
      "Train Epoch: 2 [51840/110534 (47%)]\tClassification Loss: 1.4618\r\n",
      "Train Epoch: 2 [52480/110534 (47%)]\tClassification Loss: 1.5597\r\n",
      "Train Epoch: 2 [53120/110534 (48%)]\tClassification Loss: 1.8514\r\n",
      "Train Epoch: 2 [53760/110534 (49%)]\tClassification Loss: 1.6173\r\n",
      "Train Epoch: 2 [54400/110534 (49%)]\tClassification Loss: 1.7833\r\n",
      "Train Epoch: 2 [55040/110534 (50%)]\tClassification Loss: 1.7835\r\n",
      "Train Epoch: 2 [55680/110534 (50%)]\tClassification Loss: 1.9632\r\n",
      "Train Epoch: 2 [56320/110534 (51%)]\tClassification Loss: 1.5279\r\n",
      "Train Epoch: 2 [56960/110534 (52%)]\tClassification Loss: 1.6526\r\n",
      "Train Epoch: 2 [57600/110534 (52%)]\tClassification Loss: 1.6854\r\n",
      "Train Epoch: 2 [58240/110534 (53%)]\tClassification Loss: 1.6065\r\n",
      "Train Epoch: 2 [58880/110534 (53%)]\tClassification Loss: 1.1194\r\n",
      "Train Epoch: 2 [59520/110534 (54%)]\tClassification Loss: 1.5263\r\n",
      "Train Epoch: 2 [60160/110534 (54%)]\tClassification Loss: 1.3675\r\n",
      "Train Epoch: 2 [60800/110534 (55%)]\tClassification Loss: 1.4686\r\n",
      "Train Epoch: 2 [61440/110534 (56%)]\tClassification Loss: 1.5646\r\n",
      "Train Epoch: 2 [62080/110534 (56%)]\tClassification Loss: 1.5618\r\n",
      "Train Epoch: 2 [62720/110534 (57%)]\tClassification Loss: 1.7533\r\n",
      "Train Epoch: 2 [63360/110534 (57%)]\tClassification Loss: 1.6102\r\n",
      "Train Epoch: 2 [64000/110534 (58%)]\tClassification Loss: 1.3671\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1000.pth.tar\r\n",
      "Train Epoch: 2 [64640/110534 (58%)]\tClassification Loss: 1.6878\r\n",
      "Train Epoch: 2 [65280/110534 (59%)]\tClassification Loss: 1.4547\r\n",
      "Train Epoch: 2 [65920/110534 (60%)]\tClassification Loss: 1.8149\r\n",
      "Train Epoch: 2 [66560/110534 (60%)]\tClassification Loss: 1.4878\r\n",
      "Train Epoch: 2 [67200/110534 (61%)]\tClassification Loss: 1.3222\r\n",
      "Train Epoch: 2 [67840/110534 (61%)]\tClassification Loss: 1.4776\r\n",
      "Train Epoch: 2 [68480/110534 (62%)]\tClassification Loss: 1.7160\r\n",
      "Train Epoch: 2 [69120/110534 (63%)]\tClassification Loss: 1.2371\r\n",
      "Train Epoch: 2 [69760/110534 (63%)]\tClassification Loss: 1.7277\r\n",
      "Train Epoch: 2 [70400/110534 (64%)]\tClassification Loss: 1.4900\r\n",
      "Train Epoch: 2 [71040/110534 (64%)]\tClassification Loss: 1.7072\r\n",
      "Train Epoch: 2 [71680/110534 (65%)]\tClassification Loss: 1.8571\r\n",
      "Train Epoch: 2 [72320/110534 (65%)]\tClassification Loss: 1.5640\r\n",
      "Train Epoch: 2 [72960/110534 (66%)]\tClassification Loss: 1.4810\r\n",
      "Train Epoch: 2 [73600/110534 (67%)]\tClassification Loss: 1.5260\r\n",
      "Train Epoch: 2 [74240/110534 (67%)]\tClassification Loss: 1.4784\r\n",
      "Train Epoch: 2 [74880/110534 (68%)]\tClassification Loss: 1.7588\r\n",
      "Train Epoch: 2 [75520/110534 (68%)]\tClassification Loss: 1.5925\r\n",
      "Train Epoch: 2 [76160/110534 (69%)]\tClassification Loss: 1.3484\r\n",
      "Train Epoch: 2 [76800/110534 (69%)]\tClassification Loss: 1.6605\r\n",
      "Train Epoch: 2 [77440/110534 (70%)]\tClassification Loss: 1.6926\r\n",
      "Train Epoch: 2 [78080/110534 (71%)]\tClassification Loss: 1.7145\r\n",
      "Train Epoch: 2 [78720/110534 (71%)]\tClassification Loss: 1.5632\r\n",
      "Train Epoch: 2 [79360/110534 (72%)]\tClassification Loss: 1.6129\r\n",
      "Train Epoch: 2 [80000/110534 (72%)]\tClassification Loss: 1.7043\r\n",
      "Train Epoch: 2 [80640/110534 (73%)]\tClassification Loss: 1.6280\r\n",
      "Train Epoch: 2 [81280/110534 (74%)]\tClassification Loss: 1.4800\r\n",
      "Train Epoch: 2 [81920/110534 (74%)]\tClassification Loss: 1.7580\r\n",
      "Train Epoch: 2 [82560/110534 (75%)]\tClassification Loss: 1.8131\r\n",
      "Train Epoch: 2 [83200/110534 (75%)]\tClassification Loss: 1.5709\r\n",
      "Train Epoch: 2 [83840/110534 (76%)]\tClassification Loss: 1.6248\r\n",
      "Train Epoch: 2 [84480/110534 (76%)]\tClassification Loss: 1.6251\r\n",
      "Train Epoch: 2 [85120/110534 (77%)]\tClassification Loss: 1.4315\r\n",
      "Train Epoch: 2 [85760/110534 (78%)]\tClassification Loss: 1.3803\r\n",
      "Train Epoch: 2 [86400/110534 (78%)]\tClassification Loss: 1.4012\r\n",
      "Train Epoch: 2 [87040/110534 (79%)]\tClassification Loss: 1.6242\r\n",
      "Train Epoch: 2 [87680/110534 (79%)]\tClassification Loss: 1.9267\r\n",
      "Train Epoch: 2 [88320/110534 (80%)]\tClassification Loss: 1.5484\r\n",
      "Train Epoch: 2 [88960/110534 (80%)]\tClassification Loss: 1.5760\r\n",
      "Train Epoch: 2 [89600/110534 (81%)]\tClassification Loss: 1.5590\r\n",
      "Train Epoch: 2 [90240/110534 (82%)]\tClassification Loss: 1.5063\r\n",
      "Train Epoch: 2 [90880/110534 (82%)]\tClassification Loss: 1.7860\r\n",
      "Train Epoch: 2 [91520/110534 (83%)]\tClassification Loss: 1.5696\r\n",
      "Train Epoch: 2 [92160/110534 (83%)]\tClassification Loss: 1.4289\r\n",
      "Train Epoch: 2 [92800/110534 (84%)]\tClassification Loss: 1.4030\r\n",
      "Train Epoch: 2 [93440/110534 (85%)]\tClassification Loss: 1.5135\r\n",
      "Train Epoch: 2 [94080/110534 (85%)]\tClassification Loss: 1.5449\r\n",
      "Train Epoch: 2 [94720/110534 (86%)]\tClassification Loss: 1.5004\r\n",
      "Train Epoch: 2 [95360/110534 (86%)]\tClassification Loss: 1.5979\r\n",
      "Train Epoch: 2 [96000/110534 (87%)]\tClassification Loss: 1.5437\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1500.pth.tar\r\n",
      "Train Epoch: 2 [96640/110534 (87%)]\tClassification Loss: 1.5249\r\n",
      "Train Epoch: 2 [97280/110534 (88%)]\tClassification Loss: 1.5288\r\n",
      "Train Epoch: 2 [97920/110534 (89%)]\tClassification Loss: 1.8482\r\n",
      "Train Epoch: 2 [98560/110534 (89%)]\tClassification Loss: 1.8246\r\n",
      "Train Epoch: 2 [99200/110534 (90%)]\tClassification Loss: 1.2165\r\n",
      "Train Epoch: 2 [99840/110534 (90%)]\tClassification Loss: 1.5059\r\n",
      "Train Epoch: 2 [100480/110534 (91%)]\tClassification Loss: 1.4394\r\n",
      "Train Epoch: 2 [101120/110534 (91%)]\tClassification Loss: 1.7090\r\n",
      "Train Epoch: 2 [101760/110534 (92%)]\tClassification Loss: 1.3572\r\n",
      "Train Epoch: 2 [102400/110534 (93%)]\tClassification Loss: 1.4177\r\n",
      "Train Epoch: 2 [103040/110534 (93%)]\tClassification Loss: 1.3983\r\n",
      "Train Epoch: 2 [103680/110534 (94%)]\tClassification Loss: 1.5874\r\n",
      "Train Epoch: 2 [104320/110534 (94%)]\tClassification Loss: 1.4596\r\n",
      "Train Epoch: 2 [104960/110534 (95%)]\tClassification Loss: 1.6782\r\n",
      "Train Epoch: 2 [105600/110534 (96%)]\tClassification Loss: 1.4807\r\n",
      "Train Epoch: 2 [106240/110534 (96%)]\tClassification Loss: 1.5118\r\n",
      "Train Epoch: 2 [106880/110534 (97%)]\tClassification Loss: 1.6932\r\n",
      "Train Epoch: 2 [107520/110534 (97%)]\tClassification Loss: 1.4059\r\n",
      "Train Epoch: 2 [108160/110534 (98%)]\tClassification Loss: 1.5068\r\n",
      "Train Epoch: 2 [108800/110534 (98%)]\tClassification Loss: 1.3752\r\n",
      "Train Epoch: 2 [109440/110534 (99%)]\tClassification Loss: 1.7533\r\n",
      "Train Epoch: 2 [110080/110534 (100%)]\tClassification Loss: 1.9953\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_final.pth.tar\r\n",
      "Train Epoch: 3 [0/110534 (0%)]\tClassification Loss: 2.0231\r\n",
      "\r\n",
      "Test set: Average loss: 1.4543, Accuracy: 22956/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 3 [640/110534 (1%)]\tClassification Loss: 1.6202\r\n",
      "Train Epoch: 3 [1280/110534 (1%)]\tClassification Loss: 1.5397\r\n",
      "Train Epoch: 3 [1920/110534 (2%)]\tClassification Loss: 1.8038\r\n",
      "Train Epoch: 3 [2560/110534 (2%)]\tClassification Loss: 1.5506\r\n",
      "Train Epoch: 3 [3200/110534 (3%)]\tClassification Loss: 1.4167\r\n",
      "Train Epoch: 3 [3840/110534 (3%)]\tClassification Loss: 1.7025\r\n",
      "Train Epoch: 3 [4480/110534 (4%)]\tClassification Loss: 1.4078\r\n",
      "Train Epoch: 3 [5120/110534 (5%)]\tClassification Loss: 2.0267\r\n",
      "Train Epoch: 3 [5760/110534 (5%)]\tClassification Loss: 1.6722\r\n",
      "Train Epoch: 3 [6400/110534 (6%)]\tClassification Loss: 1.6453\r\n",
      "Train Epoch: 3 [7040/110534 (6%)]\tClassification Loss: 1.5139\r\n",
      "Train Epoch: 3 [7680/110534 (7%)]\tClassification Loss: 1.6514\r\n",
      "Train Epoch: 3 [8320/110534 (8%)]\tClassification Loss: 1.8653\r\n",
      "Train Epoch: 3 [8960/110534 (8%)]\tClassification Loss: 1.4449\r\n",
      "Train Epoch: 3 [9600/110534 (9%)]\tClassification Loss: 1.5254\r\n",
      "Train Epoch: 3 [10240/110534 (9%)]\tClassification Loss: 1.4136\r\n",
      "Train Epoch: 3 [10880/110534 (10%)]\tClassification Loss: 1.4197\r\n",
      "Train Epoch: 3 [11520/110534 (10%)]\tClassification Loss: 1.6087\r\n",
      "Train Epoch: 3 [12160/110534 (11%)]\tClassification Loss: 1.3785\r\n",
      "Train Epoch: 3 [12800/110534 (12%)]\tClassification Loss: 1.7212\r\n",
      "Train Epoch: 3 [13440/110534 (12%)]\tClassification Loss: 1.8253\r\n",
      "Train Epoch: 3 [14080/110534 (13%)]\tClassification Loss: 1.4458\r\n",
      "Train Epoch: 3 [14720/110534 (13%)]\tClassification Loss: 1.3377\r\n",
      "Train Epoch: 3 [15360/110534 (14%)]\tClassification Loss: 1.4267\r\n",
      "Train Epoch: 3 [16000/110534 (14%)]\tClassification Loss: 1.6619\r\n",
      "Train Epoch: 3 [16640/110534 (15%)]\tClassification Loss: 1.5091\r\n",
      "Train Epoch: 3 [17280/110534 (16%)]\tClassification Loss: 1.6886\r\n",
      "Train Epoch: 3 [17920/110534 (16%)]\tClassification Loss: 1.6851\r\n",
      "Train Epoch: 3 [18560/110534 (17%)]\tClassification Loss: 1.5269\r\n",
      "Train Epoch: 3 [19200/110534 (17%)]\tClassification Loss: 1.3558\r\n",
      "Train Epoch: 3 [19840/110534 (18%)]\tClassification Loss: 1.3780\r\n",
      "Train Epoch: 3 [20480/110534 (19%)]\tClassification Loss: 1.2887\r\n",
      "Train Epoch: 3 [21120/110534 (19%)]\tClassification Loss: 1.4809\r\n",
      "Train Epoch: 3 [21760/110534 (20%)]\tClassification Loss: 1.5830\r\n",
      "Train Epoch: 3 [22400/110534 (20%)]\tClassification Loss: 1.5734\r\n",
      "Train Epoch: 3 [23040/110534 (21%)]\tClassification Loss: 1.2661\r\n",
      "Train Epoch: 3 [23680/110534 (21%)]\tClassification Loss: 1.3489\r\n",
      "Train Epoch: 3 [24320/110534 (22%)]\tClassification Loss: 1.5838\r\n",
      "Train Epoch: 3 [24960/110534 (23%)]\tClassification Loss: 1.3417\r\n",
      "Train Epoch: 3 [25600/110534 (23%)]\tClassification Loss: 1.5123\r\n",
      "Train Epoch: 3 [26240/110534 (24%)]\tClassification Loss: 1.7759\r\n",
      "Train Epoch: 3 [26880/110534 (24%)]\tClassification Loss: 1.4927\r\n",
      "Train Epoch: 3 [27520/110534 (25%)]\tClassification Loss: 1.6453\r\n",
      "Train Epoch: 3 [28160/110534 (25%)]\tClassification Loss: 1.4490\r\n",
      "Train Epoch: 3 [28800/110534 (26%)]\tClassification Loss: 1.7659\r\n",
      "Train Epoch: 3 [29440/110534 (27%)]\tClassification Loss: 1.6991\r\n",
      "Train Epoch: 3 [30080/110534 (27%)]\tClassification Loss: 1.6666\r\n",
      "Train Epoch: 3 [30720/110534 (28%)]\tClassification Loss: 1.4881\r\n",
      "Train Epoch: 3 [31360/110534 (28%)]\tClassification Loss: 1.4086\r\n",
      "Train Epoch: 3 [32000/110534 (29%)]\tClassification Loss: 1.4601\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_500.pth.tar\r\n",
      "Train Epoch: 3 [32640/110534 (30%)]\tClassification Loss: 2.0329\r\n",
      "Train Epoch: 3 [33280/110534 (30%)]\tClassification Loss: 1.5564\r\n",
      "Train Epoch: 3 [33920/110534 (31%)]\tClassification Loss: 1.6142\r\n",
      "Train Epoch: 3 [34560/110534 (31%)]\tClassification Loss: 1.5476\r\n",
      "Train Epoch: 3 [35200/110534 (32%)]\tClassification Loss: 1.6579\r\n",
      "Train Epoch: 3 [35840/110534 (32%)]\tClassification Loss: 1.6337\r\n",
      "Train Epoch: 3 [36480/110534 (33%)]\tClassification Loss: 1.5764\r\n",
      "Train Epoch: 3 [37120/110534 (34%)]\tClassification Loss: 1.2717\r\n",
      "Train Epoch: 3 [37760/110534 (34%)]\tClassification Loss: 1.3850\r\n",
      "Train Epoch: 3 [38400/110534 (35%)]\tClassification Loss: 1.5098\r\n",
      "Train Epoch: 3 [39040/110534 (35%)]\tClassification Loss: 1.1699\r\n",
      "Train Epoch: 3 [39680/110534 (36%)]\tClassification Loss: 1.5225\r\n",
      "Train Epoch: 3 [40320/110534 (36%)]\tClassification Loss: 1.5976\r\n",
      "Train Epoch: 3 [40960/110534 (37%)]\tClassification Loss: 1.6597\r\n",
      "Train Epoch: 3 [41600/110534 (38%)]\tClassification Loss: 1.5943\r\n",
      "Train Epoch: 3 [42240/110534 (38%)]\tClassification Loss: 1.8717\r\n",
      "Train Epoch: 3 [42880/110534 (39%)]\tClassification Loss: 1.5286\r\n",
      "Train Epoch: 3 [43520/110534 (39%)]\tClassification Loss: 1.5055\r\n",
      "Train Epoch: 3 [44160/110534 (40%)]\tClassification Loss: 1.4680\r\n",
      "Train Epoch: 3 [44800/110534 (41%)]\tClassification Loss: 1.4017\r\n",
      "Train Epoch: 3 [45440/110534 (41%)]\tClassification Loss: 1.4248\r\n",
      "Train Epoch: 3 [46080/110534 (42%)]\tClassification Loss: 1.7016\r\n",
      "Train Epoch: 3 [46720/110534 (42%)]\tClassification Loss: 1.3449\r\n",
      "Train Epoch: 3 [47360/110534 (43%)]\tClassification Loss: 1.4871\r\n",
      "Train Epoch: 3 [48000/110534 (43%)]\tClassification Loss: 1.6185\r\n",
      "Train Epoch: 3 [48640/110534 (44%)]\tClassification Loss: 1.6700\r\n",
      "Train Epoch: 3 [49280/110534 (45%)]\tClassification Loss: 1.6443\r\n",
      "Train Epoch: 3 [49920/110534 (45%)]\tClassification Loss: 1.3240\r\n",
      "Train Epoch: 3 [50560/110534 (46%)]\tClassification Loss: 1.7661\r\n",
      "Train Epoch: 3 [51200/110534 (46%)]\tClassification Loss: 1.3666\r\n",
      "Train Epoch: 3 [51840/110534 (47%)]\tClassification Loss: 1.4484\r\n",
      "Train Epoch: 3 [52480/110534 (47%)]\tClassification Loss: 1.4349\r\n",
      "Train Epoch: 3 [53120/110534 (48%)]\tClassification Loss: 1.7108\r\n",
      "Train Epoch: 3 [53760/110534 (49%)]\tClassification Loss: 1.5634\r\n",
      "Train Epoch: 3 [54400/110534 (49%)]\tClassification Loss: 1.7782\r\n",
      "Train Epoch: 3 [55040/110534 (50%)]\tClassification Loss: 1.7336\r\n",
      "Train Epoch: 3 [55680/110534 (50%)]\tClassification Loss: 1.8373\r\n",
      "Train Epoch: 3 [56320/110534 (51%)]\tClassification Loss: 1.4552\r\n",
      "Train Epoch: 3 [56960/110534 (52%)]\tClassification Loss: 1.5962\r\n",
      "Train Epoch: 3 [57600/110534 (52%)]\tClassification Loss: 1.6553\r\n",
      "Train Epoch: 3 [58240/110534 (53%)]\tClassification Loss: 1.6357\r\n",
      "Train Epoch: 3 [58880/110534 (53%)]\tClassification Loss: 1.2039\r\n",
      "Train Epoch: 3 [59520/110534 (54%)]\tClassification Loss: 1.5384\r\n",
      "Train Epoch: 3 [60160/110534 (54%)]\tClassification Loss: 1.3215\r\n",
      "Train Epoch: 3 [60800/110534 (55%)]\tClassification Loss: 1.5363\r\n",
      "Train Epoch: 3 [61440/110534 (56%)]\tClassification Loss: 1.5512\r\n",
      "Train Epoch: 3 [62080/110534 (56%)]\tClassification Loss: 1.5174\r\n",
      "Train Epoch: 3 [62720/110534 (57%)]\tClassification Loss: 1.6526\r\n",
      "Train Epoch: 3 [63360/110534 (57%)]\tClassification Loss: 1.5857\r\n",
      "Train Epoch: 3 [64000/110534 (58%)]\tClassification Loss: 1.3484\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1000.pth.tar\r\n",
      "Train Epoch: 3 [64640/110534 (58%)]\tClassification Loss: 1.7876\r\n",
      "Train Epoch: 3 [65280/110534 (59%)]\tClassification Loss: 1.4855\r\n",
      "Train Epoch: 3 [65920/110534 (60%)]\tClassification Loss: 1.6610\r\n",
      "Train Epoch: 3 [66560/110534 (60%)]\tClassification Loss: 1.4322\r\n",
      "Train Epoch: 3 [67200/110534 (61%)]\tClassification Loss: 1.3197\r\n",
      "Train Epoch: 3 [67840/110534 (61%)]\tClassification Loss: 1.4743\r\n",
      "Train Epoch: 3 [68480/110534 (62%)]\tClassification Loss: 1.4949\r\n",
      "Train Epoch: 3 [69120/110534 (63%)]\tClassification Loss: 1.3875\r\n",
      "Train Epoch: 3 [69760/110534 (63%)]\tClassification Loss: 1.7449\r\n",
      "Train Epoch: 3 [70400/110534 (64%)]\tClassification Loss: 1.4778\r\n",
      "Train Epoch: 3 [71040/110534 (64%)]\tClassification Loss: 1.6244\r\n",
      "Train Epoch: 3 [71680/110534 (65%)]\tClassification Loss: 1.8437\r\n",
      "Train Epoch: 3 [72320/110534 (65%)]\tClassification Loss: 1.6089\r\n",
      "Train Epoch: 3 [72960/110534 (66%)]\tClassification Loss: 1.3549\r\n",
      "Train Epoch: 3 [73600/110534 (67%)]\tClassification Loss: 1.3318\r\n",
      "Train Epoch: 3 [74240/110534 (67%)]\tClassification Loss: 1.4040\r\n",
      "Train Epoch: 3 [74880/110534 (68%)]\tClassification Loss: 1.7983\r\n",
      "Train Epoch: 3 [75520/110534 (68%)]\tClassification Loss: 1.6608\r\n",
      "Train Epoch: 3 [76160/110534 (69%)]\tClassification Loss: 1.3277\r\n",
      "Train Epoch: 3 [76800/110534 (69%)]\tClassification Loss: 1.6592\r\n",
      "Train Epoch: 3 [77440/110534 (70%)]\tClassification Loss: 1.7562\r\n",
      "Train Epoch: 3 [78080/110534 (71%)]\tClassification Loss: 1.6733\r\n",
      "Train Epoch: 3 [78720/110534 (71%)]\tClassification Loss: 1.5445\r\n",
      "Train Epoch: 3 [79360/110534 (72%)]\tClassification Loss: 1.5481\r\n",
      "Train Epoch: 3 [80000/110534 (72%)]\tClassification Loss: 1.5430\r\n",
      "Train Epoch: 3 [80640/110534 (73%)]\tClassification Loss: 1.3367\r\n",
      "Train Epoch: 3 [81280/110534 (74%)]\tClassification Loss: 1.3669\r\n",
      "Train Epoch: 3 [81920/110534 (74%)]\tClassification Loss: 1.7951\r\n",
      "Train Epoch: 3 [82560/110534 (75%)]\tClassification Loss: 1.6888\r\n",
      "Train Epoch: 3 [83200/110534 (75%)]\tClassification Loss: 1.6842\r\n",
      "Train Epoch: 3 [83840/110534 (76%)]\tClassification Loss: 1.4905\r\n",
      "Train Epoch: 3 [84480/110534 (76%)]\tClassification Loss: 1.4512\r\n",
      "Train Epoch: 3 [85120/110534 (77%)]\tClassification Loss: 1.6430\r\n",
      "Train Epoch: 3 [85760/110534 (78%)]\tClassification Loss: 1.5192\r\n",
      "Train Epoch: 3 [86400/110534 (78%)]\tClassification Loss: 1.4562\r\n",
      "Train Epoch: 3 [87040/110534 (79%)]\tClassification Loss: 1.5882\r\n",
      "Train Epoch: 3 [87680/110534 (79%)]\tClassification Loss: 1.9696\r\n",
      "Train Epoch: 3 [88320/110534 (80%)]\tClassification Loss: 1.4131\r\n",
      "Train Epoch: 3 [88960/110534 (80%)]\tClassification Loss: 1.2689\r\n",
      "Train Epoch: 3 [89600/110534 (81%)]\tClassification Loss: 1.5444\r\n",
      "Train Epoch: 3 [90240/110534 (82%)]\tClassification Loss: 1.6888\r\n",
      "Train Epoch: 3 [90880/110534 (82%)]\tClassification Loss: 1.5972\r\n",
      "Train Epoch: 3 [91520/110534 (83%)]\tClassification Loss: 1.6034\r\n",
      "Train Epoch: 3 [92160/110534 (83%)]\tClassification Loss: 1.3751\r\n",
      "Train Epoch: 3 [92800/110534 (84%)]\tClassification Loss: 1.3595\r\n",
      "Train Epoch: 3 [93440/110534 (85%)]\tClassification Loss: 1.6824\r\n",
      "Train Epoch: 3 [94080/110534 (85%)]\tClassification Loss: 1.4975\r\n",
      "Train Epoch: 3 [94720/110534 (86%)]\tClassification Loss: 1.4813\r\n",
      "Train Epoch: 3 [95360/110534 (86%)]\tClassification Loss: 1.7213\r\n",
      "Train Epoch: 3 [96000/110534 (87%)]\tClassification Loss: 1.6338\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1500.pth.tar\r\n",
      "Train Epoch: 3 [96640/110534 (87%)]\tClassification Loss: 1.6685\r\n",
      "Train Epoch: 3 [97280/110534 (88%)]\tClassification Loss: 1.4994\r\n",
      "Train Epoch: 3 [97920/110534 (89%)]\tClassification Loss: 1.7506\r\n",
      "Train Epoch: 3 [98560/110534 (89%)]\tClassification Loss: 1.6125\r\n",
      "Train Epoch: 3 [99200/110534 (90%)]\tClassification Loss: 1.2092\r\n",
      "Train Epoch: 3 [99840/110534 (90%)]\tClassification Loss: 1.4792\r\n",
      "Train Epoch: 3 [100480/110534 (91%)]\tClassification Loss: 1.3494\r\n",
      "Train Epoch: 3 [101120/110534 (91%)]\tClassification Loss: 1.6178\r\n",
      "Train Epoch: 3 [101760/110534 (92%)]\tClassification Loss: 1.1614\r\n",
      "Train Epoch: 3 [102400/110534 (93%)]\tClassification Loss: 1.3816\r\n",
      "Train Epoch: 3 [103040/110534 (93%)]\tClassification Loss: 1.5365\r\n",
      "Train Epoch: 3 [103680/110534 (94%)]\tClassification Loss: 1.6390\r\n",
      "Train Epoch: 3 [104320/110534 (94%)]\tClassification Loss: 1.5503\r\n",
      "Train Epoch: 3 [104960/110534 (95%)]\tClassification Loss: 1.7619\r\n",
      "Train Epoch: 3 [105600/110534 (96%)]\tClassification Loss: 1.5861\r\n",
      "Train Epoch: 3 [106240/110534 (96%)]\tClassification Loss: 1.5702\r\n",
      "Train Epoch: 3 [106880/110534 (97%)]\tClassification Loss: 1.6867\r\n",
      "Train Epoch: 3 [107520/110534 (97%)]\tClassification Loss: 1.5490\r\n",
      "Train Epoch: 3 [108160/110534 (98%)]\tClassification Loss: 1.4197\r\n",
      "Train Epoch: 3 [108800/110534 (98%)]\tClassification Loss: 1.2643\r\n",
      "Train Epoch: 3 [109440/110534 (99%)]\tClassification Loss: 1.4908\r\n",
      "Train Epoch: 3 [110080/110534 (100%)]\tClassification Loss: 1.7394\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_final.pth.tar\r\n",
      "Train Epoch: 4 [0/110534 (0%)]\tClassification Loss: 1.9539\r\n",
      "\r\n",
      "Test set: Average loss: 1.4339, Accuracy: 23138/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 4 [640/110534 (1%)]\tClassification Loss: 1.5347\r\n",
      "Train Epoch: 4 [1280/110534 (1%)]\tClassification Loss: 1.4656\r\n",
      "Train Epoch: 4 [1920/110534 (2%)]\tClassification Loss: 1.7549\r\n",
      "Train Epoch: 4 [2560/110534 (2%)]\tClassification Loss: 1.5924\r\n",
      "Train Epoch: 4 [3200/110534 (3%)]\tClassification Loss: 1.5208\r\n",
      "Train Epoch: 4 [3840/110534 (3%)]\tClassification Loss: 1.7634\r\n",
      "Train Epoch: 4 [4480/110534 (4%)]\tClassification Loss: 1.4899\r\n",
      "Train Epoch: 4 [5120/110534 (5%)]\tClassification Loss: 1.7439\r\n",
      "Train Epoch: 4 [5760/110534 (5%)]\tClassification Loss: 1.5988\r\n",
      "Train Epoch: 4 [6400/110534 (6%)]\tClassification Loss: 1.7331\r\n",
      "Train Epoch: 4 [7040/110534 (6%)]\tClassification Loss: 1.4042\r\n",
      "Train Epoch: 4 [7680/110534 (7%)]\tClassification Loss: 1.6208\r\n",
      "Train Epoch: 4 [8320/110534 (8%)]\tClassification Loss: 1.8898\r\n",
      "Train Epoch: 4 [8960/110534 (8%)]\tClassification Loss: 1.4494\r\n",
      "Train Epoch: 4 [9600/110534 (9%)]\tClassification Loss: 1.4476\r\n",
      "Train Epoch: 4 [10240/110534 (9%)]\tClassification Loss: 1.5235\r\n",
      "Train Epoch: 4 [10880/110534 (10%)]\tClassification Loss: 1.2937\r\n",
      "Train Epoch: 4 [11520/110534 (10%)]\tClassification Loss: 1.6367\r\n",
      "Train Epoch: 4 [12160/110534 (11%)]\tClassification Loss: 1.4229\r\n",
      "Train Epoch: 4 [12800/110534 (12%)]\tClassification Loss: 1.6770\r\n",
      "Train Epoch: 4 [13440/110534 (12%)]\tClassification Loss: 1.9755\r\n",
      "Train Epoch: 4 [14080/110534 (13%)]\tClassification Loss: 1.3813\r\n",
      "Train Epoch: 4 [14720/110534 (13%)]\tClassification Loss: 1.3416\r\n",
      "Train Epoch: 4 [15360/110534 (14%)]\tClassification Loss: 1.3389\r\n",
      "Train Epoch: 4 [16000/110534 (14%)]\tClassification Loss: 1.7889\r\n",
      "Train Epoch: 4 [16640/110534 (15%)]\tClassification Loss: 1.5218\r\n",
      "Train Epoch: 4 [17280/110534 (16%)]\tClassification Loss: 1.7327\r\n",
      "Train Epoch: 4 [17920/110534 (16%)]\tClassification Loss: 1.6969\r\n",
      "Train Epoch: 4 [18560/110534 (17%)]\tClassification Loss: 1.6366\r\n",
      "Train Epoch: 4 [19200/110534 (17%)]\tClassification Loss: 1.2543\r\n",
      "Train Epoch: 4 [19840/110534 (18%)]\tClassification Loss: 1.1719\r\n",
      "Train Epoch: 4 [20480/110534 (19%)]\tClassification Loss: 1.1789\r\n",
      "Train Epoch: 4 [21120/110534 (19%)]\tClassification Loss: 1.4505\r\n",
      "Train Epoch: 4 [21760/110534 (20%)]\tClassification Loss: 1.5504\r\n",
      "Train Epoch: 4 [22400/110534 (20%)]\tClassification Loss: 1.5177\r\n",
      "Train Epoch: 4 [23040/110534 (21%)]\tClassification Loss: 1.3771\r\n",
      "Train Epoch: 4 [23680/110534 (21%)]\tClassification Loss: 1.2606\r\n",
      "Train Epoch: 4 [24320/110534 (22%)]\tClassification Loss: 1.6289\r\n",
      "Train Epoch: 4 [24960/110534 (23%)]\tClassification Loss: 1.3614\r\n",
      "Train Epoch: 4 [25600/110534 (23%)]\tClassification Loss: 1.5619\r\n",
      "Train Epoch: 4 [26240/110534 (24%)]\tClassification Loss: 1.6421\r\n",
      "Train Epoch: 4 [26880/110534 (24%)]\tClassification Loss: 1.5964\r\n",
      "Train Epoch: 4 [27520/110534 (25%)]\tClassification Loss: 1.6126\r\n",
      "Train Epoch: 4 [28160/110534 (25%)]\tClassification Loss: 1.4112\r\n",
      "Train Epoch: 4 [28800/110534 (26%)]\tClassification Loss: 1.5267\r\n",
      "Train Epoch: 4 [29440/110534 (27%)]\tClassification Loss: 1.5835\r\n",
      "Train Epoch: 4 [30080/110534 (27%)]\tClassification Loss: 1.8417\r\n",
      "Train Epoch: 4 [30720/110534 (28%)]\tClassification Loss: 1.4775\r\n",
      "Train Epoch: 4 [31360/110534 (28%)]\tClassification Loss: 1.3518\r\n",
      "Train Epoch: 4 [32000/110534 (29%)]\tClassification Loss: 1.4582\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_500.pth.tar\r\n",
      "Train Epoch: 4 [32640/110534 (30%)]\tClassification Loss: 2.0341\r\n",
      "Train Epoch: 4 [33280/110534 (30%)]\tClassification Loss: 1.5929\r\n",
      "Train Epoch: 4 [33920/110534 (31%)]\tClassification Loss: 1.6636\r\n",
      "Train Epoch: 4 [34560/110534 (31%)]\tClassification Loss: 1.4723\r\n",
      "Train Epoch: 4 [35200/110534 (32%)]\tClassification Loss: 1.3751\r\n",
      "Train Epoch: 4 [35840/110534 (32%)]\tClassification Loss: 1.5990\r\n",
      "Train Epoch: 4 [36480/110534 (33%)]\tClassification Loss: 1.5414\r\n",
      "Train Epoch: 4 [37120/110534 (34%)]\tClassification Loss: 1.3251\r\n",
      "Train Epoch: 4 [37760/110534 (34%)]\tClassification Loss: 1.5147\r\n",
      "Train Epoch: 4 [38400/110534 (35%)]\tClassification Loss: 1.4368\r\n",
      "Train Epoch: 4 [39040/110534 (35%)]\tClassification Loss: 1.1165\r\n",
      "Train Epoch: 4 [39680/110534 (36%)]\tClassification Loss: 1.4727\r\n",
      "Train Epoch: 4 [40320/110534 (36%)]\tClassification Loss: 1.6753\r\n",
      "Train Epoch: 4 [40960/110534 (37%)]\tClassification Loss: 1.6868\r\n",
      "Train Epoch: 4 [41600/110534 (38%)]\tClassification Loss: 1.5084\r\n",
      "Train Epoch: 4 [42240/110534 (38%)]\tClassification Loss: 1.7943\r\n",
      "Train Epoch: 4 [42880/110534 (39%)]\tClassification Loss: 1.4709\r\n",
      "Train Epoch: 4 [43520/110534 (39%)]\tClassification Loss: 1.6151\r\n",
      "Train Epoch: 4 [44160/110534 (40%)]\tClassification Loss: 1.5971\r\n",
      "Train Epoch: 4 [44800/110534 (41%)]\tClassification Loss: 1.3505\r\n",
      "Train Epoch: 4 [45440/110534 (41%)]\tClassification Loss: 1.5332\r\n",
      "Train Epoch: 4 [46080/110534 (42%)]\tClassification Loss: 1.6495\r\n",
      "Train Epoch: 4 [46720/110534 (42%)]\tClassification Loss: 1.4009\r\n",
      "Train Epoch: 4 [47360/110534 (43%)]\tClassification Loss: 1.4046\r\n",
      "Train Epoch: 4 [48000/110534 (43%)]\tClassification Loss: 1.6561\r\n",
      "Train Epoch: 4 [48640/110534 (44%)]\tClassification Loss: 1.5909\r\n",
      "Train Epoch: 4 [49280/110534 (45%)]\tClassification Loss: 1.5730\r\n",
      "Train Epoch: 4 [49920/110534 (45%)]\tClassification Loss: 1.3122\r\n",
      "Train Epoch: 4 [50560/110534 (46%)]\tClassification Loss: 1.7378\r\n",
      "Train Epoch: 4 [51200/110534 (46%)]\tClassification Loss: 1.2292\r\n",
      "Train Epoch: 4 [51840/110534 (47%)]\tClassification Loss: 1.4441\r\n",
      "Train Epoch: 4 [52480/110534 (47%)]\tClassification Loss: 1.6126\r\n",
      "Train Epoch: 4 [53120/110534 (48%)]\tClassification Loss: 1.9010\r\n",
      "Train Epoch: 4 [53760/110534 (49%)]\tClassification Loss: 1.4318\r\n",
      "Train Epoch: 4 [54400/110534 (49%)]\tClassification Loss: 1.7050\r\n",
      "Train Epoch: 4 [55040/110534 (50%)]\tClassification Loss: 1.7040\r\n",
      "Train Epoch: 4 [55680/110534 (50%)]\tClassification Loss: 1.9009\r\n",
      "Train Epoch: 4 [56320/110534 (51%)]\tClassification Loss: 1.5137\r\n",
      "Train Epoch: 4 [56960/110534 (52%)]\tClassification Loss: 1.5497\r\n",
      "Train Epoch: 4 [57600/110534 (52%)]\tClassification Loss: 1.6979\r\n",
      "Train Epoch: 4 [58240/110534 (53%)]\tClassification Loss: 1.6483\r\n",
      "Train Epoch: 4 [58880/110534 (53%)]\tClassification Loss: 1.2320\r\n",
      "Train Epoch: 4 [59520/110534 (54%)]\tClassification Loss: 1.5473\r\n",
      "Train Epoch: 4 [60160/110534 (54%)]\tClassification Loss: 1.3477\r\n",
      "Train Epoch: 4 [60800/110534 (55%)]\tClassification Loss: 1.4235\r\n",
      "Train Epoch: 4 [61440/110534 (56%)]\tClassification Loss: 1.4804\r\n",
      "Train Epoch: 4 [62080/110534 (56%)]\tClassification Loss: 1.2926\r\n",
      "Train Epoch: 4 [62720/110534 (57%)]\tClassification Loss: 1.8061\r\n",
      "Train Epoch: 4 [63360/110534 (57%)]\tClassification Loss: 1.3966\r\n",
      "Train Epoch: 4 [64000/110534 (58%)]\tClassification Loss: 1.3075\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1000.pth.tar\r\n",
      "Train Epoch: 4 [64640/110534 (58%)]\tClassification Loss: 1.5364\r\n",
      "Train Epoch: 4 [65280/110534 (59%)]\tClassification Loss: 1.2802\r\n",
      "Train Epoch: 4 [65920/110534 (60%)]\tClassification Loss: 1.5771\r\n",
      "Train Epoch: 4 [66560/110534 (60%)]\tClassification Loss: 1.4238\r\n",
      "Train Epoch: 4 [67200/110534 (61%)]\tClassification Loss: 1.3224\r\n",
      "Train Epoch: 4 [67840/110534 (61%)]\tClassification Loss: 1.5674\r\n",
      "Train Epoch: 4 [68480/110534 (62%)]\tClassification Loss: 1.4461\r\n",
      "Train Epoch: 4 [69120/110534 (63%)]\tClassification Loss: 1.2877\r\n",
      "Train Epoch: 4 [69760/110534 (63%)]\tClassification Loss: 1.7451\r\n",
      "Train Epoch: 4 [70400/110534 (64%)]\tClassification Loss: 1.5713\r\n",
      "Train Epoch: 4 [71040/110534 (64%)]\tClassification Loss: 1.4681\r\n",
      "Train Epoch: 4 [71680/110534 (65%)]\tClassification Loss: 1.8266\r\n",
      "Train Epoch: 4 [72320/110534 (65%)]\tClassification Loss: 1.6222\r\n",
      "Train Epoch: 4 [72960/110534 (66%)]\tClassification Loss: 1.3850\r\n",
      "Train Epoch: 4 [73600/110534 (67%)]\tClassification Loss: 1.3456\r\n",
      "Train Epoch: 4 [74240/110534 (67%)]\tClassification Loss: 1.3337\r\n",
      "Train Epoch: 4 [74880/110534 (68%)]\tClassification Loss: 1.5194\r\n",
      "Train Epoch: 4 [75520/110534 (68%)]\tClassification Loss: 1.5012\r\n",
      "Train Epoch: 4 [76160/110534 (69%)]\tClassification Loss: 1.2623\r\n",
      "Train Epoch: 4 [76800/110534 (69%)]\tClassification Loss: 1.5821\r\n",
      "Train Epoch: 4 [77440/110534 (70%)]\tClassification Loss: 1.6611\r\n",
      "Train Epoch: 4 [78080/110534 (71%)]\tClassification Loss: 1.6562\r\n",
      "Train Epoch: 4 [78720/110534 (71%)]\tClassification Loss: 1.5953\r\n",
      "Train Epoch: 4 [79360/110534 (72%)]\tClassification Loss: 1.5666\r\n",
      "Train Epoch: 4 [80000/110534 (72%)]\tClassification Loss: 1.5694\r\n",
      "Train Epoch: 4 [80640/110534 (73%)]\tClassification Loss: 1.3762\r\n",
      "Train Epoch: 4 [81280/110534 (74%)]\tClassification Loss: 1.4346\r\n",
      "Train Epoch: 4 [81920/110534 (74%)]\tClassification Loss: 1.8135\r\n",
      "Train Epoch: 4 [82560/110534 (75%)]\tClassification Loss: 1.7774\r\n",
      "Train Epoch: 4 [83200/110534 (75%)]\tClassification Loss: 1.5817\r\n",
      "Train Epoch: 4 [83840/110534 (76%)]\tClassification Loss: 1.5136\r\n",
      "Train Epoch: 4 [84480/110534 (76%)]\tClassification Loss: 1.4424\r\n",
      "Train Epoch: 4 [85120/110534 (77%)]\tClassification Loss: 1.4176\r\n",
      "Train Epoch: 4 [85760/110534 (78%)]\tClassification Loss: 1.4419\r\n",
      "Train Epoch: 4 [86400/110534 (78%)]\tClassification Loss: 1.3156\r\n",
      "Train Epoch: 4 [87040/110534 (79%)]\tClassification Loss: 1.6702\r\n",
      "Train Epoch: 4 [87680/110534 (79%)]\tClassification Loss: 1.9719\r\n",
      "Train Epoch: 4 [88320/110534 (80%)]\tClassification Loss: 1.5443\r\n",
      "Train Epoch: 4 [88960/110534 (80%)]\tClassification Loss: 1.3815\r\n",
      "Train Epoch: 4 [89600/110534 (81%)]\tClassification Loss: 1.5223\r\n",
      "Train Epoch: 4 [90240/110534 (82%)]\tClassification Loss: 1.6016\r\n",
      "Train Epoch: 4 [90880/110534 (82%)]\tClassification Loss: 1.6262\r\n",
      "Train Epoch: 4 [91520/110534 (83%)]\tClassification Loss: 1.6177\r\n",
      "Train Epoch: 4 [92160/110534 (83%)]\tClassification Loss: 1.5429\r\n",
      "Train Epoch: 4 [92800/110534 (84%)]\tClassification Loss: 1.3486\r\n",
      "Train Epoch: 4 [93440/110534 (85%)]\tClassification Loss: 1.8430\r\n",
      "Train Epoch: 4 [94080/110534 (85%)]\tClassification Loss: 1.5020\r\n",
      "Train Epoch: 4 [94720/110534 (86%)]\tClassification Loss: 1.4353\r\n",
      "Train Epoch: 4 [95360/110534 (86%)]\tClassification Loss: 1.5835\r\n",
      "Train Epoch: 4 [96000/110534 (87%)]\tClassification Loss: 1.4265\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1500.pth.tar\r\n",
      "Train Epoch: 4 [96640/110534 (87%)]\tClassification Loss: 1.5924\r\n",
      "Train Epoch: 4 [97280/110534 (88%)]\tClassification Loss: 1.4196\r\n",
      "Train Epoch: 4 [97920/110534 (89%)]\tClassification Loss: 1.7756\r\n",
      "Train Epoch: 4 [98560/110534 (89%)]\tClassification Loss: 1.7008\r\n",
      "Train Epoch: 4 [99200/110534 (90%)]\tClassification Loss: 1.2241\r\n",
      "Train Epoch: 4 [99840/110534 (90%)]\tClassification Loss: 1.4949\r\n",
      "Train Epoch: 4 [100480/110534 (91%)]\tClassification Loss: 1.4166\r\n",
      "Train Epoch: 4 [101120/110534 (91%)]\tClassification Loss: 1.5063\r\n",
      "Train Epoch: 4 [101760/110534 (92%)]\tClassification Loss: 1.2067\r\n",
      "Train Epoch: 4 [102400/110534 (93%)]\tClassification Loss: 1.3464\r\n",
      "Train Epoch: 4 [103040/110534 (93%)]\tClassification Loss: 1.3954\r\n",
      "Train Epoch: 4 [103680/110534 (94%)]\tClassification Loss: 1.5258\r\n",
      "Train Epoch: 4 [104320/110534 (94%)]\tClassification Loss: 1.5325\r\n",
      "Train Epoch: 4 [104960/110534 (95%)]\tClassification Loss: 1.7772\r\n",
      "Train Epoch: 4 [105600/110534 (96%)]\tClassification Loss: 1.4839\r\n",
      "Train Epoch: 4 [106240/110534 (96%)]\tClassification Loss: 1.4135\r\n",
      "Train Epoch: 4 [106880/110534 (97%)]\tClassification Loss: 1.6547\r\n",
      "Train Epoch: 4 [107520/110534 (97%)]\tClassification Loss: 1.6663\r\n",
      "Train Epoch: 4 [108160/110534 (98%)]\tClassification Loss: 1.3895\r\n",
      "Train Epoch: 4 [108800/110534 (98%)]\tClassification Loss: 1.3140\r\n",
      "Train Epoch: 4 [109440/110534 (99%)]\tClassification Loss: 1.5077\r\n",
      "Train Epoch: 4 [110080/110534 (100%)]\tClassification Loss: 1.8641\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_final.pth.tar\r\n",
      "Train Epoch: 5 [0/110534 (0%)]\tClassification Loss: 1.9265\r\n",
      "\r\n",
      "Test set: Average loss: 1.4230, Accuracy: 23211/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 5 [640/110534 (1%)]\tClassification Loss: 1.5368\r\n",
      "Train Epoch: 5 [1280/110534 (1%)]\tClassification Loss: 1.3051\r\n",
      "Train Epoch: 5 [1920/110534 (2%)]\tClassification Loss: 1.6808\r\n",
      "Train Epoch: 5 [2560/110534 (2%)]\tClassification Loss: 1.5185\r\n",
      "Train Epoch: 5 [3200/110534 (3%)]\tClassification Loss: 1.4442\r\n",
      "Train Epoch: 5 [3840/110534 (3%)]\tClassification Loss: 1.7278\r\n",
      "Train Epoch: 5 [4480/110534 (4%)]\tClassification Loss: 1.2457\r\n",
      "Train Epoch: 5 [5120/110534 (5%)]\tClassification Loss: 1.7002\r\n",
      "Train Epoch: 5 [5760/110534 (5%)]\tClassification Loss: 1.5522\r\n",
      "Train Epoch: 5 [6400/110534 (6%)]\tClassification Loss: 1.7049\r\n",
      "Train Epoch: 5 [7040/110534 (6%)]\tClassification Loss: 1.3345\r\n",
      "Train Epoch: 5 [7680/110534 (7%)]\tClassification Loss: 1.4941\r\n",
      "Train Epoch: 5 [8320/110534 (8%)]\tClassification Loss: 1.8461\r\n",
      "Train Epoch: 5 [8960/110534 (8%)]\tClassification Loss: 1.4428\r\n",
      "Train Epoch: 5 [9600/110534 (9%)]\tClassification Loss: 1.5761\r\n",
      "Train Epoch: 5 [10240/110534 (9%)]\tClassification Loss: 1.3950\r\n",
      "Train Epoch: 5 [10880/110534 (10%)]\tClassification Loss: 1.2996\r\n",
      "Train Epoch: 5 [11520/110534 (10%)]\tClassification Loss: 1.4012\r\n",
      "Train Epoch: 5 [12160/110534 (11%)]\tClassification Loss: 1.4828\r\n",
      "Train Epoch: 5 [12800/110534 (12%)]\tClassification Loss: 1.7475\r\n",
      "Train Epoch: 5 [13440/110534 (12%)]\tClassification Loss: 1.7664\r\n",
      "Train Epoch: 5 [14080/110534 (13%)]\tClassification Loss: 1.3597\r\n",
      "Train Epoch: 5 [14720/110534 (13%)]\tClassification Loss: 1.3579\r\n",
      "Train Epoch: 5 [15360/110534 (14%)]\tClassification Loss: 1.3246\r\n",
      "Train Epoch: 5 [16000/110534 (14%)]\tClassification Loss: 1.5524\r\n",
      "Train Epoch: 5 [16640/110534 (15%)]\tClassification Loss: 1.5051\r\n",
      "Train Epoch: 5 [17280/110534 (16%)]\tClassification Loss: 1.6154\r\n",
      "Train Epoch: 5 [17920/110534 (16%)]\tClassification Loss: 1.7091\r\n",
      "Train Epoch: 5 [18560/110534 (17%)]\tClassification Loss: 1.5273\r\n",
      "Train Epoch: 5 [19200/110534 (17%)]\tClassification Loss: 1.4625\r\n",
      "Train Epoch: 5 [19840/110534 (18%)]\tClassification Loss: 1.3436\r\n",
      "Train Epoch: 5 [20480/110534 (19%)]\tClassification Loss: 1.1980\r\n",
      "Train Epoch: 5 [21120/110534 (19%)]\tClassification Loss: 1.4496\r\n",
      "Train Epoch: 5 [21760/110534 (20%)]\tClassification Loss: 1.8233\r\n",
      "Train Epoch: 5 [22400/110534 (20%)]\tClassification Loss: 1.6356\r\n",
      "Train Epoch: 5 [23040/110534 (21%)]\tClassification Loss: 1.3828\r\n",
      "Train Epoch: 5 [23680/110534 (21%)]\tClassification Loss: 1.3556\r\n",
      "Train Epoch: 5 [24320/110534 (22%)]\tClassification Loss: 1.8927\r\n",
      "Train Epoch: 5 [24960/110534 (23%)]\tClassification Loss: 1.4425\r\n",
      "Train Epoch: 5 [25600/110534 (23%)]\tClassification Loss: 1.6171\r\n",
      "Train Epoch: 5 [26240/110534 (24%)]\tClassification Loss: 1.7657\r\n",
      "Train Epoch: 5 [26880/110534 (24%)]\tClassification Loss: 1.4883\r\n",
      "Train Epoch: 5 [27520/110534 (25%)]\tClassification Loss: 1.6607\r\n",
      "Train Epoch: 5 [28160/110534 (25%)]\tClassification Loss: 1.5108\r\n",
      "Train Epoch: 5 [28800/110534 (26%)]\tClassification Loss: 1.5817\r\n",
      "Train Epoch: 5 [29440/110534 (27%)]\tClassification Loss: 1.5836\r\n",
      "Train Epoch: 5 [30080/110534 (27%)]\tClassification Loss: 1.6556\r\n",
      "Train Epoch: 5 [30720/110534 (28%)]\tClassification Loss: 1.3781\r\n",
      "Train Epoch: 5 [31360/110534 (28%)]\tClassification Loss: 1.3489\r\n",
      "Train Epoch: 5 [32000/110534 (29%)]\tClassification Loss: 1.4636\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_500.pth.tar\r\n",
      "Train Epoch: 5 [32640/110534 (30%)]\tClassification Loss: 2.0362\r\n",
      "Train Epoch: 5 [33280/110534 (30%)]\tClassification Loss: 1.5595\r\n",
      "Train Epoch: 5 [33920/110534 (31%)]\tClassification Loss: 1.6098\r\n",
      "Train Epoch: 5 [34560/110534 (31%)]\tClassification Loss: 1.3647\r\n",
      "Train Epoch: 5 [35200/110534 (32%)]\tClassification Loss: 1.3995\r\n",
      "Train Epoch: 5 [35840/110534 (32%)]\tClassification Loss: 1.6396\r\n",
      "Train Epoch: 5 [36480/110534 (33%)]\tClassification Loss: 1.4515\r\n",
      "Train Epoch: 5 [37120/110534 (34%)]\tClassification Loss: 1.2288\r\n",
      "Train Epoch: 5 [37760/110534 (34%)]\tClassification Loss: 1.5733\r\n",
      "Train Epoch: 5 [38400/110534 (35%)]\tClassification Loss: 1.4474\r\n",
      "Train Epoch: 5 [39040/110534 (35%)]\tClassification Loss: 1.1416\r\n",
      "Train Epoch: 5 [39680/110534 (36%)]\tClassification Loss: 1.4680\r\n",
      "Train Epoch: 5 [40320/110534 (36%)]\tClassification Loss: 1.5544\r\n",
      "Train Epoch: 5 [40960/110534 (37%)]\tClassification Loss: 1.7929\r\n",
      "Train Epoch: 5 [41600/110534 (38%)]\tClassification Loss: 1.5358\r\n",
      "Train Epoch: 5 [42240/110534 (38%)]\tClassification Loss: 1.6176\r\n",
      "Train Epoch: 5 [42880/110534 (39%)]\tClassification Loss: 1.4183\r\n",
      "Train Epoch: 5 [43520/110534 (39%)]\tClassification Loss: 1.5232\r\n",
      "Train Epoch: 5 [44160/110534 (40%)]\tClassification Loss: 1.6196\r\n",
      "Train Epoch: 5 [44800/110534 (41%)]\tClassification Loss: 1.4764\r\n",
      "Train Epoch: 5 [45440/110534 (41%)]\tClassification Loss: 1.5689\r\n",
      "Train Epoch: 5 [46080/110534 (42%)]\tClassification Loss: 1.7084\r\n",
      "Train Epoch: 5 [46720/110534 (42%)]\tClassification Loss: 1.4191\r\n",
      "Train Epoch: 5 [47360/110534 (43%)]\tClassification Loss: 1.4143\r\n",
      "Train Epoch: 5 [48000/110534 (43%)]\tClassification Loss: 1.6348\r\n",
      "Train Epoch: 5 [48640/110534 (44%)]\tClassification Loss: 1.6418\r\n",
      "Train Epoch: 5 [49280/110534 (45%)]\tClassification Loss: 1.4203\r\n",
      "Train Epoch: 5 [49920/110534 (45%)]\tClassification Loss: 1.2199\r\n",
      "Train Epoch: 5 [50560/110534 (46%)]\tClassification Loss: 1.6287\r\n",
      "Train Epoch: 5 [51200/110534 (46%)]\tClassification Loss: 1.3111\r\n",
      "Train Epoch: 5 [51840/110534 (47%)]\tClassification Loss: 1.4206\r\n",
      "Train Epoch: 5 [52480/110534 (47%)]\tClassification Loss: 1.4316\r\n",
      "Train Epoch: 5 [53120/110534 (48%)]\tClassification Loss: 1.8435\r\n",
      "Train Epoch: 5 [53760/110534 (49%)]\tClassification Loss: 1.4160\r\n",
      "Train Epoch: 5 [54400/110534 (49%)]\tClassification Loss: 1.7743\r\n",
      "Train Epoch: 5 [55040/110534 (50%)]\tClassification Loss: 1.7828\r\n",
      "Train Epoch: 5 [55680/110534 (50%)]\tClassification Loss: 1.9641\r\n",
      "Train Epoch: 5 [56320/110534 (51%)]\tClassification Loss: 1.3431\r\n",
      "Train Epoch: 5 [56960/110534 (52%)]\tClassification Loss: 1.6367\r\n",
      "Train Epoch: 5 [57600/110534 (52%)]\tClassification Loss: 1.7889\r\n",
      "Train Epoch: 5 [58240/110534 (53%)]\tClassification Loss: 1.5829\r\n",
      "Train Epoch: 5 [58880/110534 (53%)]\tClassification Loss: 1.2266\r\n",
      "Train Epoch: 5 [59520/110534 (54%)]\tClassification Loss: 1.6227\r\n",
      "Train Epoch: 5 [60160/110534 (54%)]\tClassification Loss: 1.2775\r\n",
      "Train Epoch: 5 [60800/110534 (55%)]\tClassification Loss: 1.4677\r\n",
      "Train Epoch: 5 [61440/110534 (56%)]\tClassification Loss: 1.5922\r\n",
      "Train Epoch: 5 [62080/110534 (56%)]\tClassification Loss: 1.4693\r\n",
      "Train Epoch: 5 [62720/110534 (57%)]\tClassification Loss: 1.5751\r\n",
      "Train Epoch: 5 [63360/110534 (57%)]\tClassification Loss: 1.6336\r\n",
      "Train Epoch: 5 [64000/110534 (58%)]\tClassification Loss: 1.2738\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_1000.pth.tar\r\n",
      "Train Epoch: 5 [64640/110534 (58%)]\tClassification Loss: 1.6443\r\n",
      "Train Epoch: 5 [65280/110534 (59%)]\tClassification Loss: 1.3138\r\n",
      "Train Epoch: 5 [65920/110534 (60%)]\tClassification Loss: 1.6263\r\n",
      "Train Epoch: 5 [66560/110534 (60%)]\tClassification Loss: 1.4180\r\n",
      "Train Epoch: 5 [67200/110534 (61%)]\tClassification Loss: 1.1912\r\n",
      "Train Epoch: 5 [67840/110534 (61%)]\tClassification Loss: 1.5622\r\n",
      "Train Epoch: 5 [68480/110534 (62%)]\tClassification Loss: 1.5324\r\n",
      "Train Epoch: 5 [69120/110534 (63%)]\tClassification Loss: 1.2356\r\n",
      "Train Epoch: 5 [69760/110534 (63%)]\tClassification Loss: 1.6920\r\n",
      "Train Epoch: 5 [70400/110534 (64%)]\tClassification Loss: 1.3150\r\n",
      "Train Epoch: 5 [71040/110534 (64%)]\tClassification Loss: 1.6479\r\n",
      "Train Epoch: 5 [71680/110534 (65%)]\tClassification Loss: 1.9281\r\n",
      "Train Epoch: 5 [72320/110534 (65%)]\tClassification Loss: 1.5507\r\n",
      "Train Epoch: 5 [72960/110534 (66%)]\tClassification Loss: 1.4854\r\n",
      "Train Epoch: 5 [73600/110534 (67%)]\tClassification Loss: 1.3230\r\n",
      "Train Epoch: 5 [74240/110534 (67%)]\tClassification Loss: 1.3763\r\n",
      "Train Epoch: 5 [74880/110534 (68%)]\tClassification Loss: 1.4811\r\n",
      "Train Epoch: 5 [75520/110534 (68%)]\tClassification Loss: 1.6060\r\n",
      "Train Epoch: 5 [76160/110534 (69%)]\tClassification Loss: 1.2109\r\n",
      "Train Epoch: 5 [76800/110534 (69%)]\tClassification Loss: 1.5144\r\n",
      "Train Epoch: 5 [77440/110534 (70%)]\tClassification Loss: 1.6027\r\n",
      "Train Epoch: 5 [78080/110534 (71%)]\tClassification Loss: 1.6703\r\n",
      "Train Epoch: 5 [78720/110534 (71%)]\tClassification Loss: 1.5146\r\n",
      "Train Epoch: 5 [79360/110534 (72%)]\tClassification Loss: 1.5255\r\n",
      "Train Epoch: 5 [80000/110534 (72%)]\tClassification Loss: 1.7102\r\n",
      "Train Epoch: 5 [80640/110534 (73%)]\tClassification Loss: 1.4224\r\n",
      "Train Epoch: 5 [81280/110534 (74%)]\tClassification Loss: 1.2959\r\n",
      "Train Epoch: 5 [81920/110534 (74%)]\tClassification Loss: 1.7363\r\n",
      "Train Epoch: 5 [82560/110534 (75%)]\tClassification Loss: 1.8227\r\n",
      "Train Epoch: 5 [83200/110534 (75%)]\tClassification Loss: 1.6784\r\n",
      "Train Epoch: 5 [83840/110534 (76%)]\tClassification Loss: 1.4911\r\n",
      "Train Epoch: 5 [84480/110534 (76%)]\tClassification Loss: 1.4661\r\n",
      "Train Epoch: 5 [85120/110534 (77%)]\tClassification Loss: 1.5791\r\n",
      "Train Epoch: 5 [85760/110534 (78%)]\tClassification Loss: 1.4877\r\n",
      "Train Epoch: 5 [86400/110534 (78%)]\tClassification Loss: 1.3182\r\n",
      "Train Epoch: 5 [87040/110534 (79%)]\tClassification Loss: 1.5394\r\n",
      "Train Epoch: 5 [87680/110534 (79%)]\tClassification Loss: 1.9873\r\n",
      "Train Epoch: 5 [88320/110534 (80%)]\tClassification Loss: 1.3747\r\n",
      "Train Epoch: 5 [88960/110534 (80%)]\tClassification Loss: 1.4475\r\n",
      "Train Epoch: 5 [89600/110534 (81%)]\tClassification Loss: 1.5966\r\n",
      "Train Epoch: 5 [90240/110534 (82%)]\tClassification Loss: 1.5757\r\n",
      "Train Epoch: 5 [90880/110534 (82%)]\tClassification Loss: 1.6182\r\n",
      "Train Epoch: 5 [91520/110534 (83%)]\tClassification Loss: 1.6687\r\n",
      "Train Epoch: 5 [92160/110534 (83%)]\tClassification Loss: 1.3636\r\n",
      "Train Epoch: 5 [92800/110534 (84%)]\tClassification Loss: 1.3561\r\n",
      "Train Epoch: 5 [93440/110534 (85%)]\tClassification Loss: 1.8007\r\n",
      "Train Epoch: 5 [94080/110534 (85%)]\tClassification Loss: 1.3943\r\n",
      "Train Epoch: 5 [94720/110534 (86%)]\tClassification Loss: 1.4841\r\n",
      "Train Epoch: 5 [95360/110534 (86%)]\tClassification Loss: 1.4430\r\n",
      "Train Epoch: 5 [96000/110534 (87%)]\tClassification Loss: 1.6016\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_1500.pth.tar\r\n",
      "Train Epoch: 5 [96640/110534 (87%)]\tClassification Loss: 1.5461\r\n",
      "Train Epoch: 5 [97280/110534 (88%)]\tClassification Loss: 1.4412\r\n",
      "Train Epoch: 5 [97920/110534 (89%)]\tClassification Loss: 1.6507\r\n",
      "Train Epoch: 5 [98560/110534 (89%)]\tClassification Loss: 1.6530\r\n",
      "Train Epoch: 5 [99200/110534 (90%)]\tClassification Loss: 1.1232\r\n",
      "Train Epoch: 5 [99840/110534 (90%)]\tClassification Loss: 1.4915\r\n",
      "Train Epoch: 5 [100480/110534 (91%)]\tClassification Loss: 1.4368\r\n",
      "Train Epoch: 5 [101120/110534 (91%)]\tClassification Loss: 1.6652\r\n",
      "Train Epoch: 5 [101760/110534 (92%)]\tClassification Loss: 1.3539\r\n",
      "Train Epoch: 5 [102400/110534 (93%)]\tClassification Loss: 1.2734\r\n",
      "Train Epoch: 5 [103040/110534 (93%)]\tClassification Loss: 1.4224\r\n",
      "Train Epoch: 5 [103680/110534 (94%)]\tClassification Loss: 1.6483\r\n",
      "Train Epoch: 5 [104320/110534 (94%)]\tClassification Loss: 1.5551\r\n",
      "Train Epoch: 5 [104960/110534 (95%)]\tClassification Loss: 1.6232\r\n",
      "Train Epoch: 5 [105600/110534 (96%)]\tClassification Loss: 1.3947\r\n",
      "Train Epoch: 5 [106240/110534 (96%)]\tClassification Loss: 1.3146\r\n",
      "Train Epoch: 5 [106880/110534 (97%)]\tClassification Loss: 1.6862\r\n",
      "Train Epoch: 5 [107520/110534 (97%)]\tClassification Loss: 1.6502\r\n",
      "Train Epoch: 5 [108160/110534 (98%)]\tClassification Loss: 1.3602\r\n",
      "Train Epoch: 5 [108800/110534 (98%)]\tClassification Loss: 1.3553\r\n",
      "Train Epoch: 5 [109440/110534 (99%)]\tClassification Loss: 1.6916\r\n",
      "Train Epoch: 5 [110080/110534 (100%)]\tClassification Loss: 1.6585\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_final.pth.tar\r\n",
      "Train Epoch: 6 [0/110534 (0%)]\tClassification Loss: 1.9336\r\n",
      "\r\n",
      "Test set: Average loss: 1.4187, Accuracy: 23161/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 6 [640/110534 (1%)]\tClassification Loss: 1.5372\r\n",
      "Train Epoch: 6 [1280/110534 (1%)]\tClassification Loss: 1.3690\r\n",
      "Train Epoch: 6 [1920/110534 (2%)]\tClassification Loss: 1.7107\r\n",
      "Train Epoch: 6 [2560/110534 (2%)]\tClassification Loss: 1.4957\r\n",
      "Train Epoch: 6 [3200/110534 (3%)]\tClassification Loss: 1.4192\r\n",
      "Train Epoch: 6 [3840/110534 (3%)]\tClassification Loss: 1.7990\r\n",
      "Train Epoch: 6 [4480/110534 (4%)]\tClassification Loss: 1.4513\r\n",
      "Train Epoch: 6 [5120/110534 (5%)]\tClassification Loss: 1.6926\r\n",
      "Train Epoch: 6 [5760/110534 (5%)]\tClassification Loss: 1.4251\r\n",
      "Train Epoch: 6 [6400/110534 (6%)]\tClassification Loss: 1.6133\r\n",
      "Train Epoch: 6 [7040/110534 (6%)]\tClassification Loss: 1.4035\r\n",
      "Train Epoch: 6 [7680/110534 (7%)]\tClassification Loss: 1.6318\r\n",
      "Train Epoch: 6 [8320/110534 (8%)]\tClassification Loss: 1.8391\r\n",
      "Train Epoch: 6 [8960/110534 (8%)]\tClassification Loss: 1.5742\r\n",
      "Train Epoch: 6 [9600/110534 (9%)]\tClassification Loss: 1.5071\r\n",
      "Train Epoch: 6 [10240/110534 (9%)]\tClassification Loss: 1.4252\r\n",
      "Train Epoch: 6 [10880/110534 (10%)]\tClassification Loss: 1.3733\r\n",
      "Train Epoch: 6 [11520/110534 (10%)]\tClassification Loss: 1.4754\r\n",
      "Train Epoch: 6 [12160/110534 (11%)]\tClassification Loss: 1.5168\r\n",
      "Train Epoch: 6 [12800/110534 (12%)]\tClassification Loss: 1.5416\r\n",
      "Train Epoch: 6 [13440/110534 (12%)]\tClassification Loss: 1.8048\r\n",
      "Train Epoch: 6 [14080/110534 (13%)]\tClassification Loss: 1.3792\r\n",
      "Train Epoch: 6 [14720/110534 (13%)]\tClassification Loss: 1.4381\r\n",
      "Train Epoch: 6 [15360/110534 (14%)]\tClassification Loss: 1.2676\r\n",
      "Train Epoch: 6 [16000/110534 (14%)]\tClassification Loss: 1.6734\r\n",
      "Train Epoch: 6 [16640/110534 (15%)]\tClassification Loss: 1.6440\r\n",
      "Train Epoch: 6 [17280/110534 (16%)]\tClassification Loss: 1.6547\r\n",
      "Train Epoch: 6 [17920/110534 (16%)]\tClassification Loss: 1.6574\r\n",
      "Train Epoch: 6 [18560/110534 (17%)]\tClassification Loss: 1.4463\r\n",
      "Train Epoch: 6 [19200/110534 (17%)]\tClassification Loss: 1.3846\r\n",
      "Train Epoch: 6 [19840/110534 (18%)]\tClassification Loss: 1.2084\r\n",
      "Train Epoch: 6 [20480/110534 (19%)]\tClassification Loss: 1.1688\r\n",
      "Train Epoch: 6 [21120/110534 (19%)]\tClassification Loss: 1.6048\r\n",
      "Train Epoch: 6 [21760/110534 (20%)]\tClassification Loss: 1.5759\r\n",
      "Train Epoch: 6 [22400/110534 (20%)]\tClassification Loss: 1.5309\r\n",
      "Train Epoch: 6 [23040/110534 (21%)]\tClassification Loss: 1.3531\r\n",
      "Train Epoch: 6 [23680/110534 (21%)]\tClassification Loss: 1.4354\r\n",
      "Train Epoch: 6 [24320/110534 (22%)]\tClassification Loss: 1.5888\r\n",
      "Train Epoch: 6 [24960/110534 (23%)]\tClassification Loss: 1.4985\r\n",
      "Train Epoch: 6 [25600/110534 (23%)]\tClassification Loss: 1.6178\r\n",
      "Train Epoch: 6 [26240/110534 (24%)]\tClassification Loss: 1.7214\r\n",
      "Train Epoch: 6 [26880/110534 (24%)]\tClassification Loss: 1.4358\r\n",
      "Train Epoch: 6 [27520/110534 (25%)]\tClassification Loss: 1.7504\r\n",
      "Train Epoch: 6 [28160/110534 (25%)]\tClassification Loss: 1.3952\r\n",
      "Train Epoch: 6 [28800/110534 (26%)]\tClassification Loss: 1.5257\r\n",
      "Train Epoch: 6 [29440/110534 (27%)]\tClassification Loss: 1.6952\r\n",
      "Train Epoch: 6 [30080/110534 (27%)]\tClassification Loss: 1.6647\r\n",
      "Train Epoch: 6 [30720/110534 (28%)]\tClassification Loss: 1.4749\r\n",
      "Train Epoch: 6 [31360/110534 (28%)]\tClassification Loss: 1.4004\r\n",
      "Train Epoch: 6 [32000/110534 (29%)]\tClassification Loss: 1.5156\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_500.pth.tar\r\n",
      "Train Epoch: 6 [32640/110534 (30%)]\tClassification Loss: 2.0178\r\n",
      "Train Epoch: 6 [33280/110534 (30%)]\tClassification Loss: 1.5425\r\n",
      "Train Epoch: 6 [33920/110534 (31%)]\tClassification Loss: 1.6313\r\n",
      "Train Epoch: 6 [34560/110534 (31%)]\tClassification Loss: 1.6344\r\n",
      "Train Epoch: 6 [35200/110534 (32%)]\tClassification Loss: 1.4517\r\n",
      "Train Epoch: 6 [35840/110534 (32%)]\tClassification Loss: 1.6548\r\n",
      "Train Epoch: 6 [36480/110534 (33%)]\tClassification Loss: 1.4864\r\n",
      "Train Epoch: 6 [37120/110534 (34%)]\tClassification Loss: 1.1793\r\n",
      "Train Epoch: 6 [37760/110534 (34%)]\tClassification Loss: 1.6802\r\n",
      "Train Epoch: 6 [38400/110534 (35%)]\tClassification Loss: 1.6052\r\n",
      "Train Epoch: 6 [39040/110534 (35%)]\tClassification Loss: 1.1944\r\n",
      "Train Epoch: 6 [39680/110534 (36%)]\tClassification Loss: 1.4589\r\n",
      "Train Epoch: 6 [40320/110534 (36%)]\tClassification Loss: 1.6797\r\n",
      "Train Epoch: 6 [40960/110534 (37%)]\tClassification Loss: 1.6695\r\n",
      "Train Epoch: 6 [41600/110534 (38%)]\tClassification Loss: 1.6079\r\n",
      "Train Epoch: 6 [42240/110534 (38%)]\tClassification Loss: 1.7658\r\n",
      "Train Epoch: 6 [42880/110534 (39%)]\tClassification Loss: 1.6077\r\n",
      "Train Epoch: 6 [43520/110534 (39%)]\tClassification Loss: 1.4826\r\n",
      "Train Epoch: 6 [44160/110534 (40%)]\tClassification Loss: 1.4011\r\n",
      "Train Epoch: 6 [44800/110534 (41%)]\tClassification Loss: 1.4061\r\n",
      "Train Epoch: 6 [45440/110534 (41%)]\tClassification Loss: 1.3802\r\n",
      "Train Epoch: 6 [46080/110534 (42%)]\tClassification Loss: 1.5868\r\n",
      "Train Epoch: 6 [46720/110534 (42%)]\tClassification Loss: 1.3395\r\n",
      "Train Epoch: 6 [47360/110534 (43%)]\tClassification Loss: 1.5472\r\n",
      "Train Epoch: 6 [48000/110534 (43%)]\tClassification Loss: 1.5096\r\n",
      "Train Epoch: 6 [48640/110534 (44%)]\tClassification Loss: 1.5856\r\n",
      "Train Epoch: 6 [49280/110534 (45%)]\tClassification Loss: 1.5965\r\n",
      "Train Epoch: 6 [49920/110534 (45%)]\tClassification Loss: 1.1784\r\n",
      "Train Epoch: 6 [50560/110534 (46%)]\tClassification Loss: 1.6495\r\n",
      "Train Epoch: 6 [51200/110534 (46%)]\tClassification Loss: 1.1648\r\n",
      "Train Epoch: 6 [51840/110534 (47%)]\tClassification Loss: 1.5414\r\n",
      "Train Epoch: 6 [52480/110534 (47%)]\tClassification Loss: 1.6279\r\n",
      "Train Epoch: 6 [53120/110534 (48%)]\tClassification Loss: 1.7590\r\n",
      "Train Epoch: 6 [53760/110534 (49%)]\tClassification Loss: 1.4650\r\n",
      "Train Epoch: 6 [54400/110534 (49%)]\tClassification Loss: 1.7087\r\n",
      "Train Epoch: 6 [55040/110534 (50%)]\tClassification Loss: 1.6138\r\n",
      "Train Epoch: 6 [55680/110534 (50%)]\tClassification Loss: 1.9782\r\n",
      "Train Epoch: 6 [56320/110534 (51%)]\tClassification Loss: 1.4378\r\n",
      "Train Epoch: 6 [56960/110534 (52%)]\tClassification Loss: 1.5852\r\n",
      "Train Epoch: 6 [57600/110534 (52%)]\tClassification Loss: 1.5779\r\n",
      "Train Epoch: 6 [58240/110534 (53%)]\tClassification Loss: 1.4991\r\n",
      "Train Epoch: 6 [58880/110534 (53%)]\tClassification Loss: 1.1907\r\n",
      "Train Epoch: 6 [59520/110534 (54%)]\tClassification Loss: 1.5647\r\n",
      "Train Epoch: 6 [60160/110534 (54%)]\tClassification Loss: 1.3698\r\n",
      "Train Epoch: 6 [60800/110534 (55%)]\tClassification Loss: 1.5056\r\n",
      "Train Epoch: 6 [61440/110534 (56%)]\tClassification Loss: 1.5579\r\n",
      "Train Epoch: 6 [62080/110534 (56%)]\tClassification Loss: 1.5509\r\n",
      "Train Epoch: 6 [62720/110534 (57%)]\tClassification Loss: 1.6373\r\n",
      "Train Epoch: 6 [63360/110534 (57%)]\tClassification Loss: 1.5528\r\n",
      "Train Epoch: 6 [64000/110534 (58%)]\tClassification Loss: 1.3646\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_1000.pth.tar\r\n",
      "Train Epoch: 6 [64640/110534 (58%)]\tClassification Loss: 1.5864\r\n",
      "Train Epoch: 6 [65280/110534 (59%)]\tClassification Loss: 1.5234\r\n",
      "Train Epoch: 6 [65920/110534 (60%)]\tClassification Loss: 1.5880\r\n",
      "Train Epoch: 6 [66560/110534 (60%)]\tClassification Loss: 1.5131\r\n",
      "Train Epoch: 6 [67200/110534 (61%)]\tClassification Loss: 1.3950\r\n",
      "Train Epoch: 6 [67840/110534 (61%)]\tClassification Loss: 1.4986\r\n",
      "Train Epoch: 6 [68480/110534 (62%)]\tClassification Loss: 1.5528\r\n",
      "Train Epoch: 6 [69120/110534 (63%)]\tClassification Loss: 1.1774\r\n",
      "Train Epoch: 6 [69760/110534 (63%)]\tClassification Loss: 1.6699\r\n",
      "Train Epoch: 6 [70400/110534 (64%)]\tClassification Loss: 1.3575\r\n",
      "Train Epoch: 6 [71040/110534 (64%)]\tClassification Loss: 1.4267\r\n",
      "Train Epoch: 6 [71680/110534 (65%)]\tClassification Loss: 1.6934\r\n",
      "Train Epoch: 6 [72320/110534 (65%)]\tClassification Loss: 1.7004\r\n",
      "Train Epoch: 6 [72960/110534 (66%)]\tClassification Loss: 1.4679\r\n",
      "Train Epoch: 6 [73600/110534 (67%)]\tClassification Loss: 1.3912\r\n",
      "Train Epoch: 6 [74240/110534 (67%)]\tClassification Loss: 1.3586\r\n",
      "Train Epoch: 6 [74880/110534 (68%)]\tClassification Loss: 1.6628\r\n",
      "Train Epoch: 6 [75520/110534 (68%)]\tClassification Loss: 1.4796\r\n",
      "Train Epoch: 6 [76160/110534 (69%)]\tClassification Loss: 1.2685\r\n",
      "Train Epoch: 6 [76800/110534 (69%)]\tClassification Loss: 1.6076\r\n",
      "Train Epoch: 6 [77440/110534 (70%)]\tClassification Loss: 1.6154\r\n",
      "Train Epoch: 6 [78080/110534 (71%)]\tClassification Loss: 1.5624\r\n",
      "Train Epoch: 6 [78720/110534 (71%)]\tClassification Loss: 1.5101\r\n",
      "Train Epoch: 6 [79360/110534 (72%)]\tClassification Loss: 1.6658\r\n",
      "Train Epoch: 6 [80000/110534 (72%)]\tClassification Loss: 1.6654\r\n",
      "Train Epoch: 6 [80640/110534 (73%)]\tClassification Loss: 1.4787\r\n",
      "Train Epoch: 6 [81280/110534 (74%)]\tClassification Loss: 1.2939\r\n",
      "Train Epoch: 6 [81920/110534 (74%)]\tClassification Loss: 1.7357\r\n",
      "Train Epoch: 6 [82560/110534 (75%)]\tClassification Loss: 1.8179\r\n",
      "Train Epoch: 6 [83200/110534 (75%)]\tClassification Loss: 1.7705\r\n",
      "Train Epoch: 6 [83840/110534 (76%)]\tClassification Loss: 1.4383\r\n",
      "Train Epoch: 6 [84480/110534 (76%)]\tClassification Loss: 1.4661\r\n",
      "Train Epoch: 6 [85120/110534 (77%)]\tClassification Loss: 1.4823\r\n",
      "Train Epoch: 6 [85760/110534 (78%)]\tClassification Loss: 1.4468\r\n",
      "Train Epoch: 6 [86400/110534 (78%)]\tClassification Loss: 1.3680\r\n",
      "Train Epoch: 6 [87040/110534 (79%)]\tClassification Loss: 1.5562\r\n",
      "Train Epoch: 6 [87680/110534 (79%)]\tClassification Loss: 1.8414\r\n",
      "Train Epoch: 6 [88320/110534 (80%)]\tClassification Loss: 1.3955\r\n",
      "Train Epoch: 6 [88960/110534 (80%)]\tClassification Loss: 1.2636\r\n",
      "Train Epoch: 6 [89600/110534 (81%)]\tClassification Loss: 1.4693\r\n",
      "Train Epoch: 6 [90240/110534 (82%)]\tClassification Loss: 1.5550\r\n",
      "Train Epoch: 6 [90880/110534 (82%)]\tClassification Loss: 1.6112\r\n",
      "Train Epoch: 6 [91520/110534 (83%)]\tClassification Loss: 1.6832\r\n",
      "Train Epoch: 6 [92160/110534 (83%)]\tClassification Loss: 1.3922\r\n",
      "Train Epoch: 6 [92800/110534 (84%)]\tClassification Loss: 1.3318\r\n",
      "Train Epoch: 6 [93440/110534 (85%)]\tClassification Loss: 1.6641\r\n",
      "Train Epoch: 6 [94080/110534 (85%)]\tClassification Loss: 1.4869\r\n",
      "Train Epoch: 6 [94720/110534 (86%)]\tClassification Loss: 1.4080\r\n",
      "Train Epoch: 6 [95360/110534 (86%)]\tClassification Loss: 1.4759\r\n",
      "Train Epoch: 6 [96000/110534 (87%)]\tClassification Loss: 1.4363\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_1500.pth.tar\r\n",
      "Train Epoch: 6 [96640/110534 (87%)]\tClassification Loss: 1.5876\r\n",
      "Train Epoch: 6 [97280/110534 (88%)]\tClassification Loss: 1.6604\r\n",
      "Train Epoch: 6 [97920/110534 (89%)]\tClassification Loss: 1.6666\r\n",
      "Train Epoch: 6 [98560/110534 (89%)]\tClassification Loss: 1.6085\r\n",
      "Train Epoch: 6 [99200/110534 (90%)]\tClassification Loss: 1.1631\r\n",
      "Train Epoch: 6 [99840/110534 (90%)]\tClassification Loss: 1.6428\r\n",
      "Train Epoch: 6 [100480/110534 (91%)]\tClassification Loss: 1.3659\r\n",
      "Train Epoch: 6 [101120/110534 (91%)]\tClassification Loss: 1.6874\r\n",
      "Train Epoch: 6 [101760/110534 (92%)]\tClassification Loss: 1.2808\r\n",
      "Train Epoch: 6 [102400/110534 (93%)]\tClassification Loss: 1.3520\r\n",
      "Train Epoch: 6 [103040/110534 (93%)]\tClassification Loss: 1.2807\r\n",
      "Train Epoch: 6 [103680/110534 (94%)]\tClassification Loss: 1.6918\r\n",
      "Train Epoch: 6 [104320/110534 (94%)]\tClassification Loss: 1.5577\r\n",
      "Train Epoch: 6 [104960/110534 (95%)]\tClassification Loss: 1.6263\r\n",
      "Train Epoch: 6 [105600/110534 (96%)]\tClassification Loss: 1.6145\r\n",
      "Train Epoch: 6 [106240/110534 (96%)]\tClassification Loss: 1.5997\r\n",
      "Train Epoch: 6 [106880/110534 (97%)]\tClassification Loss: 1.6870\r\n",
      "Train Epoch: 6 [107520/110534 (97%)]\tClassification Loss: 1.4924\r\n",
      "Train Epoch: 6 [108160/110534 (98%)]\tClassification Loss: 1.3739\r\n",
      "Train Epoch: 6 [108800/110534 (98%)]\tClassification Loss: 1.3693\r\n",
      "Train Epoch: 6 [109440/110534 (99%)]\tClassification Loss: 1.6844\r\n",
      "Train Epoch: 6 [110080/110534 (100%)]\tClassification Loss: 1.7844\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_final.pth.tar\r\n",
      "Train Epoch: 7 [0/110534 (0%)]\tClassification Loss: 1.8691\r\n",
      "\r\n",
      "Test set: Average loss: 1.4111, Accuracy: 23258/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 7 [640/110534 (1%)]\tClassification Loss: 1.4310\r\n",
      "Train Epoch: 7 [1280/110534 (1%)]\tClassification Loss: 1.2534\r\n",
      "Train Epoch: 7 [1920/110534 (2%)]\tClassification Loss: 1.7544\r\n",
      "Train Epoch: 7 [2560/110534 (2%)]\tClassification Loss: 1.5640\r\n",
      "Train Epoch: 7 [3200/110534 (3%)]\tClassification Loss: 1.5224\r\n",
      "Train Epoch: 7 [3840/110534 (3%)]\tClassification Loss: 1.7278\r\n",
      "Train Epoch: 7 [4480/110534 (4%)]\tClassification Loss: 1.4672\r\n",
      "Train Epoch: 7 [5120/110534 (5%)]\tClassification Loss: 1.7231\r\n",
      "Train Epoch: 7 [5760/110534 (5%)]\tClassification Loss: 1.5933\r\n",
      "Train Epoch: 7 [6400/110534 (6%)]\tClassification Loss: 1.6767\r\n",
      "Train Epoch: 7 [7040/110534 (6%)]\tClassification Loss: 1.4078\r\n",
      "Train Epoch: 7 [7680/110534 (7%)]\tClassification Loss: 1.5557\r\n",
      "Train Epoch: 7 [8320/110534 (8%)]\tClassification Loss: 1.7110\r\n",
      "Train Epoch: 7 [8960/110534 (8%)]\tClassification Loss: 1.4736\r\n",
      "Train Epoch: 7 [9600/110534 (9%)]\tClassification Loss: 1.5532\r\n",
      "Train Epoch: 7 [10240/110534 (9%)]\tClassification Loss: 1.2958\r\n",
      "Train Epoch: 7 [10880/110534 (10%)]\tClassification Loss: 1.4008\r\n",
      "Train Epoch: 7 [11520/110534 (10%)]\tClassification Loss: 1.6331\r\n",
      "Train Epoch: 7 [12160/110534 (11%)]\tClassification Loss: 1.2518\r\n",
      "Train Epoch: 7 [12800/110534 (12%)]\tClassification Loss: 1.5819\r\n",
      "Train Epoch: 7 [13440/110534 (12%)]\tClassification Loss: 1.8715\r\n",
      "Train Epoch: 7 [14080/110534 (13%)]\tClassification Loss: 1.3942\r\n",
      "Train Epoch: 7 [14720/110534 (13%)]\tClassification Loss: 1.2683\r\n",
      "Train Epoch: 7 [15360/110534 (14%)]\tClassification Loss: 1.2747\r\n",
      "Train Epoch: 7 [16000/110534 (14%)]\tClassification Loss: 1.5695\r\n",
      "Train Epoch: 7 [16640/110534 (15%)]\tClassification Loss: 1.3011\r\n",
      "Train Epoch: 7 [17280/110534 (16%)]\tClassification Loss: 1.6353\r\n",
      "Train Epoch: 7 [17920/110534 (16%)]\tClassification Loss: 1.7753\r\n",
      "Train Epoch: 7 [18560/110534 (17%)]\tClassification Loss: 1.5289\r\n",
      "Train Epoch: 7 [19200/110534 (17%)]\tClassification Loss: 1.4452\r\n",
      "Train Epoch: 7 [19840/110534 (18%)]\tClassification Loss: 1.3148\r\n",
      "Train Epoch: 7 [20480/110534 (19%)]\tClassification Loss: 1.1894\r\n",
      "Train Epoch: 7 [21120/110534 (19%)]\tClassification Loss: 1.4738\r\n",
      "Train Epoch: 7 [21760/110534 (20%)]\tClassification Loss: 1.5534\r\n",
      "Train Epoch: 7 [22400/110534 (20%)]\tClassification Loss: 1.6077\r\n",
      "Train Epoch: 7 [23040/110534 (21%)]\tClassification Loss: 1.4745\r\n",
      "Train Epoch: 7 [23680/110534 (21%)]\tClassification Loss: 1.3104\r\n",
      "Train Epoch: 7 [24320/110534 (22%)]\tClassification Loss: 1.6549\r\n",
      "Train Epoch: 7 [24960/110534 (23%)]\tClassification Loss: 1.4312\r\n",
      "Train Epoch: 7 [25600/110534 (23%)]\tClassification Loss: 1.4079\r\n",
      "Train Epoch: 7 [26240/110534 (24%)]\tClassification Loss: 1.8611\r\n",
      "Train Epoch: 7 [26880/110534 (24%)]\tClassification Loss: 1.5251\r\n",
      "Train Epoch: 7 [27520/110534 (25%)]\tClassification Loss: 1.5779\r\n",
      "Train Epoch: 7 [28160/110534 (25%)]\tClassification Loss: 1.3694\r\n",
      "Train Epoch: 7 [28800/110534 (26%)]\tClassification Loss: 1.4536\r\n",
      "Train Epoch: 7 [29440/110534 (27%)]\tClassification Loss: 1.3917\r\n",
      "Train Epoch: 7 [30080/110534 (27%)]\tClassification Loss: 1.6220\r\n",
      "Train Epoch: 7 [30720/110534 (28%)]\tClassification Loss: 1.4272\r\n",
      "Train Epoch: 7 [31360/110534 (28%)]\tClassification Loss: 1.3310\r\n",
      "Train Epoch: 7 [32000/110534 (29%)]\tClassification Loss: 1.3059\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_500.pth.tar\r\n",
      "Train Epoch: 7 [32640/110534 (30%)]\tClassification Loss: 1.9657\r\n",
      "Train Epoch: 7 [33280/110534 (30%)]\tClassification Loss: 1.4908\r\n",
      "Train Epoch: 7 [33920/110534 (31%)]\tClassification Loss: 1.4862\r\n",
      "Train Epoch: 7 [34560/110534 (31%)]\tClassification Loss: 1.5340\r\n",
      "Train Epoch: 7 [35200/110534 (32%)]\tClassification Loss: 1.4127\r\n",
      "Train Epoch: 7 [35840/110534 (32%)]\tClassification Loss: 1.6337\r\n",
      "Train Epoch: 7 [36480/110534 (33%)]\tClassification Loss: 1.5468\r\n",
      "Train Epoch: 7 [37120/110534 (34%)]\tClassification Loss: 1.1336\r\n",
      "Train Epoch: 7 [37760/110534 (34%)]\tClassification Loss: 1.5110\r\n",
      "Train Epoch: 7 [38400/110534 (35%)]\tClassification Loss: 1.4690\r\n",
      "Train Epoch: 7 [39040/110534 (35%)]\tClassification Loss: 1.1320\r\n",
      "Train Epoch: 7 [39680/110534 (36%)]\tClassification Loss: 1.5522\r\n",
      "Train Epoch: 7 [40320/110534 (36%)]\tClassification Loss: 1.5499\r\n",
      "Train Epoch: 7 [40960/110534 (37%)]\tClassification Loss: 1.7039\r\n",
      "Train Epoch: 7 [41600/110534 (38%)]\tClassification Loss: 1.4337\r\n",
      "Train Epoch: 7 [42240/110534 (38%)]\tClassification Loss: 1.6185\r\n",
      "Train Epoch: 7 [42880/110534 (39%)]\tClassification Loss: 1.6067\r\n",
      "Train Epoch: 7 [43520/110534 (39%)]\tClassification Loss: 1.6067\r\n",
      "Train Epoch: 7 [44160/110534 (40%)]\tClassification Loss: 1.5707\r\n",
      "Train Epoch: 7 [44800/110534 (41%)]\tClassification Loss: 1.3832\r\n",
      "Train Epoch: 7 [45440/110534 (41%)]\tClassification Loss: 1.4735\r\n",
      "Train Epoch: 7 [46080/110534 (42%)]\tClassification Loss: 1.5539\r\n",
      "Train Epoch: 7 [46720/110534 (42%)]\tClassification Loss: 1.2414\r\n",
      "Train Epoch: 7 [47360/110534 (43%)]\tClassification Loss: 1.5407\r\n",
      "Train Epoch: 7 [48000/110534 (43%)]\tClassification Loss: 1.4859\r\n",
      "Train Epoch: 7 [48640/110534 (44%)]\tClassification Loss: 1.6050\r\n",
      "Train Epoch: 7 [49280/110534 (45%)]\tClassification Loss: 1.6347\r\n",
      "Train Epoch: 7 [49920/110534 (45%)]\tClassification Loss: 1.1817\r\n",
      "Train Epoch: 7 [50560/110534 (46%)]\tClassification Loss: 1.5477\r\n",
      "Train Epoch: 7 [51200/110534 (46%)]\tClassification Loss: 1.1574\r\n",
      "Train Epoch: 7 [51840/110534 (47%)]\tClassification Loss: 1.4414\r\n",
      "Train Epoch: 7 [52480/110534 (47%)]\tClassification Loss: 1.3806\r\n",
      "Train Epoch: 7 [53120/110534 (48%)]\tClassification Loss: 1.7916\r\n",
      "Train Epoch: 7 [53760/110534 (49%)]\tClassification Loss: 1.5065\r\n",
      "Train Epoch: 7 [54400/110534 (49%)]\tClassification Loss: 1.6654\r\n",
      "Train Epoch: 7 [55040/110534 (50%)]\tClassification Loss: 1.6013\r\n",
      "Train Epoch: 7 [55680/110534 (50%)]\tClassification Loss: 2.0222\r\n",
      "Train Epoch: 7 [56320/110534 (51%)]\tClassification Loss: 1.4336\r\n",
      "Train Epoch: 7 [56960/110534 (52%)]\tClassification Loss: 1.4870\r\n",
      "Train Epoch: 7 [57600/110534 (52%)]\tClassification Loss: 1.7168\r\n",
      "Train Epoch: 7 [58240/110534 (53%)]\tClassification Loss: 1.4950\r\n",
      "Train Epoch: 7 [58880/110534 (53%)]\tClassification Loss: 1.0729\r\n",
      "Train Epoch: 7 [59520/110534 (54%)]\tClassification Loss: 1.4551\r\n",
      "Train Epoch: 7 [60160/110534 (54%)]\tClassification Loss: 1.2905\r\n",
      "Train Epoch: 7 [60800/110534 (55%)]\tClassification Loss: 1.5169\r\n",
      "Train Epoch: 7 [61440/110534 (56%)]\tClassification Loss: 1.5314\r\n",
      "Train Epoch: 7 [62080/110534 (56%)]\tClassification Loss: 1.5913\r\n",
      "Train Epoch: 7 [62720/110534 (57%)]\tClassification Loss: 1.5114\r\n",
      "Train Epoch: 7 [63360/110534 (57%)]\tClassification Loss: 1.4884\r\n",
      "Train Epoch: 7 [64000/110534 (58%)]\tClassification Loss: 1.4328\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_1000.pth.tar\r\n",
      "Train Epoch: 7 [64640/110534 (58%)]\tClassification Loss: 1.6333\r\n",
      "Train Epoch: 7 [65280/110534 (59%)]\tClassification Loss: 1.5021\r\n",
      "Train Epoch: 7 [65920/110534 (60%)]\tClassification Loss: 1.7509\r\n",
      "Train Epoch: 7 [66560/110534 (60%)]\tClassification Loss: 1.4560\r\n",
      "Train Epoch: 7 [67200/110534 (61%)]\tClassification Loss: 1.1684\r\n",
      "Train Epoch: 7 [67840/110534 (61%)]\tClassification Loss: 1.4464\r\n",
      "Train Epoch: 7 [68480/110534 (62%)]\tClassification Loss: 1.4999\r\n",
      "Train Epoch: 7 [69120/110534 (63%)]\tClassification Loss: 1.4532\r\n",
      "Train Epoch: 7 [69760/110534 (63%)]\tClassification Loss: 1.5036\r\n",
      "Train Epoch: 7 [70400/110534 (64%)]\tClassification Loss: 1.3583\r\n",
      "Train Epoch: 7 [71040/110534 (64%)]\tClassification Loss: 1.7399\r\n",
      "Train Epoch: 7 [71680/110534 (65%)]\tClassification Loss: 1.8787\r\n",
      "Train Epoch: 7 [72320/110534 (65%)]\tClassification Loss: 1.5428\r\n",
      "Train Epoch: 7 [72960/110534 (66%)]\tClassification Loss: 1.3936\r\n",
      "Train Epoch: 7 [73600/110534 (67%)]\tClassification Loss: 1.3776\r\n",
      "Train Epoch: 7 [74240/110534 (67%)]\tClassification Loss: 1.3587\r\n",
      "Train Epoch: 7 [74880/110534 (68%)]\tClassification Loss: 1.4848\r\n",
      "Train Epoch: 7 [75520/110534 (68%)]\tClassification Loss: 1.4764\r\n",
      "Train Epoch: 7 [76160/110534 (69%)]\tClassification Loss: 1.2536\r\n",
      "Train Epoch: 7 [76800/110534 (69%)]\tClassification Loss: 1.6795\r\n",
      "Train Epoch: 7 [77440/110534 (70%)]\tClassification Loss: 1.6630\r\n",
      "Train Epoch: 7 [78080/110534 (71%)]\tClassification Loss: 1.7554\r\n",
      "Train Epoch: 7 [78720/110534 (71%)]\tClassification Loss: 1.4614\r\n",
      "Train Epoch: 7 [79360/110534 (72%)]\tClassification Loss: 1.6329\r\n",
      "Train Epoch: 7 [80000/110534 (72%)]\tClassification Loss: 1.5445\r\n",
      "Train Epoch: 7 [80640/110534 (73%)]\tClassification Loss: 1.4712\r\n",
      "Train Epoch: 7 [81280/110534 (74%)]\tClassification Loss: 1.3480\r\n",
      "Train Epoch: 7 [81920/110534 (74%)]\tClassification Loss: 1.6672\r\n",
      "Train Epoch: 7 [82560/110534 (75%)]\tClassification Loss: 1.7750\r\n",
      "Train Epoch: 7 [83200/110534 (75%)]\tClassification Loss: 1.6205\r\n",
      "Train Epoch: 7 [83840/110534 (76%)]\tClassification Loss: 1.6220\r\n",
      "Train Epoch: 7 [84480/110534 (76%)]\tClassification Loss: 1.7019\r\n",
      "Train Epoch: 7 [85120/110534 (77%)]\tClassification Loss: 1.4315\r\n",
      "Train Epoch: 7 [85760/110534 (78%)]\tClassification Loss: 1.3819\r\n",
      "Train Epoch: 7 [86400/110534 (78%)]\tClassification Loss: 1.2780\r\n",
      "Train Epoch: 7 [87040/110534 (79%)]\tClassification Loss: 1.7908\r\n",
      "Train Epoch: 7 [87680/110534 (79%)]\tClassification Loss: 1.9058\r\n",
      "Train Epoch: 7 [88320/110534 (80%)]\tClassification Loss: 1.4423\r\n",
      "Train Epoch: 7 [88960/110534 (80%)]\tClassification Loss: 1.4651\r\n",
      "Train Epoch: 7 [89600/110534 (81%)]\tClassification Loss: 1.5122\r\n",
      "Train Epoch: 7 [90240/110534 (82%)]\tClassification Loss: 1.5629\r\n",
      "Train Epoch: 7 [90880/110534 (82%)]\tClassification Loss: 1.5284\r\n",
      "Train Epoch: 7 [91520/110534 (83%)]\tClassification Loss: 1.5597\r\n",
      "Train Epoch: 7 [92160/110534 (83%)]\tClassification Loss: 1.4530\r\n",
      "Train Epoch: 7 [92800/110534 (84%)]\tClassification Loss: 1.2221\r\n",
      "Train Epoch: 7 [93440/110534 (85%)]\tClassification Loss: 1.7146\r\n",
      "Train Epoch: 7 [94080/110534 (85%)]\tClassification Loss: 1.6531\r\n",
      "Train Epoch: 7 [94720/110534 (86%)]\tClassification Loss: 1.4133\r\n",
      "Train Epoch: 7 [95360/110534 (86%)]\tClassification Loss: 1.7289\r\n",
      "Train Epoch: 7 [96000/110534 (87%)]\tClassification Loss: 1.4516\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_1500.pth.tar\r\n",
      "Train Epoch: 7 [96640/110534 (87%)]\tClassification Loss: 1.5646\r\n",
      "Train Epoch: 7 [97280/110534 (88%)]\tClassification Loss: 1.5058\r\n",
      "Train Epoch: 7 [97920/110534 (89%)]\tClassification Loss: 1.6978\r\n",
      "Train Epoch: 7 [98560/110534 (89%)]\tClassification Loss: 1.5827\r\n",
      "Train Epoch: 7 [99200/110534 (90%)]\tClassification Loss: 1.2554\r\n",
      "Train Epoch: 7 [99840/110534 (90%)]\tClassification Loss: 1.5420\r\n",
      "Train Epoch: 7 [100480/110534 (91%)]\tClassification Loss: 1.3558\r\n",
      "Train Epoch: 7 [101120/110534 (91%)]\tClassification Loss: 1.5030\r\n",
      "Train Epoch: 7 [101760/110534 (92%)]\tClassification Loss: 1.3124\r\n",
      "Train Epoch: 7 [102400/110534 (93%)]\tClassification Loss: 1.4021\r\n",
      "Train Epoch: 7 [103040/110534 (93%)]\tClassification Loss: 1.4232\r\n",
      "Train Epoch: 7 [103680/110534 (94%)]\tClassification Loss: 1.6451\r\n",
      "Train Epoch: 7 [104320/110534 (94%)]\tClassification Loss: 1.6180\r\n",
      "Train Epoch: 7 [104960/110534 (95%)]\tClassification Loss: 1.6231\r\n",
      "Train Epoch: 7 [105600/110534 (96%)]\tClassification Loss: 1.4280\r\n",
      "Train Epoch: 7 [106240/110534 (96%)]\tClassification Loss: 1.5633\r\n",
      "Train Epoch: 7 [106880/110534 (97%)]\tClassification Loss: 1.6327\r\n",
      "Train Epoch: 7 [107520/110534 (97%)]\tClassification Loss: 1.5349\r\n",
      "Train Epoch: 7 [108160/110534 (98%)]\tClassification Loss: 1.4890\r\n",
      "Train Epoch: 7 [108800/110534 (98%)]\tClassification Loss: 1.3885\r\n",
      "Train Epoch: 7 [109440/110534 (99%)]\tClassification Loss: 1.5711\r\n",
      "Train Epoch: 7 [110080/110534 (100%)]\tClassification Loss: 1.6164\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_final.pth.tar\r\n",
      "Train Epoch: 8 [0/110534 (0%)]\tClassification Loss: 1.9252\r\n",
      "\r\n",
      "Test set: Average loss: 1.4124, Accuracy: 23248/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 8 [640/110534 (1%)]\tClassification Loss: 1.5337\r\n",
      "Train Epoch: 8 [1280/110534 (1%)]\tClassification Loss: 1.3864\r\n",
      "Train Epoch: 8 [1920/110534 (2%)]\tClassification Loss: 1.6798\r\n",
      "Train Epoch: 8 [2560/110534 (2%)]\tClassification Loss: 1.6181\r\n",
      "Train Epoch: 8 [3200/110534 (3%)]\tClassification Loss: 1.4922\r\n",
      "Train Epoch: 8 [3840/110534 (3%)]\tClassification Loss: 1.7774\r\n",
      "Train Epoch: 8 [4480/110534 (4%)]\tClassification Loss: 1.2993\r\n",
      "Train Epoch: 8 [5120/110534 (5%)]\tClassification Loss: 1.8203\r\n",
      "Train Epoch: 8 [5760/110534 (5%)]\tClassification Loss: 1.6189\r\n",
      "Train Epoch: 8 [6400/110534 (6%)]\tClassification Loss: 1.6954\r\n",
      "Train Epoch: 8 [7040/110534 (6%)]\tClassification Loss: 1.2604\r\n",
      "Train Epoch: 8 [7680/110534 (7%)]\tClassification Loss: 1.3529\r\n",
      "Train Epoch: 8 [8320/110534 (8%)]\tClassification Loss: 1.8024\r\n",
      "Train Epoch: 8 [8960/110534 (8%)]\tClassification Loss: 1.4072\r\n",
      "Train Epoch: 8 [9600/110534 (9%)]\tClassification Loss: 1.5450\r\n",
      "Train Epoch: 8 [10240/110534 (9%)]\tClassification Loss: 1.2782\r\n",
      "Train Epoch: 8 [10880/110534 (10%)]\tClassification Loss: 1.4414\r\n",
      "Train Epoch: 8 [11520/110534 (10%)]\tClassification Loss: 1.5887\r\n",
      "Train Epoch: 8 [12160/110534 (11%)]\tClassification Loss: 1.2394\r\n",
      "Train Epoch: 8 [12800/110534 (12%)]\tClassification Loss: 1.7819\r\n",
      "Train Epoch: 8 [13440/110534 (12%)]\tClassification Loss: 1.7589\r\n",
      "Train Epoch: 8 [14080/110534 (13%)]\tClassification Loss: 1.5288\r\n",
      "Train Epoch: 8 [14720/110534 (13%)]\tClassification Loss: 1.3680\r\n",
      "Train Epoch: 8 [15360/110534 (14%)]\tClassification Loss: 1.4954\r\n",
      "Train Epoch: 8 [16000/110534 (14%)]\tClassification Loss: 1.5663\r\n",
      "Train Epoch: 8 [16640/110534 (15%)]\tClassification Loss: 1.4470\r\n",
      "Train Epoch: 8 [17280/110534 (16%)]\tClassification Loss: 1.6006\r\n",
      "Train Epoch: 8 [17920/110534 (16%)]\tClassification Loss: 1.6772\r\n",
      "Train Epoch: 8 [18560/110534 (17%)]\tClassification Loss: 1.5137\r\n",
      "Train Epoch: 8 [19200/110534 (17%)]\tClassification Loss: 1.3290\r\n",
      "Train Epoch: 8 [19840/110534 (18%)]\tClassification Loss: 1.2780\r\n",
      "Train Epoch: 8 [20480/110534 (19%)]\tClassification Loss: 1.2676\r\n",
      "Train Epoch: 8 [21120/110534 (19%)]\tClassification Loss: 1.4880\r\n",
      "Train Epoch: 8 [21760/110534 (20%)]\tClassification Loss: 1.7309\r\n",
      "Train Epoch: 8 [22400/110534 (20%)]\tClassification Loss: 1.5465\r\n",
      "Train Epoch: 8 [23040/110534 (21%)]\tClassification Loss: 1.3953\r\n",
      "Train Epoch: 8 [23680/110534 (21%)]\tClassification Loss: 1.2781\r\n",
      "Train Epoch: 8 [24320/110534 (22%)]\tClassification Loss: 1.5628\r\n",
      "Train Epoch: 8 [24960/110534 (23%)]\tClassification Loss: 1.3112\r\n",
      "Train Epoch: 8 [25600/110534 (23%)]\tClassification Loss: 1.5542\r\n",
      "Train Epoch: 8 [26240/110534 (24%)]\tClassification Loss: 1.7220\r\n",
      "Train Epoch: 8 [26880/110534 (24%)]\tClassification Loss: 1.4076\r\n",
      "Train Epoch: 8 [27520/110534 (25%)]\tClassification Loss: 1.5784\r\n",
      "Train Epoch: 8 [28160/110534 (25%)]\tClassification Loss: 1.4676\r\n",
      "Train Epoch: 8 [28800/110534 (26%)]\tClassification Loss: 1.5579\r\n",
      "Train Epoch: 8 [29440/110534 (27%)]\tClassification Loss: 1.5240\r\n",
      "Train Epoch: 8 [30080/110534 (27%)]\tClassification Loss: 1.7044\r\n",
      "Train Epoch: 8 [30720/110534 (28%)]\tClassification Loss: 1.3101\r\n",
      "Train Epoch: 8 [31360/110534 (28%)]\tClassification Loss: 1.3624\r\n",
      "Train Epoch: 8 [32000/110534 (29%)]\tClassification Loss: 1.3467\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_500.pth.tar\r\n",
      "Train Epoch: 8 [32640/110534 (30%)]\tClassification Loss: 1.9312\r\n",
      "Train Epoch: 8 [33280/110534 (30%)]\tClassification Loss: 1.4867\r\n",
      "Train Epoch: 8 [33920/110534 (31%)]\tClassification Loss: 1.5209\r\n",
      "Train Epoch: 8 [34560/110534 (31%)]\tClassification Loss: 1.5219\r\n",
      "Train Epoch: 8 [35200/110534 (32%)]\tClassification Loss: 1.4628\r\n",
      "Train Epoch: 8 [35840/110534 (32%)]\tClassification Loss: 1.6687\r\n",
      "Train Epoch: 8 [36480/110534 (33%)]\tClassification Loss: 1.5603\r\n",
      "Train Epoch: 8 [37120/110534 (34%)]\tClassification Loss: 1.3504\r\n",
      "Train Epoch: 8 [37760/110534 (34%)]\tClassification Loss: 1.6152\r\n",
      "Train Epoch: 8 [38400/110534 (35%)]\tClassification Loss: 1.4222\r\n",
      "Train Epoch: 8 [39040/110534 (35%)]\tClassification Loss: 1.1430\r\n",
      "Train Epoch: 8 [39680/110534 (36%)]\tClassification Loss: 1.3911\r\n",
      "Train Epoch: 8 [40320/110534 (36%)]\tClassification Loss: 1.6951\r\n",
      "Train Epoch: 8 [40960/110534 (37%)]\tClassification Loss: 1.6196\r\n",
      "Train Epoch: 8 [41600/110534 (38%)]\tClassification Loss: 1.6169\r\n",
      "Train Epoch: 8 [42240/110534 (38%)]\tClassification Loss: 1.7919\r\n",
      "Train Epoch: 8 [42880/110534 (39%)]\tClassification Loss: 1.3993\r\n",
      "Train Epoch: 8 [43520/110534 (39%)]\tClassification Loss: 1.5887\r\n",
      "Train Epoch: 8 [44160/110534 (40%)]\tClassification Loss: 1.4619\r\n",
      "Train Epoch: 8 [44800/110534 (41%)]\tClassification Loss: 1.2948\r\n",
      "Train Epoch: 8 [45440/110534 (41%)]\tClassification Loss: 1.5518\r\n",
      "Train Epoch: 8 [46080/110534 (42%)]\tClassification Loss: 1.6035\r\n",
      "Train Epoch: 8 [46720/110534 (42%)]\tClassification Loss: 1.2742\r\n",
      "Train Epoch: 8 [47360/110534 (43%)]\tClassification Loss: 1.5101\r\n",
      "Train Epoch: 8 [48000/110534 (43%)]\tClassification Loss: 1.6114\r\n",
      "Train Epoch: 8 [48640/110534 (44%)]\tClassification Loss: 1.4872\r\n",
      "Train Epoch: 8 [49280/110534 (45%)]\tClassification Loss: 1.6628\r\n",
      "Train Epoch: 8 [49920/110534 (45%)]\tClassification Loss: 1.2423\r\n",
      "Train Epoch: 8 [50560/110534 (46%)]\tClassification Loss: 1.5449\r\n",
      "Train Epoch: 8 [51200/110534 (46%)]\tClassification Loss: 1.2097\r\n",
      "Train Epoch: 8 [51840/110534 (47%)]\tClassification Loss: 1.3837\r\n",
      "Train Epoch: 8 [52480/110534 (47%)]\tClassification Loss: 1.5637\r\n",
      "Train Epoch: 8 [53120/110534 (48%)]\tClassification Loss: 1.7258\r\n",
      "Train Epoch: 8 [53760/110534 (49%)]\tClassification Loss: 1.6250\r\n",
      "Train Epoch: 8 [54400/110534 (49%)]\tClassification Loss: 1.6416\r\n",
      "Train Epoch: 8 [55040/110534 (50%)]\tClassification Loss: 1.5179\r\n",
      "Train Epoch: 8 [55680/110534 (50%)]\tClassification Loss: 2.0212\r\n",
      "Train Epoch: 8 [56320/110534 (51%)]\tClassification Loss: 1.3814\r\n",
      "Train Epoch: 8 [56960/110534 (52%)]\tClassification Loss: 1.7461\r\n",
      "Train Epoch: 8 [57600/110534 (52%)]\tClassification Loss: 1.6810\r\n",
      "Train Epoch: 8 [58240/110534 (53%)]\tClassification Loss: 1.5430\r\n",
      "Train Epoch: 8 [58880/110534 (53%)]\tClassification Loss: 1.1412\r\n",
      "Train Epoch: 8 [59520/110534 (54%)]\tClassification Loss: 1.5209\r\n",
      "Train Epoch: 8 [60160/110534 (54%)]\tClassification Loss: 1.3656\r\n",
      "Train Epoch: 8 [60800/110534 (55%)]\tClassification Loss: 1.4058\r\n",
      "Train Epoch: 8 [61440/110534 (56%)]\tClassification Loss: 1.5201\r\n",
      "Train Epoch: 8 [62080/110534 (56%)]\tClassification Loss: 1.4628\r\n",
      "Train Epoch: 8 [62720/110534 (57%)]\tClassification Loss: 1.7317\r\n",
      "Train Epoch: 8 [63360/110534 (57%)]\tClassification Loss: 1.5287\r\n",
      "Train Epoch: 8 [64000/110534 (58%)]\tClassification Loss: 1.4341\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_1000.pth.tar\r\n",
      "Train Epoch: 8 [64640/110534 (58%)]\tClassification Loss: 1.5027\r\n",
      "Train Epoch: 8 [65280/110534 (59%)]\tClassification Loss: 1.4104\r\n",
      "Train Epoch: 8 [65920/110534 (60%)]\tClassification Loss: 1.6037\r\n",
      "Train Epoch: 8 [66560/110534 (60%)]\tClassification Loss: 1.4612\r\n",
      "Train Epoch: 8 [67200/110534 (61%)]\tClassification Loss: 1.3044\r\n",
      "Train Epoch: 8 [67840/110534 (61%)]\tClassification Loss: 1.5627\r\n",
      "Train Epoch: 8 [68480/110534 (62%)]\tClassification Loss: 1.5569\r\n",
      "Train Epoch: 8 [69120/110534 (63%)]\tClassification Loss: 1.3740\r\n",
      "Train Epoch: 8 [69760/110534 (63%)]\tClassification Loss: 1.7744\r\n",
      "Train Epoch: 8 [70400/110534 (64%)]\tClassification Loss: 1.5113\r\n",
      "Train Epoch: 8 [71040/110534 (64%)]\tClassification Loss: 1.7161\r\n",
      "Train Epoch: 8 [71680/110534 (65%)]\tClassification Loss: 1.8076\r\n",
      "Train Epoch: 8 [72320/110534 (65%)]\tClassification Loss: 1.5800\r\n",
      "Train Epoch: 8 [72960/110534 (66%)]\tClassification Loss: 1.4690\r\n",
      "Train Epoch: 8 [73600/110534 (67%)]\tClassification Loss: 1.5462\r\n",
      "Train Epoch: 8 [74240/110534 (67%)]\tClassification Loss: 1.2363\r\n",
      "Train Epoch: 8 [74880/110534 (68%)]\tClassification Loss: 1.5705\r\n",
      "Train Epoch: 8 [75520/110534 (68%)]\tClassification Loss: 1.4988\r\n",
      "Train Epoch: 8 [76160/110534 (69%)]\tClassification Loss: 1.2677\r\n",
      "Train Epoch: 8 [76800/110534 (69%)]\tClassification Loss: 1.5225\r\n",
      "Train Epoch: 8 [77440/110534 (70%)]\tClassification Loss: 1.5337\r\n",
      "Train Epoch: 8 [78080/110534 (71%)]\tClassification Loss: 1.6460\r\n",
      "Train Epoch: 8 [78720/110534 (71%)]\tClassification Loss: 1.5759\r\n",
      "Train Epoch: 8 [79360/110534 (72%)]\tClassification Loss: 1.7478\r\n",
      "Train Epoch: 8 [80000/110534 (72%)]\tClassification Loss: 1.7031\r\n",
      "Train Epoch: 8 [80640/110534 (73%)]\tClassification Loss: 1.4538\r\n",
      "Train Epoch: 8 [81280/110534 (74%)]\tClassification Loss: 1.3348\r\n",
      "Train Epoch: 8 [81920/110534 (74%)]\tClassification Loss: 1.7953\r\n",
      "Train Epoch: 8 [82560/110534 (75%)]\tClassification Loss: 1.7796\r\n",
      "Train Epoch: 8 [83200/110534 (75%)]\tClassification Loss: 1.6338\r\n",
      "Train Epoch: 8 [83840/110534 (76%)]\tClassification Loss: 1.6457\r\n",
      "Train Epoch: 8 [84480/110534 (76%)]\tClassification Loss: 1.4859\r\n",
      "Train Epoch: 8 [85120/110534 (77%)]\tClassification Loss: 1.4083\r\n",
      "Train Epoch: 8 [85760/110534 (78%)]\tClassification Loss: 1.4380\r\n",
      "Train Epoch: 8 [86400/110534 (78%)]\tClassification Loss: 1.2572\r\n",
      "Train Epoch: 8 [87040/110534 (79%)]\tClassification Loss: 1.6941\r\n",
      "Train Epoch: 8 [87680/110534 (79%)]\tClassification Loss: 1.8209\r\n",
      "Train Epoch: 8 [88320/110534 (80%)]\tClassification Loss: 1.3934\r\n",
      "Train Epoch: 8 [88960/110534 (80%)]\tClassification Loss: 1.3474\r\n",
      "Train Epoch: 8 [89600/110534 (81%)]\tClassification Loss: 1.5238\r\n",
      "Train Epoch: 8 [90240/110534 (82%)]\tClassification Loss: 1.5344\r\n",
      "Train Epoch: 8 [90880/110534 (82%)]\tClassification Loss: 1.6446\r\n",
      "Train Epoch: 8 [91520/110534 (83%)]\tClassification Loss: 1.6482\r\n",
      "Train Epoch: 8 [92160/110534 (83%)]\tClassification Loss: 1.2792\r\n",
      "Train Epoch: 8 [92800/110534 (84%)]\tClassification Loss: 1.2198\r\n",
      "Train Epoch: 8 [93440/110534 (85%)]\tClassification Loss: 1.6729\r\n",
      "Train Epoch: 8 [94080/110534 (85%)]\tClassification Loss: 1.4870\r\n",
      "Train Epoch: 8 [94720/110534 (86%)]\tClassification Loss: 1.4128\r\n",
      "Train Epoch: 8 [95360/110534 (86%)]\tClassification Loss: 1.5321\r\n",
      "Train Epoch: 8 [96000/110534 (87%)]\tClassification Loss: 1.5030\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_1500.pth.tar\r\n",
      "Train Epoch: 8 [96640/110534 (87%)]\tClassification Loss: 1.7112\r\n",
      "Train Epoch: 8 [97280/110534 (88%)]\tClassification Loss: 1.5754\r\n",
      "Train Epoch: 8 [97920/110534 (89%)]\tClassification Loss: 1.6625\r\n",
      "Train Epoch: 8 [98560/110534 (89%)]\tClassification Loss: 1.7384\r\n",
      "Train Epoch: 8 [99200/110534 (90%)]\tClassification Loss: 1.1886\r\n",
      "Train Epoch: 8 [99840/110534 (90%)]\tClassification Loss: 1.4498\r\n",
      "Train Epoch: 8 [100480/110534 (91%)]\tClassification Loss: 1.3295\r\n",
      "Train Epoch: 8 [101120/110534 (91%)]\tClassification Loss: 1.5376\r\n",
      "Train Epoch: 8 [101760/110534 (92%)]\tClassification Loss: 1.3125\r\n",
      "Train Epoch: 8 [102400/110534 (93%)]\tClassification Loss: 1.3265\r\n",
      "Train Epoch: 8 [103040/110534 (93%)]\tClassification Loss: 1.4893\r\n",
      "Train Epoch: 8 [103680/110534 (94%)]\tClassification Loss: 1.5360\r\n",
      "Train Epoch: 8 [104320/110534 (94%)]\tClassification Loss: 1.4198\r\n",
      "Train Epoch: 8 [104960/110534 (95%)]\tClassification Loss: 1.7559\r\n",
      "Train Epoch: 8 [105600/110534 (96%)]\tClassification Loss: 1.4742\r\n",
      "Train Epoch: 8 [106240/110534 (96%)]\tClassification Loss: 1.3885\r\n",
      "Train Epoch: 8 [106880/110534 (97%)]\tClassification Loss: 1.5783\r\n",
      "Train Epoch: 8 [107520/110534 (97%)]\tClassification Loss: 1.5122\r\n",
      "Train Epoch: 8 [108160/110534 (98%)]\tClassification Loss: 1.2300\r\n",
      "Train Epoch: 8 [108800/110534 (98%)]\tClassification Loss: 1.3070\r\n",
      "Train Epoch: 8 [109440/110534 (99%)]\tClassification Loss: 1.5277\r\n",
      "Train Epoch: 8 [110080/110534 (100%)]\tClassification Loss: 1.7697\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_final.pth.tar\r\n",
      "Train Epoch: 9 [0/110534 (0%)]\tClassification Loss: 1.8949\r\n",
      "\r\n",
      "Test set: Average loss: 1.4118, Accuracy: 23130/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 9 [640/110534 (1%)]\tClassification Loss: 1.5842\r\n",
      "Train Epoch: 9 [1280/110534 (1%)]\tClassification Loss: 1.4456\r\n",
      "Train Epoch: 9 [1920/110534 (2%)]\tClassification Loss: 1.5784\r\n",
      "Train Epoch: 9 [2560/110534 (2%)]\tClassification Loss: 1.5111\r\n",
      "Train Epoch: 9 [3200/110534 (3%)]\tClassification Loss: 1.3961\r\n",
      "Train Epoch: 9 [3840/110534 (3%)]\tClassification Loss: 1.9256\r\n",
      "Train Epoch: 9 [4480/110534 (4%)]\tClassification Loss: 1.5278\r\n",
      "Train Epoch: 9 [5120/110534 (5%)]\tClassification Loss: 1.5483\r\n",
      "Train Epoch: 9 [5760/110534 (5%)]\tClassification Loss: 1.5810\r\n",
      "Train Epoch: 9 [6400/110534 (6%)]\tClassification Loss: 1.7019\r\n",
      "Train Epoch: 9 [7040/110534 (6%)]\tClassification Loss: 1.3990\r\n",
      "Train Epoch: 9 [7680/110534 (7%)]\tClassification Loss: 1.5501\r\n",
      "Train Epoch: 9 [8320/110534 (8%)]\tClassification Loss: 1.8222\r\n",
      "Train Epoch: 9 [8960/110534 (8%)]\tClassification Loss: 1.5201\r\n",
      "Train Epoch: 9 [9600/110534 (9%)]\tClassification Loss: 1.5291\r\n",
      "Train Epoch: 9 [10240/110534 (9%)]\tClassification Loss: 1.4289\r\n",
      "Train Epoch: 9 [10880/110534 (10%)]\tClassification Loss: 1.3770\r\n",
      "Train Epoch: 9 [11520/110534 (10%)]\tClassification Loss: 1.4249\r\n",
      "Train Epoch: 9 [12160/110534 (11%)]\tClassification Loss: 1.2807\r\n",
      "Train Epoch: 9 [12800/110534 (12%)]\tClassification Loss: 1.7907\r\n",
      "Train Epoch: 9 [13440/110534 (12%)]\tClassification Loss: 1.5813\r\n",
      "Train Epoch: 9 [14080/110534 (13%)]\tClassification Loss: 1.3006\r\n",
      "Train Epoch: 9 [14720/110534 (13%)]\tClassification Loss: 1.2026\r\n",
      "Train Epoch: 9 [15360/110534 (14%)]\tClassification Loss: 1.2650\r\n",
      "Train Epoch: 9 [16000/110534 (14%)]\tClassification Loss: 1.8832\r\n",
      "Train Epoch: 9 [16640/110534 (15%)]\tClassification Loss: 1.5347\r\n",
      "Train Epoch: 9 [17280/110534 (16%)]\tClassification Loss: 1.6134\r\n",
      "Train Epoch: 9 [17920/110534 (16%)]\tClassification Loss: 1.6178\r\n",
      "Train Epoch: 9 [18560/110534 (17%)]\tClassification Loss: 1.4610\r\n",
      "Train Epoch: 9 [19200/110534 (17%)]\tClassification Loss: 1.4961\r\n",
      "Train Epoch: 9 [19840/110534 (18%)]\tClassification Loss: 1.2444\r\n",
      "Train Epoch: 9 [20480/110534 (19%)]\tClassification Loss: 1.2140\r\n",
      "Train Epoch: 9 [21120/110534 (19%)]\tClassification Loss: 1.4567\r\n",
      "Train Epoch: 9 [21760/110534 (20%)]\tClassification Loss: 1.6566\r\n",
      "Train Epoch: 9 [22400/110534 (20%)]\tClassification Loss: 1.5844\r\n",
      "Train Epoch: 9 [23040/110534 (21%)]\tClassification Loss: 1.4551\r\n",
      "Train Epoch: 9 [23680/110534 (21%)]\tClassification Loss: 1.4749\r\n",
      "Train Epoch: 9 [24320/110534 (22%)]\tClassification Loss: 1.6554\r\n",
      "Train Epoch: 9 [24960/110534 (23%)]\tClassification Loss: 1.4764\r\n",
      "Train Epoch: 9 [25600/110534 (23%)]\tClassification Loss: 1.5367\r\n",
      "Train Epoch: 9 [26240/110534 (24%)]\tClassification Loss: 1.7936\r\n",
      "Train Epoch: 9 [26880/110534 (24%)]\tClassification Loss: 1.4637\r\n",
      "Train Epoch: 9 [27520/110534 (25%)]\tClassification Loss: 1.7617\r\n",
      "Train Epoch: 9 [28160/110534 (25%)]\tClassification Loss: 1.4025\r\n",
      "Train Epoch: 9 [28800/110534 (26%)]\tClassification Loss: 1.5544\r\n",
      "Train Epoch: 9 [29440/110534 (27%)]\tClassification Loss: 1.4914\r\n",
      "Train Epoch: 9 [30080/110534 (27%)]\tClassification Loss: 1.7186\r\n",
      "Train Epoch: 9 [30720/110534 (28%)]\tClassification Loss: 1.3744\r\n",
      "Train Epoch: 9 [31360/110534 (28%)]\tClassification Loss: 1.4414\r\n",
      "Train Epoch: 9 [32000/110534 (29%)]\tClassification Loss: 1.5206\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_500.pth.tar\r\n",
      "Train Epoch: 9 [32640/110534 (30%)]\tClassification Loss: 1.8338\r\n",
      "Train Epoch: 9 [33280/110534 (30%)]\tClassification Loss: 1.5540\r\n",
      "Train Epoch: 9 [33920/110534 (31%)]\tClassification Loss: 1.4525\r\n",
      "Train Epoch: 9 [34560/110534 (31%)]\tClassification Loss: 1.5071\r\n",
      "Train Epoch: 9 [35200/110534 (32%)]\tClassification Loss: 1.2414\r\n",
      "Train Epoch: 9 [35840/110534 (32%)]\tClassification Loss: 1.6361\r\n",
      "Train Epoch: 9 [36480/110534 (33%)]\tClassification Loss: 1.4530\r\n",
      "Train Epoch: 9 [37120/110534 (34%)]\tClassification Loss: 1.2252\r\n",
      "Train Epoch: 9 [37760/110534 (34%)]\tClassification Loss: 1.5899\r\n",
      "Train Epoch: 9 [38400/110534 (35%)]\tClassification Loss: 1.4031\r\n",
      "Train Epoch: 9 [39040/110534 (35%)]\tClassification Loss: 1.2240\r\n",
      "Train Epoch: 9 [39680/110534 (36%)]\tClassification Loss: 1.5122\r\n",
      "Train Epoch: 9 [40320/110534 (36%)]\tClassification Loss: 1.7063\r\n",
      "Train Epoch: 9 [40960/110534 (37%)]\tClassification Loss: 1.6108\r\n",
      "Train Epoch: 9 [41600/110534 (38%)]\tClassification Loss: 1.5004\r\n",
      "Train Epoch: 9 [42240/110534 (38%)]\tClassification Loss: 1.5700\r\n",
      "Train Epoch: 9 [42880/110534 (39%)]\tClassification Loss: 1.3337\r\n",
      "Train Epoch: 9 [43520/110534 (39%)]\tClassification Loss: 1.5298\r\n",
      "Train Epoch: 9 [44160/110534 (40%)]\tClassification Loss: 1.5641\r\n",
      "Train Epoch: 9 [44800/110534 (41%)]\tClassification Loss: 1.3816\r\n",
      "Train Epoch: 9 [45440/110534 (41%)]\tClassification Loss: 1.5392\r\n",
      "Train Epoch: 9 [46080/110534 (42%)]\tClassification Loss: 1.6312\r\n",
      "Train Epoch: 9 [46720/110534 (42%)]\tClassification Loss: 1.2875\r\n",
      "Train Epoch: 9 [47360/110534 (43%)]\tClassification Loss: 1.5385\r\n",
      "Train Epoch: 9 [48000/110534 (43%)]\tClassification Loss: 1.5124\r\n",
      "Train Epoch: 9 [48640/110534 (44%)]\tClassification Loss: 1.5402\r\n",
      "Train Epoch: 9 [49280/110534 (45%)]\tClassification Loss: 1.6240\r\n",
      "Train Epoch: 9 [49920/110534 (45%)]\tClassification Loss: 1.3982\r\n",
      "Train Epoch: 9 [50560/110534 (46%)]\tClassification Loss: 1.4976\r\n",
      "Train Epoch: 9 [51200/110534 (46%)]\tClassification Loss: 1.1947\r\n",
      "Train Epoch: 9 [51840/110534 (47%)]\tClassification Loss: 1.4016\r\n",
      "Train Epoch: 9 [52480/110534 (47%)]\tClassification Loss: 1.5022\r\n",
      "Train Epoch: 9 [53120/110534 (48%)]\tClassification Loss: 1.7100\r\n",
      "Train Epoch: 9 [53760/110534 (49%)]\tClassification Loss: 1.5323\r\n",
      "Train Epoch: 9 [54400/110534 (49%)]\tClassification Loss: 1.5598\r\n",
      "Train Epoch: 9 [55040/110534 (50%)]\tClassification Loss: 1.7385\r\n",
      "Train Epoch: 9 [55680/110534 (50%)]\tClassification Loss: 1.8622\r\n",
      "Train Epoch: 9 [56320/110534 (51%)]\tClassification Loss: 1.3761\r\n",
      "Train Epoch: 9 [56960/110534 (52%)]\tClassification Loss: 1.5950\r\n",
      "Train Epoch: 9 [57600/110534 (52%)]\tClassification Loss: 1.6488\r\n",
      "Train Epoch: 9 [58240/110534 (53%)]\tClassification Loss: 1.4533\r\n",
      "Train Epoch: 9 [58880/110534 (53%)]\tClassification Loss: 1.3054\r\n",
      "Train Epoch: 9 [59520/110534 (54%)]\tClassification Loss: 1.5946\r\n",
      "Train Epoch: 9 [60160/110534 (54%)]\tClassification Loss: 1.3570\r\n",
      "Train Epoch: 9 [60800/110534 (55%)]\tClassification Loss: 1.4057\r\n",
      "Train Epoch: 9 [61440/110534 (56%)]\tClassification Loss: 1.5063\r\n",
      "Train Epoch: 9 [62080/110534 (56%)]\tClassification Loss: 1.4776\r\n",
      "Train Epoch: 9 [62720/110534 (57%)]\tClassification Loss: 1.7143\r\n",
      "Train Epoch: 9 [63360/110534 (57%)]\tClassification Loss: 1.4466\r\n",
      "Train Epoch: 9 [64000/110534 (58%)]\tClassification Loss: 1.4129\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_1000.pth.tar\r\n",
      "Train Epoch: 9 [64640/110534 (58%)]\tClassification Loss: 1.5297\r\n",
      "Train Epoch: 9 [65280/110534 (59%)]\tClassification Loss: 1.4607\r\n",
      "Train Epoch: 9 [65920/110534 (60%)]\tClassification Loss: 1.7443\r\n",
      "Train Epoch: 9 [66560/110534 (60%)]\tClassification Loss: 1.4544\r\n",
      "Train Epoch: 9 [67200/110534 (61%)]\tClassification Loss: 1.4178\r\n",
      "Train Epoch: 9 [67840/110534 (61%)]\tClassification Loss: 1.6584\r\n",
      "Train Epoch: 9 [68480/110534 (62%)]\tClassification Loss: 1.5743\r\n",
      "Train Epoch: 9 [69120/110534 (63%)]\tClassification Loss: 1.2195\r\n",
      "Train Epoch: 9 [69760/110534 (63%)]\tClassification Loss: 1.7197\r\n",
      "Train Epoch: 9 [70400/110534 (64%)]\tClassification Loss: 1.4729\r\n",
      "Train Epoch: 9 [71040/110534 (64%)]\tClassification Loss: 1.4938\r\n",
      "Train Epoch: 9 [71680/110534 (65%)]\tClassification Loss: 1.7836\r\n",
      "Train Epoch: 9 [72320/110534 (65%)]\tClassification Loss: 1.6012\r\n",
      "Train Epoch: 9 [72960/110534 (66%)]\tClassification Loss: 1.4495\r\n",
      "Train Epoch: 9 [73600/110534 (67%)]\tClassification Loss: 1.3263\r\n",
      "Train Epoch: 9 [74240/110534 (67%)]\tClassification Loss: 1.4660\r\n",
      "Train Epoch: 9 [74880/110534 (68%)]\tClassification Loss: 1.4460\r\n",
      "Train Epoch: 9 [75520/110534 (68%)]\tClassification Loss: 1.5641\r\n",
      "Train Epoch: 9 [76160/110534 (69%)]\tClassification Loss: 1.2314\r\n",
      "Train Epoch: 9 [76800/110534 (69%)]\tClassification Loss: 1.6360\r\n",
      "Train Epoch: 9 [77440/110534 (70%)]\tClassification Loss: 1.5658\r\n",
      "Train Epoch: 9 [78080/110534 (71%)]\tClassification Loss: 1.6757\r\n",
      "Train Epoch: 9 [78720/110534 (71%)]\tClassification Loss: 1.5316\r\n",
      "Train Epoch: 9 [79360/110534 (72%)]\tClassification Loss: 1.7170\r\n",
      "Train Epoch: 9 [80000/110534 (72%)]\tClassification Loss: 1.6127\r\n",
      "Train Epoch: 9 [80640/110534 (73%)]\tClassification Loss: 1.4108\r\n",
      "Train Epoch: 9 [81280/110534 (74%)]\tClassification Loss: 1.4872\r\n",
      "Train Epoch: 9 [81920/110534 (74%)]\tClassification Loss: 1.7260\r\n",
      "Train Epoch: 9 [82560/110534 (75%)]\tClassification Loss: 1.6717\r\n",
      "Train Epoch: 9 [83200/110534 (75%)]\tClassification Loss: 1.5636\r\n",
      "Train Epoch: 9 [83840/110534 (76%)]\tClassification Loss: 1.5054\r\n",
      "Train Epoch: 9 [84480/110534 (76%)]\tClassification Loss: 1.2894\r\n",
      "Train Epoch: 9 [85120/110534 (77%)]\tClassification Loss: 1.3554\r\n",
      "Train Epoch: 9 [85760/110534 (78%)]\tClassification Loss: 1.4618\r\n",
      "Train Epoch: 9 [86400/110534 (78%)]\tClassification Loss: 1.2932\r\n",
      "Train Epoch: 9 [87040/110534 (79%)]\tClassification Loss: 1.6057\r\n",
      "Train Epoch: 9 [87680/110534 (79%)]\tClassification Loss: 2.0192\r\n",
      "Train Epoch: 9 [88320/110534 (80%)]\tClassification Loss: 1.5142\r\n",
      "Train Epoch: 9 [88960/110534 (80%)]\tClassification Loss: 1.3288\r\n",
      "Train Epoch: 9 [89600/110534 (81%)]\tClassification Loss: 1.3906\r\n",
      "Train Epoch: 9 [90240/110534 (82%)]\tClassification Loss: 1.4914\r\n",
      "Train Epoch: 9 [90880/110534 (82%)]\tClassification Loss: 1.5060\r\n",
      "Train Epoch: 9 [91520/110534 (83%)]\tClassification Loss: 1.5500\r\n",
      "Train Epoch: 9 [92160/110534 (83%)]\tClassification Loss: 1.4143\r\n",
      "Train Epoch: 9 [92800/110534 (84%)]\tClassification Loss: 1.2640\r\n",
      "Train Epoch: 9 [93440/110534 (85%)]\tClassification Loss: 1.7230\r\n",
      "Train Epoch: 9 [94080/110534 (85%)]\tClassification Loss: 1.4299\r\n",
      "Train Epoch: 9 [94720/110534 (86%)]\tClassification Loss: 1.3126\r\n",
      "Train Epoch: 9 [95360/110534 (86%)]\tClassification Loss: 1.4368\r\n",
      "Train Epoch: 9 [96000/110534 (87%)]\tClassification Loss: 1.5438\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_1500.pth.tar\r\n",
      "Train Epoch: 9 [96640/110534 (87%)]\tClassification Loss: 1.5333\r\n",
      "Train Epoch: 9 [97280/110534 (88%)]\tClassification Loss: 1.5229\r\n",
      "Train Epoch: 9 [97920/110534 (89%)]\tClassification Loss: 1.9381\r\n",
      "Train Epoch: 9 [98560/110534 (89%)]\tClassification Loss: 1.6536\r\n",
      "Train Epoch: 9 [99200/110534 (90%)]\tClassification Loss: 1.0935\r\n",
      "Train Epoch: 9 [99840/110534 (90%)]\tClassification Loss: 1.6987\r\n",
      "Train Epoch: 9 [100480/110534 (91%)]\tClassification Loss: 1.4319\r\n",
      "Train Epoch: 9 [101120/110534 (91%)]\tClassification Loss: 1.5875\r\n",
      "Train Epoch: 9 [101760/110534 (92%)]\tClassification Loss: 1.2820\r\n",
      "Train Epoch: 9 [102400/110534 (93%)]\tClassification Loss: 1.2625\r\n",
      "Train Epoch: 9 [103040/110534 (93%)]\tClassification Loss: 1.3761\r\n",
      "Train Epoch: 9 [103680/110534 (94%)]\tClassification Loss: 1.4248\r\n",
      "Train Epoch: 9 [104320/110534 (94%)]\tClassification Loss: 1.4125\r\n",
      "Train Epoch: 9 [104960/110534 (95%)]\tClassification Loss: 1.7144\r\n",
      "Train Epoch: 9 [105600/110534 (96%)]\tClassification Loss: 1.2596\r\n",
      "Train Epoch: 9 [106240/110534 (96%)]\tClassification Loss: 1.4556\r\n",
      "Train Epoch: 9 [106880/110534 (97%)]\tClassification Loss: 1.5851\r\n",
      "Train Epoch: 9 [107520/110534 (97%)]\tClassification Loss: 1.5722\r\n",
      "Train Epoch: 9 [108160/110534 (98%)]\tClassification Loss: 1.3649\r\n",
      "Train Epoch: 9 [108800/110534 (98%)]\tClassification Loss: 1.4749\r\n",
      "Train Epoch: 9 [109440/110534 (99%)]\tClassification Loss: 1.5380\r\n",
      "Train Epoch: 9 [110080/110534 (100%)]\tClassification Loss: 1.6795\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_final.pth.tar\r\n",
      "Train Epoch: 10 [0/110534 (0%)]\tClassification Loss: 1.8978\r\n",
      "\r\n",
      "Test set: Average loss: 1.4090, Accuracy: 23170/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 10 [640/110534 (1%)]\tClassification Loss: 1.5049\r\n",
      "Train Epoch: 10 [1280/110534 (1%)]\tClassification Loss: 1.2897\r\n",
      "Train Epoch: 10 [1920/110534 (2%)]\tClassification Loss: 1.7713\r\n",
      "Train Epoch: 10 [2560/110534 (2%)]\tClassification Loss: 1.5072\r\n",
      "Train Epoch: 10 [3200/110534 (3%)]\tClassification Loss: 1.3908\r\n",
      "Train Epoch: 10 [3840/110534 (3%)]\tClassification Loss: 1.7946\r\n",
      "Train Epoch: 10 [4480/110534 (4%)]\tClassification Loss: 1.3302\r\n",
      "Train Epoch: 10 [5120/110534 (5%)]\tClassification Loss: 1.7706\r\n",
      "Train Epoch: 10 [5760/110534 (5%)]\tClassification Loss: 1.6249\r\n",
      "Train Epoch: 10 [6400/110534 (6%)]\tClassification Loss: 1.7088\r\n",
      "Train Epoch: 10 [7040/110534 (6%)]\tClassification Loss: 1.3456\r\n",
      "Train Epoch: 10 [7680/110534 (7%)]\tClassification Loss: 1.5230\r\n",
      "Train Epoch: 10 [8320/110534 (8%)]\tClassification Loss: 1.8772\r\n",
      "Train Epoch: 10 [8960/110534 (8%)]\tClassification Loss: 1.4338\r\n",
      "Train Epoch: 10 [9600/110534 (9%)]\tClassification Loss: 1.5641\r\n",
      "Train Epoch: 10 [10240/110534 (9%)]\tClassification Loss: 1.2808\r\n",
      "Train Epoch: 10 [10880/110534 (10%)]\tClassification Loss: 1.3769\r\n",
      "Train Epoch: 10 [11520/110534 (10%)]\tClassification Loss: 1.6469\r\n",
      "Train Epoch: 10 [12160/110534 (11%)]\tClassification Loss: 1.3557\r\n",
      "Train Epoch: 10 [12800/110534 (12%)]\tClassification Loss: 1.7706\r\n",
      "Train Epoch: 10 [13440/110534 (12%)]\tClassification Loss: 1.7848\r\n",
      "Train Epoch: 10 [14080/110534 (13%)]\tClassification Loss: 1.4363\r\n",
      "Train Epoch: 10 [14720/110534 (13%)]\tClassification Loss: 1.4396\r\n",
      "Train Epoch: 10 [15360/110534 (14%)]\tClassification Loss: 1.2608\r\n",
      "Train Epoch: 10 [16000/110534 (14%)]\tClassification Loss: 1.5576\r\n",
      "Train Epoch: 10 [16640/110534 (15%)]\tClassification Loss: 1.4274\r\n",
      "Train Epoch: 10 [17280/110534 (16%)]\tClassification Loss: 1.4897\r\n",
      "Train Epoch: 10 [17920/110534 (16%)]\tClassification Loss: 1.7935\r\n",
      "Train Epoch: 10 [18560/110534 (17%)]\tClassification Loss: 1.4582\r\n",
      "Train Epoch: 10 [19200/110534 (17%)]\tClassification Loss: 1.2812\r\n",
      "Train Epoch: 10 [19840/110534 (18%)]\tClassification Loss: 1.2940\r\n",
      "Train Epoch: 10 [20480/110534 (19%)]\tClassification Loss: 1.2746\r\n",
      "Train Epoch: 10 [21120/110534 (19%)]\tClassification Loss: 1.4922\r\n",
      "Train Epoch: 10 [21760/110534 (20%)]\tClassification Loss: 1.6155\r\n",
      "Train Epoch: 10 [22400/110534 (20%)]\tClassification Loss: 1.5035\r\n",
      "Train Epoch: 10 [23040/110534 (21%)]\tClassification Loss: 1.4460\r\n",
      "Train Epoch: 10 [23680/110534 (21%)]\tClassification Loss: 1.3511\r\n",
      "Train Epoch: 10 [24320/110534 (22%)]\tClassification Loss: 1.4383\r\n",
      "Train Epoch: 10 [24960/110534 (23%)]\tClassification Loss: 1.3578\r\n",
      "Train Epoch: 10 [25600/110534 (23%)]\tClassification Loss: 1.3962\r\n",
      "Train Epoch: 10 [26240/110534 (24%)]\tClassification Loss: 1.7449\r\n",
      "Train Epoch: 10 [26880/110534 (24%)]\tClassification Loss: 1.3610\r\n",
      "Train Epoch: 10 [27520/110534 (25%)]\tClassification Loss: 1.8498\r\n",
      "Train Epoch: 10 [28160/110534 (25%)]\tClassification Loss: 1.3882\r\n",
      "Train Epoch: 10 [28800/110534 (26%)]\tClassification Loss: 1.3857\r\n",
      "Train Epoch: 10 [29440/110534 (27%)]\tClassification Loss: 1.4821\r\n",
      "Train Epoch: 10 [30080/110534 (27%)]\tClassification Loss: 1.6441\r\n",
      "Train Epoch: 10 [30720/110534 (28%)]\tClassification Loss: 1.4898\r\n",
      "Train Epoch: 10 [31360/110534 (28%)]\tClassification Loss: 1.1966\r\n",
      "Train Epoch: 10 [32000/110534 (29%)]\tClassification Loss: 1.4237\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_500.pth.tar\r\n",
      "Train Epoch: 10 [32640/110534 (30%)]\tClassification Loss: 1.8687\r\n",
      "Train Epoch: 10 [33280/110534 (30%)]\tClassification Loss: 1.5374\r\n",
      "Train Epoch: 10 [33920/110534 (31%)]\tClassification Loss: 1.4950\r\n",
      "Train Epoch: 10 [34560/110534 (31%)]\tClassification Loss: 1.4992\r\n",
      "Train Epoch: 10 [35200/110534 (32%)]\tClassification Loss: 1.4770\r\n",
      "Train Epoch: 10 [35840/110534 (32%)]\tClassification Loss: 1.7163\r\n",
      "Train Epoch: 10 [36480/110534 (33%)]\tClassification Loss: 1.4814\r\n",
      "Train Epoch: 10 [37120/110534 (34%)]\tClassification Loss: 1.2335\r\n",
      "Train Epoch: 10 [37760/110534 (34%)]\tClassification Loss: 1.5156\r\n",
      "Train Epoch: 10 [38400/110534 (35%)]\tClassification Loss: 1.4727\r\n",
      "Train Epoch: 10 [39040/110534 (35%)]\tClassification Loss: 1.1402\r\n",
      "Train Epoch: 10 [39680/110534 (36%)]\tClassification Loss: 1.4920\r\n",
      "Train Epoch: 10 [40320/110534 (36%)]\tClassification Loss: 1.6034\r\n",
      "Train Epoch: 10 [40960/110534 (37%)]\tClassification Loss: 1.6683\r\n",
      "Train Epoch: 10 [41600/110534 (38%)]\tClassification Loss: 1.6426\r\n",
      "Train Epoch: 10 [42240/110534 (38%)]\tClassification Loss: 1.7662\r\n",
      "Train Epoch: 10 [42880/110534 (39%)]\tClassification Loss: 1.5223\r\n",
      "Train Epoch: 10 [43520/110534 (39%)]\tClassification Loss: 1.4827\r\n",
      "Train Epoch: 10 [44160/110534 (40%)]\tClassification Loss: 1.4842\r\n",
      "Train Epoch: 10 [44800/110534 (41%)]\tClassification Loss: 1.2793\r\n",
      "Train Epoch: 10 [45440/110534 (41%)]\tClassification Loss: 1.3762\r\n",
      "Train Epoch: 10 [46080/110534 (42%)]\tClassification Loss: 1.6426\r\n",
      "Train Epoch: 10 [46720/110534 (42%)]\tClassification Loss: 1.3931\r\n",
      "Train Epoch: 10 [47360/110534 (43%)]\tClassification Loss: 1.5162\r\n",
      "Train Epoch: 10 [48000/110534 (43%)]\tClassification Loss: 1.4404\r\n",
      "Train Epoch: 10 [48640/110534 (44%)]\tClassification Loss: 1.6460\r\n",
      "Train Epoch: 10 [49280/110534 (45%)]\tClassification Loss: 1.5432\r\n",
      "Train Epoch: 10 [49920/110534 (45%)]\tClassification Loss: 1.2275\r\n",
      "Train Epoch: 10 [50560/110534 (46%)]\tClassification Loss: 1.5608\r\n",
      "Train Epoch: 10 [51200/110534 (46%)]\tClassification Loss: 1.2668\r\n",
      "Train Epoch: 10 [51840/110534 (47%)]\tClassification Loss: 1.3061\r\n",
      "Train Epoch: 10 [52480/110534 (47%)]\tClassification Loss: 1.5755\r\n",
      "Train Epoch: 10 [53120/110534 (48%)]\tClassification Loss: 1.8992\r\n",
      "Train Epoch: 10 [53760/110534 (49%)]\tClassification Loss: 1.4918\r\n",
      "Train Epoch: 10 [54400/110534 (49%)]\tClassification Loss: 1.6609\r\n",
      "Train Epoch: 10 [55040/110534 (50%)]\tClassification Loss: 1.7168\r\n",
      "Train Epoch: 10 [55680/110534 (50%)]\tClassification Loss: 1.8533\r\n",
      "Train Epoch: 10 [56320/110534 (51%)]\tClassification Loss: 1.4042\r\n",
      "Train Epoch: 10 [56960/110534 (52%)]\tClassification Loss: 1.5351\r\n",
      "Train Epoch: 10 [57600/110534 (52%)]\tClassification Loss: 1.8482\r\n",
      "Train Epoch: 10 [58240/110534 (53%)]\tClassification Loss: 1.4571\r\n",
      "Train Epoch: 10 [58880/110534 (53%)]\tClassification Loss: 1.1865\r\n",
      "Train Epoch: 10 [59520/110534 (54%)]\tClassification Loss: 1.5250\r\n",
      "Train Epoch: 10 [60160/110534 (54%)]\tClassification Loss: 1.2989\r\n",
      "Train Epoch: 10 [60800/110534 (55%)]\tClassification Loss: 1.5741\r\n",
      "Train Epoch: 10 [61440/110534 (56%)]\tClassification Loss: 1.4945\r\n",
      "Train Epoch: 10 [62080/110534 (56%)]\tClassification Loss: 1.5147\r\n",
      "Train Epoch: 10 [62720/110534 (57%)]\tClassification Loss: 1.6000\r\n",
      "Train Epoch: 10 [63360/110534 (57%)]\tClassification Loss: 1.4310\r\n",
      "Train Epoch: 10 [64000/110534 (58%)]\tClassification Loss: 1.3331\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_1000.pth.tar\r\n",
      "Train Epoch: 10 [64640/110534 (58%)]\tClassification Loss: 1.7097\r\n",
      "Train Epoch: 10 [65280/110534 (59%)]\tClassification Loss: 1.4228\r\n",
      "Train Epoch: 10 [65920/110534 (60%)]\tClassification Loss: 1.6080\r\n",
      "Train Epoch: 10 [66560/110534 (60%)]\tClassification Loss: 1.2741\r\n",
      "Train Epoch: 10 [67200/110534 (61%)]\tClassification Loss: 1.3418\r\n",
      "Train Epoch: 10 [67840/110534 (61%)]\tClassification Loss: 1.5499\r\n",
      "Train Epoch: 10 [68480/110534 (62%)]\tClassification Loss: 1.4570\r\n",
      "Train Epoch: 10 [69120/110534 (63%)]\tClassification Loss: 1.2330\r\n",
      "Train Epoch: 10 [69760/110534 (63%)]\tClassification Loss: 1.5585\r\n",
      "Train Epoch: 10 [70400/110534 (64%)]\tClassification Loss: 1.3601\r\n",
      "Train Epoch: 10 [71040/110534 (64%)]\tClassification Loss: 1.5805\r\n",
      "Train Epoch: 10 [71680/110534 (65%)]\tClassification Loss: 1.8255\r\n",
      "Train Epoch: 10 [72320/110534 (65%)]\tClassification Loss: 1.7556\r\n",
      "Train Epoch: 10 [72960/110534 (66%)]\tClassification Loss: 1.4838\r\n",
      "Train Epoch: 10 [73600/110534 (67%)]\tClassification Loss: 1.4558\r\n",
      "Train Epoch: 10 [74240/110534 (67%)]\tClassification Loss: 1.4480\r\n",
      "Train Epoch: 10 [74880/110534 (68%)]\tClassification Loss: 1.4332\r\n",
      "Train Epoch: 10 [75520/110534 (68%)]\tClassification Loss: 1.5271\r\n",
      "Train Epoch: 10 [76160/110534 (69%)]\tClassification Loss: 1.3638\r\n",
      "Train Epoch: 10 [76800/110534 (69%)]\tClassification Loss: 1.6486\r\n",
      "Train Epoch: 10 [77440/110534 (70%)]\tClassification Loss: 1.7464\r\n",
      "Train Epoch: 10 [78080/110534 (71%)]\tClassification Loss: 1.6442\r\n",
      "Train Epoch: 10 [78720/110534 (71%)]\tClassification Loss: 1.6799\r\n",
      "Train Epoch: 10 [79360/110534 (72%)]\tClassification Loss: 1.4828\r\n",
      "Train Epoch: 10 [80000/110534 (72%)]\tClassification Loss: 1.5539\r\n",
      "Train Epoch: 10 [80640/110534 (73%)]\tClassification Loss: 1.3339\r\n",
      "Train Epoch: 10 [81280/110534 (74%)]\tClassification Loss: 1.2453\r\n",
      "Train Epoch: 10 [81920/110534 (74%)]\tClassification Loss: 1.7118\r\n",
      "Train Epoch: 10 [82560/110534 (75%)]\tClassification Loss: 1.8690\r\n",
      "Train Epoch: 10 [83200/110534 (75%)]\tClassification Loss: 1.6793\r\n",
      "Train Epoch: 10 [83840/110534 (76%)]\tClassification Loss: 1.5380\r\n",
      "Train Epoch: 10 [84480/110534 (76%)]\tClassification Loss: 1.4368\r\n",
      "Train Epoch: 10 [85120/110534 (77%)]\tClassification Loss: 1.4629\r\n",
      "Train Epoch: 10 [85760/110534 (78%)]\tClassification Loss: 1.3550\r\n",
      "Train Epoch: 10 [86400/110534 (78%)]\tClassification Loss: 1.3622\r\n",
      "Train Epoch: 10 [87040/110534 (79%)]\tClassification Loss: 1.6721\r\n",
      "Train Epoch: 10 [87680/110534 (79%)]\tClassification Loss: 1.9012\r\n",
      "Train Epoch: 10 [88320/110534 (80%)]\tClassification Loss: 1.3806\r\n",
      "Train Epoch: 10 [88960/110534 (80%)]\tClassification Loss: 1.2947\r\n",
      "Train Epoch: 10 [89600/110534 (81%)]\tClassification Loss: 1.4406\r\n",
      "Train Epoch: 10 [90240/110534 (82%)]\tClassification Loss: 1.5959\r\n",
      "Train Epoch: 10 [90880/110534 (82%)]\tClassification Loss: 1.5984\r\n",
      "Train Epoch: 10 [91520/110534 (83%)]\tClassification Loss: 1.6083\r\n",
      "Train Epoch: 10 [92160/110534 (83%)]\tClassification Loss: 1.2204\r\n",
      "Train Epoch: 10 [92800/110534 (84%)]\tClassification Loss: 1.3594\r\n",
      "Train Epoch: 10 [93440/110534 (85%)]\tClassification Loss: 1.5811\r\n",
      "Train Epoch: 10 [94080/110534 (85%)]\tClassification Loss: 1.3916\r\n",
      "Train Epoch: 10 [94720/110534 (86%)]\tClassification Loss: 1.4700\r\n",
      "Train Epoch: 10 [95360/110534 (86%)]\tClassification Loss: 1.6742\r\n",
      "Train Epoch: 10 [96000/110534 (87%)]\tClassification Loss: 1.5281\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_1500.pth.tar\r\n",
      "Train Epoch: 10 [96640/110534 (87%)]\tClassification Loss: 1.7407\r\n",
      "Train Epoch: 10 [97280/110534 (88%)]\tClassification Loss: 1.5236\r\n",
      "Train Epoch: 10 [97920/110534 (89%)]\tClassification Loss: 1.8357\r\n",
      "Train Epoch: 10 [98560/110534 (89%)]\tClassification Loss: 1.6625\r\n",
      "Train Epoch: 10 [99200/110534 (90%)]\tClassification Loss: 1.2792\r\n",
      "Train Epoch: 10 [99840/110534 (90%)]\tClassification Loss: 1.5631\r\n",
      "Train Epoch: 10 [100480/110534 (91%)]\tClassification Loss: 1.3823\r\n",
      "Train Epoch: 10 [101120/110534 (91%)]\tClassification Loss: 1.5819\r\n",
      "Train Epoch: 10 [101760/110534 (92%)]\tClassification Loss: 1.2302\r\n",
      "Train Epoch: 10 [102400/110534 (93%)]\tClassification Loss: 1.2910\r\n",
      "Train Epoch: 10 [103040/110534 (93%)]\tClassification Loss: 1.3368\r\n",
      "Train Epoch: 10 [103680/110534 (94%)]\tClassification Loss: 1.5193\r\n",
      "Train Epoch: 10 [104320/110534 (94%)]\tClassification Loss: 1.4933\r\n",
      "Train Epoch: 10 [104960/110534 (95%)]\tClassification Loss: 1.5924\r\n",
      "Train Epoch: 10 [105600/110534 (96%)]\tClassification Loss: 1.4286\r\n",
      "Train Epoch: 10 [106240/110534 (96%)]\tClassification Loss: 1.4203\r\n",
      "Train Epoch: 10 [106880/110534 (97%)]\tClassification Loss: 1.6156\r\n",
      "Train Epoch: 10 [107520/110534 (97%)]\tClassification Loss: 1.6795\r\n",
      "Train Epoch: 10 [108160/110534 (98%)]\tClassification Loss: 1.5003\r\n",
      "Train Epoch: 10 [108800/110534 (98%)]\tClassification Loss: 1.3809\r\n",
      "Train Epoch: 10 [109440/110534 (99%)]\tClassification Loss: 1.6185\r\n",
      "Train Epoch: 10 [110080/110534 (100%)]\tClassification Loss: 1.6824\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_final.pth.tar\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g5b-KDF5GUd7",
    "colab_type": "code",
    "outputId": "40ecd8a2-32bd-46e0-bb17-ff2429062648",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1584699253819,
     "user_tz": -300,
     "elapsed": 64469,
     "user": {
      "displayName": "Muhammad Ali",
      "photoUrl": "",
      "userId": "15673831022739340207"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# From scratch. Freeze=True (2). LR=0.01\n",
    "# model_5_500.pth.tar trained for 4.16 epochs. Stable at 58% accuracy and loss around 1.6 but loss was still going down slightly\n",
    "! python train.py"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:220: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:704: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  \"please use transforms.RandomResizedCrop instead.\")\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
      "100% 97.8M/97.8M [00:00<00:00, 168MB/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "train.py:132: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "\n",
      "Test set: Average loss: 3.4765, Accuracy: 45/960 (5%)\n",
      "\n",
      "Train Epoch: 1 [0/110534 (0%)]\tAll Loss: 4.3483\tTriple Loss(1): 0.5163\tClassification Loss: 3.3158\n",
      "Train Epoch: 1 [320/110534 (0%)]\tAll Loss: 4.3431\tTriple Loss(1): 0.6884\tClassification Loss: 2.9662\n",
      "Train Epoch: 1 [640/110534 (1%)]\tAll Loss: 5.8130\tTriple Loss(0): 1.5165\tClassification Loss: 2.7800\n",
      "Train Epoch: 1 [960/110534 (1%)]\tAll Loss: 3.2336\tTriple Loss(1): 0.2471\tClassification Loss: 2.7393\n",
      "Train Epoch: 1 [1280/110534 (1%)]\tAll Loss: 2.7347\tTriple Loss(0): 0.0000\tClassification Loss: 2.7347\n",
      "Train Epoch: 1 [1600/110534 (1%)]\tAll Loss: 2.5127\tTriple Loss(0): 0.0000\tClassification Loss: 2.5127\n",
      "Train Epoch: 1 [1920/110534 (2%)]\tAll Loss: 3.7189\tTriple Loss(1): 0.5633\tClassification Loss: 2.5924\n",
      "Train Epoch: 1 [2240/110534 (2%)]\tAll Loss: 3.3676\tTriple Loss(1): 0.4493\tClassification Loss: 2.4691\n",
      "Train Epoch: 1 [2560/110534 (2%)]\tAll Loss: 3.1038\tTriple Loss(1): 0.3192\tClassification Loss: 2.4655\n",
      "Train Epoch: 1 [2880/110534 (3%)]\tAll Loss: 2.9974\tTriple Loss(1): 0.2652\tClassification Loss: 2.4670\n",
      "\n",
      "Test set: Average loss: 2.5878, Accuracy: 239/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [3200/110534 (3%)]\tAll Loss: 3.7002\tTriple Loss(1): 0.5625\tClassification Loss: 2.5753\n",
      "Train Epoch: 1 [3520/110534 (3%)]\tAll Loss: 2.1138\tTriple Loss(0): 0.0000\tClassification Loss: 2.1138\n",
      "Train Epoch: 1 [3840/110534 (3%)]\tAll Loss: 3.3530\tTriple Loss(1): 0.4862\tClassification Loss: 2.3806\n",
      "Train Epoch: 1 [4160/110534 (4%)]\tAll Loss: 3.3885\tTriple Loss(1): 0.4694\tClassification Loss: 2.4498\n",
      "Train Epoch: 1 [4480/110534 (4%)]\tAll Loss: 3.1319\tTriple Loss(1): 0.3365\tClassification Loss: 2.4590\n",
      "Train Epoch: 1 [4800/110534 (4%)]\tAll Loss: 3.2836\tTriple Loss(1): 0.4319\tClassification Loss: 2.4199\n",
      "Train Epoch: 1 [5120/110534 (5%)]\tAll Loss: 3.4411\tTriple Loss(1): 0.5314\tClassification Loss: 2.3783\n",
      "Train Epoch: 1 [5440/110534 (5%)]\tAll Loss: 2.4496\tTriple Loss(0): 0.0000\tClassification Loss: 2.4496\n",
      "Train Epoch: 1 [5760/110534 (5%)]\tAll Loss: 3.2715\tTriple Loss(1): 0.5521\tClassification Loss: 2.1672\n",
      "Train Epoch: 1 [6080/110534 (5%)]\tAll Loss: 3.2655\tTriple Loss(1): 0.4961\tClassification Loss: 2.2734\n",
      "\n",
      "Test set: Average loss: 2.4070, Accuracy: 293/960 (31%)\n",
      "\n",
      "Train Epoch: 1 [6400/110534 (6%)]\tAll Loss: 3.4184\tTriple Loss(1): 0.4781\tClassification Loss: 2.4621\n",
      "Train Epoch: 1 [6720/110534 (6%)]\tAll Loss: 3.3485\tTriple Loss(1): 0.4487\tClassification Loss: 2.4512\n",
      "Train Epoch: 1 [7040/110534 (6%)]\tAll Loss: 3.9483\tTriple Loss(1): 0.7355\tClassification Loss: 2.4773\n",
      "Train Epoch: 1 [7360/110534 (7%)]\tAll Loss: 2.8470\tTriple Loss(1): 0.4186\tClassification Loss: 2.0097\n",
      "Train Epoch: 1 [7680/110534 (7%)]\tAll Loss: 3.0134\tTriple Loss(1): 0.4657\tClassification Loss: 2.0820\n",
      "Train Epoch: 1 [8000/110534 (7%)]\tAll Loss: 1.9897\tTriple Loss(0): 0.0000\tClassification Loss: 1.9897\n",
      "Train Epoch: 1 [8320/110534 (8%)]\tAll Loss: 2.1861\tTriple Loss(0): 0.0000\tClassification Loss: 2.1861\n",
      "Train Epoch: 1 [8640/110534 (8%)]\tAll Loss: 2.0087\tTriple Loss(0): 0.0000\tClassification Loss: 2.0087\n",
      "Train Epoch: 1 [8960/110534 (8%)]\tAll Loss: 2.9460\tTriple Loss(1): 0.4324\tClassification Loss: 2.0813\n",
      "Train Epoch: 1 [9280/110534 (8%)]\tAll Loss: 3.2819\tTriple Loss(1): 0.6515\tClassification Loss: 1.9788\n",
      "\n",
      "Test set: Average loss: 2.2947, Accuracy: 356/960 (37%)\n",
      "\n",
      "Train Epoch: 1 [9600/110534 (9%)]\tAll Loss: 2.3249\tTriple Loss(0): 0.0000\tClassification Loss: 2.3249\n",
      "Train Epoch: 1 [9920/110534 (9%)]\tAll Loss: 2.9201\tTriple Loss(1): 0.3725\tClassification Loss: 2.1750\n",
      "Train Epoch: 1 [10240/110534 (9%)]\tAll Loss: 2.2955\tTriple Loss(0): 0.0000\tClassification Loss: 2.2955\n",
      "Train Epoch: 1 [10560/110534 (10%)]\tAll Loss: 4.7827\tTriple Loss(0): 1.2674\tClassification Loss: 2.2480\n",
      "Train Epoch: 1 [10880/110534 (10%)]\tAll Loss: 2.4254\tTriple Loss(0): 0.0000\tClassification Loss: 2.4254\n",
      "Train Epoch: 1 [11200/110534 (10%)]\tAll Loss: 2.4969\tTriple Loss(1): 0.3294\tClassification Loss: 1.8382\n",
      "Train Epoch: 1 [11520/110534 (10%)]\tAll Loss: 2.8650\tTriple Loss(1): 0.3630\tClassification Loss: 2.1389\n",
      "Train Epoch: 1 [11840/110534 (11%)]\tAll Loss: 2.5245\tTriple Loss(1): 0.2584\tClassification Loss: 2.0077\n",
      "Train Epoch: 1 [12160/110534 (11%)]\tAll Loss: 2.3520\tTriple Loss(0): 0.0000\tClassification Loss: 2.3520\n",
      "Train Epoch: 1 [12480/110534 (11%)]\tAll Loss: 2.9566\tTriple Loss(1): 0.4006\tClassification Loss: 2.1554\n",
      "\n",
      "Test set: Average loss: 2.2093, Accuracy: 353/960 (37%)\n",
      "\n",
      "Train Epoch: 1 [12800/110534 (12%)]\tAll Loss: 2.8315\tTriple Loss(1): 0.3449\tClassification Loss: 2.1417\n",
      "Train Epoch: 1 [13120/110534 (12%)]\tAll Loss: 2.6978\tTriple Loss(1): 0.4072\tClassification Loss: 1.8835\n",
      "Train Epoch: 1 [13440/110534 (12%)]\tAll Loss: 3.2743\tTriple Loss(1): 0.4901\tClassification Loss: 2.2942\n",
      "Train Epoch: 1 [13760/110534 (12%)]\tAll Loss: 2.9040\tTriple Loss(1): 0.3723\tClassification Loss: 2.1593\n",
      "Train Epoch: 1 [14080/110534 (13%)]\tAll Loss: 2.4449\tTriple Loss(1): 0.1961\tClassification Loss: 2.0528\n",
      "Train Epoch: 1 [14400/110534 (13%)]\tAll Loss: 3.0787\tTriple Loss(1): 0.3534\tClassification Loss: 2.3719\n",
      "Train Epoch: 1 [14720/110534 (13%)]\tAll Loss: 2.5468\tTriple Loss(1): 0.1878\tClassification Loss: 2.1712\n",
      "Train Epoch: 1 [15040/110534 (14%)]\tAll Loss: 2.8062\tTriple Loss(1): 0.4043\tClassification Loss: 1.9977\n",
      "Train Epoch: 1 [15360/110534 (14%)]\tAll Loss: 3.1750\tTriple Loss(1): 0.6566\tClassification Loss: 1.8619\n",
      "Train Epoch: 1 [15680/110534 (14%)]\tAll Loss: 1.9020\tTriple Loss(0): 0.0000\tClassification Loss: 1.9020\n",
      "\n",
      "Test set: Average loss: 2.1455, Accuracy: 414/960 (43%)\n",
      "\n",
      "Train Epoch: 1 [16000/110534 (14%)]\tAll Loss: 3.3954\tTriple Loss(1): 0.6302\tClassification Loss: 2.1351\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_500.pth.tar\n",
      "Train Epoch: 1 [16320/110534 (15%)]\tAll Loss: 1.8333\tTriple Loss(0): 0.0000\tClassification Loss: 1.8333\n",
      "Train Epoch: 1 [16640/110534 (15%)]\tAll Loss: 3.3811\tTriple Loss(1): 0.6631\tClassification Loss: 2.0548\n",
      "Train Epoch: 1 [16960/110534 (15%)]\tAll Loss: 2.9412\tTriple Loss(1): 0.3009\tClassification Loss: 2.3394\n",
      "Train Epoch: 1 [17280/110534 (16%)]\tAll Loss: 2.6089\tTriple Loss(1): 0.3809\tClassification Loss: 1.8472\n",
      "Train Epoch: 1 [17600/110534 (16%)]\tAll Loss: 2.7778\tTriple Loss(1): 0.3351\tClassification Loss: 2.1077\n",
      "Train Epoch: 1 [17920/110534 (16%)]\tAll Loss: 3.1198\tTriple Loss(1): 0.5424\tClassification Loss: 2.0351\n",
      "Train Epoch: 1 [18240/110534 (16%)]\tAll Loss: 3.1858\tTriple Loss(1): 0.5191\tClassification Loss: 2.1476\n",
      "Train Epoch: 1 [18560/110534 (17%)]\tAll Loss: 2.7241\tTriple Loss(1): 0.3870\tClassification Loss: 1.9502\n",
      "Train Epoch: 1 [18880/110534 (17%)]\tAll Loss: 2.1246\tTriple Loss(0): 0.0000\tClassification Loss: 2.1246\n",
      "\n",
      "Test set: Average loss: 2.0926, Accuracy: 451/960 (47%)\n",
      "\n",
      "Train Epoch: 1 [19200/110534 (17%)]\tAll Loss: 2.9398\tTriple Loss(1): 0.5479\tClassification Loss: 1.8440\n",
      "Train Epoch: 1 [19520/110534 (18%)]\tAll Loss: 3.1365\tTriple Loss(1): 0.4846\tClassification Loss: 2.1672\n",
      "Train Epoch: 1 [19840/110534 (18%)]\tAll Loss: 2.7402\tTriple Loss(1): 0.3493\tClassification Loss: 2.0415\n",
      "Train Epoch: 1 [20160/110534 (18%)]\tAll Loss: 2.4842\tTriple Loss(1): 0.2579\tClassification Loss: 1.9684\n",
      "Train Epoch: 1 [20480/110534 (19%)]\tAll Loss: 2.9076\tTriple Loss(1): 0.5844\tClassification Loss: 1.7389\n",
      "Train Epoch: 1 [20800/110534 (19%)]\tAll Loss: 2.3740\tTriple Loss(0): 0.0000\tClassification Loss: 2.3740\n",
      "Train Epoch: 1 [21120/110534 (19%)]\tAll Loss: 2.5532\tTriple Loss(1): 0.3270\tClassification Loss: 1.8992\n",
      "Train Epoch: 1 [21440/110534 (19%)]\tAll Loss: 2.9301\tTriple Loss(1): 0.4902\tClassification Loss: 1.9498\n",
      "Train Epoch: 1 [21760/110534 (20%)]\tAll Loss: 2.9281\tTriple Loss(1): 0.4011\tClassification Loss: 2.1259\n",
      "Train Epoch: 1 [22080/110534 (20%)]\tAll Loss: 2.1255\tTriple Loss(0): 0.0000\tClassification Loss: 2.1255\n",
      "\n",
      "Test set: Average loss: 2.0552, Accuracy: 442/960 (46%)\n",
      "\n",
      "Train Epoch: 1 [22400/110534 (20%)]\tAll Loss: 2.4062\tTriple Loss(1): 0.3059\tClassification Loss: 1.7944\n",
      "Train Epoch: 1 [22720/110534 (21%)]\tAll Loss: 2.0716\tTriple Loss(0): 0.0000\tClassification Loss: 2.0716\n",
      "Train Epoch: 1 [23040/110534 (21%)]\tAll Loss: 2.6025\tTriple Loss(1): 0.3060\tClassification Loss: 1.9905\n",
      "Train Epoch: 1 [23360/110534 (21%)]\tAll Loss: 2.9490\tTriple Loss(1): 0.4043\tClassification Loss: 2.1405\n",
      "Train Epoch: 1 [23680/110534 (21%)]\tAll Loss: 3.5304\tTriple Loss(1): 0.6128\tClassification Loss: 2.3049\n",
      "Train Epoch: 1 [24000/110534 (22%)]\tAll Loss: 2.7842\tTriple Loss(1): 0.4443\tClassification Loss: 1.8957\n",
      "Train Epoch: 1 [24320/110534 (22%)]\tAll Loss: 2.9956\tTriple Loss(1): 0.4409\tClassification Loss: 2.1139\n",
      "Train Epoch: 1 [24640/110534 (22%)]\tAll Loss: 3.2313\tTriple Loss(1): 0.5145\tClassification Loss: 2.2024\n",
      "Train Epoch: 1 [24960/110534 (23%)]\tAll Loss: 2.6267\tTriple Loss(1): 0.3616\tClassification Loss: 1.9035\n",
      "Train Epoch: 1 [25280/110534 (23%)]\tAll Loss: 2.5326\tTriple Loss(1): 0.2467\tClassification Loss: 2.0391\n",
      "\n",
      "Test set: Average loss: 2.0189, Accuracy: 445/960 (46%)\n",
      "\n",
      "Train Epoch: 1 [25600/110534 (23%)]\tAll Loss: 2.8240\tTriple Loss(1): 0.3765\tClassification Loss: 2.0709\n",
      "Train Epoch: 1 [25920/110534 (23%)]\tAll Loss: 2.7654\tTriple Loss(1): 0.2802\tClassification Loss: 2.2051\n",
      "Train Epoch: 1 [26240/110534 (24%)]\tAll Loss: 2.6757\tTriple Loss(1): 0.4651\tClassification Loss: 1.7454\n",
      "Train Epoch: 1 [26560/110534 (24%)]\tAll Loss: 2.7239\tTriple Loss(1): 0.2846\tClassification Loss: 2.1547\n",
      "Train Epoch: 1 [26880/110534 (24%)]\tAll Loss: 2.8952\tTriple Loss(1): 0.3654\tClassification Loss: 2.1643\n",
      "Train Epoch: 1 [27200/110534 (25%)]\tAll Loss: 2.5882\tTriple Loss(1): 0.2133\tClassification Loss: 2.1617\n",
      "Train Epoch: 1 [27520/110534 (25%)]\tAll Loss: 2.9765\tTriple Loss(1): 0.4522\tClassification Loss: 2.0720\n",
      "Train Epoch: 1 [27840/110534 (25%)]\tAll Loss: 2.6444\tTriple Loss(1): 0.4858\tClassification Loss: 1.6727\n",
      "Train Epoch: 1 [28160/110534 (25%)]\tAll Loss: 2.1910\tTriple Loss(0): 0.0000\tClassification Loss: 2.1910\n",
      "Train Epoch: 1 [28480/110534 (26%)]\tAll Loss: 2.6191\tTriple Loss(1): 0.2397\tClassification Loss: 2.1397\n",
      "\n",
      "Test set: Average loss: 1.9852, Accuracy: 464/960 (48%)\n",
      "\n",
      "Train Epoch: 1 [28800/110534 (26%)]\tAll Loss: 2.8718\tTriple Loss(1): 0.5096\tClassification Loss: 1.8527\n",
      "Train Epoch: 1 [29120/110534 (26%)]\tAll Loss: 1.9934\tTriple Loss(0): 0.0000\tClassification Loss: 1.9934\n",
      "Train Epoch: 1 [29440/110534 (27%)]\tAll Loss: 1.8415\tTriple Loss(0): 0.0000\tClassification Loss: 1.8415\n",
      "Train Epoch: 1 [29760/110534 (27%)]\tAll Loss: 2.8349\tTriple Loss(1): 0.5418\tClassification Loss: 1.7513\n",
      "Train Epoch: 1 [30080/110534 (27%)]\tAll Loss: 2.8767\tTriple Loss(1): 0.5367\tClassification Loss: 1.8032\n",
      "Train Epoch: 1 [30400/110534 (27%)]\tAll Loss: 1.8885\tTriple Loss(0): 0.0000\tClassification Loss: 1.8885\n",
      "Train Epoch: 1 [30720/110534 (28%)]\tAll Loss: 2.3419\tTriple Loss(1): 0.3519\tClassification Loss: 1.6381\n",
      "Train Epoch: 1 [31040/110534 (28%)]\tAll Loss: 2.0692\tTriple Loss(0): 0.0000\tClassification Loss: 2.0692\n",
      "Train Epoch: 1 [31360/110534 (28%)]\tAll Loss: 2.4971\tTriple Loss(1): 0.1483\tClassification Loss: 2.2005\n",
      "Train Epoch: 1 [31680/110534 (29%)]\tAll Loss: 2.8840\tTriple Loss(1): 0.5302\tClassification Loss: 1.8236\n",
      "\n",
      "Test set: Average loss: 1.9634, Accuracy: 495/960 (52%)\n",
      "\n",
      "Train Epoch: 1 [32000/110534 (29%)]\tAll Loss: 2.7454\tTriple Loss(1): 0.3377\tClassification Loss: 2.0701\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_1000.pth.tar\n",
      "Train Epoch: 1 [32320/110534 (29%)]\tAll Loss: 2.7000\tTriple Loss(1): 0.4641\tClassification Loss: 1.7718\n",
      "Train Epoch: 1 [32640/110534 (30%)]\tAll Loss: 2.9430\tTriple Loss(1): 0.4569\tClassification Loss: 2.0292\n",
      "Train Epoch: 1 [32960/110534 (30%)]\tAll Loss: 2.1577\tTriple Loss(0): 0.0000\tClassification Loss: 2.1577\n",
      "Train Epoch: 1 [33280/110534 (30%)]\tAll Loss: 2.9199\tTriple Loss(1): 0.4382\tClassification Loss: 2.0434\n",
      "Train Epoch: 1 [33600/110534 (30%)]\tAll Loss: 2.3569\tTriple Loss(1): 0.2624\tClassification Loss: 1.8322\n",
      "Train Epoch: 1 [33920/110534 (31%)]\tAll Loss: 2.4958\tTriple Loss(1): 0.3111\tClassification Loss: 1.8736\n",
      "Train Epoch: 1 [34240/110534 (31%)]\tAll Loss: 2.3389\tTriple Loss(1): 0.1821\tClassification Loss: 1.9747\n",
      "Train Epoch: 1 [34560/110534 (31%)]\tAll Loss: 2.2353\tTriple Loss(1): 0.2653\tClassification Loss: 1.7047\n",
      "Train Epoch: 1 [34880/110534 (32%)]\tAll Loss: 2.4089\tTriple Loss(1): 0.2764\tClassification Loss: 1.8561\n",
      "\n",
      "Test set: Average loss: 1.9388, Accuracy: 509/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [35200/110534 (32%)]\tAll Loss: 3.0277\tTriple Loss(1): 0.4425\tClassification Loss: 2.1426\n",
      "Train Epoch: 1 [35520/110534 (32%)]\tAll Loss: 2.5437\tTriple Loss(1): 0.3404\tClassification Loss: 1.8630\n",
      "Train Epoch: 1 [35840/110534 (32%)]\tAll Loss: 2.4272\tTriple Loss(1): 0.3055\tClassification Loss: 1.8162\n",
      "Train Epoch: 1 [36160/110534 (33%)]\tAll Loss: 1.7582\tTriple Loss(0): 0.0000\tClassification Loss: 1.7582\n",
      "Train Epoch: 1 [36480/110534 (33%)]\tAll Loss: 2.0010\tTriple Loss(0): 0.0000\tClassification Loss: 2.0010\n",
      "Train Epoch: 1 [36800/110534 (33%)]\tAll Loss: 2.5182\tTriple Loss(1): 0.3421\tClassification Loss: 1.8340\n",
      "Train Epoch: 1 [37120/110534 (34%)]\tAll Loss: 2.0998\tTriple Loss(0): 0.0000\tClassification Loss: 2.0998\n",
      "Train Epoch: 1 [37440/110534 (34%)]\tAll Loss: 2.1519\tTriple Loss(0): 0.0000\tClassification Loss: 2.1519\n",
      "Train Epoch: 1 [37760/110534 (34%)]\tAll Loss: 2.2487\tTriple Loss(1): 0.2287\tClassification Loss: 1.7913\n",
      "Train Epoch: 1 [38080/110534 (34%)]\tAll Loss: 2.7475\tTriple Loss(1): 0.3595\tClassification Loss: 2.0285\n",
      "\n",
      "Test set: Average loss: 1.9134, Accuracy: 506/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [38400/110534 (35%)]\tAll Loss: 2.1651\tTriple Loss(1): 0.2237\tClassification Loss: 1.7178\n",
      "Train Epoch: 1 [38720/110534 (35%)]\tAll Loss: 2.3181\tTriple Loss(1): 0.2214\tClassification Loss: 1.8752\n",
      "Train Epoch: 1 [39040/110534 (35%)]\tAll Loss: 1.7000\tTriple Loss(0): 0.0000\tClassification Loss: 1.7000\n",
      "Train Epoch: 1 [39360/110534 (36%)]\tAll Loss: 2.3534\tTriple Loss(1): 0.3298\tClassification Loss: 1.6938\n",
      "Train Epoch: 1 [39680/110534 (36%)]\tAll Loss: 2.1633\tTriple Loss(0): 0.0000\tClassification Loss: 2.1633\n",
      "Train Epoch: 1 [40000/110534 (36%)]\tAll Loss: 2.1082\tTriple Loss(1): 0.3570\tClassification Loss: 1.3942\n",
      "Train Epoch: 1 [40320/110534 (36%)]\tAll Loss: 1.9464\tTriple Loss(0): 0.0000\tClassification Loss: 1.9464\n",
      "Train Epoch: 1 [40640/110534 (37%)]\tAll Loss: 2.4581\tTriple Loss(1): 0.2881\tClassification Loss: 1.8819\n",
      "Train Epoch: 1 [40960/110534 (37%)]\tAll Loss: 2.4596\tTriple Loss(1): 0.3763\tClassification Loss: 1.7070\n",
      "Train Epoch: 1 [41280/110534 (37%)]\tAll Loss: 2.8360\tTriple Loss(1): 0.3933\tClassification Loss: 2.0495\n",
      "\n",
      "Test set: Average loss: 1.8913, Accuracy: 501/960 (52%)\n",
      "\n",
      "Train Epoch: 1 [41600/110534 (38%)]\tAll Loss: 2.6485\tTriple Loss(1): 0.2794\tClassification Loss: 2.0896\n",
      "Train Epoch: 1 [41920/110534 (38%)]\tAll Loss: 1.8013\tTriple Loss(0): 0.0000\tClassification Loss: 1.8013\n",
      "Train Epoch: 1 [42240/110534 (38%)]\tAll Loss: 2.3413\tTriple Loss(1): 0.2126\tClassification Loss: 1.9160\n",
      "Train Epoch: 1 [42560/110534 (38%)]\tAll Loss: 2.4925\tTriple Loss(1): 0.3506\tClassification Loss: 1.7913\n",
      "Train Epoch: 1 [42880/110534 (39%)]\tAll Loss: 2.5602\tTriple Loss(1): 0.3528\tClassification Loss: 1.8546\n",
      "Train Epoch: 1 [43200/110534 (39%)]\tAll Loss: 2.9310\tTriple Loss(1): 0.4195\tClassification Loss: 2.0920\n",
      "Train Epoch: 1 [43520/110534 (39%)]\tAll Loss: 2.2854\tTriple Loss(1): 0.2855\tClassification Loss: 1.7144\n",
      "Train Epoch: 1 [43840/110534 (40%)]\tAll Loss: 2.2022\tTriple Loss(1): 0.2600\tClassification Loss: 1.6823\n",
      "Train Epoch: 1 [44160/110534 (40%)]\tAll Loss: 2.6150\tTriple Loss(1): 0.2260\tClassification Loss: 2.1630\n",
      "Train Epoch: 1 [44480/110534 (40%)]\tAll Loss: 2.5634\tTriple Loss(1): 0.2866\tClassification Loss: 1.9902\n",
      "\n",
      "Test set: Average loss: 1.8762, Accuracy: 507/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [44800/110534 (41%)]\tAll Loss: 2.0189\tTriple Loss(1): 0.2534\tClassification Loss: 1.5121\n",
      "Train Epoch: 1 [45120/110534 (41%)]\tAll Loss: 2.7420\tTriple Loss(1): 0.4076\tClassification Loss: 1.9269\n",
      "Train Epoch: 1 [45440/110534 (41%)]\tAll Loss: 2.1491\tTriple Loss(1): 0.1709\tClassification Loss: 1.8072\n",
      "Train Epoch: 1 [45760/110534 (41%)]\tAll Loss: 2.4320\tTriple Loss(1): 0.4516\tClassification Loss: 1.5288\n",
      "Train Epoch: 1 [46080/110534 (42%)]\tAll Loss: 1.5956\tTriple Loss(0): 0.0000\tClassification Loss: 1.5956\n",
      "Train Epoch: 1 [46400/110534 (42%)]\tAll Loss: 2.4420\tTriple Loss(1): 0.1715\tClassification Loss: 2.0991\n",
      "Train Epoch: 1 [46720/110534 (42%)]\tAll Loss: 2.8519\tTriple Loss(1): 0.4245\tClassification Loss: 2.0029\n",
      "Train Epoch: 1 [47040/110534 (43%)]\tAll Loss: 2.5904\tTriple Loss(1): 0.3942\tClassification Loss: 1.8020\n",
      "Train Epoch: 1 [47360/110534 (43%)]\tAll Loss: 2.6433\tTriple Loss(1): 0.3151\tClassification Loss: 2.0130\n",
      "Train Epoch: 1 [47680/110534 (43%)]\tAll Loss: 1.6539\tTriple Loss(1): 0.0781\tClassification Loss: 1.4976\n",
      "\n",
      "Test set: Average loss: 1.8631, Accuracy: 505/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [48000/110534 (43%)]\tAll Loss: 3.2785\tTriple Loss(1): 0.5653\tClassification Loss: 2.1478\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_1500.pth.tar\n",
      "Train Epoch: 1 [48320/110534 (44%)]\tAll Loss: 1.8732\tTriple Loss(0): 0.0000\tClassification Loss: 1.8732\n",
      "Train Epoch: 1 [48640/110534 (44%)]\tAll Loss: 2.5874\tTriple Loss(1): 0.2613\tClassification Loss: 2.0649\n",
      "Train Epoch: 1 [48960/110534 (44%)]\tAll Loss: 2.1897\tTriple Loss(1): 0.2048\tClassification Loss: 1.7800\n",
      "Train Epoch: 1 [49280/110534 (45%)]\tAll Loss: 2.7718\tTriple Loss(1): 0.4770\tClassification Loss: 1.8178\n",
      "Train Epoch: 1 [49600/110534 (45%)]\tAll Loss: 2.2213\tTriple Loss(1): 0.1181\tClassification Loss: 1.9852\n",
      "Train Epoch: 1 [49920/110534 (45%)]\tAll Loss: 2.5682\tTriple Loss(1): 0.4894\tClassification Loss: 1.5893\n",
      "Train Epoch: 1 [50240/110534 (45%)]\tAll Loss: 2.1994\tTriple Loss(1): 0.3703\tClassification Loss: 1.4588\n",
      "Train Epoch: 1 [50560/110534 (46%)]\tAll Loss: 2.9597\tTriple Loss(1): 0.4937\tClassification Loss: 1.9723\n",
      "Train Epoch: 1 [50880/110534 (46%)]\tAll Loss: 2.4249\tTriple Loss(1): 0.3435\tClassification Loss: 1.7379\n",
      "\n",
      "Test set: Average loss: 1.8459, Accuracy: 514/960 (54%)\n",
      "\n",
      "Train Epoch: 1 [51200/110534 (46%)]\tAll Loss: 2.6998\tTriple Loss(1): 0.4711\tClassification Loss: 1.7577\n",
      "Train Epoch: 1 [51520/110534 (47%)]\tAll Loss: 2.5335\tTriple Loss(1): 0.4784\tClassification Loss: 1.5767\n",
      "Train Epoch: 1 [51840/110534 (47%)]\tAll Loss: 2.4529\tTriple Loss(1): 0.3118\tClassification Loss: 1.8293\n",
      "Train Epoch: 1 [52160/110534 (47%)]\tAll Loss: 1.8344\tTriple Loss(0): 0.0000\tClassification Loss: 1.8344\n",
      "Train Epoch: 1 [52480/110534 (47%)]\tAll Loss: 2.6516\tTriple Loss(1): 0.1587\tClassification Loss: 2.3342\n",
      "Train Epoch: 1 [52800/110534 (48%)]\tAll Loss: 1.7014\tTriple Loss(0): 0.0000\tClassification Loss: 1.7014\n",
      "Train Epoch: 1 [53120/110534 (48%)]\tAll Loss: 1.7610\tTriple Loss(0): 0.0000\tClassification Loss: 1.7610\n",
      "Train Epoch: 1 [53440/110534 (48%)]\tAll Loss: 2.1598\tTriple Loss(1): 0.1105\tClassification Loss: 1.9388\n",
      "Train Epoch: 1 [53760/110534 (49%)]\tAll Loss: 2.5967\tTriple Loss(1): 0.3039\tClassification Loss: 1.9889\n",
      "Train Epoch: 1 [54080/110534 (49%)]\tAll Loss: 2.7736\tTriple Loss(1): 0.4240\tClassification Loss: 1.9255\n",
      "\n",
      "Test set: Average loss: 1.8410, Accuracy: 508/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [54400/110534 (49%)]\tAll Loss: 2.8189\tTriple Loss(1): 0.4549\tClassification Loss: 1.9091\n",
      "Train Epoch: 1 [54720/110534 (49%)]\tAll Loss: 2.6048\tTriple Loss(1): 0.3069\tClassification Loss: 1.9909\n",
      "Train Epoch: 1 [55040/110534 (50%)]\tAll Loss: 2.5006\tTriple Loss(1): 0.1884\tClassification Loss: 2.1238\n",
      "Train Epoch: 1 [55360/110534 (50%)]\tAll Loss: 1.9566\tTriple Loss(1): 0.1422\tClassification Loss: 1.6722\n",
      "Train Epoch: 1 [55680/110534 (50%)]\tAll Loss: 2.2964\tTriple Loss(1): 0.1742\tClassification Loss: 1.9481\n",
      "Train Epoch: 1 [56000/110534 (51%)]\tAll Loss: 3.4284\tTriple Loss(1): 0.5743\tClassification Loss: 2.2799\n",
      "Train Epoch: 1 [56320/110534 (51%)]\tAll Loss: 2.3117\tTriple Loss(1): 0.1571\tClassification Loss: 1.9976\n",
      "Train Epoch: 1 [56640/110534 (51%)]\tAll Loss: 2.4158\tTriple Loss(1): 0.5048\tClassification Loss: 1.4063\n",
      "Train Epoch: 1 [56960/110534 (52%)]\tAll Loss: 2.8628\tTriple Loss(1): 0.5304\tClassification Loss: 1.8021\n",
      "Train Epoch: 1 [57280/110534 (52%)]\tAll Loss: 3.0746\tTriple Loss(1): 0.5206\tClassification Loss: 2.0335\n",
      "\n",
      "Test set: Average loss: 1.8273, Accuracy: 521/960 (54%)\n",
      "\n",
      "Train Epoch: 1 [57600/110534 (52%)]\tAll Loss: 2.3462\tTriple Loss(1): 0.1881\tClassification Loss: 1.9701\n",
      "Train Epoch: 1 [57920/110534 (52%)]\tAll Loss: 2.9457\tTriple Loss(1): 0.4668\tClassification Loss: 2.0122\n",
      "Train Epoch: 1 [58240/110534 (53%)]\tAll Loss: 2.2595\tTriple Loss(1): 0.2970\tClassification Loss: 1.6654\n",
      "Train Epoch: 1 [58560/110534 (53%)]\tAll Loss: 1.8096\tTriple Loss(0): 0.0000\tClassification Loss: 1.8096\n",
      "Train Epoch: 1 [58880/110534 (53%)]\tAll Loss: 1.9453\tTriple Loss(0): 0.0000\tClassification Loss: 1.9453\n",
      "Train Epoch: 1 [59200/110534 (54%)]\tAll Loss: 2.0179\tTriple Loss(0): 0.0000\tClassification Loss: 2.0179\n",
      "Train Epoch: 1 [59520/110534 (54%)]\tAll Loss: 1.9886\tTriple Loss(1): 0.1341\tClassification Loss: 1.7204\n",
      "Train Epoch: 1 [59840/110534 (54%)]\tAll Loss: 1.6498\tTriple Loss(0): 0.0000\tClassification Loss: 1.6498\n",
      "Train Epoch: 1 [60160/110534 (54%)]\tAll Loss: 2.3359\tTriple Loss(1): 0.3142\tClassification Loss: 1.7074\n",
      "Train Epoch: 1 [60480/110534 (55%)]\tAll Loss: 1.7006\tTriple Loss(0): 0.0000\tClassification Loss: 1.7006\n",
      "\n",
      "Test set: Average loss: 1.8186, Accuracy: 516/960 (54%)\n",
      "\n",
      "Train Epoch: 1 [60800/110534 (55%)]\tAll Loss: 1.9742\tTriple Loss(0): 0.0000\tClassification Loss: 1.9742\n",
      "Train Epoch: 1 [61120/110534 (55%)]\tAll Loss: 2.8295\tTriple Loss(1): 0.4873\tClassification Loss: 1.8549\n",
      "Train Epoch: 1 [61440/110534 (56%)]\tAll Loss: 2.5856\tTriple Loss(1): 0.6225\tClassification Loss: 1.3406\n",
      "Train Epoch: 1 [61760/110534 (56%)]\tAll Loss: 2.5430\tTriple Loss(1): 0.2986\tClassification Loss: 1.9459\n",
      "Train Epoch: 1 [62080/110534 (56%)]\tAll Loss: 2.4627\tTriple Loss(1): 0.3963\tClassification Loss: 1.6701\n",
      "Train Epoch: 1 [62400/110534 (56%)]\tAll Loss: 2.0829\tTriple Loss(1): 0.1892\tClassification Loss: 1.7045\n",
      "Train Epoch: 1 [62720/110534 (57%)]\tAll Loss: 1.4925\tTriple Loss(0): 0.0000\tClassification Loss: 1.4925\n",
      "Train Epoch: 1 [63040/110534 (57%)]\tAll Loss: 2.7423\tTriple Loss(1): 0.1598\tClassification Loss: 2.4227\n",
      "Train Epoch: 1 [63360/110534 (57%)]\tAll Loss: 2.3618\tTriple Loss(1): 0.2468\tClassification Loss: 1.8681\n",
      "Train Epoch: 1 [63680/110534 (58%)]\tAll Loss: 2.3278\tTriple Loss(1): 0.4459\tClassification Loss: 1.4361\n",
      "\n",
      "Test set: Average loss: 1.8103, Accuracy: 506/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [64000/110534 (58%)]\tAll Loss: 2.8265\tTriple Loss(1): 0.3108\tClassification Loss: 2.2049\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_2000.pth.tar\n",
      "Train Epoch: 1 [64320/110534 (58%)]\tAll Loss: 1.6694\tTriple Loss(0): 0.0000\tClassification Loss: 1.6694\n",
      "Train Epoch: 1 [64640/110534 (58%)]\tAll Loss: 2.8607\tTriple Loss(1): 0.1525\tClassification Loss: 2.5558\n",
      "Train Epoch: 1 [64960/110534 (59%)]\tAll Loss: 2.3631\tTriple Loss(1): 0.3434\tClassification Loss: 1.6764\n",
      "Train Epoch: 1 [65280/110534 (59%)]\tAll Loss: 2.6446\tTriple Loss(1): 0.3635\tClassification Loss: 1.9175\n",
      "Train Epoch: 1 [65600/110534 (59%)]\tAll Loss: 4.7827\tTriple Loss(1): 1.4682\tClassification Loss: 1.8464\n",
      "Train Epoch: 1 [65920/110534 (60%)]\tAll Loss: 2.0072\tTriple Loss(1): 0.2383\tClassification Loss: 1.5306\n",
      "Train Epoch: 1 [66240/110534 (60%)]\tAll Loss: 2.4007\tTriple Loss(1): 0.3395\tClassification Loss: 1.7217\n",
      "Train Epoch: 1 [66560/110534 (60%)]\tAll Loss: 2.8311\tTriple Loss(1): 0.5403\tClassification Loss: 1.7505\n",
      "Train Epoch: 1 [66880/110534 (60%)]\tAll Loss: 2.5571\tTriple Loss(1): 0.2954\tClassification Loss: 1.9662\n",
      "\n",
      "Test set: Average loss: 1.8084, Accuracy: 507/960 (53%)\n",
      "\n",
      "Train Epoch: 1 [67200/110534 (61%)]\tAll Loss: 2.4412\tTriple Loss(1): 0.2294\tClassification Loss: 1.9824\n",
      "Train Epoch: 1 [67520/110534 (61%)]\tAll Loss: 2.6413\tTriple Loss(1): 0.3574\tClassification Loss: 1.9264\n",
      "Train Epoch: 1 [67840/110534 (61%)]\tAll Loss: 2.9034\tTriple Loss(1): 0.4123\tClassification Loss: 2.0788\n",
      "Train Epoch: 1 [68160/110534 (62%)]\tAll Loss: 1.7608\tTriple Loss(1): 0.1701\tClassification Loss: 1.4205\n",
      "Train Epoch: 1 [68480/110534 (62%)]\tAll Loss: 2.0638\tTriple Loss(1): 0.2492\tClassification Loss: 1.5654\n",
      "Train Epoch: 1 [68800/110534 (62%)]\tAll Loss: 2.3183\tTriple Loss(1): 0.3316\tClassification Loss: 1.6551\n",
      "Train Epoch: 1 [69120/110534 (63%)]\tAll Loss: 2.3030\tTriple Loss(1): 0.2948\tClassification Loss: 1.7135\n",
      "Train Epoch: 1 [69440/110534 (63%)]\tAll Loss: 2.4529\tTriple Loss(1): 0.2853\tClassification Loss: 1.8823\n",
      "Train Epoch: 1 [69760/110534 (63%)]\tAll Loss: 2.0452\tTriple Loss(1): 0.1375\tClassification Loss: 1.7701\n",
      "Train Epoch: 1 [70080/110534 (63%)]\tAll Loss: 1.6478\tTriple Loss(1): 0.0251\tClassification Loss: 1.5975\n",
      "\n",
      "Test set: Average loss: 1.7928, Accuracy: 519/960 (54%)\n",
      "\n",
      "Train Epoch: 1 [70400/110534 (64%)]\tAll Loss: 2.3296\tTriple Loss(1): 0.3641\tClassification Loss: 1.6013\n",
      "Train Epoch: 1 [70720/110534 (64%)]\tAll Loss: 1.8982\tTriple Loss(1): 0.2154\tClassification Loss: 1.4675\n",
      "Train Epoch: 1 [71040/110534 (64%)]\tAll Loss: 2.2778\tTriple Loss(1): 0.2835\tClassification Loss: 1.7109\n",
      "Train Epoch: 1 [71360/110534 (65%)]\tAll Loss: 2.1244\tTriple Loss(1): 0.1839\tClassification Loss: 1.7567\n",
      "Train Epoch: 1 [71680/110534 (65%)]\tAll Loss: 2.4158\tTriple Loss(1): 0.2634\tClassification Loss: 1.8889\n",
      "Train Epoch: 1 [72000/110534 (65%)]\tAll Loss: 2.6531\tTriple Loss(1): 0.4082\tClassification Loss: 1.8368\n",
      "Train Epoch: 1 [72320/110534 (65%)]\tAll Loss: 2.3675\tTriple Loss(1): 0.3691\tClassification Loss: 1.6293\n",
      "Train Epoch: 1 [72640/110534 (66%)]\tAll Loss: 2.2782\tTriple Loss(1): 0.4456\tClassification Loss: 1.3870\n",
      "Train Epoch: 1 [72960/110534 (66%)]\tAll Loss: 2.0959\tTriple Loss(1): 0.2819\tClassification Loss: 1.5322\n",
      "Train Epoch: 1 [73280/110534 (66%)]\tAll Loss: 2.0327\tTriple Loss(1): 0.3087\tClassification Loss: 1.4154\n",
      "\n",
      "Test set: Average loss: 1.7856, Accuracy: 525/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [73600/110534 (67%)]\tAll Loss: 2.8245\tTriple Loss(1): 0.3028\tClassification Loss: 2.2190\n",
      "Train Epoch: 1 [73920/110534 (67%)]\tAll Loss: 2.5612\tTriple Loss(1): 0.3287\tClassification Loss: 1.9038\n",
      "Train Epoch: 1 [74240/110534 (67%)]\tAll Loss: 2.0773\tTriple Loss(1): 0.2912\tClassification Loss: 1.4949\n",
      "Train Epoch: 1 [74560/110534 (67%)]\tAll Loss: 2.9874\tTriple Loss(1): 0.3831\tClassification Loss: 2.2212\n",
      "Train Epoch: 1 [74880/110534 (68%)]\tAll Loss: 2.4087\tTriple Loss(1): 0.2402\tClassification Loss: 1.9284\n",
      "Train Epoch: 1 [75200/110534 (68%)]\tAll Loss: 2.0415\tTriple Loss(1): 0.1795\tClassification Loss: 1.6826\n",
      "Train Epoch: 1 [75520/110534 (68%)]\tAll Loss: 2.2684\tTriple Loss(1): 0.3777\tClassification Loss: 1.5129\n",
      "Train Epoch: 1 [75840/110534 (69%)]\tAll Loss: 2.3190\tTriple Loss(1): 0.2496\tClassification Loss: 1.8198\n",
      "Train Epoch: 1 [76160/110534 (69%)]\tAll Loss: 2.1836\tTriple Loss(1): 0.1938\tClassification Loss: 1.7961\n",
      "Train Epoch: 1 [76480/110534 (69%)]\tAll Loss: 2.0495\tTriple Loss(1): 0.2256\tClassification Loss: 1.5982\n",
      "\n",
      "Test set: Average loss: 1.7764, Accuracy: 532/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [76800/110534 (69%)]\tAll Loss: 1.7576\tTriple Loss(0): 0.0000\tClassification Loss: 1.7576\n",
      "Train Epoch: 1 [77120/110534 (70%)]\tAll Loss: 1.7004\tTriple Loss(0): 0.0000\tClassification Loss: 1.7004\n",
      "Train Epoch: 1 [77440/110534 (70%)]\tAll Loss: 1.7737\tTriple Loss(0): 0.0000\tClassification Loss: 1.7737\n",
      "Train Epoch: 1 [77760/110534 (70%)]\tAll Loss: 1.5699\tTriple Loss(0): 0.0000\tClassification Loss: 1.5699\n",
      "Train Epoch: 1 [78080/110534 (71%)]\tAll Loss: 2.1513\tTriple Loss(0): 0.0000\tClassification Loss: 2.1513\n",
      "Train Epoch: 1 [78400/110534 (71%)]\tAll Loss: 1.8238\tTriple Loss(0): 0.0000\tClassification Loss: 1.8238\n",
      "Train Epoch: 1 [78720/110534 (71%)]\tAll Loss: 1.9410\tTriple Loss(1): 0.2228\tClassification Loss: 1.4953\n",
      "Train Epoch: 1 [79040/110534 (71%)]\tAll Loss: 2.2730\tTriple Loss(1): 0.2462\tClassification Loss: 1.7806\n",
      "Train Epoch: 1 [79360/110534 (72%)]\tAll Loss: 2.7604\tTriple Loss(1): 0.3362\tClassification Loss: 2.0881\n",
      "Train Epoch: 1 [79680/110534 (72%)]\tAll Loss: 2.2181\tTriple Loss(1): 0.2943\tClassification Loss: 1.6295\n",
      "\n",
      "Test set: Average loss: 1.7714, Accuracy: 522/960 (54%)\n",
      "\n",
      "Train Epoch: 1 [80000/110534 (72%)]\tAll Loss: 2.3018\tTriple Loss(1): 0.2581\tClassification Loss: 1.7856\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_2500.pth.tar\n",
      "Train Epoch: 1 [80320/110534 (73%)]\tAll Loss: 1.8587\tTriple Loss(1): 0.2124\tClassification Loss: 1.4340\n",
      "Train Epoch: 1 [80640/110534 (73%)]\tAll Loss: 1.8738\tTriple Loss(1): 0.1223\tClassification Loss: 1.6291\n",
      "Train Epoch: 1 [80960/110534 (73%)]\tAll Loss: 1.6995\tTriple Loss(0): 0.0000\tClassification Loss: 1.6995\n",
      "Train Epoch: 1 [81280/110534 (74%)]\tAll Loss: 2.2450\tTriple Loss(1): 0.3222\tClassification Loss: 1.6006\n",
      "Train Epoch: 1 [81600/110534 (74%)]\tAll Loss: 1.4992\tTriple Loss(0): 0.0000\tClassification Loss: 1.4992\n",
      "Train Epoch: 1 [81920/110534 (74%)]\tAll Loss: 2.1801\tTriple Loss(1): 0.2521\tClassification Loss: 1.6758\n",
      "Train Epoch: 1 [82240/110534 (74%)]\tAll Loss: 2.8596\tTriple Loss(1): 0.5311\tClassification Loss: 1.7975\n",
      "Train Epoch: 1 [82560/110534 (75%)]\tAll Loss: 1.7594\tTriple Loss(0): 0.0000\tClassification Loss: 1.7594\n",
      "Train Epoch: 1 [82880/110534 (75%)]\tAll Loss: 1.9521\tTriple Loss(0): 0.0000\tClassification Loss: 1.9521\n",
      "\n",
      "Test set: Average loss: 1.7686, Accuracy: 524/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [83200/110534 (75%)]\tAll Loss: 2.5890\tTriple Loss(1): 0.4552\tClassification Loss: 1.6786\n",
      "Train Epoch: 1 [83520/110534 (76%)]\tAll Loss: 2.0330\tTriple Loss(1): 0.1459\tClassification Loss: 1.7413\n",
      "Train Epoch: 1 [83840/110534 (76%)]\tAll Loss: 2.1185\tTriple Loss(1): 0.2446\tClassification Loss: 1.6293\n",
      "Train Epoch: 1 [84160/110534 (76%)]\tAll Loss: 2.1832\tTriple Loss(1): 0.3422\tClassification Loss: 1.4988\n",
      "Train Epoch: 1 [84480/110534 (76%)]\tAll Loss: 1.7955\tTriple Loss(1): 0.1631\tClassification Loss: 1.4693\n",
      "Train Epoch: 1 [84800/110534 (77%)]\tAll Loss: 2.3203\tTriple Loss(1): 0.1800\tClassification Loss: 1.9603\n",
      "Train Epoch: 1 [85120/110534 (77%)]\tAll Loss: 2.3963\tTriple Loss(1): 0.4111\tClassification Loss: 1.5741\n",
      "Train Epoch: 1 [85440/110534 (77%)]\tAll Loss: 1.9818\tTriple Loss(1): 0.2462\tClassification Loss: 1.4894\n",
      "Train Epoch: 1 [85760/110534 (78%)]\tAll Loss: 2.2152\tTriple Loss(1): 0.2293\tClassification Loss: 1.7566\n",
      "Train Epoch: 1 [86080/110534 (78%)]\tAll Loss: 2.4546\tTriple Loss(1): 0.3882\tClassification Loss: 1.6782\n",
      "\n",
      "Test set: Average loss: 1.7602, Accuracy: 529/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [86400/110534 (78%)]\tAll Loss: 2.5731\tTriple Loss(1): 0.1879\tClassification Loss: 2.1973\n",
      "Train Epoch: 1 [86720/110534 (78%)]\tAll Loss: 1.9862\tTriple Loss(1): 0.2532\tClassification Loss: 1.4797\n",
      "Train Epoch: 1 [87040/110534 (79%)]\tAll Loss: 2.3193\tTriple Loss(1): 0.3745\tClassification Loss: 1.5703\n",
      "Train Epoch: 1 [87360/110534 (79%)]\tAll Loss: 2.4982\tTriple Loss(1): 0.3791\tClassification Loss: 1.7399\n",
      "Train Epoch: 1 [87680/110534 (79%)]\tAll Loss: 2.1686\tTriple Loss(1): 0.2151\tClassification Loss: 1.7384\n",
      "Train Epoch: 1 [88000/110534 (80%)]\tAll Loss: 3.0999\tTriple Loss(1): 0.3523\tClassification Loss: 2.3954\n",
      "Train Epoch: 1 [88320/110534 (80%)]\tAll Loss: 2.3341\tTriple Loss(1): 0.3855\tClassification Loss: 1.5630\n",
      "Train Epoch: 1 [88640/110534 (80%)]\tAll Loss: 3.2444\tTriple Loss(1): 0.5510\tClassification Loss: 2.1423\n",
      "Train Epoch: 1 [88960/110534 (80%)]\tAll Loss: 2.5136\tTriple Loss(1): 0.3174\tClassification Loss: 1.8788\n",
      "Train Epoch: 1 [89280/110534 (81%)]\tAll Loss: 6.7501\tTriple Loss(0): 2.5056\tClassification Loss: 1.7390\n",
      "\n",
      "Test set: Average loss: 1.7580, Accuracy: 533/960 (56%)\n",
      "\n",
      "Train Epoch: 1 [89600/110534 (81%)]\tAll Loss: 2.7892\tTriple Loss(1): 0.3187\tClassification Loss: 2.1518\n",
      "Train Epoch: 1 [89920/110534 (81%)]\tAll Loss: 2.8351\tTriple Loss(1): 0.3775\tClassification Loss: 2.0800\n",
      "Train Epoch: 1 [90240/110534 (82%)]\tAll Loss: 2.0197\tTriple Loss(1): 0.2858\tClassification Loss: 1.4481\n",
      "Train Epoch: 1 [90560/110534 (82%)]\tAll Loss: 1.7117\tTriple Loss(1): 0.1398\tClassification Loss: 1.4321\n",
      "Train Epoch: 1 [90880/110534 (82%)]\tAll Loss: 1.7422\tTriple Loss(0): 0.0000\tClassification Loss: 1.7422\n",
      "Train Epoch: 1 [91200/110534 (82%)]\tAll Loss: 2.0855\tTriple Loss(1): 0.1686\tClassification Loss: 1.7483\n",
      "Train Epoch: 1 [91520/110534 (83%)]\tAll Loss: 2.3808\tTriple Loss(1): 0.3919\tClassification Loss: 1.5970\n",
      "Train Epoch: 1 [91840/110534 (83%)]\tAll Loss: 1.7672\tTriple Loss(0): 0.0000\tClassification Loss: 1.7672\n",
      "Train Epoch: 1 [92160/110534 (83%)]\tAll Loss: 2.5439\tTriple Loss(1): 0.2743\tClassification Loss: 1.9953\n",
      "Train Epoch: 1 [92480/110534 (84%)]\tAll Loss: 2.3065\tTriple Loss(1): 0.3451\tClassification Loss: 1.6163\n",
      "\n",
      "Test set: Average loss: 1.7517, Accuracy: 532/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [92800/110534 (84%)]\tAll Loss: 1.6471\tTriple Loss(0): 0.0000\tClassification Loss: 1.6471\n",
      "Train Epoch: 1 [93120/110534 (84%)]\tAll Loss: 1.9948\tTriple Loss(0): 0.0000\tClassification Loss: 1.9948\n",
      "Train Epoch: 1 [93440/110534 (85%)]\tAll Loss: 2.1370\tTriple Loss(1): 0.1822\tClassification Loss: 1.7726\n",
      "Train Epoch: 1 [93760/110534 (85%)]\tAll Loss: 2.3059\tTriple Loss(1): 0.4311\tClassification Loss: 1.4438\n",
      "Train Epoch: 1 [94080/110534 (85%)]\tAll Loss: 2.5431\tTriple Loss(1): 0.4537\tClassification Loss: 1.6357\n",
      "Train Epoch: 1 [94400/110534 (85%)]\tAll Loss: 1.8640\tTriple Loss(1): 0.0899\tClassification Loss: 1.6843\n",
      "Train Epoch: 1 [94720/110534 (86%)]\tAll Loss: 2.0161\tTriple Loss(1): 0.1419\tClassification Loss: 1.7324\n",
      "Train Epoch: 1 [95040/110534 (86%)]\tAll Loss: 2.9017\tTriple Loss(1): 0.4830\tClassification Loss: 1.9358\n",
      "Train Epoch: 1 [95360/110534 (86%)]\tAll Loss: 2.5064\tTriple Loss(1): 0.3799\tClassification Loss: 1.7467\n",
      "Train Epoch: 1 [95680/110534 (87%)]\tAll Loss: 6.8117\tTriple Loss(0): 2.5527\tClassification Loss: 1.7063\n",
      "\n",
      "Test set: Average loss: 1.7453, Accuracy: 544/960 (57%)\n",
      "\n",
      "Train Epoch: 1 [96000/110534 (87%)]\tAll Loss: 1.4101\tTriple Loss(0): 0.0000\tClassification Loss: 1.4101\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_3000.pth.tar\n",
      "Train Epoch: 1 [96320/110534 (87%)]\tAll Loss: 1.8353\tTriple Loss(1): 0.1840\tClassification Loss: 1.4673\n",
      "Train Epoch: 1 [96640/110534 (87%)]\tAll Loss: 2.2191\tTriple Loss(1): 0.1817\tClassification Loss: 1.8557\n",
      "Train Epoch: 1 [96960/110534 (88%)]\tAll Loss: 1.3168\tTriple Loss(0): 0.0000\tClassification Loss: 1.3168\n",
      "Train Epoch: 1 [97280/110534 (88%)]\tAll Loss: 1.9920\tTriple Loss(1): 0.2517\tClassification Loss: 1.4887\n",
      "Train Epoch: 1 [97600/110534 (88%)]\tAll Loss: 2.3372\tTriple Loss(1): 0.1470\tClassification Loss: 2.0431\n",
      "Train Epoch: 1 [97920/110534 (89%)]\tAll Loss: 1.6884\tTriple Loss(1): 0.2043\tClassification Loss: 1.2799\n",
      "Train Epoch: 1 [98240/110534 (89%)]\tAll Loss: 2.0529\tTriple Loss(1): 0.3436\tClassification Loss: 1.3658\n",
      "Train Epoch: 1 [98560/110534 (89%)]\tAll Loss: 2.7592\tTriple Loss(1): 0.5253\tClassification Loss: 1.7086\n",
      "Train Epoch: 1 [98880/110534 (89%)]\tAll Loss: 2.2714\tTriple Loss(1): 0.3334\tClassification Loss: 1.6045\n",
      "\n",
      "Test set: Average loss: 1.7466, Accuracy: 531/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [99200/110534 (90%)]\tAll Loss: 1.4943\tTriple Loss(0): 0.0000\tClassification Loss: 1.4943\n",
      "Train Epoch: 1 [99520/110534 (90%)]\tAll Loss: 2.2640\tTriple Loss(1): 0.2768\tClassification Loss: 1.7104\n",
      "Train Epoch: 1 [99840/110534 (90%)]\tAll Loss: 2.4267\tTriple Loss(1): 0.3344\tClassification Loss: 1.7579\n",
      "Train Epoch: 1 [100160/110534 (91%)]\tAll Loss: 1.9971\tTriple Loss(0): 0.0000\tClassification Loss: 1.9971\n",
      "Train Epoch: 1 [100480/110534 (91%)]\tAll Loss: 2.1782\tTriple Loss(1): 0.2529\tClassification Loss: 1.6725\n",
      "Train Epoch: 1 [100800/110534 (91%)]\tAll Loss: 2.7019\tTriple Loss(1): 0.1748\tClassification Loss: 2.3522\n",
      "Train Epoch: 1 [101120/110534 (91%)]\tAll Loss: 1.4711\tTriple Loss(0): 0.0000\tClassification Loss: 1.4711\n",
      "Train Epoch: 1 [101440/110534 (92%)]\tAll Loss: 2.0412\tTriple Loss(1): 0.3027\tClassification Loss: 1.4359\n",
      "Train Epoch: 1 [101760/110534 (92%)]\tAll Loss: 1.8082\tTriple Loss(1): 0.0902\tClassification Loss: 1.6278\n",
      "Train Epoch: 1 [102080/110534 (92%)]\tAll Loss: 2.6796\tTriple Loss(1): 0.2749\tClassification Loss: 2.1299\n",
      "\n",
      "Test set: Average loss: 1.7372, Accuracy: 530/960 (55%)\n",
      "\n",
      "Train Epoch: 1 [102400/110534 (93%)]\tAll Loss: 2.4854\tTriple Loss(1): 0.3328\tClassification Loss: 1.8197\n",
      "Train Epoch: 1 [102720/110534 (93%)]\tAll Loss: 2.5434\tTriple Loss(1): 0.3558\tClassification Loss: 1.8319\n",
      "Train Epoch: 1 [103040/110534 (93%)]\tAll Loss: 2.0624\tTriple Loss(1): 0.2261\tClassification Loss: 1.6101\n",
      "Train Epoch: 1 [103360/110534 (93%)]\tAll Loss: 2.2817\tTriple Loss(1): 0.2097\tClassification Loss: 1.8623\n",
      "Train Epoch: 1 [103680/110534 (94%)]\tAll Loss: 2.1291\tTriple Loss(1): 0.1359\tClassification Loss: 1.8572\n",
      "Train Epoch: 1 [104000/110534 (94%)]\tAll Loss: 1.6326\tTriple Loss(0): 0.0000\tClassification Loss: 1.6326\n",
      "Train Epoch: 1 [104320/110534 (94%)]\tAll Loss: 2.5769\tTriple Loss(1): 0.2595\tClassification Loss: 2.0580\n",
      "Train Epoch: 1 [104640/110534 (95%)]\tAll Loss: 1.9418\tTriple Loss(0): 0.0000\tClassification Loss: 1.9418\n",
      "Train Epoch: 1 [104960/110534 (95%)]\tAll Loss: 2.2493\tTriple Loss(1): 0.3140\tClassification Loss: 1.6213\n",
      "Train Epoch: 1 [105280/110534 (95%)]\tAll Loss: 2.4247\tTriple Loss(1): 0.3199\tClassification Loss: 1.7849\n",
      "\n",
      "Test set: Average loss: 1.7575, Accuracy: 517/960 (54%)\n",
      "\n",
      "Train Epoch: 1 [105600/110534 (96%)]\tAll Loss: 2.3755\tTriple Loss(1): 0.3085\tClassification Loss: 1.7585\n",
      "Train Epoch: 1 [105920/110534 (96%)]\tAll Loss: 2.2612\tTriple Loss(1): 0.2635\tClassification Loss: 1.7341\n",
      "Train Epoch: 1 [106240/110534 (96%)]\tAll Loss: 2.2239\tTriple Loss(1): 0.3401\tClassification Loss: 1.5436\n",
      "Train Epoch: 1 [106560/110534 (96%)]\tAll Loss: 2.0847\tTriple Loss(1): 0.2904\tClassification Loss: 1.5039\n",
      "Train Epoch: 1 [106880/110534 (97%)]\tAll Loss: 2.3152\tTriple Loss(1): 0.1991\tClassification Loss: 1.9169\n",
      "Train Epoch: 1 [107200/110534 (97%)]\tAll Loss: 2.6478\tTriple Loss(1): 0.4249\tClassification Loss: 1.7981\n",
      "Train Epoch: 1 [107520/110534 (97%)]\tAll Loss: 2.9075\tTriple Loss(1): 0.4104\tClassification Loss: 2.0868\n",
      "Train Epoch: 1 [107840/110534 (98%)]\tAll Loss: 2.3895\tTriple Loss(1): 0.4341\tClassification Loss: 1.5214\n",
      "Train Epoch: 1 [108160/110534 (98%)]\tAll Loss: 2.0814\tTriple Loss(1): 0.2965\tClassification Loss: 1.4883\n",
      "Train Epoch: 1 [108480/110534 (98%)]\tAll Loss: 2.5762\tTriple Loss(1): 0.4362\tClassification Loss: 1.7038\n",
      "\n",
      "Test set: Average loss: 1.7241, Accuracy: 535/960 (56%)\n",
      "\n",
      "Train Epoch: 1 [108800/110534 (98%)]\tAll Loss: 2.6288\tTriple Loss(1): 0.4828\tClassification Loss: 1.6632\n",
      "Train Epoch: 1 [109120/110534 (99%)]\tAll Loss: 2.3780\tTriple Loss(1): 0.3193\tClassification Loss: 1.7395\n",
      "Train Epoch: 1 [109440/110534 (99%)]\tAll Loss: 1.6101\tTriple Loss(0): 0.0000\tClassification Loss: 1.6101\n",
      "Train Epoch: 1 [109760/110534 (99%)]\tAll Loss: 2.0934\tTriple Loss(1): 0.2363\tClassification Loss: 1.6209\n",
      "Train Epoch: 1 [110080/110534 (100%)]\tAll Loss: 2.1771\tTriple Loss(1): 0.2957\tClassification Loss: 1.5857\n",
      "Train Epoch: 1 [110400/110534 (100%)]\tAll Loss: 2.1458\tTriple Loss(1): 0.2415\tClassification Loss: 1.6629\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_final.pth.tar\n",
      "\n",
      "Test set: Average loss: 1.7276, Accuracy: 535/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [0/110534 (0%)]\tAll Loss: 2.4888\tTriple Loss(1): 0.4119\tClassification Loss: 1.6651\n",
      "Train Epoch: 2 [320/110534 (0%)]\tAll Loss: 1.9379\tTriple Loss(1): 0.1140\tClassification Loss: 1.7098\n",
      "Train Epoch: 2 [640/110534 (1%)]\tAll Loss: 3.1061\tTriple Loss(0): 1.0354\tClassification Loss: 1.0353\n",
      "Train Epoch: 2 [960/110534 (1%)]\tAll Loss: 2.6403\tTriple Loss(1): 0.3697\tClassification Loss: 1.9010\n",
      "Train Epoch: 2 [1280/110534 (1%)]\tAll Loss: 2.5230\tTriple Loss(1): 0.4533\tClassification Loss: 1.6164\n",
      "Train Epoch: 2 [1600/110534 (1%)]\tAll Loss: 2.4727\tTriple Loss(1): 0.3389\tClassification Loss: 1.7949\n",
      "Train Epoch: 2 [1920/110534 (2%)]\tAll Loss: 1.8828\tTriple Loss(1): 0.0665\tClassification Loss: 1.7497\n",
      "Train Epoch: 2 [2240/110534 (2%)]\tAll Loss: 2.1663\tTriple Loss(1): 0.2365\tClassification Loss: 1.6934\n",
      "Train Epoch: 2 [2560/110534 (2%)]\tAll Loss: 1.6943\tTriple Loss(0): 0.0000\tClassification Loss: 1.6943\n",
      "Train Epoch: 2 [2880/110534 (3%)]\tAll Loss: 2.3294\tTriple Loss(1): 0.1955\tClassification Loss: 1.9384\n",
      "\n",
      "Test set: Average loss: 1.7290, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [3200/110534 (3%)]\tAll Loss: 2.8168\tTriple Loss(1): 0.2830\tClassification Loss: 2.2508\n",
      "Train Epoch: 2 [3520/110534 (3%)]\tAll Loss: 1.6901\tTriple Loss(1): 0.2318\tClassification Loss: 1.2266\n",
      "Train Epoch: 2 [3840/110534 (3%)]\tAll Loss: 2.3281\tTriple Loss(1): 0.3439\tClassification Loss: 1.6402\n",
      "Train Epoch: 2 [4160/110534 (4%)]\tAll Loss: 2.7172\tTriple Loss(1): 0.5102\tClassification Loss: 1.6969\n",
      "Train Epoch: 2 [4480/110534 (4%)]\tAll Loss: 2.1177\tTriple Loss(1): 0.3157\tClassification Loss: 1.4864\n",
      "Train Epoch: 2 [4800/110534 (4%)]\tAll Loss: 1.9950\tTriple Loss(1): 0.2141\tClassification Loss: 1.5669\n",
      "Train Epoch: 2 [5120/110534 (5%)]\tAll Loss: 2.8651\tTriple Loss(1): 0.4585\tClassification Loss: 1.9481\n",
      "Train Epoch: 2 [5440/110534 (5%)]\tAll Loss: 2.1426\tTriple Loss(1): 0.1962\tClassification Loss: 1.7502\n",
      "Train Epoch: 2 [5760/110534 (5%)]\tAll Loss: 1.9910\tTriple Loss(1): 0.2595\tClassification Loss: 1.4720\n",
      "Train Epoch: 2 [6080/110534 (5%)]\tAll Loss: 1.6211\tTriple Loss(0): 0.0000\tClassification Loss: 1.6211\n",
      "\n",
      "Test set: Average loss: 1.7271, Accuracy: 538/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [6400/110534 (6%)]\tAll Loss: 2.5488\tTriple Loss(1): 0.2871\tClassification Loss: 1.9746\n",
      "Train Epoch: 2 [6720/110534 (6%)]\tAll Loss: 2.0933\tTriple Loss(1): 0.1458\tClassification Loss: 1.8016\n",
      "Train Epoch: 2 [7040/110534 (6%)]\tAll Loss: 2.2270\tTriple Loss(1): 0.2193\tClassification Loss: 1.7884\n",
      "Train Epoch: 2 [7360/110534 (7%)]\tAll Loss: 1.7071\tTriple Loss(0): 0.0000\tClassification Loss: 1.7071\n",
      "Train Epoch: 2 [7680/110534 (7%)]\tAll Loss: 2.0665\tTriple Loss(1): 0.2850\tClassification Loss: 1.4966\n",
      "Train Epoch: 2 [8000/110534 (7%)]\tAll Loss: 1.9871\tTriple Loss(1): 0.3577\tClassification Loss: 1.2716\n",
      "Train Epoch: 2 [8320/110534 (8%)]\tAll Loss: 1.6625\tTriple Loss(0): 0.0000\tClassification Loss: 1.6625\n",
      "Train Epoch: 2 [8640/110534 (8%)]\tAll Loss: 1.9762\tTriple Loss(1): 0.2428\tClassification Loss: 1.4906\n",
      "Train Epoch: 2 [8960/110534 (8%)]\tAll Loss: 1.8285\tTriple Loss(1): 0.1404\tClassification Loss: 1.5476\n",
      "Train Epoch: 2 [9280/110534 (8%)]\tAll Loss: 5.3859\tTriple Loss(0): 1.9683\tClassification Loss: 1.4494\n",
      "\n",
      "Test set: Average loss: 1.7165, Accuracy: 544/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [9600/110534 (9%)]\tAll Loss: 2.5125\tTriple Loss(1): 0.2882\tClassification Loss: 1.9361\n",
      "Train Epoch: 2 [9920/110534 (9%)]\tAll Loss: 2.1329\tTriple Loss(1): 0.1695\tClassification Loss: 1.7939\n",
      "Train Epoch: 2 [10240/110534 (9%)]\tAll Loss: 1.8770\tTriple Loss(0): 0.0000\tClassification Loss: 1.8770\n",
      "Train Epoch: 2 [10560/110534 (10%)]\tAll Loss: 2.6242\tTriple Loss(1): 0.3769\tClassification Loss: 1.8704\n",
      "Train Epoch: 2 [10880/110534 (10%)]\tAll Loss: 2.4676\tTriple Loss(1): 0.2982\tClassification Loss: 1.8711\n",
      "Train Epoch: 2 [11200/110534 (10%)]\tAll Loss: 1.9896\tTriple Loss(1): 0.2266\tClassification Loss: 1.5365\n",
      "Train Epoch: 2 [11520/110534 (10%)]\tAll Loss: 2.1402\tTriple Loss(1): 0.2774\tClassification Loss: 1.5854\n",
      "Train Epoch: 2 [11840/110534 (11%)]\tAll Loss: 1.9730\tTriple Loss(1): 0.1723\tClassification Loss: 1.6283\n",
      "Train Epoch: 2 [12160/110534 (11%)]\tAll Loss: 2.3370\tTriple Loss(1): 0.3032\tClassification Loss: 1.7306\n",
      "Train Epoch: 2 [12480/110534 (11%)]\tAll Loss: 1.7091\tTriple Loss(0): 0.0000\tClassification Loss: 1.7091\n",
      "\n",
      "Test set: Average loss: 1.7131, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [12800/110534 (12%)]\tAll Loss: 1.8863\tTriple Loss(1): 0.1178\tClassification Loss: 1.6507\n",
      "Train Epoch: 2 [13120/110534 (12%)]\tAll Loss: 1.7322\tTriple Loss(1): 0.2247\tClassification Loss: 1.2828\n",
      "Train Epoch: 2 [13440/110534 (12%)]\tAll Loss: 1.8523\tTriple Loss(0): 0.0000\tClassification Loss: 1.8523\n",
      "Train Epoch: 2 [13760/110534 (12%)]\tAll Loss: 2.2200\tTriple Loss(1): 0.2416\tClassification Loss: 1.7368\n",
      "Train Epoch: 2 [14080/110534 (13%)]\tAll Loss: 1.5162\tTriple Loss(0): 0.0000\tClassification Loss: 1.5162\n",
      "Train Epoch: 2 [14400/110534 (13%)]\tAll Loss: 2.7163\tTriple Loss(1): 0.2974\tClassification Loss: 2.1216\n",
      "Train Epoch: 2 [14720/110534 (13%)]\tAll Loss: 1.7607\tTriple Loss(0): 0.0000\tClassification Loss: 1.7607\n",
      "Train Epoch: 2 [15040/110534 (14%)]\tAll Loss: 2.2110\tTriple Loss(0): 0.2735\tClassification Loss: 1.6640\n",
      "Train Epoch: 2 [15360/110534 (14%)]\tAll Loss: 2.1503\tTriple Loss(1): 0.2862\tClassification Loss: 1.5779\n",
      "Train Epoch: 2 [15680/110534 (14%)]\tAll Loss: 2.1043\tTriple Loss(1): 0.2909\tClassification Loss: 1.5226\n",
      "\n",
      "Test set: Average loss: 1.7034, Accuracy: 541/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [16000/110534 (14%)]\tAll Loss: 2.3310\tTriple Loss(1): 0.2466\tClassification Loss: 1.8378\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_500.pth.tar\n",
      "Train Epoch: 2 [16320/110534 (15%)]\tAll Loss: 2.0527\tTriple Loss(1): 0.3712\tClassification Loss: 1.3103\n",
      "Train Epoch: 2 [16640/110534 (15%)]\tAll Loss: 2.6672\tTriple Loss(1): 0.3718\tClassification Loss: 1.9235\n",
      "Train Epoch: 2 [16960/110534 (15%)]\tAll Loss: 2.6399\tTriple Loss(1): 0.3046\tClassification Loss: 2.0308\n",
      "Train Epoch: 2 [17280/110534 (16%)]\tAll Loss: 1.6875\tTriple Loss(1): 0.0874\tClassification Loss: 1.5126\n",
      "Train Epoch: 2 [17600/110534 (16%)]\tAll Loss: 2.4644\tTriple Loss(1): 0.4327\tClassification Loss: 1.5990\n",
      "Train Epoch: 2 [17920/110534 (16%)]\tAll Loss: 1.8505\tTriple Loss(0): 0.0000\tClassification Loss: 1.8505\n",
      "Train Epoch: 2 [18240/110534 (16%)]\tAll Loss: 2.0013\tTriple Loss(0): 0.0000\tClassification Loss: 2.0013\n",
      "Train Epoch: 2 [18560/110534 (17%)]\tAll Loss: 1.5661\tTriple Loss(0): 0.0000\tClassification Loss: 1.5661\n",
      "Train Epoch: 2 [18880/110534 (17%)]\tAll Loss: 2.3244\tTriple Loss(1): 0.3121\tClassification Loss: 1.7002\n",
      "\n",
      "Test set: Average loss: 1.7087, Accuracy: 538/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [19200/110534 (17%)]\tAll Loss: 1.9395\tTriple Loss(1): 0.2556\tClassification Loss: 1.4283\n",
      "Train Epoch: 2 [19520/110534 (18%)]\tAll Loss: 2.4110\tTriple Loss(1): 0.2813\tClassification Loss: 1.8483\n",
      "Train Epoch: 2 [19840/110534 (18%)]\tAll Loss: 2.1709\tTriple Loss(1): 0.2929\tClassification Loss: 1.5851\n",
      "Train Epoch: 2 [20160/110534 (18%)]\tAll Loss: 2.0533\tTriple Loss(1): 0.2123\tClassification Loss: 1.6286\n",
      "Train Epoch: 2 [20480/110534 (19%)]\tAll Loss: 2.1315\tTriple Loss(1): 0.2673\tClassification Loss: 1.5970\n",
      "Train Epoch: 2 [20800/110534 (19%)]\tAll Loss: 2.6052\tTriple Loss(1): 0.2684\tClassification Loss: 2.0684\n",
      "Train Epoch: 2 [21120/110534 (19%)]\tAll Loss: 1.6049\tTriple Loss(0): 0.0000\tClassification Loss: 1.6049\n",
      "Train Epoch: 2 [21440/110534 (19%)]\tAll Loss: 2.0198\tTriple Loss(1): 0.2723\tClassification Loss: 1.4751\n",
      "Train Epoch: 2 [21760/110534 (20%)]\tAll Loss: 2.1268\tTriple Loss(0): 0.0000\tClassification Loss: 2.1268\n",
      "Train Epoch: 2 [22080/110534 (20%)]\tAll Loss: 2.3836\tTriple Loss(1): 0.3423\tClassification Loss: 1.6990\n",
      "\n",
      "Test set: Average loss: 1.7116, Accuracy: 519/960 (54%)\n",
      "\n",
      "Train Epoch: 2 [22400/110534 (20%)]\tAll Loss: 2.2553\tTriple Loss(1): 0.3756\tClassification Loss: 1.5042\n",
      "Train Epoch: 2 [22720/110534 (21%)]\tAll Loss: 1.7874\tTriple Loss(0): 0.0000\tClassification Loss: 1.7874\n",
      "Train Epoch: 2 [23040/110534 (21%)]\tAll Loss: 2.2437\tTriple Loss(1): 0.2144\tClassification Loss: 1.8149\n",
      "Train Epoch: 2 [23360/110534 (21%)]\tAll Loss: 2.0689\tTriple Loss(1): 0.1629\tClassification Loss: 1.7432\n",
      "Train Epoch: 2 [23680/110534 (21%)]\tAll Loss: 2.5378\tTriple Loss(1): 0.3068\tClassification Loss: 1.9241\n",
      "Train Epoch: 2 [24000/110534 (22%)]\tAll Loss: 2.6956\tTriple Loss(1): 0.5635\tClassification Loss: 1.5685\n",
      "Train Epoch: 2 [24320/110534 (22%)]\tAll Loss: 2.0538\tTriple Loss(1): 0.1398\tClassification Loss: 1.7742\n",
      "Train Epoch: 2 [24640/110534 (22%)]\tAll Loss: 2.5665\tTriple Loss(1): 0.1888\tClassification Loss: 2.1890\n",
      "Train Epoch: 2 [24960/110534 (23%)]\tAll Loss: 1.8926\tTriple Loss(1): 0.1344\tClassification Loss: 1.6238\n",
      "Train Epoch: 2 [25280/110534 (23%)]\tAll Loss: 2.3642\tTriple Loss(1): 0.3091\tClassification Loss: 1.7461\n",
      "\n",
      "Test set: Average loss: 1.6995, Accuracy: 537/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [25600/110534 (23%)]\tAll Loss: 2.0844\tTriple Loss(1): 0.1718\tClassification Loss: 1.7408\n",
      "Train Epoch: 2 [25920/110534 (23%)]\tAll Loss: 1.8263\tTriple Loss(0): 0.0000\tClassification Loss: 1.8263\n",
      "Train Epoch: 2 [26240/110534 (24%)]\tAll Loss: 1.8329\tTriple Loss(1): 0.0921\tClassification Loss: 1.6486\n",
      "Train Epoch: 2 [26560/110534 (24%)]\tAll Loss: 2.8687\tTriple Loss(1): 0.4491\tClassification Loss: 1.9704\n",
      "Train Epoch: 2 [26880/110534 (24%)]\tAll Loss: 2.3955\tTriple Loss(1): 0.2196\tClassification Loss: 1.9563\n",
      "Train Epoch: 2 [27200/110534 (25%)]\tAll Loss: 3.0978\tTriple Loss(1): 0.5665\tClassification Loss: 1.9648\n",
      "Train Epoch: 2 [27520/110534 (25%)]\tAll Loss: 2.1992\tTriple Loss(1): 0.2747\tClassification Loss: 1.6498\n",
      "Train Epoch: 2 [27840/110534 (25%)]\tAll Loss: 2.0458\tTriple Loss(1): 0.2615\tClassification Loss: 1.5229\n",
      "Train Epoch: 2 [28160/110534 (25%)]\tAll Loss: 2.6621\tTriple Loss(1): 0.3085\tClassification Loss: 2.0452\n",
      "Train Epoch: 2 [28480/110534 (26%)]\tAll Loss: 2.4246\tTriple Loss(0): 0.2080\tClassification Loss: 2.0085\n",
      "\n",
      "Test set: Average loss: 1.6955, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [28800/110534 (26%)]\tAll Loss: 1.4340\tTriple Loss(0): 0.0000\tClassification Loss: 1.4340\n",
      "Train Epoch: 2 [29120/110534 (26%)]\tAll Loss: 1.9399\tTriple Loss(1): 0.0777\tClassification Loss: 1.7846\n",
      "Train Epoch: 2 [29440/110534 (27%)]\tAll Loss: 2.5564\tTriple Loss(1): 0.4713\tClassification Loss: 1.6137\n",
      "Train Epoch: 2 [29760/110534 (27%)]\tAll Loss: 1.7505\tTriple Loss(1): 0.1493\tClassification Loss: 1.4520\n",
      "Train Epoch: 2 [30080/110534 (27%)]\tAll Loss: 1.9909\tTriple Loss(1): 0.2490\tClassification Loss: 1.4928\n",
      "Train Epoch: 2 [30400/110534 (27%)]\tAll Loss: 1.5536\tTriple Loss(0): 0.0000\tClassification Loss: 1.5536\n",
      "Train Epoch: 2 [30720/110534 (28%)]\tAll Loss: 2.2994\tTriple Loss(1): 0.4106\tClassification Loss: 1.4783\n",
      "Train Epoch: 2 [31040/110534 (28%)]\tAll Loss: 2.3579\tTriple Loss(1): 0.2380\tClassification Loss: 1.8820\n",
      "Train Epoch: 2 [31360/110534 (28%)]\tAll Loss: 2.3309\tTriple Loss(1): 0.2575\tClassification Loss: 1.8158\n",
      "Train Epoch: 2 [31680/110534 (29%)]\tAll Loss: 2.0479\tTriple Loss(1): 0.1818\tClassification Loss: 1.6843\n",
      "\n",
      "Test set: Average loss: 1.6989, Accuracy: 533/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [32000/110534 (29%)]\tAll Loss: 2.2790\tTriple Loss(1): 0.2495\tClassification Loss: 1.7801\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_1000.pth.tar\n",
      "Train Epoch: 2 [32320/110534 (29%)]\tAll Loss: 2.2293\tTriple Loss(1): 0.3772\tClassification Loss: 1.4748\n",
      "Train Epoch: 2 [32640/110534 (30%)]\tAll Loss: 2.1376\tTriple Loss(1): 0.1651\tClassification Loss: 1.8075\n",
      "Train Epoch: 2 [32960/110534 (30%)]\tAll Loss: 2.6559\tTriple Loss(1): 0.4026\tClassification Loss: 1.8507\n",
      "Train Epoch: 2 [33280/110534 (30%)]\tAll Loss: 2.2985\tTriple Loss(1): 0.2356\tClassification Loss: 1.8273\n",
      "Train Epoch: 2 [33600/110534 (30%)]\tAll Loss: 1.9524\tTriple Loss(1): 0.1834\tClassification Loss: 1.5856\n",
      "Train Epoch: 2 [33920/110534 (31%)]\tAll Loss: 7.8739\tTriple Loss(0): 3.1530\tClassification Loss: 1.5679\n",
      "Train Epoch: 2 [34240/110534 (31%)]\tAll Loss: 2.7509\tTriple Loss(1): 0.5702\tClassification Loss: 1.6105\n",
      "Train Epoch: 2 [34560/110534 (31%)]\tAll Loss: 2.4724\tTriple Loss(1): 0.4983\tClassification Loss: 1.4758\n",
      "Train Epoch: 2 [34880/110534 (32%)]\tAll Loss: 1.4401\tTriple Loss(0): 0.0000\tClassification Loss: 1.4401\n",
      "\n",
      "Test set: Average loss: 1.6903, Accuracy: 539/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [35200/110534 (32%)]\tAll Loss: 2.7976\tTriple Loss(1): 0.3994\tClassification Loss: 1.9987\n",
      "Train Epoch: 2 [35520/110534 (32%)]\tAll Loss: 2.1194\tTriple Loss(1): 0.1015\tClassification Loss: 1.9164\n",
      "Train Epoch: 2 [35840/110534 (32%)]\tAll Loss: 1.7293\tTriple Loss(1): 0.1504\tClassification Loss: 1.4285\n",
      "Train Epoch: 2 [36160/110534 (33%)]\tAll Loss: 1.8832\tTriple Loss(1): 0.1570\tClassification Loss: 1.5693\n",
      "Train Epoch: 2 [36480/110534 (33%)]\tAll Loss: 2.5406\tTriple Loss(1): 0.3438\tClassification Loss: 1.8531\n",
      "Train Epoch: 2 [36800/110534 (33%)]\tAll Loss: 2.0727\tTriple Loss(1): 0.2235\tClassification Loss: 1.6256\n",
      "Train Epoch: 2 [37120/110534 (34%)]\tAll Loss: 2.2950\tTriple Loss(1): 0.2119\tClassification Loss: 1.8713\n",
      "Train Epoch: 2 [37440/110534 (34%)]\tAll Loss: 2.0083\tTriple Loss(0): 0.0000\tClassification Loss: 2.0083\n",
      "Train Epoch: 2 [37760/110534 (34%)]\tAll Loss: 2.5735\tTriple Loss(1): 0.4206\tClassification Loss: 1.7324\n",
      "Train Epoch: 2 [38080/110534 (34%)]\tAll Loss: 2.3746\tTriple Loss(1): 0.3393\tClassification Loss: 1.6959\n",
      "\n",
      "Test set: Average loss: 1.6885, Accuracy: 535/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [38400/110534 (35%)]\tAll Loss: 1.7433\tTriple Loss(1): 0.1770\tClassification Loss: 1.3892\n",
      "Train Epoch: 2 [38720/110534 (35%)]\tAll Loss: 1.8362\tTriple Loss(0): 0.0000\tClassification Loss: 1.8362\n",
      "Train Epoch: 2 [39040/110534 (35%)]\tAll Loss: 1.8537\tTriple Loss(1): 0.1941\tClassification Loss: 1.4656\n",
      "Train Epoch: 2 [39360/110534 (36%)]\tAll Loss: 2.1808\tTriple Loss(1): 0.2845\tClassification Loss: 1.6119\n",
      "Train Epoch: 2 [39680/110534 (36%)]\tAll Loss: 2.3698\tTriple Loss(1): 0.1858\tClassification Loss: 1.9981\n",
      "Train Epoch: 2 [40000/110534 (36%)]\tAll Loss: 1.9526\tTriple Loss(1): 0.3570\tClassification Loss: 1.2386\n",
      "Train Epoch: 2 [40320/110534 (36%)]\tAll Loss: 2.5555\tTriple Loss(1): 0.3686\tClassification Loss: 1.8184\n",
      "Train Epoch: 2 [40640/110534 (37%)]\tAll Loss: 2.5359\tTriple Loss(1): 0.3273\tClassification Loss: 1.8813\n",
      "Train Epoch: 2 [40960/110534 (37%)]\tAll Loss: 2.0179\tTriple Loss(1): 0.2364\tClassification Loss: 1.5450\n",
      "Train Epoch: 2 [41280/110534 (37%)]\tAll Loss: 2.3799\tTriple Loss(1): 0.2943\tClassification Loss: 1.7914\n",
      "\n",
      "Test set: Average loss: 1.6858, Accuracy: 535/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [41600/110534 (38%)]\tAll Loss: 1.8126\tTriple Loss(0): 0.0000\tClassification Loss: 1.8126\n",
      "Train Epoch: 2 [41920/110534 (38%)]\tAll Loss: 1.8717\tTriple Loss(1): 0.1132\tClassification Loss: 1.6454\n",
      "Train Epoch: 2 [42240/110534 (38%)]\tAll Loss: 2.3829\tTriple Loss(1): 0.3631\tClassification Loss: 1.6566\n",
      "Train Epoch: 2 [42560/110534 (38%)]\tAll Loss: 1.8253\tTriple Loss(0): 0.0000\tClassification Loss: 1.8253\n",
      "Train Epoch: 2 [42880/110534 (39%)]\tAll Loss: 1.8487\tTriple Loss(0): 0.0000\tClassification Loss: 1.8487\n",
      "Train Epoch: 2 [43200/110534 (39%)]\tAll Loss: 2.2524\tTriple Loss(1): 0.2966\tClassification Loss: 1.6592\n",
      "Train Epoch: 2 [43520/110534 (39%)]\tAll Loss: 1.9347\tTriple Loss(1): 0.1892\tClassification Loss: 1.5563\n",
      "Train Epoch: 2 [43840/110534 (40%)]\tAll Loss: 2.0369\tTriple Loss(1): 0.2353\tClassification Loss: 1.5662\n",
      "Train Epoch: 2 [44160/110534 (40%)]\tAll Loss: 2.7770\tTriple Loss(1): 0.3737\tClassification Loss: 2.0296\n",
      "Train Epoch: 2 [44480/110534 (40%)]\tAll Loss: 1.6665\tTriple Loss(0): 0.0000\tClassification Loss: 1.6665\n",
      "\n",
      "Test set: Average loss: 1.6857, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [44800/110534 (41%)]\tAll Loss: 1.2702\tTriple Loss(0): 0.0000\tClassification Loss: 1.2702\n",
      "Train Epoch: 2 [45120/110534 (41%)]\tAll Loss: 2.2318\tTriple Loss(1): 0.3212\tClassification Loss: 1.5894\n",
      "Train Epoch: 2 [45440/110534 (41%)]\tAll Loss: 2.1643\tTriple Loss(1): 0.2339\tClassification Loss: 1.6964\n",
      "Train Epoch: 2 [45760/110534 (41%)]\tAll Loss: 1.4610\tTriple Loss(0): 0.0000\tClassification Loss: 1.4610\n",
      "Train Epoch: 2 [46080/110534 (42%)]\tAll Loss: 1.2680\tTriple Loss(0): 0.0000\tClassification Loss: 1.2680\n",
      "Train Epoch: 2 [46400/110534 (42%)]\tAll Loss: 2.4933\tTriple Loss(1): 0.3189\tClassification Loss: 1.8555\n",
      "Train Epoch: 2 [46720/110534 (42%)]\tAll Loss: 1.7976\tTriple Loss(0): 0.0000\tClassification Loss: 1.7976\n",
      "Train Epoch: 2 [47040/110534 (43%)]\tAll Loss: 2.4857\tTriple Loss(1): 0.3821\tClassification Loss: 1.7216\n",
      "Train Epoch: 2 [47360/110534 (43%)]\tAll Loss: 2.1261\tTriple Loss(1): 0.2403\tClassification Loss: 1.6455\n",
      "Train Epoch: 2 [47680/110534 (43%)]\tAll Loss: 1.6445\tTriple Loss(1): 0.1569\tClassification Loss: 1.3307\n",
      "\n",
      "Test set: Average loss: 1.6887, Accuracy: 539/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [48000/110534 (43%)]\tAll Loss: 4.4430\tTriple Loss(0): 1.2317\tClassification Loss: 1.9797\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_1500.pth.tar\n",
      "Train Epoch: 2 [48320/110534 (44%)]\tAll Loss: 2.3963\tTriple Loss(1): 0.3189\tClassification Loss: 1.7585\n",
      "Train Epoch: 2 [48640/110534 (44%)]\tAll Loss: 1.8761\tTriple Loss(0): 0.0000\tClassification Loss: 1.8761\n",
      "Train Epoch: 2 [48960/110534 (44%)]\tAll Loss: 2.5714\tTriple Loss(1): 0.3741\tClassification Loss: 1.8231\n",
      "Train Epoch: 2 [49280/110534 (45%)]\tAll Loss: 2.1606\tTriple Loss(1): 0.3252\tClassification Loss: 1.5103\n",
      "Train Epoch: 2 [49600/110534 (45%)]\tAll Loss: 2.5213\tTriple Loss(1): 0.3579\tClassification Loss: 1.8055\n",
      "Train Epoch: 2 [49920/110534 (45%)]\tAll Loss: 1.9394\tTriple Loss(1): 0.2814\tClassification Loss: 1.3767\n",
      "Train Epoch: 2 [50240/110534 (45%)]\tAll Loss: 1.8231\tTriple Loss(1): 0.1122\tClassification Loss: 1.5988\n",
      "Train Epoch: 2 [50560/110534 (46%)]\tAll Loss: 2.0492\tTriple Loss(1): 0.1633\tClassification Loss: 1.7226\n",
      "Train Epoch: 2 [50880/110534 (46%)]\tAll Loss: 2.4563\tTriple Loss(1): 0.3262\tClassification Loss: 1.8039\n",
      "\n",
      "Test set: Average loss: 1.6805, Accuracy: 544/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [51200/110534 (46%)]\tAll Loss: 5.4395\tTriple Loss(0): 1.9318\tClassification Loss: 1.5760\n",
      "Train Epoch: 2 [51520/110534 (47%)]\tAll Loss: 2.5007\tTriple Loss(1): 0.4199\tClassification Loss: 1.6609\n",
      "Train Epoch: 2 [51840/110534 (47%)]\tAll Loss: 2.3323\tTriple Loss(1): 0.3514\tClassification Loss: 1.6295\n",
      "Train Epoch: 2 [52160/110534 (47%)]\tAll Loss: 2.8511\tTriple Loss(1): 0.4236\tClassification Loss: 2.0039\n",
      "Train Epoch: 2 [52480/110534 (47%)]\tAll Loss: 2.3624\tTriple Loss(1): 0.0829\tClassification Loss: 2.1966\n",
      "Train Epoch: 2 [52800/110534 (48%)]\tAll Loss: 1.9530\tTriple Loss(1): 0.2018\tClassification Loss: 1.5494\n",
      "Train Epoch: 2 [53120/110534 (48%)]\tAll Loss: 1.4486\tTriple Loss(0): 0.0000\tClassification Loss: 1.4486\n",
      "Train Epoch: 2 [53440/110534 (48%)]\tAll Loss: 8.3666\tTriple Loss(0): 3.2471\tClassification Loss: 1.8724\n",
      "Train Epoch: 2 [53760/110534 (49%)]\tAll Loss: 2.3406\tTriple Loss(1): 0.2747\tClassification Loss: 1.7912\n",
      "Train Epoch: 2 [54080/110534 (49%)]\tAll Loss: 1.7550\tTriple Loss(0): 0.0000\tClassification Loss: 1.7550\n",
      "\n",
      "Test set: Average loss: 1.6849, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [54400/110534 (49%)]\tAll Loss: 2.6238\tTriple Loss(1): 0.4617\tClassification Loss: 1.7004\n",
      "Train Epoch: 2 [54720/110534 (49%)]\tAll Loss: 2.3234\tTriple Loss(1): 0.3148\tClassification Loss: 1.6937\n",
      "Train Epoch: 2 [55040/110534 (50%)]\tAll Loss: 2.7421\tTriple Loss(1): 0.3915\tClassification Loss: 1.9591\n",
      "Train Epoch: 2 [55360/110534 (50%)]\tAll Loss: 1.4227\tTriple Loss(0): 0.0000\tClassification Loss: 1.4227\n",
      "Train Epoch: 2 [55680/110534 (50%)]\tAll Loss: 2.3809\tTriple Loss(1): 0.2776\tClassification Loss: 1.8257\n",
      "Train Epoch: 2 [56000/110534 (51%)]\tAll Loss: 2.5533\tTriple Loss(1): 0.2423\tClassification Loss: 2.0687\n",
      "Train Epoch: 2 [56320/110534 (51%)]\tAll Loss: 1.8539\tTriple Loss(0): 0.0000\tClassification Loss: 1.8539\n",
      "Train Epoch: 2 [56640/110534 (51%)]\tAll Loss: 1.8054\tTriple Loss(1): 0.2720\tClassification Loss: 1.2613\n",
      "Train Epoch: 2 [56960/110534 (52%)]\tAll Loss: 2.1948\tTriple Loss(1): 0.2064\tClassification Loss: 1.7820\n",
      "Train Epoch: 2 [57280/110534 (52%)]\tAll Loss: 2.4135\tTriple Loss(1): 0.2962\tClassification Loss: 1.8211\n",
      "\n",
      "Test set: Average loss: 1.6769, Accuracy: 552/960 (58%)\n",
      "\n",
      "Train Epoch: 2 [57600/110534 (52%)]\tAll Loss: 2.3116\tTriple Loss(1): 0.2254\tClassification Loss: 1.8609\n",
      "Train Epoch: 2 [57920/110534 (52%)]\tAll Loss: 2.5277\tTriple Loss(1): 0.3809\tClassification Loss: 1.7659\n",
      "Train Epoch: 2 [58240/110534 (53%)]\tAll Loss: 1.8676\tTriple Loss(1): 0.2463\tClassification Loss: 1.3750\n",
      "Train Epoch: 2 [58560/110534 (53%)]\tAll Loss: 1.5860\tTriple Loss(0): 0.0000\tClassification Loss: 1.5860\n",
      "Train Epoch: 2 [58880/110534 (53%)]\tAll Loss: 2.2577\tTriple Loss(1): 0.2192\tClassification Loss: 1.8193\n",
      "Train Epoch: 2 [59200/110534 (54%)]\tAll Loss: 2.2929\tTriple Loss(1): 0.2316\tClassification Loss: 1.8298\n",
      "Train Epoch: 2 [59520/110534 (54%)]\tAll Loss: 1.3778\tTriple Loss(0): 0.0000\tClassification Loss: 1.3778\n",
      "Train Epoch: 2 [59840/110534 (54%)]\tAll Loss: 2.3819\tTriple Loss(1): 0.4661\tClassification Loss: 1.4497\n",
      "Train Epoch: 2 [60160/110534 (54%)]\tAll Loss: 2.0080\tTriple Loss(1): 0.2097\tClassification Loss: 1.5886\n",
      "Train Epoch: 2 [60480/110534 (55%)]\tAll Loss: 1.7734\tTriple Loss(1): 0.0735\tClassification Loss: 1.6264\n",
      "\n",
      "Test set: Average loss: 1.6746, Accuracy: 540/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [60800/110534 (55%)]\tAll Loss: 1.9851\tTriple Loss(1): 0.0935\tClassification Loss: 1.7982\n",
      "Train Epoch: 2 [61120/110534 (55%)]\tAll Loss: 2.4575\tTriple Loss(1): 0.3659\tClassification Loss: 1.7257\n",
      "Train Epoch: 2 [61440/110534 (56%)]\tAll Loss: 1.8211\tTriple Loss(1): 0.3792\tClassification Loss: 1.0626\n",
      "Train Epoch: 2 [61760/110534 (56%)]\tAll Loss: 2.1943\tTriple Loss(1): 0.2128\tClassification Loss: 1.7688\n",
      "Train Epoch: 2 [62080/110534 (56%)]\tAll Loss: 2.3574\tTriple Loss(1): 0.3177\tClassification Loss: 1.7219\n",
      "Train Epoch: 2 [62400/110534 (56%)]\tAll Loss: 2.4445\tTriple Loss(0): 0.4804\tClassification Loss: 1.4837\n",
      "Train Epoch: 2 [62720/110534 (57%)]\tAll Loss: 1.4021\tTriple Loss(0): 0.0000\tClassification Loss: 1.4021\n",
      "Train Epoch: 2 [63040/110534 (57%)]\tAll Loss: 3.1305\tTriple Loss(1): 0.5339\tClassification Loss: 2.0627\n",
      "Train Epoch: 2 [63360/110534 (57%)]\tAll Loss: 2.1954\tTriple Loss(1): 0.2520\tClassification Loss: 1.6914\n",
      "Train Epoch: 2 [63680/110534 (58%)]\tAll Loss: 1.4770\tTriple Loss(0): 0.0000\tClassification Loss: 1.4770\n",
      "\n",
      "Test set: Average loss: 1.6816, Accuracy: 541/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [64000/110534 (58%)]\tAll Loss: 2.4947\tTriple Loss(1): 0.1955\tClassification Loss: 2.1038\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_2000.pth.tar\n",
      "Train Epoch: 2 [64320/110534 (58%)]\tAll Loss: 2.1477\tTriple Loss(1): 0.3229\tClassification Loss: 1.5019\n",
      "Train Epoch: 2 [64640/110534 (58%)]\tAll Loss: 4.8599\tTriple Loss(0): 1.3121\tClassification Loss: 2.2358\n",
      "Train Epoch: 2 [64960/110534 (59%)]\tAll Loss: 2.3308\tTriple Loss(1): 0.3097\tClassification Loss: 1.7113\n",
      "Train Epoch: 2 [65280/110534 (59%)]\tAll Loss: 1.8602\tTriple Loss(1): 0.0377\tClassification Loss: 1.7848\n",
      "Train Epoch: 2 [65600/110534 (59%)]\tAll Loss: 1.9804\tTriple Loss(1): 0.1440\tClassification Loss: 1.6924\n",
      "Train Epoch: 2 [65920/110534 (60%)]\tAll Loss: 1.9103\tTriple Loss(1): 0.1011\tClassification Loss: 1.7081\n",
      "Train Epoch: 2 [66240/110534 (60%)]\tAll Loss: 1.7736\tTriple Loss(0): 0.0000\tClassification Loss: 1.7736\n",
      "Train Epoch: 2 [66560/110534 (60%)]\tAll Loss: 1.9558\tTriple Loss(1): 0.2270\tClassification Loss: 1.5019\n",
      "Train Epoch: 2 [66880/110534 (60%)]\tAll Loss: 1.7467\tTriple Loss(0): 0.0000\tClassification Loss: 1.7467\n",
      "\n",
      "Test set: Average loss: 1.6729, Accuracy: 533/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [67200/110534 (61%)]\tAll Loss: 2.2452\tTriple Loss(1): 0.2022\tClassification Loss: 1.8409\n",
      "Train Epoch: 2 [67520/110534 (61%)]\tAll Loss: 2.4317\tTriple Loss(1): 0.2716\tClassification Loss: 1.8886\n",
      "Train Epoch: 2 [67840/110534 (61%)]\tAll Loss: 2.3753\tTriple Loss(1): 0.2353\tClassification Loss: 1.9047\n",
      "Train Epoch: 2 [68160/110534 (62%)]\tAll Loss: 2.1274\tTriple Loss(1): 0.3165\tClassification Loss: 1.4944\n",
      "Train Epoch: 2 [68480/110534 (62%)]\tAll Loss: 1.4172\tTriple Loss(0): 0.0000\tClassification Loss: 1.4172\n",
      "Train Epoch: 2 [68800/110534 (62%)]\tAll Loss: 1.9005\tTriple Loss(1): 0.1482\tClassification Loss: 1.6042\n",
      "Train Epoch: 2 [69120/110534 (63%)]\tAll Loss: 2.1510\tTriple Loss(0): 0.2272\tClassification Loss: 1.6966\n",
      "Train Epoch: 2 [69440/110534 (63%)]\tAll Loss: 2.2385\tTriple Loss(1): 0.2939\tClassification Loss: 1.6507\n",
      "Train Epoch: 2 [69760/110534 (63%)]\tAll Loss: 2.4104\tTriple Loss(1): 0.3484\tClassification Loss: 1.7135\n",
      "Train Epoch: 2 [70080/110534 (63%)]\tAll Loss: 2.0236\tTriple Loss(1): 0.3436\tClassification Loss: 1.3364\n",
      "\n",
      "Test set: Average loss: 1.6682, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [70400/110534 (64%)]\tAll Loss: 2.3131\tTriple Loss(1): 0.3779\tClassification Loss: 1.5573\n",
      "Train Epoch: 2 [70720/110534 (64%)]\tAll Loss: 1.7775\tTriple Loss(0): 0.2021\tClassification Loss: 1.3732\n",
      "Train Epoch: 2 [71040/110534 (64%)]\tAll Loss: 2.4137\tTriple Loss(1): 0.4493\tClassification Loss: 1.5151\n",
      "Train Epoch: 2 [71360/110534 (65%)]\tAll Loss: 2.4237\tTriple Loss(1): 0.2843\tClassification Loss: 1.8552\n",
      "Train Epoch: 2 [71680/110534 (65%)]\tAll Loss: 2.5274\tTriple Loss(1): 0.3993\tClassification Loss: 1.7289\n",
      "Train Epoch: 2 [72000/110534 (65%)]\tAll Loss: 2.0057\tTriple Loss(1): 0.2138\tClassification Loss: 1.5780\n",
      "Train Epoch: 2 [72320/110534 (65%)]\tAll Loss: 1.9913\tTriple Loss(1): 0.2056\tClassification Loss: 1.5800\n",
      "Train Epoch: 2 [72640/110534 (66%)]\tAll Loss: 1.9437\tTriple Loss(1): 0.2373\tClassification Loss: 1.4691\n",
      "Train Epoch: 2 [72960/110534 (66%)]\tAll Loss: 1.6841\tTriple Loss(1): 0.1537\tClassification Loss: 1.3767\n",
      "Train Epoch: 2 [73280/110534 (66%)]\tAll Loss: 1.2847\tTriple Loss(0): 0.0000\tClassification Loss: 1.2847\n",
      "\n",
      "Test set: Average loss: 1.6652, Accuracy: 545/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [73600/110534 (67%)]\tAll Loss: 2.8814\tTriple Loss(1): 0.3406\tClassification Loss: 2.2002\n",
      "Train Epoch: 2 [73920/110534 (67%)]\tAll Loss: 2.2439\tTriple Loss(1): 0.1486\tClassification Loss: 1.9466\n",
      "Train Epoch: 2 [74240/110534 (67%)]\tAll Loss: 1.8759\tTriple Loss(1): 0.2104\tClassification Loss: 1.4550\n",
      "Train Epoch: 2 [74560/110534 (67%)]\tAll Loss: 2.3478\tTriple Loss(1): 0.1687\tClassification Loss: 2.0105\n",
      "Train Epoch: 2 [74880/110534 (68%)]\tAll Loss: 2.6002\tTriple Loss(1): 0.4244\tClassification Loss: 1.7513\n",
      "Train Epoch: 2 [75200/110534 (68%)]\tAll Loss: 1.5798\tTriple Loss(0): 0.0000\tClassification Loss: 1.5798\n",
      "Train Epoch: 2 [75520/110534 (68%)]\tAll Loss: 3.7064\tTriple Loss(0): 1.1333\tClassification Loss: 1.4397\n",
      "Train Epoch: 2 [75840/110534 (69%)]\tAll Loss: 2.1227\tTriple Loss(1): 0.2768\tClassification Loss: 1.5691\n",
      "Train Epoch: 2 [76160/110534 (69%)]\tAll Loss: 2.2644\tTriple Loss(1): 0.2883\tClassification Loss: 1.6877\n",
      "Train Epoch: 2 [76480/110534 (69%)]\tAll Loss: 2.0898\tTriple Loss(1): 0.1945\tClassification Loss: 1.7009\n",
      "\n",
      "Test set: Average loss: 1.6621, Accuracy: 542/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [76800/110534 (69%)]\tAll Loss: 1.9161\tTriple Loss(1): 0.2286\tClassification Loss: 1.4590\n",
      "Train Epoch: 2 [77120/110534 (70%)]\tAll Loss: 2.3094\tTriple Loss(1): 0.3386\tClassification Loss: 1.6322\n",
      "Train Epoch: 2 [77440/110534 (70%)]\tAll Loss: 2.4436\tTriple Loss(1): 0.4432\tClassification Loss: 1.5572\n",
      "Train Epoch: 2 [77760/110534 (70%)]\tAll Loss: 1.6590\tTriple Loss(0): 0.0000\tClassification Loss: 1.6590\n",
      "Train Epoch: 2 [78080/110534 (71%)]\tAll Loss: 2.3398\tTriple Loss(1): 0.1994\tClassification Loss: 1.9410\n",
      "Train Epoch: 2 [78400/110534 (71%)]\tAll Loss: 2.2804\tTriple Loss(1): 0.3473\tClassification Loss: 1.5858\n",
      "Train Epoch: 2 [78720/110534 (71%)]\tAll Loss: 1.9721\tTriple Loss(1): 0.2674\tClassification Loss: 1.4373\n",
      "Train Epoch: 2 [79040/110534 (71%)]\tAll Loss: 1.8302\tTriple Loss(0): 0.0000\tClassification Loss: 1.8302\n",
      "Train Epoch: 2 [79360/110534 (72%)]\tAll Loss: 3.2934\tTriple Loss(1): 0.6495\tClassification Loss: 1.9943\n",
      "Train Epoch: 2 [79680/110534 (72%)]\tAll Loss: 1.7346\tTriple Loss(0): 0.1125\tClassification Loss: 1.5096\n",
      "\n",
      "Test set: Average loss: 1.6705, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [80000/110534 (72%)]\tAll Loss: 1.7868\tTriple Loss(1): 0.1214\tClassification Loss: 1.5439\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_2500.pth.tar\n",
      "Train Epoch: 2 [80320/110534 (73%)]\tAll Loss: 1.7362\tTriple Loss(1): 0.2156\tClassification Loss: 1.3050\n",
      "Train Epoch: 2 [80640/110534 (73%)]\tAll Loss: 2.0687\tTriple Loss(1): 0.2768\tClassification Loss: 1.5151\n",
      "Train Epoch: 2 [80960/110534 (73%)]\tAll Loss: 2.0660\tTriple Loss(1): 0.1528\tClassification Loss: 1.7603\n",
      "Train Epoch: 2 [81280/110534 (74%)]\tAll Loss: 2.2158\tTriple Loss(1): 0.3962\tClassification Loss: 1.4235\n",
      "Train Epoch: 2 [81600/110534 (74%)]\tAll Loss: 2.0526\tTriple Loss(1): 0.3006\tClassification Loss: 1.4513\n",
      "Train Epoch: 2 [81920/110534 (74%)]\tAll Loss: 1.7403\tTriple Loss(0): 0.0000\tClassification Loss: 1.7403\n",
      "Train Epoch: 2 [82240/110534 (74%)]\tAll Loss: 2.0119\tTriple Loss(0): 0.0000\tClassification Loss: 2.0119\n",
      "Train Epoch: 2 [82560/110534 (75%)]\tAll Loss: 2.1282\tTriple Loss(1): 0.2630\tClassification Loss: 1.6023\n",
      "Train Epoch: 2 [82880/110534 (75%)]\tAll Loss: 2.9401\tTriple Loss(1): 0.4661\tClassification Loss: 2.0079\n",
      "\n",
      "Test set: Average loss: 1.6642, Accuracy: 547/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [83200/110534 (75%)]\tAll Loss: 2.6491\tTriple Loss(1): 0.4791\tClassification Loss: 1.6909\n",
      "Train Epoch: 2 [83520/110534 (76%)]\tAll Loss: 2.1388\tTriple Loss(1): 0.2522\tClassification Loss: 1.6344\n",
      "Train Epoch: 2 [83840/110534 (76%)]\tAll Loss: 1.5501\tTriple Loss(1): 0.1077\tClassification Loss: 1.3348\n",
      "Train Epoch: 2 [84160/110534 (76%)]\tAll Loss: 1.5154\tTriple Loss(1): 0.0899\tClassification Loss: 1.3357\n",
      "Train Epoch: 2 [84480/110534 (76%)]\tAll Loss: 2.1333\tTriple Loss(1): 0.4090\tClassification Loss: 1.3153\n",
      "Train Epoch: 2 [84800/110534 (77%)]\tAll Loss: 2.4755\tTriple Loss(1): 0.3304\tClassification Loss: 1.8147\n",
      "Train Epoch: 2 [85120/110534 (77%)]\tAll Loss: 1.6974\tTriple Loss(1): 0.1493\tClassification Loss: 1.3989\n",
      "Train Epoch: 2 [85440/110534 (77%)]\tAll Loss: 1.3685\tTriple Loss(0): 0.0000\tClassification Loss: 1.3685\n",
      "Train Epoch: 2 [85760/110534 (78%)]\tAll Loss: 2.0540\tTriple Loss(1): 0.1693\tClassification Loss: 1.7154\n",
      "Train Epoch: 2 [86080/110534 (78%)]\tAll Loss: 2.1369\tTriple Loss(1): 0.2520\tClassification Loss: 1.6329\n",
      "\n",
      "Test set: Average loss: 1.6589, Accuracy: 542/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [86400/110534 (78%)]\tAll Loss: 2.7954\tTriple Loss(1): 0.3633\tClassification Loss: 2.0689\n",
      "Train Epoch: 2 [86720/110534 (78%)]\tAll Loss: 2.0131\tTriple Loss(1): 0.2909\tClassification Loss: 1.4313\n",
      "Train Epoch: 2 [87040/110534 (79%)]\tAll Loss: 1.9479\tTriple Loss(1): 0.2629\tClassification Loss: 1.4221\n",
      "Train Epoch: 2 [87360/110534 (79%)]\tAll Loss: 2.2029\tTriple Loss(1): 0.3202\tClassification Loss: 1.5624\n",
      "Train Epoch: 2 [87680/110534 (79%)]\tAll Loss: 1.9986\tTriple Loss(1): 0.1565\tClassification Loss: 1.6856\n",
      "Train Epoch: 2 [88000/110534 (80%)]\tAll Loss: 2.7150\tTriple Loss(1): 0.2276\tClassification Loss: 2.2598\n",
      "Train Epoch: 2 [88320/110534 (80%)]\tAll Loss: 2.0369\tTriple Loss(1): 0.1559\tClassification Loss: 1.7251\n",
      "Train Epoch: 2 [88640/110534 (80%)]\tAll Loss: 2.4387\tTriple Loss(1): 0.2317\tClassification Loss: 1.9752\n",
      "Train Epoch: 2 [88960/110534 (80%)]\tAll Loss: 1.7794\tTriple Loss(0): 0.0000\tClassification Loss: 1.7794\n",
      "Train Epoch: 2 [89280/110534 (81%)]\tAll Loss: 2.6597\tTriple Loss(1): 0.4533\tClassification Loss: 1.7531\n",
      "\n",
      "Test set: Average loss: 1.6613, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [89600/110534 (81%)]\tAll Loss: 2.5266\tTriple Loss(1): 0.1955\tClassification Loss: 2.1357\n",
      "Train Epoch: 2 [89920/110534 (81%)]\tAll Loss: 2.5861\tTriple Loss(1): 0.4182\tClassification Loss: 1.7497\n",
      "Train Epoch: 2 [90240/110534 (82%)]\tAll Loss: 2.0395\tTriple Loss(1): 0.1985\tClassification Loss: 1.6424\n",
      "Train Epoch: 2 [90560/110534 (82%)]\tAll Loss: 1.6235\tTriple Loss(1): 0.1489\tClassification Loss: 1.3257\n",
      "Train Epoch: 2 [90880/110534 (82%)]\tAll Loss: 2.1334\tTriple Loss(1): 0.2267\tClassification Loss: 1.6801\n",
      "Train Epoch: 2 [91200/110534 (82%)]\tAll Loss: 1.8708\tTriple Loss(1): 0.2210\tClassification Loss: 1.4289\n",
      "Train Epoch: 2 [91520/110534 (83%)]\tAll Loss: 1.6401\tTriple Loss(0): 0.0000\tClassification Loss: 1.6401\n",
      "Train Epoch: 2 [91840/110534 (83%)]\tAll Loss: 2.6120\tTriple Loss(1): 0.5362\tClassification Loss: 1.5396\n",
      "Train Epoch: 2 [92160/110534 (83%)]\tAll Loss: 2.7132\tTriple Loss(1): 0.3545\tClassification Loss: 2.0042\n",
      "Train Epoch: 2 [92480/110534 (84%)]\tAll Loss: 1.8850\tTriple Loss(1): 0.1350\tClassification Loss: 1.6151\n",
      "\n",
      "Test set: Average loss: 1.6691, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [92800/110534 (84%)]\tAll Loss: 1.9706\tTriple Loss(1): 0.1624\tClassification Loss: 1.6457\n",
      "Train Epoch: 2 [93120/110534 (84%)]\tAll Loss: 1.9647\tTriple Loss(1): 0.0951\tClassification Loss: 1.7745\n",
      "Train Epoch: 2 [93440/110534 (85%)]\tAll Loss: 3.0173\tTriple Loss(0): 0.6316\tClassification Loss: 1.7541\n",
      "Train Epoch: 2 [93760/110534 (85%)]\tAll Loss: 2.2309\tTriple Loss(1): 0.3585\tClassification Loss: 1.5138\n",
      "Train Epoch: 2 [94080/110534 (85%)]\tAll Loss: 1.7631\tTriple Loss(1): 0.1097\tClassification Loss: 1.5437\n",
      "Train Epoch: 2 [94400/110534 (85%)]\tAll Loss: 2.2216\tTriple Loss(1): 0.2614\tClassification Loss: 1.6988\n",
      "Train Epoch: 2 [94720/110534 (86%)]\tAll Loss: 1.7035\tTriple Loss(0): 0.0000\tClassification Loss: 1.7035\n",
      "Train Epoch: 2 [95040/110534 (86%)]\tAll Loss: 1.9317\tTriple Loss(1): 0.1473\tClassification Loss: 1.6370\n",
      "Train Epoch: 2 [95360/110534 (86%)]\tAll Loss: 2.1842\tTriple Loss(1): 0.2473\tClassification Loss: 1.6895\n",
      "Train Epoch: 2 [95680/110534 (87%)]\tAll Loss: 1.8858\tTriple Loss(1): 0.1593\tClassification Loss: 1.5672\n",
      "\n",
      "Test set: Average loss: 1.6595, Accuracy: 542/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [96000/110534 (87%)]\tAll Loss: 1.8131\tTriple Loss(1): 0.1966\tClassification Loss: 1.4199\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_3000.pth.tar\n",
      "Train Epoch: 2 [96320/110534 (87%)]\tAll Loss: 1.8410\tTriple Loss(1): 0.1606\tClassification Loss: 1.5199\n",
      "Train Epoch: 2 [96640/110534 (87%)]\tAll Loss: 1.7218\tTriple Loss(0): 0.0000\tClassification Loss: 1.7218\n",
      "Train Epoch: 2 [96960/110534 (88%)]\tAll Loss: 1.3942\tTriple Loss(1): 0.0839\tClassification Loss: 1.2265\n",
      "Train Epoch: 2 [97280/110534 (88%)]\tAll Loss: 2.0034\tTriple Loss(1): 0.3788\tClassification Loss: 1.2457\n",
      "Train Epoch: 2 [97600/110534 (88%)]\tAll Loss: 1.9115\tTriple Loss(0): 0.0000\tClassification Loss: 1.9115\n",
      "Train Epoch: 2 [97920/110534 (89%)]\tAll Loss: 1.1860\tTriple Loss(0): 0.0000\tClassification Loss: 1.1860\n",
      "Train Epoch: 2 [98240/110534 (89%)]\tAll Loss: 2.2573\tTriple Loss(0): 0.4676\tClassification Loss: 1.3220\n",
      "Train Epoch: 2 [98560/110534 (89%)]\tAll Loss: 1.9454\tTriple Loss(1): 0.2523\tClassification Loss: 1.4408\n",
      "Train Epoch: 2 [98880/110534 (89%)]\tAll Loss: 2.0493\tTriple Loss(1): 0.2397\tClassification Loss: 1.5700\n",
      "\n",
      "Test set: Average loss: 1.6667, Accuracy: 537/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [99200/110534 (90%)]\tAll Loss: 1.9327\tTriple Loss(1): 0.2137\tClassification Loss: 1.5053\n",
      "Train Epoch: 2 [99520/110534 (90%)]\tAll Loss: 2.1136\tTriple Loss(1): 0.2694\tClassification Loss: 1.5748\n",
      "Train Epoch: 2 [99840/110534 (90%)]\tAll Loss: 2.6177\tTriple Loss(1): 0.4630\tClassification Loss: 1.6916\n",
      "Train Epoch: 2 [100160/110534 (91%)]\tAll Loss: 2.4375\tTriple Loss(1): 0.2947\tClassification Loss: 1.8480\n",
      "Train Epoch: 2 [100480/110534 (91%)]\tAll Loss: 2.3060\tTriple Loss(1): 0.3379\tClassification Loss: 1.6301\n",
      "Train Epoch: 2 [100800/110534 (91%)]\tAll Loss: 2.9281\tTriple Loss(1): 0.3593\tClassification Loss: 2.2094\n",
      "Train Epoch: 2 [101120/110534 (91%)]\tAll Loss: 2.1426\tTriple Loss(1): 0.3471\tClassification Loss: 1.4484\n",
      "Train Epoch: 2 [101440/110534 (92%)]\tAll Loss: 1.8111\tTriple Loss(1): 0.1888\tClassification Loss: 1.4334\n",
      "Train Epoch: 2 [101760/110534 (92%)]\tAll Loss: 2.3895\tTriple Loss(1): 0.3468\tClassification Loss: 1.6958\n",
      "Train Epoch: 2 [102080/110534 (92%)]\tAll Loss: 2.2525\tTriple Loss(1): 0.1657\tClassification Loss: 1.9212\n",
      "\n",
      "Test set: Average loss: 1.6635, Accuracy: 541/960 (56%)\n",
      "\n",
      "Train Epoch: 2 [102400/110534 (93%)]\tAll Loss: 2.3588\tTriple Loss(1): 0.2714\tClassification Loss: 1.8161\n",
      "Train Epoch: 2 [102720/110534 (93%)]\tAll Loss: 2.5350\tTriple Loss(1): 0.3770\tClassification Loss: 1.7811\n",
      "Train Epoch: 2 [103040/110534 (93%)]\tAll Loss: 2.1051\tTriple Loss(1): 0.3401\tClassification Loss: 1.4248\n",
      "Train Epoch: 2 [103360/110534 (93%)]\tAll Loss: 1.9985\tTriple Loss(1): 0.0618\tClassification Loss: 1.8750\n",
      "Train Epoch: 2 [103680/110534 (94%)]\tAll Loss: 2.6616\tTriple Loss(1): 0.5040\tClassification Loss: 1.6536\n",
      "Train Epoch: 2 [104000/110534 (94%)]\tAll Loss: 1.5379\tTriple Loss(0): 0.0000\tClassification Loss: 1.5379\n",
      "Train Epoch: 2 [104320/110534 (94%)]\tAll Loss: 2.2485\tTriple Loss(1): 0.1496\tClassification Loss: 1.9494\n",
      "Train Epoch: 2 [104640/110534 (95%)]\tAll Loss: 2.3869\tTriple Loss(1): 0.1854\tClassification Loss: 2.0161\n",
      "Train Epoch: 2 [104960/110534 (95%)]\tAll Loss: 1.9741\tTriple Loss(1): 0.2553\tClassification Loss: 1.4635\n",
      "Train Epoch: 2 [105280/110534 (95%)]\tAll Loss: 2.1159\tTriple Loss(1): 0.2185\tClassification Loss: 1.6789\n",
      "\n",
      "Test set: Average loss: 1.6629, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [105600/110534 (96%)]\tAll Loss: 2.0852\tTriple Loss(1): 0.1616\tClassification Loss: 1.7619\n",
      "Train Epoch: 2 [105920/110534 (96%)]\tAll Loss: 2.0030\tTriple Loss(1): 0.1505\tClassification Loss: 1.7021\n",
      "Train Epoch: 2 [106240/110534 (96%)]\tAll Loss: 1.4003\tTriple Loss(0): 0.0000\tClassification Loss: 1.4003\n",
      "Train Epoch: 2 [106560/110534 (96%)]\tAll Loss: 1.6857\tTriple Loss(0): 0.0000\tClassification Loss: 1.6857\n",
      "Train Epoch: 2 [106880/110534 (97%)]\tAll Loss: 2.1564\tTriple Loss(0): 0.0000\tClassification Loss: 2.1564\n",
      "Train Epoch: 2 [107200/110534 (97%)]\tAll Loss: 3.1570\tTriple Loss(0): 0.6883\tClassification Loss: 1.7805\n",
      "Train Epoch: 2 [107520/110534 (97%)]\tAll Loss: 2.1602\tTriple Loss(1): 0.1613\tClassification Loss: 1.8377\n",
      "Train Epoch: 2 [107840/110534 (98%)]\tAll Loss: 2.2330\tTriple Loss(1): 0.3723\tClassification Loss: 1.4883\n",
      "Train Epoch: 2 [108160/110534 (98%)]\tAll Loss: 1.6095\tTriple Loss(1): 0.1682\tClassification Loss: 1.2731\n",
      "Train Epoch: 2 [108480/110534 (98%)]\tAll Loss: 2.2882\tTriple Loss(1): 0.3563\tClassification Loss: 1.5756\n",
      "\n",
      "Test set: Average loss: 1.6581, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 2 [108800/110534 (98%)]\tAll Loss: 3.6565\tTriple Loss(0): 1.0185\tClassification Loss: 1.6195\n",
      "Train Epoch: 2 [109120/110534 (99%)]\tAll Loss: 2.5592\tTriple Loss(1): 0.2760\tClassification Loss: 2.0072\n",
      "Train Epoch: 2 [109440/110534 (99%)]\tAll Loss: 1.6302\tTriple Loss(0): 0.1109\tClassification Loss: 1.4083\n",
      "Train Epoch: 2 [109760/110534 (99%)]\tAll Loss: 1.8644\tTriple Loss(1): 0.1104\tClassification Loss: 1.6436\n",
      "Train Epoch: 2 [110080/110534 (100%)]\tAll Loss: 2.2714\tTriple Loss(1): 0.2779\tClassification Loss: 1.7155\n",
      "Train Epoch: 2 [110400/110534 (100%)]\tAll Loss: 2.0645\tTriple Loss(1): 0.2581\tClassification Loss: 1.5484\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_2_final.pth.tar\n",
      "\n",
      "Test set: Average loss: 1.6647, Accuracy: 532/960 (55%)\n",
      "\n",
      "Train Epoch: 3 [0/110534 (0%)]\tAll Loss: 1.9444\tTriple Loss(1): 0.1538\tClassification Loss: 1.6367\n",
      "Train Epoch: 3 [320/110534 (0%)]\tAll Loss: 1.9898\tTriple Loss(1): 0.2035\tClassification Loss: 1.5829\n",
      "Train Epoch: 3 [640/110534 (1%)]\tAll Loss: 1.8764\tTriple Loss(1): 0.4137\tClassification Loss: 1.0490\n",
      "Train Epoch: 3 [960/110534 (1%)]\tAll Loss: 2.5638\tTriple Loss(1): 0.2467\tClassification Loss: 2.0703\n",
      "Train Epoch: 3 [1280/110534 (1%)]\tAll Loss: 2.4402\tTriple Loss(1): 0.4695\tClassification Loss: 1.5012\n",
      "Train Epoch: 3 [1600/110534 (1%)]\tAll Loss: 2.3215\tTriple Loss(1): 0.2782\tClassification Loss: 1.7652\n",
      "Train Epoch: 3 [1920/110534 (2%)]\tAll Loss: 2.1047\tTriple Loss(1): 0.1371\tClassification Loss: 1.8304\n",
      "Train Epoch: 3 [2240/110534 (2%)]\tAll Loss: 1.7270\tTriple Loss(0): 0.0000\tClassification Loss: 1.7270\n",
      "Train Epoch: 3 [2560/110534 (2%)]\tAll Loss: 2.3596\tTriple Loss(1): 0.3298\tClassification Loss: 1.6999\n",
      "Train Epoch: 3 [2880/110534 (3%)]\tAll Loss: 2.0704\tTriple Loss(1): 0.1513\tClassification Loss: 1.7679\n",
      "\n",
      "Test set: Average loss: 1.6640, Accuracy: 541/960 (56%)\n",
      "\n",
      "Train Epoch: 3 [3200/110534 (3%)]\tAll Loss: 1.9580\tTriple Loss(0): 0.0000\tClassification Loss: 1.9580\n",
      "Train Epoch: 3 [3520/110534 (3%)]\tAll Loss: 1.6650\tTriple Loss(1): 0.1892\tClassification Loss: 1.2867\n",
      "Train Epoch: 3 [3840/110534 (3%)]\tAll Loss: 1.9112\tTriple Loss(1): 0.1232\tClassification Loss: 1.6649\n",
      "Train Epoch: 3 [4160/110534 (4%)]\tAll Loss: 2.2322\tTriple Loss(1): 0.3181\tClassification Loss: 1.5960\n",
      "Train Epoch: 3 [4480/110534 (4%)]\tAll Loss: 2.0191\tTriple Loss(1): 0.2481\tClassification Loss: 1.5228\n",
      "Train Epoch: 3 [4800/110534 (4%)]\tAll Loss: 1.5659\tTriple Loss(0): 0.0000\tClassification Loss: 1.5659\n",
      "Train Epoch: 3 [5120/110534 (5%)]\tAll Loss: 1.9423\tTriple Loss(1): 0.1386\tClassification Loss: 1.6650\n",
      "Train Epoch: 3 [5440/110534 (5%)]\tAll Loss: 2.2206\tTriple Loss(1): 0.2513\tClassification Loss: 1.7181\n",
      "Train Epoch: 3 [5760/110534 (5%)]\tAll Loss: 1.9764\tTriple Loss(1): 0.2503\tClassification Loss: 1.4758\n",
      "Train Epoch: 3 [6080/110534 (5%)]\tAll Loss: 2.1138\tTriple Loss(1): 0.2574\tClassification Loss: 1.5990\n",
      "\n",
      "Test set: Average loss: 1.6543, Accuracy: 543/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [6400/110534 (6%)]\tAll Loss: 2.2415\tTriple Loss(1): 0.2315\tClassification Loss: 1.7785\n",
      "Train Epoch: 3 [6720/110534 (6%)]\tAll Loss: 1.9133\tTriple Loss(1): 0.1847\tClassification Loss: 1.5440\n",
      "Train Epoch: 3 [7040/110534 (6%)]\tAll Loss: 1.8251\tTriple Loss(0): 0.0000\tClassification Loss: 1.8251\n",
      "Train Epoch: 3 [7360/110534 (7%)]\tAll Loss: 2.0961\tTriple Loss(1): 0.2942\tClassification Loss: 1.5077\n",
      "Train Epoch: 3 [7680/110534 (7%)]\tAll Loss: 1.2267\tTriple Loss(0): 0.0000\tClassification Loss: 1.2267\n",
      "Train Epoch: 3 [8000/110534 (7%)]\tAll Loss: 2.3039\tTriple Loss(1): 0.4791\tClassification Loss: 1.3456\n",
      "Train Epoch: 3 [8320/110534 (8%)]\tAll Loss: 1.7519\tTriple Loss(1): 0.1040\tClassification Loss: 1.5439\n",
      "Train Epoch: 3 [8640/110534 (8%)]\tAll Loss: 1.9910\tTriple Loss(1): 0.3813\tClassification Loss: 1.2284\n",
      "Train Epoch: 3 [8960/110534 (8%)]\tAll Loss: 1.9546\tTriple Loss(1): 0.2521\tClassification Loss: 1.4503\n",
      "Train Epoch: 3 [9280/110534 (8%)]\tAll Loss: 1.7522\tTriple Loss(1): 0.2007\tClassification Loss: 1.3508\n",
      "\n",
      "Test set: Average loss: 1.6493, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [9600/110534 (9%)]\tAll Loss: 2.3714\tTriple Loss(1): 0.3017\tClassification Loss: 1.7680\n",
      "Train Epoch: 3 [9920/110534 (9%)]\tAll Loss: 2.1995\tTriple Loss(1): 0.2789\tClassification Loss: 1.6416\n",
      "Train Epoch: 3 [10240/110534 (9%)]\tAll Loss: 2.3498\tTriple Loss(1): 0.2461\tClassification Loss: 1.8576\n",
      "Train Epoch: 3 [10560/110534 (10%)]\tAll Loss: 2.1456\tTriple Loss(1): 0.1719\tClassification Loss: 1.8018\n",
      "Train Epoch: 3 [10880/110534 (10%)]\tAll Loss: 2.6118\tTriple Loss(1): 0.3696\tClassification Loss: 1.8726\n",
      "Train Epoch: 3 [11200/110534 (10%)]\tAll Loss: 1.7860\tTriple Loss(1): 0.2594\tClassification Loss: 1.2672\n",
      "Train Epoch: 3 [11520/110534 (10%)]\tAll Loss: 1.5803\tTriple Loss(0): 0.0000\tClassification Loss: 1.5803\n",
      "Train Epoch: 3 [11840/110534 (11%)]\tAll Loss: 2.0584\tTriple Loss(1): 0.1707\tClassification Loss: 1.7170\n",
      "Train Epoch: 3 [12160/110534 (11%)]\tAll Loss: 1.8099\tTriple Loss(0): 0.0000\tClassification Loss: 1.8099\n",
      "Train Epoch: 3 [12480/110534 (11%)]\tAll Loss: 2.2176\tTriple Loss(1): 0.2333\tClassification Loss: 1.7510\n",
      "\n",
      "Test set: Average loss: 1.6532, Accuracy: 551/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [12800/110534 (12%)]\tAll Loss: 2.1384\tTriple Loss(1): 0.3221\tClassification Loss: 1.4943\n",
      "Train Epoch: 3 [13120/110534 (12%)]\tAll Loss: 1.3973\tTriple Loss(0): 0.0000\tClassification Loss: 1.3973\n",
      "Train Epoch: 3 [13440/110534 (12%)]\tAll Loss: 1.9962\tTriple Loss(0): 0.0000\tClassification Loss: 1.9962\n",
      "Train Epoch: 3 [13760/110534 (12%)]\tAll Loss: 2.0375\tTriple Loss(1): 0.1760\tClassification Loss: 1.6855\n",
      "Train Epoch: 3 [14080/110534 (13%)]\tAll Loss: 2.3512\tTriple Loss(1): 0.3113\tClassification Loss: 1.7287\n",
      "Train Epoch: 3 [14400/110534 (13%)]\tAll Loss: 2.6253\tTriple Loss(1): 0.2240\tClassification Loss: 2.1773\n",
      "Train Epoch: 3 [14720/110534 (13%)]\tAll Loss: 2.2869\tTriple Loss(1): 0.2412\tClassification Loss: 1.8046\n",
      "Train Epoch: 3 [15040/110534 (14%)]\tAll Loss: 2.0509\tTriple Loss(1): 0.3294\tClassification Loss: 1.3922\n",
      "Train Epoch: 3 [15360/110534 (14%)]\tAll Loss: 1.8597\tTriple Loss(1): 0.1985\tClassification Loss: 1.4626\n",
      "Train Epoch: 3 [15680/110534 (14%)]\tAll Loss: 1.4384\tTriple Loss(0): 0.0000\tClassification Loss: 1.4384\n",
      "\n",
      "Test set: Average loss: 1.6466, Accuracy: 544/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [16000/110534 (14%)]\tAll Loss: 5.7329\tTriple Loss(0): 1.9399\tClassification Loss: 1.8530\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_500.pth.tar\n",
      "Train Epoch: 3 [16320/110534 (15%)]\tAll Loss: 1.8269\tTriple Loss(1): 0.2669\tClassification Loss: 1.2931\n",
      "Train Epoch: 3 [16640/110534 (15%)]\tAll Loss: 1.9150\tTriple Loss(1): 0.1821\tClassification Loss: 1.5508\n",
      "Train Epoch: 3 [16960/110534 (15%)]\tAll Loss: 1.9914\tTriple Loss(0): 0.0000\tClassification Loss: 1.9914\n",
      "Train Epoch: 3 [17280/110534 (16%)]\tAll Loss: 1.6781\tTriple Loss(1): 0.1296\tClassification Loss: 1.4189\n",
      "Train Epoch: 3 [17600/110534 (16%)]\tAll Loss: 2.4527\tTriple Loss(1): 0.3734\tClassification Loss: 1.7059\n",
      "Train Epoch: 3 [17920/110534 (16%)]\tAll Loss: 2.0821\tTriple Loss(1): 0.1518\tClassification Loss: 1.7784\n",
      "Train Epoch: 3 [18240/110534 (16%)]\tAll Loss: 2.0339\tTriple Loss(1): 0.0604\tClassification Loss: 1.9131\n",
      "Train Epoch: 3 [18560/110534 (17%)]\tAll Loss: 1.9909\tTriple Loss(1): 0.2292\tClassification Loss: 1.5326\n",
      "Train Epoch: 3 [18880/110534 (17%)]\tAll Loss: 2.1103\tTriple Loss(1): 0.2532\tClassification Loss: 1.6040\n",
      "\n",
      "Test set: Average loss: 1.6454, Accuracy: 552/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [19200/110534 (17%)]\tAll Loss: 1.4262\tTriple Loss(0): 0.0000\tClassification Loss: 1.4262\n",
      "Train Epoch: 3 [19520/110534 (18%)]\tAll Loss: 2.1427\tTriple Loss(1): 0.2295\tClassification Loss: 1.6836\n",
      "Train Epoch: 3 [19840/110534 (18%)]\tAll Loss: 2.3921\tTriple Loss(1): 0.3755\tClassification Loss: 1.6411\n",
      "Train Epoch: 3 [20160/110534 (18%)]\tAll Loss: 1.9291\tTriple Loss(1): 0.1303\tClassification Loss: 1.6686\n",
      "Train Epoch: 3 [20480/110534 (19%)]\tAll Loss: 1.9943\tTriple Loss(1): 0.2876\tClassification Loss: 1.4191\n",
      "Train Epoch: 3 [20800/110534 (19%)]\tAll Loss: 3.3002\tTriple Loss(1): 0.5478\tClassification Loss: 2.2047\n",
      "Train Epoch: 3 [21120/110534 (19%)]\tAll Loss: 1.9359\tTriple Loss(1): 0.2321\tClassification Loss: 1.4717\n",
      "Train Epoch: 3 [21440/110534 (19%)]\tAll Loss: 2.3040\tTriple Loss(1): 0.4554\tClassification Loss: 1.3932\n",
      "Train Epoch: 3 [21760/110534 (20%)]\tAll Loss: 2.4705\tTriple Loss(1): 0.2163\tClassification Loss: 2.0378\n",
      "Train Epoch: 3 [22080/110534 (20%)]\tAll Loss: 2.0128\tTriple Loss(1): 0.1486\tClassification Loss: 1.7155\n",
      "\n",
      "Test set: Average loss: 1.6504, Accuracy: 529/960 (55%)\n",
      "\n",
      "Train Epoch: 3 [22400/110534 (20%)]\tAll Loss: 2.2688\tTriple Loss(1): 0.3205\tClassification Loss: 1.6279\n",
      "Train Epoch: 3 [22720/110534 (21%)]\tAll Loss: 1.6511\tTriple Loss(0): 0.0000\tClassification Loss: 1.6511\n",
      "Train Epoch: 3 [23040/110534 (21%)]\tAll Loss: 1.6268\tTriple Loss(0): 0.0000\tClassification Loss: 1.6268\n",
      "Train Epoch: 3 [23360/110534 (21%)]\tAll Loss: 1.6899\tTriple Loss(1): 0.0578\tClassification Loss: 1.5742\n",
      "Train Epoch: 3 [23680/110534 (21%)]\tAll Loss: 2.2949\tTriple Loss(1): 0.2079\tClassification Loss: 1.8791\n",
      "Train Epoch: 3 [24000/110534 (22%)]\tAll Loss: 2.3342\tTriple Loss(1): 0.4290\tClassification Loss: 1.4762\n",
      "Train Epoch: 3 [24320/110534 (22%)]\tAll Loss: 2.2253\tTriple Loss(1): 0.2651\tClassification Loss: 1.6951\n",
      "Train Epoch: 3 [24640/110534 (22%)]\tAll Loss: 2.0580\tTriple Loss(0): 0.0000\tClassification Loss: 2.0580\n",
      "Train Epoch: 3 [24960/110534 (23%)]\tAll Loss: 1.9726\tTriple Loss(1): 0.2246\tClassification Loss: 1.5233\n",
      "Train Epoch: 3 [25280/110534 (23%)]\tAll Loss: 2.2613\tTriple Loss(1): 0.3067\tClassification Loss: 1.6479\n",
      "\n",
      "Test set: Average loss: 1.6415, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [25600/110534 (23%)]\tAll Loss: 1.5874\tTriple Loss(0): 0.0000\tClassification Loss: 1.5874\n",
      "Train Epoch: 3 [25920/110534 (23%)]\tAll Loss: 2.3986\tTriple Loss(1): 0.3505\tClassification Loss: 1.6977\n",
      "Train Epoch: 3 [26240/110534 (24%)]\tAll Loss: 2.6749\tTriple Loss(1): 0.5807\tClassification Loss: 1.5135\n",
      "Train Epoch: 3 [26560/110534 (24%)]\tAll Loss: 2.4483\tTriple Loss(1): 0.3346\tClassification Loss: 1.7791\n",
      "Train Epoch: 3 [26880/110534 (24%)]\tAll Loss: 1.8399\tTriple Loss(0): 0.0000\tClassification Loss: 1.8399\n",
      "Train Epoch: 3 [27200/110534 (25%)]\tAll Loss: 2.4215\tTriple Loss(1): 0.2254\tClassification Loss: 1.9707\n",
      "Train Epoch: 3 [27520/110534 (25%)]\tAll Loss: 1.8356\tTriple Loss(1): 0.1488\tClassification Loss: 1.5380\n",
      "Train Epoch: 3 [27840/110534 (25%)]\tAll Loss: 1.8149\tTriple Loss(1): 0.1800\tClassification Loss: 1.4548\n",
      "Train Epoch: 3 [28160/110534 (25%)]\tAll Loss: 2.3969\tTriple Loss(1): 0.2692\tClassification Loss: 1.8585\n",
      "Train Epoch: 3 [28480/110534 (26%)]\tAll Loss: 2.3744\tTriple Loss(1): 0.2819\tClassification Loss: 1.8106\n",
      "\n",
      "Test set: Average loss: 1.6448, Accuracy: 557/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [28800/110534 (26%)]\tAll Loss: 1.6487\tTriple Loss(1): 0.1860\tClassification Loss: 1.2767\n",
      "Train Epoch: 3 [29120/110534 (26%)]\tAll Loss: 2.2537\tTriple Loss(1): 0.2628\tClassification Loss: 1.7282\n",
      "Train Epoch: 3 [29440/110534 (27%)]\tAll Loss: 1.4078\tTriple Loss(0): 0.0000\tClassification Loss: 1.4078\n",
      "Train Epoch: 3 [29760/110534 (27%)]\tAll Loss: 1.6080\tTriple Loss(1): 0.1991\tClassification Loss: 1.2098\n",
      "Train Epoch: 3 [30080/110534 (27%)]\tAll Loss: 1.5150\tTriple Loss(1): 0.0758\tClassification Loss: 1.3634\n",
      "Train Epoch: 3 [30400/110534 (27%)]\tAll Loss: 1.7987\tTriple Loss(1): 0.2249\tClassification Loss: 1.3489\n",
      "Train Epoch: 3 [30720/110534 (28%)]\tAll Loss: 2.1277\tTriple Loss(1): 0.4177\tClassification Loss: 1.2922\n",
      "Train Epoch: 3 [31040/110534 (28%)]\tAll Loss: 2.1116\tTriple Loss(1): 0.1590\tClassification Loss: 1.7937\n",
      "Train Epoch: 3 [31360/110534 (28%)]\tAll Loss: 2.2025\tTriple Loss(1): 0.2723\tClassification Loss: 1.6578\n",
      "Train Epoch: 3 [31680/110534 (29%)]\tAll Loss: 1.8642\tTriple Loss(1): 0.1463\tClassification Loss: 1.5716\n",
      "\n",
      "Test set: Average loss: 1.6380, Accuracy: 550/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [32000/110534 (29%)]\tAll Loss: 1.9004\tTriple Loss(1): 0.0000\tClassification Loss: 1.9004\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_1000.pth.tar\n",
      "Train Epoch: 3 [32320/110534 (29%)]\tAll Loss: 1.9250\tTriple Loss(1): 0.1913\tClassification Loss: 1.5425\n",
      "Train Epoch: 3 [32640/110534 (30%)]\tAll Loss: 1.9585\tTriple Loss(1): 0.2242\tClassification Loss: 1.5100\n",
      "Train Epoch: 3 [32960/110534 (30%)]\tAll Loss: 1.9648\tTriple Loss(1): 0.1368\tClassification Loss: 1.6911\n",
      "Train Epoch: 3 [33280/110534 (30%)]\tAll Loss: 2.2617\tTriple Loss(1): 0.2602\tClassification Loss: 1.7412\n",
      "Train Epoch: 3 [33600/110534 (30%)]\tAll Loss: 1.5912\tTriple Loss(0): 0.0000\tClassification Loss: 1.5912\n",
      "Train Epoch: 3 [33920/110534 (31%)]\tAll Loss: 2.0048\tTriple Loss(1): 0.2263\tClassification Loss: 1.5522\n",
      "Train Epoch: 3 [34240/110534 (31%)]\tAll Loss: 2.5789\tTriple Loss(1): 0.3772\tClassification Loss: 1.8244\n",
      "Train Epoch: 3 [34560/110534 (31%)]\tAll Loss: 2.0613\tTriple Loss(1): 0.3154\tClassification Loss: 1.4305\n",
      "Train Epoch: 3 [34880/110534 (32%)]\tAll Loss: 1.7031\tTriple Loss(1): 0.0676\tClassification Loss: 1.5680\n",
      "\n",
      "Test set: Average loss: 1.6343, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [35200/110534 (32%)]\tAll Loss: 2.4243\tTriple Loss(1): 0.1646\tClassification Loss: 2.0950\n",
      "Train Epoch: 3 [35520/110534 (32%)]\tAll Loss: 1.6794\tTriple Loss(0): 0.0000\tClassification Loss: 1.6794\n",
      "Train Epoch: 3 [35840/110534 (32%)]\tAll Loss: 1.6273\tTriple Loss(1): 0.1516\tClassification Loss: 1.3240\n",
      "Train Epoch: 3 [36160/110534 (33%)]\tAll Loss: 2.2452\tTriple Loss(1): 0.3345\tClassification Loss: 1.5762\n",
      "Train Epoch: 3 [36480/110534 (33%)]\tAll Loss: 2.0733\tTriple Loss(1): 0.1947\tClassification Loss: 1.6839\n",
      "Train Epoch: 3 [36800/110534 (33%)]\tAll Loss: 2.4671\tTriple Loss(1): 0.3269\tClassification Loss: 1.8133\n",
      "Train Epoch: 3 [37120/110534 (34%)]\tAll Loss: 2.2441\tTriple Loss(1): 0.1563\tClassification Loss: 1.9315\n",
      "Train Epoch: 3 [37440/110534 (34%)]\tAll Loss: 1.9050\tTriple Loss(1): 0.1263\tClassification Loss: 1.6523\n",
      "Train Epoch: 3 [37760/110534 (34%)]\tAll Loss: 1.6936\tTriple Loss(1): 0.0529\tClassification Loss: 1.5879\n",
      "Train Epoch: 3 [38080/110534 (34%)]\tAll Loss: 1.9887\tTriple Loss(1): 0.0907\tClassification Loss: 1.8073\n",
      "\n",
      "Test set: Average loss: 1.6415, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [38400/110534 (35%)]\tAll Loss: 1.3891\tTriple Loss(0): 0.0000\tClassification Loss: 1.3891\n",
      "Train Epoch: 3 [38720/110534 (35%)]\tAll Loss: 2.5951\tTriple Loss(1): 0.3112\tClassification Loss: 1.9727\n",
      "Train Epoch: 3 [39040/110534 (35%)]\tAll Loss: 1.4274\tTriple Loss(0): 0.0000\tClassification Loss: 1.4274\n",
      "Train Epoch: 3 [39360/110534 (36%)]\tAll Loss: 1.3725\tTriple Loss(0): 0.0000\tClassification Loss: 1.3725\n",
      "Train Epoch: 3 [39680/110534 (36%)]\tAll Loss: 2.1414\tTriple Loss(1): 0.1849\tClassification Loss: 1.7715\n",
      "Train Epoch: 3 [40000/110534 (36%)]\tAll Loss: 1.7204\tTriple Loss(1): 0.2208\tClassification Loss: 1.2789\n",
      "Train Epoch: 3 [40320/110534 (36%)]\tAll Loss: 2.0371\tTriple Loss(1): 0.1190\tClassification Loss: 1.7991\n",
      "Train Epoch: 3 [40640/110534 (37%)]\tAll Loss: 2.2603\tTriple Loss(1): 0.2372\tClassification Loss: 1.7858\n",
      "Train Epoch: 3 [40960/110534 (37%)]\tAll Loss: 1.5412\tTriple Loss(0): 0.0000\tClassification Loss: 1.5412\n",
      "Train Epoch: 3 [41280/110534 (37%)]\tAll Loss: 2.0678\tTriple Loss(1): 0.2143\tClassification Loss: 1.6391\n",
      "\n",
      "Test set: Average loss: 1.6333, Accuracy: 547/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [41600/110534 (38%)]\tAll Loss: 1.6474\tTriple Loss(1): 0.0368\tClassification Loss: 1.5737\n",
      "Train Epoch: 3 [41920/110534 (38%)]\tAll Loss: 1.9990\tTriple Loss(1): 0.1882\tClassification Loss: 1.6227\n",
      "Train Epoch: 3 [42240/110534 (38%)]\tAll Loss: 1.7048\tTriple Loss(0): 0.0000\tClassification Loss: 1.7048\n",
      "Train Epoch: 3 [42560/110534 (38%)]\tAll Loss: 1.7313\tTriple Loss(1): 0.1665\tClassification Loss: 1.3983\n",
      "Train Epoch: 3 [42880/110534 (39%)]\tAll Loss: 1.6392\tTriple Loss(0): 0.0000\tClassification Loss: 1.6392\n",
      "Train Epoch: 3 [43200/110534 (39%)]\tAll Loss: 1.7118\tTriple Loss(0): 0.0000\tClassification Loss: 1.7118\n",
      "Train Epoch: 3 [43520/110534 (39%)]\tAll Loss: 1.9168\tTriple Loss(1): 0.2374\tClassification Loss: 1.4420\n",
      "Train Epoch: 3 [43840/110534 (40%)]\tAll Loss: 2.2104\tTriple Loss(1): 0.2632\tClassification Loss: 1.6840\n",
      "Train Epoch: 3 [44160/110534 (40%)]\tAll Loss: 2.5213\tTriple Loss(1): 0.2113\tClassification Loss: 2.0987\n",
      "Train Epoch: 3 [44480/110534 (40%)]\tAll Loss: 1.6990\tTriple Loss(0): 0.0000\tClassification Loss: 1.6990\n",
      "\n",
      "Test set: Average loss: 1.6327, Accuracy: 562/960 (59%)\n",
      "\n",
      "Train Epoch: 3 [44800/110534 (41%)]\tAll Loss: 1.8694\tTriple Loss(1): 0.2851\tClassification Loss: 1.2992\n",
      "Train Epoch: 3 [45120/110534 (41%)]\tAll Loss: 1.8155\tTriple Loss(1): 0.0417\tClassification Loss: 1.7322\n",
      "Train Epoch: 3 [45440/110534 (41%)]\tAll Loss: 1.6589\tTriple Loss(1): 0.1390\tClassification Loss: 1.3808\n",
      "Train Epoch: 3 [45760/110534 (41%)]\tAll Loss: 1.6444\tTriple Loss(1): 0.1431\tClassification Loss: 1.3582\n",
      "Train Epoch: 3 [46080/110534 (42%)]\tAll Loss: 1.8285\tTriple Loss(1): 0.2568\tClassification Loss: 1.3149\n",
      "Train Epoch: 3 [46400/110534 (42%)]\tAll Loss: 2.0277\tTriple Loss(0): 0.0000\tClassification Loss: 2.0277\n",
      "Train Epoch: 3 [46720/110534 (42%)]\tAll Loss: 2.4568\tTriple Loss(1): 0.2478\tClassification Loss: 1.9612\n",
      "Train Epoch: 3 [47040/110534 (43%)]\tAll Loss: 2.2700\tTriple Loss(1): 0.3820\tClassification Loss: 1.5059\n",
      "Train Epoch: 3 [47360/110534 (43%)]\tAll Loss: 2.3403\tTriple Loss(1): 0.3601\tClassification Loss: 1.6201\n",
      "Train Epoch: 3 [47680/110534 (43%)]\tAll Loss: 1.6766\tTriple Loss(1): 0.2061\tClassification Loss: 1.2645\n",
      "\n",
      "Test set: Average loss: 1.6363, Accuracy: 541/960 (56%)\n",
      "\n",
      "Train Epoch: 3 [48000/110534 (43%)]\tAll Loss: 2.3369\tTriple Loss(1): 0.1846\tClassification Loss: 1.9678\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_1500.pth.tar\n",
      "Train Epoch: 3 [48320/110534 (44%)]\tAll Loss: 2.0344\tTriple Loss(1): 0.2491\tClassification Loss: 1.5362\n",
      "Train Epoch: 3 [48640/110534 (44%)]\tAll Loss: 2.5994\tTriple Loss(1): 0.3193\tClassification Loss: 1.9608\n",
      "Train Epoch: 3 [48960/110534 (44%)]\tAll Loss: 2.0912\tTriple Loss(1): 0.3516\tClassification Loss: 1.3881\n",
      "Train Epoch: 3 [49280/110534 (45%)]\tAll Loss: 1.9475\tTriple Loss(1): 0.2019\tClassification Loss: 1.5438\n",
      "Train Epoch: 3 [49600/110534 (45%)]\tAll Loss: 3.9717\tTriple Loss(0): 1.1959\tClassification Loss: 1.5799\n",
      "Train Epoch: 3 [49920/110534 (45%)]\tAll Loss: 1.9204\tTriple Loss(1): 0.3578\tClassification Loss: 1.2049\n",
      "Train Epoch: 3 [50240/110534 (45%)]\tAll Loss: 1.9564\tTriple Loss(1): 0.3390\tClassification Loss: 1.2785\n",
      "Train Epoch: 3 [50560/110534 (46%)]\tAll Loss: 2.3836\tTriple Loss(1): 0.3028\tClassification Loss: 1.7781\n",
      "Train Epoch: 3 [50880/110534 (46%)]\tAll Loss: 2.3294\tTriple Loss(1): 0.3235\tClassification Loss: 1.6824\n",
      "\n",
      "Test set: Average loss: 1.6281, Accuracy: 560/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [51200/110534 (46%)]\tAll Loss: 1.4515\tTriple Loss(0): 0.0000\tClassification Loss: 1.4515\n",
      "Train Epoch: 3 [51520/110534 (47%)]\tAll Loss: 2.0303\tTriple Loss(1): 0.3244\tClassification Loss: 1.3816\n",
      "Train Epoch: 3 [51840/110534 (47%)]\tAll Loss: 1.9317\tTriple Loss(1): 0.1772\tClassification Loss: 1.5773\n",
      "Train Epoch: 3 [52160/110534 (47%)]\tAll Loss: 2.1229\tTriple Loss(1): 0.2072\tClassification Loss: 1.7084\n",
      "Train Epoch: 3 [52480/110534 (47%)]\tAll Loss: 2.8164\tTriple Loss(1): 0.2314\tClassification Loss: 2.3536\n",
      "Train Epoch: 3 [52800/110534 (48%)]\tAll Loss: 1.3932\tTriple Loss(0): 0.0000\tClassification Loss: 1.3932\n",
      "Train Epoch: 3 [53120/110534 (48%)]\tAll Loss: 2.0384\tTriple Loss(1): 0.2116\tClassification Loss: 1.6152\n",
      "Train Epoch: 3 [53440/110534 (48%)]\tAll Loss: 2.2906\tTriple Loss(1): 0.2513\tClassification Loss: 1.7880\n",
      "Train Epoch: 3 [53760/110534 (49%)]\tAll Loss: 1.9553\tTriple Loss(1): 0.1013\tClassification Loss: 1.7526\n",
      "Train Epoch: 3 [54080/110534 (49%)]\tAll Loss: 2.4975\tTriple Loss(1): 0.2097\tClassification Loss: 2.0781\n",
      "\n",
      "Test set: Average loss: 1.6343, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [54400/110534 (49%)]\tAll Loss: 2.2396\tTriple Loss(1): 0.1844\tClassification Loss: 1.8708\n",
      "Train Epoch: 3 [54720/110534 (49%)]\tAll Loss: 2.0620\tTriple Loss(1): 0.1597\tClassification Loss: 1.7426\n",
      "Train Epoch: 3 [55040/110534 (50%)]\tAll Loss: 2.2182\tTriple Loss(1): 0.1242\tClassification Loss: 1.9698\n",
      "Train Epoch: 3 [55360/110534 (50%)]\tAll Loss: 2.2291\tTriple Loss(1): 0.3018\tClassification Loss: 1.6255\n",
      "Train Epoch: 3 [55680/110534 (50%)]\tAll Loss: 2.3113\tTriple Loss(1): 0.2009\tClassification Loss: 1.9096\n",
      "Train Epoch: 3 [56000/110534 (51%)]\tAll Loss: 2.5859\tTriple Loss(1): 0.2457\tClassification Loss: 2.0945\n",
      "Train Epoch: 3 [56320/110534 (51%)]\tAll Loss: 2.3593\tTriple Loss(1): 0.3034\tClassification Loss: 1.7525\n",
      "Train Epoch: 3 [56640/110534 (51%)]\tAll Loss: 1.6820\tTriple Loss(1): 0.2259\tClassification Loss: 1.2303\n",
      "Train Epoch: 3 [56960/110534 (52%)]\tAll Loss: 1.5436\tTriple Loss(0): 0.0000\tClassification Loss: 1.5436\n",
      "Train Epoch: 3 [57280/110534 (52%)]\tAll Loss: 2.0458\tTriple Loss(1): 0.0676\tClassification Loss: 1.9107\n",
      "\n",
      "Test set: Average loss: 1.6301, Accuracy: 555/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [57600/110534 (52%)]\tAll Loss: 2.2502\tTriple Loss(1): 0.2137\tClassification Loss: 1.8229\n",
      "Train Epoch: 3 [57920/110534 (52%)]\tAll Loss: 1.7763\tTriple Loss(1): 0.0711\tClassification Loss: 1.6341\n",
      "Train Epoch: 3 [58240/110534 (53%)]\tAll Loss: 2.2550\tTriple Loss(1): 0.4140\tClassification Loss: 1.4270\n",
      "Train Epoch: 3 [58560/110534 (53%)]\tAll Loss: 2.1723\tTriple Loss(1): 0.3453\tClassification Loss: 1.4817\n",
      "Train Epoch: 3 [58880/110534 (53%)]\tAll Loss: 1.6535\tTriple Loss(0): 0.0000\tClassification Loss: 1.6535\n",
      "Train Epoch: 3 [59200/110534 (54%)]\tAll Loss: 2.2643\tTriple Loss(1): 0.1647\tClassification Loss: 1.9349\n",
      "Train Epoch: 3 [59520/110534 (54%)]\tAll Loss: 2.0145\tTriple Loss(0): 0.2686\tClassification Loss: 1.4773\n",
      "Train Epoch: 3 [59840/110534 (54%)]\tAll Loss: 2.2136\tTriple Loss(1): 0.3250\tClassification Loss: 1.5636\n",
      "Train Epoch: 3 [60160/110534 (54%)]\tAll Loss: 2.4810\tTriple Loss(0): 0.5369\tClassification Loss: 1.4072\n",
      "Train Epoch: 3 [60480/110534 (55%)]\tAll Loss: 1.6357\tTriple Loss(0): 0.0000\tClassification Loss: 1.6357\n",
      "\n",
      "Test set: Average loss: 1.6252, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [60800/110534 (55%)]\tAll Loss: 2.0973\tTriple Loss(1): 0.1624\tClassification Loss: 1.7725\n",
      "Train Epoch: 3 [61120/110534 (55%)]\tAll Loss: 2.3301\tTriple Loss(1): 0.2503\tClassification Loss: 1.8295\n",
      "Train Epoch: 3 [61440/110534 (56%)]\tAll Loss: 1.4669\tTriple Loss(1): 0.1950\tClassification Loss: 1.0768\n",
      "Train Epoch: 3 [61760/110534 (56%)]\tAll Loss: 2.2899\tTriple Loss(1): 0.2767\tClassification Loss: 1.7364\n",
      "Train Epoch: 3 [62080/110534 (56%)]\tAll Loss: 2.1694\tTriple Loss(1): 0.3168\tClassification Loss: 1.5358\n",
      "Train Epoch: 3 [62400/110534 (56%)]\tAll Loss: 2.1228\tTriple Loss(1): 0.1726\tClassification Loss: 1.7776\n",
      "Train Epoch: 3 [62720/110534 (57%)]\tAll Loss: 2.0449\tTriple Loss(1): 0.2825\tClassification Loss: 1.4800\n",
      "Train Epoch: 3 [63040/110534 (57%)]\tAll Loss: 2.3214\tTriple Loss(1): 0.2305\tClassification Loss: 1.8605\n",
      "Train Epoch: 3 [63360/110534 (57%)]\tAll Loss: 1.5930\tTriple Loss(0): 0.0000\tClassification Loss: 1.5930\n",
      "Train Epoch: 3 [63680/110534 (58%)]\tAll Loss: 1.6754\tTriple Loss(1): 0.0742\tClassification Loss: 1.5271\n",
      "\n",
      "Test set: Average loss: 1.6292, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [64000/110534 (58%)]\tAll Loss: 3.0538\tTriple Loss(1): 0.3916\tClassification Loss: 2.2706\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_2000.pth.tar\n",
      "Train Epoch: 3 [64320/110534 (58%)]\tAll Loss: 1.7263\tTriple Loss(1): 0.2333\tClassification Loss: 1.2598\n",
      "Train Epoch: 3 [64640/110534 (58%)]\tAll Loss: 3.1154\tTriple Loss(1): 0.3322\tClassification Loss: 2.4511\n",
      "Train Epoch: 3 [64960/110534 (59%)]\tAll Loss: 2.0358\tTriple Loss(1): 0.2198\tClassification Loss: 1.5961\n",
      "Train Epoch: 3 [65280/110534 (59%)]\tAll Loss: 2.3008\tTriple Loss(1): 0.2593\tClassification Loss: 1.7821\n",
      "Train Epoch: 3 [65600/110534 (59%)]\tAll Loss: 1.9665\tTriple Loss(1): 0.1795\tClassification Loss: 1.6074\n",
      "Train Epoch: 3 [65920/110534 (60%)]\tAll Loss: 2.3238\tTriple Loss(1): 0.3190\tClassification Loss: 1.6857\n",
      "Train Epoch: 3 [66240/110534 (60%)]\tAll Loss: 1.5704\tTriple Loss(0): 0.0000\tClassification Loss: 1.5704\n",
      "Train Epoch: 3 [66560/110534 (60%)]\tAll Loss: 1.5376\tTriple Loss(1): 0.1062\tClassification Loss: 1.3253\n",
      "Train Epoch: 3 [66880/110534 (60%)]\tAll Loss: 2.0282\tTriple Loss(1): 0.1186\tClassification Loss: 1.7910\n",
      "\n",
      "Test set: Average loss: 1.6257, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [67200/110534 (61%)]\tAll Loss: 2.1903\tTriple Loss(1): 0.2226\tClassification Loss: 1.7452\n",
      "Train Epoch: 3 [67520/110534 (61%)]\tAll Loss: 2.4715\tTriple Loss(1): 0.2599\tClassification Loss: 1.9517\n",
      "Train Epoch: 3 [67840/110534 (61%)]\tAll Loss: 1.9117\tTriple Loss(0): 0.0000\tClassification Loss: 1.9117\n",
      "Train Epoch: 3 [68160/110534 (62%)]\tAll Loss: 1.5613\tTriple Loss(1): 0.0740\tClassification Loss: 1.4133\n",
      "Train Epoch: 3 [68480/110534 (62%)]\tAll Loss: 1.8814\tTriple Loss(1): 0.2353\tClassification Loss: 1.4107\n",
      "Train Epoch: 3 [68800/110534 (62%)]\tAll Loss: 2.3777\tTriple Loss(0): 0.5468\tClassification Loss: 1.2841\n",
      "Train Epoch: 3 [69120/110534 (63%)]\tAll Loss: 11.8949\tTriple Loss(0): 5.1917\tClassification Loss: 1.5115\n",
      "Train Epoch: 3 [69440/110534 (63%)]\tAll Loss: 2.0683\tTriple Loss(1): 0.2568\tClassification Loss: 1.5547\n",
      "Train Epoch: 3 [69760/110534 (63%)]\tAll Loss: 2.0952\tTriple Loss(1): 0.1475\tClassification Loss: 1.8003\n",
      "Train Epoch: 3 [70080/110534 (63%)]\tAll Loss: 1.5824\tTriple Loss(0): 0.0000\tClassification Loss: 1.5824\n",
      "\n",
      "Test set: Average loss: 1.6151, Accuracy: 560/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [70400/110534 (64%)]\tAll Loss: 1.7463\tTriple Loss(1): 0.1076\tClassification Loss: 1.5311\n",
      "Train Epoch: 3 [70720/110534 (64%)]\tAll Loss: 1.3627\tTriple Loss(0): 0.0000\tClassification Loss: 1.3627\n",
      "Train Epoch: 3 [71040/110534 (64%)]\tAll Loss: 1.9133\tTriple Loss(1): 0.1860\tClassification Loss: 1.5414\n",
      "Train Epoch: 3 [71360/110534 (65%)]\tAll Loss: 2.1963\tTriple Loss(1): 0.2752\tClassification Loss: 1.6460\n",
      "Train Epoch: 3 [71680/110534 (65%)]\tAll Loss: 1.8167\tTriple Loss(1): 0.1437\tClassification Loss: 1.5293\n",
      "Train Epoch: 3 [72000/110534 (65%)]\tAll Loss: 2.1869\tTriple Loss(1): 0.2321\tClassification Loss: 1.7227\n",
      "Train Epoch: 3 [72320/110534 (65%)]\tAll Loss: 1.4786\tTriple Loss(0): 0.0000\tClassification Loss: 1.4786\n",
      "Train Epoch: 3 [72640/110534 (66%)]\tAll Loss: 1.8234\tTriple Loss(1): 0.2448\tClassification Loss: 1.3338\n",
      "Train Epoch: 3 [72960/110534 (66%)]\tAll Loss: 1.6790\tTriple Loss(1): 0.1109\tClassification Loss: 1.4571\n",
      "Train Epoch: 3 [73280/110534 (66%)]\tAll Loss: 1.6978\tTriple Loss(1): 0.2081\tClassification Loss: 1.2816\n",
      "\n",
      "Test set: Average loss: 1.6185, Accuracy: 550/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [73600/110534 (67%)]\tAll Loss: 2.8201\tTriple Loss(1): 0.2554\tClassification Loss: 2.3093\n",
      "Train Epoch: 3 [73920/110534 (67%)]\tAll Loss: 2.2153\tTriple Loss(1): 0.1019\tClassification Loss: 2.0114\n",
      "Train Epoch: 3 [74240/110534 (67%)]\tAll Loss: 1.3148\tTriple Loss(0): 0.0000\tClassification Loss: 1.3148\n",
      "Train Epoch: 3 [74560/110534 (67%)]\tAll Loss: 2.0693\tTriple Loss(1): 0.2190\tClassification Loss: 1.6312\n",
      "Train Epoch: 3 [74880/110534 (68%)]\tAll Loss: 1.8192\tTriple Loss(0): 0.0000\tClassification Loss: 1.8192\n",
      "Train Epoch: 3 [75200/110534 (68%)]\tAll Loss: 1.9503\tTriple Loss(1): 0.2487\tClassification Loss: 1.4530\n",
      "Train Epoch: 3 [75520/110534 (68%)]\tAll Loss: 1.8273\tTriple Loss(1): 0.1392\tClassification Loss: 1.5489\n",
      "Train Epoch: 3 [75840/110534 (69%)]\tAll Loss: 1.6608\tTriple Loss(0): 0.0000\tClassification Loss: 1.6608\n",
      "Train Epoch: 3 [76160/110534 (69%)]\tAll Loss: 1.8226\tTriple Loss(1): 0.1005\tClassification Loss: 1.6215\n",
      "Train Epoch: 3 [76480/110534 (69%)]\tAll Loss: 2.0707\tTriple Loss(1): 0.3536\tClassification Loss: 1.3635\n",
      "\n",
      "Test set: Average loss: 1.6147, Accuracy: 554/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [76800/110534 (69%)]\tAll Loss: 2.1622\tTriple Loss(1): 0.3161\tClassification Loss: 1.5301\n",
      "Train Epoch: 3 [77120/110534 (70%)]\tAll Loss: 1.9641\tTriple Loss(1): 0.1861\tClassification Loss: 1.5919\n",
      "Train Epoch: 3 [77440/110534 (70%)]\tAll Loss: 2.0775\tTriple Loss(1): 0.1514\tClassification Loss: 1.7746\n",
      "Train Epoch: 3 [77760/110534 (70%)]\tAll Loss: 1.8946\tTriple Loss(1): 0.2338\tClassification Loss: 1.4271\n",
      "Train Epoch: 3 [78080/110534 (71%)]\tAll Loss: 2.7158\tTriple Loss(1): 0.3252\tClassification Loss: 2.0653\n",
      "Train Epoch: 3 [78400/110534 (71%)]\tAll Loss: 1.8315\tTriple Loss(1): 0.1976\tClassification Loss: 1.4363\n",
      "Train Epoch: 3 [78720/110534 (71%)]\tAll Loss: 1.2295\tTriple Loss(0): 0.0000\tClassification Loss: 1.2295\n",
      "Train Epoch: 3 [79040/110534 (71%)]\tAll Loss: 2.2809\tTriple Loss(1): 0.2479\tClassification Loss: 1.7852\n",
      "Train Epoch: 3 [79360/110534 (72%)]\tAll Loss: 1.9516\tTriple Loss(0): 0.0000\tClassification Loss: 1.9516\n",
      "Train Epoch: 3 [79680/110534 (72%)]\tAll Loss: 1.5644\tTriple Loss(1): 0.0594\tClassification Loss: 1.4456\n",
      "\n",
      "Test set: Average loss: 1.6144, Accuracy: 547/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [80000/110534 (72%)]\tAll Loss: 2.0505\tTriple Loss(1): 0.2476\tClassification Loss: 1.5553\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_2500.pth.tar\n",
      "Train Epoch: 3 [80320/110534 (73%)]\tAll Loss: 1.1478\tTriple Loss(0): 0.0000\tClassification Loss: 1.1478\n",
      "Train Epoch: 3 [80640/110534 (73%)]\tAll Loss: 1.7865\tTriple Loss(1): 0.1950\tClassification Loss: 1.3965\n",
      "Train Epoch: 3 [80960/110534 (73%)]\tAll Loss: 2.0770\tTriple Loss(1): 0.2439\tClassification Loss: 1.5893\n",
      "Train Epoch: 3 [81280/110534 (74%)]\tAll Loss: 1.6787\tTriple Loss(1): 0.1545\tClassification Loss: 1.3697\n",
      "Train Epoch: 3 [81600/110534 (74%)]\tAll Loss: 1.9507\tTriple Loss(1): 0.2588\tClassification Loss: 1.4331\n",
      "Train Epoch: 3 [81920/110534 (74%)]\tAll Loss: 2.1382\tTriple Loss(1): 0.1786\tClassification Loss: 1.7810\n",
      "Train Epoch: 3 [82240/110534 (74%)]\tAll Loss: 1.9644\tTriple Loss(1): 0.1600\tClassification Loss: 1.6444\n",
      "Train Epoch: 3 [82560/110534 (75%)]\tAll Loss: 1.9499\tTriple Loss(1): 0.1929\tClassification Loss: 1.5642\n",
      "Train Epoch: 3 [82880/110534 (75%)]\tAll Loss: 2.2308\tTriple Loss(1): 0.1992\tClassification Loss: 1.8324\n",
      "\n",
      "Test set: Average loss: 1.6172, Accuracy: 550/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [83200/110534 (75%)]\tAll Loss: 2.1292\tTriple Loss(1): 0.2177\tClassification Loss: 1.6938\n",
      "Train Epoch: 3 [83520/110534 (76%)]\tAll Loss: 1.4743\tTriple Loss(0): 0.0000\tClassification Loss: 1.4743\n",
      "Train Epoch: 3 [83840/110534 (76%)]\tAll Loss: 2.4492\tTriple Loss(1): 0.4035\tClassification Loss: 1.6422\n",
      "Train Epoch: 3 [84160/110534 (76%)]\tAll Loss: 1.7572\tTriple Loss(1): 0.2667\tClassification Loss: 1.2238\n",
      "Train Epoch: 3 [84480/110534 (76%)]\tAll Loss: 1.4341\tTriple Loss(0): 0.0000\tClassification Loss: 1.4341\n",
      "Train Epoch: 3 [84800/110534 (77%)]\tAll Loss: 2.0831\tTriple Loss(1): 0.1803\tClassification Loss: 1.7226\n",
      "Train Epoch: 3 [85120/110534 (77%)]\tAll Loss: 2.1895\tTriple Loss(1): 0.4047\tClassification Loss: 1.3800\n",
      "Train Epoch: 3 [85440/110534 (77%)]\tAll Loss: 1.1450\tTriple Loss(0): 0.0000\tClassification Loss: 1.1450\n",
      "Train Epoch: 3 [85760/110534 (78%)]\tAll Loss: 2.0557\tTriple Loss(1): 0.2168\tClassification Loss: 1.6220\n",
      "Train Epoch: 3 [86080/110534 (78%)]\tAll Loss: 1.7505\tTriple Loss(0): 0.0000\tClassification Loss: 1.7505\n",
      "\n",
      "Test set: Average loss: 1.6118, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [86400/110534 (78%)]\tAll Loss: 2.3783\tTriple Loss(1): 0.1696\tClassification Loss: 2.0392\n",
      "Train Epoch: 3 [86720/110534 (78%)]\tAll Loss: 1.2384\tTriple Loss(0): 0.0000\tClassification Loss: 1.2384\n",
      "Train Epoch: 3 [87040/110534 (79%)]\tAll Loss: 1.5438\tTriple Loss(0): 0.0000\tClassification Loss: 1.5438\n",
      "Train Epoch: 3 [87360/110534 (79%)]\tAll Loss: 2.3095\tTriple Loss(1): 0.2727\tClassification Loss: 1.7641\n",
      "Train Epoch: 3 [87680/110534 (79%)]\tAll Loss: 1.9177\tTriple Loss(1): 0.2096\tClassification Loss: 1.4984\n",
      "Train Epoch: 3 [88000/110534 (80%)]\tAll Loss: 2.0831\tTriple Loss(0): 0.0000\tClassification Loss: 2.0831\n",
      "Train Epoch: 3 [88320/110534 (80%)]\tAll Loss: 1.8857\tTriple Loss(1): 0.1446\tClassification Loss: 1.5965\n",
      "Train Epoch: 3 [88640/110534 (80%)]\tAll Loss: 1.9323\tTriple Loss(0): 0.0000\tClassification Loss: 1.9323\n",
      "Train Epoch: 3 [88960/110534 (80%)]\tAll Loss: 2.5407\tTriple Loss(1): 0.3541\tClassification Loss: 1.8324\n",
      "Train Epoch: 3 [89280/110534 (81%)]\tAll Loss: 1.5860\tTriple Loss(1): 0.0843\tClassification Loss: 1.4173\n",
      "\n",
      "Test set: Average loss: 1.6076, Accuracy: 555/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [89600/110534 (81%)]\tAll Loss: 2.0985\tTriple Loss(0): 0.0000\tClassification Loss: 2.0985\n",
      "Train Epoch: 3 [89920/110534 (81%)]\tAll Loss: 2.3212\tTriple Loss(1): 0.2344\tClassification Loss: 1.8523\n",
      "Train Epoch: 3 [90240/110534 (82%)]\tAll Loss: 1.6913\tTriple Loss(1): 0.1502\tClassification Loss: 1.3908\n",
      "Train Epoch: 3 [90560/110534 (82%)]\tAll Loss: 1.7004\tTriple Loss(1): 0.1354\tClassification Loss: 1.4296\n",
      "Train Epoch: 3 [90880/110534 (82%)]\tAll Loss: 2.5980\tTriple Loss(1): 0.4080\tClassification Loss: 1.7819\n",
      "Train Epoch: 3 [91200/110534 (82%)]\tAll Loss: 2.1935\tTriple Loss(1): 0.3464\tClassification Loss: 1.5006\n",
      "Train Epoch: 3 [91520/110534 (83%)]\tAll Loss: 2.7347\tTriple Loss(1): 0.5830\tClassification Loss: 1.5688\n",
      "Train Epoch: 3 [91840/110534 (83%)]\tAll Loss: 2.1010\tTriple Loss(1): 0.2340\tClassification Loss: 1.6331\n",
      "Train Epoch: 3 [92160/110534 (83%)]\tAll Loss: 2.0085\tTriple Loss(0): 0.0000\tClassification Loss: 2.0085\n",
      "Train Epoch: 3 [92480/110534 (84%)]\tAll Loss: 1.9461\tTriple Loss(1): 0.1932\tClassification Loss: 1.5598\n",
      "\n",
      "Test set: Average loss: 1.6155, Accuracy: 551/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [92800/110534 (84%)]\tAll Loss: 1.5008\tTriple Loss(0): 0.0000\tClassification Loss: 1.5008\n",
      "Train Epoch: 3 [93120/110534 (84%)]\tAll Loss: 2.3300\tTriple Loss(1): 0.2869\tClassification Loss: 1.7563\n",
      "Train Epoch: 3 [93440/110534 (85%)]\tAll Loss: 2.2402\tTriple Loss(1): 0.3373\tClassification Loss: 1.5655\n",
      "Train Epoch: 3 [93760/110534 (85%)]\tAll Loss: 1.4289\tTriple Loss(0): 0.0000\tClassification Loss: 1.4289\n",
      "Train Epoch: 3 [94080/110534 (85%)]\tAll Loss: 1.9068\tTriple Loss(1): 0.1801\tClassification Loss: 1.5466\n",
      "Train Epoch: 3 [94400/110534 (85%)]\tAll Loss: 2.2672\tTriple Loss(1): 0.2430\tClassification Loss: 1.7813\n",
      "Train Epoch: 3 [94720/110534 (86%)]\tAll Loss: 1.9643\tTriple Loss(1): 0.1864\tClassification Loss: 1.5915\n",
      "Train Epoch: 3 [95040/110534 (86%)]\tAll Loss: 2.0011\tTriple Loss(1): 0.1701\tClassification Loss: 1.6609\n",
      "Train Epoch: 3 [95360/110534 (86%)]\tAll Loss: 2.4574\tTriple Loss(1): 0.4822\tClassification Loss: 1.4931\n",
      "Train Epoch: 3 [95680/110534 (87%)]\tAll Loss: 2.1804\tTriple Loss(1): 0.2329\tClassification Loss: 1.7146\n",
      "\n",
      "Test set: Average loss: 1.6164, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [96000/110534 (87%)]\tAll Loss: 1.6168\tTriple Loss(1): 0.1377\tClassification Loss: 1.3414\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_3000.pth.tar\n",
      "Train Epoch: 3 [96320/110534 (87%)]\tAll Loss: 1.4745\tTriple Loss(0): 0.0000\tClassification Loss: 1.4745\n",
      "Train Epoch: 3 [96640/110534 (87%)]\tAll Loss: 1.8507\tTriple Loss(1): 0.0667\tClassification Loss: 1.7172\n",
      "Train Epoch: 3 [96960/110534 (88%)]\tAll Loss: 1.8136\tTriple Loss(1): 0.2362\tClassification Loss: 1.3411\n",
      "Train Epoch: 3 [97280/110534 (88%)]\tAll Loss: 1.6458\tTriple Loss(1): 0.1205\tClassification Loss: 1.4048\n",
      "Train Epoch: 3 [97600/110534 (88%)]\tAll Loss: 1.7890\tTriple Loss(0): 0.0763\tClassification Loss: 1.6364\n",
      "Train Epoch: 3 [97920/110534 (89%)]\tAll Loss: 1.2719\tTriple Loss(0): 0.0000\tClassification Loss: 1.2719\n",
      "Train Epoch: 3 [98240/110534 (89%)]\tAll Loss: 1.4392\tTriple Loss(1): 0.0829\tClassification Loss: 1.2735\n",
      "Train Epoch: 3 [98560/110534 (89%)]\tAll Loss: 1.3552\tTriple Loss(0): 0.0000\tClassification Loss: 1.3552\n",
      "Train Epoch: 3 [98880/110534 (89%)]\tAll Loss: 2.1221\tTriple Loss(1): 0.3400\tClassification Loss: 1.4421\n",
      "\n",
      "Test set: Average loss: 1.6239, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [99200/110534 (90%)]\tAll Loss: 2.6382\tTriple Loss(1): 0.5282\tClassification Loss: 1.5817\n",
      "Train Epoch: 3 [99520/110534 (90%)]\tAll Loss: 1.8999\tTriple Loss(1): 0.1222\tClassification Loss: 1.6554\n",
      "Train Epoch: 3 [99840/110534 (90%)]\tAll Loss: 2.0371\tTriple Loss(1): 0.2075\tClassification Loss: 1.6221\n",
      "Train Epoch: 3 [100160/110534 (91%)]\tAll Loss: 2.5638\tTriple Loss(1): 0.3251\tClassification Loss: 1.9136\n",
      "Train Epoch: 3 [100480/110534 (91%)]\tAll Loss: 2.0411\tTriple Loss(1): 0.3208\tClassification Loss: 1.3995\n",
      "Train Epoch: 3 [100800/110534 (91%)]\tAll Loss: 2.6828\tTriple Loss(1): 0.3388\tClassification Loss: 2.0052\n",
      "Train Epoch: 3 [101120/110534 (91%)]\tAll Loss: 1.8462\tTriple Loss(1): 0.1878\tClassification Loss: 1.4707\n",
      "Train Epoch: 3 [101440/110534 (92%)]\tAll Loss: 1.6994\tTriple Loss(1): 0.1926\tClassification Loss: 1.3142\n",
      "Train Epoch: 3 [101760/110534 (92%)]\tAll Loss: 2.0764\tTriple Loss(1): 0.1943\tClassification Loss: 1.6878\n",
      "Train Epoch: 3 [102080/110534 (92%)]\tAll Loss: 2.6985\tTriple Loss(1): 0.3695\tClassification Loss: 1.9595\n",
      "\n",
      "Test set: Average loss: 1.6157, Accuracy: 542/960 (56%)\n",
      "\n",
      "Train Epoch: 3 [102400/110534 (93%)]\tAll Loss: 1.9388\tTriple Loss(1): 0.0979\tClassification Loss: 1.7431\n",
      "Train Epoch: 3 [102720/110534 (93%)]\tAll Loss: 2.2306\tTriple Loss(1): 0.2005\tClassification Loss: 1.8295\n",
      "Train Epoch: 3 [103040/110534 (93%)]\tAll Loss: 2.1076\tTriple Loss(1): 0.2692\tClassification Loss: 1.5693\n",
      "Train Epoch: 3 [103360/110534 (93%)]\tAll Loss: 1.9942\tTriple Loss(1): 0.1480\tClassification Loss: 1.6983\n",
      "Train Epoch: 3 [103680/110534 (94%)]\tAll Loss: 2.4466\tTriple Loss(1): 0.3272\tClassification Loss: 1.7922\n",
      "Train Epoch: 3 [104000/110534 (94%)]\tAll Loss: 2.1344\tTriple Loss(1): 0.3220\tClassification Loss: 1.4903\n",
      "Train Epoch: 3 [104320/110534 (94%)]\tAll Loss: 2.1739\tTriple Loss(0): 0.0000\tClassification Loss: 2.1739\n",
      "Train Epoch: 3 [104640/110534 (95%)]\tAll Loss: 1.9766\tTriple Loss(0): 0.0000\tClassification Loss: 1.9766\n",
      "Train Epoch: 3 [104960/110534 (95%)]\tAll Loss: 1.9880\tTriple Loss(1): 0.2906\tClassification Loss: 1.4069\n",
      "Train Epoch: 3 [105280/110534 (95%)]\tAll Loss: 2.5649\tTriple Loss(1): 0.4854\tClassification Loss: 1.5940\n",
      "\n",
      "Test set: Average loss: 1.6166, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 3 [105600/110534 (96%)]\tAll Loss: 2.0278\tTriple Loss(1): 0.1926\tClassification Loss: 1.6426\n",
      "Train Epoch: 3 [105920/110534 (96%)]\tAll Loss: 2.0284\tTriple Loss(1): 0.1864\tClassification Loss: 1.6557\n",
      "Train Epoch: 3 [106240/110534 (96%)]\tAll Loss: 1.5826\tTriple Loss(1): 0.1594\tClassification Loss: 1.2639\n",
      "Train Epoch: 3 [106560/110534 (96%)]\tAll Loss: 2.1635\tTriple Loss(1): 0.2631\tClassification Loss: 1.6373\n",
      "Train Epoch: 3 [106880/110534 (97%)]\tAll Loss: 2.3258\tTriple Loss(1): 0.1864\tClassification Loss: 1.9529\n",
      "Train Epoch: 3 [107200/110534 (97%)]\tAll Loss: 1.7433\tTriple Loss(0): 0.0000\tClassification Loss: 1.7433\n",
      "Train Epoch: 3 [107520/110534 (97%)]\tAll Loss: 1.7301\tTriple Loss(0): 0.0000\tClassification Loss: 1.7301\n",
      "Train Epoch: 3 [107840/110534 (98%)]\tAll Loss: 1.4623\tTriple Loss(0): 0.0000\tClassification Loss: 1.4623\n",
      "Train Epoch: 3 [108160/110534 (98%)]\tAll Loss: 1.7753\tTriple Loss(1): 0.2587\tClassification Loss: 1.2580\n",
      "Train Epoch: 3 [108480/110534 (98%)]\tAll Loss: 2.4207\tTriple Loss(1): 0.4230\tClassification Loss: 1.5748\n",
      "\n",
      "Test set: Average loss: 1.6027, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 3 [108800/110534 (98%)]\tAll Loss: 1.6664\tTriple Loss(1): 0.1057\tClassification Loss: 1.4551\n",
      "Train Epoch: 3 [109120/110534 (99%)]\tAll Loss: 2.1947\tTriple Loss(1): 0.1654\tClassification Loss: 1.8640\n",
      "Train Epoch: 3 [109440/110534 (99%)]\tAll Loss: 1.6944\tTriple Loss(1): 0.1878\tClassification Loss: 1.3188\n",
      "Train Epoch: 3 [109760/110534 (99%)]\tAll Loss: 1.9214\tTriple Loss(1): 0.1521\tClassification Loss: 1.6173\n",
      "Train Epoch: 3 [110080/110534 (100%)]\tAll Loss: 1.8071\tTriple Loss(1): 0.1050\tClassification Loss: 1.5970\n",
      "Train Epoch: 3 [110400/110534 (100%)]\tAll Loss: 2.4242\tTriple Loss(1): 0.3726\tClassification Loss: 1.6790\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_3_final.pth.tar\n",
      "\n",
      "Test set: Average loss: 1.6079, Accuracy: 550/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [0/110534 (0%)]\tAll Loss: 1.6143\tTriple Loss(0): 0.0000\tClassification Loss: 1.6143\n",
      "Train Epoch: 4 [320/110534 (0%)]\tAll Loss: 1.5282\tTriple Loss(0): 0.0000\tClassification Loss: 1.5282\n",
      "Train Epoch: 4 [640/110534 (1%)]\tAll Loss: 1.4718\tTriple Loss(1): 0.2255\tClassification Loss: 1.0208\n",
      "Train Epoch: 4 [960/110534 (1%)]\tAll Loss: 2.0784\tTriple Loss(0): 0.0000\tClassification Loss: 2.0784\n",
      "Train Epoch: 4 [1280/110534 (1%)]\tAll Loss: 2.0765\tTriple Loss(1): 0.2275\tClassification Loss: 1.6215\n",
      "Train Epoch: 4 [1600/110534 (1%)]\tAll Loss: 2.2020\tTriple Loss(1): 0.1992\tClassification Loss: 1.8037\n",
      "Train Epoch: 4 [1920/110534 (2%)]\tAll Loss: 2.2470\tTriple Loss(1): 0.1846\tClassification Loss: 1.8777\n",
      "Train Epoch: 4 [2240/110534 (2%)]\tAll Loss: 2.0864\tTriple Loss(1): 0.2609\tClassification Loss: 1.5647\n",
      "Train Epoch: 4 [2560/110534 (2%)]\tAll Loss: 1.7710\tTriple Loss(1): 0.0825\tClassification Loss: 1.6060\n",
      "Train Epoch: 4 [2880/110534 (3%)]\tAll Loss: 2.4915\tTriple Loss(1): 0.3874\tClassification Loss: 1.7167\n",
      "\n",
      "Test set: Average loss: 1.6108, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [3200/110534 (3%)]\tAll Loss: 2.2865\tTriple Loss(1): 0.1099\tClassification Loss: 2.0667\n",
      "Train Epoch: 4 [3520/110534 (3%)]\tAll Loss: 1.6985\tTriple Loss(1): 0.2248\tClassification Loss: 1.2490\n",
      "Train Epoch: 4 [3840/110534 (3%)]\tAll Loss: 1.9458\tTriple Loss(1): 0.1119\tClassification Loss: 1.7220\n",
      "Train Epoch: 4 [4160/110534 (4%)]\tAll Loss: 1.9680\tTriple Loss(1): 0.1429\tClassification Loss: 1.6822\n",
      "Train Epoch: 4 [4480/110534 (4%)]\tAll Loss: 1.9162\tTriple Loss(1): 0.2272\tClassification Loss: 1.4618\n",
      "Train Epoch: 4 [4800/110534 (4%)]\tAll Loss: 1.9294\tTriple Loss(1): 0.2557\tClassification Loss: 1.4180\n",
      "Train Epoch: 4 [5120/110534 (5%)]\tAll Loss: 2.0178\tTriple Loss(1): 0.0698\tClassification Loss: 1.8782\n",
      "Train Epoch: 4 [5440/110534 (5%)]\tAll Loss: 2.5363\tTriple Loss(1): 0.5070\tClassification Loss: 1.5224\n",
      "Train Epoch: 4 [5760/110534 (5%)]\tAll Loss: 1.7934\tTriple Loss(1): 0.2674\tClassification Loss: 1.2586\n",
      "Train Epoch: 4 [6080/110534 (5%)]\tAll Loss: 2.6046\tTriple Loss(1): 0.4923\tClassification Loss: 1.6200\n",
      "\n",
      "Test set: Average loss: 1.6040, Accuracy: 551/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [6400/110534 (6%)]\tAll Loss: 2.2226\tTriple Loss(1): 0.3075\tClassification Loss: 1.6076\n",
      "Train Epoch: 4 [6720/110534 (6%)]\tAll Loss: 2.1916\tTriple Loss(1): 0.2620\tClassification Loss: 1.6677\n",
      "Train Epoch: 4 [7040/110534 (6%)]\tAll Loss: 2.1920\tTriple Loss(1): 0.2000\tClassification Loss: 1.7921\n",
      "Train Epoch: 4 [7360/110534 (7%)]\tAll Loss: 1.8703\tTriple Loss(1): 0.2057\tClassification Loss: 1.4590\n",
      "Train Epoch: 4 [7680/110534 (7%)]\tAll Loss: 1.3664\tTriple Loss(1): 0.0864\tClassification Loss: 1.1935\n",
      "Train Epoch: 4 [8000/110534 (7%)]\tAll Loss: 1.9324\tTriple Loss(1): 0.3025\tClassification Loss: 1.3275\n",
      "Train Epoch: 4 [8320/110534 (8%)]\tAll Loss: 1.5880\tTriple Loss(1): 0.0443\tClassification Loss: 1.4994\n",
      "Train Epoch: 4 [8640/110534 (8%)]\tAll Loss: 1.2107\tTriple Loss(0): 0.0000\tClassification Loss: 1.2107\n",
      "Train Epoch: 4 [8960/110534 (8%)]\tAll Loss: 1.2963\tTriple Loss(0): 0.0000\tClassification Loss: 1.2963\n",
      "Train Epoch: 4 [9280/110534 (8%)]\tAll Loss: 1.3921\tTriple Loss(1): 0.0349\tClassification Loss: 1.3223\n",
      "\n",
      "Test set: Average loss: 1.6016, Accuracy: 554/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [9600/110534 (9%)]\tAll Loss: 1.9484\tTriple Loss(1): 0.0618\tClassification Loss: 1.8248\n",
      "Train Epoch: 4 [9920/110534 (9%)]\tAll Loss: 1.6882\tTriple Loss(0): 0.0000\tClassification Loss: 1.6882\n",
      "Train Epoch: 4 [10240/110534 (9%)]\tAll Loss: 2.3149\tTriple Loss(1): 0.2613\tClassification Loss: 1.7924\n",
      "Train Epoch: 4 [10560/110534 (10%)]\tAll Loss: 2.0079\tTriple Loss(1): 0.1805\tClassification Loss: 1.6469\n",
      "Train Epoch: 4 [10880/110534 (10%)]\tAll Loss: 2.1541\tTriple Loss(1): 0.1742\tClassification Loss: 1.8058\n",
      "Train Epoch: 4 [11200/110534 (10%)]\tAll Loss: 1.2090\tTriple Loss(0): 0.0000\tClassification Loss: 1.2090\n",
      "Train Epoch: 4 [11520/110534 (10%)]\tAll Loss: 1.6949\tTriple Loss(1): 0.1355\tClassification Loss: 1.4240\n",
      "Train Epoch: 4 [11840/110534 (11%)]\tAll Loss: 2.2563\tTriple Loss(1): 0.2764\tClassification Loss: 1.7035\n",
      "Train Epoch: 4 [12160/110534 (11%)]\tAll Loss: 1.9195\tTriple Loss(1): 0.1727\tClassification Loss: 1.5741\n",
      "Train Epoch: 4 [12480/110534 (11%)]\tAll Loss: 1.7369\tTriple Loss(0): 0.0000\tClassification Loss: 1.7369\n",
      "\n",
      "Test set: Average loss: 1.6025, Accuracy: 547/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [12800/110534 (12%)]\tAll Loss: 1.9491\tTriple Loss(1): 0.2992\tClassification Loss: 1.3506\n",
      "Train Epoch: 4 [13120/110534 (12%)]\tAll Loss: 1.6719\tTriple Loss(1): 0.1450\tClassification Loss: 1.3819\n",
      "Train Epoch: 4 [13440/110534 (12%)]\tAll Loss: 2.2059\tTriple Loss(1): 0.1689\tClassification Loss: 1.8681\n",
      "Train Epoch: 4 [13760/110534 (12%)]\tAll Loss: 1.9861\tTriple Loss(1): 0.1073\tClassification Loss: 1.7715\n",
      "Train Epoch: 4 [14080/110534 (13%)]\tAll Loss: 1.8783\tTriple Loss(0): 0.0000\tClassification Loss: 1.8783\n",
      "Train Epoch: 4 [14400/110534 (13%)]\tAll Loss: 2.7916\tTriple Loss(1): 0.3747\tClassification Loss: 2.0423\n",
      "Train Epoch: 4 [14720/110534 (13%)]\tAll Loss: 1.9012\tTriple Loss(1): 0.1365\tClassification Loss: 1.6282\n",
      "Train Epoch: 4 [15040/110534 (14%)]\tAll Loss: 2.0235\tTriple Loss(1): 0.2773\tClassification Loss: 1.4689\n",
      "Train Epoch: 4 [15360/110534 (14%)]\tAll Loss: 2.2557\tTriple Loss(1): 0.3413\tClassification Loss: 1.5732\n",
      "Train Epoch: 4 [15680/110534 (14%)]\tAll Loss: 1.6727\tTriple Loss(1): 0.2108\tClassification Loss: 1.2511\n",
      "\n",
      "Test set: Average loss: 1.6021, Accuracy: 544/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [16000/110534 (14%)]\tAll Loss: 1.9459\tTriple Loss(1): 0.1248\tClassification Loss: 1.6963\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_500.pth.tar\n",
      "Train Epoch: 4 [16320/110534 (15%)]\tAll Loss: 1.2675\tTriple Loss(0): 0.0000\tClassification Loss: 1.2675\n",
      "Train Epoch: 4 [16640/110534 (15%)]\tAll Loss: 1.9627\tTriple Loss(1): 0.1616\tClassification Loss: 1.6395\n",
      "Train Epoch: 4 [16960/110534 (15%)]\tAll Loss: 2.0852\tTriple Loss(1): 0.1504\tClassification Loss: 1.7844\n",
      "Train Epoch: 4 [17280/110534 (16%)]\tAll Loss: 1.7734\tTriple Loss(1): 0.1713\tClassification Loss: 1.4308\n",
      "Train Epoch: 4 [17600/110534 (16%)]\tAll Loss: 2.0336\tTriple Loss(1): 0.1905\tClassification Loss: 1.6527\n",
      "Train Epoch: 4 [17920/110534 (16%)]\tAll Loss: 2.0750\tTriple Loss(1): 0.1942\tClassification Loss: 1.6865\n",
      "Train Epoch: 4 [18240/110534 (16%)]\tAll Loss: 7.0800\tTriple Loss(0): 2.5153\tClassification Loss: 2.0494\n",
      "Train Epoch: 4 [18560/110534 (17%)]\tAll Loss: 1.5806\tTriple Loss(0): 0.0000\tClassification Loss: 1.5806\n",
      "Train Epoch: 4 [18880/110534 (17%)]\tAll Loss: 2.3235\tTriple Loss(1): 0.2706\tClassification Loss: 1.7824\n",
      "\n",
      "Test set: Average loss: 1.6059, Accuracy: 556/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [19200/110534 (17%)]\tAll Loss: 1.9615\tTriple Loss(1): 0.2957\tClassification Loss: 1.3700\n",
      "Train Epoch: 4 [19520/110534 (18%)]\tAll Loss: 1.5681\tTriple Loss(0): 0.0000\tClassification Loss: 1.5681\n",
      "Train Epoch: 4 [19840/110534 (18%)]\tAll Loss: 2.7177\tTriple Loss(0): 0.5612\tClassification Loss: 1.5954\n",
      "Train Epoch: 4 [20160/110534 (18%)]\tAll Loss: 1.3343\tTriple Loss(0): 0.0000\tClassification Loss: 1.3343\n",
      "Train Epoch: 4 [20480/110534 (19%)]\tAll Loss: 2.0395\tTriple Loss(1): 0.2844\tClassification Loss: 1.4708\n",
      "Train Epoch: 4 [20800/110534 (19%)]\tAll Loss: 2.4581\tTriple Loss(1): 0.2440\tClassification Loss: 1.9700\n",
      "Train Epoch: 4 [21120/110534 (19%)]\tAll Loss: 2.0580\tTriple Loss(1): 0.2701\tClassification Loss: 1.5178\n",
      "Train Epoch: 4 [21440/110534 (19%)]\tAll Loss: 1.7876\tTriple Loss(1): 0.1790\tClassification Loss: 1.4296\n",
      "Train Epoch: 4 [21760/110534 (20%)]\tAll Loss: 2.6684\tTriple Loss(1): 0.3029\tClassification Loss: 2.0626\n",
      "Train Epoch: 4 [22080/110534 (20%)]\tAll Loss: 1.9059\tTriple Loss(1): 0.1170\tClassification Loss: 1.6719\n",
      "\n",
      "Test set: Average loss: 1.6078, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [22400/110534 (20%)]\tAll Loss: 1.5224\tTriple Loss(0): 0.0000\tClassification Loss: 1.5224\n",
      "Train Epoch: 4 [22720/110534 (21%)]\tAll Loss: 1.9223\tTriple Loss(1): 0.1637\tClassification Loss: 1.5950\n",
      "Train Epoch: 4 [23040/110534 (21%)]\tAll Loss: 2.0793\tTriple Loss(1): 0.1404\tClassification Loss: 1.7986\n",
      "Train Epoch: 4 [23360/110534 (21%)]\tAll Loss: 1.8507\tTriple Loss(1): 0.2032\tClassification Loss: 1.4443\n",
      "Train Epoch: 4 [23680/110534 (21%)]\tAll Loss: 2.2691\tTriple Loss(1): 0.2072\tClassification Loss: 1.8546\n",
      "Train Epoch: 4 [24000/110534 (22%)]\tAll Loss: 1.9754\tTriple Loss(1): 0.1977\tClassification Loss: 1.5801\n",
      "Train Epoch: 4 [24320/110534 (22%)]\tAll Loss: 2.3338\tTriple Loss(1): 0.3313\tClassification Loss: 1.6712\n",
      "Train Epoch: 4 [24640/110534 (22%)]\tAll Loss: 2.4249\tTriple Loss(1): 0.2195\tClassification Loss: 1.9858\n",
      "Train Epoch: 4 [24960/110534 (23%)]\tAll Loss: 1.8664\tTriple Loss(1): 0.2435\tClassification Loss: 1.3795\n",
      "Train Epoch: 4 [25280/110534 (23%)]\tAll Loss: 1.6723\tTriple Loss(1): 0.0686\tClassification Loss: 1.5351\n",
      "\n",
      "Test set: Average loss: 1.6048, Accuracy: 555/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [25600/110534 (23%)]\tAll Loss: 1.5907\tTriple Loss(0): 0.0000\tClassification Loss: 1.5907\n",
      "Train Epoch: 4 [25920/110534 (23%)]\tAll Loss: 2.3169\tTriple Loss(1): 0.2936\tClassification Loss: 1.7297\n",
      "Train Epoch: 4 [26240/110534 (24%)]\tAll Loss: 2.2649\tTriple Loss(1): 0.3589\tClassification Loss: 1.5471\n",
      "Train Epoch: 4 [26560/110534 (24%)]\tAll Loss: 2.1117\tTriple Loss(1): 0.1522\tClassification Loss: 1.8073\n",
      "Train Epoch: 4 [26880/110534 (24%)]\tAll Loss: 2.2916\tTriple Loss(1): 0.2714\tClassification Loss: 1.7487\n",
      "Train Epoch: 4 [27200/110534 (25%)]\tAll Loss: 2.2312\tTriple Loss(1): 0.1760\tClassification Loss: 1.8793\n",
      "Train Epoch: 4 [27520/110534 (25%)]\tAll Loss: 1.7053\tTriple Loss(1): 0.0000\tClassification Loss: 1.7053\n",
      "Train Epoch: 4 [27840/110534 (25%)]\tAll Loss: 1.5078\tTriple Loss(0): 0.0000\tClassification Loss: 1.5078\n",
      "Train Epoch: 4 [28160/110534 (25%)]\tAll Loss: 2.1821\tTriple Loss(1): 0.1941\tClassification Loss: 1.7939\n",
      "Train Epoch: 4 [28480/110534 (26%)]\tAll Loss: 1.9387\tTriple Loss(1): 0.2361\tClassification Loss: 1.4665\n",
      "\n",
      "Test set: Average loss: 1.6056, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [28800/110534 (26%)]\tAll Loss: 1.4205\tTriple Loss(0): 0.0000\tClassification Loss: 1.4205\n",
      "Train Epoch: 4 [29120/110534 (26%)]\tAll Loss: 2.0927\tTriple Loss(1): 0.2764\tClassification Loss: 1.5399\n",
      "Train Epoch: 4 [29440/110534 (27%)]\tAll Loss: 1.3972\tTriple Loss(0): 0.0000\tClassification Loss: 1.3972\n",
      "Train Epoch: 4 [29760/110534 (27%)]\tAll Loss: 1.7598\tTriple Loss(1): 0.2205\tClassification Loss: 1.3188\n",
      "Train Epoch: 4 [30080/110534 (27%)]\tAll Loss: 1.7648\tTriple Loss(1): 0.1728\tClassification Loss: 1.4191\n",
      "Train Epoch: 4 [30400/110534 (27%)]\tAll Loss: 2.0758\tTriple Loss(1): 0.1662\tClassification Loss: 1.7433\n",
      "Train Epoch: 4 [30720/110534 (28%)]\tAll Loss: 1.6051\tTriple Loss(1): 0.1708\tClassification Loss: 1.2636\n",
      "Train Epoch: 4 [31040/110534 (28%)]\tAll Loss: 2.6178\tTriple Loss(1): 0.3544\tClassification Loss: 1.9090\n",
      "Train Epoch: 4 [31360/110534 (28%)]\tAll Loss: 1.7841\tTriple Loss(1): 0.0783\tClassification Loss: 1.6275\n",
      "Train Epoch: 4 [31680/110534 (29%)]\tAll Loss: 2.1278\tTriple Loss(1): 0.2509\tClassification Loss: 1.6260\n",
      "\n",
      "Test set: Average loss: 1.5984, Accuracy: 560/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [32000/110534 (29%)]\tAll Loss: 2.3783\tTriple Loss(1): 0.3408\tClassification Loss: 1.6968\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_1000.pth.tar\n",
      "Train Epoch: 4 [32320/110534 (29%)]\tAll Loss: 1.5942\tTriple Loss(1): 0.1384\tClassification Loss: 1.3174\n",
      "Train Epoch: 4 [32640/110534 (30%)]\tAll Loss: 1.6929\tTriple Loss(0): 0.0000\tClassification Loss: 1.6929\n",
      "Train Epoch: 4 [32960/110534 (30%)]\tAll Loss: 2.1175\tTriple Loss(1): 0.1803\tClassification Loss: 1.7569\n",
      "Train Epoch: 4 [33280/110534 (30%)]\tAll Loss: 2.5035\tTriple Loss(1): 0.2684\tClassification Loss: 1.9666\n",
      "Train Epoch: 4 [33600/110534 (30%)]\tAll Loss: 1.8624\tTriple Loss(1): 0.1163\tClassification Loss: 1.6297\n",
      "Train Epoch: 4 [33920/110534 (31%)]\tAll Loss: 1.5929\tTriple Loss(0): 0.0000\tClassification Loss: 1.5929\n",
      "Train Epoch: 4 [34240/110534 (31%)]\tAll Loss: 1.9849\tTriple Loss(1): 0.2240\tClassification Loss: 1.5369\n",
      "Train Epoch: 4 [34560/110534 (31%)]\tAll Loss: 2.0687\tTriple Loss(1): 0.2806\tClassification Loss: 1.5074\n",
      "Train Epoch: 4 [34880/110534 (32%)]\tAll Loss: 1.7505\tTriple Loss(1): 0.2626\tClassification Loss: 1.2252\n",
      "\n",
      "Test set: Average loss: 1.6050, Accuracy: 557/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [35200/110534 (32%)]\tAll Loss: 2.4097\tTriple Loss(1): 0.2287\tClassification Loss: 1.9523\n",
      "Train Epoch: 4 [35520/110534 (32%)]\tAll Loss: 2.0083\tTriple Loss(1): 0.1816\tClassification Loss: 1.6451\n",
      "Train Epoch: 4 [35840/110534 (32%)]\tAll Loss: 1.6150\tTriple Loss(1): 0.1367\tClassification Loss: 1.3416\n",
      "Train Epoch: 4 [36160/110534 (33%)]\tAll Loss: 2.1299\tTriple Loss(1): 0.1693\tClassification Loss: 1.7913\n",
      "Train Epoch: 4 [36480/110534 (33%)]\tAll Loss: 2.1198\tTriple Loss(1): 0.1773\tClassification Loss: 1.7653\n",
      "Train Epoch: 4 [36800/110534 (33%)]\tAll Loss: 2.0883\tTriple Loss(1): 0.2867\tClassification Loss: 1.5149\n",
      "Train Epoch: 4 [37120/110534 (34%)]\tAll Loss: 2.3692\tTriple Loss(1): 0.2538\tClassification Loss: 1.8615\n",
      "Train Epoch: 4 [37440/110534 (34%)]\tAll Loss: 2.1092\tTriple Loss(1): 0.2229\tClassification Loss: 1.6635\n",
      "Train Epoch: 4 [37760/110534 (34%)]\tAll Loss: 1.7955\tTriple Loss(1): 0.1184\tClassification Loss: 1.5586\n",
      "Train Epoch: 4 [38080/110534 (34%)]\tAll Loss: 2.2771\tTriple Loss(0): 0.2525\tClassification Loss: 1.7720\n",
      "\n",
      "Test set: Average loss: 1.5971, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [38400/110534 (35%)]\tAll Loss: 1.9470\tTriple Loss(1): 0.2871\tClassification Loss: 1.3728\n",
      "Train Epoch: 4 [38720/110534 (35%)]\tAll Loss: 1.7556\tTriple Loss(0): 0.0000\tClassification Loss: 1.7556\n",
      "Train Epoch: 4 [39040/110534 (35%)]\tAll Loss: 1.7056\tTriple Loss(1): 0.1890\tClassification Loss: 1.3276\n",
      "Train Epoch: 4 [39360/110534 (36%)]\tAll Loss: 1.5900\tTriple Loss(1): 0.0680\tClassification Loss: 1.4541\n",
      "Train Epoch: 4 [39680/110534 (36%)]\tAll Loss: 2.4338\tTriple Loss(1): 0.2951\tClassification Loss: 1.8436\n",
      "Train Epoch: 4 [40000/110534 (36%)]\tAll Loss: 1.2722\tTriple Loss(0): 0.0000\tClassification Loss: 1.2722\n",
      "Train Epoch: 4 [40320/110534 (36%)]\tAll Loss: 2.4052\tTriple Loss(1): 0.2999\tClassification Loss: 1.8054\n",
      "Train Epoch: 4 [40640/110534 (37%)]\tAll Loss: 1.9097\tTriple Loss(1): 0.1354\tClassification Loss: 1.6389\n",
      "Train Epoch: 4 [40960/110534 (37%)]\tAll Loss: 1.4005\tTriple Loss(0): 0.0000\tClassification Loss: 1.4005\n",
      "Train Epoch: 4 [41280/110534 (37%)]\tAll Loss: 2.0128\tTriple Loss(1): 0.2322\tClassification Loss: 1.5485\n",
      "\n",
      "Test set: Average loss: 1.5955, Accuracy: 557/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [41600/110534 (38%)]\tAll Loss: 1.6653\tTriple Loss(0): 0.0000\tClassification Loss: 1.6653\n",
      "Train Epoch: 4 [41920/110534 (38%)]\tAll Loss: 2.0519\tTriple Loss(1): 0.2597\tClassification Loss: 1.5326\n",
      "Train Epoch: 4 [42240/110534 (38%)]\tAll Loss: 1.9780\tTriple Loss(1): 0.1133\tClassification Loss: 1.7514\n",
      "Train Epoch: 4 [42560/110534 (38%)]\tAll Loss: 1.9826\tTriple Loss(1): 0.2425\tClassification Loss: 1.4977\n",
      "Train Epoch: 4 [42880/110534 (39%)]\tAll Loss: 2.1550\tTriple Loss(1): 0.2615\tClassification Loss: 1.6320\n",
      "Train Epoch: 4 [43200/110534 (39%)]\tAll Loss: 2.3601\tTriple Loss(1): 0.3899\tClassification Loss: 1.5803\n",
      "Train Epoch: 4 [43520/110534 (39%)]\tAll Loss: 1.3831\tTriple Loss(1): 0.0393\tClassification Loss: 1.3044\n",
      "Train Epoch: 4 [43840/110534 (40%)]\tAll Loss: 2.1792\tTriple Loss(1): 0.2076\tClassification Loss: 1.7639\n",
      "Train Epoch: 4 [44160/110534 (40%)]\tAll Loss: 2.4917\tTriple Loss(1): 0.3037\tClassification Loss: 1.8843\n",
      "Train Epoch: 4 [44480/110534 (40%)]\tAll Loss: 2.0384\tTriple Loss(1): 0.2393\tClassification Loss: 1.5597\n",
      "\n",
      "Test set: Average loss: 1.5973, Accuracy: 556/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [44800/110534 (41%)]\tAll Loss: 1.1836\tTriple Loss(1): 0.0557\tClassification Loss: 1.0722\n",
      "Train Epoch: 4 [45120/110534 (41%)]\tAll Loss: 1.8973\tTriple Loss(1): 0.1777\tClassification Loss: 1.5420\n",
      "Train Epoch: 4 [45440/110534 (41%)]\tAll Loss: 1.8518\tTriple Loss(1): 0.1733\tClassification Loss: 1.5051\n",
      "Train Epoch: 4 [45760/110534 (41%)]\tAll Loss: 1.8246\tTriple Loss(1): 0.1285\tClassification Loss: 1.5676\n",
      "Train Epoch: 4 [46080/110534 (42%)]\tAll Loss: 1.8610\tTriple Loss(1): 0.3239\tClassification Loss: 1.2131\n",
      "Train Epoch: 4 [46400/110534 (42%)]\tAll Loss: 2.9003\tTriple Loss(1): 0.4369\tClassification Loss: 2.0265\n",
      "Train Epoch: 4 [46720/110534 (42%)]\tAll Loss: 2.4275\tTriple Loss(1): 0.2438\tClassification Loss: 1.9398\n",
      "Train Epoch: 4 [47040/110534 (43%)]\tAll Loss: 2.2211\tTriple Loss(1): 0.3706\tClassification Loss: 1.4798\n",
      "Train Epoch: 4 [47360/110534 (43%)]\tAll Loss: 2.1354\tTriple Loss(1): 0.2548\tClassification Loss: 1.6257\n",
      "Train Epoch: 4 [47680/110534 (43%)]\tAll Loss: 1.1829\tTriple Loss(0): 0.0000\tClassification Loss: 1.1829\n",
      "\n",
      "Test set: Average loss: 1.6000, Accuracy: 551/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [48000/110534 (43%)]\tAll Loss: 2.3523\tTriple Loss(1): 0.2275\tClassification Loss: 1.8974\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_1500.pth.tar\n",
      "Train Epoch: 4 [48320/110534 (44%)]\tAll Loss: 2.6035\tTriple Loss(1): 0.3631\tClassification Loss: 1.8773\n",
      "Train Epoch: 4 [48640/110534 (44%)]\tAll Loss: 2.3342\tTriple Loss(1): 0.2337\tClassification Loss: 1.8669\n",
      "Train Epoch: 4 [48960/110534 (44%)]\tAll Loss: 2.1643\tTriple Loss(1): 0.3470\tClassification Loss: 1.4702\n",
      "Train Epoch: 4 [49280/110534 (45%)]\tAll Loss: 2.5824\tTriple Loss(1): 0.5587\tClassification Loss: 1.4649\n",
      "Train Epoch: 4 [49600/110534 (45%)]\tAll Loss: 1.7900\tTriple Loss(0): 0.0000\tClassification Loss: 1.7900\n",
      "Train Epoch: 4 [49920/110534 (45%)]\tAll Loss: 1.6180\tTriple Loss(1): 0.1099\tClassification Loss: 1.3982\n",
      "Train Epoch: 4 [50240/110534 (45%)]\tAll Loss: 1.8281\tTriple Loss(1): 0.2966\tClassification Loss: 1.2350\n",
      "Train Epoch: 4 [50560/110534 (46%)]\tAll Loss: 2.1639\tTriple Loss(1): 0.1529\tClassification Loss: 1.8580\n",
      "Train Epoch: 4 [50880/110534 (46%)]\tAll Loss: 2.8016\tTriple Loss(1): 0.4540\tClassification Loss: 1.8936\n",
      "\n",
      "Test set: Average loss: 1.5952, Accuracy: 552/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [51200/110534 (46%)]\tAll Loss: 2.0792\tTriple Loss(1): 0.2656\tClassification Loss: 1.5480\n",
      "Train Epoch: 4 [51520/110534 (47%)]\tAll Loss: 1.3915\tTriple Loss(0): 0.0000\tClassification Loss: 1.3915\n",
      "Train Epoch: 4 [51840/110534 (47%)]\tAll Loss: 1.6864\tTriple Loss(0): 0.0000\tClassification Loss: 1.6864\n",
      "Train Epoch: 4 [52160/110534 (47%)]\tAll Loss: 2.3159\tTriple Loss(1): 0.2844\tClassification Loss: 1.7472\n",
      "Train Epoch: 4 [52480/110534 (47%)]\tAll Loss: 2.4306\tTriple Loss(1): 0.1389\tClassification Loss: 2.1529\n",
      "Train Epoch: 4 [52800/110534 (48%)]\tAll Loss: 2.0399\tTriple Loss(1): 0.2355\tClassification Loss: 1.5690\n",
      "Train Epoch: 4 [53120/110534 (48%)]\tAll Loss: 2.1957\tTriple Loss(1): 0.2986\tClassification Loss: 1.5985\n",
      "Train Epoch: 4 [53440/110534 (48%)]\tAll Loss: 2.3623\tTriple Loss(1): 0.2389\tClassification Loss: 1.8846\n",
      "Train Epoch: 4 [53760/110534 (49%)]\tAll Loss: 2.0617\tTriple Loss(1): 0.1761\tClassification Loss: 1.7096\n",
      "Train Epoch: 4 [54080/110534 (49%)]\tAll Loss: 2.5485\tTriple Loss(1): 0.2507\tClassification Loss: 2.0471\n",
      "\n",
      "Test set: Average loss: 1.5985, Accuracy: 554/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [54400/110534 (49%)]\tAll Loss: 2.7689\tTriple Loss(1): 0.5512\tClassification Loss: 1.6665\n",
      "Train Epoch: 4 [54720/110534 (49%)]\tAll Loss: 2.0710\tTriple Loss(1): 0.1850\tClassification Loss: 1.7009\n",
      "Train Epoch: 4 [55040/110534 (50%)]\tAll Loss: 2.5161\tTriple Loss(1): 0.2355\tClassification Loss: 2.0451\n",
      "Train Epoch: 4 [55360/110534 (50%)]\tAll Loss: 1.4399\tTriple Loss(0): 0.0435\tClassification Loss: 1.3529\n",
      "Train Epoch: 4 [55680/110534 (50%)]\tAll Loss: 2.3011\tTriple Loss(1): 0.2409\tClassification Loss: 1.8192\n",
      "Train Epoch: 4 [56000/110534 (51%)]\tAll Loss: 2.2018\tTriple Loss(0): 0.0000\tClassification Loss: 2.2018\n",
      "Train Epoch: 4 [56320/110534 (51%)]\tAll Loss: 1.8208\tTriple Loss(0): 0.0000\tClassification Loss: 1.8208\n",
      "Train Epoch: 4 [56640/110534 (51%)]\tAll Loss: 1.0498\tTriple Loss(0): 0.0000\tClassification Loss: 1.0498\n",
      "Train Epoch: 4 [56960/110534 (52%)]\tAll Loss: 2.2406\tTriple Loss(1): 0.2633\tClassification Loss: 1.7141\n",
      "Train Epoch: 4 [57280/110534 (52%)]\tAll Loss: 2.1007\tTriple Loss(1): 0.1892\tClassification Loss: 1.7223\n",
      "\n",
      "Test set: Average loss: 1.5972, Accuracy: 554/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [57600/110534 (52%)]\tAll Loss: 1.8066\tTriple Loss(0): 0.0000\tClassification Loss: 1.8066\n",
      "Train Epoch: 4 [57920/110534 (52%)]\tAll Loss: 1.9905\tTriple Loss(1): 0.1581\tClassification Loss: 1.6743\n",
      "Train Epoch: 4 [58240/110534 (53%)]\tAll Loss: 1.4896\tTriple Loss(1): 0.1581\tClassification Loss: 1.1733\n",
      "Train Epoch: 4 [58560/110534 (53%)]\tAll Loss: 1.2871\tTriple Loss(1): 0.0000\tClassification Loss: 1.2871\n",
      "Train Epoch: 4 [58880/110534 (53%)]\tAll Loss: 2.4145\tTriple Loss(1): 0.3666\tClassification Loss: 1.6814\n",
      "Train Epoch: 4 [59200/110534 (54%)]\tAll Loss: 2.0576\tTriple Loss(1): 0.0994\tClassification Loss: 1.8588\n",
      "Train Epoch: 4 [59520/110534 (54%)]\tAll Loss: 1.8965\tTriple Loss(1): 0.1339\tClassification Loss: 1.6287\n",
      "Train Epoch: 4 [59840/110534 (54%)]\tAll Loss: 1.9590\tTriple Loss(1): 0.2384\tClassification Loss: 1.4822\n",
      "Train Epoch: 4 [60160/110534 (54%)]\tAll Loss: 1.5201\tTriple Loss(0): 0.0000\tClassification Loss: 1.5201\n",
      "Train Epoch: 4 [60480/110534 (55%)]\tAll Loss: 1.5668\tTriple Loss(1): 0.0986\tClassification Loss: 1.3697\n",
      "\n",
      "Test set: Average loss: 1.5963, Accuracy: 554/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [60800/110534 (55%)]\tAll Loss: 2.0602\tTriple Loss(1): 0.1946\tClassification Loss: 1.6709\n",
      "Train Epoch: 4 [61120/110534 (55%)]\tAll Loss: 2.1042\tTriple Loss(1): 0.2008\tClassification Loss: 1.7026\n",
      "Train Epoch: 4 [61440/110534 (56%)]\tAll Loss: 1.6207\tTriple Loss(1): 0.2812\tClassification Loss: 1.0583\n",
      "Train Epoch: 4 [61760/110534 (56%)]\tAll Loss: 2.1675\tTriple Loss(1): 0.2654\tClassification Loss: 1.6368\n",
      "Train Epoch: 4 [62080/110534 (56%)]\tAll Loss: 2.1382\tTriple Loss(1): 0.3114\tClassification Loss: 1.5154\n",
      "Train Epoch: 4 [62400/110534 (56%)]\tAll Loss: 1.2154\tTriple Loss(0): 0.0000\tClassification Loss: 1.2154\n",
      "Train Epoch: 4 [62720/110534 (57%)]\tAll Loss: 1.6270\tTriple Loss(1): 0.1103\tClassification Loss: 1.4063\n",
      "Train Epoch: 4 [63040/110534 (57%)]\tAll Loss: 2.0711\tTriple Loss(1): 0.1132\tClassification Loss: 1.8447\n",
      "Train Epoch: 4 [63360/110534 (57%)]\tAll Loss: 1.8845\tTriple Loss(1): 0.2035\tClassification Loss: 1.4775\n",
      "Train Epoch: 4 [63680/110534 (58%)]\tAll Loss: 1.7647\tTriple Loss(1): 0.1691\tClassification Loss: 1.4265\n",
      "\n",
      "Test set: Average loss: 1.6047, Accuracy: 547/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [64000/110534 (58%)]\tAll Loss: 2.3576\tTriple Loss(1): 0.0760\tClassification Loss: 2.2056\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_2000.pth.tar\n",
      "Train Epoch: 4 [64320/110534 (58%)]\tAll Loss: 1.6223\tTriple Loss(1): 0.1551\tClassification Loss: 1.3121\n",
      "Train Epoch: 4 [64640/110534 (58%)]\tAll Loss: 2.2186\tTriple Loss(0): 0.0000\tClassification Loss: 2.2186\n",
      "Train Epoch: 4 [64960/110534 (59%)]\tAll Loss: 2.2444\tTriple Loss(1): 0.3298\tClassification Loss: 1.5847\n",
      "Train Epoch: 4 [65280/110534 (59%)]\tAll Loss: 2.2175\tTriple Loss(1): 0.2350\tClassification Loss: 1.7475\n",
      "Train Epoch: 4 [65600/110534 (59%)]\tAll Loss: 2.2488\tTriple Loss(1): 0.2247\tClassification Loss: 1.7994\n",
      "Train Epoch: 4 [65920/110534 (60%)]\tAll Loss: 1.5568\tTriple Loss(0): 0.0000\tClassification Loss: 1.5568\n",
      "Train Epoch: 4 [66240/110534 (60%)]\tAll Loss: 1.7678\tTriple Loss(1): 0.0361\tClassification Loss: 1.6956\n",
      "Train Epoch: 4 [66560/110534 (60%)]\tAll Loss: 1.7393\tTriple Loss(1): 0.1750\tClassification Loss: 1.3892\n",
      "Train Epoch: 4 [66880/110534 (60%)]\tAll Loss: 2.3561\tTriple Loss(1): 0.3850\tClassification Loss: 1.5861\n",
      "\n",
      "Test set: Average loss: 1.6003, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [67200/110534 (61%)]\tAll Loss: 2.1307\tTriple Loss(1): 0.1551\tClassification Loss: 1.8205\n",
      "Train Epoch: 4 [67520/110534 (61%)]\tAll Loss: 1.8261\tTriple Loss(0): 0.0000\tClassification Loss: 1.8261\n",
      "Train Epoch: 4 [67840/110534 (61%)]\tAll Loss: 2.3735\tTriple Loss(1): 0.2610\tClassification Loss: 1.8516\n",
      "Train Epoch: 4 [68160/110534 (62%)]\tAll Loss: 1.4197\tTriple Loss(0): 0.0000\tClassification Loss: 1.4197\n",
      "Train Epoch: 4 [68480/110534 (62%)]\tAll Loss: 2.1250\tTriple Loss(1): 0.3298\tClassification Loss: 1.4655\n",
      "Train Epoch: 4 [68800/110534 (62%)]\tAll Loss: 1.8819\tTriple Loss(1): 0.2419\tClassification Loss: 1.3981\n",
      "Train Epoch: 4 [69120/110534 (63%)]\tAll Loss: 1.9601\tTriple Loss(1): 0.1386\tClassification Loss: 1.6828\n",
      "Train Epoch: 4 [69440/110534 (63%)]\tAll Loss: 1.4799\tTriple Loss(0): 0.0000\tClassification Loss: 1.4799\n",
      "Train Epoch: 4 [69760/110534 (63%)]\tAll Loss: 1.9940\tTriple Loss(1): 0.2697\tClassification Loss: 1.4545\n",
      "Train Epoch: 4 [70080/110534 (63%)]\tAll Loss: 1.8492\tTriple Loss(1): 0.1692\tClassification Loss: 1.5109\n",
      "\n",
      "Test set: Average loss: 1.5942, Accuracy: 563/960 (59%)\n",
      "\n",
      "Train Epoch: 4 [70400/110534 (64%)]\tAll Loss: 1.7876\tTriple Loss(1): 0.1457\tClassification Loss: 1.4963\n",
      "Train Epoch: 4 [70720/110534 (64%)]\tAll Loss: 1.9347\tTriple Loss(1): 0.2729\tClassification Loss: 1.3889\n",
      "Train Epoch: 4 [71040/110534 (64%)]\tAll Loss: 1.8869\tTriple Loss(1): 0.2414\tClassification Loss: 1.4041\n",
      "Train Epoch: 4 [71360/110534 (65%)]\tAll Loss: 2.2123\tTriple Loss(1): 0.2217\tClassification Loss: 1.7688\n",
      "Train Epoch: 4 [71680/110534 (65%)]\tAll Loss: 2.1073\tTriple Loss(1): 0.2413\tClassification Loss: 1.6246\n",
      "Train Epoch: 4 [72000/110534 (65%)]\tAll Loss: 2.4729\tTriple Loss(1): 0.3830\tClassification Loss: 1.7069\n",
      "Train Epoch: 4 [72320/110534 (65%)]\tAll Loss: 1.5412\tTriple Loss(0): 0.0000\tClassification Loss: 1.5412\n",
      "Train Epoch: 4 [72640/110534 (66%)]\tAll Loss: 1.5324\tTriple Loss(1): 0.1142\tClassification Loss: 1.3040\n",
      "Train Epoch: 4 [72960/110534 (66%)]\tAll Loss: 1.5052\tTriple Loss(0): 0.0000\tClassification Loss: 1.5052\n",
      "Train Epoch: 4 [73280/110534 (66%)]\tAll Loss: 1.6882\tTriple Loss(1): 0.2256\tClassification Loss: 1.2370\n",
      "\n",
      "Test set: Average loss: 1.5875, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [73600/110534 (67%)]\tAll Loss: 2.4388\tTriple Loss(1): 0.1108\tClassification Loss: 2.2172\n",
      "Train Epoch: 4 [73920/110534 (67%)]\tAll Loss: 2.2566\tTriple Loss(1): 0.2039\tClassification Loss: 1.8487\n",
      "Train Epoch: 4 [74240/110534 (67%)]\tAll Loss: 2.0129\tTriple Loss(1): 0.3629\tClassification Loss: 1.2870\n",
      "Train Epoch: 4 [74560/110534 (67%)]\tAll Loss: 1.9548\tTriple Loss(1): 0.1028\tClassification Loss: 1.7491\n",
      "Train Epoch: 4 [74880/110534 (68%)]\tAll Loss: 1.8811\tTriple Loss(1): 0.1631\tClassification Loss: 1.5549\n",
      "Train Epoch: 4 [75200/110534 (68%)]\tAll Loss: 1.4489\tTriple Loss(0): 0.0000\tClassification Loss: 1.4489\n",
      "Train Epoch: 4 [75520/110534 (68%)]\tAll Loss: 1.9243\tTriple Loss(1): 0.1764\tClassification Loss: 1.5715\n",
      "Train Epoch: 4 [75840/110534 (69%)]\tAll Loss: 2.3496\tTriple Loss(1): 0.4115\tClassification Loss: 1.5265\n",
      "Train Epoch: 4 [76160/110534 (69%)]\tAll Loss: 1.9182\tTriple Loss(1): 0.1355\tClassification Loss: 1.6472\n",
      "Train Epoch: 4 [76480/110534 (69%)]\tAll Loss: 1.6719\tTriple Loss(1): 0.1429\tClassification Loss: 1.3862\n",
      "\n",
      "Test set: Average loss: 1.5884, Accuracy: 552/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [76800/110534 (69%)]\tAll Loss: 1.4688\tTriple Loss(0): 0.0000\tClassification Loss: 1.4688\n",
      "Train Epoch: 4 [77120/110534 (70%)]\tAll Loss: 1.7325\tTriple Loss(1): 0.0892\tClassification Loss: 1.5541\n",
      "Train Epoch: 4 [77440/110534 (70%)]\tAll Loss: 2.1859\tTriple Loss(1): 0.3290\tClassification Loss: 1.5278\n",
      "Train Epoch: 4 [77760/110534 (70%)]\tAll Loss: 1.6206\tTriple Loss(0): 0.0000\tClassification Loss: 1.6206\n",
      "Train Epoch: 4 [78080/110534 (71%)]\tAll Loss: 2.4688\tTriple Loss(1): 0.1314\tClassification Loss: 2.2060\n",
      "Train Epoch: 4 [78400/110534 (71%)]\tAll Loss: 2.0627\tTriple Loss(1): 0.2360\tClassification Loss: 1.5907\n",
      "Train Epoch: 4 [78720/110534 (71%)]\tAll Loss: 1.6236\tTriple Loss(1): 0.2676\tClassification Loss: 1.0885\n",
      "Train Epoch: 4 [79040/110534 (71%)]\tAll Loss: 6.2384\tTriple Loss(0): 2.2640\tClassification Loss: 1.7103\n",
      "Train Epoch: 4 [79360/110534 (72%)]\tAll Loss: 2.5946\tTriple Loss(1): 0.3844\tClassification Loss: 1.8257\n",
      "Train Epoch: 4 [79680/110534 (72%)]\tAll Loss: 2.3705\tTriple Loss(1): 0.4390\tClassification Loss: 1.4924\n",
      "\n",
      "Test set: Average loss: 1.5919, Accuracy: 546/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [80000/110534 (72%)]\tAll Loss: 1.6160\tTriple Loss(1): 0.1650\tClassification Loss: 1.2859\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_2500.pth.tar\n",
      "Train Epoch: 4 [80320/110534 (73%)]\tAll Loss: 1.5677\tTriple Loss(1): 0.2212\tClassification Loss: 1.1252\n",
      "Train Epoch: 4 [80640/110534 (73%)]\tAll Loss: 1.7319\tTriple Loss(1): 0.2649\tClassification Loss: 1.2021\n",
      "Train Epoch: 4 [80960/110534 (73%)]\tAll Loss: 2.0456\tTriple Loss(1): 0.3152\tClassification Loss: 1.4152\n",
      "Train Epoch: 4 [81280/110534 (74%)]\tAll Loss: 1.9366\tTriple Loss(1): 0.2964\tClassification Loss: 1.3437\n",
      "Train Epoch: 4 [81600/110534 (74%)]\tAll Loss: 1.6872\tTriple Loss(1): 0.1420\tClassification Loss: 1.4032\n",
      "Train Epoch: 4 [81920/110534 (74%)]\tAll Loss: 2.2540\tTriple Loss(1): 0.3059\tClassification Loss: 1.6423\n",
      "Train Epoch: 4 [82240/110534 (74%)]\tAll Loss: 2.6418\tTriple Loss(1): 0.3864\tClassification Loss: 1.8690\n",
      "Train Epoch: 4 [82560/110534 (75%)]\tAll Loss: 2.2861\tTriple Loss(1): 0.3289\tClassification Loss: 1.6283\n",
      "Train Epoch: 4 [82880/110534 (75%)]\tAll Loss: 2.8237\tTriple Loss(1): 0.3248\tClassification Loss: 2.1741\n",
      "\n",
      "Test set: Average loss: 1.5875, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [83200/110534 (75%)]\tAll Loss: 1.8082\tTriple Loss(1): 0.1407\tClassification Loss: 1.5268\n",
      "Train Epoch: 4 [83520/110534 (76%)]\tAll Loss: 1.5433\tTriple Loss(0): 0.0252\tClassification Loss: 1.4929\n",
      "Train Epoch: 4 [83840/110534 (76%)]\tAll Loss: 1.3094\tTriple Loss(1): 0.0280\tClassification Loss: 1.2534\n",
      "Train Epoch: 4 [84160/110534 (76%)]\tAll Loss: 1.7579\tTriple Loss(1): 0.3026\tClassification Loss: 1.1527\n",
      "Train Epoch: 4 [84480/110534 (76%)]\tAll Loss: 1.6448\tTriple Loss(1): 0.1885\tClassification Loss: 1.2678\n",
      "Train Epoch: 4 [84800/110534 (77%)]\tAll Loss: 2.3269\tTriple Loss(1): 0.3589\tClassification Loss: 1.6091\n",
      "Train Epoch: 4 [85120/110534 (77%)]\tAll Loss: 1.4429\tTriple Loss(0): 0.0000\tClassification Loss: 1.4429\n",
      "Train Epoch: 4 [85440/110534 (77%)]\tAll Loss: 1.8710\tTriple Loss(1): 0.3793\tClassification Loss: 1.1124\n",
      "Train Epoch: 4 [85760/110534 (78%)]\tAll Loss: 1.6768\tTriple Loss(0): 0.0000\tClassification Loss: 1.6768\n",
      "Train Epoch: 4 [86080/110534 (78%)]\tAll Loss: 1.9893\tTriple Loss(0): 0.0000\tClassification Loss: 1.9893\n",
      "\n",
      "Test set: Average loss: 1.5859, Accuracy: 559/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [86400/110534 (78%)]\tAll Loss: 2.3442\tTriple Loss(1): 0.1932\tClassification Loss: 1.9577\n",
      "Train Epoch: 4 [86720/110534 (78%)]\tAll Loss: 1.7570\tTriple Loss(1): 0.1755\tClassification Loss: 1.4060\n",
      "Train Epoch: 4 [87040/110534 (79%)]\tAll Loss: 2.0247\tTriple Loss(1): 0.2774\tClassification Loss: 1.4700\n",
      "Train Epoch: 4 [87360/110534 (79%)]\tAll Loss: 2.2441\tTriple Loss(1): 0.2272\tClassification Loss: 1.7898\n",
      "Train Epoch: 4 [87680/110534 (79%)]\tAll Loss: 2.0789\tTriple Loss(1): 0.1759\tClassification Loss: 1.7271\n",
      "Train Epoch: 4 [88000/110534 (80%)]\tAll Loss: 2.9043\tTriple Loss(1): 0.2816\tClassification Loss: 2.3411\n",
      "Train Epoch: 4 [88320/110534 (80%)]\tAll Loss: 1.6383\tTriple Loss(1): 0.1182\tClassification Loss: 1.4020\n",
      "Train Epoch: 4 [88640/110534 (80%)]\tAll Loss: 2.0327\tTriple Loss(0): 0.0000\tClassification Loss: 2.0327\n",
      "Train Epoch: 4 [88960/110534 (80%)]\tAll Loss: 2.8804\tTriple Loss(1): 0.5624\tClassification Loss: 1.7556\n",
      "Train Epoch: 4 [89280/110534 (81%)]\tAll Loss: 2.4753\tTriple Loss(1): 0.4196\tClassification Loss: 1.6360\n",
      "\n",
      "Test set: Average loss: 1.5858, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [89600/110534 (81%)]\tAll Loss: 2.2284\tTriple Loss(0): 0.0000\tClassification Loss: 2.2284\n",
      "Train Epoch: 4 [89920/110534 (81%)]\tAll Loss: 2.3901\tTriple Loss(1): 0.3145\tClassification Loss: 1.7610\n",
      "Train Epoch: 4 [90240/110534 (82%)]\tAll Loss: 2.0021\tTriple Loss(1): 0.3006\tClassification Loss: 1.4008\n",
      "Train Epoch: 4 [90560/110534 (82%)]\tAll Loss: 1.6123\tTriple Loss(1): 0.1997\tClassification Loss: 1.2130\n",
      "Train Epoch: 4 [90880/110534 (82%)]\tAll Loss: 2.2769\tTriple Loss(1): 0.3266\tClassification Loss: 1.6237\n",
      "Train Epoch: 4 [91200/110534 (82%)]\tAll Loss: 1.7026\tTriple Loss(1): 0.1548\tClassification Loss: 1.3931\n",
      "Train Epoch: 4 [91520/110534 (83%)]\tAll Loss: 2.6605\tTriple Loss(1): 0.5365\tClassification Loss: 1.5876\n",
      "Train Epoch: 4 [91840/110534 (83%)]\tAll Loss: 1.4709\tTriple Loss(0): 0.0000\tClassification Loss: 1.4709\n",
      "Train Epoch: 4 [92160/110534 (83%)]\tAll Loss: 2.6662\tTriple Loss(1): 0.3617\tClassification Loss: 1.9427\n",
      "Train Epoch: 4 [92480/110534 (84%)]\tAll Loss: 1.7738\tTriple Loss(1): 0.0993\tClassification Loss: 1.5752\n",
      "\n",
      "Test set: Average loss: 1.5925, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [92800/110534 (84%)]\tAll Loss: 1.9677\tTriple Loss(1): 0.1546\tClassification Loss: 1.6585\n",
      "Train Epoch: 4 [93120/110534 (84%)]\tAll Loss: 1.7432\tTriple Loss(0): 0.0000\tClassification Loss: 1.7432\n",
      "Train Epoch: 4 [93440/110534 (85%)]\tAll Loss: 1.8013\tTriple Loss(1): 0.1865\tClassification Loss: 1.4282\n",
      "Train Epoch: 4 [93760/110534 (85%)]\tAll Loss: 5.7776\tTriple Loss(0): 2.1513\tClassification Loss: 1.4751\n",
      "Train Epoch: 4 [94080/110534 (85%)]\tAll Loss: 6.7598\tTriple Loss(0): 2.6934\tClassification Loss: 1.3730\n",
      "Train Epoch: 4 [94400/110534 (85%)]\tAll Loss: 1.9653\tTriple Loss(1): 0.1789\tClassification Loss: 1.6075\n",
      "Train Epoch: 4 [94720/110534 (86%)]\tAll Loss: 2.0206\tTriple Loss(1): 0.1857\tClassification Loss: 1.6493\n",
      "Train Epoch: 4 [95040/110534 (86%)]\tAll Loss: 1.8099\tTriple Loss(1): 0.0704\tClassification Loss: 1.6692\n",
      "Train Epoch: 4 [95360/110534 (86%)]\tAll Loss: 2.0932\tTriple Loss(1): 0.2776\tClassification Loss: 1.5380\n",
      "Train Epoch: 4 [95680/110534 (87%)]\tAll Loss: 2.0644\tTriple Loss(1): 0.2134\tClassification Loss: 1.6375\n",
      "\n",
      "Test set: Average loss: 1.5857, Accuracy: 549/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [96000/110534 (87%)]\tAll Loss: 1.9258\tTriple Loss(1): 0.2760\tClassification Loss: 1.3739\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_3000.pth.tar\n",
      "Train Epoch: 4 [96320/110534 (87%)]\tAll Loss: 1.7938\tTriple Loss(1): 0.1750\tClassification Loss: 1.4438\n",
      "Train Epoch: 4 [96640/110534 (87%)]\tAll Loss: 1.7434\tTriple Loss(0): 0.0000\tClassification Loss: 1.7434\n",
      "Train Epoch: 4 [96960/110534 (88%)]\tAll Loss: 1.9789\tTriple Loss(1): 0.2907\tClassification Loss: 1.3976\n",
      "Train Epoch: 4 [97280/110534 (88%)]\tAll Loss: 1.5676\tTriple Loss(1): 0.1746\tClassification Loss: 1.2184\n",
      "Train Epoch: 4 [97600/110534 (88%)]\tAll Loss: 2.1359\tTriple Loss(1): 0.2092\tClassification Loss: 1.7174\n",
      "Train Epoch: 4 [97920/110534 (89%)]\tAll Loss: 1.1293\tTriple Loss(0): 0.0000\tClassification Loss: 1.1293\n",
      "Train Epoch: 4 [98240/110534 (89%)]\tAll Loss: 1.6372\tTriple Loss(1): 0.2127\tClassification Loss: 1.2119\n",
      "Train Epoch: 4 [98560/110534 (89%)]\tAll Loss: 1.1898\tTriple Loss(0): 0.0000\tClassification Loss: 1.1898\n",
      "Train Epoch: 4 [98880/110534 (89%)]\tAll Loss: 1.4673\tTriple Loss(0): 0.0000\tClassification Loss: 1.4673\n",
      "\n",
      "Test set: Average loss: 1.6001, Accuracy: 555/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [99200/110534 (90%)]\tAll Loss: 1.9585\tTriple Loss(1): 0.2448\tClassification Loss: 1.4690\n",
      "Train Epoch: 4 [99520/110534 (90%)]\tAll Loss: 1.8197\tTriple Loss(1): 0.1254\tClassification Loss: 1.5689\n",
      "Train Epoch: 4 [99840/110534 (90%)]\tAll Loss: 2.0553\tTriple Loss(1): 0.1998\tClassification Loss: 1.6556\n",
      "Train Epoch: 4 [100160/110534 (91%)]\tAll Loss: 4.3528\tTriple Loss(0): 1.2153\tClassification Loss: 1.9223\n",
      "Train Epoch: 4 [100480/110534 (91%)]\tAll Loss: 2.0049\tTriple Loss(1): 0.2379\tClassification Loss: 1.5290\n",
      "Train Epoch: 4 [100800/110534 (91%)]\tAll Loss: 3.4454\tTriple Loss(0): 0.8193\tClassification Loss: 1.8068\n",
      "Train Epoch: 4 [101120/110534 (91%)]\tAll Loss: 1.8647\tTriple Loss(1): 0.2451\tClassification Loss: 1.3744\n",
      "Train Epoch: 4 [101440/110534 (92%)]\tAll Loss: 2.0374\tTriple Loss(1): 0.3677\tClassification Loss: 1.3021\n",
      "Train Epoch: 4 [101760/110534 (92%)]\tAll Loss: 1.7292\tTriple Loss(1): 0.0663\tClassification Loss: 1.5965\n",
      "Train Epoch: 4 [102080/110534 (92%)]\tAll Loss: 2.8579\tTriple Loss(1): 0.3550\tClassification Loss: 2.1479\n",
      "\n",
      "Test set: Average loss: 1.5898, Accuracy: 548/960 (57%)\n",
      "\n",
      "Train Epoch: 4 [102400/110534 (93%)]\tAll Loss: 1.7546\tTriple Loss(1): 0.1591\tClassification Loss: 1.4363\n",
      "Train Epoch: 4 [102720/110534 (93%)]\tAll Loss: 2.2690\tTriple Loss(1): 0.3175\tClassification Loss: 1.6341\n",
      "Train Epoch: 4 [103040/110534 (93%)]\tAll Loss: 2.0679\tTriple Loss(1): 0.2930\tClassification Loss: 1.4818\n",
      "Train Epoch: 4 [103360/110534 (93%)]\tAll Loss: 1.9058\tTriple Loss(0): 0.0000\tClassification Loss: 1.9058\n",
      "Train Epoch: 4 [103680/110534 (94%)]\tAll Loss: 2.3772\tTriple Loss(1): 0.3019\tClassification Loss: 1.7735\n",
      "Train Epoch: 4 [104000/110534 (94%)]\tAll Loss: 1.7711\tTriple Loss(1): 0.1266\tClassification Loss: 1.5179\n",
      "Train Epoch: 4 [104320/110534 (94%)]\tAll Loss: 1.9167\tTriple Loss(0): 0.0000\tClassification Loss: 1.9167\n",
      "Train Epoch: 4 [104640/110534 (95%)]\tAll Loss: 2.2616\tTriple Loss(1): 0.2138\tClassification Loss: 1.8341\n",
      "Train Epoch: 4 [104960/110534 (95%)]\tAll Loss: 1.5719\tTriple Loss(0): 0.0000\tClassification Loss: 1.5719\n",
      "Train Epoch: 4 [105280/110534 (95%)]\tAll Loss: 1.9879\tTriple Loss(1): 0.1800\tClassification Loss: 1.6280\n",
      "\n",
      "Test set: Average loss: 1.5918, Accuracy: 560/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [105600/110534 (96%)]\tAll Loss: 2.0039\tTriple Loss(1): 0.1176\tClassification Loss: 1.7687\n",
      "Train Epoch: 4 [105920/110534 (96%)]\tAll Loss: 1.7262\tTriple Loss(0): 0.0000\tClassification Loss: 1.7262\n",
      "Train Epoch: 4 [106240/110534 (96%)]\tAll Loss: 1.6088\tTriple Loss(1): 0.1576\tClassification Loss: 1.2937\n",
      "Train Epoch: 4 [106560/110534 (96%)]\tAll Loss: 1.8804\tTriple Loss(1): 0.1281\tClassification Loss: 1.6243\n",
      "Train Epoch: 4 [106880/110534 (97%)]\tAll Loss: 2.9208\tTriple Loss(1): 0.4500\tClassification Loss: 2.0208\n",
      "Train Epoch: 4 [107200/110534 (97%)]\tAll Loss: 1.8484\tTriple Loss(0): 0.0000\tClassification Loss: 1.8484\n",
      "Train Epoch: 4 [107520/110534 (97%)]\tAll Loss: 1.9060\tTriple Loss(1): 0.1496\tClassification Loss: 1.6068\n",
      "Train Epoch: 4 [107840/110534 (98%)]\tAll Loss: 1.5530\tTriple Loss(0): 0.0000\tClassification Loss: 1.5530\n",
      "Train Epoch: 4 [108160/110534 (98%)]\tAll Loss: 1.5517\tTriple Loss(1): 0.1518\tClassification Loss: 1.2481\n",
      "Train Epoch: 4 [108480/110534 (98%)]\tAll Loss: 1.8281\tTriple Loss(1): 0.0946\tClassification Loss: 1.6390\n",
      "\n",
      "Test set: Average loss: 1.5840, Accuracy: 557/960 (58%)\n",
      "\n",
      "Train Epoch: 4 [108800/110534 (98%)]\tAll Loss: 1.6886\tTriple Loss(0): 0.0000\tClassification Loss: 1.6886\n",
      "Train Epoch: 4 [109120/110534 (99%)]\tAll Loss: 2.2969\tTriple Loss(1): 0.2016\tClassification Loss: 1.8937\n",
      "Train Epoch: 4 [109440/110534 (99%)]\tAll Loss: 1.8607\tTriple Loss(1): 0.2129\tClassification Loss: 1.4349\n",
      "Train Epoch: 4 [109760/110534 (99%)]\tAll Loss: 1.5134\tTriple Loss(0): 0.0000\tClassification Loss: 1.5134\n",
      "Train Epoch: 4 [110080/110534 (100%)]\tAll Loss: 2.1339\tTriple Loss(1): 0.2114\tClassification Loss: 1.7110\n",
      "Train Epoch: 4 [110400/110534 (100%)]\tAll Loss: 1.9492\tTriple Loss(1): 0.1944\tClassification Loss: 1.5605\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_4_final.pth.tar\n",
      "\n",
      "Test set: Average loss: 1.5863, Accuracy: 556/960 (58%)\n",
      "\n",
      "Train Epoch: 5 [0/110534 (0%)]\tAll Loss: 1.9346\tTriple Loss(1): 0.2073\tClassification Loss: 1.5200\n",
      "Train Epoch: 5 [320/110534 (0%)]\tAll Loss: 2.3173\tTriple Loss(1): 0.4272\tClassification Loss: 1.4629\n",
      "Train Epoch: 5 [640/110534 (1%)]\tAll Loss: 1.3295\tTriple Loss(1): 0.1510\tClassification Loss: 1.0275\n",
      "Train Epoch: 5 [960/110534 (1%)]\tAll Loss: 2.3740\tTriple Loss(1): 0.2690\tClassification Loss: 1.8360\n",
      "Train Epoch: 5 [1280/110534 (1%)]\tAll Loss: 1.6855\tTriple Loss(1): 0.1196\tClassification Loss: 1.4463\n",
      "Train Epoch: 5 [1600/110534 (1%)]\tAll Loss: 2.0910\tTriple Loss(1): 0.1966\tClassification Loss: 1.6978\n",
      "Train Epoch: 5 [1920/110534 (2%)]\tAll Loss: 1.8110\tTriple Loss(1): 0.0815\tClassification Loss: 1.6479\n",
      "Train Epoch: 5 [2240/110534 (2%)]\tAll Loss: 1.8682\tTriple Loss(1): 0.1483\tClassification Loss: 1.5715\n",
      "Train Epoch: 5 [2560/110534 (2%)]\tAll Loss: 1.8474\tTriple Loss(1): 0.1536\tClassification Loss: 1.5401\n",
      "Train Epoch: 5 [2880/110534 (3%)]\tAll Loss: 2.1520\tTriple Loss(1): 0.0997\tClassification Loss: 1.9525\n",
      "\n",
      "Test set: Average loss: 1.5915, Accuracy: 557/960 (58%)\n",
      "\n",
      "Train Epoch: 5 [3200/110534 (3%)]\tAll Loss: 2.2608\tTriple Loss(1): 0.0764\tClassification Loss: 2.1080\n",
      "Train Epoch: 5 [3520/110534 (3%)]\tAll Loss: 1.2783\tTriple Loss(0): 0.0000\tClassification Loss: 1.2783\n",
      "Train Epoch: 5 [3840/110534 (3%)]\tAll Loss: 2.3105\tTriple Loss(1): 0.3141\tClassification Loss: 1.6823\n",
      "Train Epoch: 5 [4160/110534 (4%)]\tAll Loss: 1.9516\tTriple Loss(1): 0.1785\tClassification Loss: 1.5946\n",
      "Train Epoch: 5 [4480/110534 (4%)]\tAll Loss: 1.9282\tTriple Loss(1): 0.2533\tClassification Loss: 1.4215\n",
      "Train Epoch: 5 [4800/110534 (4%)]\tAll Loss: 1.6674\tTriple Loss(1): 0.1065\tClassification Loss: 1.4543\n",
      "Train Epoch: 5 [5120/110534 (5%)]\tAll Loss: 2.0875\tTriple Loss(1): 0.1981\tClassification Loss: 1.6913\n",
      "Train Epoch: 5 [5440/110534 (5%)]\tAll Loss: 2.0870\tTriple Loss(1): 0.1956\tClassification Loss: 1.6959\n",
      "Train Epoch: 5 [5760/110534 (5%)]\tAll Loss: 1.8451\tTriple Loss(1): 0.3835\tClassification Loss: 1.0781\n",
      "Train Epoch: 5 [6080/110534 (5%)]\tAll Loss: 1.4283\tTriple Loss(0): 0.0000\tClassification Loss: 1.4283\n",
      "\n",
      "Test set: Average loss: 1.5851, Accuracy: 552/960 (58%)\n",
      "\n",
      "Train Epoch: 5 [6400/110534 (6%)]\tAll Loss: 2.6505\tTriple Loss(1): 0.4293\tClassification Loss: 1.7919\n",
      "Train Epoch: 5 [6720/110534 (6%)]\tAll Loss: 1.6735\tTriple Loss(0): 0.0000\tClassification Loss: 1.6735\n",
      "Train Epoch: 5 [7040/110534 (6%)]\tAll Loss: 2.4707\tTriple Loss(1): 0.2980\tClassification Loss: 1.8746\n",
      "Train Epoch: 5 [7360/110534 (7%)]\tAll Loss: 2.0783\tTriple Loss(1): 0.3011\tClassification Loss: 1.4761\n",
      "Train Epoch: 5 [7680/110534 (7%)]\tAll Loss: 1.7756\tTriple Loss(1): 0.2950\tClassification Loss: 1.1856\n",
      "Train Epoch: 5 [8000/110534 (7%)]\tAll Loss: 1.5714\tTriple Loss(1): 0.1494\tClassification Loss: 1.2726\n",
      "Train Epoch: 5 [8320/110534 (8%)]\tAll Loss: 2.2170\tTriple Loss(1): 0.3513\tClassification Loss: 1.5143\n",
      "Train Epoch: 5 [8640/110534 (8%)]\tAll Loss: 1.6244\tTriple Loss(1): 0.1581\tClassification Loss: 1.3083\n",
      "Train Epoch: 5 [8960/110534 (8%)]\tAll Loss: 13.5483\tTriple Loss(0): 6.0888\tClassification Loss: 1.3707\n",
      "Train Epoch: 5 [9280/110534 (8%)]\tAll Loss: 1.2703\tTriple Loss(0): 0.0000\tClassification Loss: 1.2703\n",
      "\n",
      "Test set: Average loss: 1.5826, Accuracy: 551/960 (57%)\n",
      "\n",
      "Train Epoch: 5 [9600/110534 (9%)]\tAll Loss: 2.4587\tTriple Loss(1): 0.2710\tClassification Loss: 1.9167\n",
      "Train Epoch: 5 [9920/110534 (9%)]\tAll Loss: 1.6368\tTriple Loss(1): 0.0935\tClassification Loss: 1.4497\n",
      "Train Epoch: 5 [10240/110534 (9%)]\tAll Loss: 1.8395\tTriple Loss(0): 0.0000\tClassification Loss: 1.8395\n",
      "Train Epoch: 5 [10560/110534 (10%)]\tAll Loss: 1.7452\tTriple Loss(0): 0.0000\tClassification Loss: 1.7452\n",
      "Train Epoch: 5 [10880/110534 (10%)]\tAll Loss: 1.9553\tTriple Loss(1): 0.1227\tClassification Loss: 1.7098\n",
      "Train Epoch: 5 [11200/110534 (10%)]\tAll Loss: 1.5803\tTriple Loss(1): 0.1332\tClassification Loss: 1.3139\n",
      "Train Epoch: 5 [11520/110534 (10%)]\tAll Loss: 2.0895\tTriple Loss(1): 0.2813\tClassification Loss: 1.5270\n",
      "Train Epoch: 5 [11840/110534 (11%)]\tAll Loss: 2.0519\tTriple Loss(1): 0.2374\tClassification Loss: 1.5772\n",
      "Train Epoch: 5 [12160/110534 (11%)]\tAll Loss: 2.3497\tTriple Loss(1): 0.3123\tClassification Loss: 1.7251\n",
      "Train Epoch: 5 [12480/110534 (11%)]\tAll Loss: 2.0096\tTriple Loss(1): 0.1812\tClassification Loss: 1.6472\n",
      "\n",
      "Test set: Average loss: 1.5827, Accuracy: 553/960 (58%)\n",
      "\n",
      "Train Epoch: 5 [12800/110534 (12%)]\tAll Loss: 1.4241\tTriple Loss(0): 0.0000\tClassification Loss: 1.4241\n",
      "Train Epoch: 5 [13120/110534 (12%)]\tAll Loss: 1.3893\tTriple Loss(0): 0.0000\tClassification Loss: 1.3893\n",
      "Train Epoch: 5 [13440/110534 (12%)]\tAll Loss: 2.5202\tTriple Loss(1): 0.1951\tClassification Loss: 2.1300\n",
      "Train Epoch: 5 [13760/110534 (12%)]\tAll Loss: 3.0111\tTriple Loss(1): 0.6506\tClassification Loss: 1.7100\n",
      "Train Epoch: 5 [14080/110534 (13%)]\tAll Loss: 1.9223\tTriple Loss(1): 0.1785\tClassification Loss: 1.5652\n",
      "Train Epoch: 5 [14400/110534 (13%)]\tAll Loss: 2.2244\tTriple Loss(1): 0.0635\tClassification Loss: 2.0973\n",
      "Train Epoch: 5 [14720/110534 (13%)]\tAll Loss: 2.0267\tTriple Loss(1): 0.1697\tClassification Loss: 1.6873\n",
      "Train Epoch: 5 [15040/110534 (14%)]\tAll Loss: 1.7934\tTriple Loss(1): 0.1364\tClassification Loss: 1.5206\n",
      "Train Epoch: 5 [15360/110534 (14%)]\tAll Loss: 1.7923\tTriple Loss(1): 0.1004\tClassification Loss: 1.5915\n",
      "Train Epoch: 5 [15680/110534 (14%)]\tAll Loss: 1.8293\tTriple Loss(1): 0.2257\tClassification Loss: 1.3779\n",
      "\n",
      "Test set: Average loss: 1.5820, Accuracy: 551/960 (57%)\n",
      "\n",
      "Train Epoch: 5 [16000/110534 (14%)]\tAll Loss: 3.5146\tTriple Loss(0): 0.9210\tClassification Loss: 1.6725\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_5_500.pth.tar\n",
      "Train Epoch: 5 [16320/110534 (15%)]\tAll Loss: 1.8803\tTriple Loss(1): 0.2743\tClassification Loss: 1.3317\n",
      "Train Epoch: 5 [16640/110534 (15%)]\tAll Loss: 2.0335\tTriple Loss(1): 0.1485\tClassification Loss: 1.7366\n",
      "Train Epoch: 5 [16960/110534 (15%)]\tAll Loss: 2.3462\tTriple Loss(1): 0.1616\tClassification Loss: 2.0230\n",
      "Train Epoch: 5 [17280/110534 (16%)]\tAll Loss: 1.7425\tTriple Loss(1): 0.1579\tClassification Loss: 1.4266\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WQN1zCcsuzua",
    "colab_type": "code",
    "outputId": "56702ff0-f0a8-40bb-f7f0-d2a4bba654e0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "# From scratch. FREEZE = False. LR=0.01\n",
    "! python train.py"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:220: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:704: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
      "  \"please use transforms.RandomResizedCrop instead.\")\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "train.py:132: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "\n",
      "Test set: Average loss: 3.4774, Accuracy: 58/960 (6%)\n",
      "\n",
      "Train Epoch: 1 [0/110534 (0%)]\tAll Loss: 6.3927\tTriple Loss(0): 1.5768\tClassification Loss: 3.2391\n",
      "Train Epoch: 1 [320/110534 (0%)]\tAll Loss: 7.2953\tTriple Loss(0): 1.1788\tClassification Loss: 4.9378\n",
      "Train Epoch: 1 [640/110534 (1%)]\tAll Loss: 4.4997\tTriple Loss(1): 0.8896\tClassification Loss: 2.7204\n",
      "Train Epoch: 1 [960/110534 (1%)]\tAll Loss: 2.4944\tTriple Loss(0): 0.0000\tClassification Loss: 2.4944\n",
      "Train Epoch: 1 [1280/110534 (1%)]\tAll Loss: 4.5276\tTriple Loss(1): 0.9104\tClassification Loss: 2.7068\n",
      "Train Epoch: 1 [1600/110534 (1%)]\tAll Loss: 4.2570\tTriple Loss(1): 0.7107\tClassification Loss: 2.8356\n",
      "Train Epoch: 1 [1920/110534 (2%)]\tAll Loss: 5.3400\tTriple Loss(0): 1.5198\tClassification Loss: 2.3005\n",
      "Train Epoch: 1 [2240/110534 (2%)]\tAll Loss: 2.5340\tTriple Loss(0): 0.0000\tClassification Loss: 2.5340\n",
      "Train Epoch: 1 [2560/110534 (2%)]\tAll Loss: 4.3180\tTriple Loss(1): 0.9147\tClassification Loss: 2.4887\n",
      "Train Epoch: 1 [2880/110534 (3%)]\tAll Loss: 4.2571\tTriple Loss(1): 0.9409\tClassification Loss: 2.3753\n",
      "\n",
      "Test set: Average loss: 2.6772, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [3200/110534 (3%)]\tAll Loss: 4.1243\tTriple Loss(1): 0.7547\tClassification Loss: 2.6149\n",
      "Train Epoch: 1 [3520/110534 (3%)]\tAll Loss: 4.4523\tTriple Loss(1): 0.9022\tClassification Loss: 2.6479\n",
      "Train Epoch: 1 [3840/110534 (3%)]\tAll Loss: 4.3290\tTriple Loss(1): 0.9194\tClassification Loss: 2.4903\n",
      "Train Epoch: 1 [4160/110534 (4%)]\tAll Loss: 6.0292\tTriple Loss(0): 1.6875\tClassification Loss: 2.6541\n",
      "Train Epoch: 1 [4480/110534 (4%)]\tAll Loss: 5.3994\tTriple Loss(0): 1.4073\tClassification Loss: 2.5848\n",
      "Train Epoch: 1 [4800/110534 (4%)]\tAll Loss: 4.2473\tTriple Loss(1): 0.9426\tClassification Loss: 2.3621\n",
      "Train Epoch: 1 [5120/110534 (5%)]\tAll Loss: 4.4257\tTriple Loss(1): 0.9199\tClassification Loss: 2.5860\n",
      "Train Epoch: 1 [5440/110534 (5%)]\tAll Loss: 5.1151\tTriple Loss(1): 0.9369\tClassification Loss: 3.2413\n",
      "Train Epoch: 1 [5760/110534 (5%)]\tAll Loss: 4.1016\tTriple Loss(1): 0.7977\tClassification Loss: 2.5062\n",
      "Train Epoch: 1 [6080/110534 (5%)]\tAll Loss: 3.8709\tTriple Loss(1): 0.7892\tClassification Loss: 2.2924\n",
      "\n",
      "Test set: Average loss: 2.6767, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [6400/110534 (6%)]\tAll Loss: 4.0436\tTriple Loss(1): 0.7719\tClassification Loss: 2.4999\n",
      "Train Epoch: 1 [6720/110534 (6%)]\tAll Loss: 3.9948\tTriple Loss(1): 0.7379\tClassification Loss: 2.5191\n",
      "Train Epoch: 1 [7040/110534 (6%)]\tAll Loss: 3.9228\tTriple Loss(1): 0.8700\tClassification Loss: 2.1828\n",
      "Train Epoch: 1 [7360/110534 (7%)]\tAll Loss: 4.3355\tTriple Loss(0): 0.8877\tClassification Loss: 2.5601\n",
      "Train Epoch: 1 [7680/110534 (7%)]\tAll Loss: 4.0670\tTriple Loss(1): 0.8836\tClassification Loss: 2.2997\n",
      "Train Epoch: 1 [8000/110534 (7%)]\tAll Loss: 4.2738\tTriple Loss(1): 0.9201\tClassification Loss: 2.4335\n",
      "Train Epoch: 1 [8320/110534 (8%)]\tAll Loss: 4.7312\tTriple Loss(0): 1.0168\tClassification Loss: 2.6977\n",
      "Train Epoch: 1 [8640/110534 (8%)]\tAll Loss: 4.3484\tTriple Loss(1): 0.9238\tClassification Loss: 2.5008\n",
      "Train Epoch: 1 [8960/110534 (8%)]\tAll Loss: 4.0268\tTriple Loss(1): 0.7372\tClassification Loss: 2.5524\n",
      "Train Epoch: 1 [9280/110534 (8%)]\tAll Loss: 7.4774\tTriple Loss(0): 2.4656\tClassification Loss: 2.5462\n",
      "\n",
      "Test set: Average loss: 2.8447, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [9600/110534 (9%)]\tAll Loss: 4.7577\tTriple Loss(1): 0.9924\tClassification Loss: 2.7729\n",
      "Train Epoch: 1 [9920/110534 (9%)]\tAll Loss: 4.8479\tTriple Loss(0): 1.1232\tClassification Loss: 2.6015\n",
      "Train Epoch: 1 [10240/110534 (9%)]\tAll Loss: 4.1653\tTriple Loss(1): 0.8588\tClassification Loss: 2.4477\n",
      "Train Epoch: 1 [10560/110534 (10%)]\tAll Loss: 4.1695\tTriple Loss(1): 0.7784\tClassification Loss: 2.6127\n",
      "Train Epoch: 1 [10880/110534 (10%)]\tAll Loss: 3.3668\tTriple Loss(1): 0.6423\tClassification Loss: 2.0822\n",
      "Train Epoch: 1 [11200/110534 (10%)]\tAll Loss: 4.0505\tTriple Loss(1): 0.7542\tClassification Loss: 2.5421\n",
      "Train Epoch: 1 [11520/110534 (10%)]\tAll Loss: 4.2915\tTriple Loss(1): 0.8644\tClassification Loss: 2.5628\n",
      "Train Epoch: 1 [11840/110534 (11%)]\tAll Loss: 4.5104\tTriple Loss(1): 0.9290\tClassification Loss: 2.6525\n",
      "Train Epoch: 1 [12160/110534 (11%)]\tAll Loss: 4.0403\tTriple Loss(1): 0.8604\tClassification Loss: 2.3194\n",
      "Train Epoch: 1 [12480/110534 (11%)]\tAll Loss: 4.4361\tTriple Loss(1): 0.9970\tClassification Loss: 2.4421\n",
      "\n",
      "Test set: Average loss: 2.6686, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [12800/110534 (12%)]\tAll Loss: 4.2094\tTriple Loss(1): 0.8399\tClassification Loss: 2.5296\n",
      "Train Epoch: 1 [13120/110534 (12%)]\tAll Loss: 4.4838\tTriple Loss(1): 1.0555\tClassification Loss: 2.3728\n",
      "Train Epoch: 1 [13440/110534 (12%)]\tAll Loss: 4.5072\tTriple Loss(1): 0.9801\tClassification Loss: 2.5470\n",
      "Train Epoch: 1 [13760/110534 (12%)]\tAll Loss: 3.4201\tTriple Loss(0): 0.4881\tClassification Loss: 2.4438\n",
      "Train Epoch: 1 [14080/110534 (13%)]\tAll Loss: 4.2018\tTriple Loss(1): 0.8508\tClassification Loss: 2.5002\n",
      "Train Epoch: 1 [14400/110534 (13%)]\tAll Loss: 4.2747\tTriple Loss(1): 0.9568\tClassification Loss: 2.3611\n",
      "Train Epoch: 1 [14720/110534 (13%)]\tAll Loss: 8.5445\tTriple Loss(0): 3.1487\tClassification Loss: 2.2470\n",
      "Train Epoch: 1 [15040/110534 (14%)]\tAll Loss: 4.1940\tTriple Loss(1): 0.9116\tClassification Loss: 2.3708\n",
      "Train Epoch: 1 [15360/110534 (14%)]\tAll Loss: 4.3293\tTriple Loss(1): 0.8798\tClassification Loss: 2.5697\n",
      "Train Epoch: 1 [15680/110534 (14%)]\tAll Loss: 4.8355\tTriple Loss(0): 1.0902\tClassification Loss: 2.6550\n",
      "\n",
      "Test set: Average loss: 2.6613, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [16000/110534 (14%)]\tAll Loss: 4.3279\tTriple Loss(1): 0.9446\tClassification Loss: 2.4386\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_500.pth.tar\n",
      "Train Epoch: 1 [16320/110534 (15%)]\tAll Loss: 4.5907\tTriple Loss(1): 0.9076\tClassification Loss: 2.7754\n",
      "Train Epoch: 1 [16640/110534 (15%)]\tAll Loss: 5.5341\tTriple Loss(0): 1.4708\tClassification Loss: 2.5926\n",
      "Train Epoch: 1 [16960/110534 (15%)]\tAll Loss: 2.4883\tTriple Loss(0): 0.0000\tClassification Loss: 2.4883\n",
      "Train Epoch: 1 [17280/110534 (16%)]\tAll Loss: 4.1963\tTriple Loss(1): 0.8973\tClassification Loss: 2.4017\n",
      "Train Epoch: 1 [17600/110534 (16%)]\tAll Loss: 3.9172\tTriple Loss(1): 0.6945\tClassification Loss: 2.5282\n",
      "Train Epoch: 1 [17920/110534 (16%)]\tAll Loss: 4.1890\tTriple Loss(1): 0.8385\tClassification Loss: 2.5119\n",
      "Train Epoch: 1 [18240/110534 (16%)]\tAll Loss: 4.4191\tTriple Loss(1): 0.9389\tClassification Loss: 2.5413\n",
      "Train Epoch: 1 [18560/110534 (17%)]\tAll Loss: 4.6381\tTriple Loss(1): 0.9491\tClassification Loss: 2.7399\n",
      "Train Epoch: 1 [18880/110534 (17%)]\tAll Loss: 4.3851\tTriple Loss(1): 0.8349\tClassification Loss: 2.7153\n",
      "\n",
      "Test set: Average loss: 2.6528, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [19200/110534 (17%)]\tAll Loss: 4.4306\tTriple Loss(1): 0.9319\tClassification Loss: 2.5668\n",
      "Train Epoch: 1 [19520/110534 (18%)]\tAll Loss: 2.5804\tTriple Loss(0): 0.0000\tClassification Loss: 2.5804\n",
      "Train Epoch: 1 [19840/110534 (18%)]\tAll Loss: 4.1453\tTriple Loss(1): 0.8753\tClassification Loss: 2.3946\n",
      "Train Epoch: 1 [20160/110534 (18%)]\tAll Loss: 4.0131\tTriple Loss(1): 0.8551\tClassification Loss: 2.3028\n",
      "Train Epoch: 1 [20480/110534 (19%)]\tAll Loss: 4.2994\tTriple Loss(1): 0.8849\tClassification Loss: 2.5296\n",
      "Train Epoch: 1 [20800/110534 (19%)]\tAll Loss: 4.4528\tTriple Loss(1): 0.9643\tClassification Loss: 2.5241\n",
      "Train Epoch: 1 [21120/110534 (19%)]\tAll Loss: 4.5310\tTriple Loss(1): 0.8650\tClassification Loss: 2.8009\n",
      "Train Epoch: 1 [21440/110534 (19%)]\tAll Loss: 4.4944\tTriple Loss(1): 0.9457\tClassification Loss: 2.6029\n",
      "Train Epoch: 1 [21760/110534 (20%)]\tAll Loss: 4.1482\tTriple Loss(1): 0.7665\tClassification Loss: 2.6153\n",
      "Train Epoch: 1 [22080/110534 (20%)]\tAll Loss: 4.1255\tTriple Loss(1): 0.7416\tClassification Loss: 2.6424\n",
      "\n",
      "Test set: Average loss: 2.6748, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [22400/110534 (20%)]\tAll Loss: 4.1520\tTriple Loss(1): 0.7861\tClassification Loss: 2.5798\n",
      "Train Epoch: 1 [22720/110534 (21%)]\tAll Loss: 4.3277\tTriple Loss(1): 0.8814\tClassification Loss: 2.5649\n",
      "Train Epoch: 1 [23040/110534 (21%)]\tAll Loss: 4.1481\tTriple Loss(1): 0.8958\tClassification Loss: 2.3566\n",
      "Train Epoch: 1 [23360/110534 (21%)]\tAll Loss: 3.9202\tTriple Loss(1): 0.7689\tClassification Loss: 2.3824\n",
      "Train Epoch: 1 [23680/110534 (21%)]\tAll Loss: 8.2987\tTriple Loss(0): 2.8458\tClassification Loss: 2.6071\n",
      "Train Epoch: 1 [24000/110534 (22%)]\tAll Loss: 4.5714\tTriple Loss(1): 0.9867\tClassification Loss: 2.5980\n",
      "Train Epoch: 1 [24320/110534 (22%)]\tAll Loss: 4.1334\tTriple Loss(1): 0.7681\tClassification Loss: 2.5972\n",
      "Train Epoch: 1 [24640/110534 (22%)]\tAll Loss: 3.8031\tTriple Loss(1): 0.7846\tClassification Loss: 2.2338\n",
      "Train Epoch: 1 [24960/110534 (23%)]\tAll Loss: 3.7348\tTriple Loss(1): 0.6410\tClassification Loss: 2.4527\n",
      "Train Epoch: 1 [25280/110534 (23%)]\tAll Loss: 4.1063\tTriple Loss(1): 0.8097\tClassification Loss: 2.4869\n",
      "\n",
      "Test set: Average loss: 2.6601, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [25600/110534 (23%)]\tAll Loss: 3.9465\tTriple Loss(1): 0.7276\tClassification Loss: 2.4914\n",
      "Train Epoch: 1 [25920/110534 (23%)]\tAll Loss: 5.7636\tTriple Loss(0): 1.5520\tClassification Loss: 2.6596\n",
      "Train Epoch: 1 [26240/110534 (24%)]\tAll Loss: 3.8178\tTriple Loss(1): 0.8391\tClassification Loss: 2.1396\n",
      "Train Epoch: 1 [26560/110534 (24%)]\tAll Loss: 3.7539\tTriple Loss(1): 0.5853\tClassification Loss: 2.5832\n",
      "Train Epoch: 1 [26880/110534 (24%)]\tAll Loss: 3.8732\tTriple Loss(1): 0.6777\tClassification Loss: 2.5177\n",
      "Train Epoch: 1 [27200/110534 (25%)]\tAll Loss: 4.8000\tTriple Loss(0): 1.1752\tClassification Loss: 2.4496\n",
      "Train Epoch: 1 [27520/110534 (25%)]\tAll Loss: 4.1132\tTriple Loss(1): 0.7470\tClassification Loss: 2.6192\n",
      "Train Epoch: 1 [27840/110534 (25%)]\tAll Loss: 4.1018\tTriple Loss(1): 0.8068\tClassification Loss: 2.4883\n",
      "Train Epoch: 1 [28160/110534 (25%)]\tAll Loss: 7.0002\tTriple Loss(0): 2.2984\tClassification Loss: 2.4034\n",
      "Train Epoch: 1 [28480/110534 (26%)]\tAll Loss: 3.9736\tTriple Loss(1): 0.7858\tClassification Loss: 2.4020\n",
      "\n",
      "Test set: Average loss: 2.6639, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [28800/110534 (26%)]\tAll Loss: 3.7584\tTriple Loss(1): 0.6495\tClassification Loss: 2.4594\n",
      "Train Epoch: 1 [29120/110534 (26%)]\tAll Loss: 4.0681\tTriple Loss(1): 0.6573\tClassification Loss: 2.7535\n",
      "Train Epoch: 1 [29440/110534 (27%)]\tAll Loss: 4.4222\tTriple Loss(1): 0.8457\tClassification Loss: 2.7307\n",
      "Train Epoch: 1 [29760/110534 (27%)]\tAll Loss: 4.9471\tTriple Loss(0): 0.9854\tClassification Loss: 2.9762\n",
      "Train Epoch: 1 [30080/110534 (27%)]\tAll Loss: 3.7203\tTriple Loss(1): 0.6304\tClassification Loss: 2.4595\n",
      "Train Epoch: 1 [30400/110534 (27%)]\tAll Loss: 3.6259\tTriple Loss(1): 0.5765\tClassification Loss: 2.4729\n",
      "Train Epoch: 1 [30720/110534 (28%)]\tAll Loss: 4.2980\tTriple Loss(1): 0.8256\tClassification Loss: 2.6469\n",
      "Train Epoch: 1 [31040/110534 (28%)]\tAll Loss: 3.6839\tTriple Loss(1): 0.6456\tClassification Loss: 2.3928\n",
      "Train Epoch: 1 [31360/110534 (28%)]\tAll Loss: 4.0375\tTriple Loss(1): 0.8145\tClassification Loss: 2.4084\n",
      "Train Epoch: 1 [31680/110534 (29%)]\tAll Loss: 4.4286\tTriple Loss(1): 0.8084\tClassification Loss: 2.8117\n",
      "\n",
      "Test set: Average loss: 2.6668, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [32000/110534 (29%)]\tAll Loss: 3.9235\tTriple Loss(1): 0.6228\tClassification Loss: 2.6779\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_1000.pth.tar\n",
      "Train Epoch: 1 [32320/110534 (29%)]\tAll Loss: 4.0697\tTriple Loss(1): 0.8481\tClassification Loss: 2.3736\n",
      "Train Epoch: 1 [32640/110534 (30%)]\tAll Loss: 3.7210\tTriple Loss(1): 0.6839\tClassification Loss: 2.3531\n",
      "Train Epoch: 1 [32960/110534 (30%)]\tAll Loss: 3.4258\tTriple Loss(0): 0.4476\tClassification Loss: 2.5306\n",
      "Train Epoch: 1 [33280/110534 (30%)]\tAll Loss: 4.2453\tTriple Loss(1): 0.8276\tClassification Loss: 2.5901\n",
      "Train Epoch: 1 [33600/110534 (30%)]\tAll Loss: 3.7739\tTriple Loss(1): 0.7161\tClassification Loss: 2.3417\n",
      "Train Epoch: 1 [33920/110534 (31%)]\tAll Loss: 3.8801\tTriple Loss(1): 0.6531\tClassification Loss: 2.5739\n",
      "Train Epoch: 1 [34240/110534 (31%)]\tAll Loss: 3.6513\tTriple Loss(1): 0.7075\tClassification Loss: 2.2363\n",
      "Train Epoch: 1 [34560/110534 (31%)]\tAll Loss: 3.6162\tTriple Loss(0): 0.5754\tClassification Loss: 2.4654\n",
      "Train Epoch: 1 [34880/110534 (32%)]\tAll Loss: 4.5402\tTriple Loss(0): 0.9832\tClassification Loss: 2.5738\n",
      "\n",
      "Test set: Average loss: 2.6561, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [35200/110534 (32%)]\tAll Loss: 3.9922\tTriple Loss(1): 0.6541\tClassification Loss: 2.6840\n",
      "Train Epoch: 1 [35520/110534 (32%)]\tAll Loss: 3.9051\tTriple Loss(0): 0.7399\tClassification Loss: 2.4252\n",
      "Train Epoch: 1 [35840/110534 (32%)]\tAll Loss: 4.0492\tTriple Loss(1): 0.8603\tClassification Loss: 2.3287\n",
      "Train Epoch: 1 [36160/110534 (33%)]\tAll Loss: 4.4272\tTriple Loss(0): 0.9735\tClassification Loss: 2.4803\n",
      "Train Epoch: 1 [36480/110534 (33%)]\tAll Loss: 4.1439\tTriple Loss(1): 0.8121\tClassification Loss: 2.5197\n",
      "Train Epoch: 1 [36800/110534 (33%)]\tAll Loss: 2.7120\tTriple Loss(0): 0.0000\tClassification Loss: 2.7120\n",
      "Train Epoch: 1 [37120/110534 (34%)]\tAll Loss: 4.2137\tTriple Loss(1): 0.7058\tClassification Loss: 2.8021\n",
      "Train Epoch: 1 [37440/110534 (34%)]\tAll Loss: 4.2286\tTriple Loss(1): 0.7150\tClassification Loss: 2.7986\n",
      "Train Epoch: 1 [37760/110534 (34%)]\tAll Loss: 3.9963\tTriple Loss(1): 0.6717\tClassification Loss: 2.6529\n",
      "Train Epoch: 1 [38080/110534 (34%)]\tAll Loss: 4.2253\tTriple Loss(1): 0.8379\tClassification Loss: 2.5496\n",
      "\n",
      "Test set: Average loss: 2.6629, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [38400/110534 (35%)]\tAll Loss: 3.7411\tTriple Loss(1): 0.6992\tClassification Loss: 2.3426\n",
      "Train Epoch: 1 [38720/110534 (35%)]\tAll Loss: 3.3764\tTriple Loss(1): 0.4097\tClassification Loss: 2.5570\n",
      "Train Epoch: 1 [39040/110534 (35%)]\tAll Loss: 4.1509\tTriple Loss(1): 0.8638\tClassification Loss: 2.4232\n",
      "Train Epoch: 1 [39360/110534 (36%)]\tAll Loss: 4.2628\tTriple Loss(1): 0.9046\tClassification Loss: 2.4536\n",
      "Train Epoch: 1 [39680/110534 (36%)]\tAll Loss: 4.2391\tTriple Loss(1): 0.7547\tClassification Loss: 2.7298\n",
      "Train Epoch: 1 [40000/110534 (36%)]\tAll Loss: 2.6321\tTriple Loss(0): 0.0000\tClassification Loss: 2.6321\n",
      "Train Epoch: 1 [40320/110534 (36%)]\tAll Loss: 3.8283\tTriple Loss(1): 0.7154\tClassification Loss: 2.3975\n",
      "Train Epoch: 1 [40640/110534 (37%)]\tAll Loss: 3.8307\tTriple Loss(1): 0.7573\tClassification Loss: 2.3162\n",
      "Train Epoch: 1 [40960/110534 (37%)]\tAll Loss: 3.9246\tTriple Loss(1): 0.7688\tClassification Loss: 2.3869\n",
      "Train Epoch: 1 [41280/110534 (37%)]\tAll Loss: 4.4439\tTriple Loss(1): 0.8794\tClassification Loss: 2.6850\n",
      "\n",
      "Test set: Average loss: 2.7437, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [41600/110534 (38%)]\tAll Loss: 3.8282\tTriple Loss(1): 0.7124\tClassification Loss: 2.4033\n",
      "Train Epoch: 1 [41920/110534 (38%)]\tAll Loss: 3.9216\tTriple Loss(1): 0.7975\tClassification Loss: 2.3266\n",
      "Train Epoch: 1 [42240/110534 (38%)]\tAll Loss: 3.9059\tTriple Loss(1): 0.7218\tClassification Loss: 2.4622\n",
      "Train Epoch: 1 [42560/110534 (38%)]\tAll Loss: 4.2621\tTriple Loss(1): 0.8165\tClassification Loss: 2.6290\n",
      "Train Epoch: 1 [42880/110534 (39%)]\tAll Loss: 3.9384\tTriple Loss(1): 0.6800\tClassification Loss: 2.5784\n",
      "Train Epoch: 1 [43200/110534 (39%)]\tAll Loss: 4.0537\tTriple Loss(1): 0.7590\tClassification Loss: 2.5357\n",
      "Train Epoch: 1 [43520/110534 (39%)]\tAll Loss: 3.8508\tTriple Loss(1): 0.6374\tClassification Loss: 2.5761\n",
      "Train Epoch: 1 [43840/110534 (40%)]\tAll Loss: 3.9722\tTriple Loss(1): 0.7587\tClassification Loss: 2.4548\n",
      "Train Epoch: 1 [44160/110534 (40%)]\tAll Loss: 4.4477\tTriple Loss(1): 0.9011\tClassification Loss: 2.6455\n",
      "Train Epoch: 1 [44480/110534 (40%)]\tAll Loss: 3.9055\tTriple Loss(1): 0.8302\tClassification Loss: 2.2450\n",
      "\n",
      "Test set: Average loss: 2.6481, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [44800/110534 (41%)]\tAll Loss: 4.1332\tTriple Loss(1): 0.7882\tClassification Loss: 2.5567\n",
      "Train Epoch: 1 [45120/110534 (41%)]\tAll Loss: 3.7593\tTriple Loss(1): 0.7328\tClassification Loss: 2.2937\n",
      "Train Epoch: 1 [45440/110534 (41%)]\tAll Loss: 3.8391\tTriple Loss(1): 0.7869\tClassification Loss: 2.2652\n",
      "Train Epoch: 1 [45760/110534 (41%)]\tAll Loss: 4.1812\tTriple Loss(1): 0.8330\tClassification Loss: 2.5152\n",
      "Train Epoch: 1 [46080/110534 (42%)]\tAll Loss: 4.0878\tTriple Loss(1): 0.8500\tClassification Loss: 2.3877\n",
      "Train Epoch: 1 [46400/110534 (42%)]\tAll Loss: 4.2643\tTriple Loss(1): 0.9003\tClassification Loss: 2.4637\n",
      "Train Epoch: 1 [46720/110534 (42%)]\tAll Loss: 3.5854\tTriple Loss(1): 0.7438\tClassification Loss: 2.0979\n",
      "Train Epoch: 1 [47040/110534 (43%)]\tAll Loss: 3.7833\tTriple Loss(1): 0.6576\tClassification Loss: 2.4681\n",
      "Train Epoch: 1 [47360/110534 (43%)]\tAll Loss: 3.9693\tTriple Loss(1): 0.8942\tClassification Loss: 2.1810\n",
      "Train Epoch: 1 [47680/110534 (43%)]\tAll Loss: 3.7576\tTriple Loss(1): 0.5797\tClassification Loss: 2.5983\n",
      "\n",
      "Test set: Average loss: 2.6315, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [48000/110534 (43%)]\tAll Loss: 8.5209\tTriple Loss(0): 3.1098\tClassification Loss: 2.3013\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_1500.pth.tar\n",
      "Train Epoch: 1 [48320/110534 (44%)]\tAll Loss: 4.0806\tTriple Loss(1): 0.7510\tClassification Loss: 2.5787\n",
      "Train Epoch: 1 [48640/110534 (44%)]\tAll Loss: 3.6743\tTriple Loss(1): 0.6843\tClassification Loss: 2.3057\n",
      "Train Epoch: 1 [48960/110534 (44%)]\tAll Loss: 4.1766\tTriple Loss(1): 0.9917\tClassification Loss: 2.1933\n",
      "Train Epoch: 1 [49280/110534 (45%)]\tAll Loss: 4.1863\tTriple Loss(1): 0.8764\tClassification Loss: 2.4335\n",
      "Train Epoch: 1 [49600/110534 (45%)]\tAll Loss: 4.3330\tTriple Loss(1): 0.7780\tClassification Loss: 2.7771\n",
      "Train Epoch: 1 [49920/110534 (45%)]\tAll Loss: 4.0618\tTriple Loss(1): 0.7741\tClassification Loss: 2.5135\n",
      "Train Epoch: 1 [50240/110534 (45%)]\tAll Loss: 3.6110\tTriple Loss(1): 0.5645\tClassification Loss: 2.4819\n",
      "Train Epoch: 1 [50560/110534 (46%)]\tAll Loss: 4.0616\tTriple Loss(1): 0.8380\tClassification Loss: 2.3856\n",
      "Train Epoch: 1 [50880/110534 (46%)]\tAll Loss: 4.4979\tTriple Loss(0): 0.9976\tClassification Loss: 2.5027\n",
      "\n",
      "Test set: Average loss: 2.6499, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [51200/110534 (46%)]\tAll Loss: 4.2981\tTriple Loss(1): 0.8312\tClassification Loss: 2.6357\n",
      "Train Epoch: 1 [51520/110534 (47%)]\tAll Loss: 12.6927\tTriple Loss(0): 5.1161\tClassification Loss: 2.4605\n",
      "Train Epoch: 1 [51840/110534 (47%)]\tAll Loss: 4.2003\tTriple Loss(1): 0.8325\tClassification Loss: 2.5353\n",
      "Train Epoch: 1 [52160/110534 (47%)]\tAll Loss: 3.9495\tTriple Loss(1): 0.7075\tClassification Loss: 2.5345\n",
      "Train Epoch: 1 [52480/110534 (47%)]\tAll Loss: 4.1363\tTriple Loss(1): 0.8198\tClassification Loss: 2.4968\n",
      "Train Epoch: 1 [52800/110534 (48%)]\tAll Loss: 3.8626\tTriple Loss(1): 0.7561\tClassification Loss: 2.3505\n",
      "Train Epoch: 1 [53120/110534 (48%)]\tAll Loss: 4.5070\tTriple Loss(1): 1.0835\tClassification Loss: 2.3401\n",
      "Train Epoch: 1 [53440/110534 (48%)]\tAll Loss: 3.9245\tTriple Loss(1): 0.7964\tClassification Loss: 2.3317\n",
      "Train Epoch: 1 [53760/110534 (49%)]\tAll Loss: 3.6909\tTriple Loss(1): 0.5869\tClassification Loss: 2.5171\n",
      "Train Epoch: 1 [54080/110534 (49%)]\tAll Loss: 3.9717\tTriple Loss(1): 0.8395\tClassification Loss: 2.2927\n",
      "\n",
      "Test set: Average loss: 2.7334, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [54400/110534 (49%)]\tAll Loss: 5.2474\tTriple Loss(0): 1.4444\tClassification Loss: 2.3587\n",
      "Train Epoch: 1 [54720/110534 (49%)]\tAll Loss: 4.4407\tTriple Loss(1): 0.8215\tClassification Loss: 2.7978\n",
      "Train Epoch: 1 [55040/110534 (50%)]\tAll Loss: 3.7474\tTriple Loss(1): 0.6906\tClassification Loss: 2.3662\n",
      "Train Epoch: 1 [55360/110534 (50%)]\tAll Loss: 4.1838\tTriple Loss(0): 0.7159\tClassification Loss: 2.7520\n",
      "Train Epoch: 1 [55680/110534 (50%)]\tAll Loss: 2.4238\tTriple Loss(0): 0.0000\tClassification Loss: 2.4238\n",
      "Train Epoch: 1 [56000/110534 (51%)]\tAll Loss: 3.2547\tTriple Loss(1): 0.4922\tClassification Loss: 2.2703\n",
      "Train Epoch: 1 [56320/110534 (51%)]\tAll Loss: 4.0683\tTriple Loss(1): 0.8153\tClassification Loss: 2.4377\n",
      "Train Epoch: 1 [56640/110534 (51%)]\tAll Loss: 4.3793\tTriple Loss(1): 0.8783\tClassification Loss: 2.6226\n",
      "Train Epoch: 1 [56960/110534 (52%)]\tAll Loss: 4.1905\tTriple Loss(1): 0.7679\tClassification Loss: 2.6548\n",
      "Train Epoch: 1 [57280/110534 (52%)]\tAll Loss: 3.9424\tTriple Loss(1): 0.8441\tClassification Loss: 2.2543\n",
      "\n",
      "Test set: Average loss: 2.6730, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [57600/110534 (52%)]\tAll Loss: 3.8567\tTriple Loss(1): 0.7495\tClassification Loss: 2.3577\n",
      "Train Epoch: 1 [57920/110534 (52%)]\tAll Loss: 3.5804\tTriple Loss(1): 0.6242\tClassification Loss: 2.3320\n",
      "Train Epoch: 1 [58240/110534 (53%)]\tAll Loss: 6.8750\tTriple Loss(0): 2.1449\tClassification Loss: 2.5852\n",
      "Train Epoch: 1 [58560/110534 (53%)]\tAll Loss: 6.0188\tTriple Loss(0): 1.8324\tClassification Loss: 2.3540\n",
      "Train Epoch: 1 [58880/110534 (53%)]\tAll Loss: 3.9976\tTriple Loss(1): 0.8488\tClassification Loss: 2.2999\n",
      "Train Epoch: 1 [59200/110534 (54%)]\tAll Loss: 4.1748\tTriple Loss(1): 0.7894\tClassification Loss: 2.5960\n",
      "Train Epoch: 1 [59520/110534 (54%)]\tAll Loss: 3.9409\tTriple Loss(1): 0.7467\tClassification Loss: 2.4474\n",
      "Train Epoch: 1 [59840/110534 (54%)]\tAll Loss: 4.1466\tTriple Loss(1): 0.7673\tClassification Loss: 2.6120\n",
      "Train Epoch: 1 [60160/110534 (54%)]\tAll Loss: 9.7092\tTriple Loss(0): 3.5342\tClassification Loss: 2.6408\n",
      "Train Epoch: 1 [60480/110534 (55%)]\tAll Loss: 4.5505\tTriple Loss(1): 0.9712\tClassification Loss: 2.6081\n",
      "\n",
      "Test set: Average loss: 2.7275, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [60800/110534 (55%)]\tAll Loss: 4.0273\tTriple Loss(1): 0.6688\tClassification Loss: 2.6897\n",
      "Train Epoch: 1 [61120/110534 (55%)]\tAll Loss: 2.5612\tTriple Loss(0): 0.0000\tClassification Loss: 2.5612\n",
      "Train Epoch: 1 [61440/110534 (56%)]\tAll Loss: 6.3996\tTriple Loss(0): 1.9380\tClassification Loss: 2.5237\n",
      "Train Epoch: 1 [61760/110534 (56%)]\tAll Loss: 3.9192\tTriple Loss(1): 0.5812\tClassification Loss: 2.7568\n",
      "Train Epoch: 1 [62080/110534 (56%)]\tAll Loss: 4.1631\tTriple Loss(1): 0.8311\tClassification Loss: 2.5008\n",
      "Train Epoch: 1 [62400/110534 (56%)]\tAll Loss: 3.9093\tTriple Loss(1): 0.6345\tClassification Loss: 2.6403\n",
      "Train Epoch: 1 [62720/110534 (57%)]\tAll Loss: 3.7834\tTriple Loss(1): 0.6801\tClassification Loss: 2.4232\n",
      "Train Epoch: 1 [63040/110534 (57%)]\tAll Loss: 7.7268\tTriple Loss(0): 2.5676\tClassification Loss: 2.5916\n",
      "Train Epoch: 1 [63360/110534 (57%)]\tAll Loss: 3.9846\tTriple Loss(1): 0.7991\tClassification Loss: 2.3863\n",
      "Train Epoch: 1 [63680/110534 (58%)]\tAll Loss: 6.2936\tTriple Loss(0): 2.0286\tClassification Loss: 2.2364\n",
      "\n",
      "Test set: Average loss: 2.6635, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [64000/110534 (58%)]\tAll Loss: 3.9434\tTriple Loss(1): 0.7060\tClassification Loss: 2.5315\n",
      "Model saved to //content/drive/My Drive/Deep Fashion Retrieval/base/models/model_1_2000.pth.tar\n",
      "Train Epoch: 1 [64320/110534 (58%)]\tAll Loss: 4.6048\tTriple Loss(0): 1.0081\tClassification Loss: 2.5886\n",
      "Train Epoch: 1 [64640/110534 (58%)]\tAll Loss: 3.8410\tTriple Loss(1): 0.7692\tClassification Loss: 2.3027\n",
      "Train Epoch: 1 [64960/110534 (59%)]\tAll Loss: 4.0947\tTriple Loss(1): 0.7699\tClassification Loss: 2.5548\n",
      "Train Epoch: 1 [65280/110534 (59%)]\tAll Loss: 3.8123\tTriple Loss(1): 0.6383\tClassification Loss: 2.5357\n",
      "Train Epoch: 1 [65600/110534 (59%)]\tAll Loss: 6.1475\tTriple Loss(0): 1.8844\tClassification Loss: 2.3786\n",
      "Train Epoch: 1 [65920/110534 (60%)]\tAll Loss: 4.0878\tTriple Loss(1): 0.8280\tClassification Loss: 2.4319\n",
      "Train Epoch: 1 [66240/110534 (60%)]\tAll Loss: 3.9971\tTriple Loss(1): 0.8480\tClassification Loss: 2.3010\n",
      "Train Epoch: 1 [66560/110534 (60%)]\tAll Loss: 4.1392\tTriple Loss(1): 0.9196\tClassification Loss: 2.3000\n",
      "Train Epoch: 1 [66880/110534 (60%)]\tAll Loss: 3.9952\tTriple Loss(1): 0.6688\tClassification Loss: 2.6576\n",
      "\n",
      "Test set: Average loss: 2.7002, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [67200/110534 (61%)]\tAll Loss: 4.0636\tTriple Loss(1): 0.8800\tClassification Loss: 2.3036\n",
      "Train Epoch: 1 [67520/110534 (61%)]\tAll Loss: 4.3451\tTriple Loss(1): 0.8504\tClassification Loss: 2.6442\n",
      "Train Epoch: 1 [67840/110534 (61%)]\tAll Loss: 3.9375\tTriple Loss(1): 0.6755\tClassification Loss: 2.5865\n",
      "Train Epoch: 1 [68160/110534 (62%)]\tAll Loss: 4.3661\tTriple Loss(1): 0.8514\tClassification Loss: 2.6634\n",
      "Train Epoch: 1 [68480/110534 (62%)]\tAll Loss: 4.2320\tTriple Loss(1): 0.8666\tClassification Loss: 2.4987\n",
      "Train Epoch: 1 [68800/110534 (62%)]\tAll Loss: 3.7889\tTriple Loss(1): 0.7018\tClassification Loss: 2.3853\n",
      "Train Epoch: 1 [69120/110534 (63%)]\tAll Loss: 4.2493\tTriple Loss(1): 0.8332\tClassification Loss: 2.5828\n",
      "Train Epoch: 1 [69440/110534 (63%)]\tAll Loss: 4.3882\tTriple Loss(1): 0.9122\tClassification Loss: 2.5638\n",
      "Train Epoch: 1 [69760/110534 (63%)]\tAll Loss: 4.1909\tTriple Loss(1): 0.7531\tClassification Loss: 2.6846\n",
      "Train Epoch: 1 [70080/110534 (63%)]\tAll Loss: 3.6834\tTriple Loss(1): 0.7582\tClassification Loss: 2.1669\n",
      "\n",
      "Test set: Average loss: 2.6748, Accuracy: 244/960 (25%)\n",
      "\n",
      "Train Epoch: 1 [70400/110534 (64%)]\tAll Loss: 3.7322\tTriple Loss(1): 0.8063\tClassification Loss: 2.1195\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Train Epoch: 1 [0/110534 (0%)]\tClassification Loss: 3.2830\r\n",
      "train.py:172: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 3.2866, Accuracy: 881/42368 (2%)\r\n",
      "\r\n",
      "Train Epoch: 1 [640/110534 (1%)]\tClassification Loss: 2.7224\r\n",
      "Train Epoch: 1 [1280/110534 (1%)]\tClassification Loss: 2.7177\r\n",
      "Train Epoch: 1 [1920/110534 (2%)]\tClassification Loss: 2.3749\r\n",
      "Train Epoch: 1 [2560/110534 (2%)]\tClassification Loss: 2.5729\r\n",
      "Train Epoch: 1 [3200/110534 (3%)]\tClassification Loss: 2.3552\r\n",
      "Train Epoch: 1 [3840/110534 (3%)]\tClassification Loss: 2.4252\r\n",
      "Train Epoch: 1 [4480/110534 (4%)]\tClassification Loss: 2.3285\r\n",
      "Train Epoch: 1 [5120/110534 (5%)]\tClassification Loss: 2.1731\r\n",
      "Train Epoch: 1 [5760/110534 (5%)]\tClassification Loss: 2.2027\r\n",
      "Train Epoch: 1 [6400/110534 (6%)]\tClassification Loss: 2.1161\r\n",
      "Train Epoch: 1 [7040/110534 (6%)]\tClassification Loss: 2.1546\r\n",
      "Train Epoch: 1 [7680/110534 (7%)]\tClassification Loss: 2.2371\r\n",
      "Train Epoch: 1 [8320/110534 (8%)]\tClassification Loss: 2.1920\r\n",
      "Train Epoch: 1 [8960/110534 (8%)]\tClassification Loss: 2.2503\r\n",
      "Train Epoch: 1 [9600/110534 (9%)]\tClassification Loss: 1.9809\r\n",
      "Train Epoch: 1 [10240/110534 (9%)]\tClassification Loss: 2.0242\r\n",
      "Train Epoch: 1 [10880/110534 (10%)]\tClassification Loss: 1.9162\r\n",
      "Train Epoch: 1 [11520/110534 (10%)]\tClassification Loss: 2.3605\r\n",
      "Train Epoch: 1 [12160/110534 (11%)]\tClassification Loss: 1.8797\r\n",
      "Train Epoch: 1 [12800/110534 (12%)]\tClassification Loss: 2.0401\r\n",
      "Train Epoch: 1 [13440/110534 (12%)]\tClassification Loss: 1.9739\r\n",
      "Train Epoch: 1 [14080/110534 (13%)]\tClassification Loss: 1.8512\r\n",
      "Train Epoch: 1 [14720/110534 (13%)]\tClassification Loss: 2.0219\r\n",
      "Train Epoch: 1 [15360/110534 (14%)]\tClassification Loss: 1.8937\r\n",
      "Train Epoch: 1 [16000/110534 (14%)]\tClassification Loss: 2.1112\r\n",
      "Train Epoch: 1 [16640/110534 (15%)]\tClassification Loss: 1.8821\r\n",
      "Train Epoch: 1 [17280/110534 (16%)]\tClassification Loss: 1.8996\r\n",
      "Train Epoch: 1 [17920/110534 (16%)]\tClassification Loss: 1.9671\r\n",
      "Train Epoch: 1 [18560/110534 (17%)]\tClassification Loss: 2.0795\r\n",
      "Train Epoch: 1 [19200/110534 (17%)]\tClassification Loss: 1.9520\r\n",
      "Train Epoch: 1 [19840/110534 (18%)]\tClassification Loss: 1.9012\r\n",
      "Train Epoch: 1 [20480/110534 (19%)]\tClassification Loss: 2.0401\r\n",
      "Train Epoch: 1 [21120/110534 (19%)]\tClassification Loss: 2.1207\r\n",
      "Train Epoch: 1 [21760/110534 (20%)]\tClassification Loss: 1.6625\r\n",
      "Train Epoch: 1 [22400/110534 (20%)]\tClassification Loss: 1.9000\r\n",
      "Train Epoch: 1 [23040/110534 (21%)]\tClassification Loss: 1.5602\r\n",
      "Train Epoch: 1 [23680/110534 (21%)]\tClassification Loss: 2.1209\r\n",
      "Train Epoch: 1 [24320/110534 (22%)]\tClassification Loss: 1.5847\r\n",
      "Train Epoch: 1 [24960/110534 (23%)]\tClassification Loss: 1.7797\r\n",
      "Train Epoch: 1 [25600/110534 (23%)]\tClassification Loss: 1.5993\r\n",
      "Train Epoch: 1 [26240/110534 (24%)]\tClassification Loss: 1.7593\r\n",
      "Train Epoch: 1 [26880/110534 (24%)]\tClassification Loss: 2.2115\r\n",
      "Train Epoch: 1 [27520/110534 (25%)]\tClassification Loss: 1.8452\r\n",
      "Train Epoch: 1 [28160/110534 (25%)]\tClassification Loss: 1.9894\r\n",
      "Train Epoch: 1 [28800/110534 (26%)]\tClassification Loss: 2.0064\r\n",
      "Train Epoch: 1 [29440/110534 (27%)]\tClassification Loss: 1.8556\r\n",
      "Train Epoch: 1 [30080/110534 (27%)]\tClassification Loss: 1.9429\r\n",
      "Train Epoch: 1 [30720/110534 (28%)]\tClassification Loss: 1.9002\r\n",
      "Train Epoch: 1 [31360/110534 (28%)]\tClassification Loss: 1.8466\r\n",
      "Train Epoch: 1 [32000/110534 (29%)]\tClassification Loss: 1.6756\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_500.pth.tar\r\n",
      "Train Epoch: 1 [32640/110534 (30%)]\tClassification Loss: 1.7005\r\n",
      "Train Epoch: 1 [33280/110534 (30%)]\tClassification Loss: 1.8853\r\n",
      "Train Epoch: 1 [33920/110534 (31%)]\tClassification Loss: 1.8128\r\n",
      "Train Epoch: 1 [34560/110534 (31%)]\tClassification Loss: 1.8939\r\n",
      "Train Epoch: 1 [35200/110534 (32%)]\tClassification Loss: 1.7203\r\n",
      "Train Epoch: 1 [35840/110534 (32%)]\tClassification Loss: 1.6295\r\n",
      "Train Epoch: 1 [36480/110534 (33%)]\tClassification Loss: 1.7771\r\n",
      "Train Epoch: 1 [37120/110534 (34%)]\tClassification Loss: 1.9714\r\n",
      "Train Epoch: 1 [37760/110534 (34%)]\tClassification Loss: 2.2096\r\n",
      "Train Epoch: 1 [38400/110534 (35%)]\tClassification Loss: 1.9548\r\n",
      "Train Epoch: 1 [39040/110534 (35%)]\tClassification Loss: 1.7486\r\n",
      "Train Epoch: 1 [39680/110534 (36%)]\tClassification Loss: 1.6933\r\n",
      "Train Epoch: 1 [40320/110534 (36%)]\tClassification Loss: 1.9459\r\n",
      "Train Epoch: 1 [40960/110534 (37%)]\tClassification Loss: 1.6157\r\n",
      "Train Epoch: 1 [41600/110534 (38%)]\tClassification Loss: 1.7086\r\n",
      "Train Epoch: 1 [42240/110534 (38%)]\tClassification Loss: 1.9263\r\n",
      "Train Epoch: 1 [42880/110534 (39%)]\tClassification Loss: 1.6883\r\n",
      "Train Epoch: 1 [43520/110534 (39%)]\tClassification Loss: 1.2982\r\n",
      "Train Epoch: 1 [44160/110534 (40%)]\tClassification Loss: 1.6984\r\n",
      "Train Epoch: 1 [44800/110534 (41%)]\tClassification Loss: 1.8301\r\n",
      "Train Epoch: 1 [45440/110534 (41%)]\tClassification Loss: 1.7233\r\n",
      "Train Epoch: 1 [46080/110534 (42%)]\tClassification Loss: 1.4230\r\n",
      "Train Epoch: 1 [46720/110534 (42%)]\tClassification Loss: 1.6845\r\n",
      "Train Epoch: 1 [47360/110534 (43%)]\tClassification Loss: 1.7421\r\n",
      "Train Epoch: 1 [48000/110534 (43%)]\tClassification Loss: 1.7164\r\n",
      "Train Epoch: 1 [48640/110534 (44%)]\tClassification Loss: 1.5246\r\n",
      "Train Epoch: 1 [49280/110534 (45%)]\tClassification Loss: 1.7002\r\n",
      "Train Epoch: 1 [49920/110534 (45%)]\tClassification Loss: 1.8754\r\n",
      "Train Epoch: 1 [50560/110534 (46%)]\tClassification Loss: 1.7875\r\n",
      "Train Epoch: 1 [51200/110534 (46%)]\tClassification Loss: 1.6970\r\n",
      "Train Epoch: 1 [51840/110534 (47%)]\tClassification Loss: 1.7703\r\n",
      "Train Epoch: 1 [52480/110534 (47%)]\tClassification Loss: 1.7871\r\n",
      "Train Epoch: 1 [53120/110534 (48%)]\tClassification Loss: 1.5486\r\n",
      "Train Epoch: 1 [53760/110534 (49%)]\tClassification Loss: 1.7035\r\n",
      "Train Epoch: 1 [54400/110534 (49%)]\tClassification Loss: 1.6885\r\n",
      "Train Epoch: 1 [55040/110534 (50%)]\tClassification Loss: 1.8707\r\n",
      "Train Epoch: 1 [55680/110534 (50%)]\tClassification Loss: 1.8622\r\n",
      "Train Epoch: 1 [56320/110534 (51%)]\tClassification Loss: 1.6002\r\n",
      "Train Epoch: 1 [56960/110534 (52%)]\tClassification Loss: 1.8192\r\n",
      "Train Epoch: 1 [57600/110534 (52%)]\tClassification Loss: 1.8526\r\n",
      "Train Epoch: 1 [58240/110534 (53%)]\tClassification Loss: 1.8116\r\n",
      "Train Epoch: 1 [58880/110534 (53%)]\tClassification Loss: 2.1013\r\n",
      "Train Epoch: 1 [59520/110534 (54%)]\tClassification Loss: 1.5211\r\n",
      "Train Epoch: 1 [60160/110534 (54%)]\tClassification Loss: 1.6251\r\n",
      "Train Epoch: 1 [60800/110534 (55%)]\tClassification Loss: 1.8971\r\n",
      "Train Epoch: 1 [61440/110534 (56%)]\tClassification Loss: 1.8057\r\n",
      "Train Epoch: 1 [62080/110534 (56%)]\tClassification Loss: 1.5887\r\n",
      "Train Epoch: 1 [62720/110534 (57%)]\tClassification Loss: 1.9606\r\n",
      "Train Epoch: 1 [63360/110534 (57%)]\tClassification Loss: 1.5219\r\n",
      "Train Epoch: 1 [64000/110534 (58%)]\tClassification Loss: 1.5380\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1000.pth.tar\r\n",
      "Train Epoch: 1 [64640/110534 (58%)]\tClassification Loss: 1.4068\r\n",
      "Train Epoch: 1 [65280/110534 (59%)]\tClassification Loss: 1.7826\r\n",
      "Train Epoch: 1 [65920/110534 (60%)]\tClassification Loss: 1.4417\r\n",
      "Train Epoch: 1 [66560/110534 (60%)]\tClassification Loss: 1.4876\r\n",
      "Train Epoch: 1 [67200/110534 (61%)]\tClassification Loss: 1.5753\r\n",
      "Train Epoch: 1 [67840/110534 (61%)]\tClassification Loss: 1.9129\r\n",
      "Train Epoch: 1 [68480/110534 (62%)]\tClassification Loss: 1.7711\r\n",
      "Train Epoch: 1 [69120/110534 (63%)]\tClassification Loss: 1.8383\r\n",
      "Train Epoch: 1 [69760/110534 (63%)]\tClassification Loss: 1.6934\r\n",
      "Train Epoch: 1 [70400/110534 (64%)]\tClassification Loss: 1.2958\r\n",
      "Train Epoch: 1 [71040/110534 (64%)]\tClassification Loss: 1.9336\r\n",
      "Train Epoch: 1 [71680/110534 (65%)]\tClassification Loss: 1.7150\r\n",
      "Train Epoch: 1 [72320/110534 (65%)]\tClassification Loss: 1.6626\r\n",
      "Train Epoch: 1 [72960/110534 (66%)]\tClassification Loss: 1.8084\r\n",
      "Train Epoch: 1 [73600/110534 (67%)]\tClassification Loss: 1.8502\r\n",
      "Train Epoch: 1 [74240/110534 (67%)]\tClassification Loss: 1.9545\r\n",
      "Train Epoch: 1 [74880/110534 (68%)]\tClassification Loss: 1.4022\r\n",
      "Train Epoch: 1 [75520/110534 (68%)]\tClassification Loss: 1.5480\r\n",
      "Train Epoch: 1 [76160/110534 (69%)]\tClassification Loss: 1.4773\r\n",
      "Train Epoch: 1 [76800/110534 (69%)]\tClassification Loss: 1.5353\r\n",
      "Train Epoch: 1 [77440/110534 (70%)]\tClassification Loss: 1.4291\r\n",
      "Train Epoch: 1 [78080/110534 (71%)]\tClassification Loss: 1.7648\r\n",
      "Train Epoch: 1 [78720/110534 (71%)]\tClassification Loss: 1.6058\r\n",
      "Train Epoch: 1 [79360/110534 (72%)]\tClassification Loss: 1.4660\r\n",
      "Train Epoch: 1 [80000/110534 (72%)]\tClassification Loss: 1.5182\r\n",
      "Train Epoch: 1 [80640/110534 (73%)]\tClassification Loss: 1.4907\r\n",
      "Train Epoch: 1 [81280/110534 (74%)]\tClassification Loss: 2.0744\r\n",
      "Train Epoch: 1 [81920/110534 (74%)]\tClassification Loss: 1.8504\r\n",
      "Train Epoch: 1 [82560/110534 (75%)]\tClassification Loss: 2.0825\r\n",
      "Train Epoch: 1 [83200/110534 (75%)]\tClassification Loss: 1.6420\r\n",
      "Train Epoch: 1 [83840/110534 (76%)]\tClassification Loss: 2.0594\r\n",
      "Train Epoch: 1 [84480/110534 (76%)]\tClassification Loss: 1.7862\r\n",
      "Train Epoch: 1 [85120/110534 (77%)]\tClassification Loss: 1.6581\r\n",
      "Train Epoch: 1 [85760/110534 (78%)]\tClassification Loss: 1.6371\r\n",
      "Train Epoch: 1 [86400/110534 (78%)]\tClassification Loss: 1.6309\r\n",
      "Train Epoch: 1 [87040/110534 (79%)]\tClassification Loss: 1.5464\r\n",
      "Train Epoch: 1 [87680/110534 (79%)]\tClassification Loss: 1.4622\r\n",
      "Train Epoch: 1 [88320/110534 (80%)]\tClassification Loss: 1.7205\r\n",
      "Train Epoch: 1 [88960/110534 (80%)]\tClassification Loss: 1.6689\r\n",
      "Train Epoch: 1 [89600/110534 (81%)]\tClassification Loss: 1.7918\r\n",
      "Train Epoch: 1 [90240/110534 (82%)]\tClassification Loss: 1.7639\r\n",
      "Train Epoch: 1 [90880/110534 (82%)]\tClassification Loss: 1.6792\r\n",
      "Train Epoch: 1 [91520/110534 (83%)]\tClassification Loss: 1.3417\r\n",
      "Train Epoch: 1 [92160/110534 (83%)]\tClassification Loss: 1.4161\r\n",
      "Train Epoch: 1 [92800/110534 (84%)]\tClassification Loss: 1.5393\r\n",
      "Train Epoch: 1 [93440/110534 (85%)]\tClassification Loss: 1.8946\r\n",
      "Train Epoch: 1 [94080/110534 (85%)]\tClassification Loss: 1.6331\r\n",
      "Train Epoch: 1 [94720/110534 (86%)]\tClassification Loss: 1.7000\r\n",
      "Train Epoch: 1 [95360/110534 (86%)]\tClassification Loss: 1.5858\r\n",
      "Train Epoch: 1 [96000/110534 (87%)]\tClassification Loss: 1.6703\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1500.pth.tar\r\n",
      "Train Epoch: 1 [96640/110534 (87%)]\tClassification Loss: 1.4982\r\n",
      "Train Epoch: 1 [97280/110534 (88%)]\tClassification Loss: 1.2956\r\n",
      "Train Epoch: 1 [97920/110534 (89%)]\tClassification Loss: 1.3405\r\n",
      "Train Epoch: 1 [98560/110534 (89%)]\tClassification Loss: 1.4833\r\n",
      "Train Epoch: 1 [99200/110534 (90%)]\tClassification Loss: 1.7252\r\n",
      "Train Epoch: 1 [99840/110534 (90%)]\tClassification Loss: 1.5546\r\n",
      "Train Epoch: 1 [100480/110534 (91%)]\tClassification Loss: 1.8996\r\n",
      "Train Epoch: 1 [101120/110534 (91%)]\tClassification Loss: 1.5926\r\n",
      "Train Epoch: 1 [101760/110534 (92%)]\tClassification Loss: 1.6356\r\n",
      "Train Epoch: 1 [102400/110534 (93%)]\tClassification Loss: 1.5151\r\n",
      "Train Epoch: 1 [103040/110534 (93%)]\tClassification Loss: 1.6247\r\n",
      "Train Epoch: 1 [103680/110534 (94%)]\tClassification Loss: 1.8755\r\n",
      "Train Epoch: 1 [104320/110534 (94%)]\tClassification Loss: 1.5259\r\n",
      "Train Epoch: 1 [104960/110534 (95%)]\tClassification Loss: 1.7966\r\n",
      "Train Epoch: 1 [105600/110534 (96%)]\tClassification Loss: 1.6040\r\n",
      "Train Epoch: 1 [106240/110534 (96%)]\tClassification Loss: 1.3866\r\n",
      "Train Epoch: 1 [106880/110534 (97%)]\tClassification Loss: 1.9838\r\n",
      "Train Epoch: 1 [107520/110534 (97%)]\tClassification Loss: 1.6532\r\n",
      "Train Epoch: 1 [108160/110534 (98%)]\tClassification Loss: 1.6593\r\n",
      "Train Epoch: 1 [108800/110534 (98%)]\tClassification Loss: 1.8018\r\n",
      "Train Epoch: 1 [109440/110534 (99%)]\tClassification Loss: 1.6680\r\n",
      "Train Epoch: 1 [110080/110534 (100%)]\tClassification Loss: 1.5229\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_final.pth.tar\r\n",
      "Train Epoch: 2 [0/110534 (0%)]\tClassification Loss: 1.8750\r\n",
      "\r\n",
      "Test set: Average loss: 1.5445, Accuracy: 22083/42368 (52%)\r\n",
      "\r\n",
      "Train Epoch: 2 [640/110534 (1%)]\tClassification Loss: 1.4835\r\n",
      "Train Epoch: 2 [1280/110534 (1%)]\tClassification Loss: 2.1183\r\n",
      "Train Epoch: 2 [1920/110534 (2%)]\tClassification Loss: 1.7282\r\n",
      "Train Epoch: 2 [2560/110534 (2%)]\tClassification Loss: 1.9031\r\n",
      "Train Epoch: 2 [3200/110534 (3%)]\tClassification Loss: 1.5386\r\n",
      "Train Epoch: 2 [3840/110534 (3%)]\tClassification Loss: 1.5584\r\n",
      "Train Epoch: 2 [4480/110534 (4%)]\tClassification Loss: 1.6591\r\n",
      "Train Epoch: 2 [5120/110534 (5%)]\tClassification Loss: 1.5458\r\n",
      "Train Epoch: 2 [5760/110534 (5%)]\tClassification Loss: 1.7117\r\n",
      "Train Epoch: 2 [6400/110534 (6%)]\tClassification Loss: 1.3224\r\n",
      "Train Epoch: 2 [7040/110534 (6%)]\tClassification Loss: 1.6015\r\n",
      "Train Epoch: 2 [7680/110534 (7%)]\tClassification Loss: 1.7565\r\n",
      "Train Epoch: 2 [8320/110534 (8%)]\tClassification Loss: 1.7614\r\n",
      "Train Epoch: 2 [8960/110534 (8%)]\tClassification Loss: 1.9147\r\n",
      "Train Epoch: 2 [9600/110534 (9%)]\tClassification Loss: 1.4126\r\n",
      "Train Epoch: 2 [10240/110534 (9%)]\tClassification Loss: 1.7070\r\n",
      "Train Epoch: 2 [10880/110534 (10%)]\tClassification Loss: 1.5839\r\n",
      "Train Epoch: 2 [11520/110534 (10%)]\tClassification Loss: 1.9769\r\n",
      "Train Epoch: 2 [12160/110534 (11%)]\tClassification Loss: 1.5012\r\n",
      "Train Epoch: 2 [12800/110534 (12%)]\tClassification Loss: 1.5868\r\n",
      "Train Epoch: 2 [13440/110534 (12%)]\tClassification Loss: 1.4642\r\n",
      "Train Epoch: 2 [14080/110534 (13%)]\tClassification Loss: 1.6337\r\n",
      "Train Epoch: 2 [14720/110534 (13%)]\tClassification Loss: 1.8021\r\n",
      "Train Epoch: 2 [15360/110534 (14%)]\tClassification Loss: 1.5672\r\n",
      "Train Epoch: 2 [16000/110534 (14%)]\tClassification Loss: 1.7221\r\n",
      "Train Epoch: 2 [16640/110534 (15%)]\tClassification Loss: 1.5980\r\n",
      "Train Epoch: 2 [17280/110534 (16%)]\tClassification Loss: 1.7394\r\n",
      "Train Epoch: 2 [17920/110534 (16%)]\tClassification Loss: 1.7472\r\n",
      "Train Epoch: 2 [18560/110534 (17%)]\tClassification Loss: 1.7990\r\n",
      "Train Epoch: 2 [19200/110534 (17%)]\tClassification Loss: 1.6011\r\n",
      "Train Epoch: 2 [19840/110534 (18%)]\tClassification Loss: 1.6455\r\n",
      "Train Epoch: 2 [20480/110534 (19%)]\tClassification Loss: 1.8375\r\n",
      "Train Epoch: 2 [21120/110534 (19%)]\tClassification Loss: 1.6775\r\n",
      "Train Epoch: 2 [21760/110534 (20%)]\tClassification Loss: 1.3818\r\n",
      "Train Epoch: 2 [22400/110534 (20%)]\tClassification Loss: 1.7026\r\n",
      "Train Epoch: 2 [23040/110534 (21%)]\tClassification Loss: 1.1058\r\n",
      "Train Epoch: 2 [23680/110534 (21%)]\tClassification Loss: 1.7887\r\n",
      "Train Epoch: 2 [24320/110534 (22%)]\tClassification Loss: 1.2859\r\n",
      "Train Epoch: 2 [24960/110534 (23%)]\tClassification Loss: 1.7508\r\n",
      "Train Epoch: 2 [25600/110534 (23%)]\tClassification Loss: 1.5068\r\n",
      "Train Epoch: 2 [26240/110534 (24%)]\tClassification Loss: 1.5864\r\n",
      "Train Epoch: 2 [26880/110534 (24%)]\tClassification Loss: 1.8634\r\n",
      "Train Epoch: 2 [27520/110534 (25%)]\tClassification Loss: 1.5427\r\n",
      "Train Epoch: 2 [28160/110534 (25%)]\tClassification Loss: 1.9200\r\n",
      "Train Epoch: 2 [28800/110534 (26%)]\tClassification Loss: 1.9742\r\n",
      "Train Epoch: 2 [29440/110534 (27%)]\tClassification Loss: 1.5614\r\n",
      "Train Epoch: 2 [30080/110534 (27%)]\tClassification Loss: 1.7920\r\n",
      "Train Epoch: 2 [30720/110534 (28%)]\tClassification Loss: 1.5552\r\n",
      "Train Epoch: 2 [31360/110534 (28%)]\tClassification Loss: 1.6268\r\n",
      "Train Epoch: 2 [32000/110534 (29%)]\tClassification Loss: 1.5518\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_500.pth.tar\r\n",
      "Train Epoch: 2 [32640/110534 (30%)]\tClassification Loss: 1.3488\r\n",
      "Train Epoch: 2 [33280/110534 (30%)]\tClassification Loss: 1.6518\r\n",
      "Train Epoch: 2 [33920/110534 (31%)]\tClassification Loss: 1.6350\r\n",
      "Train Epoch: 2 [34560/110534 (31%)]\tClassification Loss: 1.6605\r\n",
      "Train Epoch: 2 [35200/110534 (32%)]\tClassification Loss: 1.6797\r\n",
      "Train Epoch: 2 [35840/110534 (32%)]\tClassification Loss: 1.3802\r\n",
      "Train Epoch: 2 [36480/110534 (33%)]\tClassification Loss: 1.5710\r\n",
      "Train Epoch: 2 [37120/110534 (34%)]\tClassification Loss: 1.7778\r\n",
      "Train Epoch: 2 [37760/110534 (34%)]\tClassification Loss: 2.0085\r\n",
      "Train Epoch: 2 [38400/110534 (35%)]\tClassification Loss: 1.7027\r\n",
      "Train Epoch: 2 [39040/110534 (35%)]\tClassification Loss: 1.4603\r\n",
      "Train Epoch: 2 [39680/110534 (36%)]\tClassification Loss: 1.6150\r\n",
      "Train Epoch: 2 [40320/110534 (36%)]\tClassification Loss: 1.8060\r\n",
      "Train Epoch: 2 [40960/110534 (37%)]\tClassification Loss: 1.4558\r\n",
      "Train Epoch: 2 [41600/110534 (38%)]\tClassification Loss: 1.5027\r\n",
      "Train Epoch: 2 [42240/110534 (38%)]\tClassification Loss: 1.6026\r\n",
      "Train Epoch: 2 [42880/110534 (39%)]\tClassification Loss: 1.5262\r\n",
      "Train Epoch: 2 [43520/110534 (39%)]\tClassification Loss: 1.3493\r\n",
      "Train Epoch: 2 [44160/110534 (40%)]\tClassification Loss: 1.4719\r\n",
      "Train Epoch: 2 [44800/110534 (41%)]\tClassification Loss: 1.6800\r\n",
      "Train Epoch: 2 [45440/110534 (41%)]\tClassification Loss: 1.7248\r\n",
      "Train Epoch: 2 [46080/110534 (42%)]\tClassification Loss: 1.3953\r\n",
      "Train Epoch: 2 [46720/110534 (42%)]\tClassification Loss: 1.5037\r\n",
      "Train Epoch: 2 [47360/110534 (43%)]\tClassification Loss: 1.5299\r\n",
      "Train Epoch: 2 [48000/110534 (43%)]\tClassification Loss: 1.7093\r\n",
      "Train Epoch: 2 [48640/110534 (44%)]\tClassification Loss: 1.3959\r\n",
      "Train Epoch: 2 [49280/110534 (45%)]\tClassification Loss: 1.5755\r\n",
      "Train Epoch: 2 [49920/110534 (45%)]\tClassification Loss: 1.8094\r\n",
      "Train Epoch: 2 [50560/110534 (46%)]\tClassification Loss: 1.5690\r\n",
      "Train Epoch: 2 [51200/110534 (46%)]\tClassification Loss: 1.3979\r\n",
      "Train Epoch: 2 [51840/110534 (47%)]\tClassification Loss: 1.6206\r\n",
      "Train Epoch: 2 [52480/110534 (47%)]\tClassification Loss: 1.6468\r\n",
      "Train Epoch: 2 [53120/110534 (48%)]\tClassification Loss: 1.4135\r\n",
      "Train Epoch: 2 [53760/110534 (49%)]\tClassification Loss: 1.6985\r\n",
      "Train Epoch: 2 [54400/110534 (49%)]\tClassification Loss: 1.5548\r\n",
      "Train Epoch: 2 [55040/110534 (50%)]\tClassification Loss: 1.9448\r\n",
      "Train Epoch: 2 [55680/110534 (50%)]\tClassification Loss: 1.6919\r\n",
      "Train Epoch: 2 [56320/110534 (51%)]\tClassification Loss: 1.5949\r\n",
      "Train Epoch: 2 [56960/110534 (52%)]\tClassification Loss: 1.6244\r\n",
      "Train Epoch: 2 [57600/110534 (52%)]\tClassification Loss: 1.8393\r\n",
      "Train Epoch: 2 [58240/110534 (53%)]\tClassification Loss: 1.6792\r\n",
      "Train Epoch: 2 [58880/110534 (53%)]\tClassification Loss: 1.8839\r\n",
      "Train Epoch: 2 [59520/110534 (54%)]\tClassification Loss: 1.3625\r\n",
      "Train Epoch: 2 [60160/110534 (54%)]\tClassification Loss: 1.6554\r\n",
      "Train Epoch: 2 [60800/110534 (55%)]\tClassification Loss: 1.7989\r\n",
      "Train Epoch: 2 [61440/110534 (56%)]\tClassification Loss: 1.7864\r\n",
      "Train Epoch: 2 [62080/110534 (56%)]\tClassification Loss: 1.5952\r\n",
      "Train Epoch: 2 [62720/110534 (57%)]\tClassification Loss: 1.7226\r\n",
      "Train Epoch: 2 [63360/110534 (57%)]\tClassification Loss: 1.4735\r\n",
      "Train Epoch: 2 [64000/110534 (58%)]\tClassification Loss: 1.5559\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1000.pth.tar\r\n",
      "Train Epoch: 2 [64640/110534 (58%)]\tClassification Loss: 1.3295\r\n",
      "Train Epoch: 2 [65280/110534 (59%)]\tClassification Loss: 1.5663\r\n",
      "Train Epoch: 2 [65920/110534 (60%)]\tClassification Loss: 1.6064\r\n",
      "Train Epoch: 2 [66560/110534 (60%)]\tClassification Loss: 1.4289\r\n",
      "Train Epoch: 2 [67200/110534 (61%)]\tClassification Loss: 1.4008\r\n",
      "Train Epoch: 2 [67840/110534 (61%)]\tClassification Loss: 1.9748\r\n",
      "Train Epoch: 2 [68480/110534 (62%)]\tClassification Loss: 1.7302\r\n",
      "Train Epoch: 2 [69120/110534 (63%)]\tClassification Loss: 1.8534\r\n",
      "Train Epoch: 2 [69760/110534 (63%)]\tClassification Loss: 1.6410\r\n",
      "Train Epoch: 2 [70400/110534 (64%)]\tClassification Loss: 1.3202\r\n",
      "Train Epoch: 2 [71040/110534 (64%)]\tClassification Loss: 1.7289\r\n",
      "Train Epoch: 2 [71680/110534 (65%)]\tClassification Loss: 1.4858\r\n",
      "Train Epoch: 2 [72320/110534 (65%)]\tClassification Loss: 1.6076\r\n",
      "Train Epoch: 2 [72960/110534 (66%)]\tClassification Loss: 1.6902\r\n",
      "Train Epoch: 2 [73600/110534 (67%)]\tClassification Loss: 1.8841\r\n",
      "Train Epoch: 2 [74240/110534 (67%)]\tClassification Loss: 1.9036\r\n",
      "Train Epoch: 2 [74880/110534 (68%)]\tClassification Loss: 1.3267\r\n",
      "Train Epoch: 2 [75520/110534 (68%)]\tClassification Loss: 1.5880\r\n",
      "Train Epoch: 2 [76160/110534 (69%)]\tClassification Loss: 1.4670\r\n",
      "Train Epoch: 2 [76800/110534 (69%)]\tClassification Loss: 1.3185\r\n",
      "Train Epoch: 2 [77440/110534 (70%)]\tClassification Loss: 1.5026\r\n",
      "Train Epoch: 2 [78080/110534 (71%)]\tClassification Loss: 1.6610\r\n",
      "Train Epoch: 2 [78720/110534 (71%)]\tClassification Loss: 1.4040\r\n",
      "Train Epoch: 2 [79360/110534 (72%)]\tClassification Loss: 1.4782\r\n",
      "Train Epoch: 2 [80000/110534 (72%)]\tClassification Loss: 1.4437\r\n",
      "Train Epoch: 2 [80640/110534 (73%)]\tClassification Loss: 1.4244\r\n",
      "Train Epoch: 2 [81280/110534 (74%)]\tClassification Loss: 1.9144\r\n",
      "Train Epoch: 2 [81920/110534 (74%)]\tClassification Loss: 1.6107\r\n",
      "Train Epoch: 2 [82560/110534 (75%)]\tClassification Loss: 1.8580\r\n",
      "Train Epoch: 2 [83200/110534 (75%)]\tClassification Loss: 1.4726\r\n",
      "Train Epoch: 2 [83840/110534 (76%)]\tClassification Loss: 1.7308\r\n",
      "Train Epoch: 2 [84480/110534 (76%)]\tClassification Loss: 1.7310\r\n",
      "Train Epoch: 2 [85120/110534 (77%)]\tClassification Loss: 1.5188\r\n",
      "Train Epoch: 2 [85760/110534 (78%)]\tClassification Loss: 1.5079\r\n",
      "Train Epoch: 2 [86400/110534 (78%)]\tClassification Loss: 1.7041\r\n",
      "Train Epoch: 2 [87040/110534 (79%)]\tClassification Loss: 1.4377\r\n",
      "Train Epoch: 2 [87680/110534 (79%)]\tClassification Loss: 1.6201\r\n",
      "Train Epoch: 2 [88320/110534 (80%)]\tClassification Loss: 1.6048\r\n",
      "Train Epoch: 2 [88960/110534 (80%)]\tClassification Loss: 1.6529\r\n",
      "Train Epoch: 2 [89600/110534 (81%)]\tClassification Loss: 1.7709\r\n",
      "Train Epoch: 2 [90240/110534 (82%)]\tClassification Loss: 1.8012\r\n",
      "Train Epoch: 2 [90880/110534 (82%)]\tClassification Loss: 1.7244\r\n",
      "Train Epoch: 2 [91520/110534 (83%)]\tClassification Loss: 1.2151\r\n",
      "Train Epoch: 2 [92160/110534 (83%)]\tClassification Loss: 1.5007\r\n",
      "Train Epoch: 2 [92800/110534 (84%)]\tClassification Loss: 1.4762\r\n",
      "Train Epoch: 2 [93440/110534 (85%)]\tClassification Loss: 1.8461\r\n",
      "Train Epoch: 2 [94080/110534 (85%)]\tClassification Loss: 1.5579\r\n",
      "Train Epoch: 2 [94720/110534 (86%)]\tClassification Loss: 1.7513\r\n",
      "Train Epoch: 2 [95360/110534 (86%)]\tClassification Loss: 1.4492\r\n",
      "Train Epoch: 2 [96000/110534 (87%)]\tClassification Loss: 1.5178\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1500.pth.tar\r\n",
      "Train Epoch: 2 [96640/110534 (87%)]\tClassification Loss: 1.4214\r\n",
      "Train Epoch: 2 [97280/110534 (88%)]\tClassification Loss: 1.2933\r\n",
      "Train Epoch: 2 [97920/110534 (89%)]\tClassification Loss: 1.2532\r\n",
      "Train Epoch: 2 [98560/110534 (89%)]\tClassification Loss: 1.4827\r\n",
      "Train Epoch: 2 [99200/110534 (90%)]\tClassification Loss: 1.6293\r\n",
      "Train Epoch: 2 [99840/110534 (90%)]\tClassification Loss: 1.4489\r\n",
      "Train Epoch: 2 [100480/110534 (91%)]\tClassification Loss: 1.7087\r\n",
      "Train Epoch: 2 [101120/110534 (91%)]\tClassification Loss: 1.4539\r\n",
      "Train Epoch: 2 [101760/110534 (92%)]\tClassification Loss: 1.6583\r\n",
      "Train Epoch: 2 [102400/110534 (93%)]\tClassification Loss: 1.4439\r\n",
      "Train Epoch: 2 [103040/110534 (93%)]\tClassification Loss: 1.4787\r\n",
      "Train Epoch: 2 [103680/110534 (94%)]\tClassification Loss: 1.7426\r\n",
      "Train Epoch: 2 [104320/110534 (94%)]\tClassification Loss: 1.4802\r\n",
      "Train Epoch: 2 [104960/110534 (95%)]\tClassification Loss: 1.6473\r\n",
      "Train Epoch: 2 [105600/110534 (96%)]\tClassification Loss: 1.5256\r\n",
      "Train Epoch: 2 [106240/110534 (96%)]\tClassification Loss: 1.4106\r\n",
      "Train Epoch: 2 [106880/110534 (97%)]\tClassification Loss: 1.8416\r\n",
      "Train Epoch: 2 [107520/110534 (97%)]\tClassification Loss: 1.5935\r\n",
      "Train Epoch: 2 [108160/110534 (98%)]\tClassification Loss: 1.5859\r\n",
      "Train Epoch: 2 [108800/110534 (98%)]\tClassification Loss: 1.7322\r\n",
      "Train Epoch: 2 [109440/110534 (99%)]\tClassification Loss: 1.5146\r\n",
      "Train Epoch: 2 [110080/110534 (100%)]\tClassification Loss: 1.4981\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_final.pth.tar\r\n",
      "Train Epoch: 3 [0/110534 (0%)]\tClassification Loss: 1.7783\r\n",
      "\r\n",
      "Test set: Average loss: 1.4826, Accuracy: 22805/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 3 [640/110534 (1%)]\tClassification Loss: 1.4126\r\n",
      "Train Epoch: 3 [1280/110534 (1%)]\tClassification Loss: 2.0144\r\n",
      "Train Epoch: 3 [1920/110534 (2%)]\tClassification Loss: 1.6305\r\n",
      "Train Epoch: 3 [2560/110534 (2%)]\tClassification Loss: 1.7436\r\n",
      "Train Epoch: 3 [3200/110534 (3%)]\tClassification Loss: 1.6239\r\n",
      "Train Epoch: 3 [3840/110534 (3%)]\tClassification Loss: 1.5878\r\n",
      "Train Epoch: 3 [4480/110534 (4%)]\tClassification Loss: 1.6438\r\n",
      "Train Epoch: 3 [5120/110534 (5%)]\tClassification Loss: 1.6489\r\n",
      "Train Epoch: 3 [5760/110534 (5%)]\tClassification Loss: 1.6217\r\n",
      "Train Epoch: 3 [6400/110534 (6%)]\tClassification Loss: 1.2499\r\n",
      "Train Epoch: 3 [7040/110534 (6%)]\tClassification Loss: 1.4184\r\n",
      "Train Epoch: 3 [7680/110534 (7%)]\tClassification Loss: 1.5664\r\n",
      "Train Epoch: 3 [8320/110534 (8%)]\tClassification Loss: 1.9313\r\n",
      "Train Epoch: 3 [8960/110534 (8%)]\tClassification Loss: 1.8951\r\n",
      "Train Epoch: 3 [9600/110534 (9%)]\tClassification Loss: 1.3350\r\n",
      "Train Epoch: 3 [10240/110534 (9%)]\tClassification Loss: 1.5681\r\n",
      "Train Epoch: 3 [10880/110534 (10%)]\tClassification Loss: 1.5171\r\n",
      "Train Epoch: 3 [11520/110534 (10%)]\tClassification Loss: 1.8718\r\n",
      "Train Epoch: 3 [12160/110534 (11%)]\tClassification Loss: 1.4106\r\n",
      "Train Epoch: 3 [12800/110534 (12%)]\tClassification Loss: 1.5502\r\n",
      "Train Epoch: 3 [13440/110534 (12%)]\tClassification Loss: 1.3935\r\n",
      "Train Epoch: 3 [14080/110534 (13%)]\tClassification Loss: 1.4830\r\n",
      "Train Epoch: 3 [14720/110534 (13%)]\tClassification Loss: 1.8650\r\n",
      "Train Epoch: 3 [15360/110534 (14%)]\tClassification Loss: 1.5122\r\n",
      "Train Epoch: 3 [16000/110534 (14%)]\tClassification Loss: 1.6578\r\n",
      "Train Epoch: 3 [16640/110534 (15%)]\tClassification Loss: 1.6752\r\n",
      "Train Epoch: 3 [17280/110534 (16%)]\tClassification Loss: 1.8692\r\n",
      "Train Epoch: 3 [17920/110534 (16%)]\tClassification Loss: 1.6820\r\n",
      "Train Epoch: 3 [18560/110534 (17%)]\tClassification Loss: 1.6906\r\n",
      "Train Epoch: 3 [19200/110534 (17%)]\tClassification Loss: 1.3965\r\n",
      "Train Epoch: 3 [19840/110534 (18%)]\tClassification Loss: 1.4531\r\n",
      "Train Epoch: 3 [20480/110534 (19%)]\tClassification Loss: 1.8084\r\n",
      "Train Epoch: 3 [21120/110534 (19%)]\tClassification Loss: 1.8578\r\n",
      "Train Epoch: 3 [21760/110534 (20%)]\tClassification Loss: 1.3240\r\n",
      "Train Epoch: 3 [22400/110534 (20%)]\tClassification Loss: 1.4300\r\n",
      "Train Epoch: 3 [23040/110534 (21%)]\tClassification Loss: 1.3404\r\n",
      "Train Epoch: 3 [23680/110534 (21%)]\tClassification Loss: 1.8723\r\n",
      "Train Epoch: 3 [24320/110534 (22%)]\tClassification Loss: 1.1714\r\n",
      "Train Epoch: 3 [24960/110534 (23%)]\tClassification Loss: 1.6228\r\n",
      "Train Epoch: 3 [25600/110534 (23%)]\tClassification Loss: 1.4665\r\n",
      "Train Epoch: 3 [26240/110534 (24%)]\tClassification Loss: 1.4813\r\n",
      "Train Epoch: 3 [26880/110534 (24%)]\tClassification Loss: 1.8162\r\n",
      "Train Epoch: 3 [27520/110534 (25%)]\tClassification Loss: 1.4825\r\n",
      "Train Epoch: 3 [28160/110534 (25%)]\tClassification Loss: 1.7576\r\n",
      "Train Epoch: 3 [28800/110534 (26%)]\tClassification Loss: 1.9627\r\n",
      "Train Epoch: 3 [29440/110534 (27%)]\tClassification Loss: 1.7313\r\n",
      "Train Epoch: 3 [30080/110534 (27%)]\tClassification Loss: 1.5509\r\n",
      "Train Epoch: 3 [30720/110534 (28%)]\tClassification Loss: 1.4649\r\n",
      "Train Epoch: 3 [31360/110534 (28%)]\tClassification Loss: 1.6101\r\n",
      "Train Epoch: 3 [32000/110534 (29%)]\tClassification Loss: 1.4486\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_500.pth.tar\r\n",
      "Train Epoch: 3 [32640/110534 (30%)]\tClassification Loss: 1.3051\r\n",
      "Train Epoch: 3 [33280/110534 (30%)]\tClassification Loss: 1.7434\r\n",
      "Train Epoch: 3 [33920/110534 (31%)]\tClassification Loss: 1.4927\r\n",
      "Train Epoch: 3 [34560/110534 (31%)]\tClassification Loss: 1.6947\r\n",
      "Train Epoch: 3 [35200/110534 (32%)]\tClassification Loss: 1.5520\r\n",
      "Train Epoch: 3 [35840/110534 (32%)]\tClassification Loss: 1.2117\r\n",
      "Train Epoch: 3 [36480/110534 (33%)]\tClassification Loss: 1.4784\r\n",
      "Train Epoch: 3 [37120/110534 (34%)]\tClassification Loss: 1.8384\r\n",
      "Train Epoch: 3 [37760/110534 (34%)]\tClassification Loss: 1.9289\r\n",
      "Train Epoch: 3 [38400/110534 (35%)]\tClassification Loss: 1.6768\r\n",
      "Train Epoch: 3 [39040/110534 (35%)]\tClassification Loss: 1.6498\r\n",
      "Train Epoch: 3 [39680/110534 (36%)]\tClassification Loss: 1.6368\r\n",
      "Train Epoch: 3 [40320/110534 (36%)]\tClassification Loss: 1.7864\r\n",
      "Train Epoch: 3 [40960/110534 (37%)]\tClassification Loss: 1.4136\r\n",
      "Train Epoch: 3 [41600/110534 (38%)]\tClassification Loss: 1.5244\r\n",
      "Train Epoch: 3 [42240/110534 (38%)]\tClassification Loss: 1.5814\r\n",
      "Train Epoch: 3 [42880/110534 (39%)]\tClassification Loss: 1.6627\r\n",
      "Train Epoch: 3 [43520/110534 (39%)]\tClassification Loss: 1.3258\r\n",
      "Train Epoch: 3 [44160/110534 (40%)]\tClassification Loss: 1.4811\r\n",
      "Train Epoch: 3 [44800/110534 (41%)]\tClassification Loss: 1.5443\r\n",
      "Train Epoch: 3 [45440/110534 (41%)]\tClassification Loss: 1.6319\r\n",
      "Train Epoch: 3 [46080/110534 (42%)]\tClassification Loss: 1.4641\r\n",
      "Train Epoch: 3 [46720/110534 (42%)]\tClassification Loss: 1.3451\r\n",
      "Train Epoch: 3 [47360/110534 (43%)]\tClassification Loss: 1.5326\r\n",
      "Train Epoch: 3 [48000/110534 (43%)]\tClassification Loss: 1.5940\r\n",
      "Train Epoch: 3 [48640/110534 (44%)]\tClassification Loss: 1.3841\r\n",
      "Train Epoch: 3 [49280/110534 (45%)]\tClassification Loss: 1.6234\r\n",
      "Train Epoch: 3 [49920/110534 (45%)]\tClassification Loss: 1.5907\r\n",
      "Train Epoch: 3 [50560/110534 (46%)]\tClassification Loss: 1.6263\r\n",
      "Train Epoch: 3 [51200/110534 (46%)]\tClassification Loss: 1.4053\r\n",
      "Train Epoch: 3 [51840/110534 (47%)]\tClassification Loss: 1.5727\r\n",
      "Train Epoch: 3 [52480/110534 (47%)]\tClassification Loss: 1.6605\r\n",
      "Train Epoch: 3 [53120/110534 (48%)]\tClassification Loss: 1.2320\r\n",
      "Train Epoch: 3 [53760/110534 (49%)]\tClassification Loss: 1.5914\r\n",
      "Train Epoch: 3 [54400/110534 (49%)]\tClassification Loss: 1.6154\r\n",
      "Train Epoch: 3 [55040/110534 (50%)]\tClassification Loss: 1.6482\r\n",
      "Train Epoch: 3 [55680/110534 (50%)]\tClassification Loss: 1.8200\r\n",
      "Train Epoch: 3 [56320/110534 (51%)]\tClassification Loss: 1.5028\r\n",
      "Train Epoch: 3 [56960/110534 (52%)]\tClassification Loss: 1.6131\r\n",
      "Train Epoch: 3 [57600/110534 (52%)]\tClassification Loss: 1.5545\r\n",
      "Train Epoch: 3 [58240/110534 (53%)]\tClassification Loss: 1.5379\r\n",
      "Train Epoch: 3 [58880/110534 (53%)]\tClassification Loss: 1.8619\r\n",
      "Train Epoch: 3 [59520/110534 (54%)]\tClassification Loss: 1.5194\r\n",
      "Train Epoch: 3 [60160/110534 (54%)]\tClassification Loss: 1.4615\r\n",
      "Train Epoch: 3 [60800/110534 (55%)]\tClassification Loss: 1.6916\r\n",
      "Train Epoch: 3 [61440/110534 (56%)]\tClassification Loss: 1.8493\r\n",
      "Train Epoch: 3 [62080/110534 (56%)]\tClassification Loss: 1.5547\r\n",
      "Train Epoch: 3 [62720/110534 (57%)]\tClassification Loss: 1.7472\r\n",
      "Train Epoch: 3 [63360/110534 (57%)]\tClassification Loss: 1.3232\r\n",
      "Train Epoch: 3 [64000/110534 (58%)]\tClassification Loss: 1.4836\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1000.pth.tar\r\n",
      "Train Epoch: 3 [64640/110534 (58%)]\tClassification Loss: 1.2344\r\n",
      "Train Epoch: 3 [65280/110534 (59%)]\tClassification Loss: 1.6893\r\n",
      "Train Epoch: 3 [65920/110534 (60%)]\tClassification Loss: 1.3458\r\n",
      "Train Epoch: 3 [66560/110534 (60%)]\tClassification Loss: 1.4073\r\n",
      "Train Epoch: 3 [67200/110534 (61%)]\tClassification Loss: 1.3791\r\n",
      "Train Epoch: 3 [67840/110534 (61%)]\tClassification Loss: 1.8766\r\n",
      "Train Epoch: 3 [68480/110534 (62%)]\tClassification Loss: 1.6001\r\n",
      "Train Epoch: 3 [69120/110534 (63%)]\tClassification Loss: 1.6841\r\n",
      "Train Epoch: 3 [69760/110534 (63%)]\tClassification Loss: 1.7550\r\n",
      "Train Epoch: 3 [70400/110534 (64%)]\tClassification Loss: 1.3245\r\n",
      "Train Epoch: 3 [71040/110534 (64%)]\tClassification Loss: 1.8646\r\n",
      "Train Epoch: 3 [71680/110534 (65%)]\tClassification Loss: 1.6796\r\n",
      "Train Epoch: 3 [72320/110534 (65%)]\tClassification Loss: 1.7420\r\n",
      "Train Epoch: 3 [72960/110534 (66%)]\tClassification Loss: 1.5809\r\n",
      "Train Epoch: 3 [73600/110534 (67%)]\tClassification Loss: 1.8801\r\n",
      "Train Epoch: 3 [74240/110534 (67%)]\tClassification Loss: 1.8616\r\n",
      "Train Epoch: 3 [74880/110534 (68%)]\tClassification Loss: 1.2927\r\n",
      "Train Epoch: 3 [75520/110534 (68%)]\tClassification Loss: 1.4646\r\n",
      "Train Epoch: 3 [76160/110534 (69%)]\tClassification Loss: 1.2699\r\n",
      "Train Epoch: 3 [76800/110534 (69%)]\tClassification Loss: 1.4668\r\n",
      "Train Epoch: 3 [77440/110534 (70%)]\tClassification Loss: 1.3310\r\n",
      "Train Epoch: 3 [78080/110534 (71%)]\tClassification Loss: 1.5974\r\n",
      "Train Epoch: 3 [78720/110534 (71%)]\tClassification Loss: 1.3226\r\n",
      "Train Epoch: 3 [79360/110534 (72%)]\tClassification Loss: 1.3801\r\n",
      "Train Epoch: 3 [80000/110534 (72%)]\tClassification Loss: 1.5312\r\n",
      "Train Epoch: 3 [80640/110534 (73%)]\tClassification Loss: 1.4124\r\n",
      "Train Epoch: 3 [81280/110534 (74%)]\tClassification Loss: 1.8707\r\n",
      "Train Epoch: 3 [81920/110534 (74%)]\tClassification Loss: 1.7304\r\n",
      "Train Epoch: 3 [82560/110534 (75%)]\tClassification Loss: 1.8653\r\n",
      "Train Epoch: 3 [83200/110534 (75%)]\tClassification Loss: 1.6028\r\n",
      "Train Epoch: 3 [83840/110534 (76%)]\tClassification Loss: 1.7800\r\n",
      "Train Epoch: 3 [84480/110534 (76%)]\tClassification Loss: 1.6620\r\n",
      "Train Epoch: 3 [85120/110534 (77%)]\tClassification Loss: 1.4942\r\n",
      "Train Epoch: 3 [85760/110534 (78%)]\tClassification Loss: 1.5319\r\n",
      "Train Epoch: 3 [86400/110534 (78%)]\tClassification Loss: 1.4270\r\n",
      "Train Epoch: 3 [87040/110534 (79%)]\tClassification Loss: 1.4966\r\n",
      "Train Epoch: 3 [87680/110534 (79%)]\tClassification Loss: 1.5621\r\n",
      "Train Epoch: 3 [88320/110534 (80%)]\tClassification Loss: 1.6636\r\n",
      "Train Epoch: 3 [88960/110534 (80%)]\tClassification Loss: 1.6533\r\n",
      "Train Epoch: 3 [89600/110534 (81%)]\tClassification Loss: 1.7185\r\n",
      "Train Epoch: 3 [90240/110534 (82%)]\tClassification Loss: 1.7819\r\n",
      "Train Epoch: 3 [90880/110534 (82%)]\tClassification Loss: 1.4940\r\n",
      "Train Epoch: 3 [91520/110534 (83%)]\tClassification Loss: 1.2595\r\n",
      "Train Epoch: 3 [92160/110534 (83%)]\tClassification Loss: 1.4885\r\n",
      "Train Epoch: 3 [92800/110534 (84%)]\tClassification Loss: 1.4268\r\n",
      "Train Epoch: 3 [93440/110534 (85%)]\tClassification Loss: 1.6351\r\n",
      "Train Epoch: 3 [94080/110534 (85%)]\tClassification Loss: 1.6444\r\n",
      "Train Epoch: 3 [94720/110534 (86%)]\tClassification Loss: 1.4872\r\n",
      "Train Epoch: 3 [95360/110534 (86%)]\tClassification Loss: 1.6292\r\n",
      "Train Epoch: 3 [96000/110534 (87%)]\tClassification Loss: 1.3981\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1500.pth.tar\r\n",
      "Train Epoch: 3 [96640/110534 (87%)]\tClassification Loss: 1.5399\r\n",
      "Train Epoch: 3 [97280/110534 (88%)]\tClassification Loss: 1.2532\r\n",
      "Train Epoch: 3 [97920/110534 (89%)]\tClassification Loss: 1.1090\r\n",
      "Train Epoch: 3 [98560/110534 (89%)]\tClassification Loss: 1.4611\r\n",
      "Train Epoch: 3 [99200/110534 (90%)]\tClassification Loss: 1.5233\r\n",
      "Train Epoch: 3 [99840/110534 (90%)]\tClassification Loss: 1.4751\r\n",
      "Train Epoch: 3 [100480/110534 (91%)]\tClassification Loss: 1.7375\r\n",
      "Train Epoch: 3 [101120/110534 (91%)]\tClassification Loss: 1.4033\r\n",
      "Train Epoch: 3 [101760/110534 (92%)]\tClassification Loss: 1.5349\r\n",
      "Train Epoch: 3 [102400/110534 (93%)]\tClassification Loss: 1.3909\r\n",
      "Train Epoch: 3 [103040/110534 (93%)]\tClassification Loss: 1.4941\r\n",
      "Train Epoch: 3 [103680/110534 (94%)]\tClassification Loss: 1.7092\r\n",
      "Train Epoch: 3 [104320/110534 (94%)]\tClassification Loss: 1.4949\r\n",
      "Train Epoch: 3 [104960/110534 (95%)]\tClassification Loss: 1.5451\r\n",
      "Train Epoch: 3 [105600/110534 (96%)]\tClassification Loss: 1.5957\r\n",
      "Train Epoch: 3 [106240/110534 (96%)]\tClassification Loss: 1.2513\r\n",
      "Train Epoch: 3 [106880/110534 (97%)]\tClassification Loss: 1.7303\r\n",
      "Train Epoch: 3 [107520/110534 (97%)]\tClassification Loss: 1.7171\r\n",
      "Train Epoch: 3 [108160/110534 (98%)]\tClassification Loss: 1.6144\r\n",
      "Train Epoch: 3 [108800/110534 (98%)]\tClassification Loss: 1.8093\r\n",
      "Train Epoch: 3 [109440/110534 (99%)]\tClassification Loss: 1.6034\r\n",
      "Train Epoch: 3 [110080/110534 (100%)]\tClassification Loss: 1.4996\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_final.pth.tar\r\n",
      "Train Epoch: 4 [0/110534 (0%)]\tClassification Loss: 1.8033\r\n",
      "\r\n",
      "Test set: Average loss: 1.4567, Accuracy: 23067/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 4 [640/110534 (1%)]\tClassification Loss: 1.3701\r\n",
      "Train Epoch: 4 [1280/110534 (1%)]\tClassification Loss: 2.0687\r\n",
      "Train Epoch: 4 [1920/110534 (2%)]\tClassification Loss: 1.4995\r\n",
      "Train Epoch: 4 [2560/110534 (2%)]\tClassification Loss: 1.7058\r\n",
      "Train Epoch: 4 [3200/110534 (3%)]\tClassification Loss: 1.5770\r\n",
      "Train Epoch: 4 [3840/110534 (3%)]\tClassification Loss: 1.4350\r\n",
      "Train Epoch: 4 [4480/110534 (4%)]\tClassification Loss: 1.4513\r\n",
      "Train Epoch: 4 [5120/110534 (5%)]\tClassification Loss: 1.5882\r\n",
      "Train Epoch: 4 [5760/110534 (5%)]\tClassification Loss: 1.5446\r\n",
      "Train Epoch: 4 [6400/110534 (6%)]\tClassification Loss: 1.3458\r\n",
      "Train Epoch: 4 [7040/110534 (6%)]\tClassification Loss: 1.5296\r\n",
      "Train Epoch: 4 [7680/110534 (7%)]\tClassification Loss: 1.6183\r\n",
      "Train Epoch: 4 [8320/110534 (8%)]\tClassification Loss: 1.6545\r\n",
      "Train Epoch: 4 [8960/110534 (8%)]\tClassification Loss: 1.9555\r\n",
      "Train Epoch: 4 [9600/110534 (9%)]\tClassification Loss: 1.4630\r\n",
      "Train Epoch: 4 [10240/110534 (9%)]\tClassification Loss: 1.5468\r\n",
      "Train Epoch: 4 [10880/110534 (10%)]\tClassification Loss: 1.4684\r\n",
      "Train Epoch: 4 [11520/110534 (10%)]\tClassification Loss: 1.7819\r\n",
      "Train Epoch: 4 [12160/110534 (11%)]\tClassification Loss: 1.4989\r\n",
      "Train Epoch: 4 [12800/110534 (12%)]\tClassification Loss: 1.5970\r\n",
      "Train Epoch: 4 [13440/110534 (12%)]\tClassification Loss: 1.4438\r\n",
      "Train Epoch: 4 [14080/110534 (13%)]\tClassification Loss: 1.5299\r\n",
      "Train Epoch: 4 [14720/110534 (13%)]\tClassification Loss: 1.6988\r\n",
      "Train Epoch: 4 [15360/110534 (14%)]\tClassification Loss: 1.5991\r\n",
      "Train Epoch: 4 [16000/110534 (14%)]\tClassification Loss: 1.6556\r\n",
      "Train Epoch: 4 [16640/110534 (15%)]\tClassification Loss: 1.4908\r\n",
      "Train Epoch: 4 [17280/110534 (16%)]\tClassification Loss: 1.6636\r\n",
      "Train Epoch: 4 [17920/110534 (16%)]\tClassification Loss: 1.5445\r\n",
      "Train Epoch: 4 [18560/110534 (17%)]\tClassification Loss: 1.7779\r\n",
      "Train Epoch: 4 [19200/110534 (17%)]\tClassification Loss: 1.5713\r\n",
      "Train Epoch: 4 [19840/110534 (18%)]\tClassification Loss: 1.5614\r\n",
      "Train Epoch: 4 [20480/110534 (19%)]\tClassification Loss: 1.8826\r\n",
      "Train Epoch: 4 [21120/110534 (19%)]\tClassification Loss: 1.7937\r\n",
      "Train Epoch: 4 [21760/110534 (20%)]\tClassification Loss: 1.4983\r\n",
      "Train Epoch: 4 [22400/110534 (20%)]\tClassification Loss: 1.4882\r\n",
      "Train Epoch: 4 [23040/110534 (21%)]\tClassification Loss: 1.2387\r\n",
      "Train Epoch: 4 [23680/110534 (21%)]\tClassification Loss: 1.7286\r\n",
      "Train Epoch: 4 [24320/110534 (22%)]\tClassification Loss: 1.2642\r\n",
      "Train Epoch: 4 [24960/110534 (23%)]\tClassification Loss: 1.7945\r\n",
      "Train Epoch: 4 [25600/110534 (23%)]\tClassification Loss: 1.5229\r\n",
      "Train Epoch: 4 [26240/110534 (24%)]\tClassification Loss: 1.5169\r\n",
      "Train Epoch: 4 [26880/110534 (24%)]\tClassification Loss: 1.7915\r\n",
      "Train Epoch: 4 [27520/110534 (25%)]\tClassification Loss: 1.4705\r\n",
      "Train Epoch: 4 [28160/110534 (25%)]\tClassification Loss: 1.7610\r\n",
      "Train Epoch: 4 [28800/110534 (26%)]\tClassification Loss: 1.8141\r\n",
      "Train Epoch: 4 [29440/110534 (27%)]\tClassification Loss: 1.5419\r\n",
      "Train Epoch: 4 [30080/110534 (27%)]\tClassification Loss: 1.8309\r\n",
      "Train Epoch: 4 [30720/110534 (28%)]\tClassification Loss: 1.4493\r\n",
      "Train Epoch: 4 [31360/110534 (28%)]\tClassification Loss: 1.5779\r\n",
      "Train Epoch: 4 [32000/110534 (29%)]\tClassification Loss: 1.4578\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_500.pth.tar\r\n",
      "Train Epoch: 4 [32640/110534 (30%)]\tClassification Loss: 1.3171\r\n",
      "Train Epoch: 4 [33280/110534 (30%)]\tClassification Loss: 1.5707\r\n",
      "Train Epoch: 4 [33920/110534 (31%)]\tClassification Loss: 1.5854\r\n",
      "Train Epoch: 4 [34560/110534 (31%)]\tClassification Loss: 1.6298\r\n",
      "Train Epoch: 4 [35200/110534 (32%)]\tClassification Loss: 1.3909\r\n",
      "Train Epoch: 4 [35840/110534 (32%)]\tClassification Loss: 1.2572\r\n",
      "Train Epoch: 4 [36480/110534 (33%)]\tClassification Loss: 1.3755\r\n",
      "Train Epoch: 4 [37120/110534 (34%)]\tClassification Loss: 1.7744\r\n",
      "Train Epoch: 4 [37760/110534 (34%)]\tClassification Loss: 1.9843\r\n",
      "Train Epoch: 4 [38400/110534 (35%)]\tClassification Loss: 1.5322\r\n",
      "Train Epoch: 4 [39040/110534 (35%)]\tClassification Loss: 1.5182\r\n",
      "Train Epoch: 4 [39680/110534 (36%)]\tClassification Loss: 1.7117\r\n",
      "Train Epoch: 4 [40320/110534 (36%)]\tClassification Loss: 1.8278\r\n",
      "Train Epoch: 4 [40960/110534 (37%)]\tClassification Loss: 1.3103\r\n",
      "Train Epoch: 4 [41600/110534 (38%)]\tClassification Loss: 1.4785\r\n",
      "Train Epoch: 4 [42240/110534 (38%)]\tClassification Loss: 1.5785\r\n",
      "Train Epoch: 4 [42880/110534 (39%)]\tClassification Loss: 1.4345\r\n",
      "Train Epoch: 4 [43520/110534 (39%)]\tClassification Loss: 1.4852\r\n",
      "Train Epoch: 4 [44160/110534 (40%)]\tClassification Loss: 1.5954\r\n",
      "Train Epoch: 4 [44800/110534 (41%)]\tClassification Loss: 1.6870\r\n",
      "Train Epoch: 4 [45440/110534 (41%)]\tClassification Loss: 1.5866\r\n",
      "Train Epoch: 4 [46080/110534 (42%)]\tClassification Loss: 1.3353\r\n",
      "Train Epoch: 4 [46720/110534 (42%)]\tClassification Loss: 1.6425\r\n",
      "Train Epoch: 4 [47360/110534 (43%)]\tClassification Loss: 1.5075\r\n",
      "Train Epoch: 4 [48000/110534 (43%)]\tClassification Loss: 1.5649\r\n",
      "Train Epoch: 4 [48640/110534 (44%)]\tClassification Loss: 1.4845\r\n",
      "Train Epoch: 4 [49280/110534 (45%)]\tClassification Loss: 1.4961\r\n",
      "Train Epoch: 4 [49920/110534 (45%)]\tClassification Loss: 1.6487\r\n",
      "Train Epoch: 4 [50560/110534 (46%)]\tClassification Loss: 1.6408\r\n",
      "Train Epoch: 4 [51200/110534 (46%)]\tClassification Loss: 1.4827\r\n",
      "Train Epoch: 4 [51840/110534 (47%)]\tClassification Loss: 1.5729\r\n",
      "Train Epoch: 4 [52480/110534 (47%)]\tClassification Loss: 1.4571\r\n",
      "Train Epoch: 4 [53120/110534 (48%)]\tClassification Loss: 1.1982\r\n",
      "Train Epoch: 4 [53760/110534 (49%)]\tClassification Loss: 1.4589\r\n",
      "Train Epoch: 4 [54400/110534 (49%)]\tClassification Loss: 1.5091\r\n",
      "Train Epoch: 4 [55040/110534 (50%)]\tClassification Loss: 1.6294\r\n",
      "Train Epoch: 4 [55680/110534 (50%)]\tClassification Loss: 1.8001\r\n",
      "Train Epoch: 4 [56320/110534 (51%)]\tClassification Loss: 1.4456\r\n",
      "Train Epoch: 4 [56960/110534 (52%)]\tClassification Loss: 1.6240\r\n",
      "Train Epoch: 4 [57600/110534 (52%)]\tClassification Loss: 1.6599\r\n",
      "Train Epoch: 4 [58240/110534 (53%)]\tClassification Loss: 1.4780\r\n",
      "Train Epoch: 4 [58880/110534 (53%)]\tClassification Loss: 1.6494\r\n",
      "Train Epoch: 4 [59520/110534 (54%)]\tClassification Loss: 1.4429\r\n",
      "Train Epoch: 4 [60160/110534 (54%)]\tClassification Loss: 1.3485\r\n",
      "Train Epoch: 4 [60800/110534 (55%)]\tClassification Loss: 1.6512\r\n",
      "Train Epoch: 4 [61440/110534 (56%)]\tClassification Loss: 1.6141\r\n",
      "Train Epoch: 4 [62080/110534 (56%)]\tClassification Loss: 1.5599\r\n",
      "Train Epoch: 4 [62720/110534 (57%)]\tClassification Loss: 1.8219\r\n",
      "Train Epoch: 4 [63360/110534 (57%)]\tClassification Loss: 1.3495\r\n",
      "Train Epoch: 4 [64000/110534 (58%)]\tClassification Loss: 1.5131\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1000.pth.tar\r\n",
      "Train Epoch: 4 [64640/110534 (58%)]\tClassification Loss: 1.3224\r\n",
      "Train Epoch: 4 [65280/110534 (59%)]\tClassification Loss: 1.6562\r\n",
      "Train Epoch: 4 [65920/110534 (60%)]\tClassification Loss: 1.4170\r\n",
      "Train Epoch: 4 [66560/110534 (60%)]\tClassification Loss: 1.4026\r\n",
      "Train Epoch: 4 [67200/110534 (61%)]\tClassification Loss: 1.3167\r\n",
      "Train Epoch: 4 [67840/110534 (61%)]\tClassification Loss: 1.7493\r\n",
      "Train Epoch: 4 [68480/110534 (62%)]\tClassification Loss: 1.7208\r\n",
      "Train Epoch: 4 [69120/110534 (63%)]\tClassification Loss: 1.7919\r\n",
      "Train Epoch: 4 [69760/110534 (63%)]\tClassification Loss: 1.5884\r\n",
      "Train Epoch: 4 [70400/110534 (64%)]\tClassification Loss: 1.3976\r\n",
      "Train Epoch: 4 [71040/110534 (64%)]\tClassification Loss: 1.7693\r\n",
      "Train Epoch: 4 [71680/110534 (65%)]\tClassification Loss: 1.4990\r\n",
      "Train Epoch: 4 [72320/110534 (65%)]\tClassification Loss: 1.6076\r\n",
      "Train Epoch: 4 [72960/110534 (66%)]\tClassification Loss: 1.5826\r\n",
      "Train Epoch: 4 [73600/110534 (67%)]\tClassification Loss: 1.7496\r\n",
      "Train Epoch: 4 [74240/110534 (67%)]\tClassification Loss: 1.8928\r\n",
      "Train Epoch: 4 [74880/110534 (68%)]\tClassification Loss: 1.2363\r\n",
      "Train Epoch: 4 [75520/110534 (68%)]\tClassification Loss: 1.5735\r\n",
      "Train Epoch: 4 [76160/110534 (69%)]\tClassification Loss: 1.2566\r\n",
      "Train Epoch: 4 [76800/110534 (69%)]\tClassification Loss: 1.3369\r\n",
      "Train Epoch: 4 [77440/110534 (70%)]\tClassification Loss: 1.3619\r\n",
      "Train Epoch: 4 [78080/110534 (71%)]\tClassification Loss: 1.5527\r\n",
      "Train Epoch: 4 [78720/110534 (71%)]\tClassification Loss: 1.3283\r\n",
      "Train Epoch: 4 [79360/110534 (72%)]\tClassification Loss: 1.3529\r\n",
      "Train Epoch: 4 [80000/110534 (72%)]\tClassification Loss: 1.5061\r\n",
      "Train Epoch: 4 [80640/110534 (73%)]\tClassification Loss: 1.4536\r\n",
      "Train Epoch: 4 [81280/110534 (74%)]\tClassification Loss: 1.9273\r\n",
      "Train Epoch: 4 [81920/110534 (74%)]\tClassification Loss: 1.4580\r\n",
      "Train Epoch: 4 [82560/110534 (75%)]\tClassification Loss: 1.9433\r\n",
      "Train Epoch: 4 [83200/110534 (75%)]\tClassification Loss: 1.5579\r\n",
      "Train Epoch: 4 [83840/110534 (76%)]\tClassification Loss: 1.8978\r\n",
      "Train Epoch: 4 [84480/110534 (76%)]\tClassification Loss: 1.7978\r\n",
      "Train Epoch: 4 [85120/110534 (77%)]\tClassification Loss: 1.5303\r\n",
      "Train Epoch: 4 [85760/110534 (78%)]\tClassification Loss: 1.5163\r\n",
      "Train Epoch: 4 [86400/110534 (78%)]\tClassification Loss: 1.6261\r\n",
      "Train Epoch: 4 [87040/110534 (79%)]\tClassification Loss: 1.5760\r\n",
      "Train Epoch: 4 [87680/110534 (79%)]\tClassification Loss: 1.3934\r\n",
      "Train Epoch: 4 [88320/110534 (80%)]\tClassification Loss: 1.6097\r\n",
      "Train Epoch: 4 [88960/110534 (80%)]\tClassification Loss: 1.7452\r\n",
      "Train Epoch: 4 [89600/110534 (81%)]\tClassification Loss: 1.7490\r\n",
      "Train Epoch: 4 [90240/110534 (82%)]\tClassification Loss: 1.7627\r\n",
      "Train Epoch: 4 [90880/110534 (82%)]\tClassification Loss: 1.5346\r\n",
      "Train Epoch: 4 [91520/110534 (83%)]\tClassification Loss: 1.1871\r\n",
      "Train Epoch: 4 [92160/110534 (83%)]\tClassification Loss: 1.3951\r\n",
      "Train Epoch: 4 [92800/110534 (84%)]\tClassification Loss: 1.3984\r\n",
      "Train Epoch: 4 [93440/110534 (85%)]\tClassification Loss: 1.8542\r\n",
      "Train Epoch: 4 [94080/110534 (85%)]\tClassification Loss: 1.6750\r\n",
      "Train Epoch: 4 [94720/110534 (86%)]\tClassification Loss: 1.5250\r\n",
      "Train Epoch: 4 [95360/110534 (86%)]\tClassification Loss: 1.5064\r\n",
      "Train Epoch: 4 [96000/110534 (87%)]\tClassification Loss: 1.5113\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1500.pth.tar\r\n",
      "Train Epoch: 4 [96640/110534 (87%)]\tClassification Loss: 1.4084\r\n",
      "Train Epoch: 4 [97280/110534 (88%)]\tClassification Loss: 1.2738\r\n",
      "Train Epoch: 4 [97920/110534 (89%)]\tClassification Loss: 1.3117\r\n",
      "Train Epoch: 4 [98560/110534 (89%)]\tClassification Loss: 1.2697\r\n",
      "Train Epoch: 4 [99200/110534 (90%)]\tClassification Loss: 1.5688\r\n",
      "Train Epoch: 4 [99840/110534 (90%)]\tClassification Loss: 1.4665\r\n",
      "Train Epoch: 4 [100480/110534 (91%)]\tClassification Loss: 1.6808\r\n",
      "Train Epoch: 4 [101120/110534 (91%)]\tClassification Loss: 1.5543\r\n",
      "Train Epoch: 4 [101760/110534 (92%)]\tClassification Loss: 1.5131\r\n",
      "Train Epoch: 4 [102400/110534 (93%)]\tClassification Loss: 1.4303\r\n",
      "Train Epoch: 4 [103040/110534 (93%)]\tClassification Loss: 1.3942\r\n",
      "Train Epoch: 4 [103680/110534 (94%)]\tClassification Loss: 1.7292\r\n",
      "Train Epoch: 4 [104320/110534 (94%)]\tClassification Loss: 1.4755\r\n",
      "Train Epoch: 4 [104960/110534 (95%)]\tClassification Loss: 1.4358\r\n",
      "Train Epoch: 4 [105600/110534 (96%)]\tClassification Loss: 1.4192\r\n",
      "Train Epoch: 4 [106240/110534 (96%)]\tClassification Loss: 1.2318\r\n",
      "Train Epoch: 4 [106880/110534 (97%)]\tClassification Loss: 1.7122\r\n",
      "Train Epoch: 4 [107520/110534 (97%)]\tClassification Loss: 1.6923\r\n",
      "Train Epoch: 4 [108160/110534 (98%)]\tClassification Loss: 1.6795\r\n",
      "Train Epoch: 4 [108800/110534 (98%)]\tClassification Loss: 1.6786\r\n",
      "Train Epoch: 4 [109440/110534 (99%)]\tClassification Loss: 1.4471\r\n",
      "Train Epoch: 4 [110080/110534 (100%)]\tClassification Loss: 1.3902\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_final.pth.tar\r\n",
      "Train Epoch: 5 [0/110534 (0%)]\tClassification Loss: 1.8214\r\n",
      "\r\n",
      "Test set: Average loss: 1.4414, Accuracy: 23184/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 5 [640/110534 (1%)]\tClassification Loss: 1.4757\r\n",
      "Train Epoch: 5 [1280/110534 (1%)]\tClassification Loss: 2.0677\r\n",
      "Train Epoch: 5 [1920/110534 (2%)]\tClassification Loss: 1.5913\r\n",
      "Train Epoch: 5 [2560/110534 (2%)]\tClassification Loss: 1.7521\r\n",
      "Train Epoch: 5 [3200/110534 (3%)]\tClassification Loss: 1.4012\r\n",
      "Train Epoch: 5 [3840/110534 (3%)]\tClassification Loss: 1.4709\r\n",
      "Train Epoch: 5 [4480/110534 (4%)]\tClassification Loss: 1.4583\r\n",
      "Train Epoch: 5 [5120/110534 (5%)]\tClassification Loss: 1.6779\r\n",
      "Train Epoch: 5 [5760/110534 (5%)]\tClassification Loss: 1.5874\r\n",
      "Train Epoch: 5 [6400/110534 (6%)]\tClassification Loss: 1.3437\r\n",
      "Train Epoch: 5 [7040/110534 (6%)]\tClassification Loss: 1.4731\r\n",
      "Train Epoch: 5 [7680/110534 (7%)]\tClassification Loss: 1.4330\r\n",
      "Train Epoch: 5 [8320/110534 (8%)]\tClassification Loss: 1.5649\r\n",
      "Train Epoch: 5 [8960/110534 (8%)]\tClassification Loss: 1.9053\r\n",
      "Train Epoch: 5 [9600/110534 (9%)]\tClassification Loss: 1.6284\r\n",
      "Train Epoch: 5 [10240/110534 (9%)]\tClassification Loss: 1.6265\r\n",
      "Train Epoch: 5 [10880/110534 (10%)]\tClassification Loss: 1.5864\r\n",
      "Train Epoch: 5 [11520/110534 (10%)]\tClassification Loss: 1.7487\r\n",
      "Train Epoch: 5 [12160/110534 (11%)]\tClassification Loss: 1.3043\r\n",
      "Train Epoch: 5 [12800/110534 (12%)]\tClassification Loss: 1.6998\r\n",
      "Train Epoch: 5 [13440/110534 (12%)]\tClassification Loss: 1.5795\r\n",
      "Train Epoch: 5 [14080/110534 (13%)]\tClassification Loss: 1.6049\r\n",
      "Train Epoch: 5 [14720/110534 (13%)]\tClassification Loss: 1.5807\r\n",
      "Train Epoch: 5 [15360/110534 (14%)]\tClassification Loss: 1.4907\r\n",
      "Train Epoch: 5 [16000/110534 (14%)]\tClassification Loss: 1.6198\r\n",
      "Train Epoch: 5 [16640/110534 (15%)]\tClassification Loss: 1.5162\r\n",
      "Train Epoch: 5 [17280/110534 (16%)]\tClassification Loss: 1.6290\r\n",
      "Train Epoch: 5 [17920/110534 (16%)]\tClassification Loss: 1.6295\r\n",
      "Train Epoch: 5 [18560/110534 (17%)]\tClassification Loss: 1.6427\r\n",
      "Train Epoch: 5 [19200/110534 (17%)]\tClassification Loss: 1.5794\r\n",
      "Train Epoch: 5 [19840/110534 (18%)]\tClassification Loss: 1.5450\r\n",
      "Train Epoch: 5 [20480/110534 (19%)]\tClassification Loss: 1.7526\r\n",
      "Train Epoch: 5 [21120/110534 (19%)]\tClassification Loss: 1.6720\r\n",
      "Train Epoch: 5 [21760/110534 (20%)]\tClassification Loss: 1.3151\r\n",
      "Train Epoch: 5 [22400/110534 (20%)]\tClassification Loss: 1.5810\r\n",
      "Train Epoch: 5 [23040/110534 (21%)]\tClassification Loss: 1.2549\r\n",
      "Train Epoch: 5 [23680/110534 (21%)]\tClassification Loss: 1.7112\r\n",
      "Train Epoch: 5 [24320/110534 (22%)]\tClassification Loss: 1.1438\r\n",
      "Train Epoch: 5 [24960/110534 (23%)]\tClassification Loss: 1.8037\r\n",
      "Train Epoch: 5 [25600/110534 (23%)]\tClassification Loss: 1.3492\r\n",
      "Train Epoch: 5 [26240/110534 (24%)]\tClassification Loss: 1.4599\r\n",
      "Train Epoch: 5 [26880/110534 (24%)]\tClassification Loss: 1.7940\r\n",
      "Train Epoch: 5 [27520/110534 (25%)]\tClassification Loss: 1.3934\r\n",
      "Train Epoch: 5 [28160/110534 (25%)]\tClassification Loss: 1.8175\r\n",
      "Train Epoch: 5 [28800/110534 (26%)]\tClassification Loss: 1.8557\r\n",
      "Train Epoch: 5 [29440/110534 (27%)]\tClassification Loss: 1.7247\r\n",
      "Train Epoch: 5 [30080/110534 (27%)]\tClassification Loss: 1.8264\r\n",
      "Train Epoch: 5 [30720/110534 (28%)]\tClassification Loss: 1.3616\r\n",
      "Train Epoch: 5 [31360/110534 (28%)]\tClassification Loss: 1.7320\r\n",
      "Train Epoch: 5 [32000/110534 (29%)]\tClassification Loss: 1.4909\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_500.pth.tar\r\n",
      "Train Epoch: 5 [32640/110534 (30%)]\tClassification Loss: 1.3405\r\n",
      "Train Epoch: 5 [33280/110534 (30%)]\tClassification Loss: 1.5699\r\n",
      "Train Epoch: 5 [33920/110534 (31%)]\tClassification Loss: 1.5548\r\n",
      "Train Epoch: 5 [34560/110534 (31%)]\tClassification Loss: 1.8079\r\n",
      "Train Epoch: 5 [35200/110534 (32%)]\tClassification Loss: 1.5180\r\n",
      "Train Epoch: 5 [35840/110534 (32%)]\tClassification Loss: 1.3576\r\n",
      "Train Epoch: 5 [36480/110534 (33%)]\tClassification Loss: 1.5626\r\n",
      "Train Epoch: 5 [37120/110534 (34%)]\tClassification Loss: 1.4899\r\n",
      "Train Epoch: 5 [37760/110534 (34%)]\tClassification Loss: 1.8593\r\n",
      "Train Epoch: 5 [38400/110534 (35%)]\tClassification Loss: 1.4916\r\n",
      "Train Epoch: 5 [39040/110534 (35%)]\tClassification Loss: 1.5608\r\n",
      "Train Epoch: 5 [39680/110534 (36%)]\tClassification Loss: 1.5841\r\n",
      "Train Epoch: 5 [40320/110534 (36%)]\tClassification Loss: 1.6166\r\n",
      "Train Epoch: 5 [40960/110534 (37%)]\tClassification Loss: 1.5405\r\n",
      "Train Epoch: 5 [41600/110534 (38%)]\tClassification Loss: 1.5943\r\n",
      "Train Epoch: 5 [42240/110534 (38%)]\tClassification Loss: 1.3299\r\n",
      "Train Epoch: 5 [42880/110534 (39%)]\tClassification Loss: 1.4633\r\n",
      "Train Epoch: 5 [43520/110534 (39%)]\tClassification Loss: 1.3080\r\n",
      "Train Epoch: 5 [44160/110534 (40%)]\tClassification Loss: 1.5584\r\n",
      "Train Epoch: 5 [44800/110534 (41%)]\tClassification Loss: 1.6378\r\n",
      "Train Epoch: 5 [45440/110534 (41%)]\tClassification Loss: 1.6996\r\n",
      "Train Epoch: 5 [46080/110534 (42%)]\tClassification Loss: 1.5284\r\n",
      "Train Epoch: 5 [46720/110534 (42%)]\tClassification Loss: 1.3721\r\n",
      "Train Epoch: 5 [47360/110534 (43%)]\tClassification Loss: 1.5247\r\n",
      "Train Epoch: 5 [48000/110534 (43%)]\tClassification Loss: 1.6861\r\n",
      "Train Epoch: 5 [48640/110534 (44%)]\tClassification Loss: 1.3726\r\n",
      "Train Epoch: 5 [49280/110534 (45%)]\tClassification Loss: 1.4464\r\n",
      "Train Epoch: 5 [49920/110534 (45%)]\tClassification Loss: 1.6950\r\n",
      "Train Epoch: 5 [50560/110534 (46%)]\tClassification Loss: 1.5760\r\n",
      "Train Epoch: 5 [51200/110534 (46%)]\tClassification Loss: 1.5093\r\n",
      "Train Epoch: 5 [51840/110534 (47%)]\tClassification Loss: 1.4687\r\n",
      "Train Epoch: 5 [52480/110534 (47%)]\tClassification Loss: 1.5033\r\n",
      "Train Epoch: 5 [53120/110534 (48%)]\tClassification Loss: 1.1426\r\n",
      "Train Epoch: 5 [53760/110534 (49%)]\tClassification Loss: 1.6003\r\n",
      "Train Epoch: 5 [54400/110534 (49%)]\tClassification Loss: 1.5969\r\n",
      "Train Epoch: 5 [55040/110534 (50%)]\tClassification Loss: 1.7294\r\n",
      "Train Epoch: 5 [55680/110534 (50%)]\tClassification Loss: 1.5083\r\n",
      "Train Epoch: 5 [56320/110534 (51%)]\tClassification Loss: 1.5620\r\n",
      "Train Epoch: 5 [56960/110534 (52%)]\tClassification Loss: 1.5441\r\n",
      "Train Epoch: 5 [57600/110534 (52%)]\tClassification Loss: 1.6365\r\n",
      "Train Epoch: 5 [58240/110534 (53%)]\tClassification Loss: 1.5318\r\n",
      "Train Epoch: 5 [58880/110534 (53%)]\tClassification Loss: 1.6830\r\n",
      "Train Epoch: 5 [59520/110534 (54%)]\tClassification Loss: 1.3243\r\n",
      "Train Epoch: 5 [60160/110534 (54%)]\tClassification Loss: 1.4946\r\n",
      "Train Epoch: 5 [60800/110534 (55%)]\tClassification Loss: 1.6366\r\n",
      "Train Epoch: 5 [61440/110534 (56%)]\tClassification Loss: 1.6402\r\n",
      "Train Epoch: 5 [62080/110534 (56%)]\tClassification Loss: 1.6797\r\n",
      "Train Epoch: 5 [62720/110534 (57%)]\tClassification Loss: 1.6522\r\n",
      "Train Epoch: 5 [63360/110534 (57%)]\tClassification Loss: 1.3651\r\n",
      "Train Epoch: 5 [64000/110534 (58%)]\tClassification Loss: 1.5904\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_1000.pth.tar\r\n",
      "Train Epoch: 5 [64640/110534 (58%)]\tClassification Loss: 1.1687\r\n",
      "Train Epoch: 5 [65280/110534 (59%)]\tClassification Loss: 1.6351\r\n",
      "Train Epoch: 5 [65920/110534 (60%)]\tClassification Loss: 1.5125\r\n",
      "Train Epoch: 5 [66560/110534 (60%)]\tClassification Loss: 1.1877\r\n",
      "Train Epoch: 5 [67200/110534 (61%)]\tClassification Loss: 1.3384\r\n",
      "Train Epoch: 5 [67840/110534 (61%)]\tClassification Loss: 1.9029\r\n",
      "Train Epoch: 5 [68480/110534 (62%)]\tClassification Loss: 1.6124\r\n",
      "Train Epoch: 5 [69120/110534 (63%)]\tClassification Loss: 1.6342\r\n",
      "Train Epoch: 5 [69760/110534 (63%)]\tClassification Loss: 1.5580\r\n",
      "Train Epoch: 5 [70400/110534 (64%)]\tClassification Loss: 1.3434\r\n",
      "Train Epoch: 5 [71040/110534 (64%)]\tClassification Loss: 1.8258\r\n",
      "Train Epoch: 5 [71680/110534 (65%)]\tClassification Loss: 1.5200\r\n",
      "Train Epoch: 5 [72320/110534 (65%)]\tClassification Loss: 1.5541\r\n",
      "Train Epoch: 5 [72960/110534 (66%)]\tClassification Loss: 1.7447\r\n",
      "Train Epoch: 5 [73600/110534 (67%)]\tClassification Loss: 1.8587\r\n",
      "Train Epoch: 5 [74240/110534 (67%)]\tClassification Loss: 1.7036\r\n",
      "Train Epoch: 5 [74880/110534 (68%)]\tClassification Loss: 1.0861\r\n",
      "Train Epoch: 5 [75520/110534 (68%)]\tClassification Loss: 1.4943\r\n",
      "Train Epoch: 5 [76160/110534 (69%)]\tClassification Loss: 1.3158\r\n",
      "Train Epoch: 5 [76800/110534 (69%)]\tClassification Loss: 1.3196\r\n",
      "Train Epoch: 5 [77440/110534 (70%)]\tClassification Loss: 1.5104\r\n",
      "Train Epoch: 5 [78080/110534 (71%)]\tClassification Loss: 1.6496\r\n",
      "Train Epoch: 5 [78720/110534 (71%)]\tClassification Loss: 1.3899\r\n",
      "Train Epoch: 5 [79360/110534 (72%)]\tClassification Loss: 1.4013\r\n",
      "Train Epoch: 5 [80000/110534 (72%)]\tClassification Loss: 1.3945\r\n",
      "Train Epoch: 5 [80640/110534 (73%)]\tClassification Loss: 1.3421\r\n",
      "Train Epoch: 5 [81280/110534 (74%)]\tClassification Loss: 1.8597\r\n",
      "Train Epoch: 5 [81920/110534 (74%)]\tClassification Loss: 1.5920\r\n",
      "Train Epoch: 5 [82560/110534 (75%)]\tClassification Loss: 1.7564\r\n",
      "Train Epoch: 5 [83200/110534 (75%)]\tClassification Loss: 1.5463\r\n",
      "Train Epoch: 5 [83840/110534 (76%)]\tClassification Loss: 1.8054\r\n",
      "Train Epoch: 5 [84480/110534 (76%)]\tClassification Loss: 1.5992\r\n",
      "Train Epoch: 5 [85120/110534 (77%)]\tClassification Loss: 1.6560\r\n",
      "Train Epoch: 5 [85760/110534 (78%)]\tClassification Loss: 1.5533\r\n",
      "Train Epoch: 5 [86400/110534 (78%)]\tClassification Loss: 1.6249\r\n",
      "Train Epoch: 5 [87040/110534 (79%)]\tClassification Loss: 1.4299\r\n",
      "Train Epoch: 5 [87680/110534 (79%)]\tClassification Loss: 1.4022\r\n",
      "Train Epoch: 5 [88320/110534 (80%)]\tClassification Loss: 1.5924\r\n",
      "Train Epoch: 5 [88960/110534 (80%)]\tClassification Loss: 1.5702\r\n",
      "Train Epoch: 5 [89600/110534 (81%)]\tClassification Loss: 1.7738\r\n",
      "Train Epoch: 5 [90240/110534 (82%)]\tClassification Loss: 1.8169\r\n",
      "Train Epoch: 5 [90880/110534 (82%)]\tClassification Loss: 1.6093\r\n",
      "Train Epoch: 5 [91520/110534 (83%)]\tClassification Loss: 1.2746\r\n",
      "Train Epoch: 5 [92160/110534 (83%)]\tClassification Loss: 1.3925\r\n",
      "Train Epoch: 5 [92800/110534 (84%)]\tClassification Loss: 1.3981\r\n",
      "Train Epoch: 5 [93440/110534 (85%)]\tClassification Loss: 1.7626\r\n",
      "Train Epoch: 5 [94080/110534 (85%)]\tClassification Loss: 1.6719\r\n",
      "Train Epoch: 5 [94720/110534 (86%)]\tClassification Loss: 1.5428\r\n",
      "Train Epoch: 5 [95360/110534 (86%)]\tClassification Loss: 1.4519\r\n",
      "Train Epoch: 5 [96000/110534 (87%)]\tClassification Loss: 1.5347\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_1500.pth.tar\r\n",
      "Train Epoch: 5 [96640/110534 (87%)]\tClassification Loss: 1.3060\r\n",
      "Train Epoch: 5 [97280/110534 (88%)]\tClassification Loss: 1.2843\r\n",
      "Train Epoch: 5 [97920/110534 (89%)]\tClassification Loss: 1.2391\r\n",
      "Train Epoch: 5 [98560/110534 (89%)]\tClassification Loss: 1.3395\r\n",
      "Train Epoch: 5 [99200/110534 (90%)]\tClassification Loss: 1.5094\r\n",
      "Train Epoch: 5 [99840/110534 (90%)]\tClassification Loss: 1.6165\r\n",
      "Train Epoch: 5 [100480/110534 (91%)]\tClassification Loss: 1.6179\r\n",
      "Train Epoch: 5 [101120/110534 (91%)]\tClassification Loss: 1.6072\r\n",
      "Train Epoch: 5 [101760/110534 (92%)]\tClassification Loss: 1.5407\r\n",
      "Train Epoch: 5 [102400/110534 (93%)]\tClassification Loss: 1.4532\r\n",
      "Train Epoch: 5 [103040/110534 (93%)]\tClassification Loss: 1.5366\r\n",
      "Train Epoch: 5 [103680/110534 (94%)]\tClassification Loss: 1.6526\r\n",
      "Train Epoch: 5 [104320/110534 (94%)]\tClassification Loss: 1.3449\r\n",
      "Train Epoch: 5 [104960/110534 (95%)]\tClassification Loss: 1.5551\r\n",
      "Train Epoch: 5 [105600/110534 (96%)]\tClassification Loss: 1.5816\r\n",
      "Train Epoch: 5 [106240/110534 (96%)]\tClassification Loss: 1.2997\r\n",
      "Train Epoch: 5 [106880/110534 (97%)]\tClassification Loss: 1.7168\r\n",
      "Train Epoch: 5 [107520/110534 (97%)]\tClassification Loss: 1.7498\r\n",
      "Train Epoch: 5 [108160/110534 (98%)]\tClassification Loss: 1.5371\r\n",
      "Train Epoch: 5 [108800/110534 (98%)]\tClassification Loss: 1.6714\r\n",
      "Train Epoch: 5 [109440/110534 (99%)]\tClassification Loss: 1.3873\r\n",
      "Train Epoch: 5 [110080/110534 (100%)]\tClassification Loss: 1.4041\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_final.pth.tar\r\n",
      "Train Epoch: 6 [0/110534 (0%)]\tClassification Loss: 1.6926\r\n",
      "\r\n",
      "Test set: Average loss: 1.4298, Accuracy: 23226/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 6 [640/110534 (1%)]\tClassification Loss: 1.4857\r\n",
      "Train Epoch: 6 [1280/110534 (1%)]\tClassification Loss: 1.8599\r\n",
      "Train Epoch: 6 [1920/110534 (2%)]\tClassification Loss: 1.5703\r\n",
      "Train Epoch: 6 [2560/110534 (2%)]\tClassification Loss: 1.6948\r\n",
      "Train Epoch: 6 [3200/110534 (3%)]\tClassification Loss: 1.6262\r\n",
      "Train Epoch: 6 [3840/110534 (3%)]\tClassification Loss: 1.3953\r\n",
      "Train Epoch: 6 [4480/110534 (4%)]\tClassification Loss: 1.5268\r\n",
      "Train Epoch: 6 [5120/110534 (5%)]\tClassification Loss: 1.5522\r\n",
      "Train Epoch: 6 [5760/110534 (5%)]\tClassification Loss: 1.5884\r\n",
      "Train Epoch: 6 [6400/110534 (6%)]\tClassification Loss: 1.3312\r\n",
      "Train Epoch: 6 [7040/110534 (6%)]\tClassification Loss: 1.3895\r\n",
      "Train Epoch: 6 [7680/110534 (7%)]\tClassification Loss: 1.6238\r\n",
      "Train Epoch: 6 [8320/110534 (8%)]\tClassification Loss: 1.8124\r\n",
      "Train Epoch: 6 [8960/110534 (8%)]\tClassification Loss: 1.7182\r\n",
      "Train Epoch: 6 [9600/110534 (9%)]\tClassification Loss: 1.4601\r\n",
      "Train Epoch: 6 [10240/110534 (9%)]\tClassification Loss: 1.5294\r\n",
      "Train Epoch: 6 [10880/110534 (10%)]\tClassification Loss: 1.4472\r\n",
      "Train Epoch: 6 [11520/110534 (10%)]\tClassification Loss: 1.7232\r\n",
      "Train Epoch: 6 [12160/110534 (11%)]\tClassification Loss: 1.4503\r\n",
      "Train Epoch: 6 [12800/110534 (12%)]\tClassification Loss: 1.4940\r\n",
      "Train Epoch: 6 [13440/110534 (12%)]\tClassification Loss: 1.3317\r\n",
      "Train Epoch: 6 [14080/110534 (13%)]\tClassification Loss: 1.5045\r\n",
      "Train Epoch: 6 [14720/110534 (13%)]\tClassification Loss: 1.8011\r\n",
      "Train Epoch: 6 [15360/110534 (14%)]\tClassification Loss: 1.5408\r\n",
      "Train Epoch: 6 [16000/110534 (14%)]\tClassification Loss: 1.6783\r\n",
      "Train Epoch: 6 [16640/110534 (15%)]\tClassification Loss: 1.5699\r\n",
      "Train Epoch: 6 [17280/110534 (16%)]\tClassification Loss: 1.7264\r\n",
      "Train Epoch: 6 [17920/110534 (16%)]\tClassification Loss: 1.4601\r\n",
      "Train Epoch: 6 [18560/110534 (17%)]\tClassification Loss: 1.7541\r\n",
      "Train Epoch: 6 [19200/110534 (17%)]\tClassification Loss: 1.5842\r\n",
      "Train Epoch: 6 [19840/110534 (18%)]\tClassification Loss: 1.4280\r\n",
      "Train Epoch: 6 [20480/110534 (19%)]\tClassification Loss: 1.6829\r\n",
      "Train Epoch: 6 [21120/110534 (19%)]\tClassification Loss: 1.7296\r\n",
      "Train Epoch: 6 [21760/110534 (20%)]\tClassification Loss: 1.4134\r\n",
      "Train Epoch: 6 [22400/110534 (20%)]\tClassification Loss: 1.4823\r\n",
      "Train Epoch: 6 [23040/110534 (21%)]\tClassification Loss: 1.1718\r\n",
      "Train Epoch: 6 [23680/110534 (21%)]\tClassification Loss: 1.6524\r\n",
      "Train Epoch: 6 [24320/110534 (22%)]\tClassification Loss: 1.3577\r\n",
      "Train Epoch: 6 [24960/110534 (23%)]\tClassification Loss: 1.6395\r\n",
      "Train Epoch: 6 [25600/110534 (23%)]\tClassification Loss: 1.3133\r\n",
      "Train Epoch: 6 [26240/110534 (24%)]\tClassification Loss: 1.4707\r\n",
      "Train Epoch: 6 [26880/110534 (24%)]\tClassification Loss: 1.9807\r\n",
      "Train Epoch: 6 [27520/110534 (25%)]\tClassification Loss: 1.3622\r\n",
      "Train Epoch: 6 [28160/110534 (25%)]\tClassification Loss: 1.7367\r\n",
      "Train Epoch: 6 [28800/110534 (26%)]\tClassification Loss: 1.9396\r\n",
      "Train Epoch: 6 [29440/110534 (27%)]\tClassification Loss: 1.7013\r\n",
      "Train Epoch: 6 [30080/110534 (27%)]\tClassification Loss: 1.5953\r\n",
      "Train Epoch: 6 [30720/110534 (28%)]\tClassification Loss: 1.3307\r\n",
      "Train Epoch: 6 [31360/110534 (28%)]\tClassification Loss: 1.6516\r\n",
      "Train Epoch: 6 [32000/110534 (29%)]\tClassification Loss: 1.4203\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_500.pth.tar\r\n",
      "Train Epoch: 6 [32640/110534 (30%)]\tClassification Loss: 1.4420\r\n",
      "Train Epoch: 6 [33280/110534 (30%)]\tClassification Loss: 1.4681\r\n",
      "Train Epoch: 6 [33920/110534 (31%)]\tClassification Loss: 1.6473\r\n",
      "Train Epoch: 6 [34560/110534 (31%)]\tClassification Loss: 1.6646\r\n",
      "Train Epoch: 6 [35200/110534 (32%)]\tClassification Loss: 1.4482\r\n",
      "Train Epoch: 6 [35840/110534 (32%)]\tClassification Loss: 1.2418\r\n",
      "Train Epoch: 6 [36480/110534 (33%)]\tClassification Loss: 1.5590\r\n",
      "Train Epoch: 6 [37120/110534 (34%)]\tClassification Loss: 1.7747\r\n",
      "Train Epoch: 6 [37760/110534 (34%)]\tClassification Loss: 1.9257\r\n",
      "Train Epoch: 6 [38400/110534 (35%)]\tClassification Loss: 1.4278\r\n",
      "Train Epoch: 6 [39040/110534 (35%)]\tClassification Loss: 1.4766\r\n",
      "Train Epoch: 6 [39680/110534 (36%)]\tClassification Loss: 1.5650\r\n",
      "Train Epoch: 6 [40320/110534 (36%)]\tClassification Loss: 1.7285\r\n",
      "Train Epoch: 6 [40960/110534 (37%)]\tClassification Loss: 1.4114\r\n",
      "Train Epoch: 6 [41600/110534 (38%)]\tClassification Loss: 1.4516\r\n",
      "Train Epoch: 6 [42240/110534 (38%)]\tClassification Loss: 1.4236\r\n",
      "Train Epoch: 6 [42880/110534 (39%)]\tClassification Loss: 1.4522\r\n",
      "Train Epoch: 6 [43520/110534 (39%)]\tClassification Loss: 1.3231\r\n",
      "Train Epoch: 6 [44160/110534 (40%)]\tClassification Loss: 1.4665\r\n",
      "Train Epoch: 6 [44800/110534 (41%)]\tClassification Loss: 1.7022\r\n",
      "Train Epoch: 6 [45440/110534 (41%)]\tClassification Loss: 1.6462\r\n",
      "Train Epoch: 6 [46080/110534 (42%)]\tClassification Loss: 1.3216\r\n",
      "Train Epoch: 6 [46720/110534 (42%)]\tClassification Loss: 1.4477\r\n",
      "Train Epoch: 6 [47360/110534 (43%)]\tClassification Loss: 1.4462\r\n",
      "Train Epoch: 6 [48000/110534 (43%)]\tClassification Loss: 1.4410\r\n",
      "Train Epoch: 6 [48640/110534 (44%)]\tClassification Loss: 1.2407\r\n",
      "Train Epoch: 6 [49280/110534 (45%)]\tClassification Loss: 1.6676\r\n",
      "Train Epoch: 6 [49920/110534 (45%)]\tClassification Loss: 1.6095\r\n",
      "Train Epoch: 6 [50560/110534 (46%)]\tClassification Loss: 1.5227\r\n",
      "Train Epoch: 6 [51200/110534 (46%)]\tClassification Loss: 1.4423\r\n",
      "Train Epoch: 6 [51840/110534 (47%)]\tClassification Loss: 1.4704\r\n",
      "Train Epoch: 6 [52480/110534 (47%)]\tClassification Loss: 1.5241\r\n",
      "Train Epoch: 6 [53120/110534 (48%)]\tClassification Loss: 1.0315\r\n",
      "Train Epoch: 6 [53760/110534 (49%)]\tClassification Loss: 1.5856\r\n",
      "Train Epoch: 6 [54400/110534 (49%)]\tClassification Loss: 1.4353\r\n",
      "Train Epoch: 6 [55040/110534 (50%)]\tClassification Loss: 1.6585\r\n",
      "Train Epoch: 6 [55680/110534 (50%)]\tClassification Loss: 1.6610\r\n",
      "Train Epoch: 6 [56320/110534 (51%)]\tClassification Loss: 1.5992\r\n",
      "Train Epoch: 6 [56960/110534 (52%)]\tClassification Loss: 1.4408\r\n",
      "Train Epoch: 6 [57600/110534 (52%)]\tClassification Loss: 1.5036\r\n",
      "Train Epoch: 6 [58240/110534 (53%)]\tClassification Loss: 1.5278\r\n",
      "Train Epoch: 6 [58880/110534 (53%)]\tClassification Loss: 1.6798\r\n",
      "Train Epoch: 6 [59520/110534 (54%)]\tClassification Loss: 1.3638\r\n",
      "Train Epoch: 6 [60160/110534 (54%)]\tClassification Loss: 1.3419\r\n",
      "Train Epoch: 6 [60800/110534 (55%)]\tClassification Loss: 1.4606\r\n",
      "Train Epoch: 6 [61440/110534 (56%)]\tClassification Loss: 1.5210\r\n",
      "Train Epoch: 6 [62080/110534 (56%)]\tClassification Loss: 1.4696\r\n",
      "Train Epoch: 6 [62720/110534 (57%)]\tClassification Loss: 1.6205\r\n",
      "Train Epoch: 6 [63360/110534 (57%)]\tClassification Loss: 1.2996\r\n",
      "Train Epoch: 6 [64000/110534 (58%)]\tClassification Loss: 1.4624\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_1000.pth.tar\r\n",
      "Train Epoch: 6 [64640/110534 (58%)]\tClassification Loss: 1.2302\r\n",
      "Train Epoch: 6 [65280/110534 (59%)]\tClassification Loss: 1.5983\r\n",
      "Train Epoch: 6 [65920/110534 (60%)]\tClassification Loss: 1.4615\r\n",
      "Train Epoch: 6 [66560/110534 (60%)]\tClassification Loss: 1.3417\r\n",
      "Train Epoch: 6 [67200/110534 (61%)]\tClassification Loss: 1.2895\r\n",
      "Train Epoch: 6 [67840/110534 (61%)]\tClassification Loss: 1.8815\r\n",
      "Train Epoch: 6 [68480/110534 (62%)]\tClassification Loss: 1.5807\r\n",
      "Train Epoch: 6 [69120/110534 (63%)]\tClassification Loss: 1.7410\r\n",
      "Train Epoch: 6 [69760/110534 (63%)]\tClassification Loss: 1.5767\r\n",
      "Train Epoch: 6 [70400/110534 (64%)]\tClassification Loss: 1.2633\r\n",
      "Train Epoch: 6 [71040/110534 (64%)]\tClassification Loss: 1.8210\r\n",
      "Train Epoch: 6 [71680/110534 (65%)]\tClassification Loss: 1.5645\r\n",
      "Train Epoch: 6 [72320/110534 (65%)]\tClassification Loss: 1.3991\r\n",
      "Train Epoch: 6 [72960/110534 (66%)]\tClassification Loss: 1.7314\r\n",
      "Train Epoch: 6 [73600/110534 (67%)]\tClassification Loss: 1.7801\r\n",
      "Train Epoch: 6 [74240/110534 (67%)]\tClassification Loss: 1.8161\r\n",
      "Train Epoch: 6 [74880/110534 (68%)]\tClassification Loss: 1.1840\r\n",
      "Train Epoch: 6 [75520/110534 (68%)]\tClassification Loss: 1.4236\r\n",
      "Train Epoch: 6 [76160/110534 (69%)]\tClassification Loss: 1.2733\r\n",
      "Train Epoch: 6 [76800/110534 (69%)]\tClassification Loss: 1.3633\r\n",
      "Train Epoch: 6 [77440/110534 (70%)]\tClassification Loss: 1.4424\r\n",
      "Train Epoch: 6 [78080/110534 (71%)]\tClassification Loss: 1.5094\r\n",
      "Train Epoch: 6 [78720/110534 (71%)]\tClassification Loss: 1.3052\r\n",
      "Train Epoch: 6 [79360/110534 (72%)]\tClassification Loss: 1.2278\r\n",
      "Train Epoch: 6 [80000/110534 (72%)]\tClassification Loss: 1.2745\r\n",
      "Train Epoch: 6 [80640/110534 (73%)]\tClassification Loss: 1.5914\r\n",
      "Train Epoch: 6 [81280/110534 (74%)]\tClassification Loss: 1.8180\r\n",
      "Train Epoch: 6 [81920/110534 (74%)]\tClassification Loss: 1.5216\r\n",
      "Train Epoch: 6 [82560/110534 (75%)]\tClassification Loss: 2.0221\r\n",
      "Train Epoch: 6 [83200/110534 (75%)]\tClassification Loss: 1.3945\r\n",
      "Train Epoch: 6 [83840/110534 (76%)]\tClassification Loss: 1.9321\r\n",
      "Train Epoch: 6 [84480/110534 (76%)]\tClassification Loss: 1.5134\r\n",
      "Train Epoch: 6 [85120/110534 (77%)]\tClassification Loss: 1.4156\r\n",
      "Train Epoch: 6 [85760/110534 (78%)]\tClassification Loss: 1.6721\r\n",
      "Train Epoch: 6 [86400/110534 (78%)]\tClassification Loss: 1.6241\r\n",
      "Train Epoch: 6 [87040/110534 (79%)]\tClassification Loss: 1.3544\r\n",
      "Train Epoch: 6 [87680/110534 (79%)]\tClassification Loss: 1.3589\r\n",
      "Train Epoch: 6 [88320/110534 (80%)]\tClassification Loss: 1.5311\r\n",
      "Train Epoch: 6 [88960/110534 (80%)]\tClassification Loss: 1.5879\r\n",
      "Train Epoch: 6 [89600/110534 (81%)]\tClassification Loss: 1.6618\r\n",
      "Train Epoch: 6 [90240/110534 (82%)]\tClassification Loss: 1.6835\r\n",
      "Train Epoch: 6 [90880/110534 (82%)]\tClassification Loss: 1.5481\r\n",
      "Train Epoch: 6 [91520/110534 (83%)]\tClassification Loss: 1.3475\r\n",
      "Train Epoch: 6 [92160/110534 (83%)]\tClassification Loss: 1.4192\r\n",
      "Train Epoch: 6 [92800/110534 (84%)]\tClassification Loss: 1.3309\r\n",
      "Train Epoch: 6 [93440/110534 (85%)]\tClassification Loss: 1.8734\r\n",
      "Train Epoch: 6 [94080/110534 (85%)]\tClassification Loss: 1.5821\r\n",
      "Train Epoch: 6 [94720/110534 (86%)]\tClassification Loss: 1.4848\r\n",
      "Train Epoch: 6 [95360/110534 (86%)]\tClassification Loss: 1.5181\r\n",
      "Train Epoch: 6 [96000/110534 (87%)]\tClassification Loss: 1.4016\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_1500.pth.tar\r\n",
      "Train Epoch: 6 [96640/110534 (87%)]\tClassification Loss: 1.3996\r\n",
      "Train Epoch: 6 [97280/110534 (88%)]\tClassification Loss: 1.2206\r\n",
      "Train Epoch: 6 [97920/110534 (89%)]\tClassification Loss: 1.1895\r\n",
      "Train Epoch: 6 [98560/110534 (89%)]\tClassification Loss: 1.4254\r\n",
      "Train Epoch: 6 [99200/110534 (90%)]\tClassification Loss: 1.5696\r\n",
      "Train Epoch: 6 [99840/110534 (90%)]\tClassification Loss: 1.5426\r\n",
      "Train Epoch: 6 [100480/110534 (91%)]\tClassification Loss: 1.7708\r\n",
      "Train Epoch: 6 [101120/110534 (91%)]\tClassification Loss: 1.4874\r\n",
      "Train Epoch: 6 [101760/110534 (92%)]\tClassification Loss: 1.6184\r\n",
      "Train Epoch: 6 [102400/110534 (93%)]\tClassification Loss: 1.4474\r\n",
      "Train Epoch: 6 [103040/110534 (93%)]\tClassification Loss: 1.4016\r\n",
      "Train Epoch: 6 [103680/110534 (94%)]\tClassification Loss: 1.7197\r\n",
      "Train Epoch: 6 [104320/110534 (94%)]\tClassification Loss: 1.3700\r\n",
      "Train Epoch: 6 [104960/110534 (95%)]\tClassification Loss: 1.5825\r\n",
      "Train Epoch: 6 [105600/110534 (96%)]\tClassification Loss: 1.4211\r\n",
      "Train Epoch: 6 [106240/110534 (96%)]\tClassification Loss: 1.4251\r\n",
      "Train Epoch: 6 [106880/110534 (97%)]\tClassification Loss: 1.8362\r\n",
      "Train Epoch: 6 [107520/110534 (97%)]\tClassification Loss: 1.7157\r\n",
      "Train Epoch: 6 [108160/110534 (98%)]\tClassification Loss: 1.5768\r\n",
      "Train Epoch: 6 [108800/110534 (98%)]\tClassification Loss: 1.6131\r\n",
      "Train Epoch: 6 [109440/110534 (99%)]\tClassification Loss: 1.5300\r\n",
      "Train Epoch: 6 [110080/110534 (100%)]\tClassification Loss: 1.4760\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_final.pth.tar\r\n",
      "Train Epoch: 7 [0/110534 (0%)]\tClassification Loss: 1.6988\r\n",
      "\r\n",
      "Test set: Average loss: 1.4270, Accuracy: 23215/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 7 [640/110534 (1%)]\tClassification Loss: 1.3679\r\n",
      "Train Epoch: 7 [1280/110534 (1%)]\tClassification Loss: 2.0166\r\n",
      "Train Epoch: 7 [1920/110534 (2%)]\tClassification Loss: 1.5229\r\n",
      "Train Epoch: 7 [2560/110534 (2%)]\tClassification Loss: 1.7130\r\n",
      "Train Epoch: 7 [3200/110534 (3%)]\tClassification Loss: 1.6047\r\n",
      "Train Epoch: 7 [3840/110534 (3%)]\tClassification Loss: 1.3653\r\n",
      "Train Epoch: 7 [4480/110534 (4%)]\tClassification Loss: 1.4408\r\n",
      "Train Epoch: 7 [5120/110534 (5%)]\tClassification Loss: 1.5030\r\n",
      "Train Epoch: 7 [5760/110534 (5%)]\tClassification Loss: 1.4769\r\n",
      "Train Epoch: 7 [6400/110534 (6%)]\tClassification Loss: 1.1791\r\n",
      "Train Epoch: 7 [7040/110534 (6%)]\tClassification Loss: 1.5773\r\n",
      "Train Epoch: 7 [7680/110534 (7%)]\tClassification Loss: 1.6393\r\n",
      "Train Epoch: 7 [8320/110534 (8%)]\tClassification Loss: 1.8889\r\n",
      "Train Epoch: 7 [8960/110534 (8%)]\tClassification Loss: 1.7215\r\n",
      "Train Epoch: 7 [9600/110534 (9%)]\tClassification Loss: 1.3620\r\n",
      "Train Epoch: 7 [10240/110534 (9%)]\tClassification Loss: 1.5870\r\n",
      "Train Epoch: 7 [10880/110534 (10%)]\tClassification Loss: 1.3765\r\n",
      "Train Epoch: 7 [11520/110534 (10%)]\tClassification Loss: 1.5837\r\n",
      "Train Epoch: 7 [12160/110534 (11%)]\tClassification Loss: 1.3322\r\n",
      "Train Epoch: 7 [12800/110534 (12%)]\tClassification Loss: 1.5456\r\n",
      "Train Epoch: 7 [13440/110534 (12%)]\tClassification Loss: 1.4794\r\n",
      "Train Epoch: 7 [14080/110534 (13%)]\tClassification Loss: 1.6200\r\n",
      "Train Epoch: 7 [14720/110534 (13%)]\tClassification Loss: 1.7314\r\n",
      "Train Epoch: 7 [15360/110534 (14%)]\tClassification Loss: 1.5811\r\n",
      "Train Epoch: 7 [16000/110534 (14%)]\tClassification Loss: 1.5575\r\n",
      "Train Epoch: 7 [16640/110534 (15%)]\tClassification Loss: 1.5034\r\n",
      "Train Epoch: 7 [17280/110534 (16%)]\tClassification Loss: 1.6603\r\n",
      "Train Epoch: 7 [17920/110534 (16%)]\tClassification Loss: 1.5524\r\n",
      "Train Epoch: 7 [18560/110534 (17%)]\tClassification Loss: 1.7594\r\n",
      "Train Epoch: 7 [19200/110534 (17%)]\tClassification Loss: 1.5442\r\n",
      "Train Epoch: 7 [19840/110534 (18%)]\tClassification Loss: 1.4405\r\n",
      "Train Epoch: 7 [20480/110534 (19%)]\tClassification Loss: 1.7101\r\n",
      "Train Epoch: 7 [21120/110534 (19%)]\tClassification Loss: 1.8039\r\n",
      "Train Epoch: 7 [21760/110534 (20%)]\tClassification Loss: 1.3146\r\n",
      "Train Epoch: 7 [22400/110534 (20%)]\tClassification Loss: 1.4447\r\n",
      "Train Epoch: 7 [23040/110534 (21%)]\tClassification Loss: 1.0775\r\n",
      "Train Epoch: 7 [23680/110534 (21%)]\tClassification Loss: 1.8014\r\n",
      "Train Epoch: 7 [24320/110534 (22%)]\tClassification Loss: 1.2680\r\n",
      "Train Epoch: 7 [24960/110534 (23%)]\tClassification Loss: 1.6511\r\n",
      "Train Epoch: 7 [25600/110534 (23%)]\tClassification Loss: 1.3859\r\n",
      "Train Epoch: 7 [26240/110534 (24%)]\tClassification Loss: 1.4718\r\n",
      "Train Epoch: 7 [26880/110534 (24%)]\tClassification Loss: 1.8127\r\n",
      "Train Epoch: 7 [27520/110534 (25%)]\tClassification Loss: 1.3832\r\n",
      "Train Epoch: 7 [28160/110534 (25%)]\tClassification Loss: 1.6567\r\n",
      "Train Epoch: 7 [28800/110534 (26%)]\tClassification Loss: 1.8640\r\n",
      "Train Epoch: 7 [29440/110534 (27%)]\tClassification Loss: 1.6922\r\n",
      "Train Epoch: 7 [30080/110534 (27%)]\tClassification Loss: 1.7655\r\n",
      "Train Epoch: 7 [30720/110534 (28%)]\tClassification Loss: 1.3563\r\n",
      "Train Epoch: 7 [31360/110534 (28%)]\tClassification Loss: 1.6510\r\n",
      "Train Epoch: 7 [32000/110534 (29%)]\tClassification Loss: 1.4586\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_500.pth.tar\r\n",
      "Train Epoch: 7 [32640/110534 (30%)]\tClassification Loss: 1.2961\r\n",
      "Train Epoch: 7 [33280/110534 (30%)]\tClassification Loss: 1.4505\r\n",
      "Train Epoch: 7 [33920/110534 (31%)]\tClassification Loss: 1.6747\r\n",
      "Train Epoch: 7 [34560/110534 (31%)]\tClassification Loss: 1.5431\r\n",
      "Train Epoch: 7 [35200/110534 (32%)]\tClassification Loss: 1.5729\r\n",
      "Train Epoch: 7 [35840/110534 (32%)]\tClassification Loss: 1.2118\r\n",
      "Train Epoch: 7 [36480/110534 (33%)]\tClassification Loss: 1.4299\r\n",
      "Train Epoch: 7 [37120/110534 (34%)]\tClassification Loss: 1.5680\r\n",
      "Train Epoch: 7 [37760/110534 (34%)]\tClassification Loss: 1.8314\r\n",
      "Train Epoch: 7 [38400/110534 (35%)]\tClassification Loss: 1.5480\r\n",
      "Train Epoch: 7 [39040/110534 (35%)]\tClassification Loss: 1.5432\r\n",
      "Train Epoch: 7 [39680/110534 (36%)]\tClassification Loss: 1.6585\r\n",
      "Train Epoch: 7 [40320/110534 (36%)]\tClassification Loss: 1.6173\r\n",
      "Train Epoch: 7 [40960/110534 (37%)]\tClassification Loss: 1.3774\r\n",
      "Train Epoch: 7 [41600/110534 (38%)]\tClassification Loss: 1.4556\r\n",
      "Train Epoch: 7 [42240/110534 (38%)]\tClassification Loss: 1.3914\r\n",
      "Train Epoch: 7 [42880/110534 (39%)]\tClassification Loss: 1.4796\r\n",
      "Train Epoch: 7 [43520/110534 (39%)]\tClassification Loss: 1.3453\r\n",
      "Train Epoch: 7 [44160/110534 (40%)]\tClassification Loss: 1.6428\r\n",
      "Train Epoch: 7 [44800/110534 (41%)]\tClassification Loss: 1.6044\r\n",
      "Train Epoch: 7 [45440/110534 (41%)]\tClassification Loss: 1.5859\r\n",
      "Train Epoch: 7 [46080/110534 (42%)]\tClassification Loss: 1.3989\r\n",
      "Train Epoch: 7 [46720/110534 (42%)]\tClassification Loss: 1.4133\r\n",
      "Train Epoch: 7 [47360/110534 (43%)]\tClassification Loss: 1.4848\r\n",
      "Train Epoch: 7 [48000/110534 (43%)]\tClassification Loss: 1.5164\r\n",
      "Train Epoch: 7 [48640/110534 (44%)]\tClassification Loss: 1.3614\r\n",
      "Train Epoch: 7 [49280/110534 (45%)]\tClassification Loss: 1.4744\r\n",
      "Train Epoch: 7 [49920/110534 (45%)]\tClassification Loss: 1.5113\r\n",
      "Train Epoch: 7 [50560/110534 (46%)]\tClassification Loss: 1.5488\r\n",
      "Train Epoch: 7 [51200/110534 (46%)]\tClassification Loss: 1.4132\r\n",
      "Train Epoch: 7 [51840/110534 (47%)]\tClassification Loss: 1.4113\r\n",
      "Train Epoch: 7 [52480/110534 (47%)]\tClassification Loss: 1.4964\r\n",
      "Train Epoch: 7 [53120/110534 (48%)]\tClassification Loss: 1.2427\r\n",
      "Train Epoch: 7 [53760/110534 (49%)]\tClassification Loss: 1.5960\r\n",
      "Train Epoch: 7 [54400/110534 (49%)]\tClassification Loss: 1.4441\r\n",
      "Train Epoch: 7 [55040/110534 (50%)]\tClassification Loss: 1.6981\r\n",
      "Train Epoch: 7 [55680/110534 (50%)]\tClassification Loss: 1.6159\r\n",
      "Train Epoch: 7 [56320/110534 (51%)]\tClassification Loss: 1.4988\r\n",
      "Train Epoch: 7 [56960/110534 (52%)]\tClassification Loss: 1.5499\r\n",
      "Train Epoch: 7 [57600/110534 (52%)]\tClassification Loss: 1.6345\r\n",
      "Train Epoch: 7 [58240/110534 (53%)]\tClassification Loss: 1.4969\r\n",
      "Train Epoch: 7 [58880/110534 (53%)]\tClassification Loss: 1.5531\r\n",
      "Train Epoch: 7 [59520/110534 (54%)]\tClassification Loss: 1.3446\r\n",
      "Train Epoch: 7 [60160/110534 (54%)]\tClassification Loss: 1.5582\r\n",
      "Train Epoch: 7 [60800/110534 (55%)]\tClassification Loss: 1.7598\r\n",
      "Train Epoch: 7 [61440/110534 (56%)]\tClassification Loss: 1.4294\r\n",
      "Train Epoch: 7 [62080/110534 (56%)]\tClassification Loss: 1.6185\r\n",
      "Train Epoch: 7 [62720/110534 (57%)]\tClassification Loss: 1.7460\r\n",
      "Train Epoch: 7 [63360/110534 (57%)]\tClassification Loss: 1.2624\r\n",
      "Train Epoch: 7 [64000/110534 (58%)]\tClassification Loss: 1.4629\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_1000.pth.tar\r\n",
      "Train Epoch: 7 [64640/110534 (58%)]\tClassification Loss: 1.2184\r\n",
      "Train Epoch: 7 [65280/110534 (59%)]\tClassification Loss: 1.5459\r\n",
      "Train Epoch: 7 [65920/110534 (60%)]\tClassification Loss: 1.5557\r\n",
      "Train Epoch: 7 [66560/110534 (60%)]\tClassification Loss: 1.3135\r\n",
      "Train Epoch: 7 [67200/110534 (61%)]\tClassification Loss: 1.2630\r\n",
      "Train Epoch: 7 [67840/110534 (61%)]\tClassification Loss: 1.8535\r\n",
      "Train Epoch: 7 [68480/110534 (62%)]\tClassification Loss: 1.6331\r\n",
      "Train Epoch: 7 [69120/110534 (63%)]\tClassification Loss: 1.6771\r\n",
      "Train Epoch: 7 [69760/110534 (63%)]\tClassification Loss: 1.6461\r\n",
      "Train Epoch: 7 [70400/110534 (64%)]\tClassification Loss: 1.1965\r\n",
      "Train Epoch: 7 [71040/110534 (64%)]\tClassification Loss: 1.7799\r\n",
      "Train Epoch: 7 [71680/110534 (65%)]\tClassification Loss: 1.4332\r\n",
      "Train Epoch: 7 [72320/110534 (65%)]\tClassification Loss: 1.5945\r\n",
      "Train Epoch: 7 [72960/110534 (66%)]\tClassification Loss: 1.5822\r\n",
      "Train Epoch: 7 [73600/110534 (67%)]\tClassification Loss: 1.8029\r\n",
      "Train Epoch: 7 [74240/110534 (67%)]\tClassification Loss: 1.8410\r\n",
      "Train Epoch: 7 [74880/110534 (68%)]\tClassification Loss: 1.3161\r\n",
      "Train Epoch: 7 [75520/110534 (68%)]\tClassification Loss: 1.4719\r\n",
      "Train Epoch: 7 [76160/110534 (69%)]\tClassification Loss: 1.4244\r\n",
      "Train Epoch: 7 [76800/110534 (69%)]\tClassification Loss: 1.3929\r\n",
      "Train Epoch: 7 [77440/110534 (70%)]\tClassification Loss: 1.3235\r\n",
      "Train Epoch: 7 [78080/110534 (71%)]\tClassification Loss: 1.4400\r\n",
      "Train Epoch: 7 [78720/110534 (71%)]\tClassification Loss: 1.5041\r\n",
      "Train Epoch: 7 [79360/110534 (72%)]\tClassification Loss: 1.3253\r\n",
      "Train Epoch: 7 [80000/110534 (72%)]\tClassification Loss: 1.3107\r\n",
      "Train Epoch: 7 [80640/110534 (73%)]\tClassification Loss: 1.4970\r\n",
      "Train Epoch: 7 [81280/110534 (74%)]\tClassification Loss: 1.8687\r\n",
      "Train Epoch: 7 [81920/110534 (74%)]\tClassification Loss: 1.5664\r\n",
      "Train Epoch: 7 [82560/110534 (75%)]\tClassification Loss: 1.7491\r\n",
      "Train Epoch: 7 [83200/110534 (75%)]\tClassification Loss: 1.5228\r\n",
      "Train Epoch: 7 [83840/110534 (76%)]\tClassification Loss: 2.0034\r\n",
      "Train Epoch: 7 [84480/110534 (76%)]\tClassification Loss: 1.6732\r\n",
      "Train Epoch: 7 [85120/110534 (77%)]\tClassification Loss: 1.6907\r\n",
      "Train Epoch: 7 [85760/110534 (78%)]\tClassification Loss: 1.5947\r\n",
      "Train Epoch: 7 [86400/110534 (78%)]\tClassification Loss: 1.6115\r\n",
      "Train Epoch: 7 [87040/110534 (79%)]\tClassification Loss: 1.4216\r\n",
      "Train Epoch: 7 [87680/110534 (79%)]\tClassification Loss: 1.4357\r\n",
      "Train Epoch: 7 [88320/110534 (80%)]\tClassification Loss: 1.5804\r\n",
      "Train Epoch: 7 [88960/110534 (80%)]\tClassification Loss: 1.5756\r\n",
      "Train Epoch: 7 [89600/110534 (81%)]\tClassification Loss: 1.7133\r\n",
      "Train Epoch: 7 [90240/110534 (82%)]\tClassification Loss: 1.8376\r\n",
      "Train Epoch: 7 [90880/110534 (82%)]\tClassification Loss: 1.5922\r\n",
      "Train Epoch: 7 [91520/110534 (83%)]\tClassification Loss: 1.2403\r\n",
      "Train Epoch: 7 [92160/110534 (83%)]\tClassification Loss: 1.5330\r\n",
      "Train Epoch: 7 [92800/110534 (84%)]\tClassification Loss: 1.5464\r\n",
      "Train Epoch: 7 [93440/110534 (85%)]\tClassification Loss: 1.6815\r\n",
      "Train Epoch: 7 [94080/110534 (85%)]\tClassification Loss: 1.7303\r\n",
      "Train Epoch: 7 [94720/110534 (86%)]\tClassification Loss: 1.3765\r\n",
      "Train Epoch: 7 [95360/110534 (86%)]\tClassification Loss: 1.4172\r\n",
      "Train Epoch: 7 [96000/110534 (87%)]\tClassification Loss: 1.4775\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_1500.pth.tar\r\n",
      "Train Epoch: 7 [96640/110534 (87%)]\tClassification Loss: 1.3837\r\n",
      "Train Epoch: 7 [97280/110534 (88%)]\tClassification Loss: 1.2498\r\n",
      "Train Epoch: 7 [97920/110534 (89%)]\tClassification Loss: 1.2079\r\n",
      "Train Epoch: 7 [98560/110534 (89%)]\tClassification Loss: 1.5092\r\n",
      "Train Epoch: 7 [99200/110534 (90%)]\tClassification Loss: 1.4899\r\n",
      "Train Epoch: 7 [99840/110534 (90%)]\tClassification Loss: 1.4177\r\n",
      "Train Epoch: 7 [100480/110534 (91%)]\tClassification Loss: 1.5519\r\n",
      "Train Epoch: 7 [101120/110534 (91%)]\tClassification Loss: 1.4286\r\n",
      "Train Epoch: 7 [101760/110534 (92%)]\tClassification Loss: 1.5649\r\n",
      "Train Epoch: 7 [102400/110534 (93%)]\tClassification Loss: 1.4746\r\n",
      "Train Epoch: 7 [103040/110534 (93%)]\tClassification Loss: 1.3857\r\n",
      "Train Epoch: 7 [103680/110534 (94%)]\tClassification Loss: 1.6402\r\n",
      "Train Epoch: 7 [104320/110534 (94%)]\tClassification Loss: 1.4183\r\n",
      "Train Epoch: 7 [104960/110534 (95%)]\tClassification Loss: 1.5395\r\n",
      "Train Epoch: 7 [105600/110534 (96%)]\tClassification Loss: 1.4525\r\n",
      "Train Epoch: 7 [106240/110534 (96%)]\tClassification Loss: 1.1975\r\n",
      "Train Epoch: 7 [106880/110534 (97%)]\tClassification Loss: 1.7517\r\n",
      "Train Epoch: 7 [107520/110534 (97%)]\tClassification Loss: 1.5548\r\n",
      "Train Epoch: 7 [108160/110534 (98%)]\tClassification Loss: 1.4925\r\n",
      "Train Epoch: 7 [108800/110534 (98%)]\tClassification Loss: 1.6179\r\n",
      "Train Epoch: 7 [109440/110534 (99%)]\tClassification Loss: 1.3916\r\n",
      "Train Epoch: 7 [110080/110534 (100%)]\tClassification Loss: 1.4416\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_final.pth.tar\r\n",
      "Train Epoch: 8 [0/110534 (0%)]\tClassification Loss: 1.6107\r\n",
      "\r\n",
      "Test set: Average loss: 1.4198, Accuracy: 23271/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 8 [640/110534 (1%)]\tClassification Loss: 1.2308\r\n",
      "Train Epoch: 8 [1280/110534 (1%)]\tClassification Loss: 1.9450\r\n",
      "Train Epoch: 8 [1920/110534 (2%)]\tClassification Loss: 1.6056\r\n",
      "Train Epoch: 8 [2560/110534 (2%)]\tClassification Loss: 1.8124\r\n",
      "Train Epoch: 8 [3200/110534 (3%)]\tClassification Loss: 1.4078\r\n",
      "Train Epoch: 8 [3840/110534 (3%)]\tClassification Loss: 1.4137\r\n",
      "Train Epoch: 8 [4480/110534 (4%)]\tClassification Loss: 1.5633\r\n",
      "Train Epoch: 8 [5120/110534 (5%)]\tClassification Loss: 1.6646\r\n",
      "Train Epoch: 8 [5760/110534 (5%)]\tClassification Loss: 1.4611\r\n",
      "Train Epoch: 8 [6400/110534 (6%)]\tClassification Loss: 1.1662\r\n",
      "Train Epoch: 8 [7040/110534 (6%)]\tClassification Loss: 1.5272\r\n",
      "Train Epoch: 8 [7680/110534 (7%)]\tClassification Loss: 1.5357\r\n",
      "Train Epoch: 8 [8320/110534 (8%)]\tClassification Loss: 1.8003\r\n",
      "Train Epoch: 8 [8960/110534 (8%)]\tClassification Loss: 1.7961\r\n",
      "Train Epoch: 8 [9600/110534 (9%)]\tClassification Loss: 1.4286\r\n",
      "Train Epoch: 8 [10240/110534 (9%)]\tClassification Loss: 1.4893\r\n",
      "Train Epoch: 8 [10880/110534 (10%)]\tClassification Loss: 1.5191\r\n",
      "Train Epoch: 8 [11520/110534 (10%)]\tClassification Loss: 1.7178\r\n",
      "Train Epoch: 8 [12160/110534 (11%)]\tClassification Loss: 1.3171\r\n",
      "Train Epoch: 8 [12800/110534 (12%)]\tClassification Loss: 1.6094\r\n",
      "Train Epoch: 8 [13440/110534 (12%)]\tClassification Loss: 1.4138\r\n",
      "Train Epoch: 8 [14080/110534 (13%)]\tClassification Loss: 1.6262\r\n",
      "Train Epoch: 8 [14720/110534 (13%)]\tClassification Loss: 1.7552\r\n",
      "Train Epoch: 8 [15360/110534 (14%)]\tClassification Loss: 1.4108\r\n",
      "Train Epoch: 8 [16000/110534 (14%)]\tClassification Loss: 1.6020\r\n",
      "Train Epoch: 8 [16640/110534 (15%)]\tClassification Loss: 1.4780\r\n",
      "Train Epoch: 8 [17280/110534 (16%)]\tClassification Loss: 1.6220\r\n",
      "Train Epoch: 8 [17920/110534 (16%)]\tClassification Loss: 1.7406\r\n",
      "Train Epoch: 8 [18560/110534 (17%)]\tClassification Loss: 1.6832\r\n",
      "Train Epoch: 8 [19200/110534 (17%)]\tClassification Loss: 1.5786\r\n",
      "Train Epoch: 8 [19840/110534 (18%)]\tClassification Loss: 1.5106\r\n",
      "Train Epoch: 8 [20480/110534 (19%)]\tClassification Loss: 1.5875\r\n",
      "Train Epoch: 8 [21120/110534 (19%)]\tClassification Loss: 1.6717\r\n",
      "Train Epoch: 8 [21760/110534 (20%)]\tClassification Loss: 1.2822\r\n",
      "Train Epoch: 8 [22400/110534 (20%)]\tClassification Loss: 1.4630\r\n",
      "Train Epoch: 8 [23040/110534 (21%)]\tClassification Loss: 1.1124\r\n",
      "Train Epoch: 8 [23680/110534 (21%)]\tClassification Loss: 1.7869\r\n",
      "Train Epoch: 8 [24320/110534 (22%)]\tClassification Loss: 1.1166\r\n",
      "Train Epoch: 8 [24960/110534 (23%)]\tClassification Loss: 1.8123\r\n",
      "Train Epoch: 8 [25600/110534 (23%)]\tClassification Loss: 1.3358\r\n",
      "Train Epoch: 8 [26240/110534 (24%)]\tClassification Loss: 1.5912\r\n",
      "Train Epoch: 8 [26880/110534 (24%)]\tClassification Loss: 1.8368\r\n",
      "Train Epoch: 8 [27520/110534 (25%)]\tClassification Loss: 1.4289\r\n",
      "Train Epoch: 8 [28160/110534 (25%)]\tClassification Loss: 1.8016\r\n",
      "Train Epoch: 8 [28800/110534 (26%)]\tClassification Loss: 1.8173\r\n",
      "Train Epoch: 8 [29440/110534 (27%)]\tClassification Loss: 1.5388\r\n",
      "Train Epoch: 8 [30080/110534 (27%)]\tClassification Loss: 1.8110\r\n",
      "Train Epoch: 8 [30720/110534 (28%)]\tClassification Loss: 1.3995\r\n",
      "Train Epoch: 8 [31360/110534 (28%)]\tClassification Loss: 1.5613\r\n",
      "Train Epoch: 8 [32000/110534 (29%)]\tClassification Loss: 1.5403\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_500.pth.tar\r\n",
      "Train Epoch: 8 [32640/110534 (30%)]\tClassification Loss: 1.3145\r\n",
      "Train Epoch: 8 [33280/110534 (30%)]\tClassification Loss: 1.4774\r\n",
      "Train Epoch: 8 [33920/110534 (31%)]\tClassification Loss: 1.5058\r\n",
      "Train Epoch: 8 [34560/110534 (31%)]\tClassification Loss: 1.7639\r\n",
      "Train Epoch: 8 [35200/110534 (32%)]\tClassification Loss: 1.5765\r\n",
      "Train Epoch: 8 [35840/110534 (32%)]\tClassification Loss: 1.2775\r\n",
      "Train Epoch: 8 [36480/110534 (33%)]\tClassification Loss: 1.4960\r\n",
      "Train Epoch: 8 [37120/110534 (34%)]\tClassification Loss: 1.6631\r\n",
      "Train Epoch: 8 [37760/110534 (34%)]\tClassification Loss: 1.9771\r\n",
      "Train Epoch: 8 [38400/110534 (35%)]\tClassification Loss: 1.5848\r\n",
      "Train Epoch: 8 [39040/110534 (35%)]\tClassification Loss: 1.5828\r\n",
      "Train Epoch: 8 [39680/110534 (36%)]\tClassification Loss: 1.6082\r\n",
      "Train Epoch: 8 [40320/110534 (36%)]\tClassification Loss: 1.5264\r\n",
      "Train Epoch: 8 [40960/110534 (37%)]\tClassification Loss: 1.3256\r\n",
      "Train Epoch: 8 [41600/110534 (38%)]\tClassification Loss: 1.4206\r\n",
      "Train Epoch: 8 [42240/110534 (38%)]\tClassification Loss: 1.2819\r\n",
      "Train Epoch: 8 [42880/110534 (39%)]\tClassification Loss: 1.4395\r\n",
      "Train Epoch: 8 [43520/110534 (39%)]\tClassification Loss: 1.3344\r\n",
      "Train Epoch: 8 [44160/110534 (40%)]\tClassification Loss: 1.4895\r\n",
      "Train Epoch: 8 [44800/110534 (41%)]\tClassification Loss: 1.5487\r\n",
      "Train Epoch: 8 [45440/110534 (41%)]\tClassification Loss: 1.3878\r\n",
      "Train Epoch: 8 [46080/110534 (42%)]\tClassification Loss: 1.3299\r\n",
      "Train Epoch: 8 [46720/110534 (42%)]\tClassification Loss: 1.4909\r\n",
      "Train Epoch: 8 [47360/110534 (43%)]\tClassification Loss: 1.5047\r\n",
      "Train Epoch: 8 [48000/110534 (43%)]\tClassification Loss: 1.4620\r\n",
      "Train Epoch: 8 [48640/110534 (44%)]\tClassification Loss: 1.2658\r\n",
      "Train Epoch: 8 [49280/110534 (45%)]\tClassification Loss: 1.5067\r\n",
      "Train Epoch: 8 [49920/110534 (45%)]\tClassification Loss: 1.5405\r\n",
      "Train Epoch: 8 [50560/110534 (46%)]\tClassification Loss: 1.6300\r\n",
      "Train Epoch: 8 [51200/110534 (46%)]\tClassification Loss: 1.3810\r\n",
      "Train Epoch: 8 [51840/110534 (47%)]\tClassification Loss: 1.4030\r\n",
      "Train Epoch: 8 [52480/110534 (47%)]\tClassification Loss: 1.4042\r\n",
      "Train Epoch: 8 [53120/110534 (48%)]\tClassification Loss: 1.1493\r\n",
      "Train Epoch: 8 [53760/110534 (49%)]\tClassification Loss: 1.5596\r\n",
      "Train Epoch: 8 [54400/110534 (49%)]\tClassification Loss: 1.5226\r\n",
      "Train Epoch: 8 [55040/110534 (50%)]\tClassification Loss: 1.7335\r\n",
      "Train Epoch: 8 [55680/110534 (50%)]\tClassification Loss: 1.5434\r\n",
      "Train Epoch: 8 [56320/110534 (51%)]\tClassification Loss: 1.6558\r\n",
      "Train Epoch: 8 [56960/110534 (52%)]\tClassification Loss: 1.3948\r\n",
      "Train Epoch: 8 [57600/110534 (52%)]\tClassification Loss: 1.5423\r\n",
      "Train Epoch: 8 [58240/110534 (53%)]\tClassification Loss: 1.6476\r\n",
      "Train Epoch: 8 [58880/110534 (53%)]\tClassification Loss: 1.7182\r\n",
      "Train Epoch: 8 [59520/110534 (54%)]\tClassification Loss: 1.4019\r\n",
      "Train Epoch: 8 [60160/110534 (54%)]\tClassification Loss: 1.3282\r\n",
      "Train Epoch: 8 [60800/110534 (55%)]\tClassification Loss: 1.6597\r\n",
      "Train Epoch: 8 [61440/110534 (56%)]\tClassification Loss: 1.4492\r\n",
      "Train Epoch: 8 [62080/110534 (56%)]\tClassification Loss: 1.3494\r\n",
      "Train Epoch: 8 [62720/110534 (57%)]\tClassification Loss: 1.7043\r\n",
      "Train Epoch: 8 [63360/110534 (57%)]\tClassification Loss: 1.3320\r\n",
      "Train Epoch: 8 [64000/110534 (58%)]\tClassification Loss: 1.5327\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_1000.pth.tar\r\n",
      "Train Epoch: 8 [64640/110534 (58%)]\tClassification Loss: 1.2151\r\n",
      "Train Epoch: 8 [65280/110534 (59%)]\tClassification Loss: 1.5748\r\n",
      "Train Epoch: 8 [65920/110534 (60%)]\tClassification Loss: 1.3855\r\n",
      "Train Epoch: 8 [66560/110534 (60%)]\tClassification Loss: 1.3501\r\n",
      "Train Epoch: 8 [67200/110534 (61%)]\tClassification Loss: 1.4241\r\n",
      "Train Epoch: 8 [67840/110534 (61%)]\tClassification Loss: 1.8135\r\n",
      "Train Epoch: 8 [68480/110534 (62%)]\tClassification Loss: 1.6334\r\n",
      "Train Epoch: 8 [69120/110534 (63%)]\tClassification Loss: 1.7409\r\n",
      "Train Epoch: 8 [69760/110534 (63%)]\tClassification Loss: 1.5222\r\n",
      "Train Epoch: 8 [70400/110534 (64%)]\tClassification Loss: 1.2695\r\n",
      "Train Epoch: 8 [71040/110534 (64%)]\tClassification Loss: 1.8550\r\n",
      "Train Epoch: 8 [71680/110534 (65%)]\tClassification Loss: 1.4021\r\n",
      "Train Epoch: 8 [72320/110534 (65%)]\tClassification Loss: 1.5346\r\n",
      "Train Epoch: 8 [72960/110534 (66%)]\tClassification Loss: 1.6621\r\n",
      "Train Epoch: 8 [73600/110534 (67%)]\tClassification Loss: 1.7277\r\n",
      "Train Epoch: 8 [74240/110534 (67%)]\tClassification Loss: 1.6794\r\n",
      "Train Epoch: 8 [74880/110534 (68%)]\tClassification Loss: 1.1167\r\n",
      "Train Epoch: 8 [75520/110534 (68%)]\tClassification Loss: 1.5448\r\n",
      "Train Epoch: 8 [76160/110534 (69%)]\tClassification Loss: 1.2894\r\n",
      "Train Epoch: 8 [76800/110534 (69%)]\tClassification Loss: 1.4218\r\n",
      "Train Epoch: 8 [77440/110534 (70%)]\tClassification Loss: 1.4177\r\n",
      "Train Epoch: 8 [78080/110534 (71%)]\tClassification Loss: 1.5352\r\n",
      "Train Epoch: 8 [78720/110534 (71%)]\tClassification Loss: 1.3496\r\n",
      "Train Epoch: 8 [79360/110534 (72%)]\tClassification Loss: 1.4038\r\n",
      "Train Epoch: 8 [80000/110534 (72%)]\tClassification Loss: 1.4125\r\n",
      "Train Epoch: 8 [80640/110534 (73%)]\tClassification Loss: 1.4142\r\n",
      "Train Epoch: 8 [81280/110534 (74%)]\tClassification Loss: 1.8700\r\n",
      "Train Epoch: 8 [81920/110534 (74%)]\tClassification Loss: 1.5333\r\n",
      "Train Epoch: 8 [82560/110534 (75%)]\tClassification Loss: 1.8780\r\n",
      "Train Epoch: 8 [83200/110534 (75%)]\tClassification Loss: 1.5122\r\n",
      "Train Epoch: 8 [83840/110534 (76%)]\tClassification Loss: 1.7661\r\n",
      "Train Epoch: 8 [84480/110534 (76%)]\tClassification Loss: 1.5016\r\n",
      "Train Epoch: 8 [85120/110534 (77%)]\tClassification Loss: 1.3826\r\n",
      "Train Epoch: 8 [85760/110534 (78%)]\tClassification Loss: 1.4280\r\n",
      "Train Epoch: 8 [86400/110534 (78%)]\tClassification Loss: 1.6804\r\n",
      "Train Epoch: 8 [87040/110534 (79%)]\tClassification Loss: 1.5096\r\n",
      "Train Epoch: 8 [87680/110534 (79%)]\tClassification Loss: 1.3659\r\n",
      "Train Epoch: 8 [88320/110534 (80%)]\tClassification Loss: 1.5885\r\n",
      "Train Epoch: 8 [88960/110534 (80%)]\tClassification Loss: 1.4897\r\n",
      "Train Epoch: 8 [89600/110534 (81%)]\tClassification Loss: 1.6888\r\n",
      "Train Epoch: 8 [90240/110534 (82%)]\tClassification Loss: 1.8003\r\n",
      "Train Epoch: 8 [90880/110534 (82%)]\tClassification Loss: 1.7462\r\n",
      "Train Epoch: 8 [91520/110534 (83%)]\tClassification Loss: 1.1715\r\n",
      "Train Epoch: 8 [92160/110534 (83%)]\tClassification Loss: 1.3745\r\n",
      "Train Epoch: 8 [92800/110534 (84%)]\tClassification Loss: 1.4701\r\n",
      "Train Epoch: 8 [93440/110534 (85%)]\tClassification Loss: 1.6515\r\n",
      "Train Epoch: 8 [94080/110534 (85%)]\tClassification Loss: 1.6709\r\n",
      "Train Epoch: 8 [94720/110534 (86%)]\tClassification Loss: 1.4870\r\n",
      "Train Epoch: 8 [95360/110534 (86%)]\tClassification Loss: 1.3612\r\n",
      "Train Epoch: 8 [96000/110534 (87%)]\tClassification Loss: 1.4157\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_1500.pth.tar\r\n",
      "Train Epoch: 8 [96640/110534 (87%)]\tClassification Loss: 1.3248\r\n",
      "Train Epoch: 8 [97280/110534 (88%)]\tClassification Loss: 1.3355\r\n",
      "Train Epoch: 8 [97920/110534 (89%)]\tClassification Loss: 1.2566\r\n",
      "Train Epoch: 8 [98560/110534 (89%)]\tClassification Loss: 1.4512\r\n",
      "Train Epoch: 8 [99200/110534 (90%)]\tClassification Loss: 1.5832\r\n",
      "Train Epoch: 8 [99840/110534 (90%)]\tClassification Loss: 1.5771\r\n",
      "Train Epoch: 8 [100480/110534 (91%)]\tClassification Loss: 1.6624\r\n",
      "Train Epoch: 8 [101120/110534 (91%)]\tClassification Loss: 1.5332\r\n",
      "Train Epoch: 8 [101760/110534 (92%)]\tClassification Loss: 1.5444\r\n",
      "Train Epoch: 8 [102400/110534 (93%)]\tClassification Loss: 1.4247\r\n",
      "Train Epoch: 8 [103040/110534 (93%)]\tClassification Loss: 1.5114\r\n",
      "Train Epoch: 8 [103680/110534 (94%)]\tClassification Loss: 1.6627\r\n",
      "Train Epoch: 8 [104320/110534 (94%)]\tClassification Loss: 1.3667\r\n",
      "Train Epoch: 8 [104960/110534 (95%)]\tClassification Loss: 1.4700\r\n",
      "Train Epoch: 8 [105600/110534 (96%)]\tClassification Loss: 1.5558\r\n",
      "Train Epoch: 8 [106240/110534 (96%)]\tClassification Loss: 1.2339\r\n",
      "Train Epoch: 8 [106880/110534 (97%)]\tClassification Loss: 1.7520\r\n",
      "Train Epoch: 8 [107520/110534 (97%)]\tClassification Loss: 1.7223\r\n",
      "Train Epoch: 8 [108160/110534 (98%)]\tClassification Loss: 1.5020\r\n",
      "Train Epoch: 8 [108800/110534 (98%)]\tClassification Loss: 1.7151\r\n",
      "Train Epoch: 8 [109440/110534 (99%)]\tClassification Loss: 1.3734\r\n",
      "Train Epoch: 8 [110080/110534 (100%)]\tClassification Loss: 1.4230\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_final.pth.tar\r\n",
      "Train Epoch: 9 [0/110534 (0%)]\tClassification Loss: 1.6065\r\n",
      "\r\n",
      "Test set: Average loss: 1.4244, Accuracy: 23225/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 9 [640/110534 (1%)]\tClassification Loss: 1.2743\r\n",
      "Train Epoch: 9 [1280/110534 (1%)]\tClassification Loss: 2.0521\r\n",
      "Train Epoch: 9 [1920/110534 (2%)]\tClassification Loss: 1.5424\r\n",
      "Train Epoch: 9 [2560/110534 (2%)]\tClassification Loss: 1.7168\r\n",
      "Train Epoch: 9 [3200/110534 (3%)]\tClassification Loss: 1.4778\r\n",
      "Train Epoch: 9 [3840/110534 (3%)]\tClassification Loss: 1.3217\r\n",
      "Train Epoch: 9 [4480/110534 (4%)]\tClassification Loss: 1.5421\r\n",
      "Train Epoch: 9 [5120/110534 (5%)]\tClassification Loss: 1.5146\r\n",
      "Train Epoch: 9 [5760/110534 (5%)]\tClassification Loss: 1.5188\r\n",
      "Train Epoch: 9 [6400/110534 (6%)]\tClassification Loss: 1.3413\r\n",
      "Train Epoch: 9 [7040/110534 (6%)]\tClassification Loss: 1.5065\r\n",
      "Train Epoch: 9 [7680/110534 (7%)]\tClassification Loss: 1.6659\r\n",
      "Train Epoch: 9 [8320/110534 (8%)]\tClassification Loss: 1.8136\r\n",
      "Train Epoch: 9 [8960/110534 (8%)]\tClassification Loss: 1.8475\r\n",
      "Train Epoch: 9 [9600/110534 (9%)]\tClassification Loss: 1.4290\r\n",
      "Train Epoch: 9 [10240/110534 (9%)]\tClassification Loss: 1.5455\r\n",
      "Train Epoch: 9 [10880/110534 (10%)]\tClassification Loss: 1.4629\r\n",
      "Train Epoch: 9 [11520/110534 (10%)]\tClassification Loss: 1.7535\r\n",
      "Train Epoch: 9 [12160/110534 (11%)]\tClassification Loss: 1.4338\r\n",
      "Train Epoch: 9 [12800/110534 (12%)]\tClassification Loss: 1.7494\r\n",
      "Train Epoch: 9 [13440/110534 (12%)]\tClassification Loss: 1.4395\r\n",
      "Train Epoch: 9 [14080/110534 (13%)]\tClassification Loss: 1.6800\r\n",
      "Train Epoch: 9 [14720/110534 (13%)]\tClassification Loss: 1.6889\r\n",
      "Train Epoch: 9 [15360/110534 (14%)]\tClassification Loss: 1.5258\r\n",
      "Train Epoch: 9 [16000/110534 (14%)]\tClassification Loss: 1.7348\r\n",
      "Train Epoch: 9 [16640/110534 (15%)]\tClassification Loss: 1.4692\r\n",
      "Train Epoch: 9 [17280/110534 (16%)]\tClassification Loss: 1.6750\r\n",
      "Train Epoch: 9 [17920/110534 (16%)]\tClassification Loss: 1.7515\r\n",
      "Train Epoch: 9 [18560/110534 (17%)]\tClassification Loss: 1.6313\r\n",
      "Train Epoch: 9 [19200/110534 (17%)]\tClassification Loss: 1.7075\r\n",
      "Train Epoch: 9 [19840/110534 (18%)]\tClassification Loss: 1.5136\r\n",
      "Train Epoch: 9 [20480/110534 (19%)]\tClassification Loss: 1.8075\r\n",
      "Train Epoch: 9 [21120/110534 (19%)]\tClassification Loss: 1.7562\r\n",
      "Train Epoch: 9 [21760/110534 (20%)]\tClassification Loss: 1.4494\r\n",
      "Train Epoch: 9 [22400/110534 (20%)]\tClassification Loss: 1.4964\r\n",
      "Train Epoch: 9 [23040/110534 (21%)]\tClassification Loss: 1.1316\r\n",
      "Train Epoch: 9 [23680/110534 (21%)]\tClassification Loss: 1.7087\r\n",
      "Train Epoch: 9 [24320/110534 (22%)]\tClassification Loss: 1.1067\r\n",
      "Train Epoch: 9 [24960/110534 (23%)]\tClassification Loss: 1.6991\r\n",
      "Train Epoch: 9 [25600/110534 (23%)]\tClassification Loss: 1.3119\r\n",
      "Train Epoch: 9 [26240/110534 (24%)]\tClassification Loss: 1.4969\r\n",
      "Train Epoch: 9 [26880/110534 (24%)]\tClassification Loss: 1.7426\r\n",
      "Train Epoch: 9 [27520/110534 (25%)]\tClassification Loss: 1.3866\r\n",
      "Train Epoch: 9 [28160/110534 (25%)]\tClassification Loss: 1.8192\r\n",
      "Train Epoch: 9 [28800/110534 (26%)]\tClassification Loss: 1.8511\r\n",
      "Train Epoch: 9 [29440/110534 (27%)]\tClassification Loss: 1.5707\r\n",
      "Train Epoch: 9 [30080/110534 (27%)]\tClassification Loss: 1.8826\r\n",
      "Train Epoch: 9 [30720/110534 (28%)]\tClassification Loss: 1.4693\r\n",
      "Train Epoch: 9 [31360/110534 (28%)]\tClassification Loss: 1.6612\r\n",
      "Train Epoch: 9 [32000/110534 (29%)]\tClassification Loss: 1.4956\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_500.pth.tar\r\n",
      "Train Epoch: 9 [32640/110534 (30%)]\tClassification Loss: 1.2890\r\n",
      "Train Epoch: 9 [33280/110534 (30%)]\tClassification Loss: 1.5108\r\n",
      "Train Epoch: 9 [33920/110534 (31%)]\tClassification Loss: 1.5326\r\n",
      "Train Epoch: 9 [34560/110534 (31%)]\tClassification Loss: 1.8336\r\n",
      "Train Epoch: 9 [35200/110534 (32%)]\tClassification Loss: 1.4101\r\n",
      "Train Epoch: 9 [35840/110534 (32%)]\tClassification Loss: 1.2623\r\n",
      "Train Epoch: 9 [36480/110534 (33%)]\tClassification Loss: 1.4435\r\n",
      "Train Epoch: 9 [37120/110534 (34%)]\tClassification Loss: 1.5367\r\n",
      "Train Epoch: 9 [37760/110534 (34%)]\tClassification Loss: 1.7527\r\n",
      "Train Epoch: 9 [38400/110534 (35%)]\tClassification Loss: 1.5826\r\n",
      "Train Epoch: 9 [39040/110534 (35%)]\tClassification Loss: 1.4790\r\n",
      "Train Epoch: 9 [39680/110534 (36%)]\tClassification Loss: 1.6990\r\n",
      "Train Epoch: 9 [40320/110534 (36%)]\tClassification Loss: 1.6813\r\n",
      "Train Epoch: 9 [40960/110534 (37%)]\tClassification Loss: 1.2634\r\n",
      "Train Epoch: 9 [41600/110534 (38%)]\tClassification Loss: 1.5645\r\n",
      "Train Epoch: 9 [42240/110534 (38%)]\tClassification Loss: 1.4242\r\n",
      "Train Epoch: 9 [42880/110534 (39%)]\tClassification Loss: 1.4873\r\n",
      "Train Epoch: 9 [43520/110534 (39%)]\tClassification Loss: 1.2945\r\n",
      "Train Epoch: 9 [44160/110534 (40%)]\tClassification Loss: 1.3979\r\n",
      "Train Epoch: 9 [44800/110534 (41%)]\tClassification Loss: 1.4886\r\n",
      "Train Epoch: 9 [45440/110534 (41%)]\tClassification Loss: 1.6182\r\n",
      "Train Epoch: 9 [46080/110534 (42%)]\tClassification Loss: 1.2807\r\n",
      "Train Epoch: 9 [46720/110534 (42%)]\tClassification Loss: 1.5961\r\n",
      "Train Epoch: 9 [47360/110534 (43%)]\tClassification Loss: 1.5191\r\n",
      "Train Epoch: 9 [48000/110534 (43%)]\tClassification Loss: 1.6298\r\n",
      "Train Epoch: 9 [48640/110534 (44%)]\tClassification Loss: 1.4189\r\n",
      "Train Epoch: 9 [49280/110534 (45%)]\tClassification Loss: 1.6011\r\n",
      "Train Epoch: 9 [49920/110534 (45%)]\tClassification Loss: 1.7428\r\n",
      "Train Epoch: 9 [50560/110534 (46%)]\tClassification Loss: 1.5527\r\n",
      "Train Epoch: 9 [51200/110534 (46%)]\tClassification Loss: 1.5031\r\n",
      "Train Epoch: 9 [51840/110534 (47%)]\tClassification Loss: 1.4460\r\n",
      "Train Epoch: 9 [52480/110534 (47%)]\tClassification Loss: 1.4929\r\n",
      "Train Epoch: 9 [53120/110534 (48%)]\tClassification Loss: 1.1890\r\n",
      "Train Epoch: 9 [53760/110534 (49%)]\tClassification Loss: 1.5920\r\n",
      "Train Epoch: 9 [54400/110534 (49%)]\tClassification Loss: 1.5936\r\n",
      "Train Epoch: 9 [55040/110534 (50%)]\tClassification Loss: 1.7364\r\n",
      "Train Epoch: 9 [55680/110534 (50%)]\tClassification Loss: 1.6182\r\n",
      "Train Epoch: 9 [56320/110534 (51%)]\tClassification Loss: 1.6263\r\n",
      "Train Epoch: 9 [56960/110534 (52%)]\tClassification Loss: 1.4704\r\n",
      "Train Epoch: 9 [57600/110534 (52%)]\tClassification Loss: 1.7185\r\n",
      "Train Epoch: 9 [58240/110534 (53%)]\tClassification Loss: 1.5553\r\n",
      "Train Epoch: 9 [58880/110534 (53%)]\tClassification Loss: 1.7723\r\n",
      "Train Epoch: 9 [59520/110534 (54%)]\tClassification Loss: 1.4402\r\n",
      "Train Epoch: 9 [60160/110534 (54%)]\tClassification Loss: 1.5807\r\n",
      "Train Epoch: 9 [60800/110534 (55%)]\tClassification Loss: 1.5797\r\n",
      "Train Epoch: 9 [61440/110534 (56%)]\tClassification Loss: 1.5583\r\n",
      "Train Epoch: 9 [62080/110534 (56%)]\tClassification Loss: 1.5005\r\n",
      "Train Epoch: 9 [62720/110534 (57%)]\tClassification Loss: 1.7893\r\n",
      "Train Epoch: 9 [63360/110534 (57%)]\tClassification Loss: 1.2388\r\n",
      "Train Epoch: 9 [64000/110534 (58%)]\tClassification Loss: 1.6121\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_1000.pth.tar\r\n",
      "Train Epoch: 9 [64640/110534 (58%)]\tClassification Loss: 1.0682\r\n",
      "Train Epoch: 9 [65280/110534 (59%)]\tClassification Loss: 1.4663\r\n",
      "Train Epoch: 9 [65920/110534 (60%)]\tClassification Loss: 1.4527\r\n",
      "Train Epoch: 9 [66560/110534 (60%)]\tClassification Loss: 1.2795\r\n",
      "Train Epoch: 9 [67200/110534 (61%)]\tClassification Loss: 1.3485\r\n",
      "Train Epoch: 9 [67840/110534 (61%)]\tClassification Loss: 1.8357\r\n",
      "Train Epoch: 9 [68480/110534 (62%)]\tClassification Loss: 1.6202\r\n",
      "Train Epoch: 9 [69120/110534 (63%)]\tClassification Loss: 1.6523\r\n",
      "Train Epoch: 9 [69760/110534 (63%)]\tClassification Loss: 1.6384\r\n",
      "Train Epoch: 9 [70400/110534 (64%)]\tClassification Loss: 1.1380\r\n",
      "Train Epoch: 9 [71040/110534 (64%)]\tClassification Loss: 1.8303\r\n",
      "Train Epoch: 9 [71680/110534 (65%)]\tClassification Loss: 1.4771\r\n",
      "Train Epoch: 9 [72320/110534 (65%)]\tClassification Loss: 1.6388\r\n",
      "Train Epoch: 9 [72960/110534 (66%)]\tClassification Loss: 1.6221\r\n",
      "Train Epoch: 9 [73600/110534 (67%)]\tClassification Loss: 1.7911\r\n",
      "Train Epoch: 9 [74240/110534 (67%)]\tClassification Loss: 1.5844\r\n",
      "Train Epoch: 9 [74880/110534 (68%)]\tClassification Loss: 1.2161\r\n",
      "Train Epoch: 9 [75520/110534 (68%)]\tClassification Loss: 1.5712\r\n",
      "Train Epoch: 9 [76160/110534 (69%)]\tClassification Loss: 1.3167\r\n",
      "Train Epoch: 9 [76800/110534 (69%)]\tClassification Loss: 1.2786\r\n",
      "Train Epoch: 9 [77440/110534 (70%)]\tClassification Loss: 1.4871\r\n",
      "Train Epoch: 9 [78080/110534 (71%)]\tClassification Loss: 1.3520\r\n",
      "Train Epoch: 9 [78720/110534 (71%)]\tClassification Loss: 1.3487\r\n",
      "Train Epoch: 9 [79360/110534 (72%)]\tClassification Loss: 1.4122\r\n",
      "Train Epoch: 9 [80000/110534 (72%)]\tClassification Loss: 1.4845\r\n",
      "Train Epoch: 9 [80640/110534 (73%)]\tClassification Loss: 1.3902\r\n",
      "Train Epoch: 9 [81280/110534 (74%)]\tClassification Loss: 1.8435\r\n",
      "Train Epoch: 9 [81920/110534 (74%)]\tClassification Loss: 1.4744\r\n",
      "Train Epoch: 9 [82560/110534 (75%)]\tClassification Loss: 1.8104\r\n",
      "Train Epoch: 9 [83200/110534 (75%)]\tClassification Loss: 1.4075\r\n",
      "Train Epoch: 9 [83840/110534 (76%)]\tClassification Loss: 1.8918\r\n",
      "Train Epoch: 9 [84480/110534 (76%)]\tClassification Loss: 1.6759\r\n",
      "Train Epoch: 9 [85120/110534 (77%)]\tClassification Loss: 1.3430\r\n",
      "Train Epoch: 9 [85760/110534 (78%)]\tClassification Loss: 1.6784\r\n",
      "Train Epoch: 9 [86400/110534 (78%)]\tClassification Loss: 1.6209\r\n",
      "Train Epoch: 9 [87040/110534 (79%)]\tClassification Loss: 1.4734\r\n",
      "Train Epoch: 9 [87680/110534 (79%)]\tClassification Loss: 1.3652\r\n",
      "Train Epoch: 9 [88320/110534 (80%)]\tClassification Loss: 1.5982\r\n",
      "Train Epoch: 9 [88960/110534 (80%)]\tClassification Loss: 1.6454\r\n",
      "Train Epoch: 9 [89600/110534 (81%)]\tClassification Loss: 1.7950\r\n",
      "Train Epoch: 9 [90240/110534 (82%)]\tClassification Loss: 1.9066\r\n",
      "Train Epoch: 9 [90880/110534 (82%)]\tClassification Loss: 1.5685\r\n",
      "Train Epoch: 9 [91520/110534 (83%)]\tClassification Loss: 1.2874\r\n",
      "Train Epoch: 9 [92160/110534 (83%)]\tClassification Loss: 1.3995\r\n",
      "Train Epoch: 9 [92800/110534 (84%)]\tClassification Loss: 1.4631\r\n",
      "Train Epoch: 9 [93440/110534 (85%)]\tClassification Loss: 1.6814\r\n",
      "Train Epoch: 9 [94080/110534 (85%)]\tClassification Loss: 1.4251\r\n",
      "Train Epoch: 9 [94720/110534 (86%)]\tClassification Loss: 1.3713\r\n",
      "Train Epoch: 9 [95360/110534 (86%)]\tClassification Loss: 1.3544\r\n",
      "Train Epoch: 9 [96000/110534 (87%)]\tClassification Loss: 1.3402\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_1500.pth.tar\r\n",
      "Train Epoch: 9 [96640/110534 (87%)]\tClassification Loss: 1.4281\r\n",
      "Train Epoch: 9 [97280/110534 (88%)]\tClassification Loss: 1.2246\r\n",
      "Train Epoch: 9 [97920/110534 (89%)]\tClassification Loss: 1.1602\r\n",
      "Train Epoch: 9 [98560/110534 (89%)]\tClassification Loss: 1.5374\r\n",
      "Train Epoch: 9 [99200/110534 (90%)]\tClassification Loss: 1.6025\r\n",
      "Train Epoch: 9 [99840/110534 (90%)]\tClassification Loss: 1.5543\r\n",
      "Train Epoch: 9 [100480/110534 (91%)]\tClassification Loss: 1.6570\r\n",
      "Train Epoch: 9 [101120/110534 (91%)]\tClassification Loss: 1.4446\r\n",
      "Train Epoch: 9 [101760/110534 (92%)]\tClassification Loss: 1.5817\r\n",
      "Train Epoch: 9 [102400/110534 (93%)]\tClassification Loss: 1.3148\r\n",
      "Train Epoch: 9 [103040/110534 (93%)]\tClassification Loss: 1.3834\r\n",
      "Train Epoch: 9 [103680/110534 (94%)]\tClassification Loss: 1.7466\r\n",
      "Train Epoch: 9 [104320/110534 (94%)]\tClassification Loss: 1.3955\r\n",
      "Train Epoch: 9 [104960/110534 (95%)]\tClassification Loss: 1.4372\r\n",
      "Train Epoch: 9 [105600/110534 (96%)]\tClassification Loss: 1.4732\r\n",
      "Train Epoch: 9 [106240/110534 (96%)]\tClassification Loss: 1.2440\r\n",
      "Train Epoch: 9 [106880/110534 (97%)]\tClassification Loss: 1.7100\r\n",
      "Train Epoch: 9 [107520/110534 (97%)]\tClassification Loss: 1.4416\r\n",
      "Train Epoch: 9 [108160/110534 (98%)]\tClassification Loss: 1.6324\r\n",
      "Train Epoch: 9 [108800/110534 (98%)]\tClassification Loss: 1.6718\r\n",
      "Train Epoch: 9 [109440/110534 (99%)]\tClassification Loss: 1.3911\r\n",
      "Train Epoch: 9 [110080/110534 (100%)]\tClassification Loss: 1.4637\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_final.pth.tar\r\n",
      "Train Epoch: 10 [0/110534 (0%)]\tClassification Loss: 1.5631\r\n",
      "\r\n",
      "Test set: Average loss: 1.4198, Accuracy: 23207/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 10 [640/110534 (1%)]\tClassification Loss: 1.4471\r\n",
      "Train Epoch: 10 [1280/110534 (1%)]\tClassification Loss: 1.8677\r\n",
      "Train Epoch: 10 [1920/110534 (2%)]\tClassification Loss: 1.6444\r\n",
      "Train Epoch: 10 [2560/110534 (2%)]\tClassification Loss: 1.7606\r\n",
      "Train Epoch: 10 [3200/110534 (3%)]\tClassification Loss: 1.7067\r\n",
      "Train Epoch: 10 [3840/110534 (3%)]\tClassification Loss: 1.3999\r\n",
      "Train Epoch: 10 [4480/110534 (4%)]\tClassification Loss: 1.5163\r\n",
      "Train Epoch: 10 [5120/110534 (5%)]\tClassification Loss: 1.7455\r\n",
      "Train Epoch: 10 [5760/110534 (5%)]\tClassification Loss: 1.6171\r\n",
      "Train Epoch: 10 [6400/110534 (6%)]\tClassification Loss: 1.0950\r\n",
      "Train Epoch: 10 [7040/110534 (6%)]\tClassification Loss: 1.4616\r\n",
      "Train Epoch: 10 [7680/110534 (7%)]\tClassification Loss: 1.5909\r\n",
      "Train Epoch: 10 [8320/110534 (8%)]\tClassification Loss: 1.7520\r\n",
      "Train Epoch: 10 [8960/110534 (8%)]\tClassification Loss: 1.7709\r\n",
      "Train Epoch: 10 [9600/110534 (9%)]\tClassification Loss: 1.4417\r\n",
      "Train Epoch: 10 [10240/110534 (9%)]\tClassification Loss: 1.5348\r\n",
      "Train Epoch: 10 [10880/110534 (10%)]\tClassification Loss: 1.3715\r\n",
      "Train Epoch: 10 [11520/110534 (10%)]\tClassification Loss: 1.6700\r\n",
      "Train Epoch: 10 [12160/110534 (11%)]\tClassification Loss: 1.4524\r\n",
      "Train Epoch: 10 [12800/110534 (12%)]\tClassification Loss: 1.6045\r\n",
      "Train Epoch: 10 [13440/110534 (12%)]\tClassification Loss: 1.3188\r\n",
      "Train Epoch: 10 [14080/110534 (13%)]\tClassification Loss: 1.4832\r\n",
      "Train Epoch: 10 [14720/110534 (13%)]\tClassification Loss: 1.6873\r\n",
      "Train Epoch: 10 [15360/110534 (14%)]\tClassification Loss: 1.5242\r\n",
      "Train Epoch: 10 [16000/110534 (14%)]\tClassification Loss: 1.8053\r\n",
      "Train Epoch: 10 [16640/110534 (15%)]\tClassification Loss: 1.5527\r\n",
      "Train Epoch: 10 [17280/110534 (16%)]\tClassification Loss: 1.4380\r\n",
      "Train Epoch: 10 [17920/110534 (16%)]\tClassification Loss: 1.6091\r\n",
      "Train Epoch: 10 [18560/110534 (17%)]\tClassification Loss: 1.7910\r\n",
      "Train Epoch: 10 [19200/110534 (17%)]\tClassification Loss: 1.4888\r\n",
      "Train Epoch: 10 [19840/110534 (18%)]\tClassification Loss: 1.4825\r\n",
      "Train Epoch: 10 [20480/110534 (19%)]\tClassification Loss: 1.6197\r\n",
      "Train Epoch: 10 [21120/110534 (19%)]\tClassification Loss: 1.6576\r\n",
      "Train Epoch: 10 [21760/110534 (20%)]\tClassification Loss: 1.4078\r\n",
      "Train Epoch: 10 [22400/110534 (20%)]\tClassification Loss: 1.6399\r\n",
      "Train Epoch: 10 [23040/110534 (21%)]\tClassification Loss: 1.0742\r\n",
      "Train Epoch: 10 [23680/110534 (21%)]\tClassification Loss: 1.5129\r\n",
      "Train Epoch: 10 [24320/110534 (22%)]\tClassification Loss: 1.2492\r\n",
      "Train Epoch: 10 [24960/110534 (23%)]\tClassification Loss: 1.7786\r\n",
      "Train Epoch: 10 [25600/110534 (23%)]\tClassification Loss: 1.2680\r\n",
      "Train Epoch: 10 [26240/110534 (24%)]\tClassification Loss: 1.4182\r\n",
      "Train Epoch: 10 [26880/110534 (24%)]\tClassification Loss: 1.8365\r\n",
      "Train Epoch: 10 [27520/110534 (25%)]\tClassification Loss: 1.4744\r\n",
      "Train Epoch: 10 [28160/110534 (25%)]\tClassification Loss: 1.7487\r\n",
      "Train Epoch: 10 [28800/110534 (26%)]\tClassification Loss: 1.9155\r\n",
      "Train Epoch: 10 [29440/110534 (27%)]\tClassification Loss: 1.6159\r\n",
      "Train Epoch: 10 [30080/110534 (27%)]\tClassification Loss: 1.6919\r\n",
      "Train Epoch: 10 [30720/110534 (28%)]\tClassification Loss: 1.3392\r\n",
      "Train Epoch: 10 [31360/110534 (28%)]\tClassification Loss: 1.5958\r\n",
      "Train Epoch: 10 [32000/110534 (29%)]\tClassification Loss: 1.4692\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_500.pth.tar\r\n",
      "Train Epoch: 10 [32640/110534 (30%)]\tClassification Loss: 1.3451\r\n",
      "Train Epoch: 10 [33280/110534 (30%)]\tClassification Loss: 1.5026\r\n",
      "Train Epoch: 10 [33920/110534 (31%)]\tClassification Loss: 1.6794\r\n",
      "Train Epoch: 10 [34560/110534 (31%)]\tClassification Loss: 1.6013\r\n",
      "Train Epoch: 10 [35200/110534 (32%)]\tClassification Loss: 1.5646\r\n",
      "Train Epoch: 10 [35840/110534 (32%)]\tClassification Loss: 1.1466\r\n",
      "Train Epoch: 10 [36480/110534 (33%)]\tClassification Loss: 1.3738\r\n",
      "Train Epoch: 10 [37120/110534 (34%)]\tClassification Loss: 1.4526\r\n",
      "Train Epoch: 10 [37760/110534 (34%)]\tClassification Loss: 1.8711\r\n",
      "Train Epoch: 10 [38400/110534 (35%)]\tClassification Loss: 1.3506\r\n",
      "Train Epoch: 10 [39040/110534 (35%)]\tClassification Loss: 1.5262\r\n",
      "Train Epoch: 10 [39680/110534 (36%)]\tClassification Loss: 1.6718\r\n",
      "Train Epoch: 10 [40320/110534 (36%)]\tClassification Loss: 1.5729\r\n",
      "Train Epoch: 10 [40960/110534 (37%)]\tClassification Loss: 1.4577\r\n",
      "Train Epoch: 10 [41600/110534 (38%)]\tClassification Loss: 1.5521\r\n",
      "Train Epoch: 10 [42240/110534 (38%)]\tClassification Loss: 1.4509\r\n",
      "Train Epoch: 10 [42880/110534 (39%)]\tClassification Loss: 1.4278\r\n",
      "Train Epoch: 10 [43520/110534 (39%)]\tClassification Loss: 1.4298\r\n",
      "Train Epoch: 10 [44160/110534 (40%)]\tClassification Loss: 1.5252\r\n",
      "Train Epoch: 10 [44800/110534 (41%)]\tClassification Loss: 1.6072\r\n",
      "Train Epoch: 10 [45440/110534 (41%)]\tClassification Loss: 1.6512\r\n",
      "Train Epoch: 10 [46080/110534 (42%)]\tClassification Loss: 1.3623\r\n",
      "Train Epoch: 10 [46720/110534 (42%)]\tClassification Loss: 1.4888\r\n",
      "Train Epoch: 10 [47360/110534 (43%)]\tClassification Loss: 1.5590\r\n",
      "Train Epoch: 10 [48000/110534 (43%)]\tClassification Loss: 1.7000\r\n",
      "Train Epoch: 10 [48640/110534 (44%)]\tClassification Loss: 1.3358\r\n",
      "Train Epoch: 10 [49280/110534 (45%)]\tClassification Loss: 1.5392\r\n",
      "Train Epoch: 10 [49920/110534 (45%)]\tClassification Loss: 1.5762\r\n",
      "Train Epoch: 10 [50560/110534 (46%)]\tClassification Loss: 1.4916\r\n",
      "Train Epoch: 10 [51200/110534 (46%)]\tClassification Loss: 1.4758\r\n",
      "Train Epoch: 10 [51840/110534 (47%)]\tClassification Loss: 1.5801\r\n",
      "Train Epoch: 10 [52480/110534 (47%)]\tClassification Loss: 1.4728\r\n",
      "Train Epoch: 10 [53120/110534 (48%)]\tClassification Loss: 1.1158\r\n",
      "Train Epoch: 10 [53760/110534 (49%)]\tClassification Loss: 1.3417\r\n",
      "Train Epoch: 10 [54400/110534 (49%)]\tClassification Loss: 1.5178\r\n",
      "Train Epoch: 10 [55040/110534 (50%)]\tClassification Loss: 1.6891\r\n",
      "Train Epoch: 10 [55680/110534 (50%)]\tClassification Loss: 1.5820\r\n",
      "Train Epoch: 10 [56320/110534 (51%)]\tClassification Loss: 1.4866\r\n",
      "Train Epoch: 10 [56960/110534 (52%)]\tClassification Loss: 1.6019\r\n",
      "Train Epoch: 10 [57600/110534 (52%)]\tClassification Loss: 1.6529\r\n",
      "Train Epoch: 10 [58240/110534 (53%)]\tClassification Loss: 1.5793\r\n",
      "Train Epoch: 10 [58880/110534 (53%)]\tClassification Loss: 1.7479\r\n",
      "Train Epoch: 10 [59520/110534 (54%)]\tClassification Loss: 1.2689\r\n",
      "Train Epoch: 10 [60160/110534 (54%)]\tClassification Loss: 1.3937\r\n",
      "Train Epoch: 10 [60800/110534 (55%)]\tClassification Loss: 1.7538\r\n",
      "Train Epoch: 10 [61440/110534 (56%)]\tClassification Loss: 1.4991\r\n",
      "Train Epoch: 10 [62080/110534 (56%)]\tClassification Loss: 1.4158\r\n",
      "Train Epoch: 10 [62720/110534 (57%)]\tClassification Loss: 1.7379\r\n",
      "Train Epoch: 10 [63360/110534 (57%)]\tClassification Loss: 1.1356\r\n",
      "Train Epoch: 10 [64000/110534 (58%)]\tClassification Loss: 1.5844\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_1000.pth.tar\r\n",
      "Train Epoch: 10 [64640/110534 (58%)]\tClassification Loss: 1.1809\r\n",
      "Train Epoch: 10 [65280/110534 (59%)]\tClassification Loss: 1.6333\r\n",
      "Train Epoch: 10 [65920/110534 (60%)]\tClassification Loss: 1.5009\r\n",
      "Train Epoch: 10 [66560/110534 (60%)]\tClassification Loss: 1.4119\r\n",
      "Train Epoch: 10 [67200/110534 (61%)]\tClassification Loss: 1.4410\r\n",
      "Train Epoch: 10 [67840/110534 (61%)]\tClassification Loss: 1.8978\r\n",
      "Train Epoch: 10 [68480/110534 (62%)]\tClassification Loss: 1.4657\r\n",
      "Train Epoch: 10 [69120/110534 (63%)]\tClassification Loss: 1.6910\r\n",
      "Train Epoch: 10 [69760/110534 (63%)]\tClassification Loss: 1.6503\r\n",
      "Train Epoch: 10 [70400/110534 (64%)]\tClassification Loss: 1.2928\r\n",
      "Train Epoch: 10 [71040/110534 (64%)]\tClassification Loss: 1.7801\r\n",
      "Train Epoch: 10 [71680/110534 (65%)]\tClassification Loss: 1.5303\r\n",
      "Train Epoch: 10 [72320/110534 (65%)]\tClassification Loss: 1.5347\r\n",
      "Train Epoch: 10 [72960/110534 (66%)]\tClassification Loss: 1.6676\r\n",
      "Train Epoch: 10 [73600/110534 (67%)]\tClassification Loss: 1.8558\r\n",
      "Train Epoch: 10 [74240/110534 (67%)]\tClassification Loss: 1.7429\r\n",
      "Train Epoch: 10 [74880/110534 (68%)]\tClassification Loss: 1.3449\r\n",
      "Train Epoch: 10 [75520/110534 (68%)]\tClassification Loss: 1.4920\r\n",
      "Train Epoch: 10 [76160/110534 (69%)]\tClassification Loss: 1.4190\r\n",
      "Train Epoch: 10 [76800/110534 (69%)]\tClassification Loss: 1.3735\r\n",
      "Train Epoch: 10 [77440/110534 (70%)]\tClassification Loss: 1.5075\r\n",
      "Train Epoch: 10 [78080/110534 (71%)]\tClassification Loss: 1.4020\r\n",
      "Train Epoch: 10 [78720/110534 (71%)]\tClassification Loss: 1.3394\r\n",
      "Train Epoch: 10 [79360/110534 (72%)]\tClassification Loss: 1.2740\r\n",
      "Train Epoch: 10 [80000/110534 (72%)]\tClassification Loss: 1.4341\r\n",
      "Train Epoch: 10 [80640/110534 (73%)]\tClassification Loss: 1.3746\r\n",
      "Train Epoch: 10 [81280/110534 (74%)]\tClassification Loss: 1.8207\r\n",
      "Train Epoch: 10 [81920/110534 (74%)]\tClassification Loss: 1.5167\r\n",
      "Train Epoch: 10 [82560/110534 (75%)]\tClassification Loss: 1.7650\r\n",
      "Train Epoch: 10 [83200/110534 (75%)]\tClassification Loss: 1.5284\r\n",
      "Train Epoch: 10 [83840/110534 (76%)]\tClassification Loss: 1.9477\r\n",
      "Train Epoch: 10 [84480/110534 (76%)]\tClassification Loss: 1.6657\r\n",
      "Train Epoch: 10 [85120/110534 (77%)]\tClassification Loss: 1.3833\r\n",
      "Train Epoch: 10 [85760/110534 (78%)]\tClassification Loss: 1.5285\r\n",
      "Train Epoch: 10 [86400/110534 (78%)]\tClassification Loss: 1.5799\r\n",
      "Train Epoch: 10 [87040/110534 (79%)]\tClassification Loss: 1.4791\r\n",
      "Train Epoch: 10 [87680/110534 (79%)]\tClassification Loss: 1.4394\r\n",
      "Train Epoch: 10 [88320/110534 (80%)]\tClassification Loss: 1.6000\r\n",
      "Train Epoch: 10 [88960/110534 (80%)]\tClassification Loss: 1.6307\r\n",
      "Train Epoch: 10 [89600/110534 (81%)]\tClassification Loss: 1.7364\r\n",
      "Train Epoch: 10 [90240/110534 (82%)]\tClassification Loss: 1.7441\r\n",
      "Train Epoch: 10 [90880/110534 (82%)]\tClassification Loss: 1.6572\r\n",
      "Train Epoch: 10 [91520/110534 (83%)]\tClassification Loss: 1.2386\r\n",
      "Train Epoch: 10 [92160/110534 (83%)]\tClassification Loss: 1.3542\r\n",
      "Train Epoch: 10 [92800/110534 (84%)]\tClassification Loss: 1.4937\r\n",
      "Train Epoch: 10 [93440/110534 (85%)]\tClassification Loss: 1.6960\r\n",
      "Train Epoch: 10 [94080/110534 (85%)]\tClassification Loss: 1.6755\r\n",
      "Train Epoch: 10 [94720/110534 (86%)]\tClassification Loss: 1.4013\r\n",
      "Train Epoch: 10 [95360/110534 (86%)]\tClassification Loss: 1.6103\r\n",
      "Train Epoch: 10 [96000/110534 (87%)]\tClassification Loss: 1.5072\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_1500.pth.tar\r\n",
      "Train Epoch: 10 [96640/110534 (87%)]\tClassification Loss: 1.3830\r\n",
      "Train Epoch: 10 [97280/110534 (88%)]\tClassification Loss: 1.3133\r\n",
      "Train Epoch: 10 [97920/110534 (89%)]\tClassification Loss: 1.1668\r\n",
      "Train Epoch: 10 [98560/110534 (89%)]\tClassification Loss: 1.5033\r\n",
      "Train Epoch: 10 [99200/110534 (90%)]\tClassification Loss: 1.7221\r\n",
      "Train Epoch: 10 [99840/110534 (90%)]\tClassification Loss: 1.4978\r\n",
      "Train Epoch: 10 [100480/110534 (91%)]\tClassification Loss: 1.6545\r\n",
      "Train Epoch: 10 [101120/110534 (91%)]\tClassification Loss: 1.5388\r\n",
      "Train Epoch: 10 [101760/110534 (92%)]\tClassification Loss: 1.4965\r\n",
      "Train Epoch: 10 [102400/110534 (93%)]\tClassification Loss: 1.5158\r\n",
      "Train Epoch: 10 [103040/110534 (93%)]\tClassification Loss: 1.4995\r\n",
      "Train Epoch: 10 [103680/110534 (94%)]\tClassification Loss: 1.6944\r\n",
      "Train Epoch: 10 [104320/110534 (94%)]\tClassification Loss: 1.2434\r\n",
      "Train Epoch: 10 [104960/110534 (95%)]\tClassification Loss: 1.3884\r\n",
      "Train Epoch: 10 [105600/110534 (96%)]\tClassification Loss: 1.4976\r\n",
      "Train Epoch: 10 [106240/110534 (96%)]\tClassification Loss: 1.4046\r\n",
      "Train Epoch: 10 [106880/110534 (97%)]\tClassification Loss: 1.7305\r\n",
      "Train Epoch: 10 [107520/110534 (97%)]\tClassification Loss: 1.7363\r\n",
      "Train Epoch: 10 [108160/110534 (98%)]\tClassification Loss: 1.4756\r\n",
      "Train Epoch: 10 [108800/110534 (98%)]\tClassification Loss: 1.6258\r\n",
      "Train Epoch: 10 [109440/110534 (99%)]\tClassification Loss: 1.4770\r\n",
      "Train Epoch: 10 [110080/110534 (100%)]\tClassification Loss: 1.4643\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_final.pth.tar\r\n",
      "Train Epoch: 11 [0/110534 (0%)]\tClassification Loss: 1.5511\r\n",
      "\r\n",
      "Test set: Average loss: 1.4156, Accuracy: 23262/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 11 [640/110534 (1%)]\tClassification Loss: 1.3239\r\n",
      "Train Epoch: 11 [1280/110534 (1%)]\tClassification Loss: 2.0091\r\n",
      "Train Epoch: 11 [1920/110534 (2%)]\tClassification Loss: 1.6261\r\n",
      "Train Epoch: 11 [2560/110534 (2%)]\tClassification Loss: 1.7683\r\n",
      "Train Epoch: 11 [3200/110534 (3%)]\tClassification Loss: 1.5032\r\n",
      "Train Epoch: 11 [3840/110534 (3%)]\tClassification Loss: 1.4544\r\n",
      "Train Epoch: 11 [4480/110534 (4%)]\tClassification Loss: 1.4460\r\n",
      "Train Epoch: 11 [5120/110534 (5%)]\tClassification Loss: 1.6576\r\n",
      "Train Epoch: 11 [5760/110534 (5%)]\tClassification Loss: 1.4692\r\n",
      "Train Epoch: 11 [6400/110534 (6%)]\tClassification Loss: 1.2019\r\n",
      "Train Epoch: 11 [7040/110534 (6%)]\tClassification Loss: 1.4813\r\n",
      "Train Epoch: 11 [7680/110534 (7%)]\tClassification Loss: 1.6831\r\n",
      "Train Epoch: 11 [8320/110534 (8%)]\tClassification Loss: 1.8637\r\n",
      "Train Epoch: 11 [8960/110534 (8%)]\tClassification Loss: 1.7141\r\n",
      "Train Epoch: 11 [9600/110534 (9%)]\tClassification Loss: 1.4429\r\n",
      "Train Epoch: 11 [10240/110534 (9%)]\tClassification Loss: 1.5472\r\n",
      "Train Epoch: 11 [10880/110534 (10%)]\tClassification Loss: 1.3915\r\n",
      "Train Epoch: 11 [11520/110534 (10%)]\tClassification Loss: 1.6759\r\n",
      "Train Epoch: 11 [12160/110534 (11%)]\tClassification Loss: 1.5081\r\n",
      "Train Epoch: 11 [12800/110534 (12%)]\tClassification Loss: 1.5516\r\n",
      "Train Epoch: 11 [13440/110534 (12%)]\tClassification Loss: 1.5283\r\n",
      "Train Epoch: 11 [14080/110534 (13%)]\tClassification Loss: 1.5324\r\n",
      "Train Epoch: 11 [14720/110534 (13%)]\tClassification Loss: 1.7908\r\n",
      "Train Epoch: 11 [15360/110534 (14%)]\tClassification Loss: 1.4899\r\n",
      "Train Epoch: 11 [16000/110534 (14%)]\tClassification Loss: 1.5558\r\n",
      "Train Epoch: 11 [16640/110534 (15%)]\tClassification Loss: 1.5548\r\n",
      "Train Epoch: 11 [17280/110534 (16%)]\tClassification Loss: 1.7140\r\n",
      "Train Epoch: 11 [17920/110534 (16%)]\tClassification Loss: 1.4949\r\n",
      "Train Epoch: 11 [18560/110534 (17%)]\tClassification Loss: 1.6485\r\n",
      "Train Epoch: 11 [19200/110534 (17%)]\tClassification Loss: 1.6065\r\n",
      "Train Epoch: 11 [19840/110534 (18%)]\tClassification Loss: 1.5478\r\n",
      "Train Epoch: 11 [20480/110534 (19%)]\tClassification Loss: 1.7443\r\n",
      "Train Epoch: 11 [21120/110534 (19%)]\tClassification Loss: 1.5401\r\n",
      "Train Epoch: 11 [21760/110534 (20%)]\tClassification Loss: 1.4607\r\n",
      "Train Epoch: 11 [22400/110534 (20%)]\tClassification Loss: 1.4740\r\n",
      "Train Epoch: 11 [23040/110534 (21%)]\tClassification Loss: 1.1079\r\n",
      "Train Epoch: 11 [23680/110534 (21%)]\tClassification Loss: 1.7346\r\n",
      "Train Epoch: 11 [24320/110534 (22%)]\tClassification Loss: 1.1779\r\n",
      "Train Epoch: 11 [24960/110534 (23%)]\tClassification Loss: 1.6633\r\n",
      "Train Epoch: 11 [25600/110534 (23%)]\tClassification Loss: 1.3355\r\n",
      "Train Epoch: 11 [26240/110534 (24%)]\tClassification Loss: 1.4697\r\n",
      "Train Epoch: 11 [26880/110534 (24%)]\tClassification Loss: 1.7327\r\n",
      "Train Epoch: 11 [27520/110534 (25%)]\tClassification Loss: 1.3528\r\n",
      "Train Epoch: 11 [28160/110534 (25%)]\tClassification Loss: 1.8330\r\n",
      "Train Epoch: 11 [28800/110534 (26%)]\tClassification Loss: 1.8022\r\n",
      "Train Epoch: 11 [29440/110534 (27%)]\tClassification Loss: 1.5378\r\n",
      "Train Epoch: 11 [30080/110534 (27%)]\tClassification Loss: 1.8528\r\n",
      "Train Epoch: 11 [30720/110534 (28%)]\tClassification Loss: 1.5008\r\n",
      "Train Epoch: 11 [31360/110534 (28%)]\tClassification Loss: 1.5978\r\n",
      "Train Epoch: 11 [32000/110534 (29%)]\tClassification Loss: 1.6073\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_11_500.pth.tar\r\n",
      "Train Epoch: 11 [32640/110534 (30%)]\tClassification Loss: 1.3243\r\n",
      "Train Epoch: 11 [33280/110534 (30%)]\tClassification Loss: 1.5834\r\n",
      "Train Epoch: 11 [33920/110534 (31%)]\tClassification Loss: 1.4658\r\n",
      "Train Epoch: 11 [34560/110534 (31%)]\tClassification Loss: 1.6864\r\n",
      "Train Epoch: 11 [35200/110534 (32%)]\tClassification Loss: 1.3213\r\n",
      "Train Epoch: 11 [35840/110534 (32%)]\tClassification Loss: 1.2605\r\n",
      "Train Epoch: 11 [36480/110534 (33%)]\tClassification Loss: 1.4081\r\n",
      "Train Epoch: 11 [37120/110534 (34%)]\tClassification Loss: 1.6213\r\n",
      "Train Epoch: 11 [37760/110534 (34%)]\tClassification Loss: 1.9465\r\n",
      "Train Epoch: 11 [38400/110534 (35%)]\tClassification Loss: 1.5000\r\n",
      "Train Epoch: 11 [39040/110534 (35%)]\tClassification Loss: 1.5982\r\n",
      "Train Epoch: 11 [39680/110534 (36%)]\tClassification Loss: 1.5513\r\n",
      "Train Epoch: 11 [40320/110534 (36%)]\tClassification Loss: 1.5476\r\n",
      "Train Epoch: 11 [40960/110534 (37%)]\tClassification Loss: 1.2751\r\n",
      "Train Epoch: 11 [41600/110534 (38%)]\tClassification Loss: 1.4255\r\n",
      "Train Epoch: 11 [42240/110534 (38%)]\tClassification Loss: 1.3651\r\n",
      "Train Epoch: 11 [42880/110534 (39%)]\tClassification Loss: 1.4540\r\n",
      "Train Epoch: 11 [43520/110534 (39%)]\tClassification Loss: 1.3659\r\n",
      "Train Epoch: 11 [44160/110534 (40%)]\tClassification Loss: 1.6021\r\n",
      "Train Epoch: 11 [44800/110534 (41%)]\tClassification Loss: 1.5146\r\n",
      "Train Epoch: 11 [45440/110534 (41%)]\tClassification Loss: 1.5327\r\n",
      "Train Epoch: 11 [46080/110534 (42%)]\tClassification Loss: 1.3901\r\n",
      "Train Epoch: 11 [46720/110534 (42%)]\tClassification Loss: 1.4683\r\n",
      "Train Epoch: 11 [47360/110534 (43%)]\tClassification Loss: 1.5566\r\n",
      "Train Epoch: 11 [48000/110534 (43%)]\tClassification Loss: 1.5734\r\n",
      "Train Epoch: 11 [48640/110534 (44%)]\tClassification Loss: 1.3818\r\n",
      "Train Epoch: 11 [49280/110534 (45%)]\tClassification Loss: 1.5434\r\n",
      "Train Epoch: 11 [49920/110534 (45%)]\tClassification Loss: 1.6457\r\n",
      "Train Epoch: 11 [50560/110534 (46%)]\tClassification Loss: 1.5321\r\n",
      "Train Epoch: 11 [51200/110534 (46%)]\tClassification Loss: 1.5050\r\n",
      "Train Epoch: 11 [51840/110534 (47%)]\tClassification Loss: 1.4789\r\n",
      "Train Epoch: 11 [52480/110534 (47%)]\tClassification Loss: 1.4359\r\n",
      "Train Epoch: 11 [53120/110534 (48%)]\tClassification Loss: 1.1505\r\n",
      "Train Epoch: 11 [53760/110534 (49%)]\tClassification Loss: 1.6150\r\n",
      "Train Epoch: 11 [54400/110534 (49%)]\tClassification Loss: 1.4920\r\n",
      "Train Epoch: 11 [55040/110534 (50%)]\tClassification Loss: 1.6920\r\n",
      "Train Epoch: 11 [55680/110534 (50%)]\tClassification Loss: 1.6043\r\n",
      "Train Epoch: 11 [56320/110534 (51%)]\tClassification Loss: 1.4796\r\n",
      "Train Epoch: 11 [56960/110534 (52%)]\tClassification Loss: 1.5803\r\n",
      "Train Epoch: 11 [57600/110534 (52%)]\tClassification Loss: 1.6960\r\n",
      "Train Epoch: 11 [58240/110534 (53%)]\tClassification Loss: 1.5748\r\n",
      "Train Epoch: 11 [58880/110534 (53%)]\tClassification Loss: 1.7636\r\n",
      "Train Epoch: 11 [59520/110534 (54%)]\tClassification Loss: 1.4150\r\n",
      "Train Epoch: 11 [60160/110534 (54%)]\tClassification Loss: 1.4201\r\n",
      "Train Epoch: 11 [60800/110534 (55%)]\tClassification Loss: 1.5680\r\n",
      "Train Epoch: 11 [61440/110534 (56%)]\tClassification Loss: 1.5345\r\n",
      "Train Epoch: 11 [62080/110534 (56%)]\tClassification Loss: 1.5123\r\n",
      "Train Epoch: 11 [62720/110534 (57%)]\tClassification Loss: 1.6831\r\n",
      "Train Epoch: 11 [63360/110534 (57%)]\tClassification Loss: 1.3350\r\n",
      "Train Epoch: 11 [64000/110534 (58%)]\tClassification Loss: 1.4935\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_11_1000.pth.tar\r\n",
      "Train Epoch: 11 [64640/110534 (58%)]\tClassification Loss: 1.3571\r\n",
      "Train Epoch: 11 [65280/110534 (59%)]\tClassification Loss: 1.5576\r\n",
      "Train Epoch: 11 [65920/110534 (60%)]\tClassification Loss: 1.5362\r\n",
      "Train Epoch: 11 [66560/110534 (60%)]\tClassification Loss: 1.3687\r\n",
      "Train Epoch: 11 [67200/110534 (61%)]\tClassification Loss: 1.2970\r\n",
      "Train Epoch: 11 [67840/110534 (61%)]\tClassification Loss: 1.9044\r\n",
      "Train Epoch: 11 [68480/110534 (62%)]\tClassification Loss: 1.6260\r\n",
      "Train Epoch: 11 [69120/110534 (63%)]\tClassification Loss: 1.7059\r\n",
      "Train Epoch: 11 [69760/110534 (63%)]\tClassification Loss: 1.8084\r\n",
      "Train Epoch: 11 [70400/110534 (64%)]\tClassification Loss: 1.1782\r\n",
      "Train Epoch: 11 [71040/110534 (64%)]\tClassification Loss: 1.9740\r\n",
      "Train Epoch: 11 [71680/110534 (65%)]\tClassification Loss: 1.4394\r\n",
      "Train Epoch: 11 [72320/110534 (65%)]\tClassification Loss: 1.6754\r\n",
      "Train Epoch: 11 [72960/110534 (66%)]\tClassification Loss: 1.7292\r\n",
      "Train Epoch: 11 [73600/110534 (67%)]\tClassification Loss: 1.8334\r\n",
      "Train Epoch: 11 [74240/110534 (67%)]\tClassification Loss: 1.7359\r\n",
      "Train Epoch: 11 [74880/110534 (68%)]\tClassification Loss: 1.3086\r\n",
      "Train Epoch: 11 [75520/110534 (68%)]\tClassification Loss: 1.5242\r\n",
      "Train Epoch: 11 [76160/110534 (69%)]\tClassification Loss: 1.4073\r\n",
      "Train Epoch: 11 [76800/110534 (69%)]\tClassification Loss: 1.3172\r\n",
      "Train Epoch: 11 [77440/110534 (70%)]\tClassification Loss: 1.3043\r\n",
      "Train Epoch: 11 [78080/110534 (71%)]\tClassification Loss: 1.4757\r\n",
      "Train Epoch: 11 [78720/110534 (71%)]\tClassification Loss: 1.4121\r\n",
      "Train Epoch: 11 [79360/110534 (72%)]\tClassification Loss: 1.5059\r\n",
      "Train Epoch: 11 [80000/110534 (72%)]\tClassification Loss: 1.4919\r\n",
      "Train Epoch: 11 [80640/110534 (73%)]\tClassification Loss: 1.4308\r\n",
      "Train Epoch: 11 [81280/110534 (74%)]\tClassification Loss: 1.6016\r\n",
      "Train Epoch: 11 [81920/110534 (74%)]\tClassification Loss: 1.5726\r\n",
      "Train Epoch: 11 [82560/110534 (75%)]\tClassification Loss: 1.8289\r\n",
      "Train Epoch: 11 [83200/110534 (75%)]\tClassification Loss: 1.5496\r\n",
      "Train Epoch: 11 [83840/110534 (76%)]\tClassification Loss: 1.7728\r\n",
      "Train Epoch: 11 [84480/110534 (76%)]\tClassification Loss: 1.6484\r\n",
      "Train Epoch: 11 [85120/110534 (77%)]\tClassification Loss: 1.5103\r\n",
      "Train Epoch: 11 [85760/110534 (78%)]\tClassification Loss: 1.5037\r\n",
      "Train Epoch: 11 [86400/110534 (78%)]\tClassification Loss: 1.7919\r\n",
      "Train Epoch: 11 [87040/110534 (79%)]\tClassification Loss: 1.5202\r\n",
      "Train Epoch: 11 [87680/110534 (79%)]\tClassification Loss: 1.3763\r\n",
      "Train Epoch: 11 [88320/110534 (80%)]\tClassification Loss: 1.4754\r\n",
      "Train Epoch: 11 [88960/110534 (80%)]\tClassification Loss: 1.4782\r\n",
      "Train Epoch: 11 [89600/110534 (81%)]\tClassification Loss: 1.8409\r\n",
      "Train Epoch: 11 [90240/110534 (82%)]\tClassification Loss: 1.7317\r\n",
      "Train Epoch: 11 [90880/110534 (82%)]\tClassification Loss: 1.5537\r\n",
      "Train Epoch: 11 [91520/110534 (83%)]\tClassification Loss: 1.2525\r\n",
      "Train Epoch: 11 [92160/110534 (83%)]\tClassification Loss: 1.3008\r\n",
      "Train Epoch: 11 [92800/110534 (84%)]\tClassification Loss: 1.3153\r\n",
      "Train Epoch: 11 [93440/110534 (85%)]\tClassification Loss: 1.7262\r\n",
      "Train Epoch: 11 [94080/110534 (85%)]\tClassification Loss: 1.5758\r\n",
      "Train Epoch: 11 [94720/110534 (86%)]\tClassification Loss: 1.4488\r\n",
      "Train Epoch: 11 [95360/110534 (86%)]\tClassification Loss: 1.4580\r\n",
      "Train Epoch: 11 [96000/110534 (87%)]\tClassification Loss: 1.3771\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_11_1500.pth.tar\r\n",
      "Train Epoch: 11 [96640/110534 (87%)]\tClassification Loss: 1.3645\r\n",
      "Train Epoch: 11 [97280/110534 (88%)]\tClassification Loss: 1.2747\r\n",
      "Train Epoch: 11 [97920/110534 (89%)]\tClassification Loss: 1.1036\r\n",
      "Train Epoch: 11 [98560/110534 (89%)]\tClassification Loss: 1.4790\r\n",
      "Train Epoch: 11 [99200/110534 (90%)]\tClassification Loss: 1.5306\r\n",
      "Train Epoch: 11 [99840/110534 (90%)]\tClassification Loss: 1.6088\r\n",
      "Train Epoch: 11 [100480/110534 (91%)]\tClassification Loss: 1.5752\r\n",
      "Train Epoch: 11 [101120/110534 (91%)]\tClassification Loss: 1.2981\r\n",
      "Train Epoch: 11 [101760/110534 (92%)]\tClassification Loss: 1.5773\r\n",
      "Train Epoch: 11 [102400/110534 (93%)]\tClassification Loss: 1.4125\r\n",
      "Train Epoch: 11 [103040/110534 (93%)]\tClassification Loss: 1.3419\r\n",
      "Train Epoch: 11 [103680/110534 (94%)]\tClassification Loss: 1.6814\r\n",
      "Train Epoch: 11 [104320/110534 (94%)]\tClassification Loss: 1.2885\r\n",
      "Train Epoch: 11 [104960/110534 (95%)]\tClassification Loss: 1.3849\r\n",
      "Train Epoch: 11 [105600/110534 (96%)]\tClassification Loss: 1.4134\r\n",
      "Train Epoch: 11 [106240/110534 (96%)]\tClassification Loss: 1.3807\r\n",
      "Train Epoch: 11 [106880/110534 (97%)]\tClassification Loss: 1.6946\r\n",
      "Train Epoch: 11 [107520/110534 (97%)]\tClassification Loss: 1.5994\r\n",
      "Train Epoch: 11 [108160/110534 (98%)]\tClassification Loss: 1.5574\r\n",
      "Train Epoch: 11 [108800/110534 (98%)]\tClassification Loss: 1.7778\r\n",
      "Train Epoch: 11 [109440/110534 (99%)]\tClassification Loss: 1.3648\r\n",
      "Train Epoch: 11 [110080/110534 (100%)]\tClassification Loss: 1.5201\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_11_final.pth.tar\r\n",
      "Train Epoch: 12 [0/110534 (0%)]\tClassification Loss: 1.4947\r\n",
      "\r\n",
      "Test set: Average loss: 1.4165, Accuracy: 23236/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 12 [640/110534 (1%)]\tClassification Loss: 1.3897\r\n",
      "Train Epoch: 12 [1280/110534 (1%)]\tClassification Loss: 1.9104\r\n",
      "Train Epoch: 12 [1920/110534 (2%)]\tClassification Loss: 1.4662\r\n",
      "Train Epoch: 12 [2560/110534 (2%)]\tClassification Loss: 1.8491\r\n",
      "Train Epoch: 12 [3200/110534 (3%)]\tClassification Loss: 1.5786\r\n",
      "Train Epoch: 12 [3840/110534 (3%)]\tClassification Loss: 1.4741\r\n",
      "Train Epoch: 12 [4480/110534 (4%)]\tClassification Loss: 1.5887\r\n",
      "Train Epoch: 12 [5120/110534 (5%)]\tClassification Loss: 1.5584\r\n",
      "Train Epoch: 12 [5760/110534 (5%)]\tClassification Loss: 1.5555\r\n",
      "Train Epoch: 12 [6400/110534 (6%)]\tClassification Loss: 1.2386\r\n",
      "Train Epoch: 12 [7040/110534 (6%)]\tClassification Loss: 1.3900\r\n",
      "Train Epoch: 12 [7680/110534 (7%)]\tClassification Loss: 1.5105\r\n",
      "Train Epoch: 12 [8320/110534 (8%)]\tClassification Loss: 1.6315\r\n",
      "Train Epoch: 12 [8960/110534 (8%)]\tClassification Loss: 1.6478\r\n",
      "Train Epoch: 12 [9600/110534 (9%)]\tClassification Loss: 1.4959\r\n",
      "Train Epoch: 12 [10240/110534 (9%)]\tClassification Loss: 1.4070\r\n",
      "Train Epoch: 12 [10880/110534 (10%)]\tClassification Loss: 1.4624\r\n",
      "Train Epoch: 12 [11520/110534 (10%)]\tClassification Loss: 1.6347\r\n",
      "Train Epoch: 12 [12160/110534 (11%)]\tClassification Loss: 1.4647\r\n",
      "Train Epoch: 12 [12800/110534 (12%)]\tClassification Loss: 1.7307\r\n",
      "Train Epoch: 12 [13440/110534 (12%)]\tClassification Loss: 1.4871\r\n",
      "Train Epoch: 12 [14080/110534 (13%)]\tClassification Loss: 1.6242\r\n",
      "Train Epoch: 12 [14720/110534 (13%)]\tClassification Loss: 1.8058\r\n",
      "Train Epoch: 12 [15360/110534 (14%)]\tClassification Loss: 1.4859\r\n",
      "Train Epoch: 12 [16000/110534 (14%)]\tClassification Loss: 1.6473\r\n",
      "Train Epoch: 12 [16640/110534 (15%)]\tClassification Loss: 1.5712\r\n",
      "Train Epoch: 12 [17280/110534 (16%)]\tClassification Loss: 1.6814\r\n",
      "Train Epoch: 12 [17920/110534 (16%)]\tClassification Loss: 1.6849\r\n",
      "Train Epoch: 12 [18560/110534 (17%)]\tClassification Loss: 1.6764\r\n",
      "Train Epoch: 12 [19200/110534 (17%)]\tClassification Loss: 1.5948\r\n",
      "Train Epoch: 12 [19840/110534 (18%)]\tClassification Loss: 1.3559\r\n",
      "Train Epoch: 12 [20480/110534 (19%)]\tClassification Loss: 1.6637\r\n",
      "Train Epoch: 12 [21120/110534 (19%)]\tClassification Loss: 1.6223\r\n",
      "Train Epoch: 12 [21760/110534 (20%)]\tClassification Loss: 1.3926\r\n",
      "Train Epoch: 12 [22400/110534 (20%)]\tClassification Loss: 1.6156\r\n",
      "Train Epoch: 12 [23040/110534 (21%)]\tClassification Loss: 1.0827\r\n",
      "Train Epoch: 12 [23680/110534 (21%)]\tClassification Loss: 1.6333\r\n",
      "Train Epoch: 12 [24320/110534 (22%)]\tClassification Loss: 1.3051\r\n",
      "Train Epoch: 12 [24960/110534 (23%)]\tClassification Loss: 1.7739\r\n",
      "Train Epoch: 12 [25600/110534 (23%)]\tClassification Loss: 1.3056\r\n",
      "Train Epoch: 12 [26240/110534 (24%)]\tClassification Loss: 1.5105\r\n",
      "Train Epoch: 12 [26880/110534 (24%)]\tClassification Loss: 1.6965\r\n",
      "Train Epoch: 12 [27520/110534 (25%)]\tClassification Loss: 1.4502\r\n",
      "Train Epoch: 12 [28160/110534 (25%)]\tClassification Loss: 1.7946\r\n",
      "Train Epoch: 12 [28800/110534 (26%)]\tClassification Loss: 2.0113\r\n",
      "Train Epoch: 12 [29440/110534 (27%)]\tClassification Loss: 1.6251\r\n",
      "Train Epoch: 12 [30080/110534 (27%)]\tClassification Loss: 1.7119\r\n",
      "Train Epoch: 12 [30720/110534 (28%)]\tClassification Loss: 1.2176\r\n",
      "Train Epoch: 12 [31360/110534 (28%)]\tClassification Loss: 1.6043\r\n",
      "Train Epoch: 12 [32000/110534 (29%)]\tClassification Loss: 1.5183\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_12_500.pth.tar\r\n",
      "Train Epoch: 12 [32640/110534 (30%)]\tClassification Loss: 1.3360\r\n",
      "Train Epoch: 12 [33280/110534 (30%)]\tClassification Loss: 1.4683\r\n",
      "Train Epoch: 12 [33920/110534 (31%)]\tClassification Loss: 1.6189\r\n",
      "Train Epoch: 12 [34560/110534 (31%)]\tClassification Loss: 1.8133\r\n",
      "Train Epoch: 12 [35200/110534 (32%)]\tClassification Loss: 1.4181\r\n",
      "Train Epoch: 12 [35840/110534 (32%)]\tClassification Loss: 1.1302\r\n",
      "Train Epoch: 12 [36480/110534 (33%)]\tClassification Loss: 1.4135\r\n",
      "Train Epoch: 12 [37120/110534 (34%)]\tClassification Loss: 1.5312\r\n",
      "Train Epoch: 12 [37760/110534 (34%)]\tClassification Loss: 2.0688\r\n",
      "Train Epoch: 12 [38400/110534 (35%)]\tClassification Loss: 1.4862\r\n",
      "Train Epoch: 12 [39040/110534 (35%)]\tClassification Loss: 1.4929\r\n",
      "Train Epoch: 12 [39680/110534 (36%)]\tClassification Loss: 1.5915\r\n",
      "Train Epoch: 12 [40320/110534 (36%)]\tClassification Loss: 1.6765\r\n",
      "Train Epoch: 12 [40960/110534 (37%)]\tClassification Loss: 1.2954\r\n",
      "Train Epoch: 12 [41600/110534 (38%)]\tClassification Loss: 1.4931\r\n",
      "Train Epoch: 12 [42240/110534 (38%)]\tClassification Loss: 1.4001\r\n",
      "Train Epoch: 12 [42880/110534 (39%)]\tClassification Loss: 1.3625\r\n",
      "Train Epoch: 12 [43520/110534 (39%)]\tClassification Loss: 1.3450\r\n",
      "Train Epoch: 12 [44160/110534 (40%)]\tClassification Loss: 1.5677\r\n",
      "Train Epoch: 12 [44800/110534 (41%)]\tClassification Loss: 1.5768\r\n",
      "Train Epoch: 12 [45440/110534 (41%)]\tClassification Loss: 1.5428\r\n",
      "Train Epoch: 12 [46080/110534 (42%)]\tClassification Loss: 1.2216\r\n",
      "Train Epoch: 12 [46720/110534 (42%)]\tClassification Loss: 1.4811\r\n",
      "Train Epoch: 12 [47360/110534 (43%)]\tClassification Loss: 1.5198\r\n",
      "Train Epoch: 12 [48000/110534 (43%)]\tClassification Loss: 1.6731\r\n",
      "Train Epoch: 12 [48640/110534 (44%)]\tClassification Loss: 1.4176\r\n",
      "Train Epoch: 12 [49280/110534 (45%)]\tClassification Loss: 1.7309\r\n",
      "Train Epoch: 12 [49920/110534 (45%)]\tClassification Loss: 1.5556\r\n",
      "Train Epoch: 12 [50560/110534 (46%)]\tClassification Loss: 1.8154\r\n",
      "Train Epoch: 12 [51200/110534 (46%)]\tClassification Loss: 1.4414\r\n",
      "Train Epoch: 12 [51840/110534 (47%)]\tClassification Loss: 1.4863\r\n",
      "Train Epoch: 12 [52480/110534 (47%)]\tClassification Loss: 1.5036\r\n",
      "Train Epoch: 12 [53120/110534 (48%)]\tClassification Loss: 1.0785\r\n",
      "Train Epoch: 12 [53760/110534 (49%)]\tClassification Loss: 1.5449\r\n",
      "Train Epoch: 12 [54400/110534 (49%)]\tClassification Loss: 1.3964\r\n",
      "Train Epoch: 12 [55040/110534 (50%)]\tClassification Loss: 1.7712\r\n",
      "Train Epoch: 12 [55680/110534 (50%)]\tClassification Loss: 1.7428\r\n",
      "Train Epoch: 12 [56320/110534 (51%)]\tClassification Loss: 1.4341\r\n",
      "Train Epoch: 12 [56960/110534 (52%)]\tClassification Loss: 1.4520\r\n",
      "Train Epoch: 12 [57600/110534 (52%)]\tClassification Loss: 1.5796\r\n",
      "Train Epoch: 12 [58240/110534 (53%)]\tClassification Loss: 1.5034\r\n",
      "Train Epoch: 12 [58880/110534 (53%)]\tClassification Loss: 1.8011\r\n",
      "Train Epoch: 12 [59520/110534 (54%)]\tClassification Loss: 1.3860\r\n",
      "Train Epoch: 12 [60160/110534 (54%)]\tClassification Loss: 1.4064\r\n",
      "Train Epoch: 12 [60800/110534 (55%)]\tClassification Loss: 1.5516\r\n",
      "Train Epoch: 12 [61440/110534 (56%)]\tClassification Loss: 1.5163\r\n",
      "Train Epoch: 12 [62080/110534 (56%)]\tClassification Loss: 1.6056\r\n",
      "Train Epoch: 12 [62720/110534 (57%)]\tClassification Loss: 1.6530\r\n",
      "Train Epoch: 12 [63360/110534 (57%)]\tClassification Loss: 1.4836\r\n",
      "Train Epoch: 12 [64000/110534 (58%)]\tClassification Loss: 1.5337\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_12_1000.pth.tar\r\n",
      "Train Epoch: 12 [64640/110534 (58%)]\tClassification Loss: 1.2170\r\n",
      "Train Epoch: 12 [65280/110534 (59%)]\tClassification Loss: 1.5315\r\n",
      "Train Epoch: 12 [65920/110534 (60%)]\tClassification Loss: 1.3840\r\n",
      "Train Epoch: 12 [66560/110534 (60%)]\tClassification Loss: 1.1850\r\n",
      "Train Epoch: 12 [67200/110534 (61%)]\tClassification Loss: 1.2777\r\n",
      "Train Epoch: 12 [67840/110534 (61%)]\tClassification Loss: 1.8550\r\n",
      "Train Epoch: 12 [68480/110534 (62%)]\tClassification Loss: 1.4044\r\n",
      "Train Epoch: 12 [69120/110534 (63%)]\tClassification Loss: 1.6848\r\n",
      "Train Epoch: 12 [69760/110534 (63%)]\tClassification Loss: 1.7481\r\n",
      "Train Epoch: 12 [70400/110534 (64%)]\tClassification Loss: 1.2407\r\n",
      "Train Epoch: 12 [71040/110534 (64%)]\tClassification Loss: 1.8991\r\n",
      "Train Epoch: 12 [71680/110534 (65%)]\tClassification Loss: 1.5764\r\n",
      "Train Epoch: 12 [72320/110534 (65%)]\tClassification Loss: 1.6846\r\n",
      "Train Epoch: 12 [72960/110534 (66%)]\tClassification Loss: 1.7783\r\n",
      "Train Epoch: 12 [73600/110534 (67%)]\tClassification Loss: 1.7972\r\n",
      "Train Epoch: 12 [74240/110534 (67%)]\tClassification Loss: 1.7454\r\n",
      "Train Epoch: 12 [74880/110534 (68%)]\tClassification Loss: 1.2088\r\n",
      "Train Epoch: 12 [75520/110534 (68%)]\tClassification Loss: 1.5520\r\n",
      "Train Epoch: 12 [76160/110534 (69%)]\tClassification Loss: 1.2960\r\n",
      "Train Epoch: 12 [76800/110534 (69%)]\tClassification Loss: 1.2538\r\n",
      "Train Epoch: 12 [77440/110534 (70%)]\tClassification Loss: 1.3296\r\n",
      "Train Epoch: 12 [78080/110534 (71%)]\tClassification Loss: 1.3804\r\n",
      "Train Epoch: 12 [78720/110534 (71%)]\tClassification Loss: 1.4748\r\n",
      "Train Epoch: 12 [79360/110534 (72%)]\tClassification Loss: 1.4260\r\n",
      "Train Epoch: 12 [80000/110534 (72%)]\tClassification Loss: 1.3597\r\n",
      "Train Epoch: 12 [80640/110534 (73%)]\tClassification Loss: 1.3982\r\n",
      "Train Epoch: 12 [81280/110534 (74%)]\tClassification Loss: 1.8394\r\n",
      "Train Epoch: 12 [81920/110534 (74%)]\tClassification Loss: 1.5903\r\n",
      "Train Epoch: 12 [82560/110534 (75%)]\tClassification Loss: 1.7190\r\n",
      "Train Epoch: 12 [83200/110534 (75%)]\tClassification Loss: 1.5346\r\n",
      "Train Epoch: 12 [83840/110534 (76%)]\tClassification Loss: 1.7767\r\n",
      "Train Epoch: 12 [84480/110534 (76%)]\tClassification Loss: 1.6927\r\n",
      "Train Epoch: 12 [85120/110534 (77%)]\tClassification Loss: 1.6627\r\n",
      "Train Epoch: 12 [85760/110534 (78%)]\tClassification Loss: 1.4986\r\n",
      "Train Epoch: 12 [86400/110534 (78%)]\tClassification Loss: 1.5554\r\n",
      "Train Epoch: 12 [87040/110534 (79%)]\tClassification Loss: 1.5640\r\n",
      "Train Epoch: 12 [87680/110534 (79%)]\tClassification Loss: 1.3970\r\n",
      "Train Epoch: 12 [88320/110534 (80%)]\tClassification Loss: 1.5138\r\n",
      "Train Epoch: 12 [88960/110534 (80%)]\tClassification Loss: 1.5504\r\n",
      "Train Epoch: 12 [89600/110534 (81%)]\tClassification Loss: 1.8084\r\n",
      "Train Epoch: 12 [90240/110534 (82%)]\tClassification Loss: 1.6934\r\n",
      "Train Epoch: 12 [90880/110534 (82%)]\tClassification Loss: 1.6679\r\n",
      "Train Epoch: 12 [91520/110534 (83%)]\tClassification Loss: 1.2567\r\n",
      "Train Epoch: 12 [92160/110534 (83%)]\tClassification Loss: 1.3570\r\n",
      "Train Epoch: 12 [92800/110534 (84%)]\tClassification Loss: 1.3349\r\n",
      "Train Epoch: 12 [93440/110534 (85%)]\tClassification Loss: 1.8555\r\n",
      "Train Epoch: 12 [94080/110534 (85%)]\tClassification Loss: 1.6022\r\n",
      "Train Epoch: 12 [94720/110534 (86%)]\tClassification Loss: 1.5464\r\n",
      "Train Epoch: 12 [95360/110534 (86%)]\tClassification Loss: 1.3630\r\n",
      "Train Epoch: 12 [96000/110534 (87%)]\tClassification Loss: 1.5468\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_12_1500.pth.tar\r\n",
      "Train Epoch: 12 [96640/110534 (87%)]\tClassification Loss: 1.3684\r\n",
      "Train Epoch: 12 [97280/110534 (88%)]\tClassification Loss: 1.2272\r\n",
      "Train Epoch: 12 [97920/110534 (89%)]\tClassification Loss: 1.1159\r\n",
      "Train Epoch: 12 [98560/110534 (89%)]\tClassification Loss: 1.4767\r\n",
      "Train Epoch: 12 [99200/110534 (90%)]\tClassification Loss: 1.6437\r\n",
      "Train Epoch: 12 [99840/110534 (90%)]\tClassification Loss: 1.5287\r\n",
      "Train Epoch: 12 [100480/110534 (91%)]\tClassification Loss: 1.7834\r\n",
      "Train Epoch: 12 [101120/110534 (91%)]\tClassification Loss: 1.6656\r\n",
      "Train Epoch: 12 [101760/110534 (92%)]\tClassification Loss: 1.5426\r\n",
      "Train Epoch: 12 [102400/110534 (93%)]\tClassification Loss: 1.3919\r\n",
      "Train Epoch: 12 [103040/110534 (93%)]\tClassification Loss: 1.6432\r\n",
      "Train Epoch: 12 [103680/110534 (94%)]\tClassification Loss: 1.6489\r\n",
      "Train Epoch: 12 [104320/110534 (94%)]\tClassification Loss: 1.3498\r\n",
      "Train Epoch: 12 [104960/110534 (95%)]\tClassification Loss: 1.4568\r\n",
      "Train Epoch: 12 [105600/110534 (96%)]\tClassification Loss: 1.5806\r\n",
      "Train Epoch: 12 [106240/110534 (96%)]\tClassification Loss: 1.2806\r\n",
      "Train Epoch: 12 [106880/110534 (97%)]\tClassification Loss: 1.6331\r\n",
      "Train Epoch: 12 [107520/110534 (97%)]\tClassification Loss: 1.6631\r\n",
      "Train Epoch: 12 [108160/110534 (98%)]\tClassification Loss: 1.5611\r\n",
      "Train Epoch: 12 [108800/110534 (98%)]\tClassification Loss: 1.5525\r\n",
      "Train Epoch: 12 [109440/110534 (99%)]\tClassification Loss: 1.4785\r\n",
      "Train Epoch: 12 [110080/110534 (100%)]\tClassification Loss: 1.3992\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_12_final.pth.tar\r\n",
      "Train Epoch: 13 [0/110534 (0%)]\tClassification Loss: 1.5211\r\n",
      "\r\n",
      "Test set: Average loss: 1.4218, Accuracy: 23119/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 13 [640/110534 (1%)]\tClassification Loss: 1.2997\r\n",
      "Train Epoch: 13 [1280/110534 (1%)]\tClassification Loss: 1.9248\r\n",
      "Train Epoch: 13 [1920/110534 (2%)]\tClassification Loss: 1.5523\r\n",
      "Train Epoch: 13 [2560/110534 (2%)]\tClassification Loss: 1.7741\r\n",
      "Train Epoch: 13 [3200/110534 (3%)]\tClassification Loss: 1.4398\r\n",
      "Train Epoch: 13 [3840/110534 (3%)]\tClassification Loss: 1.4689\r\n",
      "Train Epoch: 13 [4480/110534 (4%)]\tClassification Loss: 1.5800\r\n",
      "Train Epoch: 13 [5120/110534 (5%)]\tClassification Loss: 1.7812\r\n",
      "Train Epoch: 13 [5760/110534 (5%)]\tClassification Loss: 1.6223\r\n",
      "Train Epoch: 13 [6400/110534 (6%)]\tClassification Loss: 1.1606\r\n",
      "Train Epoch: 13 [7040/110534 (6%)]\tClassification Loss: 1.4260\r\n",
      "Train Epoch: 13 [7680/110534 (7%)]\tClassification Loss: 1.7481\r\n",
      "Train Epoch: 13 [8320/110534 (8%)]\tClassification Loss: 1.8723\r\n",
      "Train Epoch: 13 [8960/110534 (8%)]\tClassification Loss: 1.8080\r\n",
      "Train Epoch: 13 [9600/110534 (9%)]\tClassification Loss: 1.5761\r\n",
      "Train Epoch: 13 [10240/110534 (9%)]\tClassification Loss: 1.5057\r\n",
      "Train Epoch: 13 [10880/110534 (10%)]\tClassification Loss: 1.4241\r\n",
      "Train Epoch: 13 [11520/110534 (10%)]\tClassification Loss: 1.6066\r\n",
      "Train Epoch: 13 [12160/110534 (11%)]\tClassification Loss: 1.3708\r\n",
      "Train Epoch: 13 [12800/110534 (12%)]\tClassification Loss: 1.7525\r\n",
      "Train Epoch: 13 [13440/110534 (12%)]\tClassification Loss: 1.4431\r\n",
      "Train Epoch: 13 [14080/110534 (13%)]\tClassification Loss: 1.4573\r\n",
      "Train Epoch: 13 [14720/110534 (13%)]\tClassification Loss: 1.8395\r\n",
      "Train Epoch: 13 [15360/110534 (14%)]\tClassification Loss: 1.5113\r\n",
      "Train Epoch: 13 [16000/110534 (14%)]\tClassification Loss: 1.7331\r\n",
      "Train Epoch: 13 [16640/110534 (15%)]\tClassification Loss: 1.6236\r\n",
      "Train Epoch: 13 [17280/110534 (16%)]\tClassification Loss: 1.8044\r\n",
      "Train Epoch: 13 [17920/110534 (16%)]\tClassification Loss: 1.6951\r\n",
      "Train Epoch: 13 [18560/110534 (17%)]\tClassification Loss: 1.7075\r\n",
      "Train Epoch: 13 [19200/110534 (17%)]\tClassification Loss: 1.7016\r\n",
      "Train Epoch: 13 [19840/110534 (18%)]\tClassification Loss: 1.5825\r\n",
      "Train Epoch: 13 [20480/110534 (19%)]\tClassification Loss: 1.7251\r\n",
      "Train Epoch: 13 [21120/110534 (19%)]\tClassification Loss: 1.8176\r\n",
      "Train Epoch: 13 [21760/110534 (20%)]\tClassification Loss: 1.3534\r\n",
      "Train Epoch: 13 [22400/110534 (20%)]\tClassification Loss: 1.5023\r\n",
      "Train Epoch: 13 [23040/110534 (21%)]\tClassification Loss: 1.0291\r\n",
      "Train Epoch: 13 [23680/110534 (21%)]\tClassification Loss: 1.5032\r\n",
      "Train Epoch: 13 [24320/110534 (22%)]\tClassification Loss: 1.3101\r\n",
      "Train Epoch: 13 [24960/110534 (23%)]\tClassification Loss: 1.7127\r\n",
      "Train Epoch: 13 [25600/110534 (23%)]\tClassification Loss: 1.1853\r\n",
      "Train Epoch: 13 [26240/110534 (24%)]\tClassification Loss: 1.4573\r\n",
      "Train Epoch: 13 [26880/110534 (24%)]\tClassification Loss: 1.7948\r\n",
      "Train Epoch: 13 [27520/110534 (25%)]\tClassification Loss: 1.3786\r\n",
      "Train Epoch: 13 [28160/110534 (25%)]\tClassification Loss: 1.7527\r\n",
      "Train Epoch: 13 [28800/110534 (26%)]\tClassification Loss: 1.7690\r\n",
      "Train Epoch: 13 [29440/110534 (27%)]\tClassification Loss: 1.6881\r\n",
      "Train Epoch: 13 [30080/110534 (27%)]\tClassification Loss: 1.6925\r\n",
      "Train Epoch: 13 [30720/110534 (28%)]\tClassification Loss: 1.3010\r\n",
      "Train Epoch: 13 [31360/110534 (28%)]\tClassification Loss: 1.5628\r\n",
      "Train Epoch: 13 [32000/110534 (29%)]\tClassification Loss: 1.5905\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_13_500.pth.tar\r\n",
      "Train Epoch: 13 [32640/110534 (30%)]\tClassification Loss: 1.3694\r\n",
      "Train Epoch: 13 [33280/110534 (30%)]\tClassification Loss: 1.5045\r\n",
      "Train Epoch: 13 [33920/110534 (31%)]\tClassification Loss: 1.5048\r\n",
      "Train Epoch: 13 [34560/110534 (31%)]\tClassification Loss: 1.7251\r\n",
      "Train Epoch: 13 [35200/110534 (32%)]\tClassification Loss: 1.4546\r\n",
      "Train Epoch: 13 [35840/110534 (32%)]\tClassification Loss: 1.2469\r\n",
      "Train Epoch: 13 [36480/110534 (33%)]\tClassification Loss: 1.3288\r\n",
      "Train Epoch: 13 [37120/110534 (34%)]\tClassification Loss: 1.5991\r\n",
      "Train Epoch: 13 [37760/110534 (34%)]\tClassification Loss: 1.9407\r\n",
      "Train Epoch: 13 [38400/110534 (35%)]\tClassification Loss: 1.3992\r\n",
      "Train Epoch: 13 [39040/110534 (35%)]\tClassification Loss: 1.4046\r\n",
      "Train Epoch: 13 [39680/110534 (36%)]\tClassification Loss: 1.4818\r\n",
      "Train Epoch: 13 [40320/110534 (36%)]\tClassification Loss: 1.5133\r\n",
      "Train Epoch: 13 [40960/110534 (37%)]\tClassification Loss: 1.3318\r\n",
      "Train Epoch: 13 [41600/110534 (38%)]\tClassification Loss: 1.3866\r\n",
      "Train Epoch: 13 [42240/110534 (38%)]\tClassification Loss: 1.4558\r\n",
      "Train Epoch: 13 [42880/110534 (39%)]\tClassification Loss: 1.4366\r\n",
      "Train Epoch: 13 [43520/110534 (39%)]\tClassification Loss: 1.2298\r\n",
      "Train Epoch: 13 [44160/110534 (40%)]\tClassification Loss: 1.4369\r\n",
      "Train Epoch: 13 [44800/110534 (41%)]\tClassification Loss: 1.7163\r\n",
      "Train Epoch: 13 [45440/110534 (41%)]\tClassification Loss: 1.6021\r\n",
      "Train Epoch: 13 [46080/110534 (42%)]\tClassification Loss: 1.3972\r\n",
      "Train Epoch: 13 [46720/110534 (42%)]\tClassification Loss: 1.5264\r\n",
      "Train Epoch: 13 [47360/110534 (43%)]\tClassification Loss: 1.4868\r\n",
      "Train Epoch: 13 [48000/110534 (43%)]\tClassification Loss: 1.6291\r\n",
      "Train Epoch: 13 [48640/110534 (44%)]\tClassification Loss: 1.3619\r\n",
      "Train Epoch: 13 [49280/110534 (45%)]\tClassification Loss: 1.4087\r\n",
      "Train Epoch: 13 [49920/110534 (45%)]\tClassification Loss: 1.5213\r\n",
      "Train Epoch: 13 [50560/110534 (46%)]\tClassification Loss: 1.5175\r\n",
      "Train Epoch: 13 [51200/110534 (46%)]\tClassification Loss: 1.3005\r\n",
      "Train Epoch: 13 [51840/110534 (47%)]\tClassification Loss: 1.5126\r\n",
      "Train Epoch: 13 [52480/110534 (47%)]\tClassification Loss: 1.4850\r\n",
      "Train Epoch: 13 [53120/110534 (48%)]\tClassification Loss: 1.1396\r\n",
      "Train Epoch: 13 [53760/110534 (49%)]\tClassification Loss: 1.6506\r\n",
      "Train Epoch: 13 [54400/110534 (49%)]\tClassification Loss: 1.3980\r\n",
      "Train Epoch: 13 [55040/110534 (50%)]\tClassification Loss: 1.6338\r\n",
      "Train Epoch: 13 [55680/110534 (50%)]\tClassification Loss: 1.6480\r\n",
      "Train Epoch: 13 [56320/110534 (51%)]\tClassification Loss: 1.4429\r\n",
      "Train Epoch: 13 [56960/110534 (52%)]\tClassification Loss: 1.5458\r\n",
      "Train Epoch: 13 [57600/110534 (52%)]\tClassification Loss: 1.6083\r\n",
      "Train Epoch: 13 [58240/110534 (53%)]\tClassification Loss: 1.4370\r\n",
      "Train Epoch: 13 [58880/110534 (53%)]\tClassification Loss: 1.7925\r\n",
      "Train Epoch: 13 [59520/110534 (54%)]\tClassification Loss: 1.2764\r\n",
      "Train Epoch: 13 [60160/110534 (54%)]\tClassification Loss: 1.3481\r\n",
      "Train Epoch: 13 [60800/110534 (55%)]\tClassification Loss: 1.6078\r\n",
      "Train Epoch: 13 [61440/110534 (56%)]\tClassification Loss: 1.5051\r\n",
      "Train Epoch: 13 [62080/110534 (56%)]\tClassification Loss: 1.6154\r\n",
      "Train Epoch: 13 [62720/110534 (57%)]\tClassification Loss: 1.6393\r\n",
      "Train Epoch: 13 [63360/110534 (57%)]\tClassification Loss: 1.2901\r\n",
      "Train Epoch: 13 [64000/110534 (58%)]\tClassification Loss: 1.5652\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_13_1000.pth.tar\r\n",
      "Train Epoch: 13 [64640/110534 (58%)]\tClassification Loss: 1.1788\r\n",
      "Train Epoch: 13 [65280/110534 (59%)]\tClassification Loss: 1.5508\r\n",
      "Train Epoch: 13 [65920/110534 (60%)]\tClassification Loss: 1.4897\r\n",
      "Train Epoch: 13 [66560/110534 (60%)]\tClassification Loss: 1.3554\r\n",
      "Train Epoch: 13 [67200/110534 (61%)]\tClassification Loss: 1.3280\r\n",
      "Train Epoch: 13 [67840/110534 (61%)]\tClassification Loss: 1.8610\r\n",
      "Train Epoch: 13 [68480/110534 (62%)]\tClassification Loss: 1.6037\r\n",
      "Train Epoch: 13 [69120/110534 (63%)]\tClassification Loss: 1.6846\r\n",
      "Train Epoch: 13 [69760/110534 (63%)]\tClassification Loss: 1.4679\r\n",
      "Train Epoch: 13 [70400/110534 (64%)]\tClassification Loss: 1.3750\r\n",
      "Train Epoch: 13 [71040/110534 (64%)]\tClassification Loss: 1.7246\r\n",
      "Train Epoch: 13 [71680/110534 (65%)]\tClassification Loss: 1.6192\r\n",
      "Train Epoch: 13 [72320/110534 (65%)]\tClassification Loss: 1.6454\r\n",
      "Train Epoch: 13 [72960/110534 (66%)]\tClassification Loss: 1.6658\r\n",
      "Train Epoch: 13 [73600/110534 (67%)]\tClassification Loss: 1.8651\r\n",
      "Train Epoch: 13 [74240/110534 (67%)]\tClassification Loss: 1.7052\r\n",
      "Train Epoch: 13 [74880/110534 (68%)]\tClassification Loss: 1.1557\r\n",
      "Train Epoch: 13 [75520/110534 (68%)]\tClassification Loss: 1.4863\r\n",
      "Train Epoch: 13 [76160/110534 (69%)]\tClassification Loss: 1.3939\r\n",
      "Train Epoch: 13 [76800/110534 (69%)]\tClassification Loss: 1.3465\r\n",
      "Train Epoch: 13 [77440/110534 (70%)]\tClassification Loss: 1.4621\r\n",
      "Train Epoch: 13 [78080/110534 (71%)]\tClassification Loss: 1.4307\r\n",
      "Train Epoch: 13 [78720/110534 (71%)]\tClassification Loss: 1.6323\r\n",
      "Train Epoch: 13 [79360/110534 (72%)]\tClassification Loss: 1.4145\r\n",
      "Train Epoch: 13 [80000/110534 (72%)]\tClassification Loss: 1.5502\r\n",
      "Train Epoch: 13 [80640/110534 (73%)]\tClassification Loss: 1.4665\r\n",
      "Train Epoch: 13 [81280/110534 (74%)]\tClassification Loss: 1.7788\r\n",
      "Train Epoch: 13 [81920/110534 (74%)]\tClassification Loss: 1.3938\r\n",
      "Train Epoch: 13 [82560/110534 (75%)]\tClassification Loss: 1.8634\r\n",
      "Train Epoch: 13 [83200/110534 (75%)]\tClassification Loss: 1.6160\r\n",
      "Train Epoch: 13 [83840/110534 (76%)]\tClassification Loss: 1.7860\r\n",
      "Train Epoch: 13 [84480/110534 (76%)]\tClassification Loss: 1.7481\r\n",
      "Train Epoch: 13 [85120/110534 (77%)]\tClassification Loss: 1.6373\r\n",
      "Train Epoch: 13 [85760/110534 (78%)]\tClassification Loss: 1.4475\r\n",
      "Train Epoch: 13 [86400/110534 (78%)]\tClassification Loss: 1.7428\r\n",
      "Train Epoch: 13 [87040/110534 (79%)]\tClassification Loss: 1.4569\r\n",
      "Train Epoch: 13 [87680/110534 (79%)]\tClassification Loss: 1.2991\r\n",
      "Train Epoch: 13 [88320/110534 (80%)]\tClassification Loss: 1.5931\r\n",
      "Train Epoch: 13 [88960/110534 (80%)]\tClassification Loss: 1.7508\r\n",
      "Train Epoch: 13 [89600/110534 (81%)]\tClassification Loss: 1.5898\r\n",
      "Train Epoch: 13 [90240/110534 (82%)]\tClassification Loss: 1.8127\r\n",
      "Train Epoch: 13 [90880/110534 (82%)]\tClassification Loss: 1.5303\r\n",
      "Train Epoch: 13 [91520/110534 (83%)]\tClassification Loss: 1.2631\r\n",
      "Train Epoch: 13 [92160/110534 (83%)]\tClassification Loss: 1.3273\r\n",
      "Train Epoch: 13 [92800/110534 (84%)]\tClassification Loss: 1.3887\r\n",
      "Train Epoch: 13 [93440/110534 (85%)]\tClassification Loss: 1.7118\r\n",
      "Train Epoch: 13 [94080/110534 (85%)]\tClassification Loss: 1.4434\r\n",
      "Train Epoch: 13 [94720/110534 (86%)]\tClassification Loss: 1.3838\r\n",
      "Train Epoch: 13 [95360/110534 (86%)]\tClassification Loss: 1.3537\r\n",
      "Train Epoch: 13 [96000/110534 (87%)]\tClassification Loss: 1.4100\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_13_1500.pth.tar\r\n",
      "Train Epoch: 13 [96640/110534 (87%)]\tClassification Loss: 1.3468\r\n",
      "Train Epoch: 13 [97280/110534 (88%)]\tClassification Loss: 1.2479\r\n",
      "Train Epoch: 13 [97920/110534 (89%)]\tClassification Loss: 1.1385\r\n",
      "Train Epoch: 13 [98560/110534 (89%)]\tClassification Loss: 1.4067\r\n",
      "Train Epoch: 13 [99200/110534 (90%)]\tClassification Loss: 1.6521\r\n",
      "Train Epoch: 13 [99840/110534 (90%)]\tClassification Loss: 1.3885\r\n",
      "Train Epoch: 13 [100480/110534 (91%)]\tClassification Loss: 1.7590\r\n",
      "Train Epoch: 13 [101120/110534 (91%)]\tClassification Loss: 1.4808\r\n",
      "Train Epoch: 13 [101760/110534 (92%)]\tClassification Loss: 1.5816\r\n",
      "Train Epoch: 13 [102400/110534 (93%)]\tClassification Loss: 1.4151\r\n",
      "Train Epoch: 13 [103040/110534 (93%)]\tClassification Loss: 1.6018\r\n",
      "Train Epoch: 13 [103680/110534 (94%)]\tClassification Loss: 1.7210\r\n",
      "Train Epoch: 13 [104320/110534 (94%)]\tClassification Loss: 1.4427\r\n",
      "Train Epoch: 13 [104960/110534 (95%)]\tClassification Loss: 1.4229\r\n",
      "Train Epoch: 13 [105600/110534 (96%)]\tClassification Loss: 1.4850\r\n",
      "Train Epoch: 13 [106240/110534 (96%)]\tClassification Loss: 1.3064\r\n",
      "Train Epoch: 13 [106880/110534 (97%)]\tClassification Loss: 1.8112\r\n",
      "Train Epoch: 13 [107520/110534 (97%)]\tClassification Loss: 1.7532\r\n",
      "Train Epoch: 13 [108160/110534 (98%)]\tClassification Loss: 1.4026\r\n",
      "Train Epoch: 13 [108800/110534 (98%)]\tClassification Loss: 1.6336\r\n",
      "Train Epoch: 13 [109440/110534 (99%)]\tClassification Loss: 1.4919\r\n",
      "Train Epoch: 13 [110080/110534 (100%)]\tClassification Loss: 1.3806\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_13_final.pth.tar\r\n",
      "Train Epoch: 14 [0/110534 (0%)]\tClassification Loss: 1.6896\r\n",
      "\r\n",
      "Test set: Average loss: 1.4217, Accuracy: 23169/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 14 [640/110534 (1%)]\tClassification Loss: 1.3470\r\n",
      "Train Epoch: 14 [1280/110534 (1%)]\tClassification Loss: 2.0333\r\n",
      "Train Epoch: 14 [1920/110534 (2%)]\tClassification Loss: 1.4491\r\n",
      "Train Epoch: 14 [2560/110534 (2%)]\tClassification Loss: 1.6964\r\n",
      "Train Epoch: 14 [3200/110534 (3%)]\tClassification Loss: 1.4447\r\n",
      "Train Epoch: 14 [3840/110534 (3%)]\tClassification Loss: 1.4595\r\n",
      "Train Epoch: 14 [4480/110534 (4%)]\tClassification Loss: 1.5300\r\n",
      "Train Epoch: 14 [5120/110534 (5%)]\tClassification Loss: 1.3952\r\n",
      "Train Epoch: 14 [5760/110534 (5%)]\tClassification Loss: 1.5497\r\n",
      "Train Epoch: 14 [6400/110534 (6%)]\tClassification Loss: 1.3480\r\n",
      "Train Epoch: 14 [7040/110534 (6%)]\tClassification Loss: 1.4937\r\n",
      "Train Epoch: 14 [7680/110534 (7%)]\tClassification Loss: 1.6143\r\n",
      "Train Epoch: 14 [8320/110534 (8%)]\tClassification Loss: 1.7814\r\n",
      "Train Epoch: 14 [8960/110534 (8%)]\tClassification Loss: 1.8033\r\n",
      "Train Epoch: 14 [9600/110534 (9%)]\tClassification Loss: 1.4639\r\n",
      "Train Epoch: 14 [10240/110534 (9%)]\tClassification Loss: 1.4982\r\n",
      "Train Epoch: 14 [10880/110534 (10%)]\tClassification Loss: 1.5247\r\n",
      "Train Epoch: 14 [11520/110534 (10%)]\tClassification Loss: 1.6255\r\n",
      "Train Epoch: 14 [12160/110534 (11%)]\tClassification Loss: 1.3444\r\n",
      "Train Epoch: 14 [12800/110534 (12%)]\tClassification Loss: 1.7707\r\n",
      "Train Epoch: 14 [13440/110534 (12%)]\tClassification Loss: 1.3871\r\n",
      "Train Epoch: 14 [14080/110534 (13%)]\tClassification Loss: 1.5423\r\n",
      "Train Epoch: 14 [14720/110534 (13%)]\tClassification Loss: 1.7886\r\n",
      "Train Epoch: 14 [15360/110534 (14%)]\tClassification Loss: 1.4703\r\n",
      "Train Epoch: 14 [16000/110534 (14%)]\tClassification Loss: 1.6320\r\n",
      "Train Epoch: 14 [16640/110534 (15%)]\tClassification Loss: 1.5132\r\n",
      "Train Epoch: 14 [17280/110534 (16%)]\tClassification Loss: 1.7147\r\n",
      "Train Epoch: 14 [17920/110534 (16%)]\tClassification Loss: 1.6088\r\n",
      "Train Epoch: 14 [18560/110534 (17%)]\tClassification Loss: 1.6745\r\n",
      "Train Epoch: 14 [19200/110534 (17%)]\tClassification Loss: 1.6373\r\n",
      "Train Epoch: 14 [19840/110534 (18%)]\tClassification Loss: 1.6131\r\n",
      "Train Epoch: 14 [20480/110534 (19%)]\tClassification Loss: 1.8798\r\n",
      "Train Epoch: 14 [21120/110534 (19%)]\tClassification Loss: 1.7102\r\n",
      "Train Epoch: 14 [21760/110534 (20%)]\tClassification Loss: 1.4440\r\n",
      "Train Epoch: 14 [22400/110534 (20%)]\tClassification Loss: 1.7295\r\n",
      "Train Epoch: 14 [23040/110534 (21%)]\tClassification Loss: 1.1819\r\n",
      "Train Epoch: 14 [23680/110534 (21%)]\tClassification Loss: 1.6549\r\n",
      "Train Epoch: 14 [24320/110534 (22%)]\tClassification Loss: 1.2779\r\n",
      "Train Epoch: 14 [24960/110534 (23%)]\tClassification Loss: 1.6264\r\n",
      "Train Epoch: 14 [25600/110534 (23%)]\tClassification Loss: 1.2370\r\n",
      "Train Epoch: 14 [26240/110534 (24%)]\tClassification Loss: 1.4115\r\n",
      "Train Epoch: 14 [26880/110534 (24%)]\tClassification Loss: 1.6643\r\n",
      "Train Epoch: 14 [27520/110534 (25%)]\tClassification Loss: 1.5560\r\n",
      "Train Epoch: 14 [28160/110534 (25%)]\tClassification Loss: 1.6815\r\n",
      "Train Epoch: 14 [28800/110534 (26%)]\tClassification Loss: 1.7307\r\n",
      "Train Epoch: 14 [29440/110534 (27%)]\tClassification Loss: 1.7065\r\n",
      "Train Epoch: 14 [30080/110534 (27%)]\tClassification Loss: 1.9540\r\n",
      "Train Epoch: 14 [30720/110534 (28%)]\tClassification Loss: 1.4816\r\n",
      "Train Epoch: 14 [31360/110534 (28%)]\tClassification Loss: 1.5549\r\n",
      "Train Epoch: 14 [32000/110534 (29%)]\tClassification Loss: 1.3854\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_14_500.pth.tar\r\n",
      "Train Epoch: 14 [32640/110534 (30%)]\tClassification Loss: 1.2664\r\n",
      "Train Epoch: 14 [33280/110534 (30%)]\tClassification Loss: 1.6588\r\n",
      "Train Epoch: 14 [33920/110534 (31%)]\tClassification Loss: 1.5228\r\n",
      "Train Epoch: 14 [34560/110534 (31%)]\tClassification Loss: 1.6741\r\n",
      "Train Epoch: 14 [35200/110534 (32%)]\tClassification Loss: 1.3267\r\n",
      "Train Epoch: 14 [35840/110534 (32%)]\tClassification Loss: 1.2349\r\n",
      "Train Epoch: 14 [36480/110534 (33%)]\tClassification Loss: 1.4032\r\n",
      "Train Epoch: 14 [37120/110534 (34%)]\tClassification Loss: 1.6054\r\n",
      "Train Epoch: 14 [37760/110534 (34%)]\tClassification Loss: 1.9360\r\n",
      "Train Epoch: 14 [38400/110534 (35%)]\tClassification Loss: 1.4892\r\n",
      "Train Epoch: 14 [39040/110534 (35%)]\tClassification Loss: 1.5272\r\n",
      "Train Epoch: 14 [39680/110534 (36%)]\tClassification Loss: 1.5230\r\n",
      "Train Epoch: 14 [40320/110534 (36%)]\tClassification Loss: 1.5969\r\n",
      "Train Epoch: 14 [40960/110534 (37%)]\tClassification Loss: 1.4092\r\n",
      "Train Epoch: 14 [41600/110534 (38%)]\tClassification Loss: 1.3926\r\n",
      "Train Epoch: 14 [42240/110534 (38%)]\tClassification Loss: 1.4939\r\n",
      "Train Epoch: 14 [42880/110534 (39%)]\tClassification Loss: 1.4334\r\n",
      "Train Epoch: 14 [43520/110534 (39%)]\tClassification Loss: 1.2842\r\n",
      "Train Epoch: 14 [44160/110534 (40%)]\tClassification Loss: 1.6079\r\n",
      "Train Epoch: 14 [44800/110534 (41%)]\tClassification Loss: 1.5897\r\n",
      "Train Epoch: 14 [45440/110534 (41%)]\tClassification Loss: 1.4798\r\n",
      "Train Epoch: 14 [46080/110534 (42%)]\tClassification Loss: 1.4406\r\n",
      "Train Epoch: 14 [46720/110534 (42%)]\tClassification Loss: 1.5002\r\n",
      "Train Epoch: 14 [47360/110534 (43%)]\tClassification Loss: 1.5154\r\n",
      "Train Epoch: 14 [48000/110534 (43%)]\tClassification Loss: 1.7475\r\n",
      "Train Epoch: 14 [48640/110534 (44%)]\tClassification Loss: 1.4368\r\n",
      "Train Epoch: 14 [49280/110534 (45%)]\tClassification Loss: 1.6505\r\n",
      "Train Epoch: 14 [49920/110534 (45%)]\tClassification Loss: 1.4832\r\n",
      "Train Epoch: 14 [50560/110534 (46%)]\tClassification Loss: 1.6209\r\n",
      "Train Epoch: 14 [51200/110534 (46%)]\tClassification Loss: 1.3119\r\n",
      "Train Epoch: 14 [51840/110534 (47%)]\tClassification Loss: 1.3813\r\n",
      "Train Epoch: 14 [52480/110534 (47%)]\tClassification Loss: 1.4779\r\n",
      "Train Epoch: 14 [53120/110534 (48%)]\tClassification Loss: 1.3294\r\n",
      "Train Epoch: 14 [53760/110534 (49%)]\tClassification Loss: 1.4642\r\n",
      "Train Epoch: 14 [54400/110534 (49%)]\tClassification Loss: 1.4472\r\n",
      "Train Epoch: 14 [55040/110534 (50%)]\tClassification Loss: 1.6866\r\n",
      "Train Epoch: 14 [55680/110534 (50%)]\tClassification Loss: 1.6240\r\n",
      "Train Epoch: 14 [56320/110534 (51%)]\tClassification Loss: 1.5056\r\n",
      "Train Epoch: 14 [56960/110534 (52%)]\tClassification Loss: 1.5555\r\n",
      "Train Epoch: 14 [57600/110534 (52%)]\tClassification Loss: 1.5618\r\n",
      "Train Epoch: 14 [58240/110534 (53%)]\tClassification Loss: 1.5049\r\n",
      "Train Epoch: 14 [58880/110534 (53%)]\tClassification Loss: 1.8352\r\n",
      "Train Epoch: 14 [59520/110534 (54%)]\tClassification Loss: 1.2715\r\n",
      "Train Epoch: 14 [60160/110534 (54%)]\tClassification Loss: 1.5453\r\n",
      "Train Epoch: 14 [60800/110534 (55%)]\tClassification Loss: 1.6088\r\n",
      "Train Epoch: 14 [61440/110534 (56%)]\tClassification Loss: 1.4424\r\n",
      "Train Epoch: 14 [62080/110534 (56%)]\tClassification Loss: 1.4656\r\n",
      "Train Epoch: 14 [62720/110534 (57%)]\tClassification Loss: 1.8024\r\n",
      "Train Epoch: 14 [63360/110534 (57%)]\tClassification Loss: 1.1956\r\n",
      "Train Epoch: 14 [64000/110534 (58%)]\tClassification Loss: 1.5654\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_14_1000.pth.tar\r\n",
      "Train Epoch: 14 [64640/110534 (58%)]\tClassification Loss: 1.1660\r\n",
      "Train Epoch: 14 [65280/110534 (59%)]\tClassification Loss: 1.5173\r\n",
      "Train Epoch: 14 [65920/110534 (60%)]\tClassification Loss: 1.4326\r\n",
      "Train Epoch: 14 [66560/110534 (60%)]\tClassification Loss: 1.3414\r\n",
      "Train Epoch: 14 [67200/110534 (61%)]\tClassification Loss: 1.2620\r\n",
      "Train Epoch: 14 [67840/110534 (61%)]\tClassification Loss: 1.7971\r\n",
      "Train Epoch: 14 [68480/110534 (62%)]\tClassification Loss: 1.6248\r\n",
      "Train Epoch: 14 [69120/110534 (63%)]\tClassification Loss: 1.8479\r\n",
      "Train Epoch: 14 [69760/110534 (63%)]\tClassification Loss: 1.6040\r\n",
      "Train Epoch: 14 [70400/110534 (64%)]\tClassification Loss: 1.1381\r\n",
      "Train Epoch: 14 [71040/110534 (64%)]\tClassification Loss: 1.8640\r\n",
      "Train Epoch: 14 [71680/110534 (65%)]\tClassification Loss: 1.4831\r\n",
      "Train Epoch: 14 [72320/110534 (65%)]\tClassification Loss: 1.7240\r\n",
      "Train Epoch: 14 [72960/110534 (66%)]\tClassification Loss: 1.9070\r\n",
      "Train Epoch: 14 [73600/110534 (67%)]\tClassification Loss: 1.6580\r\n",
      "Train Epoch: 14 [74240/110534 (67%)]\tClassification Loss: 1.7785\r\n",
      "Train Epoch: 14 [74880/110534 (68%)]\tClassification Loss: 1.1403\r\n",
      "Train Epoch: 14 [75520/110534 (68%)]\tClassification Loss: 1.4230\r\n",
      "Train Epoch: 14 [76160/110534 (69%)]\tClassification Loss: 1.2698\r\n",
      "Train Epoch: 14 [76800/110534 (69%)]\tClassification Loss: 1.3862\r\n",
      "Train Epoch: 14 [77440/110534 (70%)]\tClassification Loss: 1.3588\r\n",
      "Train Epoch: 14 [78080/110534 (71%)]\tClassification Loss: 1.5473\r\n",
      "Train Epoch: 14 [78720/110534 (71%)]\tClassification Loss: 1.4161\r\n",
      "Train Epoch: 14 [79360/110534 (72%)]\tClassification Loss: 1.3483\r\n",
      "Train Epoch: 14 [80000/110534 (72%)]\tClassification Loss: 1.3812\r\n",
      "Train Epoch: 14 [80640/110534 (73%)]\tClassification Loss: 1.4097\r\n",
      "Train Epoch: 14 [81280/110534 (74%)]\tClassification Loss: 1.6823\r\n",
      "Train Epoch: 14 [81920/110534 (74%)]\tClassification Loss: 1.5657\r\n",
      "Train Epoch: 14 [82560/110534 (75%)]\tClassification Loss: 1.6113\r\n",
      "Train Epoch: 14 [83200/110534 (75%)]\tClassification Loss: 1.5540\r\n",
      "Train Epoch: 14 [83840/110534 (76%)]\tClassification Loss: 2.1069\r\n",
      "Train Epoch: 14 [84480/110534 (76%)]\tClassification Loss: 1.5538\r\n",
      "Train Epoch: 14 [85120/110534 (77%)]\tClassification Loss: 1.3672\r\n",
      "Train Epoch: 14 [85760/110534 (78%)]\tClassification Loss: 1.4669\r\n",
      "Train Epoch: 14 [86400/110534 (78%)]\tClassification Loss: 1.5734\r\n",
      "Train Epoch: 14 [87040/110534 (79%)]\tClassification Loss: 1.5567\r\n",
      "Train Epoch: 14 [87680/110534 (79%)]\tClassification Loss: 1.3569\r\n",
      "Train Epoch: 14 [88320/110534 (80%)]\tClassification Loss: 1.5370\r\n",
      "Train Epoch: 14 [88960/110534 (80%)]\tClassification Loss: 1.6810\r\n",
      "Train Epoch: 14 [89600/110534 (81%)]\tClassification Loss: 1.7052\r\n",
      "Train Epoch: 14 [90240/110534 (82%)]\tClassification Loss: 1.7371\r\n",
      "Train Epoch: 14 [90880/110534 (82%)]\tClassification Loss: 1.5352\r\n",
      "Train Epoch: 14 [91520/110534 (83%)]\tClassification Loss: 1.3779\r\n",
      "Train Epoch: 14 [92160/110534 (83%)]\tClassification Loss: 1.3200\r\n",
      "Train Epoch: 14 [92800/110534 (84%)]\tClassification Loss: 1.3859\r\n",
      "Train Epoch: 14 [93440/110534 (85%)]\tClassification Loss: 1.6118\r\n",
      "Train Epoch: 14 [94080/110534 (85%)]\tClassification Loss: 1.4152\r\n",
      "Train Epoch: 14 [94720/110534 (86%)]\tClassification Loss: 1.2969\r\n",
      "Train Epoch: 14 [95360/110534 (86%)]\tClassification Loss: 1.4229\r\n",
      "Train Epoch: 14 [96000/110534 (87%)]\tClassification Loss: 1.4040\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_14_1500.pth.tar\r\n",
      "Train Epoch: 14 [96640/110534 (87%)]\tClassification Loss: 1.3429\r\n",
      "Train Epoch: 14 [97280/110534 (88%)]\tClassification Loss: 1.2242\r\n",
      "Train Epoch: 14 [97920/110534 (89%)]\tClassification Loss: 1.1998\r\n",
      "Train Epoch: 14 [98560/110534 (89%)]\tClassification Loss: 1.5435\r\n",
      "Train Epoch: 14 [99200/110534 (90%)]\tClassification Loss: 1.6284\r\n",
      "Train Epoch: 14 [99840/110534 (90%)]\tClassification Loss: 1.4970\r\n",
      "Train Epoch: 14 [100480/110534 (91%)]\tClassification Loss: 1.7501\r\n",
      "Train Epoch: 14 [101120/110534 (91%)]\tClassification Loss: 1.5104\r\n",
      "Train Epoch: 14 [101760/110534 (92%)]\tClassification Loss: 1.5040\r\n",
      "Train Epoch: 14 [102400/110534 (93%)]\tClassification Loss: 1.5843\r\n",
      "Train Epoch: 14 [103040/110534 (93%)]\tClassification Loss: 1.6380\r\n",
      "Train Epoch: 14 [103680/110534 (94%)]\tClassification Loss: 1.7251\r\n",
      "Train Epoch: 14 [104320/110534 (94%)]\tClassification Loss: 1.4852\r\n",
      "Train Epoch: 14 [104960/110534 (95%)]\tClassification Loss: 1.4719\r\n",
      "Train Epoch: 14 [105600/110534 (96%)]\tClassification Loss: 1.4868\r\n",
      "Train Epoch: 14 [106240/110534 (96%)]\tClassification Loss: 1.4374\r\n",
      "Train Epoch: 14 [106880/110534 (97%)]\tClassification Loss: 1.8377\r\n",
      "Train Epoch: 14 [107520/110534 (97%)]\tClassification Loss: 1.4428\r\n",
      "Train Epoch: 14 [108160/110534 (98%)]\tClassification Loss: 1.5396\r\n",
      "Train Epoch: 14 [108800/110534 (98%)]\tClassification Loss: 1.6695\r\n",
      "Train Epoch: 14 [109440/110534 (99%)]\tClassification Loss: 1.4344\r\n",
      "Train Epoch: 14 [110080/110534 (100%)]\tClassification Loss: 1.5101\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_14_final.pth.tar\r\n",
      "Train Epoch: 15 [0/110534 (0%)]\tClassification Loss: 1.5813\r\n",
      "\r\n",
      "Test set: Average loss: 1.4169, Accuracy: 23188/42368 (55%)\r\n",
      "\r\n",
      "Train Epoch: 15 [640/110534 (1%)]\tClassification Loss: 1.2973\r\n",
      "Train Epoch: 15 [1280/110534 (1%)]\tClassification Loss: 1.9754\r\n",
      "Train Epoch: 15 [1920/110534 (2%)]\tClassification Loss: 1.5729\r\n",
      "Train Epoch: 15 [2560/110534 (2%)]\tClassification Loss: 1.7709\r\n",
      "Train Epoch: 15 [3200/110534 (3%)]\tClassification Loss: 1.3911\r\n",
      "Train Epoch: 15 [3840/110534 (3%)]\tClassification Loss: 1.5039\r\n",
      "Train Epoch: 15 [4480/110534 (4%)]\tClassification Loss: 1.5162\r\n",
      "Train Epoch: 15 [5120/110534 (5%)]\tClassification Loss: 1.5714\r\n",
      "Train Epoch: 15 [5760/110534 (5%)]\tClassification Loss: 1.5169\r\n",
      "Train Epoch: 15 [6400/110534 (6%)]\tClassification Loss: 1.2808\r\n",
      "Train Epoch: 15 [7040/110534 (6%)]\tClassification Loss: 1.5263\r\n",
      "Train Epoch: 15 [7680/110534 (7%)]\tClassification Loss: 1.5075\r\n",
      "Train Epoch: 15 [8320/110534 (8%)]\tClassification Loss: 1.5762\r\n",
      "Train Epoch: 15 [8960/110534 (8%)]\tClassification Loss: 1.8931\r\n",
      "Train Epoch: 15 [9600/110534 (9%)]\tClassification Loss: 1.5255\r\n",
      "Train Epoch: 15 [10240/110534 (9%)]\tClassification Loss: 1.4774\r\n",
      "Train Epoch: 15 [10880/110534 (10%)]\tClassification Loss: 1.4517\r\n",
      "Train Epoch: 15 [11520/110534 (10%)]\tClassification Loss: 1.5867\r\n",
      "Train Epoch: 15 [12160/110534 (11%)]\tClassification Loss: 1.4125\r\n",
      "Train Epoch: 15 [12800/110534 (12%)]\tClassification Loss: 1.5799\r\n",
      "Train Epoch: 15 [13440/110534 (12%)]\tClassification Loss: 1.3841\r\n",
      "Train Epoch: 15 [14080/110534 (13%)]\tClassification Loss: 1.6345\r\n",
      "Train Epoch: 15 [14720/110534 (13%)]\tClassification Loss: 1.7724\r\n",
      "Train Epoch: 15 [15360/110534 (14%)]\tClassification Loss: 1.5378\r\n",
      "Train Epoch: 15 [16000/110534 (14%)]\tClassification Loss: 1.7733\r\n",
      "Train Epoch: 15 [16640/110534 (15%)]\tClassification Loss: 1.4916\r\n",
      "Train Epoch: 15 [17280/110534 (16%)]\tClassification Loss: 1.5846\r\n",
      "Train Epoch: 15 [17920/110534 (16%)]\tClassification Loss: 1.5086\r\n",
      "Train Epoch: 15 [18560/110534 (17%)]\tClassification Loss: 1.8942\r\n",
      "Train Epoch: 15 [19200/110534 (17%)]\tClassification Loss: 1.5711\r\n",
      "Train Epoch: 15 [19840/110534 (18%)]\tClassification Loss: 1.5894\r\n",
      "Train Epoch: 15 [20480/110534 (19%)]\tClassification Loss: 1.8709\r\n",
      "Train Epoch: 15 [21120/110534 (19%)]\tClassification Loss: 1.6889\r\n",
      "Train Epoch: 15 [21760/110534 (20%)]\tClassification Loss: 1.5091\r\n",
      "Train Epoch: 15 [22400/110534 (20%)]\tClassification Loss: 1.5141\r\n",
      "Train Epoch: 15 [23040/110534 (21%)]\tClassification Loss: 1.1098\r\n",
      "Train Epoch: 15 [23680/110534 (21%)]\tClassification Loss: 1.5452\r\n",
      "Train Epoch: 15 [24320/110534 (22%)]\tClassification Loss: 1.2927\r\n",
      "Train Epoch: 15 [24960/110534 (23%)]\tClassification Loss: 1.6793\r\n",
      "Train Epoch: 15 [25600/110534 (23%)]\tClassification Loss: 1.2292\r\n",
      "Train Epoch: 15 [26240/110534 (24%)]\tClassification Loss: 1.5142\r\n",
      "Train Epoch: 15 [26880/110534 (24%)]\tClassification Loss: 1.7403\r\n",
      "Train Epoch: 15 [27520/110534 (25%)]\tClassification Loss: 1.4941\r\n",
      "Train Epoch: 15 [28160/110534 (25%)]\tClassification Loss: 1.6044\r\n",
      "Train Epoch: 15 [28800/110534 (26%)]\tClassification Loss: 1.7844\r\n",
      "Train Epoch: 15 [29440/110534 (27%)]\tClassification Loss: 1.7407\r\n",
      "Train Epoch: 15 [30080/110534 (27%)]\tClassification Loss: 1.7758\r\n",
      "Train Epoch: 15 [30720/110534 (28%)]\tClassification Loss: 1.3586\r\n",
      "Train Epoch: 15 [31360/110534 (28%)]\tClassification Loss: 1.6886\r\n",
      "Train Epoch: 15 [32000/110534 (29%)]\tClassification Loss: 1.6256\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_15_500.pth.tar\r\n",
      "Train Epoch: 15 [32640/110534 (30%)]\tClassification Loss: 1.3548\r\n",
      "Train Epoch: 15 [33280/110534 (30%)]\tClassification Loss: 1.4971\r\n",
      "Train Epoch: 15 [33920/110534 (31%)]\tClassification Loss: 1.6259\r\n",
      "Train Epoch: 15 [34560/110534 (31%)]\tClassification Loss: 1.7036\r\n",
      "Train Epoch: 15 [35200/110534 (32%)]\tClassification Loss: 1.5470\r\n",
      "Train Epoch: 15 [35840/110534 (32%)]\tClassification Loss: 1.3396\r\n",
      "Train Epoch: 15 [36480/110534 (33%)]\tClassification Loss: 1.4831\r\n",
      "Train Epoch: 15 [37120/110534 (34%)]\tClassification Loss: 1.6698\r\n",
      "Train Epoch: 15 [37760/110534 (34%)]\tClassification Loss: 1.8528\r\n",
      "Train Epoch: 15 [38400/110534 (35%)]\tClassification Loss: 1.5244\r\n",
      "Train Epoch: 15 [39040/110534 (35%)]\tClassification Loss: 1.3274\r\n",
      "Train Epoch: 15 [39680/110534 (36%)]\tClassification Loss: 1.4897\r\n",
      "Train Epoch: 15 [40320/110534 (36%)]\tClassification Loss: 1.5824\r\n",
      "Train Epoch: 15 [40960/110534 (37%)]\tClassification Loss: 1.3005\r\n",
      "Train Epoch: 15 [41600/110534 (38%)]\tClassification Loss: 1.3328\r\n",
      "Train Epoch: 15 [42240/110534 (38%)]\tClassification Loss: 1.4190\r\n",
      "Train Epoch: 15 [42880/110534 (39%)]\tClassification Loss: 1.4569\r\n",
      "Train Epoch: 15 [43520/110534 (39%)]\tClassification Loss: 1.3814\r\n",
      "Train Epoch: 15 [44160/110534 (40%)]\tClassification Loss: 1.5554\r\n",
      "Train Epoch: 15 [44800/110534 (41%)]\tClassification Loss: 1.6559\r\n",
      "Train Epoch: 15 [45440/110534 (41%)]\tClassification Loss: 1.6671\r\n",
      "Train Epoch: 15 [46080/110534 (42%)]\tClassification Loss: 1.3833\r\n",
      "Train Epoch: 15 [46720/110534 (42%)]\tClassification Loss: 1.5741\r\n",
      "Train Epoch: 15 [47360/110534 (43%)]\tClassification Loss: 1.5454\r\n",
      "Train Epoch: 15 [48000/110534 (43%)]\tClassification Loss: 1.5953\r\n",
      "Train Epoch: 15 [48640/110534 (44%)]\tClassification Loss: 1.4438\r\n",
      "Train Epoch: 15 [49280/110534 (45%)]\tClassification Loss: 1.5458\r\n",
      "Train Epoch: 15 [49920/110534 (45%)]\tClassification Loss: 1.5153\r\n",
      "Train Epoch: 15 [50560/110534 (46%)]\tClassification Loss: 1.5330\r\n",
      "Train Epoch: 15 [51200/110534 (46%)]\tClassification Loss: 1.3164\r\n",
      "Train Epoch: 15 [51840/110534 (47%)]\tClassification Loss: 1.6241\r\n",
      "Train Epoch: 15 [52480/110534 (47%)]\tClassification Loss: 1.6276\r\n",
      "Train Epoch: 15 [53120/110534 (48%)]\tClassification Loss: 1.1405\r\n",
      "Train Epoch: 15 [53760/110534 (49%)]\tClassification Loss: 1.4822\r\n",
      "Train Epoch: 15 [54400/110534 (49%)]\tClassification Loss: 1.4951\r\n",
      "Train Epoch: 15 [55040/110534 (50%)]\tClassification Loss: 1.6720\r\n",
      "Train Epoch: 15 [55680/110534 (50%)]\tClassification Loss: 1.5977\r\n",
      "Train Epoch: 15 [56320/110534 (51%)]\tClassification Loss: 1.4513\r\n",
      "Train Epoch: 15 [56960/110534 (52%)]\tClassification Loss: 1.6129\r\n",
      "Train Epoch: 15 [57600/110534 (52%)]\tClassification Loss: 1.6374\r\n",
      "Train Epoch: 15 [58240/110534 (53%)]\tClassification Loss: 1.6351\r\n",
      "Train Epoch: 15 [58880/110534 (53%)]\tClassification Loss: 1.8081\r\n",
      "Train Epoch: 15 [59520/110534 (54%)]\tClassification Loss: 1.4930\r\n",
      "Train Epoch: 15 [60160/110534 (54%)]\tClassification Loss: 1.4549\r\n",
      "Train Epoch: 15 [60800/110534 (55%)]\tClassification Loss: 1.4397\r\n",
      "Train Epoch: 15 [61440/110534 (56%)]\tClassification Loss: 1.5047\r\n",
      "Train Epoch: 15 [62080/110534 (56%)]\tClassification Loss: 1.5523\r\n",
      "Train Epoch: 15 [62720/110534 (57%)]\tClassification Loss: 1.6617\r\n",
      "Train Epoch: 15 [63360/110534 (57%)]\tClassification Loss: 1.2429\r\n",
      "Train Epoch: 15 [64000/110534 (58%)]\tClassification Loss: 1.6040\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_15_1000.pth.tar\r\n",
      "Train Epoch: 15 [64640/110534 (58%)]\tClassification Loss: 1.2406\r\n",
      "Train Epoch: 15 [65280/110534 (59%)]\tClassification Loss: 1.5231\r\n",
      "Train Epoch: 15 [65920/110534 (60%)]\tClassification Loss: 1.6471\r\n",
      "Train Epoch: 15 [66560/110534 (60%)]\tClassification Loss: 1.1916\r\n",
      "Train Epoch: 15 [67200/110534 (61%)]\tClassification Loss: 1.2652\r\n",
      "Train Epoch: 15 [67840/110534 (61%)]\tClassification Loss: 1.7994\r\n",
      "Train Epoch: 15 [68480/110534 (62%)]\tClassification Loss: 1.7459\r\n",
      "Train Epoch: 15 [69120/110534 (63%)]\tClassification Loss: 1.7886\r\n",
      "Train Epoch: 15 [69760/110534 (63%)]\tClassification Loss: 1.6232\r\n",
      "Train Epoch: 15 [70400/110534 (64%)]\tClassification Loss: 1.2702\r\n",
      "Train Epoch: 15 [71040/110534 (64%)]\tClassification Loss: 1.8782\r\n",
      "Train Epoch: 15 [71680/110534 (65%)]\tClassification Loss: 1.4075\r\n",
      "Train Epoch: 15 [72320/110534 (65%)]\tClassification Loss: 1.5642\r\n",
      "Train Epoch: 15 [72960/110534 (66%)]\tClassification Loss: 1.7947\r\n",
      "Train Epoch: 15 [73600/110534 (67%)]\tClassification Loss: 1.7537\r\n",
      "Train Epoch: 15 [74240/110534 (67%)]\tClassification Loss: 1.6908\r\n",
      "Train Epoch: 15 [74880/110534 (68%)]\tClassification Loss: 1.1733\r\n",
      "Train Epoch: 15 [75520/110534 (68%)]\tClassification Loss: 1.5748\r\n",
      "Train Epoch: 15 [76160/110534 (69%)]\tClassification Loss: 1.3712\r\n",
      "Train Epoch: 15 [76800/110534 (69%)]\tClassification Loss: 1.3395\r\n",
      "Train Epoch: 15 [77440/110534 (70%)]\tClassification Loss: 1.5154\r\n",
      "Train Epoch: 15 [78080/110534 (71%)]\tClassification Loss: 1.5167\r\n",
      "Train Epoch: 15 [78720/110534 (71%)]\tClassification Loss: 1.3486\r\n",
      "Train Epoch: 15 [79360/110534 (72%)]\tClassification Loss: 1.3869\r\n",
      "Train Epoch: 15 [80000/110534 (72%)]\tClassification Loss: 1.3667\r\n",
      "Train Epoch: 15 [80640/110534 (73%)]\tClassification Loss: 1.4985\r\n",
      "Train Epoch: 15 [81280/110534 (74%)]\tClassification Loss: 1.8106\r\n",
      "Train Epoch: 15 [81920/110534 (74%)]\tClassification Loss: 1.4827\r\n",
      "Train Epoch: 15 [82560/110534 (75%)]\tClassification Loss: 1.7208\r\n",
      "Train Epoch: 15 [83200/110534 (75%)]\tClassification Loss: 1.4313\r\n",
      "Train Epoch: 15 [83840/110534 (76%)]\tClassification Loss: 1.8134\r\n",
      "Train Epoch: 15 [84480/110534 (76%)]\tClassification Loss: 1.7318\r\n",
      "Train Epoch: 15 [85120/110534 (77%)]\tClassification Loss: 1.4189\r\n",
      "Train Epoch: 15 [85760/110534 (78%)]\tClassification Loss: 1.4367\r\n",
      "Train Epoch: 15 [86400/110534 (78%)]\tClassification Loss: 1.6567\r\n",
      "Train Epoch: 15 [87040/110534 (79%)]\tClassification Loss: 1.5117\r\n",
      "Train Epoch: 15 [87680/110534 (79%)]\tClassification Loss: 1.3864\r\n",
      "Train Epoch: 15 [88320/110534 (80%)]\tClassification Loss: 1.4675\r\n",
      "Train Epoch: 15 [88960/110534 (80%)]\tClassification Loss: 1.6615\r\n",
      "Train Epoch: 15 [89600/110534 (81%)]\tClassification Loss: 1.7716\r\n",
      "Train Epoch: 15 [90240/110534 (82%)]\tClassification Loss: 1.7801\r\n",
      "Train Epoch: 15 [90880/110534 (82%)]\tClassification Loss: 1.6623\r\n",
      "Train Epoch: 15 [91520/110534 (83%)]\tClassification Loss: 1.3287\r\n",
      "Train Epoch: 15 [92160/110534 (83%)]\tClassification Loss: 1.3519\r\n",
      "Train Epoch: 15 [92800/110534 (84%)]\tClassification Loss: 1.4864\r\n",
      "Train Epoch: 15 [93440/110534 (85%)]\tClassification Loss: 1.8062\r\n",
      "Train Epoch: 15 [94080/110534 (85%)]\tClassification Loss: 1.5708\r\n",
      "Train Epoch: 15 [94720/110534 (86%)]\tClassification Loss: 1.3451\r\n",
      "Train Epoch: 15 [95360/110534 (86%)]\tClassification Loss: 1.3823\r\n",
      "Train Epoch: 15 [96000/110534 (87%)]\tClassification Loss: 1.4027\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_15_1500.pth.tar\r\n",
      "Train Epoch: 15 [96640/110534 (87%)]\tClassification Loss: 1.3554\r\n",
      "Train Epoch: 15 [97280/110534 (88%)]\tClassification Loss: 1.3284\r\n",
      "Train Epoch: 15 [97920/110534 (89%)]\tClassification Loss: 1.1401\r\n",
      "Train Epoch: 15 [98560/110534 (89%)]\tClassification Loss: 1.5107\r\n",
      "Train Epoch: 15 [99200/110534 (90%)]\tClassification Loss: 1.6113\r\n",
      "Train Epoch: 15 [99840/110534 (90%)]\tClassification Loss: 1.4692\r\n",
      "Train Epoch: 15 [100480/110534 (91%)]\tClassification Loss: 1.6207\r\n",
      "Train Epoch: 15 [101120/110534 (91%)]\tClassification Loss: 1.5103\r\n",
      "Train Epoch: 15 [101760/110534 (92%)]\tClassification Loss: 1.4883\r\n",
      "Train Epoch: 15 [102400/110534 (93%)]\tClassification Loss: 1.5387\r\n",
      "Train Epoch: 15 [103040/110534 (93%)]\tClassification Loss: 1.3340\r\n",
      "Train Epoch: 15 [103680/110534 (94%)]\tClassification Loss: 1.6283\r\n",
      "Train Epoch: 15 [104320/110534 (94%)]\tClassification Loss: 1.4743\r\n",
      "Train Epoch: 15 [104960/110534 (95%)]\tClassification Loss: 1.5138\r\n",
      "Train Epoch: 15 [105600/110534 (96%)]\tClassification Loss: 1.5033\r\n",
      "Train Epoch: 15 [106240/110534 (96%)]\tClassification Loss: 1.3417\r\n",
      "Train Epoch: 15 [106880/110534 (97%)]\tClassification Loss: 1.6767\r\n",
      "Train Epoch: 15 [107520/110534 (97%)]\tClassification Loss: 1.4824\r\n",
      "Train Epoch: 15 [108160/110534 (98%)]\tClassification Loss: 1.5694\r\n",
      "Train Epoch: 15 [108800/110534 (98%)]\tClassification Loss: 1.5652\r\n",
      "Train Epoch: 15 [109440/110534 (99%)]\tClassification Loss: 1.4279\r\n",
      "Train Epoch: 15 [110080/110534 (100%)]\tClassification Loss: 1.3903\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_15_final.pth.tar\r\n",
      "Train Epoch: 16 [0/110534 (0%)]\tClassification Loss: 1.5277\r\n",
      "\r\n",
      "Test set: Average loss: 1.4268, Accuracy: 23060/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 16 [640/110534 (1%)]\tClassification Loss: 1.3355\r\n",
      "Train Epoch: 16 [1280/110534 (1%)]\tClassification Loss: 1.9720\r\n",
      "Train Epoch: 16 [1920/110534 (2%)]\tClassification Loss: 1.6913\r\n",
      "Train Epoch: 16 [2560/110534 (2%)]\tClassification Loss: 1.7980\r\n",
      "Train Epoch: 16 [3200/110534 (3%)]\tClassification Loss: 1.5528\r\n",
      "Train Epoch: 16 [3840/110534 (3%)]\tClassification Loss: 1.3851\r\n",
      "Train Epoch: 16 [4480/110534 (4%)]\tClassification Loss: 1.3215\r\n",
      "Train Epoch: 16 [5120/110534 (5%)]\tClassification Loss: 1.5885\r\n",
      "Train Epoch: 16 [5760/110534 (5%)]\tClassification Loss: 1.5335\r\n",
      "Train Epoch: 16 [6400/110534 (6%)]\tClassification Loss: 1.3758\r\n",
      "Train Epoch: 16 [7040/110534 (6%)]\tClassification Loss: 1.5280\r\n",
      "Train Epoch: 16 [7680/110534 (7%)]\tClassification Loss: 1.6822\r\n",
      "Train Epoch: 16 [8320/110534 (8%)]\tClassification Loss: 1.8177\r\n",
      "Train Epoch: 16 [8960/110534 (8%)]\tClassification Loss: 1.6796\r\n",
      "Train Epoch: 16 [9600/110534 (9%)]\tClassification Loss: 1.3938\r\n",
      "Train Epoch: 16 [10240/110534 (9%)]\tClassification Loss: 1.7351\r\n",
      "Train Epoch: 16 [10880/110534 (10%)]\tClassification Loss: 1.3884\r\n",
      "Train Epoch: 16 [11520/110534 (10%)]\tClassification Loss: 1.6174\r\n",
      "Train Epoch: 16 [12160/110534 (11%)]\tClassification Loss: 1.3784\r\n",
      "Train Epoch: 16 [12800/110534 (12%)]\tClassification Loss: 1.6732\r\n",
      "Train Epoch: 16 [13440/110534 (12%)]\tClassification Loss: 1.5846\r\n",
      "Train Epoch: 16 [14080/110534 (13%)]\tClassification Loss: 1.6834\r\n",
      "Train Epoch: 16 [14720/110534 (13%)]\tClassification Loss: 1.8115\r\n",
      "Train Epoch: 16 [15360/110534 (14%)]\tClassification Loss: 1.4008\r\n",
      "Train Epoch: 16 [16000/110534 (14%)]\tClassification Loss: 1.4488\r\n",
      "Train Epoch: 16 [16640/110534 (15%)]\tClassification Loss: 1.5738\r\n",
      "Train Epoch: 16 [17280/110534 (16%)]\tClassification Loss: 1.6727\r\n",
      "Train Epoch: 16 [17920/110534 (16%)]\tClassification Loss: 1.6412\r\n",
      "Train Epoch: 16 [18560/110534 (17%)]\tClassification Loss: 1.6838\r\n",
      "Train Epoch: 16 [19200/110534 (17%)]\tClassification Loss: 1.6524\r\n",
      "Train Epoch: 16 [19840/110534 (18%)]\tClassification Loss: 1.5798\r\n",
      "Train Epoch: 16 [20480/110534 (19%)]\tClassification Loss: 1.7413\r\n",
      "Train Epoch: 16 [21120/110534 (19%)]\tClassification Loss: 1.6450\r\n",
      "Train Epoch: 16 [21760/110534 (20%)]\tClassification Loss: 1.4206\r\n",
      "Train Epoch: 16 [22400/110534 (20%)]\tClassification Loss: 1.5115\r\n",
      "Train Epoch: 16 [23040/110534 (21%)]\tClassification Loss: 1.0544\r\n",
      "Train Epoch: 16 [23680/110534 (21%)]\tClassification Loss: 1.6190\r\n",
      "Train Epoch: 16 [24320/110534 (22%)]\tClassification Loss: 1.3143\r\n",
      "Train Epoch: 16 [24960/110534 (23%)]\tClassification Loss: 1.9102\r\n",
      "Train Epoch: 16 [25600/110534 (23%)]\tClassification Loss: 1.2619\r\n",
      "Train Epoch: 16 [26240/110534 (24%)]\tClassification Loss: 1.3875\r\n",
      "Train Epoch: 16 [26880/110534 (24%)]\tClassification Loss: 1.6145\r\n",
      "Train Epoch: 16 [27520/110534 (25%)]\tClassification Loss: 1.3796\r\n",
      "Train Epoch: 16 [28160/110534 (25%)]\tClassification Loss: 1.7782\r\n",
      "Train Epoch: 16 [28800/110534 (26%)]\tClassification Loss: 1.7823\r\n",
      "Train Epoch: 16 [29440/110534 (27%)]\tClassification Loss: 1.6053\r\n",
      "Train Epoch: 16 [30080/110534 (27%)]\tClassification Loss: 1.8129\r\n",
      "Train Epoch: 16 [30720/110534 (28%)]\tClassification Loss: 1.3798\r\n",
      "Train Epoch: 16 [31360/110534 (28%)]\tClassification Loss: 1.7156\r\n",
      "Train Epoch: 16 [32000/110534 (29%)]\tClassification Loss: 1.4889\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_16_500.pth.tar\r\n",
      "Train Epoch: 16 [32640/110534 (30%)]\tClassification Loss: 1.3078\r\n",
      "Train Epoch: 16 [33280/110534 (30%)]\tClassification Loss: 1.5253\r\n",
      "Train Epoch: 16 [33920/110534 (31%)]\tClassification Loss: 1.4379\r\n",
      "Train Epoch: 16 [34560/110534 (31%)]\tClassification Loss: 1.6705\r\n",
      "Train Epoch: 16 [35200/110534 (32%)]\tClassification Loss: 1.4168\r\n",
      "Train Epoch: 16 [35840/110534 (32%)]\tClassification Loss: 1.2247\r\n",
      "Train Epoch: 16 [36480/110534 (33%)]\tClassification Loss: 1.4264\r\n",
      "Train Epoch: 16 [37120/110534 (34%)]\tClassification Loss: 1.5894\r\n",
      "Train Epoch: 16 [37760/110534 (34%)]\tClassification Loss: 1.8459\r\n",
      "Train Epoch: 16 [38400/110534 (35%)]\tClassification Loss: 1.3354\r\n",
      "Train Epoch: 16 [39040/110534 (35%)]\tClassification Loss: 1.5653\r\n",
      "Train Epoch: 16 [39680/110534 (36%)]\tClassification Loss: 1.5706\r\n",
      "Train Epoch: 16 [40320/110534 (36%)]\tClassification Loss: 1.3740\r\n",
      "Train Epoch: 16 [40960/110534 (37%)]\tClassification Loss: 1.3856\r\n",
      "Train Epoch: 16 [41600/110534 (38%)]\tClassification Loss: 1.4039\r\n",
      "Train Epoch: 16 [42240/110534 (38%)]\tClassification Loss: 1.3880\r\n",
      "Train Epoch: 16 [42880/110534 (39%)]\tClassification Loss: 1.4994\r\n",
      "Train Epoch: 16 [43520/110534 (39%)]\tClassification Loss: 1.3187\r\n",
      "Train Epoch: 16 [44160/110534 (40%)]\tClassification Loss: 1.4724\r\n",
      "Train Epoch: 16 [44800/110534 (41%)]\tClassification Loss: 1.5955\r\n",
      "Train Epoch: 16 [45440/110534 (41%)]\tClassification Loss: 1.5580\r\n",
      "Train Epoch: 16 [46080/110534 (42%)]\tClassification Loss: 1.4044\r\n",
      "Train Epoch: 16 [46720/110534 (42%)]\tClassification Loss: 1.4302\r\n",
      "Train Epoch: 16 [47360/110534 (43%)]\tClassification Loss: 1.4466\r\n",
      "Train Epoch: 16 [48000/110534 (43%)]\tClassification Loss: 1.6601\r\n",
      "Train Epoch: 16 [48640/110534 (44%)]\tClassification Loss: 1.4574\r\n",
      "Train Epoch: 16 [49280/110534 (45%)]\tClassification Loss: 1.4918\r\n",
      "Train Epoch: 16 [49920/110534 (45%)]\tClassification Loss: 1.5318\r\n",
      "Train Epoch: 16 [50560/110534 (46%)]\tClassification Loss: 1.4305\r\n",
      "Train Epoch: 16 [51200/110534 (46%)]\tClassification Loss: 1.3912\r\n",
      "Train Epoch: 16 [51840/110534 (47%)]\tClassification Loss: 1.5996\r\n",
      "Train Epoch: 16 [52480/110534 (47%)]\tClassification Loss: 1.4943\r\n",
      "Train Epoch: 16 [53120/110534 (48%)]\tClassification Loss: 1.1533\r\n",
      "Train Epoch: 16 [53760/110534 (49%)]\tClassification Loss: 1.6751\r\n",
      "Train Epoch: 16 [54400/110534 (49%)]\tClassification Loss: 1.5054\r\n",
      "Train Epoch: 16 [55040/110534 (50%)]\tClassification Loss: 1.5791\r\n",
      "Train Epoch: 16 [55680/110534 (50%)]\tClassification Loss: 1.5534\r\n",
      "Train Epoch: 16 [56320/110534 (51%)]\tClassification Loss: 1.5217\r\n",
      "Train Epoch: 16 [56960/110534 (52%)]\tClassification Loss: 1.4979\r\n",
      "Train Epoch: 16 [57600/110534 (52%)]\tClassification Loss: 1.5859\r\n",
      "Train Epoch: 16 [58240/110534 (53%)]\tClassification Loss: 1.5964\r\n",
      "Train Epoch: 16 [58880/110534 (53%)]\tClassification Loss: 1.8497\r\n",
      "Train Epoch: 16 [59520/110534 (54%)]\tClassification Loss: 1.3625\r\n",
      "Train Epoch: 16 [60160/110534 (54%)]\tClassification Loss: 1.4176\r\n",
      "Train Epoch: 16 [60800/110534 (55%)]\tClassification Loss: 1.5619\r\n",
      "Train Epoch: 16 [61440/110534 (56%)]\tClassification Loss: 1.4262\r\n",
      "Train Epoch: 16 [62080/110534 (56%)]\tClassification Loss: 1.5945\r\n",
      "Train Epoch: 16 [62720/110534 (57%)]\tClassification Loss: 1.6880\r\n",
      "Train Epoch: 16 [63360/110534 (57%)]\tClassification Loss: 1.3561\r\n",
      "Train Epoch: 16 [64000/110534 (58%)]\tClassification Loss: 1.6655\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_16_1000.pth.tar\r\n",
      "Train Epoch: 16 [64640/110534 (58%)]\tClassification Loss: 1.1052\r\n",
      "Train Epoch: 16 [65280/110534 (59%)]\tClassification Loss: 1.4429\r\n",
      "Train Epoch: 16 [65920/110534 (60%)]\tClassification Loss: 1.5615\r\n",
      "Train Epoch: 16 [66560/110534 (60%)]\tClassification Loss: 1.4756\r\n",
      "Train Epoch: 16 [67200/110534 (61%)]\tClassification Loss: 1.3070\r\n",
      "Train Epoch: 16 [67840/110534 (61%)]\tClassification Loss: 1.8427\r\n",
      "Train Epoch: 16 [68480/110534 (62%)]\tClassification Loss: 1.5697\r\n",
      "Train Epoch: 16 [69120/110534 (63%)]\tClassification Loss: 1.8104\r\n",
      "Train Epoch: 16 [69760/110534 (63%)]\tClassification Loss: 1.5485\r\n",
      "Train Epoch: 16 [70400/110534 (64%)]\tClassification Loss: 1.1773\r\n",
      "Train Epoch: 16 [71040/110534 (64%)]\tClassification Loss: 1.8841\r\n",
      "Train Epoch: 16 [71680/110534 (65%)]\tClassification Loss: 1.5503\r\n",
      "Train Epoch: 16 [72320/110534 (65%)]\tClassification Loss: 1.7375\r\n",
      "Train Epoch: 16 [72960/110534 (66%)]\tClassification Loss: 1.7499\r\n",
      "Train Epoch: 16 [73600/110534 (67%)]\tClassification Loss: 1.7145\r\n",
      "Train Epoch: 16 [74240/110534 (67%)]\tClassification Loss: 1.7353\r\n",
      "Train Epoch: 16 [74880/110534 (68%)]\tClassification Loss: 1.1501\r\n",
      "Train Epoch: 16 [75520/110534 (68%)]\tClassification Loss: 1.4976\r\n",
      "Train Epoch: 16 [76160/110534 (69%)]\tClassification Loss: 1.4247\r\n",
      "Train Epoch: 16 [76800/110534 (69%)]\tClassification Loss: 1.2943\r\n",
      "Train Epoch: 16 [77440/110534 (70%)]\tClassification Loss: 1.2720\r\n",
      "Train Epoch: 16 [78080/110534 (71%)]\tClassification Loss: 1.3455\r\n",
      "Train Epoch: 16 [78720/110534 (71%)]\tClassification Loss: 1.4871\r\n",
      "Train Epoch: 16 [79360/110534 (72%)]\tClassification Loss: 1.3712\r\n",
      "Train Epoch: 16 [80000/110534 (72%)]\tClassification Loss: 1.4379\r\n",
      "Train Epoch: 16 [80640/110534 (73%)]\tClassification Loss: 1.4672\r\n",
      "Train Epoch: 16 [81280/110534 (74%)]\tClassification Loss: 1.8329\r\n",
      "Train Epoch: 16 [81920/110534 (74%)]\tClassification Loss: 1.5496\r\n",
      "Train Epoch: 16 [82560/110534 (75%)]\tClassification Loss: 1.8017\r\n",
      "Train Epoch: 16 [83200/110534 (75%)]\tClassification Loss: 1.4081\r\n",
      "Train Epoch: 16 [83840/110534 (76%)]\tClassification Loss: 1.8643\r\n",
      "Train Epoch: 16 [84480/110534 (76%)]\tClassification Loss: 1.6730\r\n",
      "Train Epoch: 16 [85120/110534 (77%)]\tClassification Loss: 1.3841\r\n",
      "Train Epoch: 16 [85760/110534 (78%)]\tClassification Loss: 1.5310\r\n",
      "Train Epoch: 16 [86400/110534 (78%)]\tClassification Loss: 1.8081\r\n",
      "Train Epoch: 16 [87040/110534 (79%)]\tClassification Loss: 1.5018\r\n",
      "Train Epoch: 16 [87680/110534 (79%)]\tClassification Loss: 1.3226\r\n",
      "Train Epoch: 16 [88320/110534 (80%)]\tClassification Loss: 1.5161\r\n",
      "Train Epoch: 16 [88960/110534 (80%)]\tClassification Loss: 1.6956\r\n",
      "Train Epoch: 16 [89600/110534 (81%)]\tClassification Loss: 1.7979\r\n",
      "Train Epoch: 16 [90240/110534 (82%)]\tClassification Loss: 1.7883\r\n",
      "Train Epoch: 16 [90880/110534 (82%)]\tClassification Loss: 1.5426\r\n",
      "Train Epoch: 16 [91520/110534 (83%)]\tClassification Loss: 1.3456\r\n",
      "Train Epoch: 16 [92160/110534 (83%)]\tClassification Loss: 1.4451\r\n",
      "Train Epoch: 16 [92800/110534 (84%)]\tClassification Loss: 1.5042\r\n",
      "Train Epoch: 16 [93440/110534 (85%)]\tClassification Loss: 1.8917\r\n",
      "Train Epoch: 16 [94080/110534 (85%)]\tClassification Loss: 1.5631\r\n",
      "Train Epoch: 16 [94720/110534 (86%)]\tClassification Loss: 1.2983\r\n",
      "Train Epoch: 16 [95360/110534 (86%)]\tClassification Loss: 1.5562\r\n",
      "Train Epoch: 16 [96000/110534 (87%)]\tClassification Loss: 1.5018\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_16_1500.pth.tar\r\n",
      "Train Epoch: 16 [96640/110534 (87%)]\tClassification Loss: 1.5115\r\n",
      "Train Epoch: 16 [97280/110534 (88%)]\tClassification Loss: 1.3417\r\n",
      "Train Epoch: 16 [97920/110534 (89%)]\tClassification Loss: 1.2161\r\n",
      "Train Epoch: 16 [98560/110534 (89%)]\tClassification Loss: 1.3239\r\n",
      "Train Epoch: 16 [99200/110534 (90%)]\tClassification Loss: 1.7102\r\n",
      "Train Epoch: 16 [99840/110534 (90%)]\tClassification Loss: 1.4713\r\n",
      "Train Epoch: 16 [100480/110534 (91%)]\tClassification Loss: 1.6487\r\n",
      "Train Epoch: 16 [101120/110534 (91%)]\tClassification Loss: 1.4691\r\n",
      "Train Epoch: 16 [101760/110534 (92%)]\tClassification Loss: 1.5798\r\n",
      "Train Epoch: 16 [102400/110534 (93%)]\tClassification Loss: 1.5530\r\n",
      "Train Epoch: 16 [103040/110534 (93%)]\tClassification Loss: 1.4131\r\n",
      "Train Epoch: 16 [103680/110534 (94%)]\tClassification Loss: 1.6842\r\n",
      "Train Epoch: 16 [104320/110534 (94%)]\tClassification Loss: 1.4811\r\n",
      "Train Epoch: 16 [104960/110534 (95%)]\tClassification Loss: 1.5762\r\n",
      "Train Epoch: 16 [105600/110534 (96%)]\tClassification Loss: 1.4074\r\n",
      "Train Epoch: 16 [106240/110534 (96%)]\tClassification Loss: 1.1591\r\n",
      "Train Epoch: 16 [106880/110534 (97%)]\tClassification Loss: 1.7020\r\n",
      "Train Epoch: 16 [107520/110534 (97%)]\tClassification Loss: 1.6387\r\n",
      "Train Epoch: 16 [108160/110534 (98%)]\tClassification Loss: 1.6291\r\n",
      "Train Epoch: 16 [108800/110534 (98%)]\tClassification Loss: 1.6185\r\n",
      "Train Epoch: 16 [109440/110534 (99%)]\tClassification Loss: 1.3910\r\n",
      "Train Epoch: 16 [110080/110534 (100%)]\tClassification Loss: 1.4076\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_16_final.pth.tar\r\n",
      "Train Epoch: 17 [0/110534 (0%)]\tClassification Loss: 1.4829\r\n",
      "\r\n",
      "Test set: Average loss: 1.4254, Accuracy: 23039/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 17 [640/110534 (1%)]\tClassification Loss: 1.3808\r\n",
      "Train Epoch: 17 [1280/110534 (1%)]\tClassification Loss: 1.8631\r\n",
      "Train Epoch: 17 [1920/110534 (2%)]\tClassification Loss: 1.6445\r\n",
      "Train Epoch: 17 [2560/110534 (2%)]\tClassification Loss: 1.7646\r\n",
      "Train Epoch: 17 [3200/110534 (3%)]\tClassification Loss: 1.4729\r\n",
      "Train Epoch: 17 [3840/110534 (3%)]\tClassification Loss: 1.3545\r\n",
      "Train Epoch: 17 [4480/110534 (4%)]\tClassification Loss: 1.5113\r\n",
      "Train Epoch: 17 [5120/110534 (5%)]\tClassification Loss: 1.6500\r\n",
      "Train Epoch: 17 [5760/110534 (5%)]\tClassification Loss: 1.4691\r\n",
      "Train Epoch: 17 [6400/110534 (6%)]\tClassification Loss: 1.3817\r\n",
      "Train Epoch: 17 [7040/110534 (6%)]\tClassification Loss: 1.5413\r\n",
      "Train Epoch: 17 [7680/110534 (7%)]\tClassification Loss: 1.4142\r\n",
      "Train Epoch: 17 [8320/110534 (8%)]\tClassification Loss: 1.6497\r\n",
      "Train Epoch: 17 [8960/110534 (8%)]\tClassification Loss: 1.6508\r\n",
      "Train Epoch: 17 [9600/110534 (9%)]\tClassification Loss: 1.4383\r\n",
      "Train Epoch: 17 [10240/110534 (9%)]\tClassification Loss: 1.5548\r\n",
      "Train Epoch: 17 [10880/110534 (10%)]\tClassification Loss: 1.4910\r\n",
      "Train Epoch: 17 [11520/110534 (10%)]\tClassification Loss: 1.6772\r\n",
      "Train Epoch: 17 [12160/110534 (11%)]\tClassification Loss: 1.3528\r\n",
      "Train Epoch: 17 [12800/110534 (12%)]\tClassification Loss: 1.5123\r\n",
      "Train Epoch: 17 [13440/110534 (12%)]\tClassification Loss: 1.4603\r\n",
      "Train Epoch: 17 [14080/110534 (13%)]\tClassification Loss: 1.7550\r\n",
      "Train Epoch: 17 [14720/110534 (13%)]\tClassification Loss: 1.7335\r\n",
      "Train Epoch: 17 [15360/110534 (14%)]\tClassification Loss: 1.6230\r\n",
      "Train Epoch: 17 [16000/110534 (14%)]\tClassification Loss: 1.6412\r\n",
      "Train Epoch: 17 [16640/110534 (15%)]\tClassification Loss: 1.4861\r\n",
      "Train Epoch: 17 [17280/110534 (16%)]\tClassification Loss: 1.6098\r\n",
      "Train Epoch: 17 [17920/110534 (16%)]\tClassification Loss: 1.6600\r\n",
      "Train Epoch: 17 [18560/110534 (17%)]\tClassification Loss: 1.8568\r\n",
      "Train Epoch: 17 [19200/110534 (17%)]\tClassification Loss: 1.5352\r\n",
      "Train Epoch: 17 [19840/110534 (18%)]\tClassification Loss: 1.6288\r\n",
      "Train Epoch: 17 [20480/110534 (19%)]\tClassification Loss: 1.9357\r\n",
      "Train Epoch: 17 [21120/110534 (19%)]\tClassification Loss: 1.6306\r\n",
      "Train Epoch: 17 [21760/110534 (20%)]\tClassification Loss: 1.2346\r\n",
      "Train Epoch: 17 [22400/110534 (20%)]\tClassification Loss: 1.5611\r\n",
      "Train Epoch: 17 [23040/110534 (21%)]\tClassification Loss: 1.1655\r\n",
      "Train Epoch: 17 [23680/110534 (21%)]\tClassification Loss: 1.6929\r\n",
      "Train Epoch: 17 [24320/110534 (22%)]\tClassification Loss: 1.2473\r\n",
      "Train Epoch: 17 [24960/110534 (23%)]\tClassification Loss: 1.7565\r\n",
      "Train Epoch: 17 [25600/110534 (23%)]\tClassification Loss: 1.3748\r\n",
      "Train Epoch: 17 [26240/110534 (24%)]\tClassification Loss: 1.4814\r\n",
      "Train Epoch: 17 [26880/110534 (24%)]\tClassification Loss: 1.7949\r\n",
      "Train Epoch: 17 [27520/110534 (25%)]\tClassification Loss: 1.4970\r\n",
      "Train Epoch: 17 [28160/110534 (25%)]\tClassification Loss: 1.7299\r\n",
      "Train Epoch: 17 [28800/110534 (26%)]\tClassification Loss: 1.9264\r\n",
      "Train Epoch: 17 [29440/110534 (27%)]\tClassification Loss: 1.7265\r\n",
      "Train Epoch: 17 [30080/110534 (27%)]\tClassification Loss: 1.9056\r\n",
      "Train Epoch: 17 [30720/110534 (28%)]\tClassification Loss: 1.6041\r\n",
      "Train Epoch: 17 [31360/110534 (28%)]\tClassification Loss: 1.5070\r\n",
      "Train Epoch: 17 [32000/110534 (29%)]\tClassification Loss: 1.4099\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_17_500.pth.tar\r\n",
      "Train Epoch: 17 [32640/110534 (30%)]\tClassification Loss: 1.3967\r\n",
      "Train Epoch: 17 [33280/110534 (30%)]\tClassification Loss: 1.5507\r\n",
      "Train Epoch: 17 [33920/110534 (31%)]\tClassification Loss: 1.6763\r\n",
      "Train Epoch: 17 [34560/110534 (31%)]\tClassification Loss: 1.6438\r\n",
      "Train Epoch: 17 [35200/110534 (32%)]\tClassification Loss: 1.4045\r\n",
      "Train Epoch: 17 [35840/110534 (32%)]\tClassification Loss: 1.3630\r\n",
      "Train Epoch: 17 [36480/110534 (33%)]\tClassification Loss: 1.5381\r\n",
      "Train Epoch: 17 [37120/110534 (34%)]\tClassification Loss: 1.4969\r\n",
      "Train Epoch: 17 [37760/110534 (34%)]\tClassification Loss: 1.9300\r\n",
      "Train Epoch: 17 [38400/110534 (35%)]\tClassification Loss: 1.5258\r\n",
      "Train Epoch: 17 [39040/110534 (35%)]\tClassification Loss: 1.4096\r\n",
      "Train Epoch: 17 [39680/110534 (36%)]\tClassification Loss: 1.5243\r\n",
      "Train Epoch: 17 [40320/110534 (36%)]\tClassification Loss: 1.5125\r\n",
      "Train Epoch: 17 [40960/110534 (37%)]\tClassification Loss: 1.3249\r\n",
      "Train Epoch: 17 [41600/110534 (38%)]\tClassification Loss: 1.5551\r\n",
      "Train Epoch: 17 [42240/110534 (38%)]\tClassification Loss: 1.5596\r\n",
      "Train Epoch: 17 [42880/110534 (39%)]\tClassification Loss: 1.4849\r\n",
      "Train Epoch: 17 [43520/110534 (39%)]\tClassification Loss: 1.4148\r\n",
      "Train Epoch: 17 [44160/110534 (40%)]\tClassification Loss: 1.5868\r\n",
      "Train Epoch: 17 [44800/110534 (41%)]\tClassification Loss: 1.7915\r\n",
      "Train Epoch: 17 [45440/110534 (41%)]\tClassification Loss: 1.5514\r\n",
      "Train Epoch: 17 [46080/110534 (42%)]\tClassification Loss: 1.3594\r\n",
      "Train Epoch: 17 [46720/110534 (42%)]\tClassification Loss: 1.5288\r\n",
      "Train Epoch: 17 [47360/110534 (43%)]\tClassification Loss: 1.3702\r\n",
      "Train Epoch: 17 [48000/110534 (43%)]\tClassification Loss: 1.5659\r\n",
      "Train Epoch: 17 [48640/110534 (44%)]\tClassification Loss: 1.4715\r\n",
      "Train Epoch: 17 [49280/110534 (45%)]\tClassification Loss: 1.5989\r\n",
      "Train Epoch: 17 [49920/110534 (45%)]\tClassification Loss: 1.7679\r\n",
      "Train Epoch: 17 [50560/110534 (46%)]\tClassification Loss: 1.6452\r\n",
      "Train Epoch: 17 [51200/110534 (46%)]\tClassification Loss: 1.4463\r\n",
      "Train Epoch: 17 [51840/110534 (47%)]\tClassification Loss: 1.5510\r\n",
      "Train Epoch: 17 [52480/110534 (47%)]\tClassification Loss: 1.5214\r\n",
      "Train Epoch: 17 [53120/110534 (48%)]\tClassification Loss: 1.0976\r\n",
      "Train Epoch: 17 [53760/110534 (49%)]\tClassification Loss: 1.5982\r\n",
      "Train Epoch: 17 [54400/110534 (49%)]\tClassification Loss: 1.4206\r\n",
      "Train Epoch: 17 [55040/110534 (50%)]\tClassification Loss: 1.6889\r\n",
      "Train Epoch: 17 [55680/110534 (50%)]\tClassification Loss: 1.7003\r\n",
      "Train Epoch: 17 [56320/110534 (51%)]\tClassification Loss: 1.4314\r\n",
      "Train Epoch: 17 [56960/110534 (52%)]\tClassification Loss: 1.4394\r\n",
      "Train Epoch: 17 [57600/110534 (52%)]\tClassification Loss: 1.7841\r\n",
      "Train Epoch: 17 [58240/110534 (53%)]\tClassification Loss: 1.6076\r\n",
      "Train Epoch: 17 [58880/110534 (53%)]\tClassification Loss: 1.7394\r\n",
      "Train Epoch: 17 [59520/110534 (54%)]\tClassification Loss: 1.3840\r\n",
      "Train Epoch: 17 [60160/110534 (54%)]\tClassification Loss: 1.4409\r\n",
      "Train Epoch: 17 [60800/110534 (55%)]\tClassification Loss: 1.5289\r\n",
      "Train Epoch: 17 [61440/110534 (56%)]\tClassification Loss: 1.4383\r\n",
      "Train Epoch: 17 [62080/110534 (56%)]\tClassification Loss: 1.4855\r\n",
      "Train Epoch: 17 [62720/110534 (57%)]\tClassification Loss: 1.7079\r\n",
      "Train Epoch: 17 [63360/110534 (57%)]\tClassification Loss: 1.2898\r\n",
      "Train Epoch: 17 [64000/110534 (58%)]\tClassification Loss: 1.5239\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_17_1000.pth.tar\r\n",
      "Train Epoch: 17 [64640/110534 (58%)]\tClassification Loss: 1.1992\r\n",
      "Train Epoch: 17 [65280/110534 (59%)]\tClassification Loss: 1.4508\r\n",
      "Train Epoch: 17 [65920/110534 (60%)]\tClassification Loss: 1.5102\r\n",
      "Train Epoch: 17 [66560/110534 (60%)]\tClassification Loss: 1.4080\r\n",
      "Train Epoch: 17 [67200/110534 (61%)]\tClassification Loss: 1.2517\r\n",
      "Train Epoch: 17 [67840/110534 (61%)]\tClassification Loss: 1.8872\r\n",
      "Train Epoch: 17 [68480/110534 (62%)]\tClassification Loss: 1.5177\r\n",
      "Train Epoch: 17 [69120/110534 (63%)]\tClassification Loss: 1.7372\r\n",
      "Train Epoch: 17 [69760/110534 (63%)]\tClassification Loss: 1.6866\r\n",
      "Train Epoch: 17 [70400/110534 (64%)]\tClassification Loss: 1.3723\r\n",
      "Train Epoch: 17 [71040/110534 (64%)]\tClassification Loss: 1.7883\r\n",
      "Train Epoch: 17 [71680/110534 (65%)]\tClassification Loss: 1.4581\r\n",
      "Train Epoch: 17 [72320/110534 (65%)]\tClassification Loss: 1.5286\r\n",
      "Train Epoch: 17 [72960/110534 (66%)]\tClassification Loss: 1.6501\r\n",
      "Train Epoch: 17 [73600/110534 (67%)]\tClassification Loss: 1.7128\r\n",
      "Train Epoch: 17 [74240/110534 (67%)]\tClassification Loss: 1.6025\r\n",
      "Train Epoch: 17 [74880/110534 (68%)]\tClassification Loss: 1.2006\r\n",
      "Train Epoch: 17 [75520/110534 (68%)]\tClassification Loss: 1.5288\r\n",
      "Train Epoch: 17 [76160/110534 (69%)]\tClassification Loss: 1.3813\r\n",
      "Train Epoch: 17 [76800/110534 (69%)]\tClassification Loss: 1.2678\r\n",
      "Train Epoch: 17 [77440/110534 (70%)]\tClassification Loss: 1.4682\r\n",
      "Train Epoch: 17 [78080/110534 (71%)]\tClassification Loss: 1.3479\r\n",
      "Train Epoch: 17 [78720/110534 (71%)]\tClassification Loss: 1.4525\r\n",
      "Train Epoch: 17 [79360/110534 (72%)]\tClassification Loss: 1.4021\r\n",
      "Train Epoch: 17 [80000/110534 (72%)]\tClassification Loss: 1.3237\r\n",
      "Train Epoch: 17 [80640/110534 (73%)]\tClassification Loss: 1.3605\r\n",
      "Train Epoch: 17 [81280/110534 (74%)]\tClassification Loss: 1.7566\r\n",
      "Train Epoch: 17 [81920/110534 (74%)]\tClassification Loss: 1.4194\r\n",
      "Train Epoch: 17 [82560/110534 (75%)]\tClassification Loss: 1.7606\r\n",
      "Train Epoch: 17 [83200/110534 (75%)]\tClassification Loss: 1.3709\r\n",
      "Train Epoch: 17 [83840/110534 (76%)]\tClassification Loss: 1.9032\r\n",
      "Train Epoch: 17 [84480/110534 (76%)]\tClassification Loss: 1.5605\r\n",
      "Train Epoch: 17 [85120/110534 (77%)]\tClassification Loss: 1.4406\r\n",
      "Train Epoch: 17 [85760/110534 (78%)]\tClassification Loss: 1.5963\r\n",
      "Train Epoch: 17 [86400/110534 (78%)]\tClassification Loss: 1.5244\r\n",
      "Train Epoch: 17 [87040/110534 (79%)]\tClassification Loss: 1.4863\r\n",
      "Train Epoch: 17 [87680/110534 (79%)]\tClassification Loss: 1.1935\r\n",
      "Train Epoch: 17 [88320/110534 (80%)]\tClassification Loss: 1.6224\r\n",
      "Train Epoch: 17 [88960/110534 (80%)]\tClassification Loss: 1.6499\r\n",
      "Train Epoch: 17 [89600/110534 (81%)]\tClassification Loss: 1.7542\r\n",
      "Train Epoch: 17 [90240/110534 (82%)]\tClassification Loss: 1.6719\r\n",
      "Train Epoch: 17 [90880/110534 (82%)]\tClassification Loss: 1.5563\r\n",
      "Train Epoch: 17 [91520/110534 (83%)]\tClassification Loss: 1.2003\r\n",
      "Train Epoch: 17 [92160/110534 (83%)]\tClassification Loss: 1.4314\r\n",
      "Train Epoch: 17 [92800/110534 (84%)]\tClassification Loss: 1.4414\r\n",
      "Train Epoch: 17 [93440/110534 (85%)]\tClassification Loss: 1.8028\r\n",
      "Train Epoch: 17 [94080/110534 (85%)]\tClassification Loss: 1.6458\r\n",
      "Train Epoch: 17 [94720/110534 (86%)]\tClassification Loss: 1.3584\r\n",
      "Train Epoch: 17 [95360/110534 (86%)]\tClassification Loss: 1.3738\r\n",
      "Train Epoch: 17 [96000/110534 (87%)]\tClassification Loss: 1.5293\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_17_1500.pth.tar\r\n",
      "Train Epoch: 17 [96640/110534 (87%)]\tClassification Loss: 1.2777\r\n",
      "Train Epoch: 17 [97280/110534 (88%)]\tClassification Loss: 1.0589\r\n",
      "Train Epoch: 17 [97920/110534 (89%)]\tClassification Loss: 1.2859\r\n",
      "Train Epoch: 17 [98560/110534 (89%)]\tClassification Loss: 1.3498\r\n",
      "Train Epoch: 17 [99200/110534 (90%)]\tClassification Loss: 1.7388\r\n",
      "Train Epoch: 17 [99840/110534 (90%)]\tClassification Loss: 1.3424\r\n",
      "Train Epoch: 17 [100480/110534 (91%)]\tClassification Loss: 1.8931\r\n",
      "Train Epoch: 17 [101120/110534 (91%)]\tClassification Loss: 1.4152\r\n",
      "Train Epoch: 17 [101760/110534 (92%)]\tClassification Loss: 1.5706\r\n",
      "Train Epoch: 17 [102400/110534 (93%)]\tClassification Loss: 1.4780\r\n",
      "Train Epoch: 17 [103040/110534 (93%)]\tClassification Loss: 1.4560\r\n",
      "Train Epoch: 17 [103680/110534 (94%)]\tClassification Loss: 1.6939\r\n",
      "Train Epoch: 17 [104320/110534 (94%)]\tClassification Loss: 1.5972\r\n",
      "Train Epoch: 17 [104960/110534 (95%)]\tClassification Loss: 1.5289\r\n",
      "Train Epoch: 17 [105600/110534 (96%)]\tClassification Loss: 1.3098\r\n",
      "Train Epoch: 17 [106240/110534 (96%)]\tClassification Loss: 1.1327\r\n",
      "Train Epoch: 17 [106880/110534 (97%)]\tClassification Loss: 1.5994\r\n",
      "Train Epoch: 17 [107520/110534 (97%)]\tClassification Loss: 1.6919\r\n",
      "Train Epoch: 17 [108160/110534 (98%)]\tClassification Loss: 1.5957\r\n",
      "Train Epoch: 17 [108800/110534 (98%)]\tClassification Loss: 1.7936\r\n",
      "Train Epoch: 17 [109440/110534 (99%)]\tClassification Loss: 1.4738\r\n",
      "Train Epoch: 17 [110080/110534 (100%)]\tClassification Loss: 1.4043\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_17_final.pth.tar\r\n",
      "Train Epoch: 18 [0/110534 (0%)]\tClassification Loss: 1.4566\r\n",
      "\r\n",
      "Test set: Average loss: 1.4268, Accuracy: 22972/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 18 [640/110534 (1%)]\tClassification Loss: 1.3683\r\n",
      "Train Epoch: 18 [1280/110534 (1%)]\tClassification Loss: 1.8444\r\n",
      "Train Epoch: 18 [1920/110534 (2%)]\tClassification Loss: 1.5703\r\n",
      "Train Epoch: 18 [2560/110534 (2%)]\tClassification Loss: 1.8496\r\n",
      "Train Epoch: 18 [3200/110534 (3%)]\tClassification Loss: 1.4703\r\n",
      "Train Epoch: 18 [3840/110534 (3%)]\tClassification Loss: 1.4272\r\n",
      "Train Epoch: 18 [4480/110534 (4%)]\tClassification Loss: 1.5818\r\n",
      "Train Epoch: 18 [5120/110534 (5%)]\tClassification Loss: 1.5956\r\n",
      "Train Epoch: 18 [5760/110534 (5%)]\tClassification Loss: 1.5061\r\n",
      "Train Epoch: 18 [6400/110534 (6%)]\tClassification Loss: 1.2827\r\n",
      "Train Epoch: 18 [7040/110534 (6%)]\tClassification Loss: 1.4053\r\n",
      "Train Epoch: 18 [7680/110534 (7%)]\tClassification Loss: 1.4572\r\n",
      "Train Epoch: 18 [8320/110534 (8%)]\tClassification Loss: 1.7012\r\n",
      "Train Epoch: 18 [8960/110534 (8%)]\tClassification Loss: 1.6453\r\n",
      "Train Epoch: 18 [9600/110534 (9%)]\tClassification Loss: 1.4858\r\n",
      "Train Epoch: 18 [10240/110534 (9%)]\tClassification Loss: 1.5220\r\n",
      "Train Epoch: 18 [10880/110534 (10%)]\tClassification Loss: 1.6569\r\n",
      "Train Epoch: 18 [11520/110534 (10%)]\tClassification Loss: 1.6096\r\n",
      "Train Epoch: 18 [12160/110534 (11%)]\tClassification Loss: 1.3467\r\n",
      "Train Epoch: 18 [12800/110534 (12%)]\tClassification Loss: 1.6867\r\n",
      "Train Epoch: 18 [13440/110534 (12%)]\tClassification Loss: 1.4950\r\n",
      "Train Epoch: 18 [14080/110534 (13%)]\tClassification Loss: 1.5827\r\n",
      "Train Epoch: 18 [14720/110534 (13%)]\tClassification Loss: 1.6722\r\n",
      "Train Epoch: 18 [15360/110534 (14%)]\tClassification Loss: 1.6227\r\n",
      "Train Epoch: 18 [16000/110534 (14%)]\tClassification Loss: 1.6569\r\n",
      "Train Epoch: 18 [16640/110534 (15%)]\tClassification Loss: 1.4206\r\n",
      "Train Epoch: 18 [17280/110534 (16%)]\tClassification Loss: 1.6800\r\n",
      "Train Epoch: 18 [17920/110534 (16%)]\tClassification Loss: 1.5592\r\n",
      "Train Epoch: 18 [18560/110534 (17%)]\tClassification Loss: 1.7354\r\n",
      "Train Epoch: 18 [19200/110534 (17%)]\tClassification Loss: 1.6269\r\n",
      "Train Epoch: 18 [19840/110534 (18%)]\tClassification Loss: 1.5741\r\n",
      "Train Epoch: 18 [20480/110534 (19%)]\tClassification Loss: 1.7756\r\n",
      "Train Epoch: 18 [21120/110534 (19%)]\tClassification Loss: 1.6949\r\n",
      "Train Epoch: 18 [21760/110534 (20%)]\tClassification Loss: 1.3188\r\n",
      "Train Epoch: 18 [22400/110534 (20%)]\tClassification Loss: 1.6381\r\n",
      "Train Epoch: 18 [23040/110534 (21%)]\tClassification Loss: 1.1336\r\n",
      "Train Epoch: 18 [23680/110534 (21%)]\tClassification Loss: 1.6494\r\n",
      "Train Epoch: 18 [24320/110534 (22%)]\tClassification Loss: 1.2561\r\n",
      "Train Epoch: 18 [24960/110534 (23%)]\tClassification Loss: 1.8035\r\n",
      "Train Epoch: 18 [25600/110534 (23%)]\tClassification Loss: 1.2940\r\n",
      "Train Epoch: 18 [26240/110534 (24%)]\tClassification Loss: 1.3282\r\n",
      "Train Epoch: 18 [26880/110534 (24%)]\tClassification Loss: 1.6901\r\n",
      "Train Epoch: 18 [27520/110534 (25%)]\tClassification Loss: 1.3185\r\n",
      "Train Epoch: 18 [28160/110534 (25%)]\tClassification Loss: 1.8512\r\n",
      "Train Epoch: 18 [28800/110534 (26%)]\tClassification Loss: 1.9734\r\n",
      "Train Epoch: 18 [29440/110534 (27%)]\tClassification Loss: 1.6292\r\n",
      "Train Epoch: 18 [30080/110534 (27%)]\tClassification Loss: 1.7859\r\n",
      "Train Epoch: 18 [30720/110534 (28%)]\tClassification Loss: 1.2818\r\n",
      "Train Epoch: 18 [31360/110534 (28%)]\tClassification Loss: 1.6586\r\n",
      "Train Epoch: 18 [32000/110534 (29%)]\tClassification Loss: 1.4115\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_18_500.pth.tar\r\n",
      "Train Epoch: 18 [32640/110534 (30%)]\tClassification Loss: 1.4249\r\n",
      "Train Epoch: 18 [33280/110534 (30%)]\tClassification Loss: 1.6212\r\n",
      "Train Epoch: 18 [33920/110534 (31%)]\tClassification Loss: 1.5533\r\n",
      "Train Epoch: 18 [34560/110534 (31%)]\tClassification Loss: 1.6841\r\n",
      "Train Epoch: 18 [35200/110534 (32%)]\tClassification Loss: 1.4697\r\n",
      "Train Epoch: 18 [35840/110534 (32%)]\tClassification Loss: 1.1472\r\n",
      "Train Epoch: 18 [36480/110534 (33%)]\tClassification Loss: 1.3496\r\n",
      "Train Epoch: 18 [37120/110534 (34%)]\tClassification Loss: 1.7765\r\n",
      "Train Epoch: 18 [37760/110534 (34%)]\tClassification Loss: 1.8734\r\n",
      "Train Epoch: 18 [38400/110534 (35%)]\tClassification Loss: 1.5655\r\n",
      "Train Epoch: 18 [39040/110534 (35%)]\tClassification Loss: 1.4102\r\n",
      "Train Epoch: 18 [39680/110534 (36%)]\tClassification Loss: 1.6447\r\n",
      "Train Epoch: 18 [40320/110534 (36%)]\tClassification Loss: 1.4748\r\n",
      "Train Epoch: 18 [40960/110534 (37%)]\tClassification Loss: 1.3653\r\n",
      "Train Epoch: 18 [41600/110534 (38%)]\tClassification Loss: 1.3954\r\n",
      "Train Epoch: 18 [42240/110534 (38%)]\tClassification Loss: 1.4782\r\n",
      "Train Epoch: 18 [42880/110534 (39%)]\tClassification Loss: 1.3827\r\n",
      "Train Epoch: 18 [43520/110534 (39%)]\tClassification Loss: 1.3045\r\n",
      "Train Epoch: 18 [44160/110534 (40%)]\tClassification Loss: 1.5251\r\n",
      "Train Epoch: 18 [44800/110534 (41%)]\tClassification Loss: 1.5316\r\n",
      "Train Epoch: 18 [45440/110534 (41%)]\tClassification Loss: 1.6623\r\n",
      "Train Epoch: 18 [46080/110534 (42%)]\tClassification Loss: 1.3432\r\n",
      "Train Epoch: 18 [46720/110534 (42%)]\tClassification Loss: 1.5444\r\n",
      "Train Epoch: 18 [47360/110534 (43%)]\tClassification Loss: 1.4145\r\n",
      "Train Epoch: 18 [48000/110534 (43%)]\tClassification Loss: 1.6159\r\n",
      "Train Epoch: 18 [48640/110534 (44%)]\tClassification Loss: 1.3344\r\n",
      "Train Epoch: 18 [49280/110534 (45%)]\tClassification Loss: 1.5684\r\n",
      "Train Epoch: 18 [49920/110534 (45%)]\tClassification Loss: 1.6642\r\n",
      "Train Epoch: 18 [50560/110534 (46%)]\tClassification Loss: 1.6332\r\n",
      "Train Epoch: 18 [51200/110534 (46%)]\tClassification Loss: 1.4096\r\n",
      "Train Epoch: 18 [51840/110534 (47%)]\tClassification Loss: 1.5044\r\n",
      "Train Epoch: 18 [52480/110534 (47%)]\tClassification Loss: 1.4949\r\n",
      "Train Epoch: 18 [53120/110534 (48%)]\tClassification Loss: 1.2142\r\n",
      "Train Epoch: 18 [53760/110534 (49%)]\tClassification Loss: 1.5642\r\n",
      "Train Epoch: 18 [54400/110534 (49%)]\tClassification Loss: 1.2896\r\n",
      "Train Epoch: 18 [55040/110534 (50%)]\tClassification Loss: 1.6348\r\n",
      "Train Epoch: 18 [55680/110534 (50%)]\tClassification Loss: 1.7444\r\n",
      "Train Epoch: 18 [56320/110534 (51%)]\tClassification Loss: 1.3977\r\n",
      "Train Epoch: 18 [56960/110534 (52%)]\tClassification Loss: 1.4739\r\n",
      "Train Epoch: 18 [57600/110534 (52%)]\tClassification Loss: 1.7443\r\n",
      "Train Epoch: 18 [58240/110534 (53%)]\tClassification Loss: 1.5547\r\n",
      "Train Epoch: 18 [58880/110534 (53%)]\tClassification Loss: 1.7068\r\n",
      "Train Epoch: 18 [59520/110534 (54%)]\tClassification Loss: 1.5874\r\n",
      "Train Epoch: 18 [60160/110534 (54%)]\tClassification Loss: 1.6220\r\n",
      "Train Epoch: 18 [60800/110534 (55%)]\tClassification Loss: 1.5484\r\n",
      "Train Epoch: 18 [61440/110534 (56%)]\tClassification Loss: 1.4466\r\n",
      "Train Epoch: 18 [62080/110534 (56%)]\tClassification Loss: 1.5201\r\n",
      "Train Epoch: 18 [62720/110534 (57%)]\tClassification Loss: 1.6307\r\n",
      "Train Epoch: 18 [63360/110534 (57%)]\tClassification Loss: 1.2672\r\n",
      "Train Epoch: 18 [64000/110534 (58%)]\tClassification Loss: 1.5494\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_18_1000.pth.tar\r\n",
      "Train Epoch: 18 [64640/110534 (58%)]\tClassification Loss: 1.1619\r\n",
      "Train Epoch: 18 [65280/110534 (59%)]\tClassification Loss: 1.6623\r\n",
      "Train Epoch: 18 [65920/110534 (60%)]\tClassification Loss: 1.6336\r\n",
      "Train Epoch: 18 [66560/110534 (60%)]\tClassification Loss: 1.3253\r\n",
      "Train Epoch: 18 [67200/110534 (61%)]\tClassification Loss: 1.4866\r\n",
      "Train Epoch: 18 [67840/110534 (61%)]\tClassification Loss: 1.8643\r\n",
      "Train Epoch: 18 [68480/110534 (62%)]\tClassification Loss: 1.5976\r\n",
      "Train Epoch: 18 [69120/110534 (63%)]\tClassification Loss: 1.6912\r\n",
      "Train Epoch: 18 [69760/110534 (63%)]\tClassification Loss: 1.6505\r\n",
      "Train Epoch: 18 [70400/110534 (64%)]\tClassification Loss: 1.1738\r\n",
      "Train Epoch: 18 [71040/110534 (64%)]\tClassification Loss: 1.9285\r\n",
      "Train Epoch: 18 [71680/110534 (65%)]\tClassification Loss: 1.5479\r\n",
      "Train Epoch: 18 [72320/110534 (65%)]\tClassification Loss: 1.5849\r\n",
      "Train Epoch: 18 [72960/110534 (66%)]\tClassification Loss: 1.6588\r\n",
      "Train Epoch: 18 [73600/110534 (67%)]\tClassification Loss: 1.8037\r\n",
      "Train Epoch: 18 [74240/110534 (67%)]\tClassification Loss: 1.7034\r\n",
      "Train Epoch: 18 [74880/110534 (68%)]\tClassification Loss: 1.2398\r\n",
      "Train Epoch: 18 [75520/110534 (68%)]\tClassification Loss: 1.5251\r\n",
      "Train Epoch: 18 [76160/110534 (69%)]\tClassification Loss: 1.3028\r\n",
      "Train Epoch: 18 [76800/110534 (69%)]\tClassification Loss: 1.3206\r\n",
      "Train Epoch: 18 [77440/110534 (70%)]\tClassification Loss: 1.5376\r\n",
      "Train Epoch: 18 [78080/110534 (71%)]\tClassification Loss: 1.5018\r\n",
      "Train Epoch: 18 [78720/110534 (71%)]\tClassification Loss: 1.5011\r\n",
      "Train Epoch: 18 [79360/110534 (72%)]\tClassification Loss: 1.4912\r\n",
      "Train Epoch: 18 [80000/110534 (72%)]\tClassification Loss: 1.3822\r\n",
      "Train Epoch: 18 [80640/110534 (73%)]\tClassification Loss: 1.5406\r\n",
      "Train Epoch: 18 [81280/110534 (74%)]\tClassification Loss: 1.7996\r\n",
      "Train Epoch: 18 [81920/110534 (74%)]\tClassification Loss: 1.5347\r\n",
      "Train Epoch: 18 [82560/110534 (75%)]\tClassification Loss: 1.7294\r\n",
      "Train Epoch: 18 [83200/110534 (75%)]\tClassification Loss: 1.4851\r\n",
      "Train Epoch: 18 [83840/110534 (76%)]\tClassification Loss: 1.8305\r\n",
      "Train Epoch: 18 [84480/110534 (76%)]\tClassification Loss: 1.6798\r\n",
      "Train Epoch: 18 [85120/110534 (77%)]\tClassification Loss: 1.4686\r\n",
      "Train Epoch: 18 [85760/110534 (78%)]\tClassification Loss: 1.4922\r\n",
      "Train Epoch: 18 [86400/110534 (78%)]\tClassification Loss: 1.6469\r\n",
      "Train Epoch: 18 [87040/110534 (79%)]\tClassification Loss: 1.4409\r\n",
      "Train Epoch: 18 [87680/110534 (79%)]\tClassification Loss: 1.3075\r\n",
      "Train Epoch: 18 [88320/110534 (80%)]\tClassification Loss: 1.4697\r\n",
      "Train Epoch: 18 [88960/110534 (80%)]\tClassification Loss: 1.7025\r\n",
      "Train Epoch: 18 [89600/110534 (81%)]\tClassification Loss: 1.7896\r\n",
      "Train Epoch: 18 [90240/110534 (82%)]\tClassification Loss: 1.8553\r\n",
      "Train Epoch: 18 [90880/110534 (82%)]\tClassification Loss: 1.5443\r\n",
      "Train Epoch: 18 [91520/110534 (83%)]\tClassification Loss: 1.2791\r\n",
      "Train Epoch: 18 [92160/110534 (83%)]\tClassification Loss: 1.2992\r\n",
      "Train Epoch: 18 [92800/110534 (84%)]\tClassification Loss: 1.4232\r\n",
      "Train Epoch: 18 [93440/110534 (85%)]\tClassification Loss: 1.7795\r\n",
      "Train Epoch: 18 [94080/110534 (85%)]\tClassification Loss: 1.6185\r\n",
      "Train Epoch: 18 [94720/110534 (86%)]\tClassification Loss: 1.6068\r\n",
      "Train Epoch: 18 [95360/110534 (86%)]\tClassification Loss: 1.4495\r\n",
      "Train Epoch: 18 [96000/110534 (87%)]\tClassification Loss: 1.3823\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_18_1500.pth.tar\r\n",
      "Train Epoch: 18 [96640/110534 (87%)]\tClassification Loss: 1.2644\r\n",
      "Train Epoch: 18 [97280/110534 (88%)]\tClassification Loss: 1.2823\r\n",
      "Train Epoch: 18 [97920/110534 (89%)]\tClassification Loss: 1.1485\r\n",
      "Train Epoch: 18 [98560/110534 (89%)]\tClassification Loss: 1.3423\r\n",
      "Train Epoch: 18 [99200/110534 (90%)]\tClassification Loss: 1.6149\r\n",
      "Train Epoch: 18 [99840/110534 (90%)]\tClassification Loss: 1.5016\r\n",
      "Train Epoch: 18 [100480/110534 (91%)]\tClassification Loss: 1.7274\r\n",
      "Train Epoch: 18 [101120/110534 (91%)]\tClassification Loss: 1.4072\r\n",
      "Train Epoch: 18 [101760/110534 (92%)]\tClassification Loss: 1.5309\r\n",
      "Train Epoch: 18 [102400/110534 (93%)]\tClassification Loss: 1.5848\r\n",
      "Train Epoch: 18 [103040/110534 (93%)]\tClassification Loss: 1.3496\r\n",
      "Train Epoch: 18 [103680/110534 (94%)]\tClassification Loss: 1.8338\r\n",
      "Train Epoch: 18 [104320/110534 (94%)]\tClassification Loss: 1.3259\r\n",
      "Train Epoch: 18 [104960/110534 (95%)]\tClassification Loss: 1.3988\r\n",
      "Train Epoch: 18 [105600/110534 (96%)]\tClassification Loss: 1.4199\r\n",
      "Train Epoch: 18 [106240/110534 (96%)]\tClassification Loss: 1.3462\r\n",
      "Train Epoch: 18 [106880/110534 (97%)]\tClassification Loss: 1.6877\r\n",
      "Train Epoch: 18 [107520/110534 (97%)]\tClassification Loss: 1.6630\r\n",
      "Train Epoch: 18 [108160/110534 (98%)]\tClassification Loss: 1.4410\r\n",
      "Train Epoch: 18 [108800/110534 (98%)]\tClassification Loss: 1.7121\r\n",
      "Train Epoch: 18 [109440/110534 (99%)]\tClassification Loss: 1.5145\r\n",
      "Train Epoch: 18 [110080/110534 (100%)]\tClassification Loss: 1.5305\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_18_final.pth.tar\r\n",
      "Train Epoch: 19 [0/110534 (0%)]\tClassification Loss: 1.4706\r\n",
      "\r\n",
      "Test set: Average loss: 1.4298, Accuracy: 22912/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 19 [640/110534 (1%)]\tClassification Loss: 1.3148\r\n",
      "Train Epoch: 19 [1280/110534 (1%)]\tClassification Loss: 2.0969\r\n",
      "Train Epoch: 19 [1920/110534 (2%)]\tClassification Loss: 1.6947\r\n",
      "Train Epoch: 19 [2560/110534 (2%)]\tClassification Loss: 1.7502\r\n",
      "Train Epoch: 19 [3200/110534 (3%)]\tClassification Loss: 1.4302\r\n",
      "Train Epoch: 19 [3840/110534 (3%)]\tClassification Loss: 1.5268\r\n",
      "Train Epoch: 19 [4480/110534 (4%)]\tClassification Loss: 1.4274\r\n",
      "Train Epoch: 19 [5120/110534 (5%)]\tClassification Loss: 1.5113\r\n",
      "Train Epoch: 19 [5760/110534 (5%)]\tClassification Loss: 1.6972\r\n",
      "Train Epoch: 19 [6400/110534 (6%)]\tClassification Loss: 1.2594\r\n",
      "Train Epoch: 19 [7040/110534 (6%)]\tClassification Loss: 1.4998\r\n",
      "Train Epoch: 19 [7680/110534 (7%)]\tClassification Loss: 1.4187\r\n",
      "Train Epoch: 19 [8320/110534 (8%)]\tClassification Loss: 1.8228\r\n",
      "Train Epoch: 19 [8960/110534 (8%)]\tClassification Loss: 1.6831\r\n",
      "Train Epoch: 19 [9600/110534 (9%)]\tClassification Loss: 1.4329\r\n",
      "Train Epoch: 19 [10240/110534 (9%)]\tClassification Loss: 1.4760\r\n",
      "Train Epoch: 19 [10880/110534 (10%)]\tClassification Loss: 1.6194\r\n",
      "Train Epoch: 19 [11520/110534 (10%)]\tClassification Loss: 1.5840\r\n",
      "Train Epoch: 19 [12160/110534 (11%)]\tClassification Loss: 1.2299\r\n",
      "Train Epoch: 19 [12800/110534 (12%)]\tClassification Loss: 1.5859\r\n",
      "Train Epoch: 19 [13440/110534 (12%)]\tClassification Loss: 1.4037\r\n",
      "Train Epoch: 19 [14080/110534 (13%)]\tClassification Loss: 1.4665\r\n",
      "Train Epoch: 19 [14720/110534 (13%)]\tClassification Loss: 1.7083\r\n",
      "Train Epoch: 19 [15360/110534 (14%)]\tClassification Loss: 1.5861\r\n",
      "Train Epoch: 19 [16000/110534 (14%)]\tClassification Loss: 1.5306\r\n",
      "Train Epoch: 19 [16640/110534 (15%)]\tClassification Loss: 1.4473\r\n",
      "Train Epoch: 19 [17280/110534 (16%)]\tClassification Loss: 1.5863\r\n",
      "Train Epoch: 19 [17920/110534 (16%)]\tClassification Loss: 1.4192\r\n",
      "Train Epoch: 19 [18560/110534 (17%)]\tClassification Loss: 1.9347\r\n",
      "Train Epoch: 19 [19200/110534 (17%)]\tClassification Loss: 1.6583\r\n",
      "Train Epoch: 19 [19840/110534 (18%)]\tClassification Loss: 1.6002\r\n",
      "Train Epoch: 19 [20480/110534 (19%)]\tClassification Loss: 1.7562\r\n",
      "Train Epoch: 19 [21120/110534 (19%)]\tClassification Loss: 1.7902\r\n",
      "Train Epoch: 19 [21760/110534 (20%)]\tClassification Loss: 1.3536\r\n",
      "Train Epoch: 19 [22400/110534 (20%)]\tClassification Loss: 1.6576\r\n",
      "Train Epoch: 19 [23040/110534 (21%)]\tClassification Loss: 1.0069\r\n",
      "Train Epoch: 19 [23680/110534 (21%)]\tClassification Loss: 1.5050\r\n",
      "Train Epoch: 19 [24320/110534 (22%)]\tClassification Loss: 1.2268\r\n",
      "Train Epoch: 19 [24960/110534 (23%)]\tClassification Loss: 1.7857\r\n",
      "Train Epoch: 19 [25600/110534 (23%)]\tClassification Loss: 1.3096\r\n",
      "Train Epoch: 19 [26240/110534 (24%)]\tClassification Loss: 1.2822\r\n",
      "Train Epoch: 19 [26880/110534 (24%)]\tClassification Loss: 1.7020\r\n",
      "Train Epoch: 19 [27520/110534 (25%)]\tClassification Loss: 1.5010\r\n",
      "Train Epoch: 19 [28160/110534 (25%)]\tClassification Loss: 1.8022\r\n",
      "Train Epoch: 19 [28800/110534 (26%)]\tClassification Loss: 1.6839\r\n",
      "Train Epoch: 19 [29440/110534 (27%)]\tClassification Loss: 1.6698\r\n",
      "Train Epoch: 19 [30080/110534 (27%)]\tClassification Loss: 1.8718\r\n",
      "Train Epoch: 19 [30720/110534 (28%)]\tClassification Loss: 1.4146\r\n",
      "Train Epoch: 19 [31360/110534 (28%)]\tClassification Loss: 1.6491\r\n",
      "Train Epoch: 19 [32000/110534 (29%)]\tClassification Loss: 1.4964\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_19_500.pth.tar\r\n",
      "Train Epoch: 19 [32640/110534 (30%)]\tClassification Loss: 1.4085\r\n",
      "Train Epoch: 19 [33280/110534 (30%)]\tClassification Loss: 1.4818\r\n",
      "Train Epoch: 19 [33920/110534 (31%)]\tClassification Loss: 1.5882\r\n",
      "Train Epoch: 19 [34560/110534 (31%)]\tClassification Loss: 1.6741\r\n",
      "Train Epoch: 19 [35200/110534 (32%)]\tClassification Loss: 1.3599\r\n",
      "Train Epoch: 19 [35840/110534 (32%)]\tClassification Loss: 1.1092\r\n",
      "Train Epoch: 19 [36480/110534 (33%)]\tClassification Loss: 1.3546\r\n",
      "Train Epoch: 19 [37120/110534 (34%)]\tClassification Loss: 1.6410\r\n",
      "Train Epoch: 19 [37760/110534 (34%)]\tClassification Loss: 1.8496\r\n",
      "Train Epoch: 19 [38400/110534 (35%)]\tClassification Loss: 1.3329\r\n",
      "Train Epoch: 19 [39040/110534 (35%)]\tClassification Loss: 1.4294\r\n",
      "Train Epoch: 19 [39680/110534 (36%)]\tClassification Loss: 1.6049\r\n",
      "Train Epoch: 19 [40320/110534 (36%)]\tClassification Loss: 1.5582\r\n",
      "Train Epoch: 19 [40960/110534 (37%)]\tClassification Loss: 1.5224\r\n",
      "Train Epoch: 19 [41600/110534 (38%)]\tClassification Loss: 1.5282\r\n",
      "Train Epoch: 19 [42240/110534 (38%)]\tClassification Loss: 1.4171\r\n",
      "Train Epoch: 19 [42880/110534 (39%)]\tClassification Loss: 1.4143\r\n",
      "Train Epoch: 19 [43520/110534 (39%)]\tClassification Loss: 1.2766\r\n",
      "Train Epoch: 19 [44160/110534 (40%)]\tClassification Loss: 1.6333\r\n",
      "Train Epoch: 19 [44800/110534 (41%)]\tClassification Loss: 1.5082\r\n",
      "Train Epoch: 19 [45440/110534 (41%)]\tClassification Loss: 1.6410\r\n",
      "Train Epoch: 19 [46080/110534 (42%)]\tClassification Loss: 1.3875\r\n",
      "Train Epoch: 19 [46720/110534 (42%)]\tClassification Loss: 1.5584\r\n",
      "Train Epoch: 19 [47360/110534 (43%)]\tClassification Loss: 1.4005\r\n",
      "Train Epoch: 19 [48000/110534 (43%)]\tClassification Loss: 1.6894\r\n",
      "Train Epoch: 19 [48640/110534 (44%)]\tClassification Loss: 1.3990\r\n",
      "Train Epoch: 19 [49280/110534 (45%)]\tClassification Loss: 1.5591\r\n",
      "Train Epoch: 19 [49920/110534 (45%)]\tClassification Loss: 1.5585\r\n",
      "Train Epoch: 19 [50560/110534 (46%)]\tClassification Loss: 1.5421\r\n",
      "Train Epoch: 19 [51200/110534 (46%)]\tClassification Loss: 1.3513\r\n",
      "Train Epoch: 19 [51840/110534 (47%)]\tClassification Loss: 1.4852\r\n",
      "Train Epoch: 19 [52480/110534 (47%)]\tClassification Loss: 1.5281\r\n",
      "Train Epoch: 19 [53120/110534 (48%)]\tClassification Loss: 1.1580\r\n",
      "Train Epoch: 19 [53760/110534 (49%)]\tClassification Loss: 1.6163\r\n",
      "Train Epoch: 19 [54400/110534 (49%)]\tClassification Loss: 1.3465\r\n",
      "Train Epoch: 19 [55040/110534 (50%)]\tClassification Loss: 1.7502\r\n",
      "Train Epoch: 19 [55680/110534 (50%)]\tClassification Loss: 1.6104\r\n",
      "Train Epoch: 19 [56320/110534 (51%)]\tClassification Loss: 1.3470\r\n",
      "Train Epoch: 19 [56960/110534 (52%)]\tClassification Loss: 1.4470\r\n",
      "Train Epoch: 19 [57600/110534 (52%)]\tClassification Loss: 1.5405\r\n",
      "Train Epoch: 19 [58240/110534 (53%)]\tClassification Loss: 1.5634\r\n",
      "Train Epoch: 19 [58880/110534 (53%)]\tClassification Loss: 1.7379\r\n",
      "Train Epoch: 19 [59520/110534 (54%)]\tClassification Loss: 1.1762\r\n",
      "Train Epoch: 19 [60160/110534 (54%)]\tClassification Loss: 1.4341\r\n",
      "Train Epoch: 19 [60800/110534 (55%)]\tClassification Loss: 1.5360\r\n",
      "Train Epoch: 19 [61440/110534 (56%)]\tClassification Loss: 1.4363\r\n",
      "Train Epoch: 19 [62080/110534 (56%)]\tClassification Loss: 1.5265\r\n",
      "Train Epoch: 19 [62720/110534 (57%)]\tClassification Loss: 1.6030\r\n",
      "Train Epoch: 19 [63360/110534 (57%)]\tClassification Loss: 1.3332\r\n",
      "Train Epoch: 19 [64000/110534 (58%)]\tClassification Loss: 1.4892\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_19_1000.pth.tar\r\n",
      "Train Epoch: 19 [64640/110534 (58%)]\tClassification Loss: 1.1776\r\n",
      "Train Epoch: 19 [65280/110534 (59%)]\tClassification Loss: 1.4481\r\n",
      "Train Epoch: 19 [65920/110534 (60%)]\tClassification Loss: 1.6182\r\n",
      "Train Epoch: 19 [66560/110534 (60%)]\tClassification Loss: 1.3198\r\n",
      "Train Epoch: 19 [67200/110534 (61%)]\tClassification Loss: 1.3123\r\n",
      "Train Epoch: 19 [67840/110534 (61%)]\tClassification Loss: 1.7771\r\n",
      "Train Epoch: 19 [68480/110534 (62%)]\tClassification Loss: 1.6866\r\n",
      "Train Epoch: 19 [69120/110534 (63%)]\tClassification Loss: 1.8821\r\n",
      "Train Epoch: 19 [69760/110534 (63%)]\tClassification Loss: 1.6791\r\n",
      "Train Epoch: 19 [70400/110534 (64%)]\tClassification Loss: 1.2494\r\n",
      "Train Epoch: 19 [71040/110534 (64%)]\tClassification Loss: 1.8803\r\n",
      "Train Epoch: 19 [71680/110534 (65%)]\tClassification Loss: 1.5087\r\n",
      "Train Epoch: 19 [72320/110534 (65%)]\tClassification Loss: 1.6532\r\n",
      "Train Epoch: 19 [72960/110534 (66%)]\tClassification Loss: 1.6451\r\n",
      "Train Epoch: 19 [73600/110534 (67%)]\tClassification Loss: 1.8824\r\n",
      "Train Epoch: 19 [74240/110534 (67%)]\tClassification Loss: 1.6143\r\n",
      "Train Epoch: 19 [74880/110534 (68%)]\tClassification Loss: 1.1644\r\n",
      "Train Epoch: 19 [75520/110534 (68%)]\tClassification Loss: 1.6014\r\n",
      "Train Epoch: 19 [76160/110534 (69%)]\tClassification Loss: 1.3114\r\n",
      "Train Epoch: 19 [76800/110534 (69%)]\tClassification Loss: 1.4408\r\n",
      "Train Epoch: 19 [77440/110534 (70%)]\tClassification Loss: 1.4698\r\n",
      "Train Epoch: 19 [78080/110534 (71%)]\tClassification Loss: 1.4991\r\n",
      "Train Epoch: 19 [78720/110534 (71%)]\tClassification Loss: 1.4933\r\n",
      "Train Epoch: 19 [79360/110534 (72%)]\tClassification Loss: 1.4911\r\n",
      "Train Epoch: 19 [80000/110534 (72%)]\tClassification Loss: 1.4744\r\n",
      "Train Epoch: 19 [80640/110534 (73%)]\tClassification Loss: 1.3974\r\n",
      "Train Epoch: 19 [81280/110534 (74%)]\tClassification Loss: 1.8253\r\n",
      "Train Epoch: 19 [81920/110534 (74%)]\tClassification Loss: 1.5784\r\n",
      "Train Epoch: 19 [82560/110534 (75%)]\tClassification Loss: 1.7896\r\n",
      "Train Epoch: 19 [83200/110534 (75%)]\tClassification Loss: 1.3671\r\n",
      "Train Epoch: 19 [83840/110534 (76%)]\tClassification Loss: 1.7817\r\n",
      "Train Epoch: 19 [84480/110534 (76%)]\tClassification Loss: 1.6435\r\n",
      "Train Epoch: 19 [85120/110534 (77%)]\tClassification Loss: 1.4366\r\n",
      "Train Epoch: 19 [85760/110534 (78%)]\tClassification Loss: 1.4466\r\n",
      "Train Epoch: 19 [86400/110534 (78%)]\tClassification Loss: 1.6113\r\n",
      "Train Epoch: 19 [87040/110534 (79%)]\tClassification Loss: 1.5022\r\n",
      "Train Epoch: 19 [87680/110534 (79%)]\tClassification Loss: 1.5113\r\n",
      "Train Epoch: 19 [88320/110534 (80%)]\tClassification Loss: 1.5727\r\n",
      "Train Epoch: 19 [88960/110534 (80%)]\tClassification Loss: 1.7114\r\n",
      "Train Epoch: 19 [89600/110534 (81%)]\tClassification Loss: 1.6393\r\n",
      "Train Epoch: 19 [90240/110534 (82%)]\tClassification Loss: 1.7989\r\n",
      "Train Epoch: 19 [90880/110534 (82%)]\tClassification Loss: 1.6752\r\n",
      "Train Epoch: 19 [91520/110534 (83%)]\tClassification Loss: 1.1759\r\n",
      "Train Epoch: 19 [92160/110534 (83%)]\tClassification Loss: 1.3212\r\n",
      "Train Epoch: 19 [92800/110534 (84%)]\tClassification Loss: 1.4531\r\n",
      "Train Epoch: 19 [93440/110534 (85%)]\tClassification Loss: 1.8677\r\n",
      "Train Epoch: 19 [94080/110534 (85%)]\tClassification Loss: 1.5799\r\n",
      "Train Epoch: 19 [94720/110534 (86%)]\tClassification Loss: 1.4419\r\n",
      "Train Epoch: 19 [95360/110534 (86%)]\tClassification Loss: 1.4476\r\n",
      "Train Epoch: 19 [96000/110534 (87%)]\tClassification Loss: 1.5003\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_19_1500.pth.tar\r\n",
      "Train Epoch: 19 [96640/110534 (87%)]\tClassification Loss: 1.3610\r\n",
      "Train Epoch: 19 [97280/110534 (88%)]\tClassification Loss: 1.2112\r\n",
      "Train Epoch: 19 [97920/110534 (89%)]\tClassification Loss: 1.1747\r\n",
      "Train Epoch: 19 [98560/110534 (89%)]\tClassification Loss: 1.4498\r\n",
      "Train Epoch: 19 [99200/110534 (90%)]\tClassification Loss: 1.8460\r\n",
      "Train Epoch: 19 [99840/110534 (90%)]\tClassification Loss: 1.5138\r\n",
      "Train Epoch: 19 [100480/110534 (91%)]\tClassification Loss: 1.7110\r\n",
      "Train Epoch: 19 [101120/110534 (91%)]\tClassification Loss: 1.5919\r\n",
      "Train Epoch: 19 [101760/110534 (92%)]\tClassification Loss: 1.5103\r\n",
      "Train Epoch: 19 [102400/110534 (93%)]\tClassification Loss: 1.4799\r\n",
      "Train Epoch: 19 [103040/110534 (93%)]\tClassification Loss: 1.4458\r\n",
      "Train Epoch: 19 [103680/110534 (94%)]\tClassification Loss: 1.6624\r\n",
      "Train Epoch: 19 [104320/110534 (94%)]\tClassification Loss: 1.3565\r\n",
      "Train Epoch: 19 [104960/110534 (95%)]\tClassification Loss: 1.4170\r\n",
      "Train Epoch: 19 [105600/110534 (96%)]\tClassification Loss: 1.5960\r\n",
      "Train Epoch: 19 [106240/110534 (96%)]\tClassification Loss: 1.1406\r\n",
      "Train Epoch: 19 [106880/110534 (97%)]\tClassification Loss: 1.6861\r\n",
      "Train Epoch: 19 [107520/110534 (97%)]\tClassification Loss: 1.5594\r\n",
      "Train Epoch: 19 [108160/110534 (98%)]\tClassification Loss: 1.5690\r\n",
      "Train Epoch: 19 [108800/110534 (98%)]\tClassification Loss: 1.5959\r\n",
      "Train Epoch: 19 [109440/110534 (99%)]\tClassification Loss: 1.4915\r\n",
      "Train Epoch: 19 [110080/110534 (100%)]\tClassification Loss: 1.5930\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_19_final.pth.tar\r\n",
      "Train Epoch: 20 [0/110534 (0%)]\tClassification Loss: 1.4882\r\n",
      "\r\n",
      "Test set: Average loss: 1.4220, Accuracy: 23043/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 20 [640/110534 (1%)]\tClassification Loss: 1.3792\r\n",
      "Train Epoch: 20 [1280/110534 (1%)]\tClassification Loss: 1.8748\r\n",
      "Train Epoch: 20 [1920/110534 (2%)]\tClassification Loss: 1.6038\r\n",
      "Train Epoch: 20 [2560/110534 (2%)]\tClassification Loss: 1.7997\r\n",
      "Train Epoch: 20 [3200/110534 (3%)]\tClassification Loss: 1.4316\r\n",
      "Train Epoch: 20 [3840/110534 (3%)]\tClassification Loss: 1.5145\r\n",
      "Train Epoch: 20 [4480/110534 (4%)]\tClassification Loss: 1.3902\r\n",
      "Train Epoch: 20 [5120/110534 (5%)]\tClassification Loss: 1.5872\r\n",
      "Train Epoch: 20 [5760/110534 (5%)]\tClassification Loss: 1.5211\r\n",
      "Train Epoch: 20 [6400/110534 (6%)]\tClassification Loss: 1.3569\r\n",
      "Train Epoch: 20 [7040/110534 (6%)]\tClassification Loss: 1.4462\r\n",
      "Train Epoch: 20 [7680/110534 (7%)]\tClassification Loss: 1.4750\r\n",
      "Train Epoch: 20 [8320/110534 (8%)]\tClassification Loss: 1.7105\r\n",
      "Train Epoch: 20 [8960/110534 (8%)]\tClassification Loss: 1.8518\r\n",
      "Train Epoch: 20 [9600/110534 (9%)]\tClassification Loss: 1.4348\r\n",
      "Train Epoch: 20 [10240/110534 (9%)]\tClassification Loss: 1.4595\r\n",
      "Train Epoch: 20 [10880/110534 (10%)]\tClassification Loss: 1.5867\r\n",
      "Train Epoch: 20 [11520/110534 (10%)]\tClassification Loss: 1.6560\r\n",
      "Train Epoch: 20 [12160/110534 (11%)]\tClassification Loss: 1.3726\r\n",
      "Train Epoch: 20 [12800/110534 (12%)]\tClassification Loss: 1.5962\r\n",
      "Train Epoch: 20 [13440/110534 (12%)]\tClassification Loss: 1.4357\r\n",
      "Train Epoch: 20 [14080/110534 (13%)]\tClassification Loss: 1.6029\r\n",
      "Train Epoch: 20 [14720/110534 (13%)]\tClassification Loss: 1.7707\r\n",
      "Train Epoch: 20 [15360/110534 (14%)]\tClassification Loss: 1.4739\r\n",
      "Train Epoch: 20 [16000/110534 (14%)]\tClassification Loss: 1.8468\r\n",
      "Train Epoch: 20 [16640/110534 (15%)]\tClassification Loss: 1.4751\r\n",
      "Train Epoch: 20 [17280/110534 (16%)]\tClassification Loss: 1.6112\r\n",
      "Train Epoch: 20 [17920/110534 (16%)]\tClassification Loss: 1.4815\r\n",
      "Train Epoch: 20 [18560/110534 (17%)]\tClassification Loss: 1.7265\r\n",
      "Train Epoch: 20 [19200/110534 (17%)]\tClassification Loss: 1.6803\r\n",
      "Train Epoch: 20 [19840/110534 (18%)]\tClassification Loss: 1.5614\r\n",
      "Train Epoch: 20 [20480/110534 (19%)]\tClassification Loss: 1.7332\r\n",
      "Train Epoch: 20 [21120/110534 (19%)]\tClassification Loss: 1.5790\r\n",
      "Train Epoch: 20 [21760/110534 (20%)]\tClassification Loss: 1.2576\r\n",
      "Train Epoch: 20 [22400/110534 (20%)]\tClassification Loss: 1.5302\r\n",
      "Train Epoch: 20 [23040/110534 (21%)]\tClassification Loss: 1.1846\r\n",
      "Train Epoch: 20 [23680/110534 (21%)]\tClassification Loss: 1.6475\r\n",
      "Train Epoch: 20 [24320/110534 (22%)]\tClassification Loss: 1.2902\r\n",
      "Train Epoch: 20 [24960/110534 (23%)]\tClassification Loss: 1.7996\r\n",
      "Train Epoch: 20 [25600/110534 (23%)]\tClassification Loss: 1.4789\r\n",
      "Train Epoch: 20 [26240/110534 (24%)]\tClassification Loss: 1.4160\r\n",
      "Train Epoch: 20 [26880/110534 (24%)]\tClassification Loss: 1.7187\r\n",
      "Train Epoch: 20 [27520/110534 (25%)]\tClassification Loss: 1.4576\r\n",
      "Train Epoch: 20 [28160/110534 (25%)]\tClassification Loss: 1.8350\r\n",
      "Train Epoch: 20 [28800/110534 (26%)]\tClassification Loss: 1.8053\r\n",
      "Train Epoch: 20 [29440/110534 (27%)]\tClassification Loss: 1.6579\r\n",
      "Train Epoch: 20 [30080/110534 (27%)]\tClassification Loss: 1.7073\r\n",
      "Train Epoch: 20 [30720/110534 (28%)]\tClassification Loss: 1.4619\r\n",
      "Train Epoch: 20 [31360/110534 (28%)]\tClassification Loss: 1.7150\r\n",
      "Train Epoch: 20 [32000/110534 (29%)]\tClassification Loss: 1.4508\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_20_500.pth.tar\r\n",
      "Train Epoch: 20 [32640/110534 (30%)]\tClassification Loss: 1.3684\r\n",
      "Train Epoch: 20 [33280/110534 (30%)]\tClassification Loss: 1.5541\r\n",
      "Train Epoch: 20 [33920/110534 (31%)]\tClassification Loss: 1.6146\r\n",
      "Train Epoch: 20 [34560/110534 (31%)]\tClassification Loss: 1.8061\r\n",
      "Train Epoch: 20 [35200/110534 (32%)]\tClassification Loss: 1.5505\r\n",
      "Train Epoch: 20 [35840/110534 (32%)]\tClassification Loss: 1.2525\r\n",
      "Train Epoch: 20 [36480/110534 (33%)]\tClassification Loss: 1.5199\r\n",
      "Train Epoch: 20 [37120/110534 (34%)]\tClassification Loss: 1.5504\r\n",
      "Train Epoch: 20 [37760/110534 (34%)]\tClassification Loss: 1.8624\r\n",
      "Train Epoch: 20 [38400/110534 (35%)]\tClassification Loss: 1.4360\r\n",
      "Train Epoch: 20 [39040/110534 (35%)]\tClassification Loss: 1.4023\r\n",
      "Train Epoch: 20 [39680/110534 (36%)]\tClassification Loss: 1.5633\r\n",
      "Train Epoch: 20 [40320/110534 (36%)]\tClassification Loss: 1.4791\r\n",
      "Train Epoch: 20 [40960/110534 (37%)]\tClassification Loss: 1.3233\r\n",
      "Train Epoch: 20 [41600/110534 (38%)]\tClassification Loss: 1.2986\r\n",
      "Train Epoch: 20 [42240/110534 (38%)]\tClassification Loss: 1.4880\r\n",
      "Train Epoch: 20 [42880/110534 (39%)]\tClassification Loss: 1.4287\r\n",
      "Train Epoch: 20 [43520/110534 (39%)]\tClassification Loss: 1.4413\r\n",
      "Train Epoch: 20 [44160/110534 (40%)]\tClassification Loss: 1.5374\r\n",
      "Train Epoch: 20 [44800/110534 (41%)]\tClassification Loss: 1.6881\r\n",
      "Train Epoch: 20 [45440/110534 (41%)]\tClassification Loss: 1.5883\r\n",
      "Train Epoch: 20 [46080/110534 (42%)]\tClassification Loss: 1.3561\r\n",
      "Train Epoch: 20 [46720/110534 (42%)]\tClassification Loss: 1.5496\r\n",
      "Train Epoch: 20 [47360/110534 (43%)]\tClassification Loss: 1.5099\r\n",
      "Train Epoch: 20 [48000/110534 (43%)]\tClassification Loss: 1.6164\r\n",
      "Train Epoch: 20 [48640/110534 (44%)]\tClassification Loss: 1.4247\r\n",
      "Train Epoch: 20 [49280/110534 (45%)]\tClassification Loss: 1.5172\r\n",
      "Train Epoch: 20 [49920/110534 (45%)]\tClassification Loss: 1.5366\r\n",
      "Train Epoch: 20 [50560/110534 (46%)]\tClassification Loss: 1.5974\r\n",
      "Train Epoch: 20 [51200/110534 (46%)]\tClassification Loss: 1.3393\r\n",
      "Train Epoch: 20 [51840/110534 (47%)]\tClassification Loss: 1.4225\r\n",
      "Train Epoch: 20 [52480/110534 (47%)]\tClassification Loss: 1.5088\r\n",
      "Train Epoch: 20 [53120/110534 (48%)]\tClassification Loss: 1.2178\r\n",
      "Train Epoch: 20 [53760/110534 (49%)]\tClassification Loss: 1.5459\r\n",
      "Train Epoch: 20 [54400/110534 (49%)]\tClassification Loss: 1.5126\r\n",
      "Train Epoch: 20 [55040/110534 (50%)]\tClassification Loss: 1.6919\r\n",
      "Train Epoch: 20 [55680/110534 (50%)]\tClassification Loss: 1.6484\r\n",
      "Train Epoch: 20 [56320/110534 (51%)]\tClassification Loss: 1.5034\r\n",
      "Train Epoch: 20 [56960/110534 (52%)]\tClassification Loss: 1.4741\r\n",
      "Train Epoch: 20 [57600/110534 (52%)]\tClassification Loss: 1.4542\r\n",
      "Train Epoch: 20 [58240/110534 (53%)]\tClassification Loss: 1.5538\r\n",
      "Train Epoch: 20 [58880/110534 (53%)]\tClassification Loss: 1.6754\r\n",
      "Train Epoch: 20 [59520/110534 (54%)]\tClassification Loss: 1.3221\r\n",
      "Train Epoch: 20 [60160/110534 (54%)]\tClassification Loss: 1.5187\r\n",
      "Train Epoch: 20 [60800/110534 (55%)]\tClassification Loss: 1.6327\r\n",
      "Train Epoch: 20 [61440/110534 (56%)]\tClassification Loss: 1.7077\r\n",
      "Train Epoch: 20 [62080/110534 (56%)]\tClassification Loss: 1.4650\r\n",
      "Train Epoch: 20 [62720/110534 (57%)]\tClassification Loss: 1.6723\r\n",
      "Train Epoch: 20 [63360/110534 (57%)]\tClassification Loss: 1.3415\r\n",
      "Train Epoch: 20 [64000/110534 (58%)]\tClassification Loss: 1.6607\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_20_1000.pth.tar\r\n",
      "Train Epoch: 20 [64640/110534 (58%)]\tClassification Loss: 1.2344\r\n",
      "Train Epoch: 20 [65280/110534 (59%)]\tClassification Loss: 1.4396\r\n",
      "Train Epoch: 20 [65920/110534 (60%)]\tClassification Loss: 1.3771\r\n",
      "Train Epoch: 20 [66560/110534 (60%)]\tClassification Loss: 1.3819\r\n",
      "Train Epoch: 20 [67200/110534 (61%)]\tClassification Loss: 1.3898\r\n",
      "Train Epoch: 20 [67840/110534 (61%)]\tClassification Loss: 1.6678\r\n",
      "Train Epoch: 20 [68480/110534 (62%)]\tClassification Loss: 1.6359\r\n",
      "Train Epoch: 20 [69120/110534 (63%)]\tClassification Loss: 1.7368\r\n",
      "Train Epoch: 20 [69760/110534 (63%)]\tClassification Loss: 1.6647\r\n",
      "Train Epoch: 20 [70400/110534 (64%)]\tClassification Loss: 1.2303\r\n",
      "Train Epoch: 20 [71040/110534 (64%)]\tClassification Loss: 1.9954\r\n",
      "Train Epoch: 20 [71680/110534 (65%)]\tClassification Loss: 1.4836\r\n",
      "Train Epoch: 20 [72320/110534 (65%)]\tClassification Loss: 1.6019\r\n",
      "Train Epoch: 20 [72960/110534 (66%)]\tClassification Loss: 1.8336\r\n",
      "Train Epoch: 20 [73600/110534 (67%)]\tClassification Loss: 1.7831\r\n",
      "Train Epoch: 20 [74240/110534 (67%)]\tClassification Loss: 1.7162\r\n",
      "Train Epoch: 20 [74880/110534 (68%)]\tClassification Loss: 1.1842\r\n",
      "Train Epoch: 20 [75520/110534 (68%)]\tClassification Loss: 1.5941\r\n",
      "Train Epoch: 20 [76160/110534 (69%)]\tClassification Loss: 1.4056\r\n",
      "Train Epoch: 20 [76800/110534 (69%)]\tClassification Loss: 1.4052\r\n",
      "Train Epoch: 20 [77440/110534 (70%)]\tClassification Loss: 1.4617\r\n",
      "Train Epoch: 20 [78080/110534 (71%)]\tClassification Loss: 1.4839\r\n",
      "Train Epoch: 20 [78720/110534 (71%)]\tClassification Loss: 1.5610\r\n",
      "Train Epoch: 20 [79360/110534 (72%)]\tClassification Loss: 1.4452\r\n",
      "Train Epoch: 20 [80000/110534 (72%)]\tClassification Loss: 1.3108\r\n",
      "Train Epoch: 20 [80640/110534 (73%)]\tClassification Loss: 1.4115\r\n",
      "Train Epoch: 20 [81280/110534 (74%)]\tClassification Loss: 1.7669\r\n",
      "Train Epoch: 20 [81920/110534 (74%)]\tClassification Loss: 1.4037\r\n",
      "Train Epoch: 20 [82560/110534 (75%)]\tClassification Loss: 1.6127\r\n",
      "Train Epoch: 20 [83200/110534 (75%)]\tClassification Loss: 1.5053\r\n",
      "Train Epoch: 20 [83840/110534 (76%)]\tClassification Loss: 1.8781\r\n",
      "Train Epoch: 20 [84480/110534 (76%)]\tClassification Loss: 1.8374\r\n",
      "Train Epoch: 20 [85120/110534 (77%)]\tClassification Loss: 1.6098\r\n",
      "Train Epoch: 20 [85760/110534 (78%)]\tClassification Loss: 1.4378\r\n",
      "Train Epoch: 20 [86400/110534 (78%)]\tClassification Loss: 1.6662\r\n",
      "Train Epoch: 20 [87040/110534 (79%)]\tClassification Loss: 1.4936\r\n",
      "Train Epoch: 20 [87680/110534 (79%)]\tClassification Loss: 1.3239\r\n",
      "Train Epoch: 20 [88320/110534 (80%)]\tClassification Loss: 1.6452\r\n",
      "Train Epoch: 20 [88960/110534 (80%)]\tClassification Loss: 1.6563\r\n",
      "Train Epoch: 20 [89600/110534 (81%)]\tClassification Loss: 1.8731\r\n",
      "Train Epoch: 20 [90240/110534 (82%)]\tClassification Loss: 1.7428\r\n",
      "Train Epoch: 20 [90880/110534 (82%)]\tClassification Loss: 1.6617\r\n",
      "Train Epoch: 20 [91520/110534 (83%)]\tClassification Loss: 1.3081\r\n",
      "Train Epoch: 20 [92160/110534 (83%)]\tClassification Loss: 1.5089\r\n",
      "Train Epoch: 20 [92800/110534 (84%)]\tClassification Loss: 1.2848\r\n",
      "Train Epoch: 20 [93440/110534 (85%)]\tClassification Loss: 1.7783\r\n",
      "Train Epoch: 20 [94080/110534 (85%)]\tClassification Loss: 1.6538\r\n",
      "Train Epoch: 20 [94720/110534 (86%)]\tClassification Loss: 1.3806\r\n",
      "Train Epoch: 20 [95360/110534 (86%)]\tClassification Loss: 1.3801\r\n",
      "Train Epoch: 20 [96000/110534 (87%)]\tClassification Loss: 1.5613\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_20_1500.pth.tar\r\n",
      "Train Epoch: 20 [96640/110534 (87%)]\tClassification Loss: 1.3095\r\n",
      "Train Epoch: 20 [97280/110534 (88%)]\tClassification Loss: 1.5019\r\n",
      "Train Epoch: 20 [97920/110534 (89%)]\tClassification Loss: 1.2173\r\n",
      "Train Epoch: 20 [98560/110534 (89%)]\tClassification Loss: 1.4249\r\n",
      "Train Epoch: 20 [99200/110534 (90%)]\tClassification Loss: 1.7073\r\n",
      "Train Epoch: 20 [99840/110534 (90%)]\tClassification Loss: 1.4456\r\n",
      "Train Epoch: 20 [100480/110534 (91%)]\tClassification Loss: 1.6827\r\n",
      "Train Epoch: 20 [101120/110534 (91%)]\tClassification Loss: 1.3715\r\n",
      "Train Epoch: 20 [101760/110534 (92%)]\tClassification Loss: 1.4792\r\n",
      "Train Epoch: 20 [102400/110534 (93%)]\tClassification Loss: 1.6131\r\n",
      "Train Epoch: 20 [103040/110534 (93%)]\tClassification Loss: 1.2962\r\n",
      "Train Epoch: 20 [103680/110534 (94%)]\tClassification Loss: 1.7821\r\n",
      "Train Epoch: 20 [104320/110534 (94%)]\tClassification Loss: 1.3100\r\n",
      "Train Epoch: 20 [104960/110534 (95%)]\tClassification Loss: 1.6251\r\n",
      "Train Epoch: 20 [105600/110534 (96%)]\tClassification Loss: 1.5246\r\n",
      "Train Epoch: 20 [106240/110534 (96%)]\tClassification Loss: 1.4021\r\n",
      "Train Epoch: 20 [106880/110534 (97%)]\tClassification Loss: 1.5416\r\n",
      "Train Epoch: 20 [107520/110534 (97%)]\tClassification Loss: 1.8962\r\n",
      "Train Epoch: 20 [108160/110534 (98%)]\tClassification Loss: 1.5534\r\n",
      "Train Epoch: 20 [108800/110534 (98%)]\tClassification Loss: 1.6574\r\n",
      "Train Epoch: 20 [109440/110534 (99%)]\tClassification Loss: 1.3343\r\n",
      "Train Epoch: 20 [110080/110534 (100%)]\tClassification Loss: 1.4341\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_20_final.pth.tar\r\n",
      "Train Epoch: 21 [0/110534 (0%)]\tClassification Loss: 1.3823\r\n",
      "\r\n",
      "Test set: Average loss: 1.4271, Accuracy: 22986/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 21 [640/110534 (1%)]\tClassification Loss: 1.2976\r\n",
      "Train Epoch: 21 [1280/110534 (1%)]\tClassification Loss: 1.9553\r\n",
      "Train Epoch: 21 [1920/110534 (2%)]\tClassification Loss: 1.6809\r\n",
      "Train Epoch: 21 [2560/110534 (2%)]\tClassification Loss: 1.6802\r\n",
      "Train Epoch: 21 [3200/110534 (3%)]\tClassification Loss: 1.4357\r\n",
      "Train Epoch: 21 [3840/110534 (3%)]\tClassification Loss: 1.3403\r\n",
      "Train Epoch: 21 [4480/110534 (4%)]\tClassification Loss: 1.5372\r\n",
      "Train Epoch: 21 [5120/110534 (5%)]\tClassification Loss: 1.5846\r\n",
      "Train Epoch: 21 [5760/110534 (5%)]\tClassification Loss: 1.4916\r\n",
      "Train Epoch: 21 [6400/110534 (6%)]\tClassification Loss: 1.3663\r\n",
      "Train Epoch: 21 [7040/110534 (6%)]\tClassification Loss: 1.6529\r\n",
      "Train Epoch: 21 [7680/110534 (7%)]\tClassification Loss: 1.5290\r\n",
      "Train Epoch: 21 [8320/110534 (8%)]\tClassification Loss: 1.7104\r\n",
      "Train Epoch: 21 [8960/110534 (8%)]\tClassification Loss: 1.6750\r\n",
      "Train Epoch: 21 [9600/110534 (9%)]\tClassification Loss: 1.5145\r\n",
      "Train Epoch: 21 [10240/110534 (9%)]\tClassification Loss: 1.4544\r\n",
      "Train Epoch: 21 [10880/110534 (10%)]\tClassification Loss: 1.4554\r\n",
      "Train Epoch: 21 [11520/110534 (10%)]\tClassification Loss: 1.5539\r\n",
      "Train Epoch: 21 [12160/110534 (11%)]\tClassification Loss: 1.3889\r\n",
      "Train Epoch: 21 [12800/110534 (12%)]\tClassification Loss: 1.5593\r\n",
      "Train Epoch: 21 [13440/110534 (12%)]\tClassification Loss: 1.5859\r\n",
      "Train Epoch: 21 [14080/110534 (13%)]\tClassification Loss: 1.4781\r\n",
      "Train Epoch: 21 [14720/110534 (13%)]\tClassification Loss: 1.8002\r\n",
      "Train Epoch: 21 [15360/110534 (14%)]\tClassification Loss: 1.5257\r\n",
      "Train Epoch: 21 [16000/110534 (14%)]\tClassification Loss: 1.4820\r\n",
      "Train Epoch: 21 [16640/110534 (15%)]\tClassification Loss: 1.4869\r\n",
      "Train Epoch: 21 [17280/110534 (16%)]\tClassification Loss: 1.6353\r\n",
      "Train Epoch: 21 [17920/110534 (16%)]\tClassification Loss: 1.4542\r\n",
      "Train Epoch: 21 [18560/110534 (17%)]\tClassification Loss: 1.7637\r\n",
      "Train Epoch: 21 [19200/110534 (17%)]\tClassification Loss: 1.5839\r\n",
      "Train Epoch: 21 [19840/110534 (18%)]\tClassification Loss: 1.5554\r\n",
      "Train Epoch: 21 [20480/110534 (19%)]\tClassification Loss: 1.8294\r\n",
      "Train Epoch: 21 [21120/110534 (19%)]\tClassification Loss: 1.8082\r\n",
      "Train Epoch: 21 [21760/110534 (20%)]\tClassification Loss: 1.2881\r\n",
      "Train Epoch: 21 [22400/110534 (20%)]\tClassification Loss: 1.5829\r\n",
      "Train Epoch: 21 [23040/110534 (21%)]\tClassification Loss: 1.0813\r\n",
      "Train Epoch: 21 [23680/110534 (21%)]\tClassification Loss: 1.7259\r\n",
      "Train Epoch: 21 [24320/110534 (22%)]\tClassification Loss: 1.1275\r\n",
      "Train Epoch: 21 [24960/110534 (23%)]\tClassification Loss: 1.5645\r\n",
      "Train Epoch: 21 [25600/110534 (23%)]\tClassification Loss: 1.1944\r\n",
      "Train Epoch: 21 [26240/110534 (24%)]\tClassification Loss: 1.4201\r\n",
      "Train Epoch: 21 [26880/110534 (24%)]\tClassification Loss: 1.6390\r\n",
      "Train Epoch: 21 [27520/110534 (25%)]\tClassification Loss: 1.4380\r\n",
      "Train Epoch: 21 [28160/110534 (25%)]\tClassification Loss: 1.8048\r\n",
      "Train Epoch: 21 [28800/110534 (26%)]\tClassification Loss: 1.8135\r\n",
      "Train Epoch: 21 [29440/110534 (27%)]\tClassification Loss: 1.8601\r\n",
      "Train Epoch: 21 [30080/110534 (27%)]\tClassification Loss: 1.6715\r\n",
      "Train Epoch: 21 [30720/110534 (28%)]\tClassification Loss: 1.4438\r\n",
      "Train Epoch: 21 [31360/110534 (28%)]\tClassification Loss: 1.5650\r\n",
      "Train Epoch: 21 [32000/110534 (29%)]\tClassification Loss: 1.4872\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_21_500.pth.tar\r\n",
      "Train Epoch: 21 [32640/110534 (30%)]\tClassification Loss: 1.3314\r\n",
      "Train Epoch: 21 [33280/110534 (30%)]\tClassification Loss: 1.3937\r\n",
      "Train Epoch: 21 [33920/110534 (31%)]\tClassification Loss: 1.6196\r\n",
      "Train Epoch: 21 [34560/110534 (31%)]\tClassification Loss: 1.7724\r\n",
      "Train Epoch: 21 [35200/110534 (32%)]\tClassification Loss: 1.4075\r\n",
      "Train Epoch: 21 [35840/110534 (32%)]\tClassification Loss: 1.1395\r\n",
      "Train Epoch: 21 [36480/110534 (33%)]\tClassification Loss: 1.3984\r\n",
      "Train Epoch: 21 [37120/110534 (34%)]\tClassification Loss: 1.6192\r\n",
      "Train Epoch: 21 [37760/110534 (34%)]\tClassification Loss: 1.7801\r\n",
      "Train Epoch: 21 [38400/110534 (35%)]\tClassification Loss: 1.4618\r\n",
      "Train Epoch: 21 [39040/110534 (35%)]\tClassification Loss: 1.4200\r\n",
      "Train Epoch: 21 [39680/110534 (36%)]\tClassification Loss: 1.4899\r\n",
      "Train Epoch: 21 [40320/110534 (36%)]\tClassification Loss: 1.5829\r\n",
      "Train Epoch: 21 [40960/110534 (37%)]\tClassification Loss: 1.2934\r\n",
      "Train Epoch: 21 [41600/110534 (38%)]\tClassification Loss: 1.3631\r\n",
      "Train Epoch: 21 [42240/110534 (38%)]\tClassification Loss: 1.4661\r\n",
      "Train Epoch: 21 [42880/110534 (39%)]\tClassification Loss: 1.4400\r\n",
      "Train Epoch: 21 [43520/110534 (39%)]\tClassification Loss: 1.2746\r\n",
      "Train Epoch: 21 [44160/110534 (40%)]\tClassification Loss: 1.4952\r\n",
      "Train Epoch: 21 [44800/110534 (41%)]\tClassification Loss: 1.5471\r\n",
      "Train Epoch: 21 [45440/110534 (41%)]\tClassification Loss: 1.6065\r\n",
      "Train Epoch: 21 [46080/110534 (42%)]\tClassification Loss: 1.4844\r\n",
      "Train Epoch: 21 [46720/110534 (42%)]\tClassification Loss: 1.4563\r\n",
      "Train Epoch: 21 [47360/110534 (43%)]\tClassification Loss: 1.4103\r\n",
      "Train Epoch: 21 [48000/110534 (43%)]\tClassification Loss: 1.6339\r\n",
      "Train Epoch: 21 [48640/110534 (44%)]\tClassification Loss: 1.3457\r\n",
      "Train Epoch: 21 [49280/110534 (45%)]\tClassification Loss: 1.5061\r\n",
      "Train Epoch: 21 [49920/110534 (45%)]\tClassification Loss: 1.7691\r\n",
      "Train Epoch: 21 [50560/110534 (46%)]\tClassification Loss: 1.5572\r\n",
      "Train Epoch: 21 [51200/110534 (46%)]\tClassification Loss: 1.4352\r\n",
      "Train Epoch: 21 [51840/110534 (47%)]\tClassification Loss: 1.4021\r\n",
      "Train Epoch: 21 [52480/110534 (47%)]\tClassification Loss: 1.5673\r\n",
      "Train Epoch: 21 [53120/110534 (48%)]\tClassification Loss: 1.2074\r\n",
      "Train Epoch: 21 [53760/110534 (49%)]\tClassification Loss: 1.6488\r\n",
      "Train Epoch: 21 [54400/110534 (49%)]\tClassification Loss: 1.3725\r\n",
      "Train Epoch: 21 [55040/110534 (50%)]\tClassification Loss: 1.7783\r\n",
      "Train Epoch: 21 [55680/110534 (50%)]\tClassification Loss: 1.7123\r\n",
      "Train Epoch: 21 [56320/110534 (51%)]\tClassification Loss: 1.4780\r\n",
      "Train Epoch: 21 [56960/110534 (52%)]\tClassification Loss: 1.6144\r\n",
      "Train Epoch: 21 [57600/110534 (52%)]\tClassification Loss: 1.6463\r\n",
      "Train Epoch: 21 [58240/110534 (53%)]\tClassification Loss: 1.7483\r\n",
      "Train Epoch: 21 [58880/110534 (53%)]\tClassification Loss: 1.6713\r\n",
      "Train Epoch: 21 [59520/110534 (54%)]\tClassification Loss: 1.3958\r\n",
      "Train Epoch: 21 [60160/110534 (54%)]\tClassification Loss: 1.3405\r\n",
      "Train Epoch: 21 [60800/110534 (55%)]\tClassification Loss: 1.4565\r\n",
      "Train Epoch: 21 [61440/110534 (56%)]\tClassification Loss: 1.5213\r\n",
      "Train Epoch: 21 [62080/110534 (56%)]\tClassification Loss: 1.5226\r\n",
      "Train Epoch: 21 [62720/110534 (57%)]\tClassification Loss: 1.6706\r\n",
      "Train Epoch: 21 [63360/110534 (57%)]\tClassification Loss: 1.2849\r\n",
      "Train Epoch: 21 [64000/110534 (58%)]\tClassification Loss: 1.4697\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_21_1000.pth.tar\r\n",
      "Train Epoch: 21 [64640/110534 (58%)]\tClassification Loss: 1.2625\r\n",
      "Train Epoch: 21 [65280/110534 (59%)]\tClassification Loss: 1.5914\r\n",
      "Train Epoch: 21 [65920/110534 (60%)]\tClassification Loss: 1.4486\r\n",
      "Train Epoch: 21 [66560/110534 (60%)]\tClassification Loss: 1.3360\r\n",
      "Train Epoch: 21 [67200/110534 (61%)]\tClassification Loss: 1.2159\r\n",
      "Train Epoch: 21 [67840/110534 (61%)]\tClassification Loss: 1.8606\r\n",
      "Train Epoch: 21 [68480/110534 (62%)]\tClassification Loss: 1.7556\r\n",
      "Train Epoch: 21 [69120/110534 (63%)]\tClassification Loss: 1.7758\r\n",
      "Train Epoch: 21 [69760/110534 (63%)]\tClassification Loss: 1.6505\r\n",
      "Train Epoch: 21 [70400/110534 (64%)]\tClassification Loss: 1.1847\r\n",
      "Train Epoch: 21 [71040/110534 (64%)]\tClassification Loss: 1.7689\r\n",
      "Train Epoch: 21 [71680/110534 (65%)]\tClassification Loss: 1.4588\r\n",
      "Train Epoch: 21 [72320/110534 (65%)]\tClassification Loss: 1.6517\r\n",
      "Train Epoch: 21 [72960/110534 (66%)]\tClassification Loss: 1.8494\r\n",
      "Train Epoch: 21 [73600/110534 (67%)]\tClassification Loss: 1.7295\r\n",
      "Train Epoch: 21 [74240/110534 (67%)]\tClassification Loss: 1.7127\r\n",
      "Train Epoch: 21 [74880/110534 (68%)]\tClassification Loss: 1.2958\r\n",
      "Train Epoch: 21 [75520/110534 (68%)]\tClassification Loss: 1.4480\r\n",
      "Train Epoch: 21 [76160/110534 (69%)]\tClassification Loss: 1.2915\r\n",
      "Train Epoch: 21 [76800/110534 (69%)]\tClassification Loss: 1.4461\r\n",
      "Train Epoch: 21 [77440/110534 (70%)]\tClassification Loss: 1.4131\r\n",
      "Train Epoch: 21 [78080/110534 (71%)]\tClassification Loss: 1.4231\r\n",
      "Train Epoch: 21 [78720/110534 (71%)]\tClassification Loss: 1.3786\r\n",
      "Train Epoch: 21 [79360/110534 (72%)]\tClassification Loss: 1.4048\r\n",
      "Train Epoch: 21 [80000/110534 (72%)]\tClassification Loss: 1.4130\r\n",
      "Train Epoch: 21 [80640/110534 (73%)]\tClassification Loss: 1.4036\r\n",
      "Train Epoch: 21 [81280/110534 (74%)]\tClassification Loss: 1.9153\r\n",
      "Train Epoch: 21 [81920/110534 (74%)]\tClassification Loss: 1.5048\r\n",
      "Train Epoch: 21 [82560/110534 (75%)]\tClassification Loss: 1.6445\r\n",
      "Train Epoch: 21 [83200/110534 (75%)]\tClassification Loss: 1.6130\r\n",
      "Train Epoch: 21 [83840/110534 (76%)]\tClassification Loss: 1.8470\r\n",
      "Train Epoch: 21 [84480/110534 (76%)]\tClassification Loss: 1.8147\r\n",
      "Train Epoch: 21 [85120/110534 (77%)]\tClassification Loss: 1.3957\r\n",
      "Train Epoch: 21 [85760/110534 (78%)]\tClassification Loss: 1.5553\r\n",
      "Train Epoch: 21 [86400/110534 (78%)]\tClassification Loss: 1.7760\r\n",
      "Train Epoch: 21 [87040/110534 (79%)]\tClassification Loss: 1.5777\r\n",
      "Train Epoch: 21 [87680/110534 (79%)]\tClassification Loss: 1.3771\r\n",
      "Train Epoch: 21 [88320/110534 (80%)]\tClassification Loss: 1.6238\r\n",
      "Train Epoch: 21 [88960/110534 (80%)]\tClassification Loss: 1.7783\r\n",
      "Train Epoch: 21 [89600/110534 (81%)]\tClassification Loss: 1.6472\r\n",
      "Train Epoch: 21 [90240/110534 (82%)]\tClassification Loss: 1.7781\r\n",
      "Train Epoch: 21 [90880/110534 (82%)]\tClassification Loss: 1.6244\r\n",
      "Train Epoch: 21 [91520/110534 (83%)]\tClassification Loss: 1.2760\r\n",
      "Train Epoch: 21 [92160/110534 (83%)]\tClassification Loss: 1.3498\r\n",
      "Train Epoch: 21 [92800/110534 (84%)]\tClassification Loss: 1.4299\r\n",
      "Train Epoch: 21 [93440/110534 (85%)]\tClassification Loss: 1.6201\r\n",
      "Train Epoch: 21 [94080/110534 (85%)]\tClassification Loss: 1.5650\r\n",
      "Train Epoch: 21 [94720/110534 (86%)]\tClassification Loss: 1.3788\r\n",
      "Train Epoch: 21 [95360/110534 (86%)]\tClassification Loss: 1.3998\r\n",
      "Train Epoch: 21 [96000/110534 (87%)]\tClassification Loss: 1.4588\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_21_1500.pth.tar\r\n",
      "Train Epoch: 21 [96640/110534 (87%)]\tClassification Loss: 1.2580\r\n",
      "Train Epoch: 21 [97280/110534 (88%)]\tClassification Loss: 1.3256\r\n",
      "Train Epoch: 21 [97920/110534 (89%)]\tClassification Loss: 1.2110\r\n",
      "Train Epoch: 21 [98560/110534 (89%)]\tClassification Loss: 1.5622\r\n",
      "Train Epoch: 21 [99200/110534 (90%)]\tClassification Loss: 1.5747\r\n",
      "Train Epoch: 21 [99840/110534 (90%)]\tClassification Loss: 1.5103\r\n",
      "Train Epoch: 21 [100480/110534 (91%)]\tClassification Loss: 1.6653\r\n",
      "Train Epoch: 21 [101120/110534 (91%)]\tClassification Loss: 1.6050\r\n",
      "Train Epoch: 21 [101760/110534 (92%)]\tClassification Loss: 1.3935\r\n",
      "Train Epoch: 21 [102400/110534 (93%)]\tClassification Loss: 1.3243\r\n",
      "Train Epoch: 21 [103040/110534 (93%)]\tClassification Loss: 1.4810\r\n",
      "Train Epoch: 21 [103680/110534 (94%)]\tClassification Loss: 1.7063\r\n",
      "Train Epoch: 21 [104320/110534 (94%)]\tClassification Loss: 1.5306\r\n",
      "Train Epoch: 21 [104960/110534 (95%)]\tClassification Loss: 1.5814\r\n",
      "Train Epoch: 21 [105600/110534 (96%)]\tClassification Loss: 1.4012\r\n",
      "Train Epoch: 21 [106240/110534 (96%)]\tClassification Loss: 1.4126\r\n",
      "Train Epoch: 21 [106880/110534 (97%)]\tClassification Loss: 1.7579\r\n",
      "Train Epoch: 21 [107520/110534 (97%)]\tClassification Loss: 1.6843\r\n",
      "Train Epoch: 21 [108160/110534 (98%)]\tClassification Loss: 1.5728\r\n",
      "Train Epoch: 21 [108800/110534 (98%)]\tClassification Loss: 1.5970\r\n",
      "Train Epoch: 21 [109440/110534 (99%)]\tClassification Loss: 1.4570\r\n",
      "Train Epoch: 21 [110080/110534 (100%)]\tClassification Loss: 1.4620\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_21_final.pth.tar\r\n",
      "Train Epoch: 22 [0/110534 (0%)]\tClassification Loss: 1.4710\r\n",
      "\r\n",
      "Test set: Average loss: 1.4299, Accuracy: 22871/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 22 [640/110534 (1%)]\tClassification Loss: 1.1688\r\n",
      "Train Epoch: 22 [1280/110534 (1%)]\tClassification Loss: 1.8990\r\n",
      "Train Epoch: 22 [1920/110534 (2%)]\tClassification Loss: 1.6981\r\n",
      "Train Epoch: 22 [2560/110534 (2%)]\tClassification Loss: 1.7629\r\n",
      "Train Epoch: 22 [3200/110534 (3%)]\tClassification Loss: 1.3989\r\n",
      "Train Epoch: 22 [3840/110534 (3%)]\tClassification Loss: 1.2548\r\n",
      "Train Epoch: 22 [4480/110534 (4%)]\tClassification Loss: 1.6074\r\n",
      "Train Epoch: 22 [5120/110534 (5%)]\tClassification Loss: 1.5783\r\n",
      "Train Epoch: 22 [5760/110534 (5%)]\tClassification Loss: 1.5568\r\n",
      "Train Epoch: 22 [6400/110534 (6%)]\tClassification Loss: 1.2076\r\n",
      "Train Epoch: 22 [7040/110534 (6%)]\tClassification Loss: 1.5374\r\n",
      "Train Epoch: 22 [7680/110534 (7%)]\tClassification Loss: 1.6843\r\n",
      "Train Epoch: 22 [8320/110534 (8%)]\tClassification Loss: 1.7524\r\n",
      "Train Epoch: 22 [8960/110534 (8%)]\tClassification Loss: 1.7631\r\n",
      "Train Epoch: 22 [9600/110534 (9%)]\tClassification Loss: 1.5077\r\n",
      "Train Epoch: 22 [10240/110534 (9%)]\tClassification Loss: 1.5862\r\n",
      "Train Epoch: 22 [10880/110534 (10%)]\tClassification Loss: 1.4468\r\n",
      "Train Epoch: 22 [11520/110534 (10%)]\tClassification Loss: 1.6193\r\n",
      "Train Epoch: 22 [12160/110534 (11%)]\tClassification Loss: 1.4529\r\n",
      "Train Epoch: 22 [12800/110534 (12%)]\tClassification Loss: 1.7037\r\n",
      "Train Epoch: 22 [13440/110534 (12%)]\tClassification Loss: 1.3642\r\n",
      "Train Epoch: 22 [14080/110534 (13%)]\tClassification Loss: 1.6307\r\n",
      "Train Epoch: 22 [14720/110534 (13%)]\tClassification Loss: 1.7275\r\n",
      "Train Epoch: 22 [15360/110534 (14%)]\tClassification Loss: 1.6247\r\n",
      "Train Epoch: 22 [16000/110534 (14%)]\tClassification Loss: 1.6881\r\n",
      "Train Epoch: 22 [16640/110534 (15%)]\tClassification Loss: 1.5392\r\n",
      "Train Epoch: 22 [17280/110534 (16%)]\tClassification Loss: 1.7055\r\n",
      "Train Epoch: 22 [17920/110534 (16%)]\tClassification Loss: 1.4149\r\n",
      "Train Epoch: 22 [18560/110534 (17%)]\tClassification Loss: 1.7211\r\n",
      "Train Epoch: 22 [19200/110534 (17%)]\tClassification Loss: 1.6095\r\n",
      "Train Epoch: 22 [19840/110534 (18%)]\tClassification Loss: 1.5929\r\n",
      "Train Epoch: 22 [20480/110534 (19%)]\tClassification Loss: 1.8085\r\n",
      "Train Epoch: 22 [21120/110534 (19%)]\tClassification Loss: 1.7776\r\n",
      "Train Epoch: 22 [21760/110534 (20%)]\tClassification Loss: 1.2827\r\n",
      "Train Epoch: 22 [22400/110534 (20%)]\tClassification Loss: 1.5394\r\n",
      "Train Epoch: 22 [23040/110534 (21%)]\tClassification Loss: 1.0599\r\n",
      "Train Epoch: 22 [23680/110534 (21%)]\tClassification Loss: 1.7555\r\n",
      "Train Epoch: 22 [24320/110534 (22%)]\tClassification Loss: 1.3209\r\n",
      "Train Epoch: 22 [24960/110534 (23%)]\tClassification Loss: 1.6102\r\n",
      "Train Epoch: 22 [25600/110534 (23%)]\tClassification Loss: 1.2540\r\n",
      "Train Epoch: 22 [26240/110534 (24%)]\tClassification Loss: 1.4861\r\n",
      "Train Epoch: 22 [26880/110534 (24%)]\tClassification Loss: 1.7927\r\n",
      "Train Epoch: 22 [27520/110534 (25%)]\tClassification Loss: 1.4519\r\n",
      "Train Epoch: 22 [28160/110534 (25%)]\tClassification Loss: 1.7753\r\n",
      "Train Epoch: 22 [28800/110534 (26%)]\tClassification Loss: 1.8506\r\n",
      "Train Epoch: 22 [29440/110534 (27%)]\tClassification Loss: 1.7270\r\n",
      "Train Epoch: 22 [30080/110534 (27%)]\tClassification Loss: 1.7779\r\n",
      "Train Epoch: 22 [30720/110534 (28%)]\tClassification Loss: 1.4894\r\n",
      "Train Epoch: 22 [31360/110534 (28%)]\tClassification Loss: 1.5304\r\n",
      "Train Epoch: 22 [32000/110534 (29%)]\tClassification Loss: 1.5675\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_22_500.pth.tar\r\n",
      "Train Epoch: 22 [32640/110534 (30%)]\tClassification Loss: 1.4210\r\n",
      "Train Epoch: 22 [33280/110534 (30%)]\tClassification Loss: 1.4183\r\n",
      "Train Epoch: 22 [33920/110534 (31%)]\tClassification Loss: 1.6054\r\n",
      "Train Epoch: 22 [34560/110534 (31%)]\tClassification Loss: 1.7340\r\n",
      "Train Epoch: 22 [35200/110534 (32%)]\tClassification Loss: 1.3700\r\n",
      "Train Epoch: 22 [35840/110534 (32%)]\tClassification Loss: 1.2401\r\n",
      "Train Epoch: 22 [36480/110534 (33%)]\tClassification Loss: 1.4718\r\n",
      "Train Epoch: 22 [37120/110534 (34%)]\tClassification Loss: 1.5480\r\n",
      "Train Epoch: 22 [37760/110534 (34%)]\tClassification Loss: 1.7534\r\n",
      "Train Epoch: 22 [38400/110534 (35%)]\tClassification Loss: 1.4987\r\n",
      "Train Epoch: 22 [39040/110534 (35%)]\tClassification Loss: 1.4006\r\n",
      "Train Epoch: 22 [39680/110534 (36%)]\tClassification Loss: 1.5803\r\n",
      "Train Epoch: 22 [40320/110534 (36%)]\tClassification Loss: 1.3752\r\n",
      "Train Epoch: 22 [40960/110534 (37%)]\tClassification Loss: 1.2086\r\n",
      "Train Epoch: 22 [41600/110534 (38%)]\tClassification Loss: 1.4831\r\n",
      "Train Epoch: 22 [42240/110534 (38%)]\tClassification Loss: 1.3479\r\n",
      "Train Epoch: 22 [42880/110534 (39%)]\tClassification Loss: 1.4438\r\n",
      "Train Epoch: 22 [43520/110534 (39%)]\tClassification Loss: 1.2331\r\n",
      "Train Epoch: 22 [44160/110534 (40%)]\tClassification Loss: 1.6480\r\n",
      "Train Epoch: 22 [44800/110534 (41%)]\tClassification Loss: 1.6614\r\n",
      "Train Epoch: 22 [45440/110534 (41%)]\tClassification Loss: 1.6513\r\n",
      "Train Epoch: 22 [46080/110534 (42%)]\tClassification Loss: 1.3766\r\n",
      "Train Epoch: 22 [46720/110534 (42%)]\tClassification Loss: 1.5113\r\n",
      "Train Epoch: 22 [47360/110534 (43%)]\tClassification Loss: 1.5727\r\n",
      "Train Epoch: 22 [48000/110534 (43%)]\tClassification Loss: 1.6296\r\n",
      "Train Epoch: 22 [48640/110534 (44%)]\tClassification Loss: 1.3529\r\n",
      "Train Epoch: 22 [49280/110534 (45%)]\tClassification Loss: 1.6769\r\n",
      "Train Epoch: 22 [49920/110534 (45%)]\tClassification Loss: 1.6198\r\n",
      "Train Epoch: 22 [50560/110534 (46%)]\tClassification Loss: 1.5790\r\n",
      "Train Epoch: 22 [51200/110534 (46%)]\tClassification Loss: 1.2860\r\n",
      "Train Epoch: 22 [51840/110534 (47%)]\tClassification Loss: 1.5733\r\n",
      "Train Epoch: 22 [52480/110534 (47%)]\tClassification Loss: 1.6007\r\n",
      "Train Epoch: 22 [53120/110534 (48%)]\tClassification Loss: 1.2029\r\n",
      "Train Epoch: 22 [53760/110534 (49%)]\tClassification Loss: 1.5854\r\n",
      "Train Epoch: 22 [54400/110534 (49%)]\tClassification Loss: 1.4098\r\n",
      "Train Epoch: 22 [55040/110534 (50%)]\tClassification Loss: 1.6494\r\n",
      "Train Epoch: 22 [55680/110534 (50%)]\tClassification Loss: 1.7984\r\n",
      "Train Epoch: 22 [56320/110534 (51%)]\tClassification Loss: 1.4121\r\n",
      "Train Epoch: 22 [56960/110534 (52%)]\tClassification Loss: 1.5090\r\n",
      "Train Epoch: 22 [57600/110534 (52%)]\tClassification Loss: 1.7474\r\n",
      "Train Epoch: 22 [58240/110534 (53%)]\tClassification Loss: 1.5621\r\n",
      "Train Epoch: 22 [58880/110534 (53%)]\tClassification Loss: 1.7234\r\n",
      "Train Epoch: 22 [59520/110534 (54%)]\tClassification Loss: 1.4366\r\n",
      "Train Epoch: 22 [60160/110534 (54%)]\tClassification Loss: 1.4772\r\n",
      "Train Epoch: 22 [60800/110534 (55%)]\tClassification Loss: 1.5514\r\n",
      "Train Epoch: 22 [61440/110534 (56%)]\tClassification Loss: 1.3554\r\n",
      "Train Epoch: 22 [62080/110534 (56%)]\tClassification Loss: 1.4341\r\n",
      "Train Epoch: 22 [62720/110534 (57%)]\tClassification Loss: 1.7427\r\n",
      "Train Epoch: 22 [63360/110534 (57%)]\tClassification Loss: 1.4121\r\n",
      "Train Epoch: 22 [64000/110534 (58%)]\tClassification Loss: 1.5604\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_22_1000.pth.tar\r\n",
      "Train Epoch: 22 [64640/110534 (58%)]\tClassification Loss: 1.1722\r\n",
      "Train Epoch: 22 [65280/110534 (59%)]\tClassification Loss: 1.5775\r\n",
      "Train Epoch: 22 [65920/110534 (60%)]\tClassification Loss: 1.5671\r\n",
      "Train Epoch: 22 [66560/110534 (60%)]\tClassification Loss: 1.4072\r\n",
      "Train Epoch: 22 [67200/110534 (61%)]\tClassification Loss: 1.3887\r\n",
      "Train Epoch: 22 [67840/110534 (61%)]\tClassification Loss: 1.8931\r\n",
      "Train Epoch: 22 [68480/110534 (62%)]\tClassification Loss: 1.6119\r\n",
      "Train Epoch: 22 [69120/110534 (63%)]\tClassification Loss: 1.7449\r\n",
      "Train Epoch: 22 [69760/110534 (63%)]\tClassification Loss: 1.6642\r\n",
      "Train Epoch: 22 [70400/110534 (64%)]\tClassification Loss: 1.4313\r\n",
      "Train Epoch: 22 [71040/110534 (64%)]\tClassification Loss: 1.8677\r\n",
      "Train Epoch: 22 [71680/110534 (65%)]\tClassification Loss: 1.4872\r\n",
      "Train Epoch: 22 [72320/110534 (65%)]\tClassification Loss: 1.6493\r\n",
      "Train Epoch: 22 [72960/110534 (66%)]\tClassification Loss: 1.7948\r\n",
      "Train Epoch: 22 [73600/110534 (67%)]\tClassification Loss: 1.7759\r\n",
      "Train Epoch: 22 [74240/110534 (67%)]\tClassification Loss: 1.6750\r\n",
      "Train Epoch: 22 [74880/110534 (68%)]\tClassification Loss: 1.2097\r\n",
      "Train Epoch: 22 [75520/110534 (68%)]\tClassification Loss: 1.5932\r\n",
      "Train Epoch: 22 [76160/110534 (69%)]\tClassification Loss: 1.3616\r\n",
      "Train Epoch: 22 [76800/110534 (69%)]\tClassification Loss: 1.2472\r\n",
      "Train Epoch: 22 [77440/110534 (70%)]\tClassification Loss: 1.5487\r\n",
      "Train Epoch: 22 [78080/110534 (71%)]\tClassification Loss: 1.3292\r\n",
      "Train Epoch: 22 [78720/110534 (71%)]\tClassification Loss: 1.5260\r\n",
      "Train Epoch: 22 [79360/110534 (72%)]\tClassification Loss: 1.4757\r\n",
      "Train Epoch: 22 [80000/110534 (72%)]\tClassification Loss: 1.3499\r\n",
      "Train Epoch: 22 [80640/110534 (73%)]\tClassification Loss: 1.5637\r\n",
      "Train Epoch: 22 [81280/110534 (74%)]\tClassification Loss: 1.8148\r\n",
      "Train Epoch: 22 [81920/110534 (74%)]\tClassification Loss: 1.4881\r\n",
      "Train Epoch: 22 [82560/110534 (75%)]\tClassification Loss: 1.8248\r\n",
      "Train Epoch: 22 [83200/110534 (75%)]\tClassification Loss: 1.3861\r\n",
      "Train Epoch: 22 [83840/110534 (76%)]\tClassification Loss: 1.7738\r\n",
      "Train Epoch: 22 [84480/110534 (76%)]\tClassification Loss: 1.6398\r\n",
      "Train Epoch: 22 [85120/110534 (77%)]\tClassification Loss: 1.5750\r\n",
      "Train Epoch: 22 [85760/110534 (78%)]\tClassification Loss: 1.4549\r\n",
      "Train Epoch: 22 [86400/110534 (78%)]\tClassification Loss: 1.5751\r\n",
      "Train Epoch: 22 [87040/110534 (79%)]\tClassification Loss: 1.4742\r\n",
      "Train Epoch: 22 [87680/110534 (79%)]\tClassification Loss: 1.5373\r\n",
      "Train Epoch: 22 [88320/110534 (80%)]\tClassification Loss: 1.5289\r\n",
      "Train Epoch: 22 [88960/110534 (80%)]\tClassification Loss: 1.6183\r\n",
      "Train Epoch: 22 [89600/110534 (81%)]\tClassification Loss: 1.7458\r\n",
      "Train Epoch: 22 [90240/110534 (82%)]\tClassification Loss: 1.5676\r\n",
      "Train Epoch: 22 [90880/110534 (82%)]\tClassification Loss: 1.5380\r\n",
      "Train Epoch: 22 [91520/110534 (83%)]\tClassification Loss: 1.2694\r\n",
      "Train Epoch: 22 [92160/110534 (83%)]\tClassification Loss: 1.4554\r\n",
      "Train Epoch: 22 [92800/110534 (84%)]\tClassification Loss: 1.4460\r\n",
      "Train Epoch: 22 [93440/110534 (85%)]\tClassification Loss: 1.6088\r\n",
      "Train Epoch: 22 [94080/110534 (85%)]\tClassification Loss: 1.5218\r\n",
      "Train Epoch: 22 [94720/110534 (86%)]\tClassification Loss: 1.4634\r\n",
      "Train Epoch: 22 [95360/110534 (86%)]\tClassification Loss: 1.4168\r\n",
      "Train Epoch: 22 [96000/110534 (87%)]\tClassification Loss: 1.4550\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_22_1500.pth.tar\r\n",
      "Train Epoch: 22 [96640/110534 (87%)]\tClassification Loss: 1.3640\r\n",
      "Train Epoch: 22 [97280/110534 (88%)]\tClassification Loss: 1.2299\r\n",
      "Train Epoch: 22 [97920/110534 (89%)]\tClassification Loss: 1.1707\r\n",
      "Train Epoch: 22 [98560/110534 (89%)]\tClassification Loss: 1.4219\r\n",
      "Train Epoch: 22 [99200/110534 (90%)]\tClassification Loss: 1.8033\r\n",
      "Train Epoch: 22 [99840/110534 (90%)]\tClassification Loss: 1.4548\r\n",
      "Train Epoch: 22 [100480/110534 (91%)]\tClassification Loss: 1.7001\r\n",
      "Train Epoch: 22 [101120/110534 (91%)]\tClassification Loss: 1.4295\r\n",
      "Train Epoch: 22 [101760/110534 (92%)]\tClassification Loss: 1.5987\r\n",
      "Train Epoch: 22 [102400/110534 (93%)]\tClassification Loss: 1.5339\r\n",
      "Train Epoch: 22 [103040/110534 (93%)]\tClassification Loss: 1.3158\r\n",
      "Train Epoch: 22 [103680/110534 (94%)]\tClassification Loss: 1.6858\r\n",
      "Train Epoch: 22 [104320/110534 (94%)]\tClassification Loss: 1.4948\r\n",
      "Train Epoch: 22 [104960/110534 (95%)]\tClassification Loss: 1.5806\r\n",
      "Train Epoch: 22 [105600/110534 (96%)]\tClassification Loss: 1.5175\r\n",
      "Train Epoch: 22 [106240/110534 (96%)]\tClassification Loss: 1.3055\r\n",
      "Train Epoch: 22 [106880/110534 (97%)]\tClassification Loss: 1.7414\r\n",
      "Train Epoch: 22 [107520/110534 (97%)]\tClassification Loss: 1.6099\r\n",
      "Train Epoch: 22 [108160/110534 (98%)]\tClassification Loss: 1.4434\r\n",
      "Train Epoch: 22 [108800/110534 (98%)]\tClassification Loss: 1.6750\r\n",
      "Train Epoch: 22 [109440/110534 (99%)]\tClassification Loss: 1.4769\r\n",
      "Train Epoch: 22 [110080/110534 (100%)]\tClassification Loss: 1.4966\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_22_final.pth.tar\r\n",
      "Train Epoch: 23 [0/110534 (0%)]\tClassification Loss: 1.4103\r\n",
      "\r\n",
      "Test set: Average loss: 1.4281, Accuracy: 22897/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 23 [640/110534 (1%)]\tClassification Loss: 1.2702\r\n",
      "Train Epoch: 23 [1280/110534 (1%)]\tClassification Loss: 2.0365\r\n",
      "Train Epoch: 23 [1920/110534 (2%)]\tClassification Loss: 1.6231\r\n",
      "Train Epoch: 23 [2560/110534 (2%)]\tClassification Loss: 1.7337\r\n",
      "Train Epoch: 23 [3200/110534 (3%)]\tClassification Loss: 1.4419\r\n",
      "Train Epoch: 23 [3840/110534 (3%)]\tClassification Loss: 1.4678\r\n",
      "Train Epoch: 23 [4480/110534 (4%)]\tClassification Loss: 1.6139\r\n",
      "Train Epoch: 23 [5120/110534 (5%)]\tClassification Loss: 1.5270\r\n",
      "Train Epoch: 23 [5760/110534 (5%)]\tClassification Loss: 1.6286\r\n",
      "Train Epoch: 23 [6400/110534 (6%)]\tClassification Loss: 1.3068\r\n",
      "Train Epoch: 23 [7040/110534 (6%)]\tClassification Loss: 1.5514\r\n",
      "Train Epoch: 23 [7680/110534 (7%)]\tClassification Loss: 1.4772\r\n",
      "Train Epoch: 23 [8320/110534 (8%)]\tClassification Loss: 1.7137\r\n",
      "Train Epoch: 23 [8960/110534 (8%)]\tClassification Loss: 1.7597\r\n",
      "Train Epoch: 23 [9600/110534 (9%)]\tClassification Loss: 1.4815\r\n",
      "Train Epoch: 23 [10240/110534 (9%)]\tClassification Loss: 1.5266\r\n",
      "Train Epoch: 23 [10880/110534 (10%)]\tClassification Loss: 1.5412\r\n",
      "Train Epoch: 23 [11520/110534 (10%)]\tClassification Loss: 1.6240\r\n",
      "Train Epoch: 23 [12160/110534 (11%)]\tClassification Loss: 1.4017\r\n",
      "Train Epoch: 23 [12800/110534 (12%)]\tClassification Loss: 1.5517\r\n",
      "Train Epoch: 23 [13440/110534 (12%)]\tClassification Loss: 1.3897\r\n",
      "Train Epoch: 23 [14080/110534 (13%)]\tClassification Loss: 1.6310\r\n",
      "Train Epoch: 23 [14720/110534 (13%)]\tClassification Loss: 1.7330\r\n",
      "Train Epoch: 23 [15360/110534 (14%)]\tClassification Loss: 1.5308\r\n",
      "Train Epoch: 23 [16000/110534 (14%)]\tClassification Loss: 1.6986\r\n",
      "Train Epoch: 23 [16640/110534 (15%)]\tClassification Loss: 1.4323\r\n",
      "Train Epoch: 23 [17280/110534 (16%)]\tClassification Loss: 1.6258\r\n",
      "Train Epoch: 23 [17920/110534 (16%)]\tClassification Loss: 1.5302\r\n",
      "Train Epoch: 23 [18560/110534 (17%)]\tClassification Loss: 1.7012\r\n",
      "Train Epoch: 23 [19200/110534 (17%)]\tClassification Loss: 1.7826\r\n",
      "Train Epoch: 23 [19840/110534 (18%)]\tClassification Loss: 1.5941\r\n",
      "Train Epoch: 23 [20480/110534 (19%)]\tClassification Loss: 1.7975\r\n",
      "Train Epoch: 23 [21120/110534 (19%)]\tClassification Loss: 1.7665\r\n",
      "Train Epoch: 23 [21760/110534 (20%)]\tClassification Loss: 1.5066\r\n",
      "Train Epoch: 23 [22400/110534 (20%)]\tClassification Loss: 1.4352\r\n",
      "Train Epoch: 23 [23040/110534 (21%)]\tClassification Loss: 1.1967\r\n",
      "Train Epoch: 23 [23680/110534 (21%)]\tClassification Loss: 1.5493\r\n",
      "Train Epoch: 23 [24320/110534 (22%)]\tClassification Loss: 1.2428\r\n",
      "Train Epoch: 23 [24960/110534 (23%)]\tClassification Loss: 1.8128\r\n",
      "Train Epoch: 23 [25600/110534 (23%)]\tClassification Loss: 1.3099\r\n",
      "Train Epoch: 23 [26240/110534 (24%)]\tClassification Loss: 1.3893\r\n",
      "Train Epoch: 23 [26880/110534 (24%)]\tClassification Loss: 1.6989\r\n",
      "Train Epoch: 23 [27520/110534 (25%)]\tClassification Loss: 1.3549\r\n",
      "Train Epoch: 23 [28160/110534 (25%)]\tClassification Loss: 1.7229\r\n",
      "Train Epoch: 23 [28800/110534 (26%)]\tClassification Loss: 1.8378\r\n",
      "Train Epoch: 23 [29440/110534 (27%)]\tClassification Loss: 1.5360\r\n",
      "Train Epoch: 23 [30080/110534 (27%)]\tClassification Loss: 1.8736\r\n",
      "Train Epoch: 23 [30720/110534 (28%)]\tClassification Loss: 1.5195\r\n",
      "Train Epoch: 23 [31360/110534 (28%)]\tClassification Loss: 1.6113\r\n",
      "Train Epoch: 23 [32000/110534 (29%)]\tClassification Loss: 1.5105\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_23_500.pth.tar\r\n",
      "Train Epoch: 23 [32640/110534 (30%)]\tClassification Loss: 1.3375\r\n",
      "Train Epoch: 23 [33280/110534 (30%)]\tClassification Loss: 1.4663\r\n",
      "Train Epoch: 23 [33920/110534 (31%)]\tClassification Loss: 1.5315\r\n",
      "Train Epoch: 23 [34560/110534 (31%)]\tClassification Loss: 1.8691\r\n",
      "Train Epoch: 23 [35200/110534 (32%)]\tClassification Loss: 1.3907\r\n",
      "Train Epoch: 23 [35840/110534 (32%)]\tClassification Loss: 1.2068\r\n",
      "Train Epoch: 23 [36480/110534 (33%)]\tClassification Loss: 1.4150\r\n",
      "Train Epoch: 23 [37120/110534 (34%)]\tClassification Loss: 1.6618\r\n",
      "Train Epoch: 23 [37760/110534 (34%)]\tClassification Loss: 1.7826\r\n",
      "Train Epoch: 23 [38400/110534 (35%)]\tClassification Loss: 1.3776\r\n",
      "Train Epoch: 23 [39040/110534 (35%)]\tClassification Loss: 1.4287\r\n",
      "Train Epoch: 23 [39680/110534 (36%)]\tClassification Loss: 1.6837\r\n",
      "Train Epoch: 23 [40320/110534 (36%)]\tClassification Loss: 1.4768\r\n",
      "Train Epoch: 23 [40960/110534 (37%)]\tClassification Loss: 1.4957\r\n",
      "Train Epoch: 23 [41600/110534 (38%)]\tClassification Loss: 1.3419\r\n",
      "Train Epoch: 23 [42240/110534 (38%)]\tClassification Loss: 1.4239\r\n",
      "Train Epoch: 23 [42880/110534 (39%)]\tClassification Loss: 1.4735\r\n",
      "Train Epoch: 23 [43520/110534 (39%)]\tClassification Loss: 1.2074\r\n",
      "Train Epoch: 23 [44160/110534 (40%)]\tClassification Loss: 1.5619\r\n",
      "Train Epoch: 23 [44800/110534 (41%)]\tClassification Loss: 1.6980\r\n",
      "Train Epoch: 23 [45440/110534 (41%)]\tClassification Loss: 1.5599\r\n",
      "Train Epoch: 23 [46080/110534 (42%)]\tClassification Loss: 1.4267\r\n",
      "Train Epoch: 23 [46720/110534 (42%)]\tClassification Loss: 1.4411\r\n",
      "Train Epoch: 23 [47360/110534 (43%)]\tClassification Loss: 1.4256\r\n",
      "Train Epoch: 23 [48000/110534 (43%)]\tClassification Loss: 1.5604\r\n",
      "Train Epoch: 23 [48640/110534 (44%)]\tClassification Loss: 1.3816\r\n",
      "Train Epoch: 23 [49280/110534 (45%)]\tClassification Loss: 1.5507\r\n",
      "Train Epoch: 23 [49920/110534 (45%)]\tClassification Loss: 1.6924\r\n",
      "Train Epoch: 23 [50560/110534 (46%)]\tClassification Loss: 1.4893\r\n",
      "Train Epoch: 23 [51200/110534 (46%)]\tClassification Loss: 1.4086\r\n",
      "Train Epoch: 23 [51840/110534 (47%)]\tClassification Loss: 1.5461\r\n",
      "Train Epoch: 23 [52480/110534 (47%)]\tClassification Loss: 1.5225\r\n",
      "Train Epoch: 23 [53120/110534 (48%)]\tClassification Loss: 1.1356\r\n",
      "Train Epoch: 23 [53760/110534 (49%)]\tClassification Loss: 1.6146\r\n",
      "Train Epoch: 23 [54400/110534 (49%)]\tClassification Loss: 1.5626\r\n",
      "Train Epoch: 23 [55040/110534 (50%)]\tClassification Loss: 1.7551\r\n",
      "Train Epoch: 23 [55680/110534 (50%)]\tClassification Loss: 1.5895\r\n",
      "Train Epoch: 23 [56320/110534 (51%)]\tClassification Loss: 1.4976\r\n",
      "Train Epoch: 23 [56960/110534 (52%)]\tClassification Loss: 1.6121\r\n",
      "Train Epoch: 23 [57600/110534 (52%)]\tClassification Loss: 1.8566\r\n",
      "Train Epoch: 23 [58240/110534 (53%)]\tClassification Loss: 1.5659\r\n",
      "Train Epoch: 23 [58880/110534 (53%)]\tClassification Loss: 1.7906\r\n",
      "Train Epoch: 23 [59520/110534 (54%)]\tClassification Loss: 1.4474\r\n",
      "Train Epoch: 23 [60160/110534 (54%)]\tClassification Loss: 1.4727\r\n",
      "Train Epoch: 23 [60800/110534 (55%)]\tClassification Loss: 1.5467\r\n",
      "Train Epoch: 23 [61440/110534 (56%)]\tClassification Loss: 1.7033\r\n",
      "Train Epoch: 23 [62080/110534 (56%)]\tClassification Loss: 1.5507\r\n",
      "Train Epoch: 23 [62720/110534 (57%)]\tClassification Loss: 1.6904\r\n",
      "Train Epoch: 23 [63360/110534 (57%)]\tClassification Loss: 1.2696\r\n",
      "Train Epoch: 23 [64000/110534 (58%)]\tClassification Loss: 1.4931\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_23_1000.pth.tar\r\n",
      "Train Epoch: 23 [64640/110534 (58%)]\tClassification Loss: 1.2745\r\n",
      "Train Epoch: 23 [65280/110534 (59%)]\tClassification Loss: 1.5362\r\n",
      "Train Epoch: 23 [65920/110534 (60%)]\tClassification Loss: 1.4820\r\n",
      "Train Epoch: 23 [66560/110534 (60%)]\tClassification Loss: 1.4785\r\n",
      "Train Epoch: 23 [67200/110534 (61%)]\tClassification Loss: 1.2907\r\n",
      "Train Epoch: 23 [67840/110534 (61%)]\tClassification Loss: 1.8117\r\n",
      "Train Epoch: 23 [68480/110534 (62%)]\tClassification Loss: 1.6071\r\n",
      "Train Epoch: 23 [69120/110534 (63%)]\tClassification Loss: 1.9331\r\n",
      "Train Epoch: 23 [69760/110534 (63%)]\tClassification Loss: 1.7592\r\n",
      "Train Epoch: 23 [70400/110534 (64%)]\tClassification Loss: 1.1988\r\n",
      "Train Epoch: 23 [71040/110534 (64%)]\tClassification Loss: 1.8855\r\n",
      "Train Epoch: 23 [71680/110534 (65%)]\tClassification Loss: 1.4748\r\n",
      "Train Epoch: 23 [72320/110534 (65%)]\tClassification Loss: 1.7400\r\n",
      "Train Epoch: 23 [72960/110534 (66%)]\tClassification Loss: 1.7612\r\n",
      "Train Epoch: 23 [73600/110534 (67%)]\tClassification Loss: 1.7314\r\n",
      "Train Epoch: 23 [74240/110534 (67%)]\tClassification Loss: 1.5385\r\n",
      "Train Epoch: 23 [74880/110534 (68%)]\tClassification Loss: 1.2434\r\n",
      "Train Epoch: 23 [75520/110534 (68%)]\tClassification Loss: 1.6102\r\n",
      "Train Epoch: 23 [76160/110534 (69%)]\tClassification Loss: 1.4338\r\n",
      "Train Epoch: 23 [76800/110534 (69%)]\tClassification Loss: 1.4012\r\n",
      "Train Epoch: 23 [77440/110534 (70%)]\tClassification Loss: 1.3799\r\n",
      "Train Epoch: 23 [78080/110534 (71%)]\tClassification Loss: 1.4692\r\n",
      "Train Epoch: 23 [78720/110534 (71%)]\tClassification Loss: 1.3877\r\n",
      "Train Epoch: 23 [79360/110534 (72%)]\tClassification Loss: 1.4017\r\n",
      "Train Epoch: 23 [80000/110534 (72%)]\tClassification Loss: 1.4373\r\n",
      "Train Epoch: 23 [80640/110534 (73%)]\tClassification Loss: 1.3635\r\n",
      "Train Epoch: 23 [81280/110534 (74%)]\tClassification Loss: 1.8930\r\n",
      "Train Epoch: 23 [81920/110534 (74%)]\tClassification Loss: 1.4991\r\n",
      "Train Epoch: 23 [82560/110534 (75%)]\tClassification Loss: 1.6367\r\n",
      "Train Epoch: 23 [83200/110534 (75%)]\tClassification Loss: 1.4891\r\n",
      "Train Epoch: 23 [83840/110534 (76%)]\tClassification Loss: 1.8937\r\n",
      "Train Epoch: 23 [84480/110534 (76%)]\tClassification Loss: 1.7744\r\n",
      "Train Epoch: 23 [85120/110534 (77%)]\tClassification Loss: 1.5409\r\n",
      "Train Epoch: 23 [85760/110534 (78%)]\tClassification Loss: 1.6346\r\n",
      "Train Epoch: 23 [86400/110534 (78%)]\tClassification Loss: 1.6778\r\n",
      "Train Epoch: 23 [87040/110534 (79%)]\tClassification Loss: 1.5614\r\n",
      "Train Epoch: 23 [87680/110534 (79%)]\tClassification Loss: 1.4635\r\n",
      "Train Epoch: 23 [88320/110534 (80%)]\tClassification Loss: 1.4453\r\n",
      "Train Epoch: 23 [88960/110534 (80%)]\tClassification Loss: 1.5660\r\n",
      "Train Epoch: 23 [89600/110534 (81%)]\tClassification Loss: 1.6849\r\n",
      "Train Epoch: 23 [90240/110534 (82%)]\tClassification Loss: 1.7622\r\n",
      "Train Epoch: 23 [90880/110534 (82%)]\tClassification Loss: 1.6922\r\n",
      "Train Epoch: 23 [91520/110534 (83%)]\tClassification Loss: 1.2185\r\n",
      "Train Epoch: 23 [92160/110534 (83%)]\tClassification Loss: 1.2705\r\n",
      "Train Epoch: 23 [92800/110534 (84%)]\tClassification Loss: 1.4668\r\n",
      "Train Epoch: 23 [93440/110534 (85%)]\tClassification Loss: 1.7939\r\n",
      "Train Epoch: 23 [94080/110534 (85%)]\tClassification Loss: 1.4991\r\n",
      "Train Epoch: 23 [94720/110534 (86%)]\tClassification Loss: 1.2996\r\n",
      "Train Epoch: 23 [95360/110534 (86%)]\tClassification Loss: 1.3725\r\n",
      "Train Epoch: 23 [96000/110534 (87%)]\tClassification Loss: 1.3885\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_23_1500.pth.tar\r\n",
      "Train Epoch: 23 [96640/110534 (87%)]\tClassification Loss: 1.3311\r\n",
      "Train Epoch: 23 [97280/110534 (88%)]\tClassification Loss: 1.3663\r\n",
      "Train Epoch: 23 [97920/110534 (89%)]\tClassification Loss: 1.1560\r\n",
      "Train Epoch: 23 [98560/110534 (89%)]\tClassification Loss: 1.4970\r\n",
      "Train Epoch: 23 [99200/110534 (90%)]\tClassification Loss: 1.6640\r\n",
      "Train Epoch: 23 [99840/110534 (90%)]\tClassification Loss: 1.3850\r\n",
      "Train Epoch: 23 [100480/110534 (91%)]\tClassification Loss: 1.6640\r\n",
      "Train Epoch: 23 [101120/110534 (91%)]\tClassification Loss: 1.4749\r\n",
      "Train Epoch: 23 [101760/110534 (92%)]\tClassification Loss: 1.4745\r\n",
      "Train Epoch: 23 [102400/110534 (93%)]\tClassification Loss: 1.4185\r\n",
      "Train Epoch: 23 [103040/110534 (93%)]\tClassification Loss: 1.4624\r\n",
      "Train Epoch: 23 [103680/110534 (94%)]\tClassification Loss: 1.7643\r\n",
      "Train Epoch: 23 [104320/110534 (94%)]\tClassification Loss: 1.3059\r\n",
      "Train Epoch: 23 [104960/110534 (95%)]\tClassification Loss: 1.4481\r\n",
      "Train Epoch: 23 [105600/110534 (96%)]\tClassification Loss: 1.4305\r\n",
      "Train Epoch: 23 [106240/110534 (96%)]\tClassification Loss: 1.3091\r\n",
      "Train Epoch: 23 [106880/110534 (97%)]\tClassification Loss: 1.6360\r\n",
      "Train Epoch: 23 [107520/110534 (97%)]\tClassification Loss: 1.6432\r\n",
      "Train Epoch: 23 [108160/110534 (98%)]\tClassification Loss: 1.5022\r\n",
      "Train Epoch: 23 [108800/110534 (98%)]\tClassification Loss: 1.7991\r\n",
      "Train Epoch: 23 [109440/110534 (99%)]\tClassification Loss: 1.4669\r\n",
      "Train Epoch: 23 [110080/110534 (100%)]\tClassification Loss: 1.4357\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_23_final.pth.tar\r\n",
      "Train Epoch: 24 [0/110534 (0%)]\tClassification Loss: 1.5391\r\n",
      "\r\n",
      "Test set: Average loss: 1.4268, Accuracy: 22920/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 24 [640/110534 (1%)]\tClassification Loss: 1.2841\r\n",
      "Train Epoch: 24 [1280/110534 (1%)]\tClassification Loss: 1.9572\r\n",
      "Train Epoch: 24 [1920/110534 (2%)]\tClassification Loss: 1.5606\r\n",
      "Train Epoch: 24 [2560/110534 (2%)]\tClassification Loss: 1.6849\r\n",
      "Train Epoch: 24 [3200/110534 (3%)]\tClassification Loss: 1.4955\r\n",
      "Train Epoch: 24 [3840/110534 (3%)]\tClassification Loss: 1.3834\r\n",
      "Train Epoch: 24 [4480/110534 (4%)]\tClassification Loss: 1.4191\r\n",
      "Train Epoch: 24 [5120/110534 (5%)]\tClassification Loss: 1.5257\r\n",
      "Train Epoch: 24 [5760/110534 (5%)]\tClassification Loss: 1.3853\r\n",
      "Train Epoch: 24 [6400/110534 (6%)]\tClassification Loss: 1.3240\r\n",
      "Train Epoch: 24 [7040/110534 (6%)]\tClassification Loss: 1.5668\r\n",
      "Train Epoch: 24 [7680/110534 (7%)]\tClassification Loss: 1.6473\r\n",
      "Train Epoch: 24 [8320/110534 (8%)]\tClassification Loss: 1.7643\r\n",
      "Train Epoch: 24 [8960/110534 (8%)]\tClassification Loss: 1.6783\r\n",
      "Train Epoch: 24 [9600/110534 (9%)]\tClassification Loss: 1.4499\r\n",
      "Train Epoch: 24 [10240/110534 (9%)]\tClassification Loss: 1.5503\r\n",
      "Train Epoch: 24 [10880/110534 (10%)]\tClassification Loss: 1.5497\r\n",
      "Train Epoch: 24 [11520/110534 (10%)]\tClassification Loss: 1.5918\r\n",
      "Train Epoch: 24 [12160/110534 (11%)]\tClassification Loss: 1.3177\r\n",
      "Train Epoch: 24 [12800/110534 (12%)]\tClassification Loss: 1.5227\r\n",
      "Train Epoch: 24 [13440/110534 (12%)]\tClassification Loss: 1.3905\r\n",
      "Train Epoch: 24 [14080/110534 (13%)]\tClassification Loss: 1.6449\r\n",
      "Train Epoch: 24 [14720/110534 (13%)]\tClassification Loss: 1.9349\r\n",
      "Train Epoch: 24 [15360/110534 (14%)]\tClassification Loss: 1.5364\r\n",
      "Train Epoch: 24 [16000/110534 (14%)]\tClassification Loss: 1.6150\r\n",
      "Train Epoch: 24 [16640/110534 (15%)]\tClassification Loss: 1.4994\r\n",
      "Train Epoch: 24 [17280/110534 (16%)]\tClassification Loss: 1.6073\r\n",
      "Train Epoch: 24 [17920/110534 (16%)]\tClassification Loss: 1.4133\r\n",
      "Train Epoch: 24 [18560/110534 (17%)]\tClassification Loss: 1.7058\r\n",
      "Train Epoch: 24 [19200/110534 (17%)]\tClassification Loss: 1.6850\r\n",
      "Train Epoch: 24 [19840/110534 (18%)]\tClassification Loss: 1.4515\r\n",
      "Train Epoch: 24 [20480/110534 (19%)]\tClassification Loss: 1.8093\r\n",
      "Train Epoch: 24 [21120/110534 (19%)]\tClassification Loss: 1.8099\r\n",
      "Train Epoch: 24 [21760/110534 (20%)]\tClassification Loss: 1.3487\r\n",
      "Train Epoch: 24 [22400/110534 (20%)]\tClassification Loss: 1.5519\r\n",
      "Train Epoch: 24 [23040/110534 (21%)]\tClassification Loss: 1.2145\r\n",
      "Train Epoch: 24 [23680/110534 (21%)]\tClassification Loss: 1.6890\r\n",
      "Train Epoch: 24 [24320/110534 (22%)]\tClassification Loss: 1.2577\r\n",
      "Train Epoch: 24 [24960/110534 (23%)]\tClassification Loss: 1.7808\r\n",
      "Train Epoch: 24 [25600/110534 (23%)]\tClassification Loss: 1.3085\r\n",
      "Train Epoch: 24 [26240/110534 (24%)]\tClassification Loss: 1.4576\r\n",
      "Train Epoch: 24 [26880/110534 (24%)]\tClassification Loss: 1.7374\r\n",
      "Train Epoch: 24 [27520/110534 (25%)]\tClassification Loss: 1.3769\r\n",
      "Train Epoch: 24 [28160/110534 (25%)]\tClassification Loss: 1.7842\r\n",
      "Train Epoch: 24 [28800/110534 (26%)]\tClassification Loss: 1.7659\r\n",
      "Train Epoch: 24 [29440/110534 (27%)]\tClassification Loss: 1.5453\r\n",
      "Train Epoch: 24 [30080/110534 (27%)]\tClassification Loss: 1.6643\r\n",
      "Train Epoch: 24 [30720/110534 (28%)]\tClassification Loss: 1.5640\r\n",
      "Train Epoch: 24 [31360/110534 (28%)]\tClassification Loss: 1.6394\r\n",
      "Train Epoch: 24 [32000/110534 (29%)]\tClassification Loss: 1.4901\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_24_500.pth.tar\r\n",
      "Train Epoch: 24 [32640/110534 (30%)]\tClassification Loss: 1.3730\r\n",
      "Train Epoch: 24 [33280/110534 (30%)]\tClassification Loss: 1.5246\r\n",
      "Train Epoch: 24 [33920/110534 (31%)]\tClassification Loss: 1.6101\r\n",
      "Train Epoch: 24 [34560/110534 (31%)]\tClassification Loss: 1.8192\r\n",
      "Train Epoch: 24 [35200/110534 (32%)]\tClassification Loss: 1.4517\r\n",
      "Train Epoch: 24 [35840/110534 (32%)]\tClassification Loss: 1.2720\r\n",
      "Train Epoch: 24 [36480/110534 (33%)]\tClassification Loss: 1.3731\r\n",
      "Train Epoch: 24 [37120/110534 (34%)]\tClassification Loss: 1.5444\r\n",
      "Train Epoch: 24 [37760/110534 (34%)]\tClassification Loss: 1.8658\r\n",
      "Train Epoch: 24 [38400/110534 (35%)]\tClassification Loss: 1.4849\r\n",
      "Train Epoch: 24 [39040/110534 (35%)]\tClassification Loss: 1.4940\r\n",
      "Train Epoch: 24 [39680/110534 (36%)]\tClassification Loss: 1.5630\r\n",
      "Train Epoch: 24 [40320/110534 (36%)]\tClassification Loss: 1.6423\r\n",
      "Train Epoch: 24 [40960/110534 (37%)]\tClassification Loss: 1.4116\r\n",
      "Train Epoch: 24 [41600/110534 (38%)]\tClassification Loss: 1.3875\r\n",
      "Train Epoch: 24 [42240/110534 (38%)]\tClassification Loss: 1.4307\r\n",
      "Train Epoch: 24 [42880/110534 (39%)]\tClassification Loss: 1.4408\r\n",
      "Train Epoch: 24 [43520/110534 (39%)]\tClassification Loss: 1.3059\r\n",
      "Train Epoch: 24 [44160/110534 (40%)]\tClassification Loss: 1.5109\r\n",
      "Train Epoch: 24 [44800/110534 (41%)]\tClassification Loss: 1.6941\r\n",
      "Train Epoch: 24 [45440/110534 (41%)]\tClassification Loss: 1.5542\r\n",
      "Train Epoch: 24 [46080/110534 (42%)]\tClassification Loss: 1.3888\r\n",
      "Train Epoch: 24 [46720/110534 (42%)]\tClassification Loss: 1.5336\r\n",
      "Train Epoch: 24 [47360/110534 (43%)]\tClassification Loss: 1.5205\r\n",
      "Train Epoch: 24 [48000/110534 (43%)]\tClassification Loss: 1.5557\r\n",
      "Train Epoch: 24 [48640/110534 (44%)]\tClassification Loss: 1.3174\r\n",
      "Train Epoch: 24 [49280/110534 (45%)]\tClassification Loss: 1.6873\r\n",
      "Train Epoch: 24 [49920/110534 (45%)]\tClassification Loss: 1.5979\r\n",
      "Train Epoch: 24 [50560/110534 (46%)]\tClassification Loss: 1.5191\r\n",
      "Train Epoch: 24 [51200/110534 (46%)]\tClassification Loss: 1.3611\r\n",
      "Train Epoch: 24 [51840/110534 (47%)]\tClassification Loss: 1.4342\r\n",
      "Train Epoch: 24 [52480/110534 (47%)]\tClassification Loss: 1.5208\r\n",
      "Train Epoch: 24 [53120/110534 (48%)]\tClassification Loss: 1.1912\r\n",
      "Train Epoch: 24 [53760/110534 (49%)]\tClassification Loss: 1.6245\r\n",
      "Train Epoch: 24 [54400/110534 (49%)]\tClassification Loss: 1.4738\r\n",
      "Train Epoch: 24 [55040/110534 (50%)]\tClassification Loss: 1.6970\r\n",
      "Train Epoch: 24 [55680/110534 (50%)]\tClassification Loss: 1.6396\r\n",
      "Train Epoch: 24 [56320/110534 (51%)]\tClassification Loss: 1.4838\r\n",
      "Train Epoch: 24 [56960/110534 (52%)]\tClassification Loss: 1.5109\r\n",
      "Train Epoch: 24 [57600/110534 (52%)]\tClassification Loss: 1.7315\r\n",
      "Train Epoch: 24 [58240/110534 (53%)]\tClassification Loss: 1.4271\r\n",
      "Train Epoch: 24 [58880/110534 (53%)]\tClassification Loss: 1.6453\r\n",
      "Train Epoch: 24 [59520/110534 (54%)]\tClassification Loss: 1.3730\r\n",
      "Train Epoch: 24 [60160/110534 (54%)]\tClassification Loss: 1.4504\r\n",
      "Train Epoch: 24 [60800/110534 (55%)]\tClassification Loss: 1.6416\r\n",
      "Train Epoch: 24 [61440/110534 (56%)]\tClassification Loss: 1.2704\r\n",
      "Train Epoch: 24 [62080/110534 (56%)]\tClassification Loss: 1.5625\r\n",
      "Train Epoch: 24 [62720/110534 (57%)]\tClassification Loss: 1.8951\r\n",
      "Train Epoch: 24 [63360/110534 (57%)]\tClassification Loss: 1.4681\r\n",
      "Train Epoch: 24 [64000/110534 (58%)]\tClassification Loss: 1.5370\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_24_1000.pth.tar\r\n",
      "Train Epoch: 24 [64640/110534 (58%)]\tClassification Loss: 1.1839\r\n",
      "Train Epoch: 24 [65280/110534 (59%)]\tClassification Loss: 1.7017\r\n",
      "Train Epoch: 24 [65920/110534 (60%)]\tClassification Loss: 1.5739\r\n",
      "Train Epoch: 24 [66560/110534 (60%)]\tClassification Loss: 1.4863\r\n",
      "Train Epoch: 24 [67200/110534 (61%)]\tClassification Loss: 1.2222\r\n",
      "Train Epoch: 24 [67840/110534 (61%)]\tClassification Loss: 1.6032\r\n",
      "Train Epoch: 24 [68480/110534 (62%)]\tClassification Loss: 1.6922\r\n",
      "Train Epoch: 24 [69120/110534 (63%)]\tClassification Loss: 1.8382\r\n",
      "Train Epoch: 24 [69760/110534 (63%)]\tClassification Loss: 1.6011\r\n",
      "Train Epoch: 24 [70400/110534 (64%)]\tClassification Loss: 1.3868\r\n",
      "Train Epoch: 24 [71040/110534 (64%)]\tClassification Loss: 1.9972\r\n",
      "Train Epoch: 24 [71680/110534 (65%)]\tClassification Loss: 1.3942\r\n",
      "Train Epoch: 24 [72320/110534 (65%)]\tClassification Loss: 1.4213\r\n",
      "Train Epoch: 24 [72960/110534 (66%)]\tClassification Loss: 1.7309\r\n",
      "Train Epoch: 24 [73600/110534 (67%)]\tClassification Loss: 1.7589\r\n",
      "Train Epoch: 24 [74240/110534 (67%)]\tClassification Loss: 1.7167\r\n",
      "Train Epoch: 24 [74880/110534 (68%)]\tClassification Loss: 1.1062\r\n",
      "Train Epoch: 24 [75520/110534 (68%)]\tClassification Loss: 1.5467\r\n",
      "Train Epoch: 24 [76160/110534 (69%)]\tClassification Loss: 1.3472\r\n",
      "Train Epoch: 24 [76800/110534 (69%)]\tClassification Loss: 1.3156\r\n",
      "Train Epoch: 24 [77440/110534 (70%)]\tClassification Loss: 1.3773\r\n",
      "Train Epoch: 24 [78080/110534 (71%)]\tClassification Loss: 1.5213\r\n",
      "Train Epoch: 24 [78720/110534 (71%)]\tClassification Loss: 1.5376\r\n",
      "Train Epoch: 24 [79360/110534 (72%)]\tClassification Loss: 1.3588\r\n",
      "Train Epoch: 24 [80000/110534 (72%)]\tClassification Loss: 1.3963\r\n",
      "Train Epoch: 24 [80640/110534 (73%)]\tClassification Loss: 1.3397\r\n",
      "Train Epoch: 24 [81280/110534 (74%)]\tClassification Loss: 1.7874\r\n",
      "Train Epoch: 24 [81920/110534 (74%)]\tClassification Loss: 1.6077\r\n",
      "Train Epoch: 24 [82560/110534 (75%)]\tClassification Loss: 1.6665\r\n",
      "Train Epoch: 24 [83200/110534 (75%)]\tClassification Loss: 1.4068\r\n",
      "Train Epoch: 24 [83840/110534 (76%)]\tClassification Loss: 1.8067\r\n",
      "Train Epoch: 24 [84480/110534 (76%)]\tClassification Loss: 1.7177\r\n",
      "Train Epoch: 24 [85120/110534 (77%)]\tClassification Loss: 1.4541\r\n",
      "Train Epoch: 24 [85760/110534 (78%)]\tClassification Loss: 1.5763\r\n",
      "Train Epoch: 24 [86400/110534 (78%)]\tClassification Loss: 1.6942\r\n",
      "Train Epoch: 24 [87040/110534 (79%)]\tClassification Loss: 1.3867\r\n",
      "Train Epoch: 24 [87680/110534 (79%)]\tClassification Loss: 1.4873\r\n",
      "Train Epoch: 24 [88320/110534 (80%)]\tClassification Loss: 1.6120\r\n",
      "Train Epoch: 24 [88960/110534 (80%)]\tClassification Loss: 1.7929\r\n",
      "Train Epoch: 24 [89600/110534 (81%)]\tClassification Loss: 1.9794\r\n",
      "Train Epoch: 24 [90240/110534 (82%)]\tClassification Loss: 1.7686\r\n",
      "Train Epoch: 24 [90880/110534 (82%)]\tClassification Loss: 1.5962\r\n",
      "Train Epoch: 24 [91520/110534 (83%)]\tClassification Loss: 1.2631\r\n",
      "Train Epoch: 24 [92160/110534 (83%)]\tClassification Loss: 1.3925\r\n",
      "Train Epoch: 24 [92800/110534 (84%)]\tClassification Loss: 1.4238\r\n",
      "Train Epoch: 24 [93440/110534 (85%)]\tClassification Loss: 1.7221\r\n",
      "Train Epoch: 24 [94080/110534 (85%)]\tClassification Loss: 1.4346\r\n",
      "Train Epoch: 24 [94720/110534 (86%)]\tClassification Loss: 1.2341\r\n",
      "Train Epoch: 24 [95360/110534 (86%)]\tClassification Loss: 1.4731\r\n",
      "Train Epoch: 24 [96000/110534 (87%)]\tClassification Loss: 1.6205\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_24_1500.pth.tar\r\n",
      "Train Epoch: 24 [96640/110534 (87%)]\tClassification Loss: 1.4139\r\n",
      "Train Epoch: 24 [97280/110534 (88%)]\tClassification Loss: 1.2325\r\n",
      "Train Epoch: 24 [97920/110534 (89%)]\tClassification Loss: 1.2240\r\n",
      "Train Epoch: 24 [98560/110534 (89%)]\tClassification Loss: 1.4629\r\n",
      "Train Epoch: 24 [99200/110534 (90%)]\tClassification Loss: 1.6365\r\n",
      "Train Epoch: 24 [99840/110534 (90%)]\tClassification Loss: 1.4523\r\n",
      "Train Epoch: 24 [100480/110534 (91%)]\tClassification Loss: 1.6659\r\n",
      "Train Epoch: 24 [101120/110534 (91%)]\tClassification Loss: 1.5979\r\n",
      "Train Epoch: 24 [101760/110534 (92%)]\tClassification Loss: 1.6722\r\n",
      "Train Epoch: 24 [102400/110534 (93%)]\tClassification Loss: 1.4941\r\n",
      "Train Epoch: 24 [103040/110534 (93%)]\tClassification Loss: 1.4966\r\n",
      "Train Epoch: 24 [103680/110534 (94%)]\tClassification Loss: 1.6231\r\n",
      "Train Epoch: 24 [104320/110534 (94%)]\tClassification Loss: 1.3692\r\n",
      "Train Epoch: 24 [104960/110534 (95%)]\tClassification Loss: 1.6977\r\n",
      "Train Epoch: 24 [105600/110534 (96%)]\tClassification Loss: 1.4316\r\n",
      "Train Epoch: 24 [106240/110534 (96%)]\tClassification Loss: 1.2593\r\n",
      "Train Epoch: 24 [106880/110534 (97%)]\tClassification Loss: 1.5854\r\n",
      "Train Epoch: 24 [107520/110534 (97%)]\tClassification Loss: 1.7734\r\n",
      "Train Epoch: 24 [108160/110534 (98%)]\tClassification Loss: 1.5651\r\n",
      "Train Epoch: 24 [108800/110534 (98%)]\tClassification Loss: 1.8019\r\n",
      "Train Epoch: 24 [109440/110534 (99%)]\tClassification Loss: 1.4411\r\n",
      "Train Epoch: 24 [110080/110534 (100%)]\tClassification Loss: 1.4053\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_24_final.pth.tar\r\n",
      "Train Epoch: 25 [0/110534 (0%)]\tClassification Loss: 1.6131\r\n",
      "\r\n",
      "Test set: Average loss: 1.4412, Accuracy: 22765/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 25 [640/110534 (1%)]\tClassification Loss: 1.3124\r\n",
      "Train Epoch: 25 [1280/110534 (1%)]\tClassification Loss: 1.9708\r\n",
      "Train Epoch: 25 [1920/110534 (2%)]\tClassification Loss: 1.5589\r\n",
      "Train Epoch: 25 [2560/110534 (2%)]\tClassification Loss: 1.7617\r\n",
      "Train Epoch: 25 [3200/110534 (3%)]\tClassification Loss: 1.5430\r\n",
      "Train Epoch: 25 [3840/110534 (3%)]\tClassification Loss: 1.4332\r\n",
      "Train Epoch: 25 [4480/110534 (4%)]\tClassification Loss: 1.4184\r\n",
      "Train Epoch: 25 [5120/110534 (5%)]\tClassification Loss: 1.7527\r\n",
      "Train Epoch: 25 [5760/110534 (5%)]\tClassification Loss: 1.5366\r\n",
      "Train Epoch: 25 [6400/110534 (6%)]\tClassification Loss: 1.4244\r\n",
      "Train Epoch: 25 [7040/110534 (6%)]\tClassification Loss: 1.4007\r\n",
      "Train Epoch: 25 [7680/110534 (7%)]\tClassification Loss: 1.4465\r\n",
      "Train Epoch: 25 [8320/110534 (8%)]\tClassification Loss: 1.7476\r\n",
      "Train Epoch: 25 [8960/110534 (8%)]\tClassification Loss: 1.5736\r\n",
      "Train Epoch: 25 [9600/110534 (9%)]\tClassification Loss: 1.4384\r\n",
      "Train Epoch: 25 [10240/110534 (9%)]\tClassification Loss: 1.4713\r\n",
      "Train Epoch: 25 [10880/110534 (10%)]\tClassification Loss: 1.4088\r\n",
      "Train Epoch: 25 [11520/110534 (10%)]\tClassification Loss: 1.5829\r\n",
      "Train Epoch: 25 [12160/110534 (11%)]\tClassification Loss: 1.4732\r\n",
      "Train Epoch: 25 [12800/110534 (12%)]\tClassification Loss: 1.6246\r\n",
      "Train Epoch: 25 [13440/110534 (12%)]\tClassification Loss: 1.4882\r\n",
      "Train Epoch: 25 [14080/110534 (13%)]\tClassification Loss: 1.4614\r\n",
      "Train Epoch: 25 [14720/110534 (13%)]\tClassification Loss: 1.8486\r\n",
      "Train Epoch: 25 [15360/110534 (14%)]\tClassification Loss: 1.4715\r\n",
      "Train Epoch: 25 [16000/110534 (14%)]\tClassification Loss: 1.6717\r\n",
      "Train Epoch: 25 [16640/110534 (15%)]\tClassification Loss: 1.5870\r\n",
      "Train Epoch: 25 [17280/110534 (16%)]\tClassification Loss: 1.6040\r\n",
      "Train Epoch: 25 [17920/110534 (16%)]\tClassification Loss: 1.5047\r\n",
      "Train Epoch: 25 [18560/110534 (17%)]\tClassification Loss: 1.7550\r\n",
      "Train Epoch: 25 [19200/110534 (17%)]\tClassification Loss: 1.5455\r\n",
      "Train Epoch: 25 [19840/110534 (18%)]\tClassification Loss: 1.5016\r\n",
      "Train Epoch: 25 [20480/110534 (19%)]\tClassification Loss: 1.7187\r\n",
      "Train Epoch: 25 [21120/110534 (19%)]\tClassification Loss: 1.6594\r\n",
      "Train Epoch: 25 [21760/110534 (20%)]\tClassification Loss: 1.4623\r\n",
      "Train Epoch: 25 [22400/110534 (20%)]\tClassification Loss: 1.7145\r\n",
      "Train Epoch: 25 [23040/110534 (21%)]\tClassification Loss: 1.1960\r\n",
      "Train Epoch: 25 [23680/110534 (21%)]\tClassification Loss: 1.5877\r\n",
      "Train Epoch: 25 [24320/110534 (22%)]\tClassification Loss: 1.3095\r\n",
      "Train Epoch: 25 [24960/110534 (23%)]\tClassification Loss: 1.6640\r\n",
      "Train Epoch: 25 [25600/110534 (23%)]\tClassification Loss: 1.3912\r\n",
      "Train Epoch: 25 [26240/110534 (24%)]\tClassification Loss: 1.4224\r\n",
      "Train Epoch: 25 [26880/110534 (24%)]\tClassification Loss: 1.7120\r\n",
      "Train Epoch: 25 [27520/110534 (25%)]\tClassification Loss: 1.2410\r\n",
      "Train Epoch: 25 [28160/110534 (25%)]\tClassification Loss: 1.6331\r\n",
      "Train Epoch: 25 [28800/110534 (26%)]\tClassification Loss: 1.8027\r\n",
      "Train Epoch: 25 [29440/110534 (27%)]\tClassification Loss: 1.4850\r\n",
      "Train Epoch: 25 [30080/110534 (27%)]\tClassification Loss: 1.7668\r\n",
      "Train Epoch: 25 [30720/110534 (28%)]\tClassification Loss: 1.5798\r\n",
      "Train Epoch: 25 [31360/110534 (28%)]\tClassification Loss: 1.7379\r\n",
      "Train Epoch: 25 [32000/110534 (29%)]\tClassification Loss: 1.3625\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_25_500.pth.tar\r\n",
      "Train Epoch: 25 [32640/110534 (30%)]\tClassification Loss: 1.4407\r\n",
      "Train Epoch: 25 [33280/110534 (30%)]\tClassification Loss: 1.4704\r\n",
      "Train Epoch: 25 [33920/110534 (31%)]\tClassification Loss: 1.6889\r\n",
      "Train Epoch: 25 [34560/110534 (31%)]\tClassification Loss: 1.7385\r\n",
      "Train Epoch: 25 [35200/110534 (32%)]\tClassification Loss: 1.5853\r\n",
      "Train Epoch: 25 [35840/110534 (32%)]\tClassification Loss: 1.2086\r\n",
      "Train Epoch: 25 [36480/110534 (33%)]\tClassification Loss: 1.3965\r\n",
      "Train Epoch: 25 [37120/110534 (34%)]\tClassification Loss: 1.6377\r\n",
      "Train Epoch: 25 [37760/110534 (34%)]\tClassification Loss: 1.8633\r\n",
      "Train Epoch: 25 [38400/110534 (35%)]\tClassification Loss: 1.4680\r\n",
      "Train Epoch: 25 [39040/110534 (35%)]\tClassification Loss: 1.5621\r\n",
      "Train Epoch: 25 [39680/110534 (36%)]\tClassification Loss: 1.7199\r\n",
      "Train Epoch: 25 [40320/110534 (36%)]\tClassification Loss: 1.6035\r\n",
      "Train Epoch: 25 [40960/110534 (37%)]\tClassification Loss: 1.3154\r\n",
      "Train Epoch: 25 [41600/110534 (38%)]\tClassification Loss: 1.4165\r\n",
      "Train Epoch: 25 [42240/110534 (38%)]\tClassification Loss: 1.3425\r\n",
      "Train Epoch: 25 [42880/110534 (39%)]\tClassification Loss: 1.4506\r\n",
      "Train Epoch: 25 [43520/110534 (39%)]\tClassification Loss: 1.2621\r\n",
      "Train Epoch: 25 [44160/110534 (40%)]\tClassification Loss: 1.6185\r\n",
      "Train Epoch: 25 [44800/110534 (41%)]\tClassification Loss: 1.8407\r\n",
      "Train Epoch: 25 [45440/110534 (41%)]\tClassification Loss: 1.5785\r\n",
      "Train Epoch: 25 [46080/110534 (42%)]\tClassification Loss: 1.4455\r\n",
      "Train Epoch: 25 [46720/110534 (42%)]\tClassification Loss: 1.5839\r\n",
      "Train Epoch: 25 [47360/110534 (43%)]\tClassification Loss: 1.3810\r\n",
      "Train Epoch: 25 [48000/110534 (43%)]\tClassification Loss: 1.6122\r\n",
      "Train Epoch: 25 [48640/110534 (44%)]\tClassification Loss: 1.3314\r\n",
      "Train Epoch: 25 [49280/110534 (45%)]\tClassification Loss: 1.5855\r\n",
      "Train Epoch: 25 [49920/110534 (45%)]\tClassification Loss: 1.6381\r\n",
      "Train Epoch: 25 [50560/110534 (46%)]\tClassification Loss: 1.5949\r\n",
      "Train Epoch: 25 [51200/110534 (46%)]\tClassification Loss: 1.2124\r\n",
      "Train Epoch: 25 [51840/110534 (47%)]\tClassification Loss: 1.6188\r\n",
      "Train Epoch: 25 [52480/110534 (47%)]\tClassification Loss: 1.5110\r\n",
      "Train Epoch: 25 [53120/110534 (48%)]\tClassification Loss: 1.2692\r\n",
      "Train Epoch: 25 [53760/110534 (49%)]\tClassification Loss: 1.4236\r\n",
      "Train Epoch: 25 [54400/110534 (49%)]\tClassification Loss: 1.4057\r\n",
      "Train Epoch: 25 [55040/110534 (50%)]\tClassification Loss: 1.5980\r\n",
      "Train Epoch: 25 [55680/110534 (50%)]\tClassification Loss: 1.7226\r\n",
      "Train Epoch: 25 [56320/110534 (51%)]\tClassification Loss: 1.5380\r\n",
      "Train Epoch: 25 [56960/110534 (52%)]\tClassification Loss: 1.3928\r\n",
      "Train Epoch: 25 [57600/110534 (52%)]\tClassification Loss: 1.6163\r\n",
      "Train Epoch: 25 [58240/110534 (53%)]\tClassification Loss: 1.5365\r\n",
      "Train Epoch: 25 [58880/110534 (53%)]\tClassification Loss: 1.8698\r\n",
      "Train Epoch: 25 [59520/110534 (54%)]\tClassification Loss: 1.4419\r\n",
      "Train Epoch: 25 [60160/110534 (54%)]\tClassification Loss: 1.3742\r\n",
      "Train Epoch: 25 [60800/110534 (55%)]\tClassification Loss: 1.5066\r\n",
      "Train Epoch: 25 [61440/110534 (56%)]\tClassification Loss: 1.5626\r\n",
      "Train Epoch: 25 [62080/110534 (56%)]\tClassification Loss: 1.3715\r\n",
      "Train Epoch: 25 [62720/110534 (57%)]\tClassification Loss: 1.7144\r\n",
      "Train Epoch: 25 [63360/110534 (57%)]\tClassification Loss: 1.2733\r\n",
      "Train Epoch: 25 [64000/110534 (58%)]\tClassification Loss: 1.6432\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_25_1000.pth.tar\r\n",
      "Train Epoch: 25 [64640/110534 (58%)]\tClassification Loss: 1.2555\r\n",
      "Train Epoch: 25 [65280/110534 (59%)]\tClassification Loss: 1.5700\r\n",
      "Train Epoch: 25 [65920/110534 (60%)]\tClassification Loss: 1.7205\r\n",
      "Train Epoch: 25 [66560/110534 (60%)]\tClassification Loss: 1.2334\r\n",
      "Train Epoch: 25 [67200/110534 (61%)]\tClassification Loss: 1.2924\r\n",
      "Train Epoch: 25 [67840/110534 (61%)]\tClassification Loss: 1.8891\r\n",
      "Train Epoch: 25 [68480/110534 (62%)]\tClassification Loss: 1.6682\r\n",
      "Train Epoch: 25 [69120/110534 (63%)]\tClassification Loss: 1.6761\r\n",
      "Train Epoch: 25 [69760/110534 (63%)]\tClassification Loss: 1.6407\r\n",
      "Train Epoch: 25 [70400/110534 (64%)]\tClassification Loss: 1.2124\r\n",
      "Train Epoch: 25 [71040/110534 (64%)]\tClassification Loss: 1.9947\r\n",
      "Train Epoch: 25 [71680/110534 (65%)]\tClassification Loss: 1.5561\r\n",
      "Train Epoch: 25 [72320/110534 (65%)]\tClassification Loss: 1.7450\r\n",
      "Train Epoch: 25 [72960/110534 (66%)]\tClassification Loss: 1.8870\r\n",
      "Train Epoch: 25 [73600/110534 (67%)]\tClassification Loss: 1.8750\r\n",
      "Train Epoch: 25 [74240/110534 (67%)]\tClassification Loss: 1.7719\r\n",
      "Train Epoch: 25 [74880/110534 (68%)]\tClassification Loss: 1.1661\r\n",
      "Train Epoch: 25 [75520/110534 (68%)]\tClassification Loss: 1.5016\r\n",
      "Train Epoch: 25 [76160/110534 (69%)]\tClassification Loss: 1.4123\r\n",
      "Train Epoch: 25 [76800/110534 (69%)]\tClassification Loss: 1.5016\r\n",
      "Train Epoch: 25 [77440/110534 (70%)]\tClassification Loss: 1.3318\r\n",
      "Train Epoch: 25 [78080/110534 (71%)]\tClassification Loss: 1.5464\r\n",
      "Train Epoch: 25 [78720/110534 (71%)]\tClassification Loss: 1.4412\r\n",
      "Train Epoch: 25 [79360/110534 (72%)]\tClassification Loss: 1.4120\r\n",
      "Train Epoch: 25 [80000/110534 (72%)]\tClassification Loss: 1.4591\r\n",
      "Train Epoch: 25 [80640/110534 (73%)]\tClassification Loss: 1.4386\r\n",
      "Train Epoch: 25 [81280/110534 (74%)]\tClassification Loss: 1.6485\r\n",
      "Train Epoch: 25 [81920/110534 (74%)]\tClassification Loss: 1.6284\r\n",
      "Train Epoch: 25 [82560/110534 (75%)]\tClassification Loss: 1.6017\r\n",
      "Train Epoch: 25 [83200/110534 (75%)]\tClassification Loss: 1.4347\r\n",
      "Train Epoch: 25 [83840/110534 (76%)]\tClassification Loss: 1.8161\r\n",
      "Train Epoch: 25 [84480/110534 (76%)]\tClassification Loss: 1.7271\r\n",
      "Train Epoch: 25 [85120/110534 (77%)]\tClassification Loss: 1.5838\r\n",
      "Train Epoch: 25 [85760/110534 (78%)]\tClassification Loss: 1.5297\r\n",
      "Train Epoch: 25 [86400/110534 (78%)]\tClassification Loss: 1.6366\r\n",
      "Train Epoch: 25 [87040/110534 (79%)]\tClassification Loss: 1.5181\r\n",
      "Train Epoch: 25 [87680/110534 (79%)]\tClassification Loss: 1.4754\r\n",
      "Train Epoch: 25 [88320/110534 (80%)]\tClassification Loss: 1.5144\r\n",
      "Train Epoch: 25 [88960/110534 (80%)]\tClassification Loss: 1.6465\r\n",
      "Train Epoch: 25 [89600/110534 (81%)]\tClassification Loss: 1.7317\r\n",
      "Train Epoch: 25 [90240/110534 (82%)]\tClassification Loss: 1.7016\r\n",
      "Train Epoch: 25 [90880/110534 (82%)]\tClassification Loss: 1.6443\r\n",
      "Train Epoch: 25 [91520/110534 (83%)]\tClassification Loss: 1.2443\r\n",
      "Train Epoch: 25 [92160/110534 (83%)]\tClassification Loss: 1.3688\r\n",
      "Train Epoch: 25 [92800/110534 (84%)]\tClassification Loss: 1.3762\r\n",
      "Train Epoch: 25 [93440/110534 (85%)]\tClassification Loss: 1.7463\r\n",
      "Train Epoch: 25 [94080/110534 (85%)]\tClassification Loss: 1.7482\r\n",
      "Train Epoch: 25 [94720/110534 (86%)]\tClassification Loss: 1.2830\r\n",
      "Train Epoch: 25 [95360/110534 (86%)]\tClassification Loss: 1.3057\r\n",
      "Train Epoch: 25 [96000/110534 (87%)]\tClassification Loss: 1.4383\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_25_1500.pth.tar\r\n",
      "Train Epoch: 25 [96640/110534 (87%)]\tClassification Loss: 1.4496\r\n",
      "Train Epoch: 25 [97280/110534 (88%)]\tClassification Loss: 1.2327\r\n",
      "Train Epoch: 25 [97920/110534 (89%)]\tClassification Loss: 1.1565\r\n",
      "Train Epoch: 25 [98560/110534 (89%)]\tClassification Loss: 1.2990\r\n",
      "Train Epoch: 25 [99200/110534 (90%)]\tClassification Loss: 1.5434\r\n",
      "Train Epoch: 25 [99840/110534 (90%)]\tClassification Loss: 1.3845\r\n",
      "Train Epoch: 25 [100480/110534 (91%)]\tClassification Loss: 1.6208\r\n",
      "Train Epoch: 25 [101120/110534 (91%)]\tClassification Loss: 1.3708\r\n",
      "Train Epoch: 25 [101760/110534 (92%)]\tClassification Loss: 1.7128\r\n",
      "Train Epoch: 25 [102400/110534 (93%)]\tClassification Loss: 1.4581\r\n",
      "Train Epoch: 25 [103040/110534 (93%)]\tClassification Loss: 1.5401\r\n",
      "Train Epoch: 25 [103680/110534 (94%)]\tClassification Loss: 1.7803\r\n",
      "Train Epoch: 25 [104320/110534 (94%)]\tClassification Loss: 1.3228\r\n",
      "Train Epoch: 25 [104960/110534 (95%)]\tClassification Loss: 1.7052\r\n",
      "Train Epoch: 25 [105600/110534 (96%)]\tClassification Loss: 1.5112\r\n",
      "Train Epoch: 25 [106240/110534 (96%)]\tClassification Loss: 1.4767\r\n",
      "Train Epoch: 25 [106880/110534 (97%)]\tClassification Loss: 1.5571\r\n",
      "Train Epoch: 25 [107520/110534 (97%)]\tClassification Loss: 1.6817\r\n",
      "Train Epoch: 25 [108160/110534 (98%)]\tClassification Loss: 1.6517\r\n",
      "Train Epoch: 25 [108800/110534 (98%)]\tClassification Loss: 1.7185\r\n",
      "Train Epoch: 25 [109440/110534 (99%)]\tClassification Loss: 1.4014\r\n",
      "Train Epoch: 25 [110080/110534 (100%)]\tClassification Loss: 1.3832\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_25_final.pth.tar\r\n",
      "Train Epoch: 26 [0/110534 (0%)]\tClassification Loss: 1.5678\r\n",
      "\r\n",
      "Test set: Average loss: 1.4226, Accuracy: 23006/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 26 [640/110534 (1%)]\tClassification Loss: 1.2849\r\n",
      "Train Epoch: 26 [1280/110534 (1%)]\tClassification Loss: 1.8836\r\n",
      "Train Epoch: 26 [1920/110534 (2%)]\tClassification Loss: 1.7599\r\n",
      "Train Epoch: 26 [2560/110534 (2%)]\tClassification Loss: 1.7628\r\n",
      "Train Epoch: 26 [3200/110534 (3%)]\tClassification Loss: 1.3173\r\n",
      "Train Epoch: 26 [3840/110534 (3%)]\tClassification Loss: 1.6070\r\n",
      "Train Epoch: 26 [4480/110534 (4%)]\tClassification Loss: 1.5658\r\n",
      "Train Epoch: 26 [5120/110534 (5%)]\tClassification Loss: 1.5608\r\n",
      "Train Epoch: 26 [5760/110534 (5%)]\tClassification Loss: 1.5102\r\n",
      "Train Epoch: 26 [6400/110534 (6%)]\tClassification Loss: 1.2830\r\n",
      "Train Epoch: 26 [7040/110534 (6%)]\tClassification Loss: 1.6029\r\n",
      "Train Epoch: 26 [7680/110534 (7%)]\tClassification Loss: 1.5569\r\n",
      "Train Epoch: 26 [8320/110534 (8%)]\tClassification Loss: 1.6645\r\n",
      "Train Epoch: 26 [8960/110534 (8%)]\tClassification Loss: 1.6135\r\n",
      "Train Epoch: 26 [9600/110534 (9%)]\tClassification Loss: 1.3654\r\n",
      "Train Epoch: 26 [10240/110534 (9%)]\tClassification Loss: 1.4680\r\n",
      "Train Epoch: 26 [10880/110534 (10%)]\tClassification Loss: 1.5651\r\n",
      "Train Epoch: 26 [11520/110534 (10%)]\tClassification Loss: 1.6891\r\n",
      "Train Epoch: 26 [12160/110534 (11%)]\tClassification Loss: 1.2874\r\n",
      "Train Epoch: 26 [12800/110534 (12%)]\tClassification Loss: 1.6894\r\n",
      "Train Epoch: 26 [13440/110534 (12%)]\tClassification Loss: 1.4082\r\n",
      "Train Epoch: 26 [14080/110534 (13%)]\tClassification Loss: 1.6126\r\n",
      "Train Epoch: 26 [14720/110534 (13%)]\tClassification Loss: 1.7457\r\n",
      "Train Epoch: 26 [15360/110534 (14%)]\tClassification Loss: 1.4880\r\n",
      "Train Epoch: 26 [16000/110534 (14%)]\tClassification Loss: 1.7497\r\n",
      "Train Epoch: 26 [16640/110534 (15%)]\tClassification Loss: 1.4341\r\n",
      "Train Epoch: 26 [17280/110534 (16%)]\tClassification Loss: 1.5859\r\n",
      "Train Epoch: 26 [17920/110534 (16%)]\tClassification Loss: 1.4799\r\n",
      "Train Epoch: 26 [18560/110534 (17%)]\tClassification Loss: 1.6534\r\n",
      "Train Epoch: 26 [19200/110534 (17%)]\tClassification Loss: 1.6318\r\n",
      "Train Epoch: 26 [19840/110534 (18%)]\tClassification Loss: 1.4914\r\n",
      "Train Epoch: 26 [20480/110534 (19%)]\tClassification Loss: 1.7347\r\n",
      "Train Epoch: 26 [21120/110534 (19%)]\tClassification Loss: 1.6447\r\n",
      "Train Epoch: 26 [21760/110534 (20%)]\tClassification Loss: 1.4233\r\n",
      "Train Epoch: 26 [22400/110534 (20%)]\tClassification Loss: 1.5909\r\n",
      "Train Epoch: 26 [23040/110534 (21%)]\tClassification Loss: 1.0838\r\n",
      "Train Epoch: 26 [23680/110534 (21%)]\tClassification Loss: 1.5639\r\n",
      "Train Epoch: 26 [24320/110534 (22%)]\tClassification Loss: 1.4375\r\n",
      "Train Epoch: 26 [24960/110534 (23%)]\tClassification Loss: 1.5787\r\n",
      "Train Epoch: 26 [25600/110534 (23%)]\tClassification Loss: 1.4238\r\n",
      "Train Epoch: 26 [26240/110534 (24%)]\tClassification Loss: 1.4460\r\n",
      "Train Epoch: 26 [26880/110534 (24%)]\tClassification Loss: 1.7312\r\n",
      "Train Epoch: 26 [27520/110534 (25%)]\tClassification Loss: 1.4474\r\n",
      "Train Epoch: 26 [28160/110534 (25%)]\tClassification Loss: 1.8129\r\n",
      "Train Epoch: 26 [28800/110534 (26%)]\tClassification Loss: 1.7293\r\n",
      "Train Epoch: 26 [29440/110534 (27%)]\tClassification Loss: 1.4575\r\n",
      "Train Epoch: 26 [30080/110534 (27%)]\tClassification Loss: 1.9994\r\n",
      "Train Epoch: 26 [30720/110534 (28%)]\tClassification Loss: 1.3873\r\n",
      "Train Epoch: 26 [31360/110534 (28%)]\tClassification Loss: 1.5268\r\n",
      "Train Epoch: 26 [32000/110534 (29%)]\tClassification Loss: 1.4313\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_26_500.pth.tar\r\n",
      "Train Epoch: 26 [32640/110534 (30%)]\tClassification Loss: 1.3703\r\n",
      "Train Epoch: 26 [33280/110534 (30%)]\tClassification Loss: 1.4020\r\n",
      "Train Epoch: 26 [33920/110534 (31%)]\tClassification Loss: 1.5616\r\n",
      "Train Epoch: 26 [34560/110534 (31%)]\tClassification Loss: 1.7833\r\n",
      "Train Epoch: 26 [35200/110534 (32%)]\tClassification Loss: 1.5286\r\n",
      "Train Epoch: 26 [35840/110534 (32%)]\tClassification Loss: 1.1888\r\n",
      "Train Epoch: 26 [36480/110534 (33%)]\tClassification Loss: 1.4206\r\n",
      "Train Epoch: 26 [37120/110534 (34%)]\tClassification Loss: 1.5567\r\n",
      "Train Epoch: 26 [37760/110534 (34%)]\tClassification Loss: 1.9665\r\n",
      "Train Epoch: 26 [38400/110534 (35%)]\tClassification Loss: 1.4671\r\n",
      "Train Epoch: 26 [39040/110534 (35%)]\tClassification Loss: 1.6109\r\n",
      "Train Epoch: 26 [39680/110534 (36%)]\tClassification Loss: 1.5647\r\n",
      "Train Epoch: 26 [40320/110534 (36%)]\tClassification Loss: 1.5313\r\n",
      "Train Epoch: 26 [40960/110534 (37%)]\tClassification Loss: 1.3660\r\n",
      "Train Epoch: 26 [41600/110534 (38%)]\tClassification Loss: 1.4800\r\n",
      "Train Epoch: 26 [42240/110534 (38%)]\tClassification Loss: 1.5835\r\n",
      "Train Epoch: 26 [42880/110534 (39%)]\tClassification Loss: 1.3474\r\n",
      "Train Epoch: 26 [43520/110534 (39%)]\tClassification Loss: 1.2980\r\n",
      "Train Epoch: 26 [44160/110534 (40%)]\tClassification Loss: 1.6351\r\n",
      "Train Epoch: 26 [44800/110534 (41%)]\tClassification Loss: 1.6320\r\n",
      "Train Epoch: 26 [45440/110534 (41%)]\tClassification Loss: 1.4733\r\n",
      "Train Epoch: 26 [46080/110534 (42%)]\tClassification Loss: 1.4812\r\n",
      "Train Epoch: 26 [46720/110534 (42%)]\tClassification Loss: 1.4664\r\n",
      "Train Epoch: 26 [47360/110534 (43%)]\tClassification Loss: 1.4510\r\n",
      "Train Epoch: 26 [48000/110534 (43%)]\tClassification Loss: 1.6576\r\n",
      "Train Epoch: 26 [48640/110534 (44%)]\tClassification Loss: 1.5419\r\n",
      "Train Epoch: 26 [49280/110534 (45%)]\tClassification Loss: 1.5299\r\n",
      "Train Epoch: 26 [49920/110534 (45%)]\tClassification Loss: 1.6925\r\n",
      "Train Epoch: 26 [50560/110534 (46%)]\tClassification Loss: 1.5806\r\n",
      "Train Epoch: 26 [51200/110534 (46%)]\tClassification Loss: 1.3668\r\n",
      "Train Epoch: 26 [51840/110534 (47%)]\tClassification Loss: 1.5747\r\n",
      "Train Epoch: 26 [52480/110534 (47%)]\tClassification Loss: 1.4395\r\n",
      "Train Epoch: 26 [53120/110534 (48%)]\tClassification Loss: 1.1456\r\n",
      "Train Epoch: 26 [53760/110534 (49%)]\tClassification Loss: 1.6948\r\n",
      "Train Epoch: 26 [54400/110534 (49%)]\tClassification Loss: 1.4941\r\n",
      "Train Epoch: 26 [55040/110534 (50%)]\tClassification Loss: 1.6979\r\n",
      "Train Epoch: 26 [55680/110534 (50%)]\tClassification Loss: 1.6218\r\n",
      "Train Epoch: 26 [56320/110534 (51%)]\tClassification Loss: 1.5762\r\n",
      "Train Epoch: 26 [56960/110534 (52%)]\tClassification Loss: 1.5364\r\n",
      "Train Epoch: 26 [57600/110534 (52%)]\tClassification Loss: 1.6014\r\n",
      "Train Epoch: 26 [58240/110534 (53%)]\tClassification Loss: 1.6877\r\n",
      "Train Epoch: 26 [58880/110534 (53%)]\tClassification Loss: 1.6792\r\n",
      "Train Epoch: 26 [59520/110534 (54%)]\tClassification Loss: 1.3026\r\n",
      "Train Epoch: 26 [60160/110534 (54%)]\tClassification Loss: 1.4556\r\n",
      "Train Epoch: 26 [60800/110534 (55%)]\tClassification Loss: 1.5705\r\n",
      "Train Epoch: 26 [61440/110534 (56%)]\tClassification Loss: 1.4612\r\n",
      "Train Epoch: 26 [62080/110534 (56%)]\tClassification Loss: 1.4003\r\n",
      "Train Epoch: 26 [62720/110534 (57%)]\tClassification Loss: 1.4682\r\n",
      "Train Epoch: 26 [63360/110534 (57%)]\tClassification Loss: 1.2732\r\n",
      "Train Epoch: 26 [64000/110534 (58%)]\tClassification Loss: 1.6756\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_26_1000.pth.tar\r\n",
      "Train Epoch: 26 [64640/110534 (58%)]\tClassification Loss: 1.2511\r\n",
      "Train Epoch: 26 [65280/110534 (59%)]\tClassification Loss: 1.6901\r\n",
      "Train Epoch: 26 [65920/110534 (60%)]\tClassification Loss: 1.3043\r\n",
      "Train Epoch: 26 [66560/110534 (60%)]\tClassification Loss: 1.3178\r\n",
      "Train Epoch: 26 [67200/110534 (61%)]\tClassification Loss: 1.3190\r\n",
      "Train Epoch: 26 [67840/110534 (61%)]\tClassification Loss: 1.8477\r\n",
      "Train Epoch: 26 [68480/110534 (62%)]\tClassification Loss: 1.5248\r\n",
      "Train Epoch: 26 [69120/110534 (63%)]\tClassification Loss: 1.8471\r\n",
      "Train Epoch: 26 [69760/110534 (63%)]\tClassification Loss: 1.4388\r\n",
      "Train Epoch: 26 [70400/110534 (64%)]\tClassification Loss: 1.2088\r\n",
      "Train Epoch: 26 [71040/110534 (64%)]\tClassification Loss: 1.6661\r\n",
      "Train Epoch: 26 [71680/110534 (65%)]\tClassification Loss: 1.4887\r\n",
      "Train Epoch: 26 [72320/110534 (65%)]\tClassification Loss: 1.5664\r\n",
      "Train Epoch: 26 [72960/110534 (66%)]\tClassification Loss: 1.8365\r\n",
      "Train Epoch: 26 [73600/110534 (67%)]\tClassification Loss: 1.6321\r\n",
      "Train Epoch: 26 [74240/110534 (67%)]\tClassification Loss: 1.6738\r\n",
      "Train Epoch: 26 [74880/110534 (68%)]\tClassification Loss: 1.1207\r\n",
      "Train Epoch: 26 [75520/110534 (68%)]\tClassification Loss: 1.3355\r\n",
      "Train Epoch: 26 [76160/110534 (69%)]\tClassification Loss: 1.3458\r\n",
      "Train Epoch: 26 [76800/110534 (69%)]\tClassification Loss: 1.5490\r\n",
      "Train Epoch: 26 [77440/110534 (70%)]\tClassification Loss: 1.4183\r\n",
      "Train Epoch: 26 [78080/110534 (71%)]\tClassification Loss: 1.5615\r\n",
      "Train Epoch: 26 [78720/110534 (71%)]\tClassification Loss: 1.4163\r\n",
      "Train Epoch: 26 [79360/110534 (72%)]\tClassification Loss: 1.4756\r\n",
      "Train Epoch: 26 [80000/110534 (72%)]\tClassification Loss: 1.3908\r\n",
      "Train Epoch: 26 [80640/110534 (73%)]\tClassification Loss: 1.4188\r\n",
      "Train Epoch: 26 [81280/110534 (74%)]\tClassification Loss: 1.9344\r\n",
      "Train Epoch: 26 [81920/110534 (74%)]\tClassification Loss: 1.5381\r\n",
      "Train Epoch: 26 [82560/110534 (75%)]\tClassification Loss: 1.5993\r\n",
      "Train Epoch: 26 [83200/110534 (75%)]\tClassification Loss: 1.4059\r\n",
      "Train Epoch: 26 [83840/110534 (76%)]\tClassification Loss: 1.6780\r\n",
      "Train Epoch: 26 [84480/110534 (76%)]\tClassification Loss: 1.5757\r\n",
      "Train Epoch: 26 [85120/110534 (77%)]\tClassification Loss: 1.5025\r\n",
      "Train Epoch: 26 [85760/110534 (78%)]\tClassification Loss: 1.4504\r\n",
      "Train Epoch: 26 [86400/110534 (78%)]\tClassification Loss: 1.5686\r\n",
      "Train Epoch: 26 [87040/110534 (79%)]\tClassification Loss: 1.5922\r\n",
      "Train Epoch: 26 [87680/110534 (79%)]\tClassification Loss: 1.3934\r\n",
      "Train Epoch: 26 [88320/110534 (80%)]\tClassification Loss: 1.4799\r\n",
      "Train Epoch: 26 [88960/110534 (80%)]\tClassification Loss: 1.4541\r\n",
      "Train Epoch: 26 [89600/110534 (81%)]\tClassification Loss: 1.7195\r\n",
      "Train Epoch: 26 [90240/110534 (82%)]\tClassification Loss: 1.6767\r\n",
      "Train Epoch: 26 [90880/110534 (82%)]\tClassification Loss: 1.5363\r\n",
      "Train Epoch: 26 [91520/110534 (83%)]\tClassification Loss: 1.2553\r\n",
      "Train Epoch: 26 [92160/110534 (83%)]\tClassification Loss: 1.3206\r\n",
      "Train Epoch: 26 [92800/110534 (84%)]\tClassification Loss: 1.5589\r\n",
      "Train Epoch: 26 [93440/110534 (85%)]\tClassification Loss: 1.7129\r\n",
      "Train Epoch: 26 [94080/110534 (85%)]\tClassification Loss: 1.7670\r\n",
      "Train Epoch: 26 [94720/110534 (86%)]\tClassification Loss: 1.2226\r\n",
      "Train Epoch: 26 [95360/110534 (86%)]\tClassification Loss: 1.3125\r\n",
      "Train Epoch: 26 [96000/110534 (87%)]\tClassification Loss: 1.4338\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_26_1500.pth.tar\r\n",
      "Train Epoch: 26 [96640/110534 (87%)]\tClassification Loss: 1.2710\r\n",
      "Train Epoch: 26 [97280/110534 (88%)]\tClassification Loss: 1.2991\r\n",
      "Train Epoch: 26 [97920/110534 (89%)]\tClassification Loss: 1.3060\r\n",
      "Train Epoch: 26 [98560/110534 (89%)]\tClassification Loss: 1.6083\r\n",
      "Train Epoch: 26 [99200/110534 (90%)]\tClassification Loss: 1.6222\r\n",
      "Train Epoch: 26 [99840/110534 (90%)]\tClassification Loss: 1.3907\r\n",
      "Train Epoch: 26 [100480/110534 (91%)]\tClassification Loss: 1.6552\r\n",
      "Train Epoch: 26 [101120/110534 (91%)]\tClassification Loss: 1.3655\r\n",
      "Train Epoch: 26 [101760/110534 (92%)]\tClassification Loss: 1.6156\r\n",
      "Train Epoch: 26 [102400/110534 (93%)]\tClassification Loss: 1.6195\r\n",
      "Train Epoch: 26 [103040/110534 (93%)]\tClassification Loss: 1.4013\r\n",
      "Train Epoch: 26 [103680/110534 (94%)]\tClassification Loss: 1.7852\r\n",
      "Train Epoch: 26 [104320/110534 (94%)]\tClassification Loss: 1.2053\r\n",
      "Train Epoch: 26 [104960/110534 (95%)]\tClassification Loss: 1.4972\r\n",
      "Train Epoch: 26 [105600/110534 (96%)]\tClassification Loss: 1.3686\r\n",
      "Train Epoch: 26 [106240/110534 (96%)]\tClassification Loss: 1.2956\r\n",
      "Train Epoch: 26 [106880/110534 (97%)]\tClassification Loss: 1.6400\r\n",
      "Train Epoch: 26 [107520/110534 (97%)]\tClassification Loss: 1.7495\r\n",
      "Train Epoch: 26 [108160/110534 (98%)]\tClassification Loss: 1.4787\r\n",
      "Train Epoch: 26 [108800/110534 (98%)]\tClassification Loss: 1.7131\r\n",
      "Train Epoch: 26 [109440/110534 (99%)]\tClassification Loss: 1.5537\r\n",
      "Train Epoch: 26 [110080/110534 (100%)]\tClassification Loss: 1.3744\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_26_final.pth.tar\r\n",
      "Train Epoch: 27 [0/110534 (0%)]\tClassification Loss: 1.5648\r\n",
      "\r\n",
      "Test set: Average loss: 1.4293, Accuracy: 22892/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 27 [640/110534 (1%)]\tClassification Loss: 1.3496\r\n",
      "Train Epoch: 27 [1280/110534 (1%)]\tClassification Loss: 2.0825\r\n",
      "Train Epoch: 27 [1920/110534 (2%)]\tClassification Loss: 1.5952\r\n",
      "Train Epoch: 27 [2560/110534 (2%)]\tClassification Loss: 1.7889\r\n",
      "Train Epoch: 27 [3200/110534 (3%)]\tClassification Loss: 1.3845\r\n",
      "Train Epoch: 27 [3840/110534 (3%)]\tClassification Loss: 1.4991\r\n",
      "Train Epoch: 27 [4480/110534 (4%)]\tClassification Loss: 1.4115\r\n",
      "Train Epoch: 27 [5120/110534 (5%)]\tClassification Loss: 1.5494\r\n",
      "Train Epoch: 27 [5760/110534 (5%)]\tClassification Loss: 1.5504\r\n",
      "Train Epoch: 27 [6400/110534 (6%)]\tClassification Loss: 1.3227\r\n",
      "Train Epoch: 27 [7040/110534 (6%)]\tClassification Loss: 1.5149\r\n",
      "Train Epoch: 27 [7680/110534 (7%)]\tClassification Loss: 1.6439\r\n",
      "Train Epoch: 27 [8320/110534 (8%)]\tClassification Loss: 1.8115\r\n",
      "Train Epoch: 27 [8960/110534 (8%)]\tClassification Loss: 1.7777\r\n",
      "Train Epoch: 27 [9600/110534 (9%)]\tClassification Loss: 1.4481\r\n",
      "Train Epoch: 27 [10240/110534 (9%)]\tClassification Loss: 1.5117\r\n",
      "Train Epoch: 27 [10880/110534 (10%)]\tClassification Loss: 1.5199\r\n",
      "Train Epoch: 27 [11520/110534 (10%)]\tClassification Loss: 1.4795\r\n",
      "Train Epoch: 27 [12160/110534 (11%)]\tClassification Loss: 1.4987\r\n",
      "Train Epoch: 27 [12800/110534 (12%)]\tClassification Loss: 1.5237\r\n",
      "Train Epoch: 27 [13440/110534 (12%)]\tClassification Loss: 1.4472\r\n",
      "Train Epoch: 27 [14080/110534 (13%)]\tClassification Loss: 1.6928\r\n",
      "Train Epoch: 27 [14720/110534 (13%)]\tClassification Loss: 1.7900\r\n",
      "Train Epoch: 27 [15360/110534 (14%)]\tClassification Loss: 1.6265\r\n",
      "Train Epoch: 27 [16000/110534 (14%)]\tClassification Loss: 1.8257\r\n",
      "Train Epoch: 27 [16640/110534 (15%)]\tClassification Loss: 1.4310\r\n",
      "Train Epoch: 27 [17280/110534 (16%)]\tClassification Loss: 1.5708\r\n",
      "Train Epoch: 27 [17920/110534 (16%)]\tClassification Loss: 1.4988\r\n",
      "Train Epoch: 27 [18560/110534 (17%)]\tClassification Loss: 1.7119\r\n",
      "Train Epoch: 27 [19200/110534 (17%)]\tClassification Loss: 1.6078\r\n",
      "Train Epoch: 27 [19840/110534 (18%)]\tClassification Loss: 1.5825\r\n",
      "Train Epoch: 27 [20480/110534 (19%)]\tClassification Loss: 1.8456\r\n",
      "Train Epoch: 27 [21120/110534 (19%)]\tClassification Loss: 1.7612\r\n",
      "Train Epoch: 27 [21760/110534 (20%)]\tClassification Loss: 1.3137\r\n",
      "Train Epoch: 27 [22400/110534 (20%)]\tClassification Loss: 1.5484\r\n",
      "Train Epoch: 27 [23040/110534 (21%)]\tClassification Loss: 1.1958\r\n",
      "Train Epoch: 27 [23680/110534 (21%)]\tClassification Loss: 1.5394\r\n",
      "Train Epoch: 27 [24320/110534 (22%)]\tClassification Loss: 1.1498\r\n",
      "Train Epoch: 27 [24960/110534 (23%)]\tClassification Loss: 1.6571\r\n",
      "Train Epoch: 27 [25600/110534 (23%)]\tClassification Loss: 1.3594\r\n",
      "Train Epoch: 27 [26240/110534 (24%)]\tClassification Loss: 1.4044\r\n",
      "Train Epoch: 27 [26880/110534 (24%)]\tClassification Loss: 1.6250\r\n",
      "Train Epoch: 27 [27520/110534 (25%)]\tClassification Loss: 1.3809\r\n",
      "Train Epoch: 27 [28160/110534 (25%)]\tClassification Loss: 1.6872\r\n",
      "Train Epoch: 27 [28800/110534 (26%)]\tClassification Loss: 1.7444\r\n",
      "Train Epoch: 27 [29440/110534 (27%)]\tClassification Loss: 1.5592\r\n",
      "Train Epoch: 27 [30080/110534 (27%)]\tClassification Loss: 1.9344\r\n",
      "Train Epoch: 27 [30720/110534 (28%)]\tClassification Loss: 1.4525\r\n",
      "Train Epoch: 27 [31360/110534 (28%)]\tClassification Loss: 1.5372\r\n",
      "Train Epoch: 27 [32000/110534 (29%)]\tClassification Loss: 1.4095\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_27_500.pth.tar\r\n",
      "Train Epoch: 27 [32640/110534 (30%)]\tClassification Loss: 1.4868\r\n",
      "Train Epoch: 27 [33280/110534 (30%)]\tClassification Loss: 1.4847\r\n",
      "Train Epoch: 27 [33920/110534 (31%)]\tClassification Loss: 1.6624\r\n",
      "Train Epoch: 27 [34560/110534 (31%)]\tClassification Loss: 1.7169\r\n",
      "Train Epoch: 27 [35200/110534 (32%)]\tClassification Loss: 1.4520\r\n",
      "Train Epoch: 27 [35840/110534 (32%)]\tClassification Loss: 1.2662\r\n",
      "Train Epoch: 27 [36480/110534 (33%)]\tClassification Loss: 1.4423\r\n",
      "Train Epoch: 27 [37120/110534 (34%)]\tClassification Loss: 1.7720\r\n",
      "Train Epoch: 27 [37760/110534 (34%)]\tClassification Loss: 1.8815\r\n",
      "Train Epoch: 27 [38400/110534 (35%)]\tClassification Loss: 1.4739\r\n",
      "Train Epoch: 27 [39040/110534 (35%)]\tClassification Loss: 1.4475\r\n",
      "Train Epoch: 27 [39680/110534 (36%)]\tClassification Loss: 1.5904\r\n",
      "Train Epoch: 27 [40320/110534 (36%)]\tClassification Loss: 1.5562\r\n",
      "Train Epoch: 27 [40960/110534 (37%)]\tClassification Loss: 1.4786\r\n",
      "Train Epoch: 27 [41600/110534 (38%)]\tClassification Loss: 1.4131\r\n",
      "Train Epoch: 27 [42240/110534 (38%)]\tClassification Loss: 1.3170\r\n",
      "Train Epoch: 27 [42880/110534 (39%)]\tClassification Loss: 1.3758\r\n",
      "Train Epoch: 27 [43520/110534 (39%)]\tClassification Loss: 1.3284\r\n",
      "Train Epoch: 27 [44160/110534 (40%)]\tClassification Loss: 1.3872\r\n",
      "Train Epoch: 27 [44800/110534 (41%)]\tClassification Loss: 1.7751\r\n",
      "Train Epoch: 27 [45440/110534 (41%)]\tClassification Loss: 1.5586\r\n",
      "Train Epoch: 27 [46080/110534 (42%)]\tClassification Loss: 1.3215\r\n",
      "Train Epoch: 27 [46720/110534 (42%)]\tClassification Loss: 1.4836\r\n",
      "Train Epoch: 27 [47360/110534 (43%)]\tClassification Loss: 1.5208\r\n",
      "Train Epoch: 27 [48000/110534 (43%)]\tClassification Loss: 1.5758\r\n",
      "Train Epoch: 27 [48640/110534 (44%)]\tClassification Loss: 1.3383\r\n",
      "Train Epoch: 27 [49280/110534 (45%)]\tClassification Loss: 1.4222\r\n",
      "Train Epoch: 27 [49920/110534 (45%)]\tClassification Loss: 1.5915\r\n",
      "Train Epoch: 27 [50560/110534 (46%)]\tClassification Loss: 1.5678\r\n",
      "Train Epoch: 27 [51200/110534 (46%)]\tClassification Loss: 1.5062\r\n",
      "Train Epoch: 27 [51840/110534 (47%)]\tClassification Loss: 1.4342\r\n",
      "Train Epoch: 27 [52480/110534 (47%)]\tClassification Loss: 1.5850\r\n",
      "Train Epoch: 27 [53120/110534 (48%)]\tClassification Loss: 1.1890\r\n",
      "Train Epoch: 27 [53760/110534 (49%)]\tClassification Loss: 1.6330\r\n",
      "Train Epoch: 27 [54400/110534 (49%)]\tClassification Loss: 1.4584\r\n",
      "Train Epoch: 27 [55040/110534 (50%)]\tClassification Loss: 1.5210\r\n",
      "Train Epoch: 27 [55680/110534 (50%)]\tClassification Loss: 1.6188\r\n",
      "Train Epoch: 27 [56320/110534 (51%)]\tClassification Loss: 1.4723\r\n",
      "Train Epoch: 27 [56960/110534 (52%)]\tClassification Loss: 1.5595\r\n",
      "Train Epoch: 27 [57600/110534 (52%)]\tClassification Loss: 1.5298\r\n",
      "Train Epoch: 27 [58240/110534 (53%)]\tClassification Loss: 1.5644\r\n",
      "Train Epoch: 27 [58880/110534 (53%)]\tClassification Loss: 1.8236\r\n",
      "Train Epoch: 27 [59520/110534 (54%)]\tClassification Loss: 1.3713\r\n",
      "Train Epoch: 27 [60160/110534 (54%)]\tClassification Loss: 1.3568\r\n",
      "Train Epoch: 27 [60800/110534 (55%)]\tClassification Loss: 1.5009\r\n",
      "Train Epoch: 27 [61440/110534 (56%)]\tClassification Loss: 1.5558\r\n",
      "Train Epoch: 27 [62080/110534 (56%)]\tClassification Loss: 1.4132\r\n",
      "Train Epoch: 27 [62720/110534 (57%)]\tClassification Loss: 1.5726\r\n",
      "Train Epoch: 27 [63360/110534 (57%)]\tClassification Loss: 1.3038\r\n",
      "Train Epoch: 27 [64000/110534 (58%)]\tClassification Loss: 1.5888\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_27_1000.pth.tar\r\n",
      "Train Epoch: 27 [64640/110534 (58%)]\tClassification Loss: 1.2619\r\n",
      "Train Epoch: 27 [65280/110534 (59%)]\tClassification Loss: 1.4648\r\n",
      "Train Epoch: 27 [65920/110534 (60%)]\tClassification Loss: 1.5891\r\n",
      "Train Epoch: 27 [66560/110534 (60%)]\tClassification Loss: 1.3623\r\n",
      "Train Epoch: 27 [67200/110534 (61%)]\tClassification Loss: 1.3364\r\n",
      "Train Epoch: 27 [67840/110534 (61%)]\tClassification Loss: 1.8978\r\n",
      "Train Epoch: 27 [68480/110534 (62%)]\tClassification Loss: 1.7144\r\n",
      "Train Epoch: 27 [69120/110534 (63%)]\tClassification Loss: 1.9264\r\n",
      "Train Epoch: 27 [69760/110534 (63%)]\tClassification Loss: 1.5749\r\n",
      "Train Epoch: 27 [70400/110534 (64%)]\tClassification Loss: 1.1291\r\n",
      "Train Epoch: 27 [71040/110534 (64%)]\tClassification Loss: 1.8946\r\n",
      "Train Epoch: 27 [71680/110534 (65%)]\tClassification Loss: 1.5233\r\n",
      "Train Epoch: 27 [72320/110534 (65%)]\tClassification Loss: 1.6211\r\n",
      "Train Epoch: 27 [72960/110534 (66%)]\tClassification Loss: 1.6983\r\n",
      "Train Epoch: 27 [73600/110534 (67%)]\tClassification Loss: 1.8663\r\n",
      "Train Epoch: 27 [74240/110534 (67%)]\tClassification Loss: 1.5969\r\n",
      "Train Epoch: 27 [74880/110534 (68%)]\tClassification Loss: 1.0814\r\n",
      "Train Epoch: 27 [75520/110534 (68%)]\tClassification Loss: 1.3412\r\n",
      "Train Epoch: 27 [76160/110534 (69%)]\tClassification Loss: 1.4237\r\n",
      "Train Epoch: 27 [76800/110534 (69%)]\tClassification Loss: 1.3573\r\n",
      "Train Epoch: 27 [77440/110534 (70%)]\tClassification Loss: 1.3661\r\n",
      "Train Epoch: 27 [78080/110534 (71%)]\tClassification Loss: 1.4903\r\n",
      "Train Epoch: 27 [78720/110534 (71%)]\tClassification Loss: 1.3914\r\n",
      "Train Epoch: 27 [79360/110534 (72%)]\tClassification Loss: 1.2502\r\n",
      "Train Epoch: 27 [80000/110534 (72%)]\tClassification Loss: 1.2960\r\n",
      "Train Epoch: 27 [80640/110534 (73%)]\tClassification Loss: 1.3496\r\n",
      "Train Epoch: 27 [81280/110534 (74%)]\tClassification Loss: 1.8970\r\n",
      "Train Epoch: 27 [81920/110534 (74%)]\tClassification Loss: 1.5249\r\n",
      "Train Epoch: 27 [82560/110534 (75%)]\tClassification Loss: 1.6236\r\n",
      "Train Epoch: 27 [83200/110534 (75%)]\tClassification Loss: 1.4770\r\n",
      "Train Epoch: 27 [83840/110534 (76%)]\tClassification Loss: 1.7622\r\n",
      "Train Epoch: 27 [84480/110534 (76%)]\tClassification Loss: 1.5350\r\n",
      "Train Epoch: 27 [85120/110534 (77%)]\tClassification Loss: 1.3725\r\n",
      "Train Epoch: 27 [85760/110534 (78%)]\tClassification Loss: 1.4543\r\n",
      "Train Epoch: 27 [86400/110534 (78%)]\tClassification Loss: 1.6256\r\n",
      "Train Epoch: 27 [87040/110534 (79%)]\tClassification Loss: 1.5527\r\n",
      "Train Epoch: 27 [87680/110534 (79%)]\tClassification Loss: 1.3727\r\n",
      "Train Epoch: 27 [88320/110534 (80%)]\tClassification Loss: 1.4917\r\n",
      "Train Epoch: 27 [88960/110534 (80%)]\tClassification Loss: 1.6408\r\n",
      "Train Epoch: 27 [89600/110534 (81%)]\tClassification Loss: 1.7988\r\n",
      "Train Epoch: 27 [90240/110534 (82%)]\tClassification Loss: 1.8596\r\n",
      "Train Epoch: 27 [90880/110534 (82%)]\tClassification Loss: 1.5712\r\n",
      "Train Epoch: 27 [91520/110534 (83%)]\tClassification Loss: 1.1921\r\n",
      "Train Epoch: 27 [92160/110534 (83%)]\tClassification Loss: 1.4769\r\n",
      "Train Epoch: 27 [92800/110534 (84%)]\tClassification Loss: 1.4644\r\n",
      "Train Epoch: 27 [93440/110534 (85%)]\tClassification Loss: 1.6402\r\n",
      "Train Epoch: 27 [94080/110534 (85%)]\tClassification Loss: 1.6013\r\n",
      "Train Epoch: 27 [94720/110534 (86%)]\tClassification Loss: 1.3870\r\n",
      "Train Epoch: 27 [95360/110534 (86%)]\tClassification Loss: 1.4879\r\n",
      "Train Epoch: 27 [96000/110534 (87%)]\tClassification Loss: 1.3688\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_27_1500.pth.tar\r\n",
      "Train Epoch: 27 [96640/110534 (87%)]\tClassification Loss: 1.3086\r\n",
      "Train Epoch: 27 [97280/110534 (88%)]\tClassification Loss: 1.3235\r\n",
      "Train Epoch: 27 [97920/110534 (89%)]\tClassification Loss: 1.2185\r\n",
      "Train Epoch: 27 [98560/110534 (89%)]\tClassification Loss: 1.5088\r\n",
      "Train Epoch: 27 [99200/110534 (90%)]\tClassification Loss: 1.5043\r\n",
      "Train Epoch: 27 [99840/110534 (90%)]\tClassification Loss: 1.5174\r\n",
      "Train Epoch: 27 [100480/110534 (91%)]\tClassification Loss: 1.5727\r\n",
      "Train Epoch: 27 [101120/110534 (91%)]\tClassification Loss: 1.3961\r\n",
      "Train Epoch: 27 [101760/110534 (92%)]\tClassification Loss: 1.6069\r\n",
      "Train Epoch: 27 [102400/110534 (93%)]\tClassification Loss: 1.4665\r\n",
      "Train Epoch: 27 [103040/110534 (93%)]\tClassification Loss: 1.4727\r\n",
      "Train Epoch: 27 [103680/110534 (94%)]\tClassification Loss: 1.8251\r\n",
      "Train Epoch: 27 [104320/110534 (94%)]\tClassification Loss: 1.3164\r\n",
      "Train Epoch: 27 [104960/110534 (95%)]\tClassification Loss: 1.6227\r\n",
      "Train Epoch: 27 [105600/110534 (96%)]\tClassification Loss: 1.4045\r\n",
      "Train Epoch: 27 [106240/110534 (96%)]\tClassification Loss: 1.4678\r\n",
      "Train Epoch: 27 [106880/110534 (97%)]\tClassification Loss: 1.7371\r\n",
      "Train Epoch: 27 [107520/110534 (97%)]\tClassification Loss: 1.6937\r\n",
      "Train Epoch: 27 [108160/110534 (98%)]\tClassification Loss: 1.4151\r\n",
      "Train Epoch: 27 [108800/110534 (98%)]\tClassification Loss: 1.6234\r\n",
      "Train Epoch: 27 [109440/110534 (99%)]\tClassification Loss: 1.6628\r\n",
      "Train Epoch: 27 [110080/110534 (100%)]\tClassification Loss: 1.4457\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_27_final.pth.tar\r\n",
      "Train Epoch: 28 [0/110534 (0%)]\tClassification Loss: 1.5025\r\n",
      "\r\n",
      "Test set: Average loss: 1.4253, Accuracy: 22955/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 28 [640/110534 (1%)]\tClassification Loss: 1.2797\r\n",
      "Train Epoch: 28 [1280/110534 (1%)]\tClassification Loss: 1.9167\r\n",
      "Train Epoch: 28 [1920/110534 (2%)]\tClassification Loss: 1.5716\r\n",
      "Train Epoch: 28 [2560/110534 (2%)]\tClassification Loss: 1.6347\r\n",
      "Train Epoch: 28 [3200/110534 (3%)]\tClassification Loss: 1.4617\r\n",
      "Train Epoch: 28 [3840/110534 (3%)]\tClassification Loss: 1.2493\r\n",
      "Train Epoch: 28 [4480/110534 (4%)]\tClassification Loss: 1.4313\r\n",
      "Train Epoch: 28 [5120/110534 (5%)]\tClassification Loss: 1.6441\r\n",
      "Train Epoch: 28 [5760/110534 (5%)]\tClassification Loss: 1.6038\r\n",
      "Train Epoch: 28 [6400/110534 (6%)]\tClassification Loss: 1.2692\r\n",
      "Train Epoch: 28 [7040/110534 (6%)]\tClassification Loss: 1.5067\r\n",
      "Train Epoch: 28 [7680/110534 (7%)]\tClassification Loss: 1.5098\r\n",
      "Train Epoch: 28 [8320/110534 (8%)]\tClassification Loss: 1.6916\r\n",
      "Train Epoch: 28 [8960/110534 (8%)]\tClassification Loss: 1.7643\r\n",
      "Train Epoch: 28 [9600/110534 (9%)]\tClassification Loss: 1.3267\r\n",
      "Train Epoch: 28 [10240/110534 (9%)]\tClassification Loss: 1.4590\r\n",
      "Train Epoch: 28 [10880/110534 (10%)]\tClassification Loss: 1.5201\r\n",
      "Train Epoch: 28 [11520/110534 (10%)]\tClassification Loss: 1.5038\r\n",
      "Train Epoch: 28 [12160/110534 (11%)]\tClassification Loss: 1.2486\r\n",
      "Train Epoch: 28 [12800/110534 (12%)]\tClassification Loss: 1.8680\r\n",
      "Train Epoch: 28 [13440/110534 (12%)]\tClassification Loss: 1.2697\r\n",
      "Train Epoch: 28 [14080/110534 (13%)]\tClassification Loss: 1.6444\r\n",
      "Train Epoch: 28 [14720/110534 (13%)]\tClassification Loss: 1.7265\r\n",
      "Train Epoch: 28 [15360/110534 (14%)]\tClassification Loss: 1.6863\r\n",
      "Train Epoch: 28 [16000/110534 (14%)]\tClassification Loss: 1.7204\r\n",
      "Train Epoch: 28 [16640/110534 (15%)]\tClassification Loss: 1.5546\r\n",
      "Train Epoch: 28 [17280/110534 (16%)]\tClassification Loss: 1.6628\r\n",
      "Train Epoch: 28 [17920/110534 (16%)]\tClassification Loss: 1.5729\r\n",
      "Train Epoch: 28 [18560/110534 (17%)]\tClassification Loss: 1.7605\r\n",
      "Train Epoch: 28 [19200/110534 (17%)]\tClassification Loss: 1.6890\r\n",
      "Train Epoch: 28 [19840/110534 (18%)]\tClassification Loss: 1.6189\r\n",
      "Train Epoch: 28 [20480/110534 (19%)]\tClassification Loss: 1.8096\r\n",
      "Train Epoch: 28 [21120/110534 (19%)]\tClassification Loss: 1.7031\r\n",
      "Train Epoch: 28 [21760/110534 (20%)]\tClassification Loss: 1.2793\r\n",
      "Train Epoch: 28 [22400/110534 (20%)]\tClassification Loss: 1.4983\r\n",
      "Train Epoch: 28 [23040/110534 (21%)]\tClassification Loss: 1.1278\r\n",
      "Train Epoch: 28 [23680/110534 (21%)]\tClassification Loss: 1.5692\r\n",
      "Train Epoch: 28 [24320/110534 (22%)]\tClassification Loss: 1.4253\r\n",
      "Train Epoch: 28 [24960/110534 (23%)]\tClassification Loss: 1.7967\r\n",
      "Train Epoch: 28 [25600/110534 (23%)]\tClassification Loss: 1.2416\r\n",
      "Train Epoch: 28 [26240/110534 (24%)]\tClassification Loss: 1.4239\r\n",
      "Train Epoch: 28 [26880/110534 (24%)]\tClassification Loss: 1.6443\r\n",
      "Train Epoch: 28 [27520/110534 (25%)]\tClassification Loss: 1.2116\r\n",
      "Train Epoch: 28 [28160/110534 (25%)]\tClassification Loss: 1.8151\r\n",
      "Train Epoch: 28 [28800/110534 (26%)]\tClassification Loss: 1.7496\r\n",
      "Train Epoch: 28 [29440/110534 (27%)]\tClassification Loss: 1.7140\r\n",
      "Train Epoch: 28 [30080/110534 (27%)]\tClassification Loss: 1.6622\r\n",
      "Train Epoch: 28 [30720/110534 (28%)]\tClassification Loss: 1.3470\r\n",
      "Train Epoch: 28 [31360/110534 (28%)]\tClassification Loss: 1.5291\r\n",
      "Train Epoch: 28 [32000/110534 (29%)]\tClassification Loss: 1.5806\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_28_500.pth.tar\r\n",
      "Train Epoch: 28 [32640/110534 (30%)]\tClassification Loss: 1.3731\r\n",
      "Train Epoch: 28 [33280/110534 (30%)]\tClassification Loss: 1.4725\r\n",
      "Train Epoch: 28 [33920/110534 (31%)]\tClassification Loss: 1.5314\r\n",
      "Train Epoch: 28 [34560/110534 (31%)]\tClassification Loss: 1.9021\r\n",
      "Train Epoch: 28 [35200/110534 (32%)]\tClassification Loss: 1.4188\r\n",
      "Train Epoch: 28 [35840/110534 (32%)]\tClassification Loss: 1.2786\r\n",
      "Train Epoch: 28 [36480/110534 (33%)]\tClassification Loss: 1.5063\r\n",
      "Train Epoch: 28 [37120/110534 (34%)]\tClassification Loss: 1.5998\r\n",
      "Train Epoch: 28 [37760/110534 (34%)]\tClassification Loss: 1.8782\r\n",
      "Train Epoch: 28 [38400/110534 (35%)]\tClassification Loss: 1.4930\r\n",
      "Train Epoch: 28 [39040/110534 (35%)]\tClassification Loss: 1.5058\r\n",
      "Train Epoch: 28 [39680/110534 (36%)]\tClassification Loss: 1.6903\r\n",
      "Train Epoch: 28 [40320/110534 (36%)]\tClassification Loss: 1.5805\r\n",
      "Train Epoch: 28 [40960/110534 (37%)]\tClassification Loss: 1.2969\r\n",
      "Train Epoch: 28 [41600/110534 (38%)]\tClassification Loss: 1.4126\r\n",
      "Train Epoch: 28 [42240/110534 (38%)]\tClassification Loss: 1.4177\r\n",
      "Train Epoch: 28 [42880/110534 (39%)]\tClassification Loss: 1.4096\r\n",
      "Train Epoch: 28 [43520/110534 (39%)]\tClassification Loss: 1.1742\r\n",
      "Train Epoch: 28 [44160/110534 (40%)]\tClassification Loss: 1.5172\r\n",
      "Train Epoch: 28 [44800/110534 (41%)]\tClassification Loss: 1.6773\r\n",
      "Train Epoch: 28 [45440/110534 (41%)]\tClassification Loss: 1.5572\r\n",
      "Train Epoch: 28 [46080/110534 (42%)]\tClassification Loss: 1.3644\r\n",
      "Train Epoch: 28 [46720/110534 (42%)]\tClassification Loss: 1.5828\r\n",
      "Train Epoch: 28 [47360/110534 (43%)]\tClassification Loss: 1.5389\r\n",
      "Train Epoch: 28 [48000/110534 (43%)]\tClassification Loss: 1.7105\r\n",
      "Train Epoch: 28 [48640/110534 (44%)]\tClassification Loss: 1.2972\r\n",
      "Train Epoch: 28 [49280/110534 (45%)]\tClassification Loss: 1.5718\r\n",
      "Train Epoch: 28 [49920/110534 (45%)]\tClassification Loss: 1.6478\r\n",
      "Train Epoch: 28 [50560/110534 (46%)]\tClassification Loss: 1.4933\r\n",
      "Train Epoch: 28 [51200/110534 (46%)]\tClassification Loss: 1.3622\r\n",
      "Train Epoch: 28 [51840/110534 (47%)]\tClassification Loss: 1.3759\r\n",
      "Train Epoch: 28 [52480/110534 (47%)]\tClassification Loss: 1.6060\r\n",
      "Train Epoch: 28 [53120/110534 (48%)]\tClassification Loss: 1.1919\r\n",
      "Train Epoch: 28 [53760/110534 (49%)]\tClassification Loss: 1.4890\r\n",
      "Train Epoch: 28 [54400/110534 (49%)]\tClassification Loss: 1.6279\r\n",
      "Train Epoch: 28 [55040/110534 (50%)]\tClassification Loss: 1.5937\r\n",
      "Train Epoch: 28 [55680/110534 (50%)]\tClassification Loss: 1.6964\r\n",
      "Train Epoch: 28 [56320/110534 (51%)]\tClassification Loss: 1.3529\r\n",
      "Train Epoch: 28 [56960/110534 (52%)]\tClassification Loss: 1.4969\r\n",
      "Train Epoch: 28 [57600/110534 (52%)]\tClassification Loss: 1.7001\r\n",
      "Train Epoch: 28 [58240/110534 (53%)]\tClassification Loss: 1.6066\r\n",
      "Train Epoch: 28 [58880/110534 (53%)]\tClassification Loss: 1.7716\r\n",
      "Train Epoch: 28 [59520/110534 (54%)]\tClassification Loss: 1.4185\r\n",
      "Train Epoch: 28 [60160/110534 (54%)]\tClassification Loss: 1.3240\r\n",
      "Train Epoch: 28 [60800/110534 (55%)]\tClassification Loss: 1.3785\r\n",
      "Train Epoch: 28 [61440/110534 (56%)]\tClassification Loss: 1.6098\r\n",
      "Train Epoch: 28 [62080/110534 (56%)]\tClassification Loss: 1.4945\r\n",
      "Train Epoch: 28 [62720/110534 (57%)]\tClassification Loss: 1.5689\r\n",
      "Train Epoch: 28 [63360/110534 (57%)]\tClassification Loss: 1.2450\r\n",
      "Train Epoch: 28 [64000/110534 (58%)]\tClassification Loss: 1.5891\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_28_1000.pth.tar\r\n",
      "Train Epoch: 28 [64640/110534 (58%)]\tClassification Loss: 1.1867\r\n",
      "Train Epoch: 28 [65280/110534 (59%)]\tClassification Loss: 1.4701\r\n",
      "Train Epoch: 28 [65920/110534 (60%)]\tClassification Loss: 1.5150\r\n",
      "Train Epoch: 28 [66560/110534 (60%)]\tClassification Loss: 1.3825\r\n",
      "Train Epoch: 28 [67200/110534 (61%)]\tClassification Loss: 1.4122\r\n",
      "Train Epoch: 28 [67840/110534 (61%)]\tClassification Loss: 1.7355\r\n",
      "Train Epoch: 28 [68480/110534 (62%)]\tClassification Loss: 1.5876\r\n",
      "Train Epoch: 28 [69120/110534 (63%)]\tClassification Loss: 1.8566\r\n",
      "Train Epoch: 28 [69760/110534 (63%)]\tClassification Loss: 1.7141\r\n",
      "Train Epoch: 28 [70400/110534 (64%)]\tClassification Loss: 1.3329\r\n",
      "Train Epoch: 28 [71040/110534 (64%)]\tClassification Loss: 1.9241\r\n",
      "Train Epoch: 28 [71680/110534 (65%)]\tClassification Loss: 1.4778\r\n",
      "Train Epoch: 28 [72320/110534 (65%)]\tClassification Loss: 1.5866\r\n",
      "Train Epoch: 28 [72960/110534 (66%)]\tClassification Loss: 1.8859\r\n",
      "Train Epoch: 28 [73600/110534 (67%)]\tClassification Loss: 1.7574\r\n",
      "Train Epoch: 28 [74240/110534 (67%)]\tClassification Loss: 1.5827\r\n",
      "Train Epoch: 28 [74880/110534 (68%)]\tClassification Loss: 1.1861\r\n",
      "Train Epoch: 28 [75520/110534 (68%)]\tClassification Loss: 1.5103\r\n",
      "Train Epoch: 28 [76160/110534 (69%)]\tClassification Loss: 1.4607\r\n",
      "Train Epoch: 28 [76800/110534 (69%)]\tClassification Loss: 1.2741\r\n",
      "Train Epoch: 28 [77440/110534 (70%)]\tClassification Loss: 1.4897\r\n",
      "Train Epoch: 28 [78080/110534 (71%)]\tClassification Loss: 1.3854\r\n",
      "Train Epoch: 28 [78720/110534 (71%)]\tClassification Loss: 1.4052\r\n",
      "Train Epoch: 28 [79360/110534 (72%)]\tClassification Loss: 1.4530\r\n",
      "Train Epoch: 28 [80000/110534 (72%)]\tClassification Loss: 1.5157\r\n",
      "Train Epoch: 28 [80640/110534 (73%)]\tClassification Loss: 1.3786\r\n",
      "Train Epoch: 28 [81280/110534 (74%)]\tClassification Loss: 1.8221\r\n",
      "Train Epoch: 28 [81920/110534 (74%)]\tClassification Loss: 1.5170\r\n",
      "Train Epoch: 28 [82560/110534 (75%)]\tClassification Loss: 1.5669\r\n",
      "Train Epoch: 28 [83200/110534 (75%)]\tClassification Loss: 1.3487\r\n",
      "Train Epoch: 28 [83840/110534 (76%)]\tClassification Loss: 1.8726\r\n",
      "Train Epoch: 28 [84480/110534 (76%)]\tClassification Loss: 1.6620\r\n",
      "Train Epoch: 28 [85120/110534 (77%)]\tClassification Loss: 1.5369\r\n",
      "Train Epoch: 28 [85760/110534 (78%)]\tClassification Loss: 1.4312\r\n",
      "Train Epoch: 28 [86400/110534 (78%)]\tClassification Loss: 1.7333\r\n",
      "Train Epoch: 28 [87040/110534 (79%)]\tClassification Loss: 1.5301\r\n",
      "Train Epoch: 28 [87680/110534 (79%)]\tClassification Loss: 1.4456\r\n",
      "Train Epoch: 28 [88320/110534 (80%)]\tClassification Loss: 1.5277\r\n",
      "Train Epoch: 28 [88960/110534 (80%)]\tClassification Loss: 1.6109\r\n",
      "Train Epoch: 28 [89600/110534 (81%)]\tClassification Loss: 1.6759\r\n",
      "Train Epoch: 28 [90240/110534 (82%)]\tClassification Loss: 1.8157\r\n",
      "Train Epoch: 28 [90880/110534 (82%)]\tClassification Loss: 1.6779\r\n",
      "Train Epoch: 28 [91520/110534 (83%)]\tClassification Loss: 1.4230\r\n",
      "Train Epoch: 28 [92160/110534 (83%)]\tClassification Loss: 1.3006\r\n",
      "Train Epoch: 28 [92800/110534 (84%)]\tClassification Loss: 1.2757\r\n",
      "Train Epoch: 28 [93440/110534 (85%)]\tClassification Loss: 1.6434\r\n",
      "Train Epoch: 28 [94080/110534 (85%)]\tClassification Loss: 1.7526\r\n",
      "Train Epoch: 28 [94720/110534 (86%)]\tClassification Loss: 1.3485\r\n",
      "Train Epoch: 28 [95360/110534 (86%)]\tClassification Loss: 1.3855\r\n",
      "Train Epoch: 28 [96000/110534 (87%)]\tClassification Loss: 1.4668\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_28_1500.pth.tar\r\n",
      "Train Epoch: 28 [96640/110534 (87%)]\tClassification Loss: 1.5295\r\n",
      "Train Epoch: 28 [97280/110534 (88%)]\tClassification Loss: 1.3482\r\n",
      "Train Epoch: 28 [97920/110534 (89%)]\tClassification Loss: 1.2888\r\n",
      "Train Epoch: 28 [98560/110534 (89%)]\tClassification Loss: 1.4067\r\n",
      "Train Epoch: 28 [99200/110534 (90%)]\tClassification Loss: 1.5680\r\n",
      "Train Epoch: 28 [99840/110534 (90%)]\tClassification Loss: 1.3628\r\n",
      "Train Epoch: 28 [100480/110534 (91%)]\tClassification Loss: 1.5796\r\n",
      "Train Epoch: 28 [101120/110534 (91%)]\tClassification Loss: 1.4374\r\n",
      "Train Epoch: 28 [101760/110534 (92%)]\tClassification Loss: 1.6730\r\n",
      "Train Epoch: 28 [102400/110534 (93%)]\tClassification Loss: 1.6084\r\n",
      "Train Epoch: 28 [103040/110534 (93%)]\tClassification Loss: 1.5526\r\n",
      "Train Epoch: 28 [103680/110534 (94%)]\tClassification Loss: 1.8245\r\n",
      "Train Epoch: 28 [104320/110534 (94%)]\tClassification Loss: 1.3858\r\n",
      "Train Epoch: 28 [104960/110534 (95%)]\tClassification Loss: 1.5451\r\n",
      "Train Epoch: 28 [105600/110534 (96%)]\tClassification Loss: 1.4929\r\n",
      "Train Epoch: 28 [106240/110534 (96%)]\tClassification Loss: 1.3233\r\n",
      "Train Epoch: 28 [106880/110534 (97%)]\tClassification Loss: 1.6018\r\n",
      "Train Epoch: 28 [107520/110534 (97%)]\tClassification Loss: 1.7283\r\n",
      "Train Epoch: 28 [108160/110534 (98%)]\tClassification Loss: 1.5169\r\n",
      "Train Epoch: 28 [108800/110534 (98%)]\tClassification Loss: 1.6351\r\n",
      "Train Epoch: 28 [109440/110534 (99%)]\tClassification Loss: 1.2824\r\n",
      "Train Epoch: 28 [110080/110534 (100%)]\tClassification Loss: 1.3985\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_28_final.pth.tar\r\n",
      "Train Epoch: 29 [0/110534 (0%)]\tClassification Loss: 1.5827\r\n",
      "\r\n",
      "Test set: Average loss: 1.4235, Accuracy: 22940/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 29 [640/110534 (1%)]\tClassification Loss: 1.3655\r\n",
      "Train Epoch: 29 [1280/110534 (1%)]\tClassification Loss: 2.1513\r\n",
      "Train Epoch: 29 [1920/110534 (2%)]\tClassification Loss: 1.5692\r\n",
      "Train Epoch: 29 [2560/110534 (2%)]\tClassification Loss: 1.7461\r\n",
      "Train Epoch: 29 [3200/110534 (3%)]\tClassification Loss: 1.4629\r\n",
      "Train Epoch: 29 [3840/110534 (3%)]\tClassification Loss: 1.4814\r\n",
      "Train Epoch: 29 [4480/110534 (4%)]\tClassification Loss: 1.5840\r\n",
      "Train Epoch: 29 [5120/110534 (5%)]\tClassification Loss: 1.5579\r\n",
      "Train Epoch: 29 [5760/110534 (5%)]\tClassification Loss: 1.5019\r\n",
      "Train Epoch: 29 [6400/110534 (6%)]\tClassification Loss: 1.3274\r\n",
      "Train Epoch: 29 [7040/110534 (6%)]\tClassification Loss: 1.6070\r\n",
      "Train Epoch: 29 [7680/110534 (7%)]\tClassification Loss: 1.6654\r\n",
      "Train Epoch: 29 [8320/110534 (8%)]\tClassification Loss: 1.8333\r\n",
      "Train Epoch: 29 [8960/110534 (8%)]\tClassification Loss: 1.5643\r\n",
      "Train Epoch: 29 [9600/110534 (9%)]\tClassification Loss: 1.5174\r\n",
      "Train Epoch: 29 [10240/110534 (9%)]\tClassification Loss: 1.5198\r\n",
      "Train Epoch: 29 [10880/110534 (10%)]\tClassification Loss: 1.3341\r\n",
      "Train Epoch: 29 [11520/110534 (10%)]\tClassification Loss: 1.7048\r\n",
      "Train Epoch: 29 [12160/110534 (11%)]\tClassification Loss: 1.4307\r\n",
      "Train Epoch: 29 [12800/110534 (12%)]\tClassification Loss: 1.7053\r\n",
      "Train Epoch: 29 [13440/110534 (12%)]\tClassification Loss: 1.3687\r\n",
      "Train Epoch: 29 [14080/110534 (13%)]\tClassification Loss: 1.4917\r\n",
      "Train Epoch: 29 [14720/110534 (13%)]\tClassification Loss: 1.7173\r\n",
      "Train Epoch: 29 [15360/110534 (14%)]\tClassification Loss: 1.4206\r\n",
      "Train Epoch: 29 [16000/110534 (14%)]\tClassification Loss: 1.6036\r\n",
      "Train Epoch: 29 [16640/110534 (15%)]\tClassification Loss: 1.4400\r\n",
      "Train Epoch: 29 [17280/110534 (16%)]\tClassification Loss: 1.7785\r\n",
      "Train Epoch: 29 [17920/110534 (16%)]\tClassification Loss: 1.6096\r\n",
      "Train Epoch: 29 [18560/110534 (17%)]\tClassification Loss: 1.7610\r\n",
      "Train Epoch: 29 [19200/110534 (17%)]\tClassification Loss: 1.4656\r\n",
      "Train Epoch: 29 [19840/110534 (18%)]\tClassification Loss: 1.5028\r\n",
      "Train Epoch: 29 [20480/110534 (19%)]\tClassification Loss: 1.7623\r\n",
      "Train Epoch: 29 [21120/110534 (19%)]\tClassification Loss: 1.7656\r\n",
      "Train Epoch: 29 [21760/110534 (20%)]\tClassification Loss: 1.4418\r\n",
      "Train Epoch: 29 [22400/110534 (20%)]\tClassification Loss: 1.5640\r\n",
      "Train Epoch: 29 [23040/110534 (21%)]\tClassification Loss: 1.1624\r\n",
      "Train Epoch: 29 [23680/110534 (21%)]\tClassification Loss: 1.7068\r\n",
      "Train Epoch: 29 [24320/110534 (22%)]\tClassification Loss: 1.2483\r\n",
      "Train Epoch: 29 [24960/110534 (23%)]\tClassification Loss: 1.6381\r\n",
      "Train Epoch: 29 [25600/110534 (23%)]\tClassification Loss: 1.4000\r\n",
      "Train Epoch: 29 [26240/110534 (24%)]\tClassification Loss: 1.5458\r\n",
      "Train Epoch: 29 [26880/110534 (24%)]\tClassification Loss: 1.5278\r\n",
      "Train Epoch: 29 [27520/110534 (25%)]\tClassification Loss: 1.3680\r\n",
      "Train Epoch: 29 [28160/110534 (25%)]\tClassification Loss: 1.7483\r\n",
      "Train Epoch: 29 [28800/110534 (26%)]\tClassification Loss: 1.8273\r\n",
      "Train Epoch: 29 [29440/110534 (27%)]\tClassification Loss: 1.6328\r\n",
      "Train Epoch: 29 [30080/110534 (27%)]\tClassification Loss: 1.6855\r\n",
      "Train Epoch: 29 [30720/110534 (28%)]\tClassification Loss: 1.4795\r\n",
      "Train Epoch: 29 [31360/110534 (28%)]\tClassification Loss: 1.5709\r\n",
      "Train Epoch: 29 [32000/110534 (29%)]\tClassification Loss: 1.4166\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_29_500.pth.tar\r\n",
      "Train Epoch: 29 [32640/110534 (30%)]\tClassification Loss: 1.5136\r\n",
      "Train Epoch: 29 [33280/110534 (30%)]\tClassification Loss: 1.4800\r\n",
      "Train Epoch: 29 [33920/110534 (31%)]\tClassification Loss: 1.5097\r\n",
      "Train Epoch: 29 [34560/110534 (31%)]\tClassification Loss: 1.7689\r\n",
      "Train Epoch: 29 [35200/110534 (32%)]\tClassification Loss: 1.4443\r\n",
      "Train Epoch: 29 [35840/110534 (32%)]\tClassification Loss: 1.2965\r\n",
      "Train Epoch: 29 [36480/110534 (33%)]\tClassification Loss: 1.4154\r\n",
      "Train Epoch: 29 [37120/110534 (34%)]\tClassification Loss: 1.7174\r\n",
      "Train Epoch: 29 [37760/110534 (34%)]\tClassification Loss: 1.9165\r\n",
      "Train Epoch: 29 [38400/110534 (35%)]\tClassification Loss: 1.3056\r\n",
      "Train Epoch: 29 [39040/110534 (35%)]\tClassification Loss: 1.5021\r\n",
      "Train Epoch: 29 [39680/110534 (36%)]\tClassification Loss: 1.5243\r\n",
      "Train Epoch: 29 [40320/110534 (36%)]\tClassification Loss: 1.6043\r\n",
      "Train Epoch: 29 [40960/110534 (37%)]\tClassification Loss: 1.4570\r\n",
      "Train Epoch: 29 [41600/110534 (38%)]\tClassification Loss: 1.3163\r\n",
      "Train Epoch: 29 [42240/110534 (38%)]\tClassification Loss: 1.4697\r\n",
      "Train Epoch: 29 [42880/110534 (39%)]\tClassification Loss: 1.4349\r\n",
      "Train Epoch: 29 [43520/110534 (39%)]\tClassification Loss: 1.3607\r\n",
      "Train Epoch: 29 [44160/110534 (40%)]\tClassification Loss: 1.5760\r\n",
      "Train Epoch: 29 [44800/110534 (41%)]\tClassification Loss: 1.6410\r\n",
      "Train Epoch: 29 [45440/110534 (41%)]\tClassification Loss: 1.5394\r\n",
      "Train Epoch: 29 [46080/110534 (42%)]\tClassification Loss: 1.3720\r\n",
      "Train Epoch: 29 [46720/110534 (42%)]\tClassification Loss: 1.5319\r\n",
      "Train Epoch: 29 [47360/110534 (43%)]\tClassification Loss: 1.6624\r\n",
      "Train Epoch: 29 [48000/110534 (43%)]\tClassification Loss: 1.5071\r\n",
      "Train Epoch: 29 [48640/110534 (44%)]\tClassification Loss: 1.4273\r\n",
      "Train Epoch: 29 [49280/110534 (45%)]\tClassification Loss: 1.5391\r\n",
      "Train Epoch: 29 [49920/110534 (45%)]\tClassification Loss: 1.4318\r\n",
      "Train Epoch: 29 [50560/110534 (46%)]\tClassification Loss: 1.6413\r\n",
      "Train Epoch: 29 [51200/110534 (46%)]\tClassification Loss: 1.5244\r\n",
      "Train Epoch: 29 [51840/110534 (47%)]\tClassification Loss: 1.5355\r\n",
      "Train Epoch: 29 [52480/110534 (47%)]\tClassification Loss: 1.4571\r\n",
      "Train Epoch: 29 [53120/110534 (48%)]\tClassification Loss: 1.2299\r\n",
      "Train Epoch: 29 [53760/110534 (49%)]\tClassification Loss: 1.3968\r\n",
      "Train Epoch: 29 [54400/110534 (49%)]\tClassification Loss: 1.3819\r\n",
      "Train Epoch: 29 [55040/110534 (50%)]\tClassification Loss: 1.7522\r\n",
      "Train Epoch: 29 [55680/110534 (50%)]\tClassification Loss: 1.6257\r\n",
      "Train Epoch: 29 [56320/110534 (51%)]\tClassification Loss: 1.3968\r\n",
      "Train Epoch: 29 [56960/110534 (52%)]\tClassification Loss: 1.4280\r\n",
      "Train Epoch: 29 [57600/110534 (52%)]\tClassification Loss: 1.5905\r\n",
      "Train Epoch: 29 [58240/110534 (53%)]\tClassification Loss: 1.4009\r\n",
      "Train Epoch: 29 [58880/110534 (53%)]\tClassification Loss: 1.9025\r\n",
      "Train Epoch: 29 [59520/110534 (54%)]\tClassification Loss: 1.4074\r\n",
      "Train Epoch: 29 [60160/110534 (54%)]\tClassification Loss: 1.3475\r\n",
      "Train Epoch: 29 [60800/110534 (55%)]\tClassification Loss: 1.5962\r\n",
      "Train Epoch: 29 [61440/110534 (56%)]\tClassification Loss: 1.5362\r\n",
      "Train Epoch: 29 [62080/110534 (56%)]\tClassification Loss: 1.4629\r\n",
      "Train Epoch: 29 [62720/110534 (57%)]\tClassification Loss: 1.5030\r\n",
      "Train Epoch: 29 [63360/110534 (57%)]\tClassification Loss: 1.2404\r\n",
      "Train Epoch: 29 [64000/110534 (58%)]\tClassification Loss: 1.5753\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_29_1000.pth.tar\r\n",
      "Train Epoch: 29 [64640/110534 (58%)]\tClassification Loss: 1.3108\r\n",
      "Train Epoch: 29 [65280/110534 (59%)]\tClassification Loss: 1.3760\r\n",
      "Train Epoch: 29 [65920/110534 (60%)]\tClassification Loss: 1.4788\r\n",
      "Train Epoch: 29 [66560/110534 (60%)]\tClassification Loss: 1.3782\r\n",
      "Train Epoch: 29 [67200/110534 (61%)]\tClassification Loss: 1.3506\r\n",
      "Train Epoch: 29 [67840/110534 (61%)]\tClassification Loss: 1.9470\r\n",
      "Train Epoch: 29 [68480/110534 (62%)]\tClassification Loss: 1.6331\r\n",
      "Train Epoch: 29 [69120/110534 (63%)]\tClassification Loss: 1.7421\r\n",
      "Train Epoch: 29 [69760/110534 (63%)]\tClassification Loss: 1.6411\r\n",
      "Train Epoch: 29 [70400/110534 (64%)]\tClassification Loss: 1.2523\r\n",
      "Train Epoch: 29 [71040/110534 (64%)]\tClassification Loss: 1.8157\r\n",
      "Train Epoch: 29 [71680/110534 (65%)]\tClassification Loss: 1.4671\r\n",
      "Train Epoch: 29 [72320/110534 (65%)]\tClassification Loss: 1.6321\r\n",
      "Train Epoch: 29 [72960/110534 (66%)]\tClassification Loss: 1.7460\r\n",
      "Train Epoch: 29 [73600/110534 (67%)]\tClassification Loss: 1.7818\r\n",
      "Train Epoch: 29 [74240/110534 (67%)]\tClassification Loss: 1.7396\r\n",
      "Train Epoch: 29 [74880/110534 (68%)]\tClassification Loss: 1.1555\r\n",
      "Train Epoch: 29 [75520/110534 (68%)]\tClassification Loss: 1.4468\r\n",
      "Train Epoch: 29 [76160/110534 (69%)]\tClassification Loss: 1.4931\r\n",
      "Train Epoch: 29 [76800/110534 (69%)]\tClassification Loss: 1.3450\r\n",
      "Train Epoch: 29 [77440/110534 (70%)]\tClassification Loss: 1.3586\r\n",
      "Train Epoch: 29 [78080/110534 (71%)]\tClassification Loss: 1.4239\r\n",
      "Train Epoch: 29 [78720/110534 (71%)]\tClassification Loss: 1.4877\r\n",
      "Train Epoch: 29 [79360/110534 (72%)]\tClassification Loss: 1.3133\r\n",
      "Train Epoch: 29 [80000/110534 (72%)]\tClassification Loss: 1.3249\r\n",
      "Train Epoch: 29 [80640/110534 (73%)]\tClassification Loss: 1.3511\r\n",
      "Train Epoch: 29 [81280/110534 (74%)]\tClassification Loss: 1.6826\r\n",
      "Train Epoch: 29 [81920/110534 (74%)]\tClassification Loss: 1.5091\r\n",
      "Train Epoch: 29 [82560/110534 (75%)]\tClassification Loss: 1.7106\r\n",
      "Train Epoch: 29 [83200/110534 (75%)]\tClassification Loss: 1.3473\r\n",
      "Train Epoch: 29 [83840/110534 (76%)]\tClassification Loss: 1.7974\r\n",
      "Train Epoch: 29 [84480/110534 (76%)]\tClassification Loss: 1.8473\r\n",
      "Train Epoch: 29 [85120/110534 (77%)]\tClassification Loss: 1.5019\r\n",
      "Train Epoch: 29 [85760/110534 (78%)]\tClassification Loss: 1.4579\r\n",
      "Train Epoch: 29 [86400/110534 (78%)]\tClassification Loss: 1.4749\r\n",
      "Train Epoch: 29 [87040/110534 (79%)]\tClassification Loss: 1.6248\r\n",
      "Train Epoch: 29 [87680/110534 (79%)]\tClassification Loss: 1.4548\r\n",
      "Train Epoch: 29 [88320/110534 (80%)]\tClassification Loss: 1.4258\r\n",
      "Train Epoch: 29 [88960/110534 (80%)]\tClassification Loss: 1.7845\r\n",
      "Train Epoch: 29 [89600/110534 (81%)]\tClassification Loss: 1.7118\r\n",
      "Train Epoch: 29 [90240/110534 (82%)]\tClassification Loss: 1.7712\r\n",
      "Train Epoch: 29 [90880/110534 (82%)]\tClassification Loss: 1.5340\r\n",
      "Train Epoch: 29 [91520/110534 (83%)]\tClassification Loss: 1.2121\r\n",
      "Train Epoch: 29 [92160/110534 (83%)]\tClassification Loss: 1.3315\r\n",
      "Train Epoch: 29 [92800/110534 (84%)]\tClassification Loss: 1.2759\r\n",
      "Train Epoch: 29 [93440/110534 (85%)]\tClassification Loss: 1.6647\r\n",
      "Train Epoch: 29 [94080/110534 (85%)]\tClassification Loss: 1.6135\r\n",
      "Train Epoch: 29 [94720/110534 (86%)]\tClassification Loss: 1.2455\r\n",
      "Train Epoch: 29 [95360/110534 (86%)]\tClassification Loss: 1.3179\r\n",
      "Train Epoch: 29 [96000/110534 (87%)]\tClassification Loss: 1.3615\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_29_1500.pth.tar\r\n",
      "Train Epoch: 29 [96640/110534 (87%)]\tClassification Loss: 1.3740\r\n",
      "Train Epoch: 29 [97280/110534 (88%)]\tClassification Loss: 1.3037\r\n",
      "Train Epoch: 29 [97920/110534 (89%)]\tClassification Loss: 1.2760\r\n",
      "Train Epoch: 29 [98560/110534 (89%)]\tClassification Loss: 1.4313\r\n",
      "Train Epoch: 29 [99200/110534 (90%)]\tClassification Loss: 1.6666\r\n",
      "Train Epoch: 29 [99840/110534 (90%)]\tClassification Loss: 1.5192\r\n",
      "Train Epoch: 29 [100480/110534 (91%)]\tClassification Loss: 1.5672\r\n",
      "Train Epoch: 29 [101120/110534 (91%)]\tClassification Loss: 1.5358\r\n",
      "Train Epoch: 29 [101760/110534 (92%)]\tClassification Loss: 1.6555\r\n",
      "Train Epoch: 29 [102400/110534 (93%)]\tClassification Loss: 1.2912\r\n",
      "Train Epoch: 29 [103040/110534 (93%)]\tClassification Loss: 1.4236\r\n",
      "Train Epoch: 29 [103680/110534 (94%)]\tClassification Loss: 1.6353\r\n",
      "Train Epoch: 29 [104320/110534 (94%)]\tClassification Loss: 1.4075\r\n",
      "Train Epoch: 29 [104960/110534 (95%)]\tClassification Loss: 1.6373\r\n",
      "Train Epoch: 29 [105600/110534 (96%)]\tClassification Loss: 1.4398\r\n",
      "Train Epoch: 29 [106240/110534 (96%)]\tClassification Loss: 1.2650\r\n",
      "Train Epoch: 29 [106880/110534 (97%)]\tClassification Loss: 1.6824\r\n",
      "Train Epoch: 29 [107520/110534 (97%)]\tClassification Loss: 1.6732\r\n",
      "Train Epoch: 29 [108160/110534 (98%)]\tClassification Loss: 1.4290\r\n",
      "Train Epoch: 29 [108800/110534 (98%)]\tClassification Loss: 1.6188\r\n",
      "Train Epoch: 29 [109440/110534 (99%)]\tClassification Loss: 1.4569\r\n",
      "Train Epoch: 29 [110080/110534 (100%)]\tClassification Loss: 1.4236\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_29_final.pth.tar\r\n",
      "Train Epoch: 30 [0/110534 (0%)]\tClassification Loss: 1.5501\r\n",
      "\r\n",
      "Test set: Average loss: 1.4252, Accuracy: 22934/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 30 [640/110534 (1%)]\tClassification Loss: 1.3201\r\n",
      "Train Epoch: 30 [1280/110534 (1%)]\tClassification Loss: 1.9963\r\n",
      "Train Epoch: 30 [1920/110534 (2%)]\tClassification Loss: 1.4632\r\n",
      "Train Epoch: 30 [2560/110534 (2%)]\tClassification Loss: 1.5956\r\n",
      "Train Epoch: 30 [3200/110534 (3%)]\tClassification Loss: 1.4045\r\n",
      "Train Epoch: 30 [3840/110534 (3%)]\tClassification Loss: 1.3318\r\n",
      "Train Epoch: 30 [4480/110534 (4%)]\tClassification Loss: 1.6230\r\n",
      "Train Epoch: 30 [5120/110534 (5%)]\tClassification Loss: 1.5308\r\n",
      "Train Epoch: 30 [5760/110534 (5%)]\tClassification Loss: 1.5696\r\n",
      "Train Epoch: 30 [6400/110534 (6%)]\tClassification Loss: 1.3214\r\n",
      "Train Epoch: 30 [7040/110534 (6%)]\tClassification Loss: 1.3621\r\n",
      "Train Epoch: 30 [7680/110534 (7%)]\tClassification Loss: 1.4602\r\n",
      "Train Epoch: 30 [8320/110534 (8%)]\tClassification Loss: 1.7652\r\n",
      "Train Epoch: 30 [8960/110534 (8%)]\tClassification Loss: 1.6874\r\n",
      "Train Epoch: 30 [9600/110534 (9%)]\tClassification Loss: 1.4584\r\n",
      "Train Epoch: 30 [10240/110534 (9%)]\tClassification Loss: 1.5051\r\n",
      "Train Epoch: 30 [10880/110534 (10%)]\tClassification Loss: 1.5645\r\n",
      "Train Epoch: 30 [11520/110534 (10%)]\tClassification Loss: 1.5817\r\n",
      "Train Epoch: 30 [12160/110534 (11%)]\tClassification Loss: 1.4005\r\n",
      "Train Epoch: 30 [12800/110534 (12%)]\tClassification Loss: 1.5498\r\n",
      "Train Epoch: 30 [13440/110534 (12%)]\tClassification Loss: 1.4836\r\n",
      "Train Epoch: 30 [14080/110534 (13%)]\tClassification Loss: 1.4547\r\n",
      "Train Epoch: 30 [14720/110534 (13%)]\tClassification Loss: 1.7067\r\n",
      "Train Epoch: 30 [15360/110534 (14%)]\tClassification Loss: 1.6104\r\n",
      "Train Epoch: 30 [16000/110534 (14%)]\tClassification Loss: 1.5951\r\n",
      "Train Epoch: 30 [16640/110534 (15%)]\tClassification Loss: 1.3699\r\n",
      "Train Epoch: 30 [17280/110534 (16%)]\tClassification Loss: 1.6418\r\n",
      "Train Epoch: 30 [17920/110534 (16%)]\tClassification Loss: 1.5246\r\n",
      "Train Epoch: 30 [18560/110534 (17%)]\tClassification Loss: 1.7231\r\n",
      "Train Epoch: 30 [19200/110534 (17%)]\tClassification Loss: 1.6011\r\n",
      "Train Epoch: 30 [19840/110534 (18%)]\tClassification Loss: 1.4657\r\n",
      "Train Epoch: 30 [20480/110534 (19%)]\tClassification Loss: 1.8645\r\n",
      "Train Epoch: 30 [21120/110534 (19%)]\tClassification Loss: 1.7700\r\n",
      "Train Epoch: 30 [21760/110534 (20%)]\tClassification Loss: 1.4485\r\n",
      "Train Epoch: 30 [22400/110534 (20%)]\tClassification Loss: 1.5109\r\n",
      "Train Epoch: 30 [23040/110534 (21%)]\tClassification Loss: 1.1737\r\n",
      "Train Epoch: 30 [23680/110534 (21%)]\tClassification Loss: 1.6525\r\n",
      "Train Epoch: 30 [24320/110534 (22%)]\tClassification Loss: 1.2023\r\n",
      "Train Epoch: 30 [24960/110534 (23%)]\tClassification Loss: 1.6887\r\n",
      "Train Epoch: 30 [25600/110534 (23%)]\tClassification Loss: 1.3373\r\n",
      "Train Epoch: 30 [26240/110534 (24%)]\tClassification Loss: 1.5375\r\n",
      "Train Epoch: 30 [26880/110534 (24%)]\tClassification Loss: 1.7510\r\n",
      "Train Epoch: 30 [27520/110534 (25%)]\tClassification Loss: 1.3576\r\n",
      "Train Epoch: 30 [28160/110534 (25%)]\tClassification Loss: 1.7440\r\n",
      "Train Epoch: 30 [28800/110534 (26%)]\tClassification Loss: 1.7205\r\n",
      "Train Epoch: 30 [29440/110534 (27%)]\tClassification Loss: 1.6155\r\n",
      "Train Epoch: 30 [30080/110534 (27%)]\tClassification Loss: 1.7927\r\n",
      "Train Epoch: 30 [30720/110534 (28%)]\tClassification Loss: 1.3693\r\n",
      "Train Epoch: 30 [31360/110534 (28%)]\tClassification Loss: 1.7497\r\n",
      "Train Epoch: 30 [32000/110534 (29%)]\tClassification Loss: 1.4899\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_30_500.pth.tar\r\n",
      "Train Epoch: 30 [32640/110534 (30%)]\tClassification Loss: 1.4319\r\n",
      "Train Epoch: 30 [33280/110534 (30%)]\tClassification Loss: 1.4138\r\n",
      "Train Epoch: 30 [33920/110534 (31%)]\tClassification Loss: 1.7572\r\n",
      "Train Epoch: 30 [34560/110534 (31%)]\tClassification Loss: 1.7809\r\n",
      "Train Epoch: 30 [35200/110534 (32%)]\tClassification Loss: 1.4533\r\n",
      "Train Epoch: 30 [35840/110534 (32%)]\tClassification Loss: 1.2815\r\n",
      "Train Epoch: 30 [36480/110534 (33%)]\tClassification Loss: 1.3614\r\n",
      "Train Epoch: 30 [37120/110534 (34%)]\tClassification Loss: 1.5467\r\n",
      "Train Epoch: 30 [37760/110534 (34%)]\tClassification Loss: 1.8614\r\n",
      "Train Epoch: 30 [38400/110534 (35%)]\tClassification Loss: 1.4456\r\n",
      "Train Epoch: 30 [39040/110534 (35%)]\tClassification Loss: 1.5312\r\n",
      "Train Epoch: 30 [39680/110534 (36%)]\tClassification Loss: 1.5756\r\n",
      "Train Epoch: 30 [40320/110534 (36%)]\tClassification Loss: 1.5368\r\n",
      "Train Epoch: 30 [40960/110534 (37%)]\tClassification Loss: 1.3095\r\n",
      "Train Epoch: 30 [41600/110534 (38%)]\tClassification Loss: 1.4325\r\n",
      "Train Epoch: 30 [42240/110534 (38%)]\tClassification Loss: 1.4868\r\n",
      "Train Epoch: 30 [42880/110534 (39%)]\tClassification Loss: 1.4887\r\n",
      "Train Epoch: 30 [43520/110534 (39%)]\tClassification Loss: 1.2837\r\n",
      "Train Epoch: 30 [44160/110534 (40%)]\tClassification Loss: 1.4515\r\n",
      "Train Epoch: 30 [44800/110534 (41%)]\tClassification Loss: 1.6372\r\n",
      "Train Epoch: 30 [45440/110534 (41%)]\tClassification Loss: 1.5842\r\n",
      "Train Epoch: 30 [46080/110534 (42%)]\tClassification Loss: 1.4231\r\n",
      "Train Epoch: 30 [46720/110534 (42%)]\tClassification Loss: 1.5014\r\n",
      "Train Epoch: 30 [47360/110534 (43%)]\tClassification Loss: 1.4564\r\n",
      "Train Epoch: 30 [48000/110534 (43%)]\tClassification Loss: 1.5758\r\n",
      "Train Epoch: 30 [48640/110534 (44%)]\tClassification Loss: 1.3839\r\n",
      "Train Epoch: 30 [49280/110534 (45%)]\tClassification Loss: 1.5336\r\n",
      "Train Epoch: 30 [49920/110534 (45%)]\tClassification Loss: 1.5724\r\n",
      "Train Epoch: 30 [50560/110534 (46%)]\tClassification Loss: 1.5367\r\n",
      "Train Epoch: 30 [51200/110534 (46%)]\tClassification Loss: 1.2372\r\n",
      "Train Epoch: 30 [51840/110534 (47%)]\tClassification Loss: 1.4096\r\n",
      "Train Epoch: 30 [52480/110534 (47%)]\tClassification Loss: 1.4192\r\n",
      "Train Epoch: 30 [53120/110534 (48%)]\tClassification Loss: 1.1764\r\n",
      "Train Epoch: 30 [53760/110534 (49%)]\tClassification Loss: 1.3685\r\n",
      "Train Epoch: 30 [54400/110534 (49%)]\tClassification Loss: 1.6184\r\n",
      "Train Epoch: 30 [55040/110534 (50%)]\tClassification Loss: 1.8515\r\n",
      "Train Epoch: 30 [55680/110534 (50%)]\tClassification Loss: 1.6895\r\n",
      "Train Epoch: 30 [56320/110534 (51%)]\tClassification Loss: 1.4340\r\n",
      "Train Epoch: 30 [56960/110534 (52%)]\tClassification Loss: 1.5749\r\n",
      "Train Epoch: 30 [57600/110534 (52%)]\tClassification Loss: 1.6629\r\n",
      "Train Epoch: 30 [58240/110534 (53%)]\tClassification Loss: 1.5558\r\n",
      "Train Epoch: 30 [58880/110534 (53%)]\tClassification Loss: 1.8179\r\n",
      "Train Epoch: 30 [59520/110534 (54%)]\tClassification Loss: 1.2762\r\n",
      "Train Epoch: 30 [60160/110534 (54%)]\tClassification Loss: 1.4324\r\n",
      "Train Epoch: 30 [60800/110534 (55%)]\tClassification Loss: 1.5736\r\n",
      "Train Epoch: 30 [61440/110534 (56%)]\tClassification Loss: 1.6330\r\n",
      "Train Epoch: 30 [62080/110534 (56%)]\tClassification Loss: 1.4841\r\n",
      "Train Epoch: 30 [62720/110534 (57%)]\tClassification Loss: 1.6179\r\n",
      "Train Epoch: 30 [63360/110534 (57%)]\tClassification Loss: 1.3799\r\n",
      "Train Epoch: 30 [64000/110534 (58%)]\tClassification Loss: 1.7150\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_30_1000.pth.tar\r\n",
      "Train Epoch: 30 [64640/110534 (58%)]\tClassification Loss: 1.3829\r\n",
      "Train Epoch: 30 [65280/110534 (59%)]\tClassification Loss: 1.4801\r\n",
      "Train Epoch: 30 [65920/110534 (60%)]\tClassification Loss: 1.7079\r\n",
      "Train Epoch: 30 [66560/110534 (60%)]\tClassification Loss: 1.1528\r\n",
      "Train Epoch: 30 [67200/110534 (61%)]\tClassification Loss: 1.1950\r\n",
      "Train Epoch: 30 [67840/110534 (61%)]\tClassification Loss: 2.1274\r\n",
      "Train Epoch: 30 [68480/110534 (62%)]\tClassification Loss: 1.5697\r\n",
      "Train Epoch: 30 [69120/110534 (63%)]\tClassification Loss: 1.7258\r\n",
      "Train Epoch: 30 [69760/110534 (63%)]\tClassification Loss: 1.5847\r\n",
      "Train Epoch: 30 [70400/110534 (64%)]\tClassification Loss: 1.1853\r\n",
      "Train Epoch: 30 [71040/110534 (64%)]\tClassification Loss: 1.8598\r\n",
      "Train Epoch: 30 [71680/110534 (65%)]\tClassification Loss: 1.4468\r\n",
      "Train Epoch: 30 [72320/110534 (65%)]\tClassification Loss: 1.4624\r\n",
      "Train Epoch: 30 [72960/110534 (66%)]\tClassification Loss: 1.7113\r\n",
      "Train Epoch: 30 [73600/110534 (67%)]\tClassification Loss: 1.7380\r\n",
      "Train Epoch: 30 [74240/110534 (67%)]\tClassification Loss: 1.6347\r\n",
      "Train Epoch: 30 [74880/110534 (68%)]\tClassification Loss: 1.2929\r\n",
      "Train Epoch: 30 [75520/110534 (68%)]\tClassification Loss: 1.4846\r\n",
      "Train Epoch: 30 [76160/110534 (69%)]\tClassification Loss: 1.3883\r\n",
      "Train Epoch: 30 [76800/110534 (69%)]\tClassification Loss: 1.2183\r\n",
      "Train Epoch: 30 [77440/110534 (70%)]\tClassification Loss: 1.4805\r\n",
      "Train Epoch: 30 [78080/110534 (71%)]\tClassification Loss: 1.5598\r\n",
      "Train Epoch: 30 [78720/110534 (71%)]\tClassification Loss: 1.4065\r\n",
      "Train Epoch: 30 [79360/110534 (72%)]\tClassification Loss: 1.3246\r\n",
      "Train Epoch: 30 [80000/110534 (72%)]\tClassification Loss: 1.3093\r\n",
      "Train Epoch: 30 [80640/110534 (73%)]\tClassification Loss: 1.3772\r\n",
      "Train Epoch: 30 [81280/110534 (74%)]\tClassification Loss: 1.8499\r\n",
      "Train Epoch: 30 [81920/110534 (74%)]\tClassification Loss: 1.4592\r\n",
      "Train Epoch: 30 [82560/110534 (75%)]\tClassification Loss: 1.7483\r\n",
      "Train Epoch: 30 [83200/110534 (75%)]\tClassification Loss: 1.5974\r\n",
      "Train Epoch: 30 [83840/110534 (76%)]\tClassification Loss: 1.7818\r\n",
      "Train Epoch: 30 [84480/110534 (76%)]\tClassification Loss: 1.8120\r\n",
      "Train Epoch: 30 [85120/110534 (77%)]\tClassification Loss: 1.4448\r\n",
      "Train Epoch: 30 [85760/110534 (78%)]\tClassification Loss: 1.5389\r\n",
      "Train Epoch: 30 [86400/110534 (78%)]\tClassification Loss: 1.5067\r\n",
      "Train Epoch: 30 [87040/110534 (79%)]\tClassification Loss: 1.4631\r\n",
      "Train Epoch: 30 [87680/110534 (79%)]\tClassification Loss: 1.4999\r\n",
      "Train Epoch: 30 [88320/110534 (80%)]\tClassification Loss: 1.4540\r\n",
      "Train Epoch: 30 [88960/110534 (80%)]\tClassification Loss: 1.8317\r\n",
      "Train Epoch: 30 [89600/110534 (81%)]\tClassification Loss: 1.7353\r\n",
      "Train Epoch: 30 [90240/110534 (82%)]\tClassification Loss: 1.7329\r\n",
      "Train Epoch: 30 [90880/110534 (82%)]\tClassification Loss: 1.7126\r\n",
      "Train Epoch: 30 [91520/110534 (83%)]\tClassification Loss: 1.2850\r\n",
      "Train Epoch: 30 [92160/110534 (83%)]\tClassification Loss: 1.3316\r\n",
      "Train Epoch: 30 [92800/110534 (84%)]\tClassification Loss: 1.4835\r\n",
      "Train Epoch: 30 [93440/110534 (85%)]\tClassification Loss: 1.5240\r\n",
      "Train Epoch: 30 [94080/110534 (85%)]\tClassification Loss: 1.5337\r\n",
      "Train Epoch: 30 [94720/110534 (86%)]\tClassification Loss: 1.2839\r\n",
      "Train Epoch: 30 [95360/110534 (86%)]\tClassification Loss: 1.3782\r\n",
      "Train Epoch: 30 [96000/110534 (87%)]\tClassification Loss: 1.4189\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_30_1500.pth.tar\r\n",
      "Train Epoch: 30 [96640/110534 (87%)]\tClassification Loss: 1.3685\r\n",
      "Train Epoch: 30 [97280/110534 (88%)]\tClassification Loss: 1.2975\r\n",
      "Train Epoch: 30 [97920/110534 (89%)]\tClassification Loss: 1.2189\r\n",
      "Train Epoch: 30 [98560/110534 (89%)]\tClassification Loss: 1.5445\r\n",
      "Train Epoch: 30 [99200/110534 (90%)]\tClassification Loss: 1.5571\r\n",
      "Train Epoch: 30 [99840/110534 (90%)]\tClassification Loss: 1.5946\r\n",
      "Train Epoch: 30 [100480/110534 (91%)]\tClassification Loss: 1.7040\r\n",
      "Train Epoch: 30 [101120/110534 (91%)]\tClassification Loss: 1.5845\r\n",
      "Train Epoch: 30 [101760/110534 (92%)]\tClassification Loss: 1.6649\r\n",
      "Train Epoch: 30 [102400/110534 (93%)]\tClassification Loss: 1.4933\r\n",
      "Train Epoch: 30 [103040/110534 (93%)]\tClassification Loss: 1.5604\r\n",
      "Train Epoch: 30 [103680/110534 (94%)]\tClassification Loss: 1.6788\r\n",
      "Train Epoch: 30 [104320/110534 (94%)]\tClassification Loss: 1.3029\r\n",
      "Train Epoch: 30 [104960/110534 (95%)]\tClassification Loss: 1.4769\r\n",
      "Train Epoch: 30 [105600/110534 (96%)]\tClassification Loss: 1.5519\r\n",
      "Train Epoch: 30 [106240/110534 (96%)]\tClassification Loss: 1.2629\r\n",
      "Train Epoch: 30 [106880/110534 (97%)]\tClassification Loss: 1.5935\r\n",
      "Train Epoch: 30 [107520/110534 (97%)]\tClassification Loss: 1.6496\r\n",
      "Train Epoch: 30 [108160/110534 (98%)]\tClassification Loss: 1.4055\r\n",
      "Train Epoch: 30 [108800/110534 (98%)]\tClassification Loss: 1.7341\r\n",
      "Train Epoch: 30 [109440/110534 (99%)]\tClassification Loss: 1.5152\r\n",
      "Train Epoch: 30 [110080/110534 (100%)]\tClassification Loss: 1.4242\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_30_final.pth.tar\r\n"
     ]
    }
   ],
   "source": [
    "# FREEZE = False. LR=0.003. in-shop=False. 30 epochs\n",
    "! python train.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Train Epoch: 1 [0/110534 (0%)]\tClassification Loss: 3.2574\r\n",
      "train.py:172: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 3.2369, Accuracy: 587/42368 (1%)\r\n",
      "\r\n",
      "Train Epoch: 1 [1920/110534 (2%)]\tClassification Loss: 2.7135\r\n",
      "Train Epoch: 1 [3840/110534 (3%)]\tClassification Loss: 2.5495\r\n",
      "Train Epoch: 1 [5760/110534 (5%)]\tClassification Loss: 2.6430\r\n",
      "Train Epoch: 1 [7680/110534 (7%)]\tClassification Loss: 2.4120\r\n",
      "Train Epoch: 1 [9600/110534 (9%)]\tClassification Loss: 2.3391\r\n",
      "Train Epoch: 1 [11520/110534 (10%)]\tClassification Loss: 2.3827\r\n",
      "Train Epoch: 1 [13440/110534 (12%)]\tClassification Loss: 2.4087\r\n",
      "Train Epoch: 1 [15360/110534 (14%)]\tClassification Loss: 2.3085\r\n",
      "Train Epoch: 1 [17280/110534 (16%)]\tClassification Loss: 2.3360\r\n",
      "Train Epoch: 1 [19200/110534 (17%)]\tClassification Loss: 2.2704\r\n",
      "Train Epoch: 1 [21120/110534 (19%)]\tClassification Loss: 2.3272\r\n",
      "Train Epoch: 1 [23040/110534 (21%)]\tClassification Loss: 2.0667\r\n",
      "Train Epoch: 1 [24960/110534 (23%)]\tClassification Loss: 2.2104\r\n",
      "Train Epoch: 1 [26880/110534 (24%)]\tClassification Loss: 2.2172\r\n",
      "Train Epoch: 1 [28800/110534 (26%)]\tClassification Loss: 2.3362\r\n",
      "Train Epoch: 1 [30720/110534 (28%)]\tClassification Loss: 2.2286\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_500.pth.tar\r\n",
      "Train Epoch: 1 [32640/110534 (30%)]\tClassification Loss: 1.7893\r\n",
      "Train Epoch: 1 [34560/110534 (31%)]\tClassification Loss: 1.8705\r\n",
      "Train Epoch: 1 [36480/110534 (33%)]\tClassification Loss: 1.7958\r\n",
      "Train Epoch: 1 [38400/110534 (35%)]\tClassification Loss: 2.1396\r\n",
      "Train Epoch: 1 [40320/110534 (36%)]\tClassification Loss: 2.0229\r\n",
      "Train Epoch: 1 [42240/110534 (38%)]\tClassification Loss: 2.0080\r\n",
      "Train Epoch: 1 [44160/110534 (40%)]\tClassification Loss: 1.9624\r\n",
      "Train Epoch: 1 [46080/110534 (42%)]\tClassification Loss: 2.1007\r\n",
      "Train Epoch: 1 [48000/110534 (43%)]\tClassification Loss: 2.1294\r\n",
      "Train Epoch: 1 [49920/110534 (45%)]\tClassification Loss: 2.0765\r\n",
      "Train Epoch: 1 [51840/110534 (47%)]\tClassification Loss: 2.2344\r\n",
      "Train Epoch: 1 [53760/110534 (49%)]\tClassification Loss: 1.8529\r\n",
      "Train Epoch: 1 [55680/110534 (50%)]\tClassification Loss: 1.8122\r\n",
      "Train Epoch: 1 [57600/110534 (52%)]\tClassification Loss: 2.0477\r\n",
      "Train Epoch: 1 [59520/110534 (54%)]\tClassification Loss: 1.9866\r\n",
      "Train Epoch: 1 [61440/110534 (56%)]\tClassification Loss: 1.8276\r\n",
      "Train Epoch: 1 [63360/110534 (57%)]\tClassification Loss: 2.0709\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1000.pth.tar\r\n",
      "Train Epoch: 1 [65280/110534 (59%)]\tClassification Loss: 1.9061\r\n",
      "Train Epoch: 1 [67200/110534 (61%)]\tClassification Loss: 1.7554\r\n",
      "Train Epoch: 1 [69120/110534 (63%)]\tClassification Loss: 1.8559\r\n",
      "Train Epoch: 1 [71040/110534 (64%)]\tClassification Loss: 1.7782\r\n",
      "Train Epoch: 1 [72960/110534 (66%)]\tClassification Loss: 1.7498\r\n",
      "Train Epoch: 1 [74880/110534 (68%)]\tClassification Loss: 1.6683\r\n",
      "Train Epoch: 1 [76800/110534 (69%)]\tClassification Loss: 1.6660\r\n",
      "Train Epoch: 1 [78720/110534 (71%)]\tClassification Loss: 1.8147\r\n",
      "Train Epoch: 1 [80640/110534 (73%)]\tClassification Loss: 1.8789\r\n",
      "Train Epoch: 1 [82560/110534 (75%)]\tClassification Loss: 1.6688\r\n",
      "Train Epoch: 1 [84480/110534 (76%)]\tClassification Loss: 1.6579\r\n",
      "Train Epoch: 1 [86400/110534 (78%)]\tClassification Loss: 1.8037\r\n",
      "Train Epoch: 1 [88320/110534 (80%)]\tClassification Loss: 1.9795\r\n",
      "Train Epoch: 1 [90240/110534 (82%)]\tClassification Loss: 2.0085\r\n",
      "Train Epoch: 1 [92160/110534 (83%)]\tClassification Loss: 1.9744\r\n",
      "Train Epoch: 1 [94080/110534 (85%)]\tClassification Loss: 1.8853\r\n",
      "Train Epoch: 1 [96000/110534 (87%)]\tClassification Loss: 1.9320\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1500.pth.tar\r\n",
      "Train Epoch: 1 [97920/110534 (89%)]\tClassification Loss: 1.7821\r\n",
      "Train Epoch: 1 [99840/110534 (90%)]\tClassification Loss: 2.0308\r\n",
      "Train Epoch: 1 [101760/110534 (92%)]\tClassification Loss: 1.7555\r\n",
      "Train Epoch: 1 [103680/110534 (94%)]\tClassification Loss: 1.8541\r\n",
      "Train Epoch: 1 [105600/110534 (96%)]\tClassification Loss: 1.8268\r\n",
      "Train Epoch: 1 [107520/110534 (97%)]\tClassification Loss: 1.7398\r\n",
      "Train Epoch: 1 [109440/110534 (99%)]\tClassification Loss: 1.8591\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_final.pth.tar\r\n",
      "Train Epoch: 2 [0/110534 (0%)]\tClassification Loss: 2.0089\r\n",
      "\r\n",
      "Test set: Average loss: 1.6983, Accuracy: 20827/42368 (49%)\r\n",
      "\r\n",
      "Train Epoch: 2 [1920/110534 (2%)]\tClassification Loss: 1.7425\r\n",
      "Train Epoch: 2 [3840/110534 (3%)]\tClassification Loss: 1.8795\r\n",
      "Train Epoch: 2 [5760/110534 (5%)]\tClassification Loss: 1.9725\r\n",
      "Train Epoch: 2 [7680/110534 (7%)]\tClassification Loss: 1.6574\r\n",
      "Train Epoch: 2 [9600/110534 (9%)]\tClassification Loss: 1.7991\r\n",
      "Train Epoch: 2 [11520/110534 (10%)]\tClassification Loss: 1.8117\r\n",
      "Train Epoch: 2 [13440/110534 (12%)]\tClassification Loss: 1.7238\r\n",
      "Train Epoch: 2 [15360/110534 (14%)]\tClassification Loss: 1.9071\r\n",
      "Train Epoch: 2 [17280/110534 (16%)]\tClassification Loss: 1.8593\r\n",
      "Train Epoch: 2 [19200/110534 (17%)]\tClassification Loss: 1.9115\r\n",
      "Train Epoch: 2 [21120/110534 (19%)]\tClassification Loss: 1.8727\r\n",
      "Train Epoch: 2 [23040/110534 (21%)]\tClassification Loss: 1.7022\r\n",
      "Train Epoch: 2 [24960/110534 (23%)]\tClassification Loss: 1.9054\r\n",
      "Train Epoch: 2 [26880/110534 (24%)]\tClassification Loss: 1.7970\r\n",
      "Train Epoch: 2 [28800/110534 (26%)]\tClassification Loss: 2.0521\r\n",
      "Train Epoch: 2 [30720/110534 (28%)]\tClassification Loss: 1.8467\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_500.pth.tar\r\n",
      "Train Epoch: 2 [32640/110534 (30%)]\tClassification Loss: 1.6296\r\n",
      "Train Epoch: 2 [34560/110534 (31%)]\tClassification Loss: 1.7080\r\n",
      "Train Epoch: 2 [36480/110534 (33%)]\tClassification Loss: 1.5081\r\n",
      "Train Epoch: 2 [38400/110534 (35%)]\tClassification Loss: 1.7417\r\n",
      "Train Epoch: 2 [40320/110534 (36%)]\tClassification Loss: 1.6071\r\n",
      "Train Epoch: 2 [42240/110534 (38%)]\tClassification Loss: 1.7030\r\n",
      "Train Epoch: 2 [44160/110534 (40%)]\tClassification Loss: 1.5465\r\n",
      "Train Epoch: 2 [46080/110534 (42%)]\tClassification Loss: 1.7607\r\n",
      "Train Epoch: 2 [48000/110534 (43%)]\tClassification Loss: 1.8120\r\n",
      "Train Epoch: 2 [49920/110534 (45%)]\tClassification Loss: 1.8107\r\n",
      "Train Epoch: 2 [51840/110534 (47%)]\tClassification Loss: 1.9696\r\n",
      "Train Epoch: 2 [53760/110534 (49%)]\tClassification Loss: 1.7709\r\n",
      "Train Epoch: 2 [55680/110534 (50%)]\tClassification Loss: 1.6108\r\n",
      "Train Epoch: 2 [57600/110534 (52%)]\tClassification Loss: 1.8019\r\n",
      "Train Epoch: 2 [59520/110534 (54%)]\tClassification Loss: 1.8865\r\n",
      "Train Epoch: 2 [61440/110534 (56%)]\tClassification Loss: 1.7418\r\n",
      "Train Epoch: 2 [63360/110534 (57%)]\tClassification Loss: 1.8634\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1000.pth.tar\r\n",
      "Train Epoch: 2 [65280/110534 (59%)]\tClassification Loss: 1.7033\r\n",
      "Train Epoch: 2 [67200/110534 (61%)]\tClassification Loss: 1.5937\r\n",
      "Train Epoch: 2 [69120/110534 (63%)]\tClassification Loss: 1.5183\r\n",
      "Train Epoch: 2 [71040/110534 (64%)]\tClassification Loss: 1.5895\r\n",
      "Train Epoch: 2 [72960/110534 (66%)]\tClassification Loss: 1.5950\r\n",
      "Train Epoch: 2 [74880/110534 (68%)]\tClassification Loss: 1.3971\r\n",
      "Train Epoch: 2 [76800/110534 (69%)]\tClassification Loss: 1.6869\r\n",
      "Train Epoch: 2 [78720/110534 (71%)]\tClassification Loss: 1.6968\r\n",
      "Train Epoch: 2 [80640/110534 (73%)]\tClassification Loss: 1.7346\r\n",
      "Train Epoch: 2 [82560/110534 (75%)]\tClassification Loss: 1.5835\r\n",
      "Train Epoch: 2 [84480/110534 (76%)]\tClassification Loss: 1.5573\r\n",
      "Train Epoch: 2 [86400/110534 (78%)]\tClassification Loss: 1.6625\r\n",
      "Train Epoch: 2 [88320/110534 (80%)]\tClassification Loss: 1.9199\r\n",
      "Train Epoch: 2 [90240/110534 (82%)]\tClassification Loss: 1.7173\r\n",
      "Train Epoch: 2 [92160/110534 (83%)]\tClassification Loss: 1.7764\r\n",
      "Train Epoch: 2 [94080/110534 (85%)]\tClassification Loss: 1.8559\r\n",
      "Train Epoch: 2 [96000/110534 (87%)]\tClassification Loss: 1.8951\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1500.pth.tar\r\n",
      "Train Epoch: 2 [97920/110534 (89%)]\tClassification Loss: 1.6434\r\n",
      "Train Epoch: 2 [99840/110534 (90%)]\tClassification Loss: 1.9700\r\n",
      "Train Epoch: 2 [101760/110534 (92%)]\tClassification Loss: 1.6013\r\n",
      "Train Epoch: 2 [103680/110534 (94%)]\tClassification Loss: 1.8495\r\n",
      "Train Epoch: 2 [105600/110534 (96%)]\tClassification Loss: 1.6895\r\n",
      "Train Epoch: 2 [107520/110534 (97%)]\tClassification Loss: 1.6002\r\n",
      "Train Epoch: 2 [109440/110534 (99%)]\tClassification Loss: 1.7988\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_final.pth.tar\r\n",
      "Train Epoch: 3 [0/110534 (0%)]\tClassification Loss: 1.8507\r\n",
      "\r\n",
      "Test set: Average loss: 1.5878, Accuracy: 21574/42368 (51%)\r\n",
      "\r\n",
      "Train Epoch: 3 [1920/110534 (2%)]\tClassification Loss: 1.5460\r\n",
      "Train Epoch: 3 [3840/110534 (3%)]\tClassification Loss: 1.6610\r\n",
      "Train Epoch: 3 [5760/110534 (5%)]\tClassification Loss: 1.7913\r\n",
      "Train Epoch: 3 [7680/110534 (7%)]\tClassification Loss: 1.5827\r\n",
      "Train Epoch: 3 [9600/110534 (9%)]\tClassification Loss: 1.8094\r\n",
      "Train Epoch: 3 [11520/110534 (10%)]\tClassification Loss: 1.7262\r\n",
      "Train Epoch: 3 [13440/110534 (12%)]\tClassification Loss: 1.6378\r\n",
      "Train Epoch: 3 [15360/110534 (14%)]\tClassification Loss: 1.9471\r\n",
      "Train Epoch: 3 [17280/110534 (16%)]\tClassification Loss: 1.9474\r\n",
      "Train Epoch: 3 [19200/110534 (17%)]\tClassification Loss: 1.9702\r\n",
      "Train Epoch: 3 [21120/110534 (19%)]\tClassification Loss: 1.7683\r\n",
      "Train Epoch: 3 [23040/110534 (21%)]\tClassification Loss: 1.6599\r\n",
      "Train Epoch: 3 [24960/110534 (23%)]\tClassification Loss: 1.7177\r\n",
      "Train Epoch: 3 [26880/110534 (24%)]\tClassification Loss: 1.7655\r\n",
      "Train Epoch: 3 [28800/110534 (26%)]\tClassification Loss: 2.1163\r\n",
      "Train Epoch: 3 [30720/110534 (28%)]\tClassification Loss: 1.7610\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_500.pth.tar\r\n",
      "Train Epoch: 3 [32640/110534 (30%)]\tClassification Loss: 1.5603\r\n",
      "Train Epoch: 3 [34560/110534 (31%)]\tClassification Loss: 1.4326\r\n",
      "Train Epoch: 3 [36480/110534 (33%)]\tClassification Loss: 1.4935\r\n",
      "Train Epoch: 3 [38400/110534 (35%)]\tClassification Loss: 1.7081\r\n",
      "Train Epoch: 3 [40320/110534 (36%)]\tClassification Loss: 1.6313\r\n",
      "Train Epoch: 3 [42240/110534 (38%)]\tClassification Loss: 1.6682\r\n",
      "Train Epoch: 3 [44160/110534 (40%)]\tClassification Loss: 1.6016\r\n",
      "Train Epoch: 3 [46080/110534 (42%)]\tClassification Loss: 1.7387\r\n",
      "Train Epoch: 3 [48000/110534 (43%)]\tClassification Loss: 1.7153\r\n",
      "Train Epoch: 3 [49920/110534 (45%)]\tClassification Loss: 1.8567\r\n",
      "Train Epoch: 3 [51840/110534 (47%)]\tClassification Loss: 1.9414\r\n",
      "Train Epoch: 3 [53760/110534 (49%)]\tClassification Loss: 1.5392\r\n",
      "Train Epoch: 3 [55680/110534 (50%)]\tClassification Loss: 1.6115\r\n",
      "Train Epoch: 3 [57600/110534 (52%)]\tClassification Loss: 1.6686\r\n",
      "Train Epoch: 3 [59520/110534 (54%)]\tClassification Loss: 1.9132\r\n",
      "Train Epoch: 3 [61440/110534 (56%)]\tClassification Loss: 1.6305\r\n",
      "Train Epoch: 3 [63360/110534 (57%)]\tClassification Loss: 1.9191\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1000.pth.tar\r\n",
      "Train Epoch: 3 [65280/110534 (59%)]\tClassification Loss: 1.6090\r\n",
      "Train Epoch: 3 [67200/110534 (61%)]\tClassification Loss: 1.4927\r\n",
      "Train Epoch: 3 [69120/110534 (63%)]\tClassification Loss: 1.5015\r\n",
      "Train Epoch: 3 [71040/110534 (64%)]\tClassification Loss: 1.6087\r\n",
      "Train Epoch: 3 [72960/110534 (66%)]\tClassification Loss: 1.4771\r\n",
      "Train Epoch: 3 [74880/110534 (68%)]\tClassification Loss: 1.4339\r\n",
      "Train Epoch: 3 [76800/110534 (69%)]\tClassification Loss: 1.5245\r\n",
      "Train Epoch: 3 [78720/110534 (71%)]\tClassification Loss: 1.5584\r\n",
      "Train Epoch: 3 [80640/110534 (73%)]\tClassification Loss: 1.6665\r\n",
      "Train Epoch: 3 [82560/110534 (75%)]\tClassification Loss: 1.4420\r\n",
      "Train Epoch: 3 [84480/110534 (76%)]\tClassification Loss: 1.4501\r\n",
      "Train Epoch: 3 [86400/110534 (78%)]\tClassification Loss: 1.5497\r\n",
      "Train Epoch: 3 [88320/110534 (80%)]\tClassification Loss: 1.8845\r\n",
      "Train Epoch: 3 [90240/110534 (82%)]\tClassification Loss: 1.8214\r\n",
      "Train Epoch: 3 [92160/110534 (83%)]\tClassification Loss: 1.7950\r\n",
      "Train Epoch: 3 [94080/110534 (85%)]\tClassification Loss: 1.6506\r\n",
      "Train Epoch: 3 [96000/110534 (87%)]\tClassification Loss: 1.9763\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1500.pth.tar\r\n",
      "Train Epoch: 3 [97920/110534 (89%)]\tClassification Loss: 1.6520\r\n",
      "Train Epoch: 3 [99840/110534 (90%)]\tClassification Loss: 1.8456\r\n",
      "Train Epoch: 3 [101760/110534 (92%)]\tClassification Loss: 1.5447\r\n",
      "Train Epoch: 3 [103680/110534 (94%)]\tClassification Loss: 1.7445\r\n",
      "Train Epoch: 3 [105600/110534 (96%)]\tClassification Loss: 1.5818\r\n",
      "Train Epoch: 3 [107520/110534 (97%)]\tClassification Loss: 1.6405\r\n",
      "Train Epoch: 3 [109440/110534 (99%)]\tClassification Loss: 1.7046\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_final.pth.tar\r\n",
      "Train Epoch: 4 [0/110534 (0%)]\tClassification Loss: 1.7847\r\n",
      "\r\n",
      "Test set: Average loss: 1.5433, Accuracy: 22000/42368 (52%)\r\n",
      "\r\n",
      "Train Epoch: 4 [1920/110534 (2%)]\tClassification Loss: 1.6675\r\n",
      "Train Epoch: 4 [3840/110534 (3%)]\tClassification Loss: 1.6250\r\n",
      "Train Epoch: 4 [5760/110534 (5%)]\tClassification Loss: 1.8452\r\n",
      "Train Epoch: 4 [7680/110534 (7%)]\tClassification Loss: 1.6800\r\n",
      "Train Epoch: 4 [9600/110534 (9%)]\tClassification Loss: 1.7212\r\n",
      "Train Epoch: 4 [11520/110534 (10%)]\tClassification Loss: 1.8816\r\n",
      "Train Epoch: 4 [13440/110534 (12%)]\tClassification Loss: 1.6703\r\n",
      "Train Epoch: 4 [15360/110534 (14%)]\tClassification Loss: 1.9035\r\n",
      "Train Epoch: 4 [17280/110534 (16%)]\tClassification Loss: 1.7969\r\n",
      "Train Epoch: 4 [19200/110534 (17%)]\tClassification Loss: 1.9288\r\n",
      "Train Epoch: 4 [21120/110534 (19%)]\tClassification Loss: 1.6685\r\n",
      "Train Epoch: 4 [23040/110534 (21%)]\tClassification Loss: 1.5860\r\n",
      "Train Epoch: 4 [24960/110534 (23%)]\tClassification Loss: 1.6686\r\n",
      "Train Epoch: 4 [26880/110534 (24%)]\tClassification Loss: 1.7058\r\n",
      "Train Epoch: 4 [28800/110534 (26%)]\tClassification Loss: 1.9711\r\n",
      "Train Epoch: 4 [30720/110534 (28%)]\tClassification Loss: 1.5142\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_500.pth.tar\r\n",
      "Train Epoch: 4 [32640/110534 (30%)]\tClassification Loss: 1.6061\r\n",
      "Train Epoch: 4 [34560/110534 (31%)]\tClassification Loss: 1.3723\r\n",
      "Train Epoch: 4 [36480/110534 (33%)]\tClassification Loss: 1.3990\r\n",
      "Train Epoch: 4 [38400/110534 (35%)]\tClassification Loss: 1.6057\r\n",
      "Train Epoch: 4 [40320/110534 (36%)]\tClassification Loss: 1.5384\r\n",
      "Train Epoch: 4 [42240/110534 (38%)]\tClassification Loss: 1.6825\r\n",
      "Train Epoch: 4 [44160/110534 (40%)]\tClassification Loss: 1.5063\r\n",
      "Train Epoch: 4 [46080/110534 (42%)]\tClassification Loss: 1.6000\r\n",
      "Train Epoch: 4 [48000/110534 (43%)]\tClassification Loss: 1.7210\r\n",
      "Train Epoch: 4 [49920/110534 (45%)]\tClassification Loss: 1.7988\r\n",
      "Train Epoch: 4 [51840/110534 (47%)]\tClassification Loss: 1.9048\r\n",
      "Train Epoch: 4 [53760/110534 (49%)]\tClassification Loss: 1.5162\r\n",
      "Train Epoch: 4 [55680/110534 (50%)]\tClassification Loss: 1.5527\r\n",
      "Train Epoch: 4 [57600/110534 (52%)]\tClassification Loss: 1.5650\r\n",
      "Train Epoch: 4 [59520/110534 (54%)]\tClassification Loss: 2.0241\r\n",
      "Train Epoch: 4 [61440/110534 (56%)]\tClassification Loss: 1.6318\r\n",
      "Train Epoch: 4 [63360/110534 (57%)]\tClassification Loss: 1.9270\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1000.pth.tar\r\n",
      "Train Epoch: 4 [65280/110534 (59%)]\tClassification Loss: 1.6366\r\n",
      "Train Epoch: 4 [67200/110534 (61%)]\tClassification Loss: 1.3887\r\n",
      "Train Epoch: 4 [69120/110534 (63%)]\tClassification Loss: 1.5611\r\n",
      "Train Epoch: 4 [71040/110534 (64%)]\tClassification Loss: 1.5103\r\n",
      "Train Epoch: 4 [72960/110534 (66%)]\tClassification Loss: 1.4370\r\n",
      "Train Epoch: 4 [74880/110534 (68%)]\tClassification Loss: 1.3574\r\n",
      "Train Epoch: 4 [76800/110534 (69%)]\tClassification Loss: 1.4811\r\n",
      "Train Epoch: 4 [78720/110534 (71%)]\tClassification Loss: 1.5793\r\n",
      "Train Epoch: 4 [80640/110534 (73%)]\tClassification Loss: 1.6762\r\n",
      "Train Epoch: 4 [82560/110534 (75%)]\tClassification Loss: 1.4317\r\n",
      "Train Epoch: 4 [84480/110534 (76%)]\tClassification Loss: 1.4894\r\n",
      "Train Epoch: 4 [86400/110534 (78%)]\tClassification Loss: 1.5185\r\n",
      "Train Epoch: 4 [88320/110534 (80%)]\tClassification Loss: 1.8743\r\n",
      "Train Epoch: 4 [90240/110534 (82%)]\tClassification Loss: 1.8281\r\n",
      "Train Epoch: 4 [92160/110534 (83%)]\tClassification Loss: 1.7372\r\n",
      "Train Epoch: 4 [94080/110534 (85%)]\tClassification Loss: 1.6431\r\n",
      "Train Epoch: 4 [96000/110534 (87%)]\tClassification Loss: 1.8722\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1500.pth.tar\r\n",
      "Train Epoch: 4 [97920/110534 (89%)]\tClassification Loss: 1.5533\r\n",
      "Train Epoch: 4 [99840/110534 (90%)]\tClassification Loss: 1.6592\r\n",
      "Train Epoch: 4 [101760/110534 (92%)]\tClassification Loss: 1.4154\r\n",
      "Train Epoch: 4 [103680/110534 (94%)]\tClassification Loss: 1.7662\r\n",
      "Train Epoch: 4 [105600/110534 (96%)]\tClassification Loss: 1.6640\r\n",
      "Train Epoch: 4 [107520/110534 (97%)]\tClassification Loss: 1.6688\r\n",
      "Train Epoch: 4 [109440/110534 (99%)]\tClassification Loss: 1.8074\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_final.pth.tar\r\n",
      "Train Epoch: 5 [0/110534 (0%)]\tClassification Loss: 1.8967\r\n",
      "\r\n",
      "Test set: Average loss: 1.5175, Accuracy: 22253/42368 (53%)\r\n",
      "\r\n",
      "Train Epoch: 5 [1920/110534 (2%)]\tClassification Loss: 1.5911\r\n",
      "Train Epoch: 5 [3840/110534 (3%)]\tClassification Loss: 1.5268\r\n",
      "Train Epoch: 5 [5760/110534 (5%)]\tClassification Loss: 1.7718\r\n",
      "Train Epoch: 5 [7680/110534 (7%)]\tClassification Loss: 1.5919\r\n",
      "Train Epoch: 5 [9600/110534 (9%)]\tClassification Loss: 1.6879\r\n",
      "Train Epoch: 5 [11520/110534 (10%)]\tClassification Loss: 1.8541\r\n",
      "Train Epoch: 5 [13440/110534 (12%)]\tClassification Loss: 1.5779\r\n",
      "Train Epoch: 5 [15360/110534 (14%)]\tClassification Loss: 1.7709\r\n",
      "Train Epoch: 5 [17280/110534 (16%)]\tClassification Loss: 1.7756\r\n",
      "Train Epoch: 5 [19200/110534 (17%)]\tClassification Loss: 1.8360\r\n",
      "Train Epoch: 5 [21120/110534 (19%)]\tClassification Loss: 1.7098\r\n",
      "Train Epoch: 5 [23040/110534 (21%)]\tClassification Loss: 1.6022\r\n",
      "Train Epoch: 5 [24960/110534 (23%)]\tClassification Loss: 1.7831\r\n",
      "Train Epoch: 5 [26880/110534 (24%)]\tClassification Loss: 1.7222\r\n",
      "Train Epoch: 5 [28800/110534 (26%)]\tClassification Loss: 1.9366\r\n",
      "Train Epoch: 5 [30720/110534 (28%)]\tClassification Loss: 1.5841\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_500.pth.tar\r\n",
      "Train Epoch: 5 [32640/110534 (30%)]\tClassification Loss: 1.5612\r\n",
      "Train Epoch: 5 [34560/110534 (31%)]\tClassification Loss: 1.4411\r\n",
      "Train Epoch: 5 [36480/110534 (33%)]\tClassification Loss: 1.2888\r\n",
      "Train Epoch: 5 [38400/110534 (35%)]\tClassification Loss: 1.5774\r\n",
      "Train Epoch: 5 [40320/110534 (36%)]\tClassification Loss: 1.6569\r\n",
      "Train Epoch: 5 [42240/110534 (38%)]\tClassification Loss: 1.6085\r\n",
      "Train Epoch: 5 [44160/110534 (40%)]\tClassification Loss: 1.4210\r\n",
      "Train Epoch: 5 [46080/110534 (42%)]\tClassification Loss: 1.6975\r\n",
      "Train Epoch: 5 [48000/110534 (43%)]\tClassification Loss: 1.6413\r\n",
      "Train Epoch: 5 [49920/110534 (45%)]\tClassification Loss: 1.6901\r\n",
      "Train Epoch: 5 [51840/110534 (47%)]\tClassification Loss: 1.9578\r\n",
      "Train Epoch: 5 [53760/110534 (49%)]\tClassification Loss: 1.5187\r\n",
      "Train Epoch: 5 [55680/110534 (50%)]\tClassification Loss: 1.5651\r\n",
      "Train Epoch: 5 [57600/110534 (52%)]\tClassification Loss: 1.6745\r\n",
      "Train Epoch: 5 [59520/110534 (54%)]\tClassification Loss: 1.7771\r\n",
      "Train Epoch: 5 [61440/110534 (56%)]\tClassification Loss: 1.6877\r\n",
      "Train Epoch: 5 [63360/110534 (57%)]\tClassification Loss: 1.8376\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_1000.pth.tar\r\n",
      "Train Epoch: 5 [65280/110534 (59%)]\tClassification Loss: 1.6845\r\n",
      "Train Epoch: 5 [67200/110534 (61%)]\tClassification Loss: 1.4422\r\n",
      "Train Epoch: 5 [69120/110534 (63%)]\tClassification Loss: 1.5749\r\n",
      "Train Epoch: 5 [71040/110534 (64%)]\tClassification Loss: 1.4050\r\n",
      "Train Epoch: 5 [72960/110534 (66%)]\tClassification Loss: 1.4743\r\n",
      "Train Epoch: 5 [74880/110534 (68%)]\tClassification Loss: 1.5088\r\n",
      "Train Epoch: 5 [76800/110534 (69%)]\tClassification Loss: 1.3641\r\n",
      "Train Epoch: 5 [78720/110534 (71%)]\tClassification Loss: 1.5225\r\n",
      "Train Epoch: 5 [80640/110534 (73%)]\tClassification Loss: 1.6534\r\n",
      "Train Epoch: 5 [82560/110534 (75%)]\tClassification Loss: 1.4079\r\n",
      "Train Epoch: 5 [84480/110534 (76%)]\tClassification Loss: 1.4596\r\n",
      "Train Epoch: 5 [86400/110534 (78%)]\tClassification Loss: 1.4868\r\n",
      "Train Epoch: 5 [88320/110534 (80%)]\tClassification Loss: 1.7924\r\n",
      "Train Epoch: 5 [90240/110534 (82%)]\tClassification Loss: 1.6766\r\n",
      "Train Epoch: 5 [92160/110534 (83%)]\tClassification Loss: 1.6712\r\n",
      "Train Epoch: 5 [94080/110534 (85%)]\tClassification Loss: 1.6309\r\n",
      "Train Epoch: 5 [96000/110534 (87%)]\tClassification Loss: 1.7391\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_1500.pth.tar\r\n",
      "Train Epoch: 5 [97920/110534 (89%)]\tClassification Loss: 1.5572\r\n",
      "Train Epoch: 5 [99840/110534 (90%)]\tClassification Loss: 1.6362\r\n",
      "Train Epoch: 5 [101760/110534 (92%)]\tClassification Loss: 1.5667\r\n",
      "Train Epoch: 5 [103680/110534 (94%)]\tClassification Loss: 1.7213\r\n",
      "Train Epoch: 5 [105600/110534 (96%)]\tClassification Loss: 1.5595\r\n",
      "Train Epoch: 5 [107520/110534 (97%)]\tClassification Loss: 1.5027\r\n",
      "Train Epoch: 5 [109440/110534 (99%)]\tClassification Loss: 1.7817\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_final.pth.tar\r\n",
      "Train Epoch: 6 [0/110534 (0%)]\tClassification Loss: 1.6679\r\n",
      "\r\n",
      "Test set: Average loss: 1.5019, Accuracy: 22453/42368 (53%)\r\n",
      "\r\n",
      "Train Epoch: 6 [1920/110534 (2%)]\tClassification Loss: 1.4779\r\n",
      "Train Epoch: 6 [3840/110534 (3%)]\tClassification Loss: 1.6093\r\n",
      "Train Epoch: 6 [5760/110534 (5%)]\tClassification Loss: 1.9675\r\n",
      "Train Epoch: 6 [7680/110534 (7%)]\tClassification Loss: 1.4451\r\n",
      "Train Epoch: 6 [9600/110534 (9%)]\tClassification Loss: 1.6715\r\n",
      "Train Epoch: 6 [11520/110534 (10%)]\tClassification Loss: 1.7027\r\n",
      "Train Epoch: 6 [13440/110534 (12%)]\tClassification Loss: 1.6060\r\n",
      "Train Epoch: 6 [15360/110534 (14%)]\tClassification Loss: 1.7395\r\n",
      "Train Epoch: 6 [17280/110534 (16%)]\tClassification Loss: 1.8150\r\n",
      "Train Epoch: 6 [19200/110534 (17%)]\tClassification Loss: 1.8024\r\n",
      "Train Epoch: 6 [21120/110534 (19%)]\tClassification Loss: 1.7538\r\n",
      "Train Epoch: 6 [23040/110534 (21%)]\tClassification Loss: 1.5214\r\n",
      "Train Epoch: 6 [24960/110534 (23%)]\tClassification Loss: 1.7764\r\n",
      "Train Epoch: 6 [26880/110534 (24%)]\tClassification Loss: 1.6866\r\n",
      "Train Epoch: 6 [28800/110534 (26%)]\tClassification Loss: 1.8129\r\n",
      "Train Epoch: 6 [30720/110534 (28%)]\tClassification Loss: 1.6740\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_500.pth.tar\r\n",
      "Train Epoch: 6 [32640/110534 (30%)]\tClassification Loss: 1.6007\r\n",
      "Train Epoch: 6 [34560/110534 (31%)]\tClassification Loss: 1.3576\r\n",
      "Train Epoch: 6 [36480/110534 (33%)]\tClassification Loss: 1.4003\r\n",
      "Train Epoch: 6 [38400/110534 (35%)]\tClassification Loss: 1.6587\r\n",
      "Train Epoch: 6 [40320/110534 (36%)]\tClassification Loss: 1.6263\r\n",
      "Train Epoch: 6 [42240/110534 (38%)]\tClassification Loss: 1.7516\r\n",
      "Train Epoch: 6 [44160/110534 (40%)]\tClassification Loss: 1.6180\r\n",
      "Train Epoch: 6 [46080/110534 (42%)]\tClassification Loss: 1.4535\r\n",
      "Train Epoch: 6 [48000/110534 (43%)]\tClassification Loss: 1.7189\r\n",
      "Train Epoch: 6 [49920/110534 (45%)]\tClassification Loss: 1.6897\r\n",
      "Train Epoch: 6 [51840/110534 (47%)]\tClassification Loss: 1.7409\r\n",
      "Train Epoch: 6 [53760/110534 (49%)]\tClassification Loss: 1.5087\r\n",
      "Train Epoch: 6 [55680/110534 (50%)]\tClassification Loss: 1.6121\r\n",
      "Train Epoch: 6 [57600/110534 (52%)]\tClassification Loss: 1.5248\r\n",
      "Train Epoch: 6 [59520/110534 (54%)]\tClassification Loss: 2.0240\r\n",
      "Train Epoch: 6 [61440/110534 (56%)]\tClassification Loss: 1.5537\r\n",
      "Train Epoch: 6 [63360/110534 (57%)]\tClassification Loss: 1.8792\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_1000.pth.tar\r\n",
      "Train Epoch: 6 [65280/110534 (59%)]\tClassification Loss: 1.5754\r\n",
      "Train Epoch: 6 [67200/110534 (61%)]\tClassification Loss: 1.4508\r\n",
      "Train Epoch: 6 [69120/110534 (63%)]\tClassification Loss: 1.5269\r\n",
      "Train Epoch: 6 [71040/110534 (64%)]\tClassification Loss: 1.5441\r\n",
      "Train Epoch: 6 [72960/110534 (66%)]\tClassification Loss: 1.4529\r\n",
      "Train Epoch: 6 [74880/110534 (68%)]\tClassification Loss: 1.4409\r\n",
      "Train Epoch: 6 [76800/110534 (69%)]\tClassification Loss: 1.4480\r\n",
      "Train Epoch: 6 [78720/110534 (71%)]\tClassification Loss: 1.5746\r\n",
      "Train Epoch: 6 [80640/110534 (73%)]\tClassification Loss: 1.6634\r\n",
      "Train Epoch: 6 [82560/110534 (75%)]\tClassification Loss: 1.3312\r\n",
      "Train Epoch: 6 [84480/110534 (76%)]\tClassification Loss: 1.4727\r\n",
      "Train Epoch: 6 [86400/110534 (78%)]\tClassification Loss: 1.5146\r\n",
      "Train Epoch: 6 [88320/110534 (80%)]\tClassification Loss: 1.7003\r\n",
      "Train Epoch: 6 [90240/110534 (82%)]\tClassification Loss: 1.7510\r\n",
      "Train Epoch: 6 [92160/110534 (83%)]\tClassification Loss: 1.6860\r\n",
      "Train Epoch: 6 [94080/110534 (85%)]\tClassification Loss: 1.7391\r\n",
      "Train Epoch: 6 [96000/110534 (87%)]\tClassification Loss: 1.8180\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_1500.pth.tar\r\n",
      "Train Epoch: 6 [97920/110534 (89%)]\tClassification Loss: 1.5925\r\n",
      "Train Epoch: 6 [99840/110534 (90%)]\tClassification Loss: 1.7230\r\n",
      "Train Epoch: 6 [101760/110534 (92%)]\tClassification Loss: 1.4502\r\n",
      "Train Epoch: 6 [103680/110534 (94%)]\tClassification Loss: 1.7223\r\n",
      "Train Epoch: 6 [105600/110534 (96%)]\tClassification Loss: 1.5332\r\n",
      "Train Epoch: 6 [107520/110534 (97%)]\tClassification Loss: 1.5109\r\n",
      "Train Epoch: 6 [109440/110534 (99%)]\tClassification Loss: 1.7340\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_final.pth.tar\r\n",
      "Train Epoch: 7 [0/110534 (0%)]\tClassification Loss: 1.6601\r\n",
      "\r\n",
      "Test set: Average loss: 1.4915, Accuracy: 22541/42368 (53%)\r\n",
      "\r\n",
      "Train Epoch: 7 [1920/110534 (2%)]\tClassification Loss: 1.3981\r\n",
      "Train Epoch: 7 [3840/110534 (3%)]\tClassification Loss: 1.6063\r\n",
      "Train Epoch: 7 [5760/110534 (5%)]\tClassification Loss: 1.7852\r\n",
      "Train Epoch: 7 [7680/110534 (7%)]\tClassification Loss: 1.7070\r\n",
      "Train Epoch: 7 [9600/110534 (9%)]\tClassification Loss: 1.6199\r\n",
      "Train Epoch: 7 [11520/110534 (10%)]\tClassification Loss: 1.6829\r\n",
      "Train Epoch: 7 [13440/110534 (12%)]\tClassification Loss: 1.5632\r\n",
      "Train Epoch: 7 [15360/110534 (14%)]\tClassification Loss: 1.7020\r\n",
      "Train Epoch: 7 [17280/110534 (16%)]\tClassification Loss: 1.7856\r\n",
      "Train Epoch: 7 [19200/110534 (17%)]\tClassification Loss: 1.7426\r\n",
      "Train Epoch: 7 [21120/110534 (19%)]\tClassification Loss: 1.5806\r\n",
      "Train Epoch: 7 [23040/110534 (21%)]\tClassification Loss: 1.5805\r\n",
      "Train Epoch: 7 [24960/110534 (23%)]\tClassification Loss: 1.5828\r\n",
      "Train Epoch: 7 [26880/110534 (24%)]\tClassification Loss: 1.7166\r\n",
      "Train Epoch: 7 [28800/110534 (26%)]\tClassification Loss: 1.8421\r\n",
      "Train Epoch: 7 [30720/110534 (28%)]\tClassification Loss: 1.6657\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_500.pth.tar\r\n",
      "Train Epoch: 7 [32640/110534 (30%)]\tClassification Loss: 1.5894\r\n",
      "Train Epoch: 7 [34560/110534 (31%)]\tClassification Loss: 1.3770\r\n",
      "Train Epoch: 7 [36480/110534 (33%)]\tClassification Loss: 1.4301\r\n",
      "Train Epoch: 7 [38400/110534 (35%)]\tClassification Loss: 1.4958\r\n",
      "Train Epoch: 7 [40320/110534 (36%)]\tClassification Loss: 1.7274\r\n",
      "Train Epoch: 7 [42240/110534 (38%)]\tClassification Loss: 1.6816\r\n",
      "Train Epoch: 7 [44160/110534 (40%)]\tClassification Loss: 1.3438\r\n",
      "Train Epoch: 7 [46080/110534 (42%)]\tClassification Loss: 1.5384\r\n",
      "Train Epoch: 7 [48000/110534 (43%)]\tClassification Loss: 1.6908\r\n",
      "Train Epoch: 7 [49920/110534 (45%)]\tClassification Loss: 1.6354\r\n",
      "Train Epoch: 7 [51840/110534 (47%)]\tClassification Loss: 1.9599\r\n",
      "Train Epoch: 7 [53760/110534 (49%)]\tClassification Loss: 1.4410\r\n",
      "Train Epoch: 7 [55680/110534 (50%)]\tClassification Loss: 1.4750\r\n",
      "Train Epoch: 7 [57600/110534 (52%)]\tClassification Loss: 1.5944\r\n",
      "Train Epoch: 7 [59520/110534 (54%)]\tClassification Loss: 2.0211\r\n",
      "Train Epoch: 7 [61440/110534 (56%)]\tClassification Loss: 1.5957\r\n",
      "Train Epoch: 7 [63360/110534 (57%)]\tClassification Loss: 1.9032\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_1000.pth.tar\r\n",
      "Train Epoch: 7 [65280/110534 (59%)]\tClassification Loss: 1.7887\r\n",
      "Train Epoch: 7 [67200/110534 (61%)]\tClassification Loss: 1.3477\r\n",
      "Train Epoch: 7 [69120/110534 (63%)]\tClassification Loss: 1.4545\r\n",
      "Train Epoch: 7 [71040/110534 (64%)]\tClassification Loss: 1.6475\r\n",
      "Train Epoch: 7 [72960/110534 (66%)]\tClassification Loss: 1.4041\r\n",
      "Train Epoch: 7 [74880/110534 (68%)]\tClassification Loss: 1.3599\r\n",
      "Train Epoch: 7 [76800/110534 (69%)]\tClassification Loss: 1.4455\r\n",
      "Train Epoch: 7 [78720/110534 (71%)]\tClassification Loss: 1.6013\r\n",
      "Train Epoch: 7 [80640/110534 (73%)]\tClassification Loss: 1.6290\r\n",
      "Train Epoch: 7 [82560/110534 (75%)]\tClassification Loss: 1.5562\r\n",
      "Train Epoch: 7 [84480/110534 (76%)]\tClassification Loss: 1.5185\r\n",
      "Train Epoch: 7 [86400/110534 (78%)]\tClassification Loss: 1.5345\r\n",
      "Train Epoch: 7 [88320/110534 (80%)]\tClassification Loss: 1.8164\r\n",
      "Train Epoch: 7 [90240/110534 (82%)]\tClassification Loss: 1.7678\r\n",
      "Train Epoch: 7 [92160/110534 (83%)]\tClassification Loss: 1.9201\r\n",
      "Train Epoch: 7 [94080/110534 (85%)]\tClassification Loss: 1.6361\r\n",
      "Train Epoch: 7 [96000/110534 (87%)]\tClassification Loss: 1.7583\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_1500.pth.tar\r\n",
      "Train Epoch: 7 [97920/110534 (89%)]\tClassification Loss: 1.5606\r\n",
      "Train Epoch: 7 [99840/110534 (90%)]\tClassification Loss: 1.7407\r\n",
      "Train Epoch: 7 [101760/110534 (92%)]\tClassification Loss: 1.5583\r\n",
      "Train Epoch: 7 [103680/110534 (94%)]\tClassification Loss: 1.6763\r\n",
      "Train Epoch: 7 [105600/110534 (96%)]\tClassification Loss: 1.6251\r\n",
      "Train Epoch: 7 [107520/110534 (97%)]\tClassification Loss: 1.7149\r\n",
      "Train Epoch: 7 [109440/110534 (99%)]\tClassification Loss: 1.5850\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_7_final.pth.tar\r\n",
      "Train Epoch: 8 [0/110534 (0%)]\tClassification Loss: 1.7301\r\n",
      "\r\n",
      "Test set: Average loss: 1.4826, Accuracy: 22675/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 8 [1920/110534 (2%)]\tClassification Loss: 1.5227\r\n",
      "Train Epoch: 8 [3840/110534 (3%)]\tClassification Loss: 1.5864\r\n",
      "Train Epoch: 8 [5760/110534 (5%)]\tClassification Loss: 1.7470\r\n",
      "Train Epoch: 8 [7680/110534 (7%)]\tClassification Loss: 1.5885\r\n",
      "Train Epoch: 8 [9600/110534 (9%)]\tClassification Loss: 1.6213\r\n",
      "Train Epoch: 8 [11520/110534 (10%)]\tClassification Loss: 1.7706\r\n",
      "Train Epoch: 8 [13440/110534 (12%)]\tClassification Loss: 1.5520\r\n",
      "Train Epoch: 8 [15360/110534 (14%)]\tClassification Loss: 1.7304\r\n",
      "Train Epoch: 8 [17280/110534 (16%)]\tClassification Loss: 1.9131\r\n",
      "Train Epoch: 8 [19200/110534 (17%)]\tClassification Loss: 1.8148\r\n",
      "Train Epoch: 8 [21120/110534 (19%)]\tClassification Loss: 1.6195\r\n",
      "Train Epoch: 8 [23040/110534 (21%)]\tClassification Loss: 1.4502\r\n",
      "Train Epoch: 8 [24960/110534 (23%)]\tClassification Loss: 1.7225\r\n",
      "Train Epoch: 8 [26880/110534 (24%)]\tClassification Loss: 1.6633\r\n",
      "Train Epoch: 8 [28800/110534 (26%)]\tClassification Loss: 1.8913\r\n",
      "Train Epoch: 8 [30720/110534 (28%)]\tClassification Loss: 1.5155\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_500.pth.tar\r\n",
      "Train Epoch: 8 [32640/110534 (30%)]\tClassification Loss: 1.5959\r\n",
      "Train Epoch: 8 [34560/110534 (31%)]\tClassification Loss: 1.2363\r\n",
      "Train Epoch: 8 [36480/110534 (33%)]\tClassification Loss: 1.3970\r\n",
      "Train Epoch: 8 [38400/110534 (35%)]\tClassification Loss: 1.5872\r\n",
      "Train Epoch: 8 [40320/110534 (36%)]\tClassification Loss: 1.5955\r\n",
      "Train Epoch: 8 [42240/110534 (38%)]\tClassification Loss: 1.6636\r\n",
      "Train Epoch: 8 [44160/110534 (40%)]\tClassification Loss: 1.3281\r\n",
      "Train Epoch: 8 [46080/110534 (42%)]\tClassification Loss: 1.4293\r\n",
      "Train Epoch: 8 [48000/110534 (43%)]\tClassification Loss: 1.7160\r\n",
      "Train Epoch: 8 [49920/110534 (45%)]\tClassification Loss: 1.7630\r\n",
      "Train Epoch: 8 [51840/110534 (47%)]\tClassification Loss: 1.7026\r\n",
      "Train Epoch: 8 [53760/110534 (49%)]\tClassification Loss: 1.4639\r\n",
      "Train Epoch: 8 [55680/110534 (50%)]\tClassification Loss: 1.6186\r\n",
      "Train Epoch: 8 [57600/110534 (52%)]\tClassification Loss: 1.5893\r\n",
      "Train Epoch: 8 [59520/110534 (54%)]\tClassification Loss: 1.8891\r\n",
      "Train Epoch: 8 [61440/110534 (56%)]\tClassification Loss: 1.5114\r\n",
      "Train Epoch: 8 [63360/110534 (57%)]\tClassification Loss: 1.7944\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_1000.pth.tar\r\n",
      "Train Epoch: 8 [65280/110534 (59%)]\tClassification Loss: 1.6593\r\n",
      "Train Epoch: 8 [67200/110534 (61%)]\tClassification Loss: 1.4805\r\n",
      "Train Epoch: 8 [69120/110534 (63%)]\tClassification Loss: 1.4524\r\n",
      "Train Epoch: 8 [71040/110534 (64%)]\tClassification Loss: 1.5296\r\n",
      "Train Epoch: 8 [72960/110534 (66%)]\tClassification Loss: 1.4786\r\n",
      "Train Epoch: 8 [74880/110534 (68%)]\tClassification Loss: 1.4369\r\n",
      "Train Epoch: 8 [76800/110534 (69%)]\tClassification Loss: 1.4578\r\n",
      "Train Epoch: 8 [78720/110534 (71%)]\tClassification Loss: 1.4607\r\n",
      "Train Epoch: 8 [80640/110534 (73%)]\tClassification Loss: 1.7224\r\n",
      "Train Epoch: 8 [82560/110534 (75%)]\tClassification Loss: 1.4614\r\n",
      "Train Epoch: 8 [84480/110534 (76%)]\tClassification Loss: 1.4335\r\n",
      "Train Epoch: 8 [86400/110534 (78%)]\tClassification Loss: 1.4663\r\n",
      "Train Epoch: 8 [88320/110534 (80%)]\tClassification Loss: 1.8775\r\n",
      "Train Epoch: 8 [90240/110534 (82%)]\tClassification Loss: 1.7165\r\n",
      "Train Epoch: 8 [92160/110534 (83%)]\tClassification Loss: 1.9566\r\n",
      "Train Epoch: 8 [94080/110534 (85%)]\tClassification Loss: 1.6819\r\n",
      "Train Epoch: 8 [96000/110534 (87%)]\tClassification Loss: 1.8782\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_1500.pth.tar\r\n",
      "Train Epoch: 8 [97920/110534 (89%)]\tClassification Loss: 1.5429\r\n",
      "Train Epoch: 8 [99840/110534 (90%)]\tClassification Loss: 1.7826\r\n",
      "Train Epoch: 8 [101760/110534 (92%)]\tClassification Loss: 1.3693\r\n",
      "Train Epoch: 8 [103680/110534 (94%)]\tClassification Loss: 1.7432\r\n",
      "Train Epoch: 8 [105600/110534 (96%)]\tClassification Loss: 1.5857\r\n",
      "Train Epoch: 8 [107520/110534 (97%)]\tClassification Loss: 1.6131\r\n",
      "Train Epoch: 8 [109440/110534 (99%)]\tClassification Loss: 1.6682\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_8_final.pth.tar\r\n",
      "Train Epoch: 9 [0/110534 (0%)]\tClassification Loss: 1.6203\r\n",
      "\r\n",
      "Test set: Average loss: 1.4767, Accuracy: 22722/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 9 [1920/110534 (2%)]\tClassification Loss: 1.4905\r\n",
      "Train Epoch: 9 [3840/110534 (3%)]\tClassification Loss: 1.5836\r\n",
      "Train Epoch: 9 [5760/110534 (5%)]\tClassification Loss: 1.6874\r\n",
      "Train Epoch: 9 [7680/110534 (7%)]\tClassification Loss: 1.5623\r\n",
      "Train Epoch: 9 [9600/110534 (9%)]\tClassification Loss: 1.6884\r\n",
      "Train Epoch: 9 [11520/110534 (10%)]\tClassification Loss: 1.7104\r\n",
      "Train Epoch: 9 [13440/110534 (12%)]\tClassification Loss: 1.5731\r\n",
      "Train Epoch: 9 [15360/110534 (14%)]\tClassification Loss: 1.7001\r\n",
      "Train Epoch: 9 [17280/110534 (16%)]\tClassification Loss: 1.7851\r\n",
      "Train Epoch: 9 [19200/110534 (17%)]\tClassification Loss: 1.9936\r\n",
      "Train Epoch: 9 [21120/110534 (19%)]\tClassification Loss: 1.5973\r\n",
      "Train Epoch: 9 [23040/110534 (21%)]\tClassification Loss: 1.4969\r\n",
      "Train Epoch: 9 [24960/110534 (23%)]\tClassification Loss: 1.5815\r\n",
      "Train Epoch: 9 [26880/110534 (24%)]\tClassification Loss: 1.6512\r\n",
      "Train Epoch: 9 [28800/110534 (26%)]\tClassification Loss: 1.7903\r\n",
      "Train Epoch: 9 [30720/110534 (28%)]\tClassification Loss: 1.6086\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_500.pth.tar\r\n",
      "Train Epoch: 9 [32640/110534 (30%)]\tClassification Loss: 1.6543\r\n",
      "Train Epoch: 9 [34560/110534 (31%)]\tClassification Loss: 1.4091\r\n",
      "Train Epoch: 9 [36480/110534 (33%)]\tClassification Loss: 1.2684\r\n",
      "Train Epoch: 9 [38400/110534 (35%)]\tClassification Loss: 1.3951\r\n",
      "Train Epoch: 9 [40320/110534 (36%)]\tClassification Loss: 1.5030\r\n",
      "Train Epoch: 9 [42240/110534 (38%)]\tClassification Loss: 1.5586\r\n",
      "Train Epoch: 9 [44160/110534 (40%)]\tClassification Loss: 1.4728\r\n",
      "Train Epoch: 9 [46080/110534 (42%)]\tClassification Loss: 1.5976\r\n",
      "Train Epoch: 9 [48000/110534 (43%)]\tClassification Loss: 1.5869\r\n",
      "Train Epoch: 9 [49920/110534 (45%)]\tClassification Loss: 1.7978\r\n",
      "Train Epoch: 9 [51840/110534 (47%)]\tClassification Loss: 1.8668\r\n",
      "Train Epoch: 9 [53760/110534 (49%)]\tClassification Loss: 1.6107\r\n",
      "Train Epoch: 9 [55680/110534 (50%)]\tClassification Loss: 1.6244\r\n",
      "Train Epoch: 9 [57600/110534 (52%)]\tClassification Loss: 1.4606\r\n",
      "Train Epoch: 9 [59520/110534 (54%)]\tClassification Loss: 1.9559\r\n",
      "Train Epoch: 9 [61440/110534 (56%)]\tClassification Loss: 1.6756\r\n",
      "Train Epoch: 9 [63360/110534 (57%)]\tClassification Loss: 1.8177\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_1000.pth.tar\r\n",
      "Train Epoch: 9 [65280/110534 (59%)]\tClassification Loss: 1.6571\r\n",
      "Train Epoch: 9 [67200/110534 (61%)]\tClassification Loss: 1.3526\r\n",
      "Train Epoch: 9 [69120/110534 (63%)]\tClassification Loss: 1.5139\r\n",
      "Train Epoch: 9 [71040/110534 (64%)]\tClassification Loss: 1.5220\r\n",
      "Train Epoch: 9 [72960/110534 (66%)]\tClassification Loss: 1.4837\r\n",
      "Train Epoch: 9 [74880/110534 (68%)]\tClassification Loss: 1.5225\r\n",
      "Train Epoch: 9 [76800/110534 (69%)]\tClassification Loss: 1.4736\r\n",
      "Train Epoch: 9 [78720/110534 (71%)]\tClassification Loss: 1.4265\r\n",
      "Train Epoch: 9 [80640/110534 (73%)]\tClassification Loss: 1.5763\r\n",
      "Train Epoch: 9 [82560/110534 (75%)]\tClassification Loss: 1.4063\r\n",
      "Train Epoch: 9 [84480/110534 (76%)]\tClassification Loss: 1.5077\r\n",
      "Train Epoch: 9 [86400/110534 (78%)]\tClassification Loss: 1.4269\r\n",
      "Train Epoch: 9 [88320/110534 (80%)]\tClassification Loss: 1.7862\r\n",
      "Train Epoch: 9 [90240/110534 (82%)]\tClassification Loss: 1.7071\r\n",
      "Train Epoch: 9 [92160/110534 (83%)]\tClassification Loss: 1.9069\r\n",
      "Train Epoch: 9 [94080/110534 (85%)]\tClassification Loss: 1.6724\r\n",
      "Train Epoch: 9 [96000/110534 (87%)]\tClassification Loss: 1.6800\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_1500.pth.tar\r\n",
      "Train Epoch: 9 [97920/110534 (89%)]\tClassification Loss: 1.4820\r\n",
      "Train Epoch: 9 [99840/110534 (90%)]\tClassification Loss: 1.7627\r\n",
      "Train Epoch: 9 [101760/110534 (92%)]\tClassification Loss: 1.3753\r\n",
      "Train Epoch: 9 [103680/110534 (94%)]\tClassification Loss: 1.5503\r\n",
      "Train Epoch: 9 [105600/110534 (96%)]\tClassification Loss: 1.5563\r\n",
      "Train Epoch: 9 [107520/110534 (97%)]\tClassification Loss: 1.5213\r\n",
      "Train Epoch: 9 [109440/110534 (99%)]\tClassification Loss: 1.6601\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_9_final.pth.tar\r\n",
      "Train Epoch: 10 [0/110534 (0%)]\tClassification Loss: 1.6326\r\n",
      "\r\n",
      "Test set: Average loss: 1.4710, Accuracy: 22786/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 10 [1920/110534 (2%)]\tClassification Loss: 1.4986\r\n",
      "Train Epoch: 10 [3840/110534 (3%)]\tClassification Loss: 1.6241\r\n",
      "Train Epoch: 10 [5760/110534 (5%)]\tClassification Loss: 1.7002\r\n",
      "Train Epoch: 10 [7680/110534 (7%)]\tClassification Loss: 1.4604\r\n",
      "Train Epoch: 10 [9600/110534 (9%)]\tClassification Loss: 1.7272\r\n",
      "Train Epoch: 10 [11520/110534 (10%)]\tClassification Loss: 1.8953\r\n",
      "Train Epoch: 10 [13440/110534 (12%)]\tClassification Loss: 1.5042\r\n",
      "Train Epoch: 10 [15360/110534 (14%)]\tClassification Loss: 1.9192\r\n",
      "Train Epoch: 10 [17280/110534 (16%)]\tClassification Loss: 1.8978\r\n",
      "Train Epoch: 10 [19200/110534 (17%)]\tClassification Loss: 1.8165\r\n",
      "Train Epoch: 10 [21120/110534 (19%)]\tClassification Loss: 1.5775\r\n",
      "Train Epoch: 10 [23040/110534 (21%)]\tClassification Loss: 1.6682\r\n",
      "Train Epoch: 10 [24960/110534 (23%)]\tClassification Loss: 1.7038\r\n",
      "Train Epoch: 10 [26880/110534 (24%)]\tClassification Loss: 1.7461\r\n",
      "Train Epoch: 10 [28800/110534 (26%)]\tClassification Loss: 2.0021\r\n",
      "Train Epoch: 10 [30720/110534 (28%)]\tClassification Loss: 1.5295\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_500.pth.tar\r\n",
      "Train Epoch: 10 [32640/110534 (30%)]\tClassification Loss: 1.4417\r\n",
      "Train Epoch: 10 [34560/110534 (31%)]\tClassification Loss: 1.4312\r\n",
      "Train Epoch: 10 [36480/110534 (33%)]\tClassification Loss: 1.4707\r\n",
      "Train Epoch: 10 [38400/110534 (35%)]\tClassification Loss: 1.4760\r\n",
      "Train Epoch: 10 [40320/110534 (36%)]\tClassification Loss: 1.5826\r\n",
      "Train Epoch: 10 [42240/110534 (38%)]\tClassification Loss: 1.5302\r\n",
      "Train Epoch: 10 [44160/110534 (40%)]\tClassification Loss: 1.5524\r\n",
      "Train Epoch: 10 [46080/110534 (42%)]\tClassification Loss: 1.6222\r\n",
      "Train Epoch: 10 [48000/110534 (43%)]\tClassification Loss: 1.7977\r\n",
      "Train Epoch: 10 [49920/110534 (45%)]\tClassification Loss: 1.6971\r\n",
      "Train Epoch: 10 [51840/110534 (47%)]\tClassification Loss: 1.8669\r\n",
      "Train Epoch: 10 [53760/110534 (49%)]\tClassification Loss: 1.4458\r\n",
      "Train Epoch: 10 [55680/110534 (50%)]\tClassification Loss: 1.4514\r\n",
      "Train Epoch: 10 [57600/110534 (52%)]\tClassification Loss: 1.4888\r\n",
      "Train Epoch: 10 [59520/110534 (54%)]\tClassification Loss: 1.9293\r\n",
      "Train Epoch: 10 [61440/110534 (56%)]\tClassification Loss: 1.3909\r\n",
      "Train Epoch: 10 [63360/110534 (57%)]\tClassification Loss: 1.8033\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_1000.pth.tar\r\n",
      "Train Epoch: 10 [65280/110534 (59%)]\tClassification Loss: 1.5399\r\n",
      "Train Epoch: 10 [67200/110534 (61%)]\tClassification Loss: 1.3218\r\n",
      "Train Epoch: 10 [69120/110534 (63%)]\tClassification Loss: 1.4544\r\n",
      "Train Epoch: 10 [71040/110534 (64%)]\tClassification Loss: 1.5263\r\n",
      "Train Epoch: 10 [72960/110534 (66%)]\tClassification Loss: 1.5746\r\n",
      "Train Epoch: 10 [74880/110534 (68%)]\tClassification Loss: 1.3982\r\n",
      "Train Epoch: 10 [76800/110534 (69%)]\tClassification Loss: 1.4845\r\n",
      "Train Epoch: 10 [78720/110534 (71%)]\tClassification Loss: 1.5595\r\n",
      "Train Epoch: 10 [80640/110534 (73%)]\tClassification Loss: 1.7241\r\n",
      "Train Epoch: 10 [82560/110534 (75%)]\tClassification Loss: 1.2906\r\n",
      "Train Epoch: 10 [84480/110534 (76%)]\tClassification Loss: 1.4003\r\n",
      "Train Epoch: 10 [86400/110534 (78%)]\tClassification Loss: 1.4366\r\n",
      "Train Epoch: 10 [88320/110534 (80%)]\tClassification Loss: 1.7820\r\n",
      "Train Epoch: 10 [90240/110534 (82%)]\tClassification Loss: 1.6376\r\n",
      "Train Epoch: 10 [92160/110534 (83%)]\tClassification Loss: 1.8156\r\n",
      "Train Epoch: 10 [94080/110534 (85%)]\tClassification Loss: 1.6669\r\n",
      "Train Epoch: 10 [96000/110534 (87%)]\tClassification Loss: 1.7744\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_1500.pth.tar\r\n",
      "Train Epoch: 10 [97920/110534 (89%)]\tClassification Loss: 1.5397\r\n",
      "Train Epoch: 10 [99840/110534 (90%)]\tClassification Loss: 1.6063\r\n",
      "Train Epoch: 10 [101760/110534 (92%)]\tClassification Loss: 1.4146\r\n",
      "Train Epoch: 10 [103680/110534 (94%)]\tClassification Loss: 1.6560\r\n",
      "Train Epoch: 10 [105600/110534 (96%)]\tClassification Loss: 1.4417\r\n",
      "Train Epoch: 10 [107520/110534 (97%)]\tClassification Loss: 1.6533\r\n",
      "Train Epoch: 10 [109440/110534 (99%)]\tClassification Loss: 1.6244\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_10_final.pth.tar\r\n",
      "Train Epoch: 11 [0/110534 (0%)]\tClassification Loss: 1.6191\r\n",
      "\r\n",
      "Test set: Average loss: 1.4690, Accuracy: 22812/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 11 [1920/110534 (2%)]\tClassification Loss: 1.4494\r\n",
      "Train Epoch: 11 [3840/110534 (3%)]\tClassification Loss: 1.5130\r\n",
      "Train Epoch: 11 [5760/110534 (5%)]\tClassification Loss: 1.6731\r\n",
      "Train Epoch: 11 [7680/110534 (7%)]\tClassification Loss: 1.4868\r\n",
      "Train Epoch: 11 [9600/110534 (9%)]\tClassification Loss: 1.5728\r\n",
      "Train Epoch: 11 [11520/110534 (10%)]\tClassification Loss: 1.6317\r\n",
      "Train Epoch: 11 [13440/110534 (12%)]\tClassification Loss: 1.5874\r\n",
      "Train Epoch: 11 [15360/110534 (14%)]\tClassification Loss: 1.8860\r\n",
      "Train Epoch: 11 [17280/110534 (16%)]\tClassification Loss: 1.8623\r\n",
      "Train Epoch: 11 [19200/110534 (17%)]\tClassification Loss: 1.8559\r\n",
      "Train Epoch: 11 [21120/110534 (19%)]\tClassification Loss: 1.5762\r\n",
      "Train Epoch: 11 [23040/110534 (21%)]\tClassification Loss: 1.4542\r\n",
      "Train Epoch: 11 [24960/110534 (23%)]\tClassification Loss: 1.6487\r\n",
      "Train Epoch: 11 [26880/110534 (24%)]\tClassification Loss: 1.6362\r\n",
      "Train Epoch: 11 [28800/110534 (26%)]\tClassification Loss: 1.8532\r\n",
      "Train Epoch: 11 [30720/110534 (28%)]\tClassification Loss: 1.4460\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_11_500.pth.tar\r\n",
      "Train Epoch: 11 [32640/110534 (30%)]\tClassification Loss: 1.6469\r\n",
      "Train Epoch: 11 [34560/110534 (31%)]\tClassification Loss: 1.4719\r\n",
      "Train Epoch: 11 [36480/110534 (33%)]\tClassification Loss: 1.4967\r\n",
      "Train Epoch: 11 [38400/110534 (35%)]\tClassification Loss: 1.5885\r\n",
      "Train Epoch: 11 [40320/110534 (36%)]\tClassification Loss: 1.4830\r\n",
      "Train Epoch: 11 [42240/110534 (38%)]\tClassification Loss: 1.4496\r\n",
      "Train Epoch: 11 [44160/110534 (40%)]\tClassification Loss: 1.6158\r\n",
      "Train Epoch: 11 [46080/110534 (42%)]\tClassification Loss: 1.4858\r\n",
      "Train Epoch: 11 [48000/110534 (43%)]\tClassification Loss: 1.6566\r\n",
      "Train Epoch: 11 [49920/110534 (45%)]\tClassification Loss: 1.6811\r\n",
      "Train Epoch: 11 [51840/110534 (47%)]\tClassification Loss: 1.9065\r\n",
      "Train Epoch: 11 [53760/110534 (49%)]\tClassification Loss: 1.3980\r\n",
      "Train Epoch: 11 [55680/110534 (50%)]\tClassification Loss: 1.4945\r\n",
      "Train Epoch: 11 [57600/110534 (52%)]\tClassification Loss: 1.6197\r\n",
      "Train Epoch: 11 [59520/110534 (54%)]\tClassification Loss: 1.8418\r\n",
      "Train Epoch: 11 [61440/110534 (56%)]\tClassification Loss: 1.5738\r\n",
      "Train Epoch: 11 [63360/110534 (57%)]\tClassification Loss: 1.8102\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_11_1000.pth.tar\r\n",
      "Train Epoch: 11 [65280/110534 (59%)]\tClassification Loss: 1.6476\r\n",
      "Train Epoch: 11 [67200/110534 (61%)]\tClassification Loss: 1.4301\r\n",
      "Train Epoch: 11 [69120/110534 (63%)]\tClassification Loss: 1.6587\r\n",
      "Train Epoch: 11 [71040/110534 (64%)]\tClassification Loss: 1.6050\r\n",
      "Train Epoch: 11 [72960/110534 (66%)]\tClassification Loss: 1.3989\r\n",
      "Train Epoch: 11 [74880/110534 (68%)]\tClassification Loss: 1.3852\r\n",
      "Train Epoch: 11 [76800/110534 (69%)]\tClassification Loss: 1.5545\r\n",
      "Train Epoch: 11 [78720/110534 (71%)]\tClassification Loss: 1.5886\r\n",
      "Train Epoch: 11 [80640/110534 (73%)]\tClassification Loss: 1.5935\r\n",
      "Train Epoch: 11 [82560/110534 (75%)]\tClassification Loss: 1.3822\r\n",
      "Train Epoch: 11 [84480/110534 (76%)]\tClassification Loss: 1.4455\r\n",
      "Train Epoch: 11 [86400/110534 (78%)]\tClassification Loss: 1.5790\r\n",
      "Train Epoch: 11 [88320/110534 (80%)]\tClassification Loss: 1.9307\r\n",
      "Train Epoch: 11 [90240/110534 (82%)]\tClassification Loss: 1.6768\r\n",
      "Train Epoch: 11 [92160/110534 (83%)]\tClassification Loss: 1.8503\r\n",
      "Train Epoch: 11 [94080/110534 (85%)]\tClassification Loss: 1.7261\r\n",
      "Train Epoch: 11 [96000/110534 (87%)]\tClassification Loss: 1.8220\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_11_1500.pth.tar\r\n",
      "Train Epoch: 11 [97920/110534 (89%)]\tClassification Loss: 1.5671\r\n",
      "Train Epoch: 11 [99840/110534 (90%)]\tClassification Loss: 1.6612\r\n",
      "Train Epoch: 11 [101760/110534 (92%)]\tClassification Loss: 1.4554\r\n",
      "Train Epoch: 11 [103680/110534 (94%)]\tClassification Loss: 1.7553\r\n",
      "Train Epoch: 11 [105600/110534 (96%)]\tClassification Loss: 1.5892\r\n",
      "Train Epoch: 11 [107520/110534 (97%)]\tClassification Loss: 1.4169\r\n",
      "Train Epoch: 11 [109440/110534 (99%)]\tClassification Loss: 1.5526\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_11_final.pth.tar\r\n",
      "Train Epoch: 12 [0/110534 (0%)]\tClassification Loss: 1.6434\r\n",
      "\r\n",
      "Test set: Average loss: 1.4665, Accuracy: 22818/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 12 [1920/110534 (2%)]\tClassification Loss: 1.3535\r\n",
      "Train Epoch: 12 [3840/110534 (3%)]\tClassification Loss: 1.5947\r\n",
      "Train Epoch: 12 [5760/110534 (5%)]\tClassification Loss: 1.7704\r\n",
      "Train Epoch: 12 [7680/110534 (7%)]\tClassification Loss: 1.5023\r\n",
      "Train Epoch: 12 [9600/110534 (9%)]\tClassification Loss: 1.5759\r\n",
      "Train Epoch: 12 [11520/110534 (10%)]\tClassification Loss: 1.8303\r\n",
      "Train Epoch: 12 [13440/110534 (12%)]\tClassification Loss: 1.6766\r\n",
      "Train Epoch: 12 [15360/110534 (14%)]\tClassification Loss: 1.7707\r\n",
      "Train Epoch: 12 [17280/110534 (16%)]\tClassification Loss: 1.7196\r\n",
      "Train Epoch: 12 [19200/110534 (17%)]\tClassification Loss: 1.8251\r\n",
      "Train Epoch: 12 [21120/110534 (19%)]\tClassification Loss: 1.5835\r\n",
      "Train Epoch: 12 [23040/110534 (21%)]\tClassification Loss: 1.3804\r\n",
      "Train Epoch: 12 [24960/110534 (23%)]\tClassification Loss: 1.5645\r\n",
      "Train Epoch: 12 [26880/110534 (24%)]\tClassification Loss: 1.5498\r\n",
      "Train Epoch: 12 [28800/110534 (26%)]\tClassification Loss: 1.9912\r\n",
      "Train Epoch: 12 [30720/110534 (28%)]\tClassification Loss: 1.5153\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_12_500.pth.tar\r\n",
      "Train Epoch: 12 [32640/110534 (30%)]\tClassification Loss: 1.4368\r\n",
      "Train Epoch: 12 [34560/110534 (31%)]\tClassification Loss: 1.4457\r\n",
      "Train Epoch: 12 [36480/110534 (33%)]\tClassification Loss: 1.2924\r\n",
      "Train Epoch: 12 [38400/110534 (35%)]\tClassification Loss: 1.5620\r\n",
      "Train Epoch: 12 [40320/110534 (36%)]\tClassification Loss: 1.5428\r\n",
      "Train Epoch: 12 [42240/110534 (38%)]\tClassification Loss: 1.5992\r\n",
      "Train Epoch: 12 [44160/110534 (40%)]\tClassification Loss: 1.4041\r\n",
      "Train Epoch: 12 [46080/110534 (42%)]\tClassification Loss: 1.4028\r\n",
      "Train Epoch: 12 [48000/110534 (43%)]\tClassification Loss: 1.6004\r\n",
      "Train Epoch: 12 [49920/110534 (45%)]\tClassification Loss: 1.6798\r\n",
      "Train Epoch: 12 [51840/110534 (47%)]\tClassification Loss: 1.7226\r\n",
      "Train Epoch: 12 [53760/110534 (49%)]\tClassification Loss: 1.5461\r\n",
      "Train Epoch: 12 [55680/110534 (50%)]\tClassification Loss: 1.6823\r\n",
      "Train Epoch: 12 [57600/110534 (52%)]\tClassification Loss: 1.5363\r\n",
      "Train Epoch: 12 [59520/110534 (54%)]\tClassification Loss: 1.8885\r\n",
      "Train Epoch: 12 [61440/110534 (56%)]\tClassification Loss: 1.5745\r\n",
      "Train Epoch: 12 [63360/110534 (57%)]\tClassification Loss: 1.6065\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_12_1000.pth.tar\r\n",
      "Train Epoch: 12 [65280/110534 (59%)]\tClassification Loss: 1.5790\r\n",
      "Train Epoch: 12 [67200/110534 (61%)]\tClassification Loss: 1.5137\r\n",
      "Train Epoch: 12 [69120/110534 (63%)]\tClassification Loss: 1.6745\r\n",
      "Train Epoch: 12 [71040/110534 (64%)]\tClassification Loss: 1.6477\r\n",
      "Train Epoch: 12 [72960/110534 (66%)]\tClassification Loss: 1.4289\r\n",
      "Train Epoch: 12 [74880/110534 (68%)]\tClassification Loss: 1.4349\r\n",
      "Train Epoch: 12 [76800/110534 (69%)]\tClassification Loss: 1.4723\r\n",
      "Train Epoch: 12 [78720/110534 (71%)]\tClassification Loss: 1.5181\r\n",
      "Train Epoch: 12 [80640/110534 (73%)]\tClassification Loss: 1.7457\r\n",
      "Train Epoch: 12 [82560/110534 (75%)]\tClassification Loss: 1.3805\r\n",
      "Train Epoch: 12 [84480/110534 (76%)]\tClassification Loss: 1.5221\r\n",
      "Train Epoch: 12 [86400/110534 (78%)]\tClassification Loss: 1.5496\r\n",
      "Train Epoch: 12 [88320/110534 (80%)]\tClassification Loss: 1.7867\r\n",
      "Train Epoch: 12 [90240/110534 (82%)]\tClassification Loss: 1.9297\r\n",
      "Train Epoch: 12 [92160/110534 (83%)]\tClassification Loss: 1.8566\r\n",
      "Train Epoch: 12 [94080/110534 (85%)]\tClassification Loss: 1.6881\r\n",
      "Train Epoch: 12 [96000/110534 (87%)]\tClassification Loss: 1.7651\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_12_1500.pth.tar\r\n",
      "Train Epoch: 12 [97920/110534 (89%)]\tClassification Loss: 1.6528\r\n",
      "Train Epoch: 12 [99840/110534 (90%)]\tClassification Loss: 1.5615\r\n",
      "Train Epoch: 12 [101760/110534 (92%)]\tClassification Loss: 1.3403\r\n",
      "Train Epoch: 12 [103680/110534 (94%)]\tClassification Loss: 1.7209\r\n",
      "Train Epoch: 12 [105600/110534 (96%)]\tClassification Loss: 1.5789\r\n",
      "Train Epoch: 12 [107520/110534 (97%)]\tClassification Loss: 1.5187\r\n",
      "Train Epoch: 12 [109440/110534 (99%)]\tClassification Loss: 1.5758\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_12_final.pth.tar\r\n",
      "Train Epoch: 13 [0/110534 (0%)]\tClassification Loss: 1.5481\r\n",
      "\r\n",
      "Test set: Average loss: 1.4671, Accuracy: 22771/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 13 [1920/110534 (2%)]\tClassification Loss: 1.3480\r\n",
      "Train Epoch: 13 [3840/110534 (3%)]\tClassification Loss: 1.5841\r\n",
      "Train Epoch: 13 [5760/110534 (5%)]\tClassification Loss: 1.5996\r\n",
      "Train Epoch: 13 [7680/110534 (7%)]\tClassification Loss: 1.6026\r\n",
      "Train Epoch: 13 [9600/110534 (9%)]\tClassification Loss: 1.5225\r\n",
      "Train Epoch: 13 [11520/110534 (10%)]\tClassification Loss: 1.7445\r\n",
      "Train Epoch: 13 [13440/110534 (12%)]\tClassification Loss: 1.7061\r\n",
      "Train Epoch: 13 [15360/110534 (14%)]\tClassification Loss: 1.7707\r\n",
      "Train Epoch: 13 [17280/110534 (16%)]\tClassification Loss: 1.7158\r\n",
      "Train Epoch: 13 [19200/110534 (17%)]\tClassification Loss: 2.0507\r\n",
      "Train Epoch: 13 [21120/110534 (19%)]\tClassification Loss: 1.3883\r\n",
      "Train Epoch: 13 [23040/110534 (21%)]\tClassification Loss: 1.3829\r\n",
      "Train Epoch: 13 [24960/110534 (23%)]\tClassification Loss: 1.6204\r\n",
      "Train Epoch: 13 [26880/110534 (24%)]\tClassification Loss: 1.6880\r\n",
      "Train Epoch: 13 [28800/110534 (26%)]\tClassification Loss: 2.0507\r\n",
      "Train Epoch: 13 [30720/110534 (28%)]\tClassification Loss: 1.4934\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_13_500.pth.tar\r\n",
      "Train Epoch: 13 [32640/110534 (30%)]\tClassification Loss: 1.6667\r\n",
      "Train Epoch: 13 [34560/110534 (31%)]\tClassification Loss: 1.4922\r\n",
      "Train Epoch: 13 [36480/110534 (33%)]\tClassification Loss: 1.5099\r\n",
      "Train Epoch: 13 [38400/110534 (35%)]\tClassification Loss: 1.5378\r\n",
      "Train Epoch: 13 [40320/110534 (36%)]\tClassification Loss: 1.4433\r\n",
      "Train Epoch: 13 [42240/110534 (38%)]\tClassification Loss: 1.3724\r\n",
      "Train Epoch: 13 [44160/110534 (40%)]\tClassification Loss: 1.4358\r\n",
      "Train Epoch: 13 [46080/110534 (42%)]\tClassification Loss: 1.4686\r\n",
      "Train Epoch: 13 [48000/110534 (43%)]\tClassification Loss: 1.7063\r\n",
      "Train Epoch: 13 [49920/110534 (45%)]\tClassification Loss: 1.7141\r\n",
      "Train Epoch: 13 [51840/110534 (47%)]\tClassification Loss: 1.7501\r\n",
      "Train Epoch: 13 [53760/110534 (49%)]\tClassification Loss: 1.4478\r\n",
      "Train Epoch: 13 [55680/110534 (50%)]\tClassification Loss: 1.6502\r\n",
      "Train Epoch: 13 [57600/110534 (52%)]\tClassification Loss: 1.4209\r\n",
      "Train Epoch: 13 [59520/110534 (54%)]\tClassification Loss: 1.8057\r\n",
      "Train Epoch: 13 [61440/110534 (56%)]\tClassification Loss: 1.4342\r\n",
      "Train Epoch: 13 [63360/110534 (57%)]\tClassification Loss: 1.6945\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_13_1000.pth.tar\r\n",
      "Train Epoch: 13 [65280/110534 (59%)]\tClassification Loss: 1.6716\r\n",
      "Train Epoch: 13 [67200/110534 (61%)]\tClassification Loss: 1.3902\r\n",
      "Train Epoch: 13 [69120/110534 (63%)]\tClassification Loss: 1.5943\r\n",
      "Train Epoch: 13 [71040/110534 (64%)]\tClassification Loss: 1.4424\r\n",
      "Train Epoch: 13 [72960/110534 (66%)]\tClassification Loss: 1.4672\r\n",
      "Train Epoch: 13 [74880/110534 (68%)]\tClassification Loss: 1.4947\r\n",
      "Train Epoch: 13 [76800/110534 (69%)]\tClassification Loss: 1.5023\r\n",
      "Train Epoch: 13 [78720/110534 (71%)]\tClassification Loss: 1.4978\r\n",
      "Train Epoch: 13 [80640/110534 (73%)]\tClassification Loss: 1.6524\r\n",
      "Train Epoch: 13 [82560/110534 (75%)]\tClassification Loss: 1.4782\r\n",
      "Train Epoch: 13 [84480/110534 (76%)]\tClassification Loss: 1.4963\r\n",
      "Train Epoch: 13 [86400/110534 (78%)]\tClassification Loss: 1.4657\r\n",
      "Train Epoch: 13 [88320/110534 (80%)]\tClassification Loss: 1.6375\r\n",
      "Train Epoch: 13 [90240/110534 (82%)]\tClassification Loss: 1.6634\r\n",
      "Train Epoch: 13 [92160/110534 (83%)]\tClassification Loss: 1.7891\r\n",
      "Train Epoch: 13 [94080/110534 (85%)]\tClassification Loss: 1.6743\r\n",
      "Train Epoch: 13 [96000/110534 (87%)]\tClassification Loss: 1.6732\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_13_1500.pth.tar\r\n",
      "Train Epoch: 13 [97920/110534 (89%)]\tClassification Loss: 1.5834\r\n",
      "Train Epoch: 13 [99840/110534 (90%)]\tClassification Loss: 1.7181\r\n",
      "Train Epoch: 13 [101760/110534 (92%)]\tClassification Loss: 1.4433\r\n",
      "Train Epoch: 13 [103680/110534 (94%)]\tClassification Loss: 1.6484\r\n",
      "Train Epoch: 13 [105600/110534 (96%)]\tClassification Loss: 1.6447\r\n",
      "Train Epoch: 13 [107520/110534 (97%)]\tClassification Loss: 1.5383\r\n",
      "Train Epoch: 13 [109440/110534 (99%)]\tClassification Loss: 1.6224\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_13_final.pth.tar\r\n",
      "Train Epoch: 14 [0/110534 (0%)]\tClassification Loss: 1.7039\r\n",
      "\r\n",
      "Test set: Average loss: 1.4636, Accuracy: 22781/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 14 [1920/110534 (2%)]\tClassification Loss: 1.3985\r\n",
      "Train Epoch: 14 [3840/110534 (3%)]\tClassification Loss: 1.6074\r\n",
      "Train Epoch: 14 [5760/110534 (5%)]\tClassification Loss: 1.7190\r\n",
      "Train Epoch: 14 [7680/110534 (7%)]\tClassification Loss: 1.6089\r\n",
      "Train Epoch: 14 [9600/110534 (9%)]\tClassification Loss: 1.5080\r\n",
      "Train Epoch: 14 [11520/110534 (10%)]\tClassification Loss: 1.6958\r\n",
      "Train Epoch: 14 [13440/110534 (12%)]\tClassification Loss: 1.6147\r\n",
      "Train Epoch: 14 [15360/110534 (14%)]\tClassification Loss: 1.8211\r\n",
      "Train Epoch: 14 [17280/110534 (16%)]\tClassification Loss: 1.8565\r\n",
      "Train Epoch: 14 [19200/110534 (17%)]\tClassification Loss: 1.9132\r\n",
      "Train Epoch: 14 [21120/110534 (19%)]\tClassification Loss: 1.5626\r\n",
      "Train Epoch: 14 [23040/110534 (21%)]\tClassification Loss: 1.4359\r\n",
      "Train Epoch: 14 [24960/110534 (23%)]\tClassification Loss: 1.6245\r\n",
      "Train Epoch: 14 [26880/110534 (24%)]\tClassification Loss: 1.6062\r\n",
      "Train Epoch: 14 [28800/110534 (26%)]\tClassification Loss: 1.8913\r\n",
      "Train Epoch: 14 [30720/110534 (28%)]\tClassification Loss: 1.5351\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_14_500.pth.tar\r\n",
      "Train Epoch: 14 [32640/110534 (30%)]\tClassification Loss: 1.4333\r\n",
      "Train Epoch: 14 [34560/110534 (31%)]\tClassification Loss: 1.4060\r\n",
      "Train Epoch: 14 [36480/110534 (33%)]\tClassification Loss: 1.4435\r\n",
      "Train Epoch: 14 [38400/110534 (35%)]\tClassification Loss: 1.4862\r\n",
      "Train Epoch: 14 [40320/110534 (36%)]\tClassification Loss: 1.4931\r\n",
      "Train Epoch: 14 [42240/110534 (38%)]\tClassification Loss: 1.5578\r\n",
      "Train Epoch: 14 [44160/110534 (40%)]\tClassification Loss: 1.5239\r\n",
      "Train Epoch: 14 [46080/110534 (42%)]\tClassification Loss: 1.3613\r\n",
      "Train Epoch: 14 [48000/110534 (43%)]\tClassification Loss: 1.5513\r\n",
      "Train Epoch: 14 [49920/110534 (45%)]\tClassification Loss: 1.6118\r\n",
      "Train Epoch: 14 [51840/110534 (47%)]\tClassification Loss: 1.7837\r\n",
      "Train Epoch: 14 [53760/110534 (49%)]\tClassification Loss: 1.5613\r\n",
      "Train Epoch: 14 [55680/110534 (50%)]\tClassification Loss: 1.5477\r\n",
      "Train Epoch: 14 [57600/110534 (52%)]\tClassification Loss: 1.6255\r\n",
      "Train Epoch: 14 [59520/110534 (54%)]\tClassification Loss: 1.7720\r\n",
      "Train Epoch: 14 [61440/110534 (56%)]\tClassification Loss: 1.6008\r\n",
      "Train Epoch: 14 [63360/110534 (57%)]\tClassification Loss: 1.7337\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_14_1000.pth.tar\r\n",
      "Train Epoch: 14 [65280/110534 (59%)]\tClassification Loss: 1.5905\r\n",
      "Train Epoch: 14 [67200/110534 (61%)]\tClassification Loss: 1.4419\r\n",
      "Train Epoch: 14 [69120/110534 (63%)]\tClassification Loss: 1.5300\r\n",
      "Train Epoch: 14 [71040/110534 (64%)]\tClassification Loss: 1.5133\r\n",
      "Train Epoch: 14 [72960/110534 (66%)]\tClassification Loss: 1.4019\r\n",
      "Train Epoch: 14 [74880/110534 (68%)]\tClassification Loss: 1.5641\r\n",
      "Train Epoch: 14 [76800/110534 (69%)]\tClassification Loss: 1.5187\r\n",
      "Train Epoch: 14 [78720/110534 (71%)]\tClassification Loss: 1.4182\r\n",
      "Train Epoch: 14 [80640/110534 (73%)]\tClassification Loss: 1.6804\r\n",
      "Train Epoch: 14 [82560/110534 (75%)]\tClassification Loss: 1.3230\r\n",
      "Train Epoch: 14 [84480/110534 (76%)]\tClassification Loss: 1.4761\r\n",
      "Train Epoch: 14 [86400/110534 (78%)]\tClassification Loss: 1.4703\r\n",
      "Train Epoch: 14 [88320/110534 (80%)]\tClassification Loss: 1.7919\r\n",
      "Train Epoch: 14 [90240/110534 (82%)]\tClassification Loss: 1.5632\r\n",
      "Train Epoch: 14 [92160/110534 (83%)]\tClassification Loss: 1.8912\r\n",
      "Train Epoch: 14 [94080/110534 (85%)]\tClassification Loss: 1.6779\r\n",
      "Train Epoch: 14 [96000/110534 (87%)]\tClassification Loss: 1.8365\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_14_1500.pth.tar\r\n",
      "Train Epoch: 14 [97920/110534 (89%)]\tClassification Loss: 1.4100\r\n",
      "Train Epoch: 14 [99840/110534 (90%)]\tClassification Loss: 1.5590\r\n",
      "Train Epoch: 14 [101760/110534 (92%)]\tClassification Loss: 1.4407\r\n",
      "Train Epoch: 14 [103680/110534 (94%)]\tClassification Loss: 1.6462\r\n",
      "Train Epoch: 14 [105600/110534 (96%)]\tClassification Loss: 1.5229\r\n",
      "Train Epoch: 14 [107520/110534 (97%)]\tClassification Loss: 1.4741\r\n",
      "Train Epoch: 14 [109440/110534 (99%)]\tClassification Loss: 1.5187\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_14_final.pth.tar\r\n",
      "Train Epoch: 15 [0/110534 (0%)]\tClassification Loss: 1.6241\r\n",
      "\r\n",
      "Test set: Average loss: 1.4645, Accuracy: 22739/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 15 [1920/110534 (2%)]\tClassification Loss: 1.4647\r\n",
      "Train Epoch: 15 [3840/110534 (3%)]\tClassification Loss: 1.6182\r\n",
      "Train Epoch: 15 [5760/110534 (5%)]\tClassification Loss: 1.6929\r\n",
      "Train Epoch: 15 [7680/110534 (7%)]\tClassification Loss: 1.4810\r\n",
      "Train Epoch: 15 [9600/110534 (9%)]\tClassification Loss: 1.7248\r\n",
      "Train Epoch: 15 [11520/110534 (10%)]\tClassification Loss: 1.7698\r\n",
      "Train Epoch: 15 [13440/110534 (12%)]\tClassification Loss: 1.6018\r\n",
      "Train Epoch: 15 [15360/110534 (14%)]\tClassification Loss: 1.7517\r\n",
      "Train Epoch: 15 [17280/110534 (16%)]\tClassification Loss: 1.8941\r\n",
      "Train Epoch: 15 [19200/110534 (17%)]\tClassification Loss: 1.9131\r\n",
      "Train Epoch: 15 [21120/110534 (19%)]\tClassification Loss: 1.6794\r\n",
      "Train Epoch: 15 [23040/110534 (21%)]\tClassification Loss: 1.3405\r\n",
      "Train Epoch: 15 [24960/110534 (23%)]\tClassification Loss: 1.5918\r\n",
      "Train Epoch: 15 [26880/110534 (24%)]\tClassification Loss: 1.5884\r\n",
      "Train Epoch: 15 [28800/110534 (26%)]\tClassification Loss: 1.9324\r\n",
      "Train Epoch: 15 [30720/110534 (28%)]\tClassification Loss: 1.4195\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_15_500.pth.tar\r\n",
      "Train Epoch: 15 [32640/110534 (30%)]\tClassification Loss: 1.5574\r\n",
      "Train Epoch: 15 [34560/110534 (31%)]\tClassification Loss: 1.3721\r\n",
      "Train Epoch: 15 [36480/110534 (33%)]\tClassification Loss: 1.3711\r\n",
      "Train Epoch: 15 [38400/110534 (35%)]\tClassification Loss: 1.6328\r\n",
      "Train Epoch: 15 [40320/110534 (36%)]\tClassification Loss: 1.5405\r\n",
      "Train Epoch: 15 [42240/110534 (38%)]\tClassification Loss: 1.6164\r\n",
      "Train Epoch: 15 [44160/110534 (40%)]\tClassification Loss: 1.5001\r\n",
      "Train Epoch: 15 [46080/110534 (42%)]\tClassification Loss: 1.4299\r\n",
      "Train Epoch: 15 [48000/110534 (43%)]\tClassification Loss: 1.6834\r\n",
      "Train Epoch: 15 [49920/110534 (45%)]\tClassification Loss: 1.5716\r\n",
      "Train Epoch: 15 [51840/110534 (47%)]\tClassification Loss: 1.8609\r\n",
      "Train Epoch: 15 [53760/110534 (49%)]\tClassification Loss: 1.5685\r\n",
      "Train Epoch: 15 [55680/110534 (50%)]\tClassification Loss: 1.5050\r\n",
      "Train Epoch: 15 [57600/110534 (52%)]\tClassification Loss: 1.5440\r\n",
      "Train Epoch: 15 [59520/110534 (54%)]\tClassification Loss: 1.9112\r\n",
      "Train Epoch: 15 [61440/110534 (56%)]\tClassification Loss: 1.6866\r\n",
      "Train Epoch: 15 [63360/110534 (57%)]\tClassification Loss: 1.6865\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_15_1000.pth.tar\r\n",
      "Train Epoch: 15 [65280/110534 (59%)]\tClassification Loss: 1.5776\r\n",
      "Train Epoch: 15 [67200/110534 (61%)]\tClassification Loss: 1.3272\r\n",
      "Train Epoch: 15 [69120/110534 (63%)]\tClassification Loss: 1.4623\r\n",
      "Train Epoch: 15 [71040/110534 (64%)]\tClassification Loss: 1.4967\r\n",
      "Train Epoch: 15 [72960/110534 (66%)]\tClassification Loss: 1.5280\r\n",
      "Train Epoch: 15 [74880/110534 (68%)]\tClassification Loss: 1.5108\r\n",
      "Train Epoch: 15 [76800/110534 (69%)]\tClassification Loss: 1.4281\r\n",
      "Train Epoch: 15 [78720/110534 (71%)]\tClassification Loss: 1.3695\r\n",
      "Train Epoch: 15 [80640/110534 (73%)]\tClassification Loss: 1.7212\r\n",
      "Train Epoch: 15 [82560/110534 (75%)]\tClassification Loss: 1.4917\r\n",
      "Train Epoch: 15 [84480/110534 (76%)]\tClassification Loss: 1.5168\r\n",
      "Train Epoch: 15 [86400/110534 (78%)]\tClassification Loss: 1.4642\r\n",
      "Train Epoch: 15 [88320/110534 (80%)]\tClassification Loss: 1.8294\r\n",
      "Train Epoch: 15 [90240/110534 (82%)]\tClassification Loss: 1.7686\r\n",
      "Train Epoch: 15 [92160/110534 (83%)]\tClassification Loss: 1.9586\r\n",
      "Train Epoch: 15 [94080/110534 (85%)]\tClassification Loss: 1.8045\r\n",
      "Train Epoch: 15 [96000/110534 (87%)]\tClassification Loss: 1.6413\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_15_1500.pth.tar\r\n",
      "Train Epoch: 15 [97920/110534 (89%)]\tClassification Loss: 1.6307\r\n",
      "Train Epoch: 15 [99840/110534 (90%)]\tClassification Loss: 1.5128\r\n",
      "Train Epoch: 15 [101760/110534 (92%)]\tClassification Loss: 1.3034\r\n",
      "Train Epoch: 15 [103680/110534 (94%)]\tClassification Loss: 1.6753\r\n",
      "Train Epoch: 15 [105600/110534 (96%)]\tClassification Loss: 1.4487\r\n",
      "Train Epoch: 15 [107520/110534 (97%)]\tClassification Loss: 1.6172\r\n",
      "Train Epoch: 15 [109440/110534 (99%)]\tClassification Loss: 1.7772\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_15_final.pth.tar\r\n",
      "Train Epoch: 16 [0/110534 (0%)]\tClassification Loss: 1.5467\r\n",
      "\r\n",
      "Test set: Average loss: 1.4630, Accuracy: 22760/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 16 [1920/110534 (2%)]\tClassification Loss: 1.4927\r\n",
      "Train Epoch: 16 [3840/110534 (3%)]\tClassification Loss: 1.5844\r\n",
      "Train Epoch: 16 [5760/110534 (5%)]\tClassification Loss: 1.8162\r\n",
      "Train Epoch: 16 [7680/110534 (7%)]\tClassification Loss: 1.5734\r\n",
      "Train Epoch: 16 [9600/110534 (9%)]\tClassification Loss: 1.7873\r\n",
      "Train Epoch: 16 [11520/110534 (10%)]\tClassification Loss: 1.7345\r\n",
      "Train Epoch: 16 [13440/110534 (12%)]\tClassification Loss: 1.7046\r\n",
      "Train Epoch: 16 [15360/110534 (14%)]\tClassification Loss: 1.8230\r\n",
      "Train Epoch: 16 [17280/110534 (16%)]\tClassification Loss: 1.8396\r\n",
      "Train Epoch: 16 [19200/110534 (17%)]\tClassification Loss: 1.9378\r\n",
      "Train Epoch: 16 [21120/110534 (19%)]\tClassification Loss: 1.5860\r\n",
      "Train Epoch: 16 [23040/110534 (21%)]\tClassification Loss: 1.4177\r\n",
      "Train Epoch: 16 [24960/110534 (23%)]\tClassification Loss: 1.5829\r\n",
      "Train Epoch: 16 [26880/110534 (24%)]\tClassification Loss: 1.6722\r\n",
      "Train Epoch: 16 [28800/110534 (26%)]\tClassification Loss: 2.0134\r\n",
      "Train Epoch: 16 [30720/110534 (28%)]\tClassification Loss: 1.3874\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_16_500.pth.tar\r\n",
      "Train Epoch: 16 [32640/110534 (30%)]\tClassification Loss: 1.5574\r\n",
      "Train Epoch: 16 [34560/110534 (31%)]\tClassification Loss: 1.4382\r\n",
      "Train Epoch: 16 [36480/110534 (33%)]\tClassification Loss: 1.4270\r\n",
      "Train Epoch: 16 [38400/110534 (35%)]\tClassification Loss: 1.5808\r\n",
      "Train Epoch: 16 [40320/110534 (36%)]\tClassification Loss: 1.5517\r\n",
      "Train Epoch: 16 [42240/110534 (38%)]\tClassification Loss: 1.4735\r\n",
      "Train Epoch: 16 [44160/110534 (40%)]\tClassification Loss: 1.4878\r\n",
      "Train Epoch: 16 [46080/110534 (42%)]\tClassification Loss: 1.5192\r\n",
      "Train Epoch: 16 [48000/110534 (43%)]\tClassification Loss: 1.6477\r\n",
      "Train Epoch: 16 [49920/110534 (45%)]\tClassification Loss: 1.5761\r\n",
      "Train Epoch: 16 [51840/110534 (47%)]\tClassification Loss: 1.7533\r\n",
      "Train Epoch: 16 [53760/110534 (49%)]\tClassification Loss: 1.3637\r\n",
      "Train Epoch: 16 [55680/110534 (50%)]\tClassification Loss: 1.6864\r\n",
      "Train Epoch: 16 [57600/110534 (52%)]\tClassification Loss: 1.5635\r\n",
      "Train Epoch: 16 [59520/110534 (54%)]\tClassification Loss: 1.9498\r\n",
      "Train Epoch: 16 [61440/110534 (56%)]\tClassification Loss: 1.7598\r\n",
      "Train Epoch: 16 [63360/110534 (57%)]\tClassification Loss: 1.6674\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_16_1000.pth.tar\r\n",
      "Train Epoch: 16 [65280/110534 (59%)]\tClassification Loss: 1.5729\r\n",
      "Train Epoch: 16 [67200/110534 (61%)]\tClassification Loss: 1.3945\r\n",
      "Train Epoch: 16 [69120/110534 (63%)]\tClassification Loss: 1.6542\r\n",
      "Train Epoch: 16 [71040/110534 (64%)]\tClassification Loss: 1.4715\r\n",
      "Train Epoch: 16 [72960/110534 (66%)]\tClassification Loss: 1.5020\r\n",
      "Train Epoch: 16 [74880/110534 (68%)]\tClassification Loss: 1.4929\r\n",
      "Train Epoch: 16 [76800/110534 (69%)]\tClassification Loss: 1.5636\r\n",
      "Train Epoch: 16 [78720/110534 (71%)]\tClassification Loss: 1.5854\r\n",
      "Train Epoch: 16 [80640/110534 (73%)]\tClassification Loss: 1.5788\r\n",
      "Train Epoch: 16 [82560/110534 (75%)]\tClassification Loss: 1.4622\r\n",
      "Train Epoch: 16 [84480/110534 (76%)]\tClassification Loss: 1.4881\r\n",
      "Train Epoch: 16 [86400/110534 (78%)]\tClassification Loss: 1.3770\r\n",
      "Train Epoch: 16 [88320/110534 (80%)]\tClassification Loss: 1.6782\r\n",
      "Train Epoch: 16 [90240/110534 (82%)]\tClassification Loss: 1.5735\r\n",
      "Train Epoch: 16 [92160/110534 (83%)]\tClassification Loss: 1.8727\r\n",
      "Train Epoch: 16 [94080/110534 (85%)]\tClassification Loss: 1.7638\r\n",
      "Train Epoch: 16 [96000/110534 (87%)]\tClassification Loss: 1.6020\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_16_1500.pth.tar\r\n",
      "Train Epoch: 16 [97920/110534 (89%)]\tClassification Loss: 1.6380\r\n",
      "Train Epoch: 16 [99840/110534 (90%)]\tClassification Loss: 1.6691\r\n",
      "Train Epoch: 16 [101760/110534 (92%)]\tClassification Loss: 1.4708\r\n",
      "Train Epoch: 16 [103680/110534 (94%)]\tClassification Loss: 1.7367\r\n",
      "Train Epoch: 16 [105600/110534 (96%)]\tClassification Loss: 1.6823\r\n",
      "Train Epoch: 16 [107520/110534 (97%)]\tClassification Loss: 1.5103\r\n",
      "Train Epoch: 16 [109440/110534 (99%)]\tClassification Loss: 1.6284\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_16_final.pth.tar\r\n",
      "Train Epoch: 17 [0/110534 (0%)]\tClassification Loss: 1.6324\r\n",
      "\r\n",
      "Test set: Average loss: 1.4624, Accuracy: 22730/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 17 [1920/110534 (2%)]\tClassification Loss: 1.4938\r\n",
      "Train Epoch: 17 [3840/110534 (3%)]\tClassification Loss: 1.6335\r\n",
      "Train Epoch: 17 [5760/110534 (5%)]\tClassification Loss: 1.8203\r\n",
      "Train Epoch: 17 [7680/110534 (7%)]\tClassification Loss: 1.5551\r\n",
      "Train Epoch: 17 [9600/110534 (9%)]\tClassification Loss: 1.6215\r\n",
      "Train Epoch: 17 [11520/110534 (10%)]\tClassification Loss: 1.7454\r\n",
      "Train Epoch: 17 [13440/110534 (12%)]\tClassification Loss: 1.5851\r\n",
      "Train Epoch: 17 [15360/110534 (14%)]\tClassification Loss: 1.8009\r\n",
      "Train Epoch: 17 [17280/110534 (16%)]\tClassification Loss: 1.8544\r\n",
      "Train Epoch: 17 [19200/110534 (17%)]\tClassification Loss: 1.7913\r\n",
      "Train Epoch: 17 [21120/110534 (19%)]\tClassification Loss: 1.4610\r\n",
      "Train Epoch: 17 [23040/110534 (21%)]\tClassification Loss: 1.5880\r\n",
      "Train Epoch: 17 [24960/110534 (23%)]\tClassification Loss: 1.5604\r\n",
      "Train Epoch: 17 [26880/110534 (24%)]\tClassification Loss: 1.6598\r\n",
      "Train Epoch: 17 [28800/110534 (26%)]\tClassification Loss: 1.9209\r\n",
      "Train Epoch: 17 [30720/110534 (28%)]\tClassification Loss: 1.4200\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_17_500.pth.tar\r\n",
      "Train Epoch: 17 [32640/110534 (30%)]\tClassification Loss: 1.4680\r\n",
      "Train Epoch: 17 [34560/110534 (31%)]\tClassification Loss: 1.2735\r\n",
      "Train Epoch: 17 [36480/110534 (33%)]\tClassification Loss: 1.5141\r\n",
      "Train Epoch: 17 [38400/110534 (35%)]\tClassification Loss: 1.4799\r\n",
      "Train Epoch: 17 [40320/110534 (36%)]\tClassification Loss: 1.5429\r\n",
      "Train Epoch: 17 [42240/110534 (38%)]\tClassification Loss: 1.5785\r\n",
      "Train Epoch: 17 [44160/110534 (40%)]\tClassification Loss: 1.4908\r\n",
      "Train Epoch: 17 [46080/110534 (42%)]\tClassification Loss: 1.5233\r\n",
      "Train Epoch: 17 [48000/110534 (43%)]\tClassification Loss: 1.6434\r\n",
      "Train Epoch: 17 [49920/110534 (45%)]\tClassification Loss: 1.6943\r\n",
      "Train Epoch: 17 [51840/110534 (47%)]\tClassification Loss: 1.8694\r\n",
      "Train Epoch: 17 [53760/110534 (49%)]\tClassification Loss: 1.4395\r\n",
      "Train Epoch: 17 [55680/110534 (50%)]\tClassification Loss: 1.6507\r\n",
      "Train Epoch: 17 [57600/110534 (52%)]\tClassification Loss: 1.5638\r\n",
      "Train Epoch: 17 [59520/110534 (54%)]\tClassification Loss: 1.7398\r\n",
      "Train Epoch: 17 [61440/110534 (56%)]\tClassification Loss: 1.5142\r\n",
      "Train Epoch: 17 [63360/110534 (57%)]\tClassification Loss: 1.8129\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_17_1000.pth.tar\r\n",
      "Train Epoch: 17 [65280/110534 (59%)]\tClassification Loss: 1.6559\r\n",
      "Train Epoch: 17 [67200/110534 (61%)]\tClassification Loss: 1.3864\r\n",
      "Train Epoch: 17 [69120/110534 (63%)]\tClassification Loss: 1.5413\r\n",
      "Train Epoch: 17 [71040/110534 (64%)]\tClassification Loss: 1.5882\r\n",
      "Train Epoch: 17 [72960/110534 (66%)]\tClassification Loss: 1.4373\r\n",
      "Train Epoch: 17 [74880/110534 (68%)]\tClassification Loss: 1.4553\r\n",
      "Train Epoch: 17 [76800/110534 (69%)]\tClassification Loss: 1.4671\r\n",
      "Train Epoch: 17 [78720/110534 (71%)]\tClassification Loss: 1.5338\r\n",
      "Train Epoch: 17 [80640/110534 (73%)]\tClassification Loss: 1.6248\r\n",
      "Train Epoch: 17 [82560/110534 (75%)]\tClassification Loss: 1.4376\r\n",
      "Train Epoch: 17 [84480/110534 (76%)]\tClassification Loss: 1.4040\r\n",
      "Train Epoch: 17 [86400/110534 (78%)]\tClassification Loss: 1.4290\r\n",
      "Train Epoch: 17 [88320/110534 (80%)]\tClassification Loss: 1.8999\r\n",
      "Train Epoch: 17 [90240/110534 (82%)]\tClassification Loss: 1.8329\r\n",
      "Train Epoch: 17 [92160/110534 (83%)]\tClassification Loss: 1.6627\r\n",
      "Train Epoch: 17 [94080/110534 (85%)]\tClassification Loss: 1.6389\r\n",
      "Train Epoch: 17 [96000/110534 (87%)]\tClassification Loss: 1.7462\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_17_1500.pth.tar\r\n",
      "Train Epoch: 17 [97920/110534 (89%)]\tClassification Loss: 1.5138\r\n",
      "Train Epoch: 17 [99840/110534 (90%)]\tClassification Loss: 1.6835\r\n",
      "Train Epoch: 17 [101760/110534 (92%)]\tClassification Loss: 1.3974\r\n",
      "Train Epoch: 17 [103680/110534 (94%)]\tClassification Loss: 1.6820\r\n",
      "Train Epoch: 17 [105600/110534 (96%)]\tClassification Loss: 1.5701\r\n",
      "Train Epoch: 17 [107520/110534 (97%)]\tClassification Loss: 1.5777\r\n",
      "Train Epoch: 17 [109440/110534 (99%)]\tClassification Loss: 1.6331\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_17_final.pth.tar\r\n",
      "Train Epoch: 18 [0/110534 (0%)]\tClassification Loss: 1.5921\r\n",
      "\r\n",
      "Test set: Average loss: 1.4634, Accuracy: 22688/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 18 [1920/110534 (2%)]\tClassification Loss: 1.4582\r\n",
      "Train Epoch: 18 [3840/110534 (3%)]\tClassification Loss: 1.6301\r\n",
      "Train Epoch: 18 [5760/110534 (5%)]\tClassification Loss: 1.7178\r\n",
      "Train Epoch: 18 [7680/110534 (7%)]\tClassification Loss: 1.4229\r\n",
      "Train Epoch: 18 [9600/110534 (9%)]\tClassification Loss: 1.6227\r\n",
      "Train Epoch: 18 [11520/110534 (10%)]\tClassification Loss: 1.7704\r\n",
      "Train Epoch: 18 [13440/110534 (12%)]\tClassification Loss: 1.5542\r\n",
      "Train Epoch: 18 [15360/110534 (14%)]\tClassification Loss: 2.0173\r\n",
      "Train Epoch: 18 [17280/110534 (16%)]\tClassification Loss: 1.7982\r\n",
      "Train Epoch: 18 [19200/110534 (17%)]\tClassification Loss: 1.8938\r\n",
      "Train Epoch: 18 [21120/110534 (19%)]\tClassification Loss: 1.5111\r\n",
      "Train Epoch: 18 [23040/110534 (21%)]\tClassification Loss: 1.5263\r\n",
      "Train Epoch: 18 [24960/110534 (23%)]\tClassification Loss: 1.6551\r\n",
      "Train Epoch: 18 [26880/110534 (24%)]\tClassification Loss: 1.5629\r\n",
      "Train Epoch: 18 [28800/110534 (26%)]\tClassification Loss: 1.9822\r\n",
      "Train Epoch: 18 [30720/110534 (28%)]\tClassification Loss: 1.4136\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_18_500.pth.tar\r\n",
      "Train Epoch: 18 [32640/110534 (30%)]\tClassification Loss: 1.7459\r\n",
      "Train Epoch: 18 [34560/110534 (31%)]\tClassification Loss: 1.4341\r\n",
      "Train Epoch: 18 [36480/110534 (33%)]\tClassification Loss: 1.4214\r\n",
      "Train Epoch: 18 [38400/110534 (35%)]\tClassification Loss: 1.4893\r\n",
      "Train Epoch: 18 [40320/110534 (36%)]\tClassification Loss: 1.6072\r\n",
      "Train Epoch: 18 [42240/110534 (38%)]\tClassification Loss: 1.6022\r\n",
      "Train Epoch: 18 [44160/110534 (40%)]\tClassification Loss: 1.4124\r\n",
      "Train Epoch: 18 [46080/110534 (42%)]\tClassification Loss: 1.4426\r\n",
      "Train Epoch: 18 [48000/110534 (43%)]\tClassification Loss: 1.6567\r\n",
      "Train Epoch: 18 [49920/110534 (45%)]\tClassification Loss: 1.6445\r\n",
      "Train Epoch: 18 [51840/110534 (47%)]\tClassification Loss: 1.8656\r\n",
      "Train Epoch: 18 [53760/110534 (49%)]\tClassification Loss: 1.3123\r\n",
      "Train Epoch: 18 [55680/110534 (50%)]\tClassification Loss: 1.5391\r\n",
      "Train Epoch: 18 [57600/110534 (52%)]\tClassification Loss: 1.5638\r\n",
      "Train Epoch: 18 [59520/110534 (54%)]\tClassification Loss: 1.8786\r\n",
      "Train Epoch: 18 [61440/110534 (56%)]\tClassification Loss: 1.5943\r\n",
      "Train Epoch: 18 [63360/110534 (57%)]\tClassification Loss: 1.6516\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_18_1000.pth.tar\r\n",
      "Train Epoch: 18 [65280/110534 (59%)]\tClassification Loss: 1.7530\r\n",
      "Train Epoch: 18 [67200/110534 (61%)]\tClassification Loss: 1.4332\r\n",
      "Train Epoch: 18 [69120/110534 (63%)]\tClassification Loss: 1.6370\r\n",
      "Train Epoch: 18 [71040/110534 (64%)]\tClassification Loss: 1.6269\r\n",
      "Train Epoch: 18 [72960/110534 (66%)]\tClassification Loss: 1.3793\r\n",
      "Train Epoch: 18 [74880/110534 (68%)]\tClassification Loss: 1.5287\r\n",
      "Train Epoch: 18 [76800/110534 (69%)]\tClassification Loss: 1.4541\r\n",
      "Train Epoch: 18 [78720/110534 (71%)]\tClassification Loss: 1.2687\r\n",
      "Train Epoch: 18 [80640/110534 (73%)]\tClassification Loss: 1.6496\r\n",
      "Train Epoch: 18 [82560/110534 (75%)]\tClassification Loss: 1.4488\r\n",
      "Train Epoch: 18 [84480/110534 (76%)]\tClassification Loss: 1.4758\r\n",
      "Train Epoch: 18 [86400/110534 (78%)]\tClassification Loss: 1.3291\r\n",
      "Train Epoch: 18 [88320/110534 (80%)]\tClassification Loss: 1.6777\r\n",
      "Train Epoch: 18 [90240/110534 (82%)]\tClassification Loss: 1.7709\r\n",
      "Train Epoch: 18 [92160/110534 (83%)]\tClassification Loss: 1.8417\r\n",
      "Train Epoch: 18 [94080/110534 (85%)]\tClassification Loss: 1.7957\r\n",
      "Train Epoch: 18 [96000/110534 (87%)]\tClassification Loss: 1.7096\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_18_1500.pth.tar\r\n",
      "Train Epoch: 18 [97920/110534 (89%)]\tClassification Loss: 1.5501\r\n",
      "Train Epoch: 18 [99840/110534 (90%)]\tClassification Loss: 1.5901\r\n",
      "Train Epoch: 18 [101760/110534 (92%)]\tClassification Loss: 1.3577\r\n",
      "Train Epoch: 18 [103680/110534 (94%)]\tClassification Loss: 1.6047\r\n",
      "Train Epoch: 18 [105600/110534 (96%)]\tClassification Loss: 1.5866\r\n",
      "Train Epoch: 18 [107520/110534 (97%)]\tClassification Loss: 1.4323\r\n",
      "Train Epoch: 18 [109440/110534 (99%)]\tClassification Loss: 1.6022\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_18_final.pth.tar\r\n",
      "Train Epoch: 19 [0/110534 (0%)]\tClassification Loss: 1.5519\r\n",
      "\r\n",
      "Test set: Average loss: 1.4641, Accuracy: 22692/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 19 [1920/110534 (2%)]\tClassification Loss: 1.4121\r\n",
      "Train Epoch: 19 [3840/110534 (3%)]\tClassification Loss: 1.5308\r\n",
      "Train Epoch: 19 [5760/110534 (5%)]\tClassification Loss: 1.7102\r\n",
      "Train Epoch: 19 [7680/110534 (7%)]\tClassification Loss: 1.4827\r\n",
      "Train Epoch: 19 [9600/110534 (9%)]\tClassification Loss: 1.6077\r\n",
      "Train Epoch: 19 [11520/110534 (10%)]\tClassification Loss: 1.8176\r\n",
      "Train Epoch: 19 [13440/110534 (12%)]\tClassification Loss: 1.7580\r\n",
      "Train Epoch: 19 [15360/110534 (14%)]\tClassification Loss: 1.7651\r\n",
      "Train Epoch: 19 [17280/110534 (16%)]\tClassification Loss: 1.8153\r\n",
      "Train Epoch: 19 [19200/110534 (17%)]\tClassification Loss: 1.9298\r\n",
      "Train Epoch: 19 [21120/110534 (19%)]\tClassification Loss: 1.5666\r\n",
      "Train Epoch: 19 [23040/110534 (21%)]\tClassification Loss: 1.4230\r\n",
      "Train Epoch: 19 [24960/110534 (23%)]\tClassification Loss: 1.6293\r\n",
      "Train Epoch: 19 [26880/110534 (24%)]\tClassification Loss: 1.6380\r\n",
      "Train Epoch: 19 [28800/110534 (26%)]\tClassification Loss: 1.9244\r\n",
      "Train Epoch: 19 [30720/110534 (28%)]\tClassification Loss: 1.6653\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_19_500.pth.tar\r\n",
      "Train Epoch: 19 [32640/110534 (30%)]\tClassification Loss: 1.4837\r\n",
      "Train Epoch: 19 [34560/110534 (31%)]\tClassification Loss: 1.5032\r\n",
      "Train Epoch: 19 [36480/110534 (33%)]\tClassification Loss: 1.4075\r\n",
      "Train Epoch: 19 [38400/110534 (35%)]\tClassification Loss: 1.5815\r\n",
      "Train Epoch: 19 [40320/110534 (36%)]\tClassification Loss: 1.4746\r\n",
      "Train Epoch: 19 [42240/110534 (38%)]\tClassification Loss: 1.3755\r\n",
      "Train Epoch: 19 [44160/110534 (40%)]\tClassification Loss: 1.4178\r\n",
      "Train Epoch: 19 [46080/110534 (42%)]\tClassification Loss: 1.4109\r\n",
      "Train Epoch: 19 [48000/110534 (43%)]\tClassification Loss: 1.6505\r\n",
      "Train Epoch: 19 [49920/110534 (45%)]\tClassification Loss: 1.6277\r\n",
      "Train Epoch: 19 [51840/110534 (47%)]\tClassification Loss: 1.7269\r\n",
      "Train Epoch: 19 [53760/110534 (49%)]\tClassification Loss: 1.3165\r\n",
      "Train Epoch: 19 [55680/110534 (50%)]\tClassification Loss: 1.7109\r\n",
      "Train Epoch: 19 [57600/110534 (52%)]\tClassification Loss: 1.3260\r\n",
      "Train Epoch: 19 [59520/110534 (54%)]\tClassification Loss: 1.8860\r\n",
      "Train Epoch: 19 [61440/110534 (56%)]\tClassification Loss: 1.6508\r\n",
      "Train Epoch: 19 [63360/110534 (57%)]\tClassification Loss: 1.7594\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_19_1000.pth.tar\r\n",
      "Train Epoch: 19 [65280/110534 (59%)]\tClassification Loss: 1.7354\r\n",
      "Train Epoch: 19 [67200/110534 (61%)]\tClassification Loss: 1.3880\r\n",
      "Train Epoch: 19 [69120/110534 (63%)]\tClassification Loss: 1.4945\r\n",
      "Train Epoch: 19 [71040/110534 (64%)]\tClassification Loss: 1.5420\r\n",
      "Train Epoch: 19 [72960/110534 (66%)]\tClassification Loss: 1.5355\r\n",
      "Train Epoch: 19 [74880/110534 (68%)]\tClassification Loss: 1.4243\r\n",
      "Train Epoch: 19 [76800/110534 (69%)]\tClassification Loss: 1.4935\r\n",
      "Train Epoch: 19 [78720/110534 (71%)]\tClassification Loss: 1.5023\r\n",
      "Train Epoch: 19 [80640/110534 (73%)]\tClassification Loss: 1.6068\r\n",
      "Train Epoch: 19 [82560/110534 (75%)]\tClassification Loss: 1.4141\r\n",
      "Train Epoch: 19 [84480/110534 (76%)]\tClassification Loss: 1.4646\r\n",
      "Train Epoch: 19 [86400/110534 (78%)]\tClassification Loss: 1.4860\r\n",
      "Train Epoch: 19 [88320/110534 (80%)]\tClassification Loss: 1.8087\r\n",
      "Train Epoch: 19 [90240/110534 (82%)]\tClassification Loss: 1.9112\r\n",
      "Train Epoch: 19 [92160/110534 (83%)]\tClassification Loss: 1.8837\r\n",
      "Train Epoch: 19 [94080/110534 (85%)]\tClassification Loss: 1.6379\r\n",
      "Train Epoch: 19 [96000/110534 (87%)]\tClassification Loss: 1.6964\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_19_1500.pth.tar\r\n",
      "Train Epoch: 19 [97920/110534 (89%)]\tClassification Loss: 1.4965\r\n",
      "Train Epoch: 19 [99840/110534 (90%)]\tClassification Loss: 1.6798\r\n",
      "Train Epoch: 19 [101760/110534 (92%)]\tClassification Loss: 1.4318\r\n",
      "Train Epoch: 19 [103680/110534 (94%)]\tClassification Loss: 1.7572\r\n",
      "Train Epoch: 19 [105600/110534 (96%)]\tClassification Loss: 1.6323\r\n",
      "Train Epoch: 19 [107520/110534 (97%)]\tClassification Loss: 1.4659\r\n",
      "Train Epoch: 19 [109440/110534 (99%)]\tClassification Loss: 1.5923\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_19_final.pth.tar\r\n",
      "Train Epoch: 20 [0/110534 (0%)]\tClassification Loss: 1.5890\r\n",
      "\r\n",
      "Test set: Average loss: 1.4598, Accuracy: 22732/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 20 [1920/110534 (2%)]\tClassification Loss: 1.5551\r\n",
      "Train Epoch: 20 [3840/110534 (3%)]\tClassification Loss: 1.6712\r\n",
      "Train Epoch: 20 [5760/110534 (5%)]\tClassification Loss: 1.7794\r\n",
      "Train Epoch: 20 [7680/110534 (7%)]\tClassification Loss: 1.4475\r\n",
      "Train Epoch: 20 [9600/110534 (9%)]\tClassification Loss: 1.6463\r\n",
      "Train Epoch: 20 [11520/110534 (10%)]\tClassification Loss: 1.7027\r\n",
      "Train Epoch: 20 [13440/110534 (12%)]\tClassification Loss: 1.6230\r\n",
      "Train Epoch: 20 [15360/110534 (14%)]\tClassification Loss: 1.6931\r\n",
      "Train Epoch: 20 [17280/110534 (16%)]\tClassification Loss: 1.7378\r\n",
      "Train Epoch: 20 [19200/110534 (17%)]\tClassification Loss: 1.7301\r\n",
      "Train Epoch: 20 [21120/110534 (19%)]\tClassification Loss: 1.3883\r\n",
      "Train Epoch: 20 [23040/110534 (21%)]\tClassification Loss: 1.3140\r\n",
      "Train Epoch: 20 [24960/110534 (23%)]\tClassification Loss: 1.5848\r\n",
      "Train Epoch: 20 [26880/110534 (24%)]\tClassification Loss: 1.6783\r\n",
      "Train Epoch: 20 [28800/110534 (26%)]\tClassification Loss: 1.9527\r\n",
      "Train Epoch: 20 [30720/110534 (28%)]\tClassification Loss: 1.4925\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_20_500.pth.tar\r\n",
      "Train Epoch: 20 [32640/110534 (30%)]\tClassification Loss: 1.5506\r\n",
      "Train Epoch: 20 [34560/110534 (31%)]\tClassification Loss: 1.5161\r\n",
      "Train Epoch: 20 [36480/110534 (33%)]\tClassification Loss: 1.4043\r\n",
      "Train Epoch: 20 [38400/110534 (35%)]\tClassification Loss: 1.4533\r\n",
      "Train Epoch: 20 [40320/110534 (36%)]\tClassification Loss: 1.4912\r\n",
      "Train Epoch: 20 [42240/110534 (38%)]\tClassification Loss: 1.5855\r\n",
      "Train Epoch: 20 [44160/110534 (40%)]\tClassification Loss: 1.3849\r\n",
      "Train Epoch: 20 [46080/110534 (42%)]\tClassification Loss: 1.5129\r\n",
      "Train Epoch: 20 [48000/110534 (43%)]\tClassification Loss: 1.7221\r\n",
      "Train Epoch: 20 [49920/110534 (45%)]\tClassification Loss: 1.6807\r\n",
      "Train Epoch: 20 [51840/110534 (47%)]\tClassification Loss: 1.7834\r\n",
      "Train Epoch: 20 [53760/110534 (49%)]\tClassification Loss: 1.5023\r\n",
      "Train Epoch: 20 [55680/110534 (50%)]\tClassification Loss: 1.5456\r\n",
      "Train Epoch: 20 [57600/110534 (52%)]\tClassification Loss: 1.5280\r\n",
      "Train Epoch: 20 [59520/110534 (54%)]\tClassification Loss: 1.8357\r\n",
      "Train Epoch: 20 [61440/110534 (56%)]\tClassification Loss: 1.5382\r\n",
      "Train Epoch: 20 [63360/110534 (57%)]\tClassification Loss: 1.7171\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_20_1000.pth.tar\r\n",
      "Train Epoch: 20 [65280/110534 (59%)]\tClassification Loss: 1.7156\r\n",
      "Train Epoch: 20 [67200/110534 (61%)]\tClassification Loss: 1.3478\r\n",
      "Train Epoch: 20 [69120/110534 (63%)]\tClassification Loss: 1.7488\r\n",
      "Train Epoch: 20 [71040/110534 (64%)]\tClassification Loss: 1.5606\r\n",
      "Train Epoch: 20 [72960/110534 (66%)]\tClassification Loss: 1.3449\r\n",
      "Train Epoch: 20 [74880/110534 (68%)]\tClassification Loss: 1.5931\r\n",
      "Train Epoch: 20 [76800/110534 (69%)]\tClassification Loss: 1.4100\r\n",
      "Train Epoch: 20 [78720/110534 (71%)]\tClassification Loss: 1.4531\r\n",
      "Train Epoch: 20 [80640/110534 (73%)]\tClassification Loss: 1.6597\r\n",
      "Train Epoch: 20 [82560/110534 (75%)]\tClassification Loss: 1.3303\r\n",
      "Train Epoch: 20 [84480/110534 (76%)]\tClassification Loss: 1.5013\r\n",
      "Train Epoch: 20 [86400/110534 (78%)]\tClassification Loss: 1.3590\r\n",
      "Train Epoch: 20 [88320/110534 (80%)]\tClassification Loss: 1.8078\r\n",
      "Train Epoch: 20 [90240/110534 (82%)]\tClassification Loss: 1.9623\r\n",
      "Train Epoch: 20 [92160/110534 (83%)]\tClassification Loss: 1.8152\r\n",
      "Train Epoch: 20 [94080/110534 (85%)]\tClassification Loss: 1.8370\r\n",
      "Train Epoch: 20 [96000/110534 (87%)]\tClassification Loss: 1.5386\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_20_1500.pth.tar\r\n",
      "Train Epoch: 20 [97920/110534 (89%)]\tClassification Loss: 1.4723\r\n",
      "Train Epoch: 20 [99840/110534 (90%)]\tClassification Loss: 1.5565\r\n",
      "Train Epoch: 20 [101760/110534 (92%)]\tClassification Loss: 1.4162\r\n",
      "Train Epoch: 20 [103680/110534 (94%)]\tClassification Loss: 1.7025\r\n",
      "Train Epoch: 20 [105600/110534 (96%)]\tClassification Loss: 1.5637\r\n",
      "Train Epoch: 20 [107520/110534 (97%)]\tClassification Loss: 1.6050\r\n",
      "Train Epoch: 20 [109440/110534 (99%)]\tClassification Loss: 1.5851\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_20_final.pth.tar\r\n",
      "Train Epoch: 21 [0/110534 (0%)]\tClassification Loss: 1.6838\r\n",
      "\r\n",
      "Test set: Average loss: 1.4594, Accuracy: 22677/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 21 [1920/110534 (2%)]\tClassification Loss: 1.4152\r\n",
      "Train Epoch: 21 [3840/110534 (3%)]\tClassification Loss: 1.7187\r\n",
      "Train Epoch: 21 [5760/110534 (5%)]\tClassification Loss: 1.6214\r\n",
      "Train Epoch: 21 [7680/110534 (7%)]\tClassification Loss: 1.5620\r\n",
      "Train Epoch: 21 [9600/110534 (9%)]\tClassification Loss: 1.6391\r\n",
      "Train Epoch: 21 [11520/110534 (10%)]\tClassification Loss: 1.7000\r\n",
      "Train Epoch: 21 [13440/110534 (12%)]\tClassification Loss: 1.5756\r\n",
      "Train Epoch: 21 [15360/110534 (14%)]\tClassification Loss: 1.7993\r\n",
      "Train Epoch: 21 [17280/110534 (16%)]\tClassification Loss: 1.8454\r\n",
      "Train Epoch: 21 [19200/110534 (17%)]\tClassification Loss: 1.8716\r\n",
      "Train Epoch: 21 [21120/110534 (19%)]\tClassification Loss: 1.6490\r\n",
      "Train Epoch: 21 [23040/110534 (21%)]\tClassification Loss: 1.5063\r\n",
      "Train Epoch: 21 [24960/110534 (23%)]\tClassification Loss: 1.5146\r\n",
      "Train Epoch: 21 [26880/110534 (24%)]\tClassification Loss: 1.5819\r\n",
      "Train Epoch: 21 [28800/110534 (26%)]\tClassification Loss: 1.9196\r\n",
      "Train Epoch: 21 [30720/110534 (28%)]\tClassification Loss: 1.5616\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_21_500.pth.tar\r\n",
      "Train Epoch: 21 [32640/110534 (30%)]\tClassification Loss: 1.4515\r\n",
      "Train Epoch: 21 [34560/110534 (31%)]\tClassification Loss: 1.4832\r\n",
      "Train Epoch: 21 [36480/110534 (33%)]\tClassification Loss: 1.4167\r\n",
      "Train Epoch: 21 [38400/110534 (35%)]\tClassification Loss: 1.6286\r\n",
      "Train Epoch: 21 [40320/110534 (36%)]\tClassification Loss: 1.5821\r\n",
      "Train Epoch: 21 [42240/110534 (38%)]\tClassification Loss: 1.5262\r\n",
      "Train Epoch: 21 [44160/110534 (40%)]\tClassification Loss: 1.4278\r\n",
      "Train Epoch: 21 [46080/110534 (42%)]\tClassification Loss: 1.5456\r\n",
      "Train Epoch: 21 [48000/110534 (43%)]\tClassification Loss: 1.5332\r\n",
      "Train Epoch: 21 [49920/110534 (45%)]\tClassification Loss: 1.6414\r\n",
      "Train Epoch: 21 [51840/110534 (47%)]\tClassification Loss: 1.8292\r\n",
      "Train Epoch: 21 [53760/110534 (49%)]\tClassification Loss: 1.4876\r\n",
      "Train Epoch: 21 [55680/110534 (50%)]\tClassification Loss: 1.5820\r\n",
      "Train Epoch: 21 [57600/110534 (52%)]\tClassification Loss: 1.6465\r\n",
      "Train Epoch: 21 [59520/110534 (54%)]\tClassification Loss: 1.9843\r\n",
      "Train Epoch: 21 [61440/110534 (56%)]\tClassification Loss: 1.7302\r\n",
      "Train Epoch: 21 [63360/110534 (57%)]\tClassification Loss: 1.6854\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_21_1000.pth.tar\r\n",
      "Train Epoch: 21 [65280/110534 (59%)]\tClassification Loss: 1.6510\r\n",
      "Train Epoch: 21 [67200/110534 (61%)]\tClassification Loss: 1.3341\r\n",
      "Train Epoch: 21 [69120/110534 (63%)]\tClassification Loss: 1.6271\r\n",
      "Train Epoch: 21 [71040/110534 (64%)]\tClassification Loss: 1.5955\r\n",
      "Train Epoch: 21 [72960/110534 (66%)]\tClassification Loss: 1.4790\r\n",
      "Train Epoch: 21 [74880/110534 (68%)]\tClassification Loss: 1.4214\r\n",
      "Train Epoch: 21 [76800/110534 (69%)]\tClassification Loss: 1.5087\r\n",
      "Train Epoch: 21 [78720/110534 (71%)]\tClassification Loss: 1.5363\r\n",
      "Train Epoch: 21 [80640/110534 (73%)]\tClassification Loss: 1.6024\r\n",
      "Train Epoch: 21 [82560/110534 (75%)]\tClassification Loss: 1.3218\r\n",
      "Train Epoch: 21 [84480/110534 (76%)]\tClassification Loss: 1.4069\r\n",
      "Train Epoch: 21 [86400/110534 (78%)]\tClassification Loss: 1.4559\r\n",
      "Train Epoch: 21 [88320/110534 (80%)]\tClassification Loss: 1.8895\r\n",
      "Train Epoch: 21 [90240/110534 (82%)]\tClassification Loss: 1.8623\r\n",
      "Train Epoch: 21 [92160/110534 (83%)]\tClassification Loss: 1.8869\r\n",
      "Train Epoch: 21 [94080/110534 (85%)]\tClassification Loss: 1.5831\r\n",
      "Train Epoch: 21 [96000/110534 (87%)]\tClassification Loss: 1.6966\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_21_1500.pth.tar\r\n",
      "Train Epoch: 21 [97920/110534 (89%)]\tClassification Loss: 1.7217\r\n",
      "Train Epoch: 21 [99840/110534 (90%)]\tClassification Loss: 1.5753\r\n",
      "Train Epoch: 21 [101760/110534 (92%)]\tClassification Loss: 1.5261\r\n",
      "Train Epoch: 21 [103680/110534 (94%)]\tClassification Loss: 1.5875\r\n",
      "Train Epoch: 21 [105600/110534 (96%)]\tClassification Loss: 1.5790\r\n",
      "Train Epoch: 21 [107520/110534 (97%)]\tClassification Loss: 1.5420\r\n",
      "Train Epoch: 21 [109440/110534 (99%)]\tClassification Loss: 1.7491\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_21_final.pth.tar\r\n",
      "Train Epoch: 22 [0/110534 (0%)]\tClassification Loss: 1.5215\r\n",
      "\r\n",
      "Test set: Average loss: 1.4589, Accuracy: 22701/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 22 [1920/110534 (2%)]\tClassification Loss: 1.4565\r\n",
      "Train Epoch: 22 [3840/110534 (3%)]\tClassification Loss: 1.5780\r\n",
      "Train Epoch: 22 [5760/110534 (5%)]\tClassification Loss: 1.5865\r\n",
      "Train Epoch: 22 [7680/110534 (7%)]\tClassification Loss: 1.5019\r\n",
      "Train Epoch: 22 [9600/110534 (9%)]\tClassification Loss: 1.7211\r\n",
      "Train Epoch: 22 [11520/110534 (10%)]\tClassification Loss: 1.7406\r\n",
      "Train Epoch: 22 [13440/110534 (12%)]\tClassification Loss: 1.5233\r\n",
      "Train Epoch: 22 [15360/110534 (14%)]\tClassification Loss: 1.8073\r\n",
      "Train Epoch: 22 [17280/110534 (16%)]\tClassification Loss: 1.7963\r\n",
      "Train Epoch: 22 [19200/110534 (17%)]\tClassification Loss: 2.0872\r\n",
      "Train Epoch: 22 [21120/110534 (19%)]\tClassification Loss: 1.6544\r\n",
      "Train Epoch: 22 [23040/110534 (21%)]\tClassification Loss: 1.3737\r\n",
      "Train Epoch: 22 [24960/110534 (23%)]\tClassification Loss: 1.8409\r\n",
      "Train Epoch: 22 [26880/110534 (24%)]\tClassification Loss: 1.5493\r\n",
      "Train Epoch: 22 [28800/110534 (26%)]\tClassification Loss: 1.9047\r\n",
      "Train Epoch: 22 [30720/110534 (28%)]\tClassification Loss: 1.4662\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_22_500.pth.tar\r\n",
      "Train Epoch: 22 [32640/110534 (30%)]\tClassification Loss: 1.4882\r\n",
      "Train Epoch: 22 [34560/110534 (31%)]\tClassification Loss: 1.4213\r\n",
      "Train Epoch: 22 [36480/110534 (33%)]\tClassification Loss: 1.4688\r\n",
      "Train Epoch: 22 [38400/110534 (35%)]\tClassification Loss: 1.3973\r\n",
      "Train Epoch: 22 [40320/110534 (36%)]\tClassification Loss: 1.4170\r\n",
      "Train Epoch: 22 [42240/110534 (38%)]\tClassification Loss: 1.4892\r\n",
      "Train Epoch: 22 [44160/110534 (40%)]\tClassification Loss: 1.4528\r\n",
      "Train Epoch: 22 [46080/110534 (42%)]\tClassification Loss: 1.6076\r\n",
      "Train Epoch: 22 [48000/110534 (43%)]\tClassification Loss: 1.7015\r\n",
      "Train Epoch: 22 [49920/110534 (45%)]\tClassification Loss: 1.6170\r\n",
      "Train Epoch: 22 [51840/110534 (47%)]\tClassification Loss: 1.6985\r\n",
      "Train Epoch: 22 [53760/110534 (49%)]\tClassification Loss: 1.4991\r\n",
      "Train Epoch: 22 [55680/110534 (50%)]\tClassification Loss: 1.4753\r\n",
      "Train Epoch: 22 [57600/110534 (52%)]\tClassification Loss: 1.5780\r\n",
      "Train Epoch: 22 [59520/110534 (54%)]\tClassification Loss: 2.1001\r\n",
      "Train Epoch: 22 [61440/110534 (56%)]\tClassification Loss: 1.6751\r\n",
      "Train Epoch: 22 [63360/110534 (57%)]\tClassification Loss: 1.6495\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_22_1000.pth.tar\r\n",
      "Train Epoch: 22 [65280/110534 (59%)]\tClassification Loss: 1.5789\r\n",
      "Train Epoch: 22 [67200/110534 (61%)]\tClassification Loss: 1.3480\r\n",
      "Train Epoch: 22 [69120/110534 (63%)]\tClassification Loss: 1.5857\r\n",
      "Train Epoch: 22 [71040/110534 (64%)]\tClassification Loss: 1.4335\r\n",
      "Train Epoch: 22 [72960/110534 (66%)]\tClassification Loss: 1.5815\r\n",
      "Train Epoch: 22 [74880/110534 (68%)]\tClassification Loss: 1.5561\r\n",
      "Train Epoch: 22 [76800/110534 (69%)]\tClassification Loss: 1.4126\r\n",
      "Train Epoch: 22 [78720/110534 (71%)]\tClassification Loss: 1.5007\r\n",
      "Train Epoch: 22 [80640/110534 (73%)]\tClassification Loss: 1.6014\r\n",
      "Train Epoch: 22 [82560/110534 (75%)]\tClassification Loss: 1.3831\r\n",
      "Train Epoch: 22 [84480/110534 (76%)]\tClassification Loss: 1.3980\r\n",
      "Train Epoch: 22 [86400/110534 (78%)]\tClassification Loss: 1.4913\r\n",
      "Train Epoch: 22 [88320/110534 (80%)]\tClassification Loss: 1.8510\r\n",
      "Train Epoch: 22 [90240/110534 (82%)]\tClassification Loss: 1.7845\r\n",
      "Train Epoch: 22 [92160/110534 (83%)]\tClassification Loss: 1.8824\r\n",
      "Train Epoch: 22 [94080/110534 (85%)]\tClassification Loss: 1.6067\r\n",
      "Train Epoch: 22 [96000/110534 (87%)]\tClassification Loss: 1.8110\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_22_1500.pth.tar\r\n",
      "Train Epoch: 22 [97920/110534 (89%)]\tClassification Loss: 1.5761\r\n",
      "Train Epoch: 22 [99840/110534 (90%)]\tClassification Loss: 1.7474\r\n",
      "Train Epoch: 22 [101760/110534 (92%)]\tClassification Loss: 1.4477\r\n",
      "Train Epoch: 22 [103680/110534 (94%)]\tClassification Loss: 1.6494\r\n",
      "Train Epoch: 22 [105600/110534 (96%)]\tClassification Loss: 1.5238\r\n",
      "Train Epoch: 22 [107520/110534 (97%)]\tClassification Loss: 1.3416\r\n",
      "Train Epoch: 22 [109440/110534 (99%)]\tClassification Loss: 1.7414\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_22_final.pth.tar\r\n",
      "Train Epoch: 23 [0/110534 (0%)]\tClassification Loss: 1.4170\r\n",
      "\r\n",
      "Test set: Average loss: 1.4584, Accuracy: 22731/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 23 [1920/110534 (2%)]\tClassification Loss: 1.4636\r\n",
      "Train Epoch: 23 [3840/110534 (3%)]\tClassification Loss: 1.6537\r\n",
      "Train Epoch: 23 [5760/110534 (5%)]\tClassification Loss: 1.5920\r\n",
      "Train Epoch: 23 [7680/110534 (7%)]\tClassification Loss: 1.4397\r\n",
      "Train Epoch: 23 [9600/110534 (9%)]\tClassification Loss: 1.6117\r\n",
      "Train Epoch: 23 [11520/110534 (10%)]\tClassification Loss: 1.7475\r\n",
      "Train Epoch: 23 [13440/110534 (12%)]\tClassification Loss: 1.5133\r\n",
      "Train Epoch: 23 [15360/110534 (14%)]\tClassification Loss: 1.8173\r\n",
      "Train Epoch: 23 [17280/110534 (16%)]\tClassification Loss: 1.8371\r\n",
      "Train Epoch: 23 [19200/110534 (17%)]\tClassification Loss: 1.6893\r\n",
      "Train Epoch: 23 [21120/110534 (19%)]\tClassification Loss: 1.6566\r\n",
      "Train Epoch: 23 [23040/110534 (21%)]\tClassification Loss: 1.3033\r\n",
      "Train Epoch: 23 [24960/110534 (23%)]\tClassification Loss: 1.5735\r\n",
      "Train Epoch: 23 [26880/110534 (24%)]\tClassification Loss: 1.6577\r\n",
      "Train Epoch: 23 [28800/110534 (26%)]\tClassification Loss: 1.8609\r\n",
      "Train Epoch: 23 [30720/110534 (28%)]\tClassification Loss: 1.5365\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_23_500.pth.tar\r\n",
      "Train Epoch: 23 [32640/110534 (30%)]\tClassification Loss: 1.3164\r\n",
      "Train Epoch: 23 [34560/110534 (31%)]\tClassification Loss: 1.3384\r\n",
      "Train Epoch: 23 [36480/110534 (33%)]\tClassification Loss: 1.4385\r\n",
      "Train Epoch: 23 [38400/110534 (35%)]\tClassification Loss: 1.4877\r\n",
      "Train Epoch: 23 [40320/110534 (36%)]\tClassification Loss: 1.5749\r\n",
      "Train Epoch: 23 [42240/110534 (38%)]\tClassification Loss: 1.4643\r\n",
      "Train Epoch: 23 [44160/110534 (40%)]\tClassification Loss: 1.4603\r\n",
      "Train Epoch: 23 [46080/110534 (42%)]\tClassification Loss: 1.4774\r\n",
      "Train Epoch: 23 [48000/110534 (43%)]\tClassification Loss: 1.6814\r\n",
      "Train Epoch: 23 [49920/110534 (45%)]\tClassification Loss: 1.7230\r\n",
      "Train Epoch: 23 [51840/110534 (47%)]\tClassification Loss: 1.8026\r\n",
      "Train Epoch: 23 [53760/110534 (49%)]\tClassification Loss: 1.4089\r\n",
      "Train Epoch: 23 [55680/110534 (50%)]\tClassification Loss: 1.5994\r\n",
      "Train Epoch: 23 [57600/110534 (52%)]\tClassification Loss: 1.8267\r\n",
      "Train Epoch: 23 [59520/110534 (54%)]\tClassification Loss: 1.9026\r\n",
      "Train Epoch: 23 [61440/110534 (56%)]\tClassification Loss: 1.5311\r\n",
      "Train Epoch: 23 [63360/110534 (57%)]\tClassification Loss: 1.7136\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_23_1000.pth.tar\r\n",
      "Train Epoch: 23 [65280/110534 (59%)]\tClassification Loss: 1.6789\r\n",
      "Train Epoch: 23 [67200/110534 (61%)]\tClassification Loss: 1.3451\r\n",
      "Train Epoch: 23 [69120/110534 (63%)]\tClassification Loss: 1.5392\r\n",
      "Train Epoch: 23 [71040/110534 (64%)]\tClassification Loss: 1.6257\r\n",
      "Train Epoch: 23 [72960/110534 (66%)]\tClassification Loss: 1.4435\r\n",
      "Train Epoch: 23 [74880/110534 (68%)]\tClassification Loss: 1.5468\r\n",
      "Train Epoch: 23 [76800/110534 (69%)]\tClassification Loss: 1.6486\r\n",
      "Train Epoch: 23 [78720/110534 (71%)]\tClassification Loss: 1.3892\r\n",
      "Train Epoch: 23 [80640/110534 (73%)]\tClassification Loss: 1.6924\r\n",
      "Train Epoch: 23 [82560/110534 (75%)]\tClassification Loss: 1.3777\r\n",
      "Train Epoch: 23 [84480/110534 (76%)]\tClassification Loss: 1.3186\r\n",
      "Train Epoch: 23 [86400/110534 (78%)]\tClassification Loss: 1.5810\r\n",
      "Train Epoch: 23 [88320/110534 (80%)]\tClassification Loss: 1.7812\r\n",
      "Train Epoch: 23 [90240/110534 (82%)]\tClassification Loss: 1.6854\r\n",
      "Train Epoch: 23 [92160/110534 (83%)]\tClassification Loss: 1.9077\r\n",
      "Train Epoch: 23 [94080/110534 (85%)]\tClassification Loss: 1.7815\r\n",
      "Train Epoch: 23 [96000/110534 (87%)]\tClassification Loss: 1.7049\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_23_1500.pth.tar\r\n",
      "Train Epoch: 23 [97920/110534 (89%)]\tClassification Loss: 1.5710\r\n",
      "Train Epoch: 23 [99840/110534 (90%)]\tClassification Loss: 1.6994\r\n",
      "Train Epoch: 23 [101760/110534 (92%)]\tClassification Loss: 1.4188\r\n",
      "Train Epoch: 23 [103680/110534 (94%)]\tClassification Loss: 1.5976\r\n",
      "Train Epoch: 23 [105600/110534 (96%)]\tClassification Loss: 1.5467\r\n",
      "Train Epoch: 23 [107520/110534 (97%)]\tClassification Loss: 1.4379\r\n",
      "Train Epoch: 23 [109440/110534 (99%)]\tClassification Loss: 1.8475\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_23_final.pth.tar\r\n",
      "Train Epoch: 24 [0/110534 (0%)]\tClassification Loss: 1.7323\r\n",
      "\r\n",
      "Test set: Average loss: 1.4563, Accuracy: 22722/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 24 [1920/110534 (2%)]\tClassification Loss: 1.4513\r\n",
      "Train Epoch: 24 [3840/110534 (3%)]\tClassification Loss: 1.5474\r\n",
      "Train Epoch: 24 [5760/110534 (5%)]\tClassification Loss: 1.7478\r\n",
      "Train Epoch: 24 [7680/110534 (7%)]\tClassification Loss: 1.6212\r\n",
      "Train Epoch: 24 [9600/110534 (9%)]\tClassification Loss: 1.6723\r\n",
      "Train Epoch: 24 [11520/110534 (10%)]\tClassification Loss: 1.6465\r\n",
      "Train Epoch: 24 [13440/110534 (12%)]\tClassification Loss: 1.6309\r\n",
      "Train Epoch: 24 [15360/110534 (14%)]\tClassification Loss: 1.8973\r\n",
      "Train Epoch: 24 [17280/110534 (16%)]\tClassification Loss: 1.9289\r\n",
      "Train Epoch: 24 [19200/110534 (17%)]\tClassification Loss: 1.7776\r\n",
      "Train Epoch: 24 [21120/110534 (19%)]\tClassification Loss: 1.5179\r\n",
      "Train Epoch: 24 [23040/110534 (21%)]\tClassification Loss: 1.5070\r\n",
      "Train Epoch: 24 [24960/110534 (23%)]\tClassification Loss: 1.7026\r\n",
      "Train Epoch: 24 [26880/110534 (24%)]\tClassification Loss: 1.5617\r\n",
      "Train Epoch: 24 [28800/110534 (26%)]\tClassification Loss: 1.9528\r\n",
      "Train Epoch: 24 [30720/110534 (28%)]\tClassification Loss: 1.5284\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_24_500.pth.tar\r\n",
      "Train Epoch: 24 [32640/110534 (30%)]\tClassification Loss: 1.3235\r\n",
      "Train Epoch: 24 [34560/110534 (31%)]\tClassification Loss: 1.4145\r\n",
      "Train Epoch: 24 [36480/110534 (33%)]\tClassification Loss: 1.3912\r\n",
      "Train Epoch: 24 [38400/110534 (35%)]\tClassification Loss: 1.4544\r\n",
      "Train Epoch: 24 [40320/110534 (36%)]\tClassification Loss: 1.5009\r\n",
      "Train Epoch: 24 [42240/110534 (38%)]\tClassification Loss: 1.4661\r\n",
      "Train Epoch: 24 [44160/110534 (40%)]\tClassification Loss: 1.5447\r\n",
      "Train Epoch: 24 [46080/110534 (42%)]\tClassification Loss: 1.4795\r\n",
      "Train Epoch: 24 [48000/110534 (43%)]\tClassification Loss: 1.6618\r\n",
      "Train Epoch: 24 [49920/110534 (45%)]\tClassification Loss: 1.6826\r\n",
      "Train Epoch: 24 [51840/110534 (47%)]\tClassification Loss: 1.8887\r\n",
      "Train Epoch: 24 [53760/110534 (49%)]\tClassification Loss: 1.5393\r\n",
      "Train Epoch: 24 [55680/110534 (50%)]\tClassification Loss: 1.5876\r\n",
      "Train Epoch: 24 [57600/110534 (52%)]\tClassification Loss: 1.5337\r\n",
      "Train Epoch: 24 [59520/110534 (54%)]\tClassification Loss: 1.7968\r\n",
      "Train Epoch: 24 [61440/110534 (56%)]\tClassification Loss: 1.5560\r\n",
      "Train Epoch: 24 [63360/110534 (57%)]\tClassification Loss: 1.6359\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_24_1000.pth.tar\r\n",
      "Train Epoch: 24 [65280/110534 (59%)]\tClassification Loss: 1.4580\r\n",
      "Train Epoch: 24 [67200/110534 (61%)]\tClassification Loss: 1.4106\r\n",
      "Train Epoch: 24 [69120/110534 (63%)]\tClassification Loss: 1.5251\r\n",
      "Train Epoch: 24 [71040/110534 (64%)]\tClassification Loss: 1.6491\r\n",
      "Train Epoch: 24 [72960/110534 (66%)]\tClassification Loss: 1.5036\r\n",
      "Train Epoch: 24 [74880/110534 (68%)]\tClassification Loss: 1.5311\r\n",
      "Train Epoch: 24 [76800/110534 (69%)]\tClassification Loss: 1.3254\r\n",
      "Train Epoch: 24 [78720/110534 (71%)]\tClassification Loss: 1.4687\r\n",
      "Train Epoch: 24 [80640/110534 (73%)]\tClassification Loss: 1.6860\r\n",
      "Train Epoch: 24 [82560/110534 (75%)]\tClassification Loss: 1.4041\r\n",
      "Train Epoch: 24 [84480/110534 (76%)]\tClassification Loss: 1.4063\r\n",
      "Train Epoch: 24 [86400/110534 (78%)]\tClassification Loss: 1.4009\r\n",
      "Train Epoch: 24 [88320/110534 (80%)]\tClassification Loss: 1.8868\r\n",
      "Train Epoch: 24 [90240/110534 (82%)]\tClassification Loss: 1.6086\r\n",
      "Train Epoch: 24 [92160/110534 (83%)]\tClassification Loss: 1.7591\r\n",
      "Train Epoch: 24 [94080/110534 (85%)]\tClassification Loss: 1.6438\r\n",
      "Train Epoch: 24 [96000/110534 (87%)]\tClassification Loss: 1.8213\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_24_1500.pth.tar\r\n",
      "Train Epoch: 24 [97920/110534 (89%)]\tClassification Loss: 1.3926\r\n",
      "Train Epoch: 24 [99840/110534 (90%)]\tClassification Loss: 1.7048\r\n",
      "Train Epoch: 24 [101760/110534 (92%)]\tClassification Loss: 1.5402\r\n",
      "Train Epoch: 24 [103680/110534 (94%)]\tClassification Loss: 1.7330\r\n",
      "Train Epoch: 24 [105600/110534 (96%)]\tClassification Loss: 1.4500\r\n",
      "Train Epoch: 24 [107520/110534 (97%)]\tClassification Loss: 1.5843\r\n",
      "Train Epoch: 24 [109440/110534 (99%)]\tClassification Loss: 1.5581\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_24_final.pth.tar\r\n",
      "Train Epoch: 25 [0/110534 (0%)]\tClassification Loss: 1.4072\r\n",
      "\r\n",
      "Test set: Average loss: 1.4583, Accuracy: 22706/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 25 [1920/110534 (2%)]\tClassification Loss: 1.4010\r\n",
      "Train Epoch: 25 [3840/110534 (3%)]\tClassification Loss: 1.5239\r\n",
      "Train Epoch: 25 [5760/110534 (5%)]\tClassification Loss: 1.6091\r\n",
      "Train Epoch: 25 [7680/110534 (7%)]\tClassification Loss: 1.5588\r\n",
      "Train Epoch: 25 [9600/110534 (9%)]\tClassification Loss: 1.6277\r\n",
      "Train Epoch: 25 [11520/110534 (10%)]\tClassification Loss: 1.8208\r\n",
      "Train Epoch: 25 [13440/110534 (12%)]\tClassification Loss: 1.5082\r\n",
      "Train Epoch: 25 [15360/110534 (14%)]\tClassification Loss: 1.8677\r\n",
      "Train Epoch: 25 [17280/110534 (16%)]\tClassification Loss: 1.7950\r\n",
      "Train Epoch: 25 [19200/110534 (17%)]\tClassification Loss: 2.0857\r\n",
      "Train Epoch: 25 [21120/110534 (19%)]\tClassification Loss: 1.6257\r\n",
      "Train Epoch: 25 [23040/110534 (21%)]\tClassification Loss: 1.3297\r\n",
      "Train Epoch: 25 [24960/110534 (23%)]\tClassification Loss: 1.5596\r\n",
      "Train Epoch: 25 [26880/110534 (24%)]\tClassification Loss: 1.6413\r\n",
      "Train Epoch: 25 [28800/110534 (26%)]\tClassification Loss: 1.9445\r\n",
      "Train Epoch: 25 [30720/110534 (28%)]\tClassification Loss: 1.4709\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_25_500.pth.tar\r\n",
      "Train Epoch: 25 [32640/110534 (30%)]\tClassification Loss: 1.5606\r\n",
      "Train Epoch: 25 [34560/110534 (31%)]\tClassification Loss: 1.4697\r\n",
      "Train Epoch: 25 [36480/110534 (33%)]\tClassification Loss: 1.2895\r\n",
      "Train Epoch: 25 [38400/110534 (35%)]\tClassification Loss: 1.3921\r\n",
      "Train Epoch: 25 [40320/110534 (36%)]\tClassification Loss: 1.3956\r\n",
      "Train Epoch: 25 [42240/110534 (38%)]\tClassification Loss: 1.4440\r\n",
      "Train Epoch: 25 [44160/110534 (40%)]\tClassification Loss: 1.6429\r\n",
      "Train Epoch: 25 [46080/110534 (42%)]\tClassification Loss: 1.6077\r\n",
      "Train Epoch: 25 [48000/110534 (43%)]\tClassification Loss: 1.6766\r\n",
      "Train Epoch: 25 [49920/110534 (45%)]\tClassification Loss: 1.7345\r\n",
      "Train Epoch: 25 [51840/110534 (47%)]\tClassification Loss: 1.8508\r\n",
      "Train Epoch: 25 [53760/110534 (49%)]\tClassification Loss: 1.6263\r\n",
      "Train Epoch: 25 [55680/110534 (50%)]\tClassification Loss: 1.6231\r\n",
      "Train Epoch: 25 [57600/110534 (52%)]\tClassification Loss: 1.6134\r\n",
      "Train Epoch: 25 [59520/110534 (54%)]\tClassification Loss: 1.7654\r\n",
      "Train Epoch: 25 [61440/110534 (56%)]\tClassification Loss: 1.6016\r\n",
      "Train Epoch: 25 [63360/110534 (57%)]\tClassification Loss: 1.8071\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_25_1000.pth.tar\r\n",
      "Train Epoch: 25 [65280/110534 (59%)]\tClassification Loss: 1.6725\r\n",
      "Train Epoch: 25 [67200/110534 (61%)]\tClassification Loss: 1.7134\r\n",
      "Train Epoch: 25 [69120/110534 (63%)]\tClassification Loss: 1.6831\r\n",
      "Train Epoch: 25 [71040/110534 (64%)]\tClassification Loss: 1.5068\r\n",
      "Train Epoch: 25 [72960/110534 (66%)]\tClassification Loss: 1.5912\r\n",
      "Train Epoch: 25 [74880/110534 (68%)]\tClassification Loss: 1.5014\r\n",
      "Train Epoch: 25 [76800/110534 (69%)]\tClassification Loss: 1.3506\r\n",
      "Train Epoch: 25 [78720/110534 (71%)]\tClassification Loss: 1.6732\r\n",
      "Train Epoch: 25 [80640/110534 (73%)]\tClassification Loss: 1.5241\r\n",
      "Train Epoch: 25 [82560/110534 (75%)]\tClassification Loss: 1.3798\r\n",
      "Train Epoch: 25 [84480/110534 (76%)]\tClassification Loss: 1.4966\r\n",
      "Train Epoch: 25 [86400/110534 (78%)]\tClassification Loss: 1.4306\r\n",
      "Train Epoch: 25 [88320/110534 (80%)]\tClassification Loss: 1.7824\r\n",
      "Train Epoch: 25 [90240/110534 (82%)]\tClassification Loss: 1.7080\r\n",
      "Train Epoch: 25 [92160/110534 (83%)]\tClassification Loss: 1.8000\r\n",
      "Train Epoch: 25 [94080/110534 (85%)]\tClassification Loss: 1.6471\r\n",
      "Train Epoch: 25 [96000/110534 (87%)]\tClassification Loss: 1.6170\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_25_1500.pth.tar\r\n",
      "Train Epoch: 25 [97920/110534 (89%)]\tClassification Loss: 1.5862\r\n",
      "Train Epoch: 25 [99840/110534 (90%)]\tClassification Loss: 1.6757\r\n",
      "Train Epoch: 25 [101760/110534 (92%)]\tClassification Loss: 1.4291\r\n",
      "Train Epoch: 25 [103680/110534 (94%)]\tClassification Loss: 1.7189\r\n",
      "Train Epoch: 25 [105600/110534 (96%)]\tClassification Loss: 1.5526\r\n",
      "Train Epoch: 25 [107520/110534 (97%)]\tClassification Loss: 1.4822\r\n",
      "Train Epoch: 25 [109440/110534 (99%)]\tClassification Loss: 1.6743\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_25_final.pth.tar\r\n",
      "Train Epoch: 26 [0/110534 (0%)]\tClassification Loss: 1.6478\r\n",
      "\r\n",
      "Test set: Average loss: 1.4540, Accuracy: 22768/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 26 [1920/110534 (2%)]\tClassification Loss: 1.5861\r\n",
      "Train Epoch: 26 [3840/110534 (3%)]\tClassification Loss: 1.5793\r\n",
      "Train Epoch: 26 [5760/110534 (5%)]\tClassification Loss: 1.6806\r\n",
      "Train Epoch: 26 [7680/110534 (7%)]\tClassification Loss: 1.5385\r\n",
      "Train Epoch: 26 [9600/110534 (9%)]\tClassification Loss: 1.7949\r\n",
      "Train Epoch: 26 [11520/110534 (10%)]\tClassification Loss: 1.8576\r\n",
      "Train Epoch: 26 [13440/110534 (12%)]\tClassification Loss: 1.6467\r\n",
      "Train Epoch: 26 [15360/110534 (14%)]\tClassification Loss: 1.7705\r\n",
      "Train Epoch: 26 [17280/110534 (16%)]\tClassification Loss: 1.7581\r\n",
      "Train Epoch: 26 [19200/110534 (17%)]\tClassification Loss: 1.9156\r\n",
      "Train Epoch: 26 [21120/110534 (19%)]\tClassification Loss: 1.4810\r\n",
      "Train Epoch: 26 [23040/110534 (21%)]\tClassification Loss: 1.6541\r\n",
      "Train Epoch: 26 [24960/110534 (23%)]\tClassification Loss: 1.4568\r\n",
      "Train Epoch: 26 [26880/110534 (24%)]\tClassification Loss: 1.6149\r\n",
      "Train Epoch: 26 [28800/110534 (26%)]\tClassification Loss: 2.0472\r\n",
      "Train Epoch: 26 [30720/110534 (28%)]\tClassification Loss: 1.5697\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_26_500.pth.tar\r\n",
      "Train Epoch: 26 [32640/110534 (30%)]\tClassification Loss: 1.4918\r\n",
      "Train Epoch: 26 [34560/110534 (31%)]\tClassification Loss: 1.4565\r\n",
      "Train Epoch: 26 [36480/110534 (33%)]\tClassification Loss: 1.2979\r\n",
      "Train Epoch: 26 [38400/110534 (35%)]\tClassification Loss: 1.4884\r\n",
      "Train Epoch: 26 [40320/110534 (36%)]\tClassification Loss: 1.3691\r\n",
      "Train Epoch: 26 [42240/110534 (38%)]\tClassification Loss: 1.4057\r\n",
      "Train Epoch: 26 [44160/110534 (40%)]\tClassification Loss: 1.6198\r\n",
      "Train Epoch: 26 [46080/110534 (42%)]\tClassification Loss: 1.5112\r\n",
      "Train Epoch: 26 [48000/110534 (43%)]\tClassification Loss: 1.5822\r\n",
      "Train Epoch: 26 [49920/110534 (45%)]\tClassification Loss: 1.8089\r\n",
      "Train Epoch: 26 [51840/110534 (47%)]\tClassification Loss: 1.7314\r\n",
      "Train Epoch: 26 [53760/110534 (49%)]\tClassification Loss: 1.4681\r\n",
      "Train Epoch: 26 [55680/110534 (50%)]\tClassification Loss: 1.5657\r\n",
      "Train Epoch: 26 [57600/110534 (52%)]\tClassification Loss: 1.5503\r\n",
      "Train Epoch: 26 [59520/110534 (54%)]\tClassification Loss: 1.7934\r\n",
      "Train Epoch: 26 [61440/110534 (56%)]\tClassification Loss: 1.6222\r\n",
      "Train Epoch: 26 [63360/110534 (57%)]\tClassification Loss: 1.7307\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_26_1000.pth.tar\r\n",
      "Train Epoch: 26 [65280/110534 (59%)]\tClassification Loss: 1.7064\r\n",
      "Train Epoch: 26 [67200/110534 (61%)]\tClassification Loss: 1.5347\r\n",
      "Train Epoch: 26 [69120/110534 (63%)]\tClassification Loss: 1.5957\r\n",
      "Train Epoch: 26 [71040/110534 (64%)]\tClassification Loss: 1.4940\r\n",
      "Train Epoch: 26 [72960/110534 (66%)]\tClassification Loss: 1.3200\r\n",
      "Train Epoch: 26 [74880/110534 (68%)]\tClassification Loss: 1.4885\r\n",
      "Train Epoch: 26 [76800/110534 (69%)]\tClassification Loss: 1.3604\r\n",
      "Train Epoch: 26 [78720/110534 (71%)]\tClassification Loss: 1.5241\r\n",
      "Train Epoch: 26 [80640/110534 (73%)]\tClassification Loss: 1.5376\r\n",
      "Train Epoch: 26 [82560/110534 (75%)]\tClassification Loss: 1.4687\r\n",
      "Train Epoch: 26 [84480/110534 (76%)]\tClassification Loss: 1.3703\r\n",
      "Train Epoch: 26 [86400/110534 (78%)]\tClassification Loss: 1.6294\r\n",
      "Train Epoch: 26 [88320/110534 (80%)]\tClassification Loss: 1.7894\r\n",
      "Train Epoch: 26 [90240/110534 (82%)]\tClassification Loss: 1.6922\r\n",
      "Train Epoch: 26 [92160/110534 (83%)]\tClassification Loss: 1.7864\r\n",
      "Train Epoch: 26 [94080/110534 (85%)]\tClassification Loss: 1.6972\r\n",
      "Train Epoch: 26 [96000/110534 (87%)]\tClassification Loss: 1.6437\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_26_1500.pth.tar\r\n",
      "Train Epoch: 26 [97920/110534 (89%)]\tClassification Loss: 1.7434\r\n",
      "Train Epoch: 26 [99840/110534 (90%)]\tClassification Loss: 1.5878\r\n",
      "Train Epoch: 26 [101760/110534 (92%)]\tClassification Loss: 1.5634\r\n",
      "Train Epoch: 26 [103680/110534 (94%)]\tClassification Loss: 1.6366\r\n",
      "Train Epoch: 26 [105600/110534 (96%)]\tClassification Loss: 1.3515\r\n",
      "Train Epoch: 26 [107520/110534 (97%)]\tClassification Loss: 1.5402\r\n",
      "Train Epoch: 26 [109440/110534 (99%)]\tClassification Loss: 1.6715\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_26_final.pth.tar\r\n",
      "Train Epoch: 27 [0/110534 (0%)]\tClassification Loss: 1.4377\r\n",
      "\r\n",
      "Test set: Average loss: 1.4569, Accuracy: 22742/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 27 [1920/110534 (2%)]\tClassification Loss: 1.5254\r\n",
      "Train Epoch: 27 [3840/110534 (3%)]\tClassification Loss: 1.6268\r\n",
      "Train Epoch: 27 [5760/110534 (5%)]\tClassification Loss: 1.8177\r\n",
      "Train Epoch: 27 [7680/110534 (7%)]\tClassification Loss: 1.4158\r\n",
      "Train Epoch: 27 [9600/110534 (9%)]\tClassification Loss: 1.6385\r\n",
      "Train Epoch: 27 [11520/110534 (10%)]\tClassification Loss: 1.7775\r\n",
      "Train Epoch: 27 [13440/110534 (12%)]\tClassification Loss: 1.4592\r\n",
      "Train Epoch: 27 [15360/110534 (14%)]\tClassification Loss: 1.8307\r\n",
      "Train Epoch: 27 [17280/110534 (16%)]\tClassification Loss: 1.7617\r\n",
      "Train Epoch: 27 [19200/110534 (17%)]\tClassification Loss: 1.8573\r\n",
      "Train Epoch: 27 [21120/110534 (19%)]\tClassification Loss: 1.5356\r\n",
      "Train Epoch: 27 [23040/110534 (21%)]\tClassification Loss: 1.5156\r\n",
      "Train Epoch: 27 [24960/110534 (23%)]\tClassification Loss: 1.4243\r\n",
      "Train Epoch: 27 [26880/110534 (24%)]\tClassification Loss: 1.6122\r\n",
      "Train Epoch: 27 [28800/110534 (26%)]\tClassification Loss: 2.0173\r\n",
      "Train Epoch: 27 [30720/110534 (28%)]\tClassification Loss: 1.5766\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_27_500.pth.tar\r\n",
      "Train Epoch: 27 [32640/110534 (30%)]\tClassification Loss: 1.4574\r\n",
      "Train Epoch: 27 [34560/110534 (31%)]\tClassification Loss: 1.3650\r\n",
      "Train Epoch: 27 [36480/110534 (33%)]\tClassification Loss: 1.3097\r\n",
      "Train Epoch: 27 [38400/110534 (35%)]\tClassification Loss: 1.5335\r\n",
      "Train Epoch: 27 [40320/110534 (36%)]\tClassification Loss: 1.5361\r\n",
      "Train Epoch: 27 [42240/110534 (38%)]\tClassification Loss: 1.3920\r\n",
      "Train Epoch: 27 [44160/110534 (40%)]\tClassification Loss: 1.4795\r\n",
      "Train Epoch: 27 [46080/110534 (42%)]\tClassification Loss: 1.5090\r\n",
      "Train Epoch: 27 [48000/110534 (43%)]\tClassification Loss: 1.6717\r\n",
      "Train Epoch: 27 [49920/110534 (45%)]\tClassification Loss: 1.7144\r\n",
      "Train Epoch: 27 [51840/110534 (47%)]\tClassification Loss: 1.8390\r\n",
      "Train Epoch: 27 [53760/110534 (49%)]\tClassification Loss: 1.6145\r\n",
      "Train Epoch: 27 [55680/110534 (50%)]\tClassification Loss: 1.5251\r\n",
      "Train Epoch: 27 [57600/110534 (52%)]\tClassification Loss: 1.6102\r\n",
      "Train Epoch: 27 [59520/110534 (54%)]\tClassification Loss: 1.9202\r\n",
      "Train Epoch: 27 [61440/110534 (56%)]\tClassification Loss: 1.6901\r\n",
      "Train Epoch: 27 [63360/110534 (57%)]\tClassification Loss: 1.8848\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_27_1000.pth.tar\r\n",
      "Train Epoch: 27 [65280/110534 (59%)]\tClassification Loss: 1.5525\r\n",
      "Train Epoch: 27 [67200/110534 (61%)]\tClassification Loss: 1.4197\r\n",
      "Train Epoch: 27 [69120/110534 (63%)]\tClassification Loss: 1.5680\r\n",
      "Train Epoch: 27 [71040/110534 (64%)]\tClassification Loss: 1.5927\r\n",
      "Train Epoch: 27 [72960/110534 (66%)]\tClassification Loss: 1.4543\r\n",
      "Train Epoch: 27 [74880/110534 (68%)]\tClassification Loss: 1.5290\r\n",
      "Train Epoch: 27 [76800/110534 (69%)]\tClassification Loss: 1.4593\r\n",
      "Train Epoch: 27 [78720/110534 (71%)]\tClassification Loss: 1.6028\r\n",
      "Train Epoch: 27 [80640/110534 (73%)]\tClassification Loss: 1.6633\r\n",
      "Train Epoch: 27 [82560/110534 (75%)]\tClassification Loss: 1.3439\r\n",
      "Train Epoch: 27 [84480/110534 (76%)]\tClassification Loss: 1.4713\r\n",
      "Train Epoch: 27 [86400/110534 (78%)]\tClassification Loss: 1.5142\r\n",
      "Train Epoch: 27 [88320/110534 (80%)]\tClassification Loss: 1.8217\r\n",
      "Train Epoch: 27 [90240/110534 (82%)]\tClassification Loss: 1.5774\r\n",
      "Train Epoch: 27 [92160/110534 (83%)]\tClassification Loss: 1.9092\r\n",
      "Train Epoch: 27 [94080/110534 (85%)]\tClassification Loss: 1.7215\r\n",
      "Train Epoch: 27 [96000/110534 (87%)]\tClassification Loss: 1.6768\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_27_1500.pth.tar\r\n",
      "Train Epoch: 27 [97920/110534 (89%)]\tClassification Loss: 1.6238\r\n",
      "Train Epoch: 27 [99840/110534 (90%)]\tClassification Loss: 1.6623\r\n",
      "Train Epoch: 27 [101760/110534 (92%)]\tClassification Loss: 1.5703\r\n",
      "Train Epoch: 27 [103680/110534 (94%)]\tClassification Loss: 1.5249\r\n",
      "Train Epoch: 27 [105600/110534 (96%)]\tClassification Loss: 1.4570\r\n",
      "Train Epoch: 27 [107520/110534 (97%)]\tClassification Loss: 1.4448\r\n",
      "Train Epoch: 27 [109440/110534 (99%)]\tClassification Loss: 1.6150\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_27_final.pth.tar\r\n",
      "Train Epoch: 28 [0/110534 (0%)]\tClassification Loss: 1.5881\r\n",
      "\r\n",
      "Test set: Average loss: 1.4576, Accuracy: 22723/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 28 [1920/110534 (2%)]\tClassification Loss: 1.3401\r\n",
      "Train Epoch: 28 [3840/110534 (3%)]\tClassification Loss: 1.5954\r\n",
      "Train Epoch: 28 [5760/110534 (5%)]\tClassification Loss: 1.5760\r\n",
      "Train Epoch: 28 [7680/110534 (7%)]\tClassification Loss: 1.6356\r\n",
      "Train Epoch: 28 [9600/110534 (9%)]\tClassification Loss: 1.6425\r\n",
      "Train Epoch: 28 [11520/110534 (10%)]\tClassification Loss: 1.8118\r\n",
      "Train Epoch: 28 [13440/110534 (12%)]\tClassification Loss: 1.5574\r\n",
      "Train Epoch: 28 [15360/110534 (14%)]\tClassification Loss: 1.9317\r\n",
      "Train Epoch: 28 [17280/110534 (16%)]\tClassification Loss: 1.8577\r\n",
      "Train Epoch: 28 [19200/110534 (17%)]\tClassification Loss: 2.0244\r\n",
      "Train Epoch: 28 [21120/110534 (19%)]\tClassification Loss: 1.6447\r\n",
      "Train Epoch: 28 [23040/110534 (21%)]\tClassification Loss: 1.4687\r\n",
      "Train Epoch: 28 [24960/110534 (23%)]\tClassification Loss: 1.5533\r\n",
      "Train Epoch: 28 [26880/110534 (24%)]\tClassification Loss: 1.6487\r\n",
      "Train Epoch: 28 [28800/110534 (26%)]\tClassification Loss: 1.8867\r\n",
      "Train Epoch: 28 [30720/110534 (28%)]\tClassification Loss: 1.4762\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_28_500.pth.tar\r\n",
      "Train Epoch: 28 [32640/110534 (30%)]\tClassification Loss: 1.4447\r\n",
      "Train Epoch: 28 [34560/110534 (31%)]\tClassification Loss: 1.5120\r\n",
      "Train Epoch: 28 [36480/110534 (33%)]\tClassification Loss: 1.3184\r\n",
      "Train Epoch: 28 [38400/110534 (35%)]\tClassification Loss: 1.5458\r\n",
      "Train Epoch: 28 [40320/110534 (36%)]\tClassification Loss: 1.4964\r\n",
      "Train Epoch: 28 [42240/110534 (38%)]\tClassification Loss: 1.4386\r\n",
      "Train Epoch: 28 [44160/110534 (40%)]\tClassification Loss: 1.4180\r\n",
      "Train Epoch: 28 [46080/110534 (42%)]\tClassification Loss: 1.4435\r\n",
      "Train Epoch: 28 [48000/110534 (43%)]\tClassification Loss: 1.5029\r\n",
      "Train Epoch: 28 [49920/110534 (45%)]\tClassification Loss: 1.7713\r\n",
      "Train Epoch: 28 [51840/110534 (47%)]\tClassification Loss: 1.7249\r\n",
      "Train Epoch: 28 [53760/110534 (49%)]\tClassification Loss: 1.4386\r\n",
      "Train Epoch: 28 [55680/110534 (50%)]\tClassification Loss: 1.5383\r\n",
      "Train Epoch: 28 [57600/110534 (52%)]\tClassification Loss: 1.5420\r\n",
      "Train Epoch: 28 [59520/110534 (54%)]\tClassification Loss: 1.7125\r\n",
      "Train Epoch: 28 [61440/110534 (56%)]\tClassification Loss: 1.5453\r\n",
      "Train Epoch: 28 [63360/110534 (57%)]\tClassification Loss: 1.7021\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_28_1000.pth.tar\r\n",
      "Train Epoch: 28 [65280/110534 (59%)]\tClassification Loss: 1.5491\r\n",
      "Train Epoch: 28 [67200/110534 (61%)]\tClassification Loss: 1.3022\r\n",
      "Train Epoch: 28 [69120/110534 (63%)]\tClassification Loss: 1.5975\r\n",
      "Train Epoch: 28 [71040/110534 (64%)]\tClassification Loss: 1.5419\r\n",
      "Train Epoch: 28 [72960/110534 (66%)]\tClassification Loss: 1.4895\r\n",
      "Train Epoch: 28 [74880/110534 (68%)]\tClassification Loss: 1.5047\r\n",
      "Train Epoch: 28 [76800/110534 (69%)]\tClassification Loss: 1.5155\r\n",
      "Train Epoch: 28 [78720/110534 (71%)]\tClassification Loss: 1.4717\r\n",
      "Train Epoch: 28 [80640/110534 (73%)]\tClassification Loss: 1.4593\r\n",
      "Train Epoch: 28 [82560/110534 (75%)]\tClassification Loss: 1.4480\r\n",
      "Train Epoch: 28 [84480/110534 (76%)]\tClassification Loss: 1.6084\r\n",
      "Train Epoch: 28 [86400/110534 (78%)]\tClassification Loss: 1.6296\r\n",
      "Train Epoch: 28 [88320/110534 (80%)]\tClassification Loss: 1.7071\r\n",
      "Train Epoch: 28 [90240/110534 (82%)]\tClassification Loss: 1.6227\r\n",
      "Train Epoch: 28 [92160/110534 (83%)]\tClassification Loss: 1.8383\r\n",
      "Train Epoch: 28 [94080/110534 (85%)]\tClassification Loss: 1.7201\r\n",
      "Train Epoch: 28 [96000/110534 (87%)]\tClassification Loss: 1.6556\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_28_1500.pth.tar\r\n",
      "Train Epoch: 28 [97920/110534 (89%)]\tClassification Loss: 1.6739\r\n",
      "Train Epoch: 28 [99840/110534 (90%)]\tClassification Loss: 1.5521\r\n",
      "Train Epoch: 28 [101760/110534 (92%)]\tClassification Loss: 1.4578\r\n",
      "Train Epoch: 28 [103680/110534 (94%)]\tClassification Loss: 1.5710\r\n",
      "Train Epoch: 28 [105600/110534 (96%)]\tClassification Loss: 1.4532\r\n",
      "Train Epoch: 28 [107520/110534 (97%)]\tClassification Loss: 1.4709\r\n",
      "Train Epoch: 28 [109440/110534 (99%)]\tClassification Loss: 1.7687\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_28_final.pth.tar\r\n",
      "Train Epoch: 29 [0/110534 (0%)]\tClassification Loss: 1.6034\r\n",
      "\r\n",
      "Test set: Average loss: 1.4545, Accuracy: 22750/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 29 [1920/110534 (2%)]\tClassification Loss: 1.4235\r\n",
      "Train Epoch: 29 [3840/110534 (3%)]\tClassification Loss: 1.4490\r\n",
      "Train Epoch: 29 [5760/110534 (5%)]\tClassification Loss: 1.6083\r\n",
      "Train Epoch: 29 [7680/110534 (7%)]\tClassification Loss: 1.5136\r\n",
      "Train Epoch: 29 [9600/110534 (9%)]\tClassification Loss: 1.6859\r\n",
      "Train Epoch: 29 [11520/110534 (10%)]\tClassification Loss: 1.6532\r\n",
      "Train Epoch: 29 [13440/110534 (12%)]\tClassification Loss: 1.5118\r\n",
      "Train Epoch: 29 [15360/110534 (14%)]\tClassification Loss: 1.6961\r\n",
      "Train Epoch: 29 [17280/110534 (16%)]\tClassification Loss: 1.8243\r\n",
      "Train Epoch: 29 [19200/110534 (17%)]\tClassification Loss: 1.9465\r\n",
      "Train Epoch: 29 [21120/110534 (19%)]\tClassification Loss: 1.5483\r\n",
      "Train Epoch: 29 [23040/110534 (21%)]\tClassification Loss: 1.3869\r\n",
      "Train Epoch: 29 [24960/110534 (23%)]\tClassification Loss: 1.5315\r\n",
      "Train Epoch: 29 [26880/110534 (24%)]\tClassification Loss: 1.6959\r\n",
      "Train Epoch: 29 [28800/110534 (26%)]\tClassification Loss: 1.9497\r\n",
      "Train Epoch: 29 [30720/110534 (28%)]\tClassification Loss: 1.4114\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_29_500.pth.tar\r\n",
      "Train Epoch: 29 [32640/110534 (30%)]\tClassification Loss: 1.4369\r\n",
      "Train Epoch: 29 [34560/110534 (31%)]\tClassification Loss: 1.3917\r\n",
      "Train Epoch: 29 [36480/110534 (33%)]\tClassification Loss: 1.3858\r\n",
      "Train Epoch: 29 [38400/110534 (35%)]\tClassification Loss: 1.6869\r\n",
      "Train Epoch: 29 [40320/110534 (36%)]\tClassification Loss: 1.5705\r\n",
      "Train Epoch: 29 [42240/110534 (38%)]\tClassification Loss: 1.5643\r\n",
      "Train Epoch: 29 [44160/110534 (40%)]\tClassification Loss: 1.5630\r\n",
      "Train Epoch: 29 [46080/110534 (42%)]\tClassification Loss: 1.4797\r\n",
      "Train Epoch: 29 [48000/110534 (43%)]\tClassification Loss: 1.6392\r\n",
      "Train Epoch: 29 [49920/110534 (45%)]\tClassification Loss: 1.6454\r\n",
      "Train Epoch: 29 [51840/110534 (47%)]\tClassification Loss: 1.9541\r\n",
      "Train Epoch: 29 [53760/110534 (49%)]\tClassification Loss: 1.5753\r\n",
      "Train Epoch: 29 [55680/110534 (50%)]\tClassification Loss: 1.5335\r\n",
      "Train Epoch: 29 [57600/110534 (52%)]\tClassification Loss: 1.5025\r\n",
      "Train Epoch: 29 [59520/110534 (54%)]\tClassification Loss: 1.8527\r\n",
      "Train Epoch: 29 [61440/110534 (56%)]\tClassification Loss: 1.6543\r\n",
      "Train Epoch: 29 [63360/110534 (57%)]\tClassification Loss: 1.6853\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_29_1000.pth.tar\r\n",
      "Train Epoch: 29 [65280/110534 (59%)]\tClassification Loss: 1.5723\r\n",
      "Train Epoch: 29 [67200/110534 (61%)]\tClassification Loss: 1.3368\r\n",
      "Train Epoch: 29 [69120/110534 (63%)]\tClassification Loss: 1.6348\r\n",
      "Train Epoch: 29 [71040/110534 (64%)]\tClassification Loss: 1.5781\r\n",
      "Train Epoch: 29 [72960/110534 (66%)]\tClassification Loss: 1.4861\r\n",
      "Train Epoch: 29 [74880/110534 (68%)]\tClassification Loss: 1.4703\r\n",
      "Train Epoch: 29 [76800/110534 (69%)]\tClassification Loss: 1.4137\r\n",
      "Train Epoch: 29 [78720/110534 (71%)]\tClassification Loss: 1.4774\r\n",
      "Train Epoch: 29 [80640/110534 (73%)]\tClassification Loss: 1.4596\r\n",
      "Train Epoch: 29 [82560/110534 (75%)]\tClassification Loss: 1.4177\r\n",
      "Train Epoch: 29 [84480/110534 (76%)]\tClassification Loss: 1.4143\r\n",
      "Train Epoch: 29 [86400/110534 (78%)]\tClassification Loss: 1.5053\r\n",
      "Train Epoch: 29 [88320/110534 (80%)]\tClassification Loss: 1.6694\r\n",
      "Train Epoch: 29 [90240/110534 (82%)]\tClassification Loss: 1.7791\r\n",
      "Train Epoch: 29 [92160/110534 (83%)]\tClassification Loss: 1.8755\r\n",
      "Train Epoch: 29 [94080/110534 (85%)]\tClassification Loss: 1.7293\r\n",
      "Train Epoch: 29 [96000/110534 (87%)]\tClassification Loss: 1.8107\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_29_1500.pth.tar\r\n",
      "Train Epoch: 29 [97920/110534 (89%)]\tClassification Loss: 1.6542\r\n",
      "Train Epoch: 29 [99840/110534 (90%)]\tClassification Loss: 1.4848\r\n",
      "Train Epoch: 29 [101760/110534 (92%)]\tClassification Loss: 1.3658\r\n",
      "Train Epoch: 29 [103680/110534 (94%)]\tClassification Loss: 1.5920\r\n",
      "Train Epoch: 29 [105600/110534 (96%)]\tClassification Loss: 1.4815\r\n",
      "Train Epoch: 29 [107520/110534 (97%)]\tClassification Loss: 1.5675\r\n",
      "Train Epoch: 29 [109440/110534 (99%)]\tClassification Loss: 1.6800\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_29_final.pth.tar\r\n",
      "Train Epoch: 30 [0/110534 (0%)]\tClassification Loss: 1.5670\r\n",
      "\r\n",
      "Test set: Average loss: 1.4542, Accuracy: 22754/42368 (54%)\r\n",
      "\r\n",
      "Train Epoch: 30 [1920/110534 (2%)]\tClassification Loss: 1.4978\r\n",
      "Train Epoch: 30 [3840/110534 (3%)]\tClassification Loss: 1.5796\r\n",
      "Train Epoch: 30 [5760/110534 (5%)]\tClassification Loss: 1.7190\r\n",
      "Train Epoch: 30 [7680/110534 (7%)]\tClassification Loss: 1.5348\r\n",
      "Train Epoch: 30 [9600/110534 (9%)]\tClassification Loss: 1.5064\r\n",
      "Train Epoch: 30 [11520/110534 (10%)]\tClassification Loss: 1.6245\r\n",
      "Train Epoch: 30 [13440/110534 (12%)]\tClassification Loss: 1.4954\r\n",
      "Train Epoch: 30 [15360/110534 (14%)]\tClassification Loss: 1.6893\r\n",
      "Train Epoch: 30 [17280/110534 (16%)]\tClassification Loss: 1.6778\r\n",
      "Train Epoch: 30 [19200/110534 (17%)]\tClassification Loss: 1.8567\r\n",
      "Train Epoch: 30 [21120/110534 (19%)]\tClassification Loss: 1.5326\r\n",
      "Train Epoch: 30 [23040/110534 (21%)]\tClassification Loss: 1.4406\r\n",
      "Train Epoch: 30 [24960/110534 (23%)]\tClassification Loss: 1.4925\r\n",
      "Train Epoch: 30 [26880/110534 (24%)]\tClassification Loss: 1.4251\r\n",
      "Train Epoch: 30 [28800/110534 (26%)]\tClassification Loss: 1.9139\r\n",
      "Train Epoch: 30 [30720/110534 (28%)]\tClassification Loss: 1.4510\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_30_500.pth.tar\r\n",
      "Train Epoch: 30 [32640/110534 (30%)]\tClassification Loss: 1.3583\r\n",
      "Train Epoch: 30 [34560/110534 (31%)]\tClassification Loss: 1.5019\r\n",
      "Train Epoch: 30 [36480/110534 (33%)]\tClassification Loss: 1.3816\r\n",
      "Train Epoch: 30 [38400/110534 (35%)]\tClassification Loss: 1.4518\r\n",
      "Train Epoch: 30 [40320/110534 (36%)]\tClassification Loss: 1.5342\r\n",
      "Train Epoch: 30 [42240/110534 (38%)]\tClassification Loss: 1.4899\r\n",
      "Train Epoch: 30 [44160/110534 (40%)]\tClassification Loss: 1.4127\r\n",
      "Train Epoch: 30 [46080/110534 (42%)]\tClassification Loss: 1.4640\r\n",
      "Train Epoch: 30 [48000/110534 (43%)]\tClassification Loss: 1.6059\r\n",
      "Train Epoch: 30 [49920/110534 (45%)]\tClassification Loss: 1.6872\r\n",
      "Train Epoch: 30 [51840/110534 (47%)]\tClassification Loss: 1.6002\r\n",
      "Train Epoch: 30 [53760/110534 (49%)]\tClassification Loss: 1.5854\r\n",
      "Train Epoch: 30 [55680/110534 (50%)]\tClassification Loss: 1.5919\r\n",
      "Train Epoch: 30 [57600/110534 (52%)]\tClassification Loss: 1.6739\r\n",
      "Train Epoch: 30 [59520/110534 (54%)]\tClassification Loss: 1.9049\r\n",
      "Train Epoch: 30 [61440/110534 (56%)]\tClassification Loss: 1.7727\r\n",
      "Train Epoch: 30 [63360/110534 (57%)]\tClassification Loss: 1.5903\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_30_1000.pth.tar\r\n",
      "Train Epoch: 30 [65280/110534 (59%)]\tClassification Loss: 1.7157\r\n",
      "Train Epoch: 30 [67200/110534 (61%)]\tClassification Loss: 1.4265\r\n",
      "Train Epoch: 30 [69120/110534 (63%)]\tClassification Loss: 1.5607\r\n",
      "Train Epoch: 30 [71040/110534 (64%)]\tClassification Loss: 1.5888\r\n",
      "Train Epoch: 30 [72960/110534 (66%)]\tClassification Loss: 1.4988\r\n",
      "Train Epoch: 30 [74880/110534 (68%)]\tClassification Loss: 1.5392\r\n",
      "Train Epoch: 30 [76800/110534 (69%)]\tClassification Loss: 1.3907\r\n",
      "Train Epoch: 30 [78720/110534 (71%)]\tClassification Loss: 1.4919\r\n",
      "Train Epoch: 30 [80640/110534 (73%)]\tClassification Loss: 1.6838\r\n",
      "Train Epoch: 30 [82560/110534 (75%)]\tClassification Loss: 1.3298\r\n",
      "Train Epoch: 30 [84480/110534 (76%)]\tClassification Loss: 1.4616\r\n",
      "Train Epoch: 30 [86400/110534 (78%)]\tClassification Loss: 1.4254\r\n",
      "Train Epoch: 30 [88320/110534 (80%)]\tClassification Loss: 1.8107\r\n",
      "Train Epoch: 30 [90240/110534 (82%)]\tClassification Loss: 1.8091\r\n",
      "Train Epoch: 30 [92160/110534 (83%)]\tClassification Loss: 1.8121\r\n",
      "Train Epoch: 30 [94080/110534 (85%)]\tClassification Loss: 1.6815\r\n",
      "Train Epoch: 30 [96000/110534 (87%)]\tClassification Loss: 1.7226\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_30_1500.pth.tar\r\n",
      "Train Epoch: 30 [97920/110534 (89%)]\tClassification Loss: 1.6312\r\n",
      "Train Epoch: 30 [99840/110534 (90%)]\tClassification Loss: 1.5999\r\n",
      "Train Epoch: 30 [101760/110534 (92%)]\tClassification Loss: 1.4895\r\n",
      "Train Epoch: 30 [103680/110534 (94%)]\tClassification Loss: 1.6261\r\n",
      "Train Epoch: 30 [105600/110534 (96%)]\tClassification Loss: 1.5679\r\n",
      "Train Epoch: 30 [107520/110534 (97%)]\tClassification Loss: 1.5724\r\n",
      "Train Epoch: 30 [109440/110534 (99%)]\tClassification Loss: 1.6672\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_30_final.pth.tar\r\n"
     ]
    }
   ],
   "source": [
    "# FREEZE = False. LR=0.001. in-shop=False. 30 epochs\n",
    "! python train.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 50 Categories"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\r\n",
      "  warnings.warn(msg, category=FutureWarning)\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Train Epoch: 1 [0/209222 (0%)]\tAll Loss: 7.0639\tTriple Loss(0): 1.5324\tClassification Loss: 3.9991\r\n",
      "train.py:187: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 3.9127\r\n",
      "Top 1 Accuracy: 1393/80000 (2%)\r\n",
      "Top 3 Accuracy: 5045/80000 (6%)\r\n",
      "Top 5 Accuracy: 8674/80000 (11%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.019 sec\r\n",
      "100%|| 14218/14218 [02:19<00:00, 102.25it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:19<00:00, 102.03it/s]\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:19<00:00, 101.73it/s]\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:19<00:00, 101.60it/s]\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 1 [32000/209222 (15%)]\tAll Loss: 4.3214\tTriple Loss(1): 0.8653\tClassification Loss: 2.5908\r\n",
      "Train Epoch: 1 [64000/209222 (31%)]\tAll Loss: 4.3819\tTriple Loss(0): 0.7146\tClassification Loss: 2.9527\r\n",
      "Train Epoch: 1 [96000/209222 (46%)]\tAll Loss: 3.7524\tTriple Loss(0): 0.4543\tClassification Loss: 2.8438\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1500.pth.tar\r\n",
      "Train Epoch: 1 [128000/209222 (61%)]\tAll Loss: 4.1818\tTriple Loss(1): 0.7572\tClassification Loss: 2.6674\r\n",
      "Train Epoch: 1 [160000/209222 (76%)]\tAll Loss: 4.3843\tTriple Loss(1): 0.7353\tClassification Loss: 2.9136\r\n",
      "Train Epoch: 1 [192000/209222 (92%)]\tAll Loss: 4.7259\tTriple Loss(0): 0.9962\tClassification Loss: 2.7335\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_3000.pth.tar\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_final.pth.tar\r\n",
      "Train Epoch: 2 [0/209222 (0%)]\tAll Loss: 4.5350\tTriple Loss(1): 0.6956\tClassification Loss: 3.1438\r\n",
      "\r\n",
      "Test set: Average loss: 2.7592\r\n",
      "Top 1 Accuracy: 20020/80000 (25%)\r\n",
      "Top 3 Accuracy: 37059/80000 (46%)\r\n",
      "Top 5 Accuracy: 46976/80000 (59%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.025 sec\r\n",
      "100%|| 14218/14218 [02:21<00:00, 100.24it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:23<00:00, 98.97it/s]\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:23<00:00, 98.78it/s]\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:24<00:00, 98.37it/s]\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 2 [32000/209222 (15%)]\tAll Loss: 4.0815\tTriple Loss(1): 0.7571\tClassification Loss: 2.5673\r\n",
      "Train Epoch: 2 [64000/209222 (31%)]\tAll Loss: 4.2430\tTriple Loss(1): 0.6373\tClassification Loss: 2.9685\r\n",
      "Train Epoch: 2 [96000/209222 (46%)]\tAll Loss: 3.2703\tTriple Loss(0): 0.2384\tClassification Loss: 2.7936\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1500.pth.tar\r\n",
      "Train Epoch: 2 [128000/209222 (61%)]\tAll Loss: 4.1656\tTriple Loss(1): 0.7461\tClassification Loss: 2.6735\r\n",
      "Train Epoch: 2 [160000/209222 (76%)]\tAll Loss: 3.9200\tTriple Loss(1): 0.5076\tClassification Loss: 2.9047\r\n",
      "Train Epoch: 2 [192000/209222 (92%)]\tAll Loss: 3.8965\tTriple Loss(1): 0.6021\tClassification Loss: 2.6924\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_3000.pth.tar\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_final.pth.tar\r\n",
      "Train Epoch: 3 [0/209222 (0%)]\tAll Loss: 5.6398\tTriple Loss(0): 1.3015\tClassification Loss: 3.0369\r\n",
      "\r\n",
      "Test set: Average loss: 2.7323\r\n",
      "Top 1 Accuracy: 20020/80000 (25%)\r\n",
      "Top 3 Accuracy: 37059/80000 (46%)\r\n",
      "Top 5 Accuracy: 46275/80000 (58%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.024 sec\r\n",
      "100%|| 14218/14218 [02:19<00:00, 101.96it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:21<00:00, 100.72it/s]\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.017 sec\r\n",
      "100%|| 14218/14218 [02:21<00:00, 100.19it/s]\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:22<00:00, 100.04it/s]\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 3 [32000/209222 (15%)]\tAll Loss: 2.5528\tTriple Loss(0): 0.0000\tClassification Loss: 2.5528\r\n",
      "Train Epoch: 3 [64000/209222 (31%)]\tAll Loss: 4.1967\tTriple Loss(1): 0.6222\tClassification Loss: 2.9524\r\n",
      "Train Epoch: 3 [96000/209222 (46%)]\tAll Loss: 3.9000\tTriple Loss(1): 0.5676\tClassification Loss: 2.7647\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1500.pth.tar\r\n",
      "Train Epoch: 3 [128000/209222 (61%)]\tAll Loss: 3.1187\tTriple Loss(1): 0.2521\tClassification Loss: 2.6145\r\n",
      "Train Epoch: 3 [160000/209222 (76%)]\tAll Loss: 3.5058\tTriple Loss(1): 0.3344\tClassification Loss: 2.8369\r\n",
      "Train Epoch: 3 [192000/209222 (92%)]\tAll Loss: 3.4936\tTriple Loss(1): 0.4241\tClassification Loss: 2.6453\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_3000.pth.tar\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_final.pth.tar\r\n",
      "Train Epoch: 4 [0/209222 (0%)]\tAll Loss: 3.9797\tTriple Loss(1): 0.5055\tClassification Loss: 2.9687\r\n",
      "\r\n",
      "Test set: Average loss: 2.6342\r\n",
      "Top 1 Accuracy: 20773/80000 (26%)\r\n",
      "Top 3 Accuracy: 37659/80000 (47%)\r\n",
      "Top 5 Accuracy: 49545/80000 (62%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.024 sec\r\n",
      "100%|| 14218/14218 [02:23<00:00, 98.83it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:24<00:00, 98.13it/s]\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:25<00:00, 97.88it/s]\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:25<00:00, 97.46it/s]\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 4 [32000/209222 (15%)]\tAll Loss: 2.4717\tTriple Loss(0): 0.0000\tClassification Loss: 2.4717\r\n",
      "Train Epoch: 4 [64000/209222 (31%)]\tAll Loss: 3.6532\tTriple Loss(1): 0.3654\tClassification Loss: 2.9223\r\n",
      "Train Epoch: 4 [96000/209222 (46%)]\tAll Loss: 3.4816\tTriple Loss(1): 0.3983\tClassification Loss: 2.6851\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_1500.pth.tar\r\n",
      "Train Epoch: 4 [128000/209222 (61%)]\tAll Loss: 3.4301\tTriple Loss(1): 0.4318\tClassification Loss: 2.5666\r\n",
      "Train Epoch: 4 [160000/209222 (76%)]\tAll Loss: 2.9659\tTriple Loss(1): 0.1038\tClassification Loss: 2.7582\r\n",
      "Train Epoch: 4 [192000/209222 (92%)]\tAll Loss: 3.0979\tTriple Loss(1): 0.3132\tClassification Loss: 2.4714\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_3000.pth.tar\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_4_final.pth.tar\r\n",
      "Train Epoch: 5 [0/209222 (0%)]\tAll Loss: 3.7272\tTriple Loss(1): 0.4374\tClassification Loss: 2.8523\r\n",
      "\r\n",
      "Test set: Average loss: 2.5326\r\n",
      "Top 1 Accuracy: 23113/80000 (29%)\r\n",
      "Top 3 Accuracy: 39595/80000 (49%)\r\n",
      "Top 5 Accuracy: 52100/80000 (65%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.024 sec\r\n",
      "100%|| 14218/14218 [02:20<00:00, 101.15it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:21<00:00, 100.59it/s]\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:21<00:00, 100.37it/s]\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:21<00:00, 100.18it/s]\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 5 [32000/209222 (15%)]\tAll Loss: 3.7092\tTriple Loss(0): 0.6319\tClassification Loss: 2.4453\r\n",
      "Train Epoch: 5 [64000/209222 (31%)]\tAll Loss: 3.4975\tTriple Loss(1): 0.3075\tClassification Loss: 2.8826\r\n",
      "Train Epoch: 5 [96000/209222 (46%)]\tAll Loss: 3.3216\tTriple Loss(1): 0.3394\tClassification Loss: 2.6429\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_1500.pth.tar\r\n",
      "Train Epoch: 5 [128000/209222 (61%)]\tAll Loss: 4.5308\tTriple Loss(0): 1.0723\tClassification Loss: 2.3862\r\n",
      "Train Epoch: 5 [160000/209222 (76%)]\tAll Loss: 2.9384\tTriple Loss(1): 0.1445\tClassification Loss: 2.6493\r\n",
      "Train Epoch: 5 [192000/209222 (92%)]\tAll Loss: 3.0407\tTriple Loss(1): 0.3012\tClassification Loss: 2.4383\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_3000.pth.tar\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_5_final.pth.tar\r\n",
      "Train Epoch: 6 [0/209222 (0%)]\tAll Loss: 3.5701\tTriple Loss(1): 0.3599\tClassification Loss: 2.8503\r\n",
      "\r\n",
      "Test set: Average loss: 2.3198\r\n",
      "Top 1 Accuracy: 28717/80000 (36%)\r\n",
      "Top 3 Accuracy: 45913/80000 (57%)\r\n",
      "Top 5 Accuracy: 56681/80000 (71%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.024 sec\r\n",
      "100%|| 14218/14218 [02:20<00:00, 100.96it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:22<00:00, 99.88it/s]\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:22<00:00, 99.73it/s]\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "Loading in-shop test feature database...\r\n",
      "Loading in-shop test feature database Done. Time: 0.018 sec\r\n",
      "100%|| 14218/14218 [02:23<00:00, 99.28it/s]\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 6 [32000/209222 (15%)]\tAll Loss: 2.3078\tTriple Loss(0): 0.0000\tClassification Loss: 2.3078\r\n",
      "Train Epoch: 6 [64000/209222 (31%)]\tAll Loss: 3.2399\tTriple Loss(1): 0.2686\tClassification Loss: 2.7028\r\n",
      "Train Epoch: 6 [96000/209222 (46%)]\tAll Loss: 2.3874\tTriple Loss(0): 0.0000\tClassification Loss: 2.3874\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_6_1500.pth.tar\r\n",
      "Train Epoch: 6 [128000/209222 (61%)]\tAll Loss: 2.8795\tTriple Loss(1): 0.3232\tClassification Loss: 2.2331\r\n"
     ]
    }
   ],
   "source": [
    "# FREEZE = False. LR=0.001. in-shop=True. 30 epochs\n",
    "! python train.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "Loading model model_6_2000.pth.tar\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\r\n",
      "  warnings.warn(msg, category=FutureWarning)\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Loading model model_6_2000.pth.tar\r\n",
      "Train Epoch: 1 [0/209222 (0%)]\tAll Loss: 3.9578\tTriple Loss(1): 0.6069\tClassification Loss: 2.7440\r\n",
      "train.py:191: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 2.6806\r\n",
      "Top 1 Accuracy: 20020/80000 (25%)\r\n",
      "Top 3 Accuracy: 37266/80000 (47%)\r\n",
      "Top 5 Accuracy: 49199/80000 (61%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "100%|| 14218/14218 [02:20<00:00, 101.04it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "100%|| 14218/14218 [02:21<00:00, 100.32it/s]\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "100%|| 14218/14218 [02:21<00:00, 100.30it/s]\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "100%|| 14218/14218 [02:22<00:00, 99.90it/s]\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 1 [32000/209222 (15%)]\tAll Loss: 3.5943\tTriple Loss(1): 0.4393\tClassification Loss: 2.7157\r\n",
      "Train Epoch: 1 [64000/209222 (31%)]\tAll Loss: 3.3859\tTriple Loss(1): 0.3599\tClassification Loss: 2.6661\r\n",
      "Train Epoch: 1 [96000/209222 (46%)]\tAll Loss: 2.8750\tTriple Loss(0): 0.0000\tClassification Loss: 2.8750\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1500.pth.tar\r\n",
      "Train Epoch: 1 [128000/209222 (61%)]\tAll Loss: 3.6866\tTriple Loss(1): 0.3495\tClassification Loss: 2.9875\r\n",
      "Train Epoch: 1 [160000/209222 (76%)]\tAll Loss: 2.7910\tTriple Loss(1): 0.2378\tClassification Loss: 2.3155\r\n",
      "Train Epoch: 1 [192000/209222 (92%)]\tAll Loss: 5.7401\tTriple Loss(0): 1.6204\tClassification Loss: 2.4993\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_3000.pth.tar\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_final.pth.tar\r\n",
      "Train Epoch: 2 [0/209222 (0%)]\tAll Loss: 3.8300\tTriple Loss(1): 0.5507\tClassification Loss: 2.7285\r\n",
      "\r\n",
      "Test set: Average loss: 2.5922\r\n",
      "Top 1 Accuracy: 20371/80000 (25%)\r\n",
      "Top 3 Accuracy: 38893/80000 (49%)\r\n",
      "Top 5 Accuracy: 50538/80000 (63%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "100%|| 14218/14218 [02:20<00:00, 101.41it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "100%|| 14218/14218 [02:21<00:00, 100.36it/s]\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "100%|| 14218/14218 [02:20<00:00, 101.49it/s]\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "100%|| 14218/14218 [02:21<00:00, 100.13it/s]\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 2 [32000/209222 (15%)]\tAll Loss: 2.7182\tTriple Loss(0): 0.0335\tClassification Loss: 2.6511\r\n",
      "Train Epoch: 2 [64000/209222 (31%)]\tAll Loss: 3.0154\tTriple Loss(1): 0.1978\tClassification Loss: 2.6197\r\n",
      "Train Epoch: 2 [96000/209222 (46%)]\tAll Loss: 3.5326\tTriple Loss(1): 0.3866\tClassification Loss: 2.7595\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1500.pth.tar\r\n",
      "Train Epoch: 2 [128000/209222 (61%)]\tAll Loss: 3.0781\tTriple Loss(1): 0.1074\tClassification Loss: 2.8633\r\n",
      "Train Epoch: 2 [160000/209222 (76%)]\tAll Loss: 2.9441\tTriple Loss(1): 0.3250\tClassification Loss: 2.2942\r\n",
      "Train Epoch: 2 [192000/209222 (92%)]\tAll Loss: 2.8051\tTriple Loss(1): 0.2068\tClassification Loss: 2.3915\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_3000.pth.tar\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_final.pth.tar\r\n",
      "Train Epoch: 3 [0/209222 (0%)]\tAll Loss: 3.5200\tTriple Loss(1): 0.4260\tClassification Loss: 2.6680\r\n",
      "\r\n",
      "Test set: Average loss: 2.4564\r\n",
      "Top 1 Accuracy: 22785/80000 (28%)\r\n",
      "Top 3 Accuracy: 41755/80000 (52%)\r\n",
      "Top 5 Accuracy: 53000/80000 (66%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "100%|| 14218/14218 [02:20<00:00, 101.00it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "100%|| 14218/14218 [02:21<00:00, 100.32it/s]\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "100%|| 14218/14218 [02:22<00:00, 99.91it/s]\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "100%|| 14218/14218 [02:22<00:00, 99.86it/s]\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 3 [32000/209222 (15%)]\tAll Loss: 3.1631\tTriple Loss(1): 0.2828\tClassification Loss: 2.5976\r\n",
      "Train Epoch: 3 [64000/209222 (31%)]\tAll Loss: 3.1815\tTriple Loss(1): 0.3089\tClassification Loss: 2.5637\r\n",
      "Train Epoch: 3 [96000/209222 (46%)]\tAll Loss: 2.9009\tTriple Loss(1): 0.1388\tClassification Loss: 2.6232\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1500.pth.tar\r\n",
      "Train Epoch: 3 [128000/209222 (61%)]\tAll Loss: 3.2167\tTriple Loss(1): 0.2418\tClassification Loss: 2.7330\r\n",
      "Train Epoch: 3 [160000/209222 (76%)]\tAll Loss: 3.0881\tTriple Loss(1): 0.4487\tClassification Loss: 2.1908\r\n",
      "Train Epoch: 3 [192000/209222 (92%)]\tAll Loss: 2.8553\tTriple Loss(1): 0.2830\tClassification Loss: 2.2894\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_3000.pth.tar\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_final.pth.tar\r\n",
      "Train Epoch: 4 [0/209222 (0%)]\tAll Loss: 3.3184\tTriple Loss(1): 0.4011\tClassification Loss: 2.5163\r\n",
      "\r\n",
      "Test set: Average loss: 2.2343\r\n",
      "Top 1 Accuracy: 28249/80000 (35%)\r\n",
      "Top 3 Accuracy: 47359/80000 (59%)\r\n",
      "Top 5 Accuracy: 57510/80000 (72%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "100%|| 14218/14218 [02:22<00:00, 99.47it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "100%|| 14218/14218 [02:23<00:00, 98.90it/s]\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "100%|| 14218/14218 [02:23<00:00, 99.09it/s]\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "100%|| 14218/14218 [02:24<00:00, 98.57it/s]\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 4 [32000/209222 (15%)]\tAll Loss: 2.6745\tTriple Loss(0): 0.1761\tClassification Loss: 2.3223\r\n"
     ]
    }
   ],
   "source": [
    "# Continuing model_6_2000.pth.tar\n",
    "# FREEZE = False. LR=0.001. in-shop=True.\n",
    "# Result is model_3_final.pth.tar. Trained for 9+ epochs.\n",
    "! python train.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "Loading model model_3_final.pth.tar\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\r\n",
      "  warnings.warn(msg, category=FutureWarning)\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Loading model model_3_final.pth.tar\r\n",
      "Train Epoch: 1 [0/209222 (0%)]\tAll Loss: 2.4196\tTriple Loss(0): 0.0000\tClassification Loss: 2.4196\r\n",
      "train.py:191: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 2.2381\r\n",
      "Top 1 Accuracy: 28278/80000 (35%)\r\n",
      "Top 3 Accuracy: 47172/80000 (59%)\r\n",
      "Top 5 Accuracy: 57355/80000 (72%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "100%|| 14218/14218 [02:23<00:00, 99.16it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 1 [32000/209222 (15%)]\tAll Loss: 2.7604\tTriple Loss(1): 0.2631\tClassification Loss: 2.2342\r\n",
      "Train Epoch: 1 [64000/209222 (31%)]\tAll Loss: 2.9373\tTriple Loss(1): 0.2202\tClassification Loss: 2.4970\r\n",
      "Train Epoch: 1 [96000/209222 (46%)]\tAll Loss: 3.0321\tTriple Loss(1): 0.3315\tClassification Loss: 2.3691\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1500.pth.tar\r\n",
      "Train Epoch: 1 [128000/209222 (61%)]\tAll Loss: 2.6921\tTriple Loss(1): 0.1971\tClassification Loss: 2.2979\r\n",
      "Train Epoch: 1 [160000/209222 (76%)]\tAll Loss: 2.3424\tTriple Loss(1): 0.1643\tClassification Loss: 2.0137\r\n",
      "Train Epoch: 1 [192000/209222 (92%)]\tAll Loss: 2.2741\tTriple Loss(0): 0.0000\tClassification Loss: 2.2741\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_3000.pth.tar\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_final.pth.tar\r\n",
      "Train Epoch: 2 [0/209222 (0%)]\tAll Loss: 3.1489\tTriple Loss(1): 0.4388\tClassification Loss: 2.2713\r\n",
      "\r\n",
      "Test set: Average loss: 1.9718\r\n",
      "Top 1 Accuracy: 34883/80000 (44%)\r\n",
      "Top 3 Accuracy: 54497/80000 (68%)\r\n",
      "Top 5 Accuracy: 63487/80000 (79%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "100%|| 14218/14218 [02:22<00:00, 100.03it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 2 [32000/209222 (15%)]\tAll Loss: 2.5346\tTriple Loss(1): 0.2154\tClassification Loss: 2.1039\r\n"
     ]
    }
   ],
   "source": [
    "# Continuing model_3_final.pth.tar, which is trained for 9+ epochs.\n",
    "# FREEZE = False. LR=0.001. in-shop=True. 30 epochs\n",
    "! python train.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "Loading model model_1_final.pth.tar\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\r\n",
      "  warnings.warn(msg, category=FutureWarning)\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Loading model model_1_final.pth.tar\r\n",
      "Train Epoch: 1 [0/209222 (0%)]\tAll Loss: 3.0388\tTriple Loss(1): 0.3443\tClassification Loss: 2.3502\r\n",
      "train.py:192: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 1.9724\r\n",
      "Top 1 Accuracy: 34889/80000 (44%)\r\n",
      "Top 3 Accuracy: 54489/80000 (68%)\r\n",
      "Top 5 Accuracy: 63483/80000 (79%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "100%|| 14218/14218 [02:24<00:00, 98.63it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 1 [32000/209222 (15%)]\tAll Loss: 2.8499\tTriple Loss(1): 0.2846\tClassification Loss: 2.2808\r\n",
      "Train Epoch: 1 [64000/209222 (31%)]\tAll Loss: 2.3696\tTriple Loss(0): 0.0000\tClassification Loss: 2.3696\r\n",
      "Train Epoch: 1 [96000/209222 (46%)]\tAll Loss: 2.2099\tTriple Loss(1): 0.2301\tClassification Loss: 1.7497\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_1500.pth.tar\r\n",
      "Train Epoch: 1 [128000/209222 (61%)]\tAll Loss: 2.1935\tTriple Loss(0): 0.0000\tClassification Loss: 2.1935\r\n",
      "Train Epoch: 1 [160000/209222 (76%)]\tAll Loss: 2.0613\tTriple Loss(1): 0.1057\tClassification Loss: 1.8498\r\n",
      "Train Epoch: 1 [192000/209222 (92%)]\tAll Loss: 2.3959\tTriple Loss(1): 0.0863\tClassification Loss: 2.2232\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_3000.pth.tar\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_1_final.pth.tar\r\n",
      "Train Epoch: 2 [0/209222 (0%)]\tAll Loss: 5.3615\tTriple Loss(0): 1.4407\tClassification Loss: 2.4801\r\n",
      "\r\n",
      "Test set: Average loss: 1.9545\r\n",
      "Top 1 Accuracy: 34773/80000 (43%)\r\n",
      "Top 3 Accuracy: 53503/80000 (67%)\r\n",
      "Top 5 Accuracy: 62858/80000 (79%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "100%|| 14218/14218 [02:24<00:00, 98.42it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 2 [32000/209222 (15%)]\tAll Loss: 2.6035\tTriple Loss(1): 0.2918\tClassification Loss: 2.0200\r\n",
      "Train Epoch: 2 [64000/209222 (31%)]\tAll Loss: 2.2079\tTriple Loss(1): 0.2091\tClassification Loss: 1.7897\r\n",
      "Train Epoch: 2 [96000/209222 (46%)]\tAll Loss: 1.9722\tTriple Loss(0): 0.1576\tClassification Loss: 1.6571\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_1500.pth.tar\r\n",
      "Train Epoch: 2 [128000/209222 (61%)]\tAll Loss: 2.4372\tTriple Loss(1): 0.2173\tClassification Loss: 2.0026\r\n",
      "Train Epoch: 2 [160000/209222 (76%)]\tAll Loss: 2.3341\tTriple Loss(1): 0.1917\tClassification Loss: 1.9508\r\n",
      "Train Epoch: 2 [192000/209222 (92%)]\tAll Loss: 2.1387\tTriple Loss(1): 0.0902\tClassification Loss: 1.9584\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_3000.pth.tar\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_2_final.pth.tar\r\n",
      "Train Epoch: 3 [0/209222 (0%)]\tAll Loss: 2.2551\tTriple Loss(0): 0.0000\tClassification Loss: 2.2551\r\n",
      "\r\n",
      "Test set: Average loss: 1.8277\r\n",
      "Top 1 Accuracy: 37386/80000 (47%)\r\n",
      "Top 3 Accuracy: 57287/80000 (72%)\r\n",
      "Top 5 Accuracy: 65663/80000 (82%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      "100%|| 14218/14218 [02:22<00:00, 99.46it/s]\r\n",
      "n = 1. Accuracy = 22.79%.\r\n",
      "n = 10. Accuracy = 46.01%.\r\n",
      "n = 20. Accuracy = 53.53%.\r\n",
      "n = 50. Accuracy = 63.70%.\r\n",
      "Train Epoch: 3 [32000/209222 (15%)]\tAll Loss: 1.9819\tTriple Loss(1): 0.0855\tClassification Loss: 1.8109\r\n",
      "Train Epoch: 3 [64000/209222 (31%)]\tAll Loss: 2.1006\tTriple Loss(1): 0.1930\tClassification Loss: 1.7145\r\n",
      "Train Epoch: 3 [96000/209222 (46%)]\tAll Loss: 2.2459\tTriple Loss(1): 0.2556\tClassification Loss: 1.7347\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_1500.pth.tar\r\n",
      "Train Epoch: 3 [128000/209222 (61%)]\tAll Loss: 2.3768\tTriple Loss(1): 0.2425\tClassification Loss: 1.8919\r\n",
      "Train Epoch: 3 [160000/209222 (76%)]\tAll Loss: 1.9545\tTriple Loss(1): 0.0970\tClassification Loss: 1.7604\r\n",
      "Train Epoch: 3 [192000/209222 (92%)]\tAll Loss: 3.0874\tTriple Loss(1): 0.3705\tClassification Loss: 2.3463\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_3000.pth.tar\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/model_3_final.pth.tar\r\n",
      "Train Epoch: 4 [0/209222 (0%)]\tAll Loss: 2.9866\tTriple Loss(1): 0.3168\tClassification Loss: 2.3530\r\n",
      "\r\n",
      "Test set: Average loss: 1.8471\r\n",
      "Top 1 Accuracy: 38723/80000 (48%)\r\n",
      "Top 3 Accuracy: 56982/80000 (71%)\r\n",
      "Top 5 Accuracy: 65303/80000 (82%)\r\n",
      "\r\n",
      "Testing in-shop retrieval\r\n",
      " 25%|                           | 3619/14218 [00:35<01:44, 101.09it/s]"
     ]
    }
   ],
   "source": [
    "# Continuing model_1_final.pth.tar, which is trained for 10+ epochs.\n",
    "# FREEZE = False. LR=0.001. in-shop=True. 30 epochs\n",
    "! python train.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "Loading model freeze=False/lr=0.001/11_epochs\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\r\n",
      "  warnings.warn(msg, category=FutureWarning)\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Loading model freeze=False/lr=0.001/11_epochs\r\n",
      "start_epoch: 11\r\n",
      "Train Epoch: 11 [0/209222 (0%)]\tAll Loss: 1.9825\tTriple Loss(1): 0.1978\tClassification Loss: 1.5868\r\n",
      "train.py:211: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 1.5684\r\n",
      "Top 1 Accuracy: 44388/80000 (55%)\r\n",
      "Top 3 Accuracy: 62162/80000 (78%)\r\n",
      "Top 5 Accuracy: 69201/80000 (87%)\r\n",
      " \r\n",
      "Train Epoch: 11 [32000/209222 (15%)]\tAll Loss: 1.7409\tTriple Loss(1): 0.1478\tClassification Loss: 1.4452\r\n",
      "Train Epoch: 11 [64000/209222 (31%)]\tAll Loss: 1.6496\tTriple Loss(1): 0.0472\tClassification Loss: 1.5553\r\n",
      "Train Epoch: 11 [96000/209222 (46%)]\tAll Loss: 2.0770\tTriple Loss(1): 0.0854\tClassification Loss: 1.9063\r\n",
      "Train Epoch: 11 [128000/209222 (61%)]\tAll Loss: 3.2441\tTriple Loss(0): 0.8261\tClassification Loss: 1.5919\r\n",
      "Train Epoch: 11 [160000/209222 (76%)]\tAll Loss: 2.2276\tTriple Loss(1): 0.0534\tClassification Loss: 2.1209\r\n",
      "Train Epoch: 11 [192000/209222 (92%)]\tAll Loss: 2.0469\tTriple Loss(1): 0.0638\tClassification Loss: 1.9193\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/11_epochs\r\n",
      "Train Epoch: 12 [0/209222 (0%)]\tAll Loss: 2.5828\tTriple Loss(1): 0.4799\tClassification Loss: 1.6231\r\n",
      "\r\n",
      "Test set: Average loss: 1.6341\r\n",
      "Top 1 Accuracy: 42322/80000 (53%)\r\n",
      "Top 3 Accuracy: 60813/80000 (76%)\r\n",
      "Top 5 Accuracy: 68279/80000 (85%)\r\n",
      " \r\n",
      "Train Epoch: 12 [32000/209222 (15%)]\tAll Loss: 1.5871\tTriple Loss(0): 0.0000\tClassification Loss: 1.5871\r\n",
      "Train Epoch: 12 [64000/209222 (31%)]\tAll Loss: 2.1089\tTriple Loss(1): 0.1622\tClassification Loss: 1.7845\r\n",
      "Train Epoch: 12 [96000/209222 (46%)]\tAll Loss: 2.0889\tTriple Loss(1): 0.0833\tClassification Loss: 1.9223\r\n",
      "Train Epoch: 12 [128000/209222 (61%)]\tAll Loss: 1.7401\tTriple Loss(1): 0.0259\tClassification Loss: 1.6882\r\n",
      "Train Epoch: 12 [160000/209222 (76%)]\tAll Loss: 1.9743\tTriple Loss(1): 0.0712\tClassification Loss: 1.8319\r\n",
      "Train Epoch: 12 [192000/209222 (92%)]\tAll Loss: 7.4192\tTriple Loss(0): 2.7661\tClassification Loss: 1.8869\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/12_epochs\r\n",
      "Train Epoch: 13 [0/209222 (0%)]\tAll Loss: 2.0225\tTriple Loss(1): 0.1895\tClassification Loss: 1.6435\r\n",
      "\r\n",
      "Test set: Average loss: 1.5708\r\n",
      "Top 1 Accuracy: 43970/80000 (55%)\r\n",
      "Top 3 Accuracy: 62321/80000 (78%)\r\n",
      "Top 5 Accuracy: 69408/80000 (87%)\r\n",
      " \r\n",
      "Train Epoch: 13 [32000/209222 (15%)]\tAll Loss: 2.0393\tTriple Loss(1): 0.1992\tClassification Loss: 1.6409\r\n",
      "Train Epoch: 13 [64000/209222 (31%)]\tAll Loss: 1.5812\tTriple Loss(1): 0.0322\tClassification Loss: 1.5169\r\n",
      "Train Epoch: 13 [96000/209222 (46%)]\tAll Loss: 2.3454\tTriple Loss(1): 0.1642\tClassification Loss: 2.0170\r\n",
      "Train Epoch: 13 [128000/209222 (61%)]\tAll Loss: 1.8618\tTriple Loss(1): 0.1532\tClassification Loss: 1.5554\r\n",
      "Train Epoch: 13 [160000/209222 (76%)]\tAll Loss: 1.8682\tTriple Loss(1): 0.0301\tClassification Loss: 1.8080\r\n",
      "Train Epoch: 13 [192000/209222 (92%)]\tAll Loss: 1.7503\tTriple Loss(0): 0.0000\tClassification Loss: 1.7503\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/13_epochs\r\n",
      "Train Epoch: 14 [0/209222 (0%)]\tAll Loss: 2.1362\tTriple Loss(1): 0.1981\tClassification Loss: 1.7399\r\n",
      "\r\n",
      "Test set: Average loss: 1.4572\r\n",
      "Top 1 Accuracy: 46363/80000 (58%)\r\n",
      "Top 3 Accuracy: 64005/80000 (80%)\r\n",
      "Top 5 Accuracy: 70480/80000 (88%)\r\n",
      " \r\n",
      "Train Epoch: 14 [32000/209222 (15%)]\tAll Loss: 1.7759\tTriple Loss(1): 0.1194\tClassification Loss: 1.5371\r\n",
      "Train Epoch: 14 [64000/209222 (31%)]\tAll Loss: 1.6924\tTriple Loss(0): 0.0000\tClassification Loss: 1.6924\r\n",
      "Train Epoch: 14 [96000/209222 (46%)]\tAll Loss: 2.1997\tTriple Loss(1): 0.1482\tClassification Loss: 1.9032\r\n",
      "Train Epoch: 14 [128000/209222 (61%)]\tAll Loss: 3.4103\tTriple Loss(1): 0.4506\tClassification Loss: 2.5091\r\n",
      "Train Epoch: 14 [160000/209222 (76%)]\tAll Loss: 2.2957\tTriple Loss(1): 0.1729\tClassification Loss: 1.9499\r\n",
      "Train Epoch: 14 [192000/209222 (92%)]\tAll Loss: 1.9018\tTriple Loss(1): 0.0862\tClassification Loss: 1.7294\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/14_epochs\r\n",
      "Train Epoch: 15 [0/209222 (0%)]\tAll Loss: 2.5020\tTriple Loss(1): 0.4037\tClassification Loss: 1.6946\r\n",
      "\r\n",
      "Test set: Average loss: 1.4505\r\n",
      "Top 1 Accuracy: 46769/80000 (58%)\r\n",
      "Top 3 Accuracy: 63894/80000 (80%)\r\n",
      "Top 5 Accuracy: 70497/80000 (88%)\r\n",
      " \r\n",
      "Train Epoch: 15 [32000/209222 (15%)]\tAll Loss: 1.4273\tTriple Loss(0): 0.0000\tClassification Loss: 1.4273\r\n",
      "Train Epoch: 15 [64000/209222 (31%)]\tAll Loss: 1.8094\tTriple Loss(1): 0.0465\tClassification Loss: 1.7164\r\n",
      "Train Epoch: 15 [96000/209222 (46%)]\tAll Loss: 2.2060\tTriple Loss(1): 0.1989\tClassification Loss: 1.8081\r\n",
      "Train Epoch: 15 [128000/209222 (61%)]\tAll Loss: 1.8232\tTriple Loss(1): 0.1164\tClassification Loss: 1.5904\r\n",
      "Train Epoch: 15 [160000/209222 (76%)]\tAll Loss: 1.6860\tTriple Loss(0): 0.0000\tClassification Loss: 1.6860\r\n",
      "Train Epoch: 15 [192000/209222 (92%)]\tAll Loss: 1.7485\tTriple Loss(1): 0.0000\tClassification Loss: 1.7485\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/15_epochs\r\n",
      "Train Epoch: 16 [0/209222 (0%)]\tAll Loss: 1.7352\tTriple Loss(0): 0.0000\tClassification Loss: 1.7352\r\n",
      "\r\n",
      "Test set: Average loss: 1.5067\r\n",
      "Top 1 Accuracy: 45829/80000 (57%)\r\n",
      "Top 3 Accuracy: 63487/80000 (79%)\r\n",
      "Top 5 Accuracy: 70261/80000 (88%)\r\n",
      " \r\n",
      "Train Epoch: 16 [32000/209222 (15%)]\tAll Loss: 1.6277\tTriple Loss(1): 0.0822\tClassification Loss: 1.4633\r\n",
      "Train Epoch: 16 [64000/209222 (31%)]\tAll Loss: 1.8376\tTriple Loss(1): 0.0636\tClassification Loss: 1.7103\r\n",
      "Train Epoch: 16 [96000/209222 (46%)]\tAll Loss: 1.9824\tTriple Loss(1): 0.0391\tClassification Loss: 1.9042\r\n",
      "Train Epoch: 16 [128000/209222 (61%)]\tAll Loss: 1.5033\tTriple Loss(1): 0.0397\tClassification Loss: 1.4239\r\n",
      "Train Epoch: 16 [160000/209222 (76%)]\tAll Loss: 1.9752\tTriple Loss(1): 0.0312\tClassification Loss: 1.9127\r\n",
      "Train Epoch: 16 [192000/209222 (92%)]\tAll Loss: 1.6281\tTriple Loss(0): 0.0000\tClassification Loss: 1.6281\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/16_epochs\r\n",
      "Train Epoch: 17 [0/209222 (0%)]\tAll Loss: 2.5235\tTriple Loss(1): 0.5166\tClassification Loss: 1.4902\r\n",
      "\r\n",
      "Test set: Average loss: 1.4225\r\n",
      "Top 1 Accuracy: 47344/80000 (59%)\r\n",
      "Top 3 Accuracy: 64593/80000 (81%)\r\n",
      "Top 5 Accuracy: 70958/80000 (89%)\r\n",
      " \r\n",
      "Train Epoch: 17 [32000/209222 (15%)]\tAll Loss: 1.4384\tTriple Loss(1): 0.0819\tClassification Loss: 1.2747\r\n",
      "Train Epoch: 17 [64000/209222 (31%)]\tAll Loss: 1.6601\tTriple Loss(1): 0.0089\tClassification Loss: 1.6422\r\n",
      "Train Epoch: 17 [96000/209222 (46%)]\tAll Loss: 1.9003\tTriple Loss(1): 0.0734\tClassification Loss: 1.7534\r\n",
      "Train Epoch: 17 [128000/209222 (61%)]\tAll Loss: 1.7292\tTriple Loss(1): 0.0813\tClassification Loss: 1.5667\r\n",
      "Train Epoch: 17 [160000/209222 (76%)]\tAll Loss: 2.0210\tTriple Loss(1): 0.0641\tClassification Loss: 1.8929\r\n",
      "Train Epoch: 17 [192000/209222 (92%)]\tAll Loss: 3.0409\tTriple Loss(0): 0.6585\tClassification Loss: 1.7239\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/17_epochs\r\n",
      "Train Epoch: 18 [0/209222 (0%)]\tAll Loss: 2.3724\tTriple Loss(1): 0.3807\tClassification Loss: 1.6110\r\n",
      "\r\n",
      "Test set: Average loss: 1.4283\r\n",
      "Top 1 Accuracy: 47167/80000 (59%)\r\n",
      "Top 3 Accuracy: 64451/80000 (81%)\r\n",
      "Top 5 Accuracy: 71003/80000 (89%)\r\n",
      " \r\n",
      "Train Epoch: 18 [32000/209222 (15%)]\tAll Loss: 1.4481\tTriple Loss(1): 0.0682\tClassification Loss: 1.3117\r\n",
      "Train Epoch: 18 [64000/209222 (31%)]\tAll Loss: 1.4975\tTriple Loss(0): 0.0000\tClassification Loss: 1.4975\r\n",
      "Train Epoch: 18 [96000/209222 (46%)]\tAll Loss: 1.9644\tTriple Loss(1): 0.0447\tClassification Loss: 1.8750\r\n",
      "Train Epoch: 18 [128000/209222 (61%)]\tAll Loss: 1.6314\tTriple Loss(1): 0.0310\tClassification Loss: 1.5695\r\n",
      "Train Epoch: 18 [160000/209222 (76%)]\tAll Loss: 1.8234\tTriple Loss(1): 0.0367\tClassification Loss: 1.7500\r\n",
      "Train Epoch: 18 [192000/209222 (92%)]\tAll Loss: 1.7534\tTriple Loss(0): 0.0000\tClassification Loss: 1.7534\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/18_epochs\r\n",
      "Train Epoch: 19 [0/209222 (0%)]\tAll Loss: 2.5086\tTriple Loss(1): 0.3875\tClassification Loss: 1.7336\r\n",
      "\r\n",
      "Test set: Average loss: 1.4006\r\n",
      "Top 1 Accuracy: 47861/80000 (60%)\r\n",
      "Top 3 Accuracy: 64872/80000 (81%)\r\n",
      "Top 5 Accuracy: 71136/80000 (89%)\r\n",
      " \r\n",
      "Train Epoch: 19 [32000/209222 (15%)]\tAll Loss: 1.4543\tTriple Loss(1): 0.0526\tClassification Loss: 1.3491\r\n",
      "Train Epoch: 19 [64000/209222 (31%)]\tAll Loss: 1.6963\tTriple Loss(1): 0.1109\tClassification Loss: 1.4745\r\n",
      "Train Epoch: 19 [96000/209222 (46%)]\tAll Loss: 1.7528\tTriple Loss(1): 0.0196\tClassification Loss: 1.7135\r\n",
      "Train Epoch: 19 [128000/209222 (61%)]\tAll Loss: 1.6705\tTriple Loss(1): 0.0409\tClassification Loss: 1.5887\r\n",
      "Train Epoch: 19 [160000/209222 (76%)]\tAll Loss: 1.7634\tTriple Loss(1): 0.0447\tClassification Loss: 1.6740\r\n",
      "Train Epoch: 19 [192000/209222 (92%)]\tAll Loss: 1.5846\tTriple Loss(1): 0.0380\tClassification Loss: 1.5086\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/19_epochs\r\n",
      "Train Epoch: 20 [0/209222 (0%)]\tAll Loss: 2.2465\tTriple Loss(1): 0.2811\tClassification Loss: 1.6843\r\n",
      "\r\n",
      "Test set: Average loss: 1.4298\r\n",
      "Top 1 Accuracy: 46994/80000 (59%)\r\n",
      "Top 3 Accuracy: 64693/80000 (81%)\r\n",
      "Top 5 Accuracy: 71045/80000 (89%)\r\n",
      " \r\n",
      "Train Epoch: 20 [32000/209222 (15%)]\tAll Loss: 1.4383\tTriple Loss(1): 0.0576\tClassification Loss: 1.3230\r\n",
      "Train Epoch: 20 [64000/209222 (31%)]\tAll Loss: 1.6447\tTriple Loss(1): 0.0855\tClassification Loss: 1.4737\r\n",
      "Train Epoch: 20 [96000/209222 (46%)]\tAll Loss: 1.9280\tTriple Loss(1): 0.0566\tClassification Loss: 1.8148\r\n",
      "Train Epoch: 20 [128000/209222 (61%)]\tAll Loss: 1.4013\tTriple Loss(0): 0.0000\tClassification Loss: 1.4013\r\n",
      "Train Epoch: 20 [160000/209222 (76%)]\tAll Loss: 1.7028\tTriple Loss(1): 0.0018\tClassification Loss: 1.6992\r\n",
      "Train Epoch: 20 [192000/209222 (92%)]\tAll Loss: 1.8537\tTriple Loss(1): 0.0605\tClassification Loss: 1.7327\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/20_epochs\r\n",
      "Train Epoch: 21 [0/209222 (0%)]\tAll Loss: 1.6257\tTriple Loss(0): 0.0000\tClassification Loss: 1.6257\r\n",
      "\r\n",
      "Test set: Average loss: 1.3536\r\n",
      "Top 1 Accuracy: 48735/80000 (61%)\r\n",
      "Top 3 Accuracy: 65814/80000 (82%)\r\n",
      "Top 5 Accuracy: 71804/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 21 [32000/209222 (15%)]\tAll Loss: 1.4744\tTriple Loss(1): 0.0359\tClassification Loss: 1.4026\r\n",
      "Train Epoch: 21 [64000/209222 (31%)]\tAll Loss: 1.5124\tTriple Loss(1): 0.0000\tClassification Loss: 1.5124\r\n",
      "Train Epoch: 21 [96000/209222 (46%)]\tAll Loss: 1.6106\tTriple Loss(0): 0.0000\tClassification Loss: 1.6106\r\n",
      "Train Epoch: 21 [128000/209222 (61%)]\tAll Loss: 1.4774\tTriple Loss(1): 0.0716\tClassification Loss: 1.3343\r\n",
      "Train Epoch: 21 [160000/209222 (76%)]\tAll Loss: 1.7422\tTriple Loss(0): 0.0000\tClassification Loss: 1.7422\r\n",
      "Train Epoch: 21 [192000/209222 (92%)]\tAll Loss: 1.7055\tTriple Loss(1): 0.0281\tClassification Loss: 1.6494\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/21_epochs\r\n",
      "Train Epoch: 22 [0/209222 (0%)]\tAll Loss: 1.6546\tTriple Loss(0): 0.0000\tClassification Loss: 1.6546\r\n",
      "\r\n",
      "Test set: Average loss: 1.7936\r\n",
      "Top 1 Accuracy: 40934/80000 (51%)\r\n",
      "Top 3 Accuracy: 57945/80000 (72%)\r\n",
      "Top 5 Accuracy: 65883/80000 (82%)\r\n",
      " \r\n",
      "Train Epoch: 22 [32000/209222 (15%)]\tAll Loss: 1.2523\tTriple Loss(0): 0.0000\tClassification Loss: 1.2523\r\n",
      "Train Epoch: 22 [64000/209222 (31%)]\tAll Loss: 1.9774\tTriple Loss(0): 0.2041\tClassification Loss: 1.5691\r\n",
      "Train Epoch: 22 [96000/209222 (46%)]\tAll Loss: 1.9325\tTriple Loss(1): 0.1074\tClassification Loss: 1.7176\r\n",
      "Train Epoch: 22 [128000/209222 (61%)]\tAll Loss: 1.6778\tTriple Loss(1): 0.1412\tClassification Loss: 1.3953\r\n",
      "Train Epoch: 22 [160000/209222 (76%)]\tAll Loss: 1.9088\tTriple Loss(1): 0.0852\tClassification Loss: 1.7385\r\n",
      "Train Epoch: 22 [192000/209222 (92%)]\tAll Loss: 1.7768\tTriple Loss(1): 0.0949\tClassification Loss: 1.5871\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/22_epochs\r\n",
      "Train Epoch: 23 [0/209222 (0%)]\tAll Loss: 1.8723\tTriple Loss(1): 0.1439\tClassification Loss: 1.5845\r\n",
      "\r\n",
      "Test set: Average loss: 1.3904\r\n",
      "Top 1 Accuracy: 47514/80000 (59%)\r\n",
      "Top 3 Accuracy: 64663/80000 (81%)\r\n",
      "Top 5 Accuracy: 71093/80000 (89%)\r\n",
      " \r\n",
      "Train Epoch: 23 [32000/209222 (15%)]\tAll Loss: 1.1479\tTriple Loss(1): 0.0042\tClassification Loss: 1.1394\r\n",
      "Train Epoch: 23 [64000/209222 (31%)]\tAll Loss: 1.7254\tTriple Loss(1): 0.0929\tClassification Loss: 1.5396\r\n",
      "Train Epoch: 23 [96000/209222 (46%)]\tAll Loss: 1.8694\tTriple Loss(1): 0.0875\tClassification Loss: 1.6943\r\n",
      "Train Epoch: 23 [128000/209222 (61%)]\tAll Loss: 1.4735\tTriple Loss(1): 0.0196\tClassification Loss: 1.4344\r\n",
      "Train Epoch: 23 [160000/209222 (76%)]\tAll Loss: 1.9167\tTriple Loss(1): 0.0350\tClassification Loss: 1.8468\r\n",
      "Train Epoch: 23 [192000/209222 (92%)]\tAll Loss: 1.7338\tTriple Loss(1): 0.0111\tClassification Loss: 1.7115\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/23_epochs\r\n",
      "Train Epoch: 24 [0/209222 (0%)]\tAll Loss: 2.0700\tTriple Loss(1): 0.2788\tClassification Loss: 1.5124\r\n",
      "\r\n",
      "Test set: Average loss: 1.3003\r\n",
      "Top 1 Accuracy: 50013/80000 (63%)\r\n",
      "Top 3 Accuracy: 66677/80000 (83%)\r\n",
      "Top 5 Accuracy: 72392/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 24 [32000/209222 (15%)]\tAll Loss: 1.3412\tTriple Loss(1): 0.0361\tClassification Loss: 1.2691\r\n",
      "Train Epoch: 24 [64000/209222 (31%)]\tAll Loss: 1.5444\tTriple Loss(0): 0.0000\tClassification Loss: 1.5444\r\n",
      "Train Epoch: 24 [96000/209222 (46%)]\tAll Loss: 1.9712\tTriple Loss(1): 0.1087\tClassification Loss: 1.7538\r\n",
      "Train Epoch: 24 [128000/209222 (61%)]\tAll Loss: 1.4051\tTriple Loss(0): 0.0000\tClassification Loss: 1.4051\r\n",
      "Train Epoch: 24 [160000/209222 (76%)]\tAll Loss: 1.7177\tTriple Loss(1): 0.0886\tClassification Loss: 1.5406\r\n",
      "Train Epoch: 24 [192000/209222 (92%)]\tAll Loss: 4.3862\tTriple Loss(0): 1.4267\tClassification Loss: 1.5328\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/24_epochs\r\n",
      "Train Epoch: 25 [0/209222 (0%)]\tAll Loss: 2.1497\tTriple Loss(1): 0.2569\tClassification Loss: 1.6360\r\n",
      "\r\n",
      "Test set: Average loss: 1.2812\r\n",
      "Top 1 Accuracy: 50193/80000 (63%)\r\n",
      "Top 3 Accuracy: 66912/80000 (84%)\r\n",
      "Top 5 Accuracy: 72507/80000 (91%)\r\n",
      " \r\n",
      "Train Epoch: 25 [32000/209222 (15%)]\tAll Loss: 1.0959\tTriple Loss(0): 0.0000\tClassification Loss: 1.0959\r\n",
      "Train Epoch: 25 [64000/209222 (31%)]\tAll Loss: 1.5261\tTriple Loss(1): 0.0239\tClassification Loss: 1.4784\r\n",
      "Train Epoch: 25 [96000/209222 (46%)]\tAll Loss: 1.6870\tTriple Loss(1): 0.0068\tClassification Loss: 1.6733\r\n",
      "Train Epoch: 25 [128000/209222 (61%)]\tAll Loss: 1.7412\tTriple Loss(1): 0.0733\tClassification Loss: 1.5946\r\n",
      "Train Epoch: 25 [160000/209222 (76%)]\tAll Loss: 1.8310\tTriple Loss(0): 0.0000\tClassification Loss: 1.8310\r\n",
      "Train Epoch: 25 [192000/209222 (92%)]\tAll Loss: 1.8355\tTriple Loss(1): 0.0924\tClassification Loss: 1.6508\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/25_epochs\r\n",
      "Train Epoch: 26 [0/209222 (0%)]\tAll Loss: 7.1886\tTriple Loss(0): 2.6894\tClassification Loss: 1.8099\r\n",
      "\r\n",
      "Test set: Average loss: 1.5254\r\n",
      "Top 1 Accuracy: 44866/80000 (56%)\r\n",
      "Top 3 Accuracy: 62580/80000 (78%)\r\n",
      "Top 5 Accuracy: 69362/80000 (87%)\r\n",
      " \r\n",
      "Train Epoch: 26 [32000/209222 (15%)]\tAll Loss: 1.3380\tTriple Loss(1): 0.0163\tClassification Loss: 1.3053\r\n",
      "Train Epoch: 26 [64000/209222 (31%)]\tAll Loss: 1.6408\tTriple Loss(0): 0.0000\tClassification Loss: 1.6408\r\n",
      "Train Epoch: 26 [96000/209222 (46%)]\tAll Loss: 1.6642\tTriple Loss(1): 0.0242\tClassification Loss: 1.6158\r\n",
      "Train Epoch: 26 [128000/209222 (61%)]\tAll Loss: 1.5501\tTriple Loss(1): 0.0178\tClassification Loss: 1.5146\r\n",
      "Train Epoch: 26 [160000/209222 (76%)]\tAll Loss: 1.6068\tTriple Loss(0): 0.0000\tClassification Loss: 1.6068\r\n",
      "Train Epoch: 26 [192000/209222 (92%)]\tAll Loss: 1.6974\tTriple Loss(1): 0.0206\tClassification Loss: 1.6561\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/26_epochs\r\n",
      "Train Epoch: 27 [0/209222 (0%)]\tAll Loss: 1.5481\tTriple Loss(0): 0.0000\tClassification Loss: 1.5481\r\n",
      "\r\n",
      "Test set: Average loss: 1.2997\r\n",
      "Top 1 Accuracy: 49851/80000 (62%)\r\n",
      "Top 3 Accuracy: 66599/80000 (83%)\r\n",
      "Top 5 Accuracy: 72348/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 27 [32000/209222 (15%)]\tAll Loss: 1.6282\tTriple Loss(1): 0.2078\tClassification Loss: 1.2125\r\n",
      "Train Epoch: 27 [64000/209222 (31%)]\tAll Loss: 1.5413\tTriple Loss(1): 0.0440\tClassification Loss: 1.4532\r\n",
      "Train Epoch: 27 [96000/209222 (46%)]\tAll Loss: 1.7877\tTriple Loss(1): 0.0464\tClassification Loss: 1.6949\r\n",
      "Train Epoch: 27 [128000/209222 (61%)]\tAll Loss: 1.6147\tTriple Loss(1): 0.1025\tClassification Loss: 1.4098\r\n",
      "Train Epoch: 27 [160000/209222 (76%)]\tAll Loss: 1.7927\tTriple Loss(1): 0.1370\tClassification Loss: 1.5188\r\n",
      "Train Epoch: 27 [192000/209222 (92%)]\tAll Loss: 1.5316\tTriple Loss(0): 0.0000\tClassification Loss: 1.5316\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/27_epochs\r\n",
      "Train Epoch: 28 [0/209222 (0%)]\tAll Loss: 1.9278\tTriple Loss(1): 0.2067\tClassification Loss: 1.5144\r\n",
      "\r\n",
      "Test set: Average loss: 1.3041\r\n",
      "Top 1 Accuracy: 49574/80000 (62%)\r\n",
      "Top 3 Accuracy: 66468/80000 (83%)\r\n",
      "Top 5 Accuracy: 72317/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 28 [32000/209222 (15%)]\tAll Loss: 1.3260\tTriple Loss(1): 0.0497\tClassification Loss: 1.2266\r\n",
      "Train Epoch: 28 [64000/209222 (31%)]\tAll Loss: 1.4815\tTriple Loss(0): 0.0000\tClassification Loss: 1.4815\r\n",
      "Train Epoch: 28 [96000/209222 (46%)]\tAll Loss: 1.4764\tTriple Loss(0): 0.0000\tClassification Loss: 1.4764\r\n",
      "Train Epoch: 28 [128000/209222 (61%)]\tAll Loss: 1.6899\tTriple Loss(1): 0.1273\tClassification Loss: 1.4354\r\n",
      "Train Epoch: 28 [160000/209222 (76%)]\tAll Loss: 1.5621\tTriple Loss(1): 0.0116\tClassification Loss: 1.5389\r\n",
      "Train Epoch: 28 [192000/209222 (92%)]\tAll Loss: 1.8435\tTriple Loss(1): 0.0420\tClassification Loss: 1.7596\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/28_epochs\r\n",
      "Train Epoch: 29 [0/209222 (0%)]\tAll Loss: 1.4295\tTriple Loss(0): 0.0000\tClassification Loss: 1.4295\r\n",
      "\r\n",
      "Test set: Average loss: 1.2937\r\n",
      "Top 1 Accuracy: 49979/80000 (62%)\r\n",
      "Top 3 Accuracy: 66603/80000 (83%)\r\n",
      "Top 5 Accuracy: 72370/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 29 [32000/209222 (15%)]\tAll Loss: 1.4815\tTriple Loss(1): 0.0485\tClassification Loss: 1.3844\r\n",
      "Train Epoch: 29 [64000/209222 (31%)]\tAll Loss: 1.5651\tTriple Loss(1): 0.0294\tClassification Loss: 1.5062\r\n",
      "Train Epoch: 29 [96000/209222 (46%)]\tAll Loss: 1.9207\tTriple Loss(0): 0.0000\tClassification Loss: 1.9207\r\n",
      "Train Epoch: 29 [128000/209222 (61%)]\tAll Loss: 1.3447\tTriple Loss(0): 0.0000\tClassification Loss: 1.3447\r\n",
      "Train Epoch: 29 [160000/209222 (76%)]\tAll Loss: 1.6548\tTriple Loss(1): 0.0273\tClassification Loss: 1.6003\r\n",
      "Train Epoch: 29 [192000/209222 (92%)]\tAll Loss: 1.5000\tTriple Loss(0): 0.0000\tClassification Loss: 1.5000\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/29_epochs\r\n",
      "Train Epoch: 30 [0/209222 (0%)]\tAll Loss: 2.1086\tTriple Loss(1): 0.2358\tClassification Loss: 1.6371\r\n",
      "\r\n",
      "Test set: Average loss: 1.2710\r\n",
      "Top 1 Accuracy: 50515/80000 (63%)\r\n",
      "Top 3 Accuracy: 67118/80000 (84%)\r\n",
      "Top 5 Accuracy: 72726/80000 (91%)\r\n",
      " \r\n",
      "Train Epoch: 30 [32000/209222 (15%)]\tAll Loss: 1.4715\tTriple Loss(1): 0.1115\tClassification Loss: 1.2485\r\n",
      "Train Epoch: 30 [64000/209222 (31%)]\tAll Loss: 1.5765\tTriple Loss(1): 0.0686\tClassification Loss: 1.4393\r\n",
      "Train Epoch: 30 [96000/209222 (46%)]\tAll Loss: 1.6756\tTriple Loss(0): 0.0000\tClassification Loss: 1.6756\r\n",
      "Train Epoch: 30 [128000/209222 (61%)]\tAll Loss: 1.6649\tTriple Loss(1): 0.1467\tClassification Loss: 1.3716\r\n",
      "Train Epoch: 30 [160000/209222 (76%)]\tAll Loss: 1.6042\tTriple Loss(1): 0.0397\tClassification Loss: 1.5247\r\n",
      "Train Epoch: 30 [192000/209222 (92%)]\tAll Loss: 1.9966\tTriple Loss(1): 0.1483\tClassification Loss: 1.7000\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/30_epochs\r\n"
     ]
    }
   ],
   "source": [
    "# Continuing \"models/freeze=False/lr=0.001/11_epochs\"\n",
    "# FREEZE = False. LR=0.001. in-shop=True.\n",
    "! python train.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "Loading model freeze=False/lr=0.001/30_epochs\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\r\n",
      "  warnings.warn(msg, category=FutureWarning)\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Loading model freeze=False/lr=0.001/30_epochs\r\n",
      "Train Epoch: 30 [0/209222 (0%)]\tAll Loss: 2.6941\tTriple Loss(1): 0.3309\tClassification Loss: 2.0323\r\n",
      "train.py:211: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 1.3078\r\n",
      "Top 1 Accuracy: 49601/80000 (62%)\r\n",
      "Top 3 Accuracy: 66543/80000 (83%)\r\n",
      "Top 5 Accuracy: 72373/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 30 [32000/209222 (15%)]\tAll Loss: 1.9181\tTriple Loss(1): 0.1279\tClassification Loss: 1.6623\r\n",
      "Train Epoch: 30 [64000/209222 (31%)]\tAll Loss: 2.1724\tTriple Loss(1): 0.0974\tClassification Loss: 1.9775\r\n",
      "Train Epoch: 30 [96000/209222 (46%)]\tAll Loss: 1.7544\tTriple Loss(1): 0.1008\tClassification Loss: 1.5529\r\n",
      "Train Epoch: 30 [128000/209222 (61%)]\tAll Loss: 1.7980\tTriple Loss(1): 0.0503\tClassification Loss: 1.6974\r\n",
      "Train Epoch: 30 [160000/209222 (76%)]\tAll Loss: 1.9695\tTriple Loss(1): 0.0478\tClassification Loss: 1.8738\r\n",
      "Train Epoch: 30 [192000/209222 (92%)]\tAll Loss: 1.8118\tTriple Loss(1): 0.0053\tClassification Loss: 1.8012\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/30_epochs\r\n",
      "Train Epoch: 31 [0/209222 (0%)]\tAll Loss: 2.4121\tTriple Loss(1): 0.3101\tClassification Loss: 1.7919\r\n",
      "\r\n",
      "Test set: Average loss: 1.3253\r\n",
      "Top 1 Accuracy: 49392/80000 (62%)\r\n",
      "Top 3 Accuracy: 66083/80000 (83%)\r\n",
      "Top 5 Accuracy: 71978/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 31 [32000/209222 (15%)]\tAll Loss: 1.4103\tTriple Loss(0): 0.0000\tClassification Loss: 1.4103\r\n",
      "Train Epoch: 31 [64000/209222 (31%)]\tAll Loss: 2.0936\tTriple Loss(1): 0.0764\tClassification Loss: 1.9407\r\n",
      "Train Epoch: 31 [96000/209222 (46%)]\tAll Loss: 1.5586\tTriple Loss(1): 0.1145\tClassification Loss: 1.3297\r\n",
      "Train Epoch: 31 [128000/209222 (61%)]\tAll Loss: 1.5351\tTriple Loss(1): 0.0807\tClassification Loss: 1.3738\r\n",
      "Train Epoch: 31 [160000/209222 (76%)]\tAll Loss: 1.8872\tTriple Loss(1): 0.0491\tClassification Loss: 1.7891\r\n",
      "Train Epoch: 31 [192000/209222 (92%)]\tAll Loss: 2.0250\tTriple Loss(1): 0.1465\tClassification Loss: 1.7321\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/31_epochs\r\n",
      "Train Epoch: 32 [0/209222 (0%)]\tAll Loss: 2.4566\tTriple Loss(1): 0.2200\tClassification Loss: 2.0165\r\n",
      "\r\n",
      "Test set: Average loss: 1.4565\r\n",
      "Top 1 Accuracy: 46328/80000 (58%)\r\n",
      "Top 3 Accuracy: 63723/80000 (80%)\r\n",
      "Top 5 Accuracy: 70313/80000 (88%)\r\n",
      " \r\n",
      "Train Epoch: 32 [32000/209222 (15%)]\tAll Loss: 1.6245\tTriple Loss(1): 0.0908\tClassification Loss: 1.4429\r\n",
      "Train Epoch: 32 [64000/209222 (31%)]\tAll Loss: 1.7534\tTriple Loss(0): 0.0000\tClassification Loss: 1.7534\r\n",
      "Train Epoch: 32 [96000/209222 (46%)]\tAll Loss: 1.3518\tTriple Loss(1): 0.0683\tClassification Loss: 1.2151\r\n",
      "Train Epoch: 32 [128000/209222 (61%)]\tAll Loss: 3.1919\tTriple Loss(0): 0.8905\tClassification Loss: 1.4110\r\n",
      "Train Epoch: 32 [160000/209222 (76%)]\tAll Loss: 1.8273\tTriple Loss(1): 0.0443\tClassification Loss: 1.7387\r\n",
      "Train Epoch: 32 [192000/209222 (92%)]\tAll Loss: 1.9723\tTriple Loss(1): 0.0303\tClassification Loss: 1.9116\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/32_epochs\r\n",
      "Train Epoch: 33 [0/209222 (0%)]\tAll Loss: 1.9818\tTriple Loss(1): 0.1218\tClassification Loss: 1.7383\r\n",
      "\r\n",
      "Test set: Average loss: 1.3886\r\n",
      "Top 1 Accuracy: 48223/80000 (60%)\r\n",
      "Top 3 Accuracy: 64773/80000 (81%)\r\n",
      "Top 5 Accuracy: 70915/80000 (89%)\r\n",
      " \r\n",
      "Train Epoch: 33 [32000/209222 (15%)]\tAll Loss: 1.4909\tTriple Loss(1): 0.0731\tClassification Loss: 1.3448\r\n",
      "Train Epoch: 33 [64000/209222 (31%)]\tAll Loss: 1.8093\tTriple Loss(1): 0.0685\tClassification Loss: 1.6722\r\n",
      "Train Epoch: 33 [96000/209222 (46%)]\tAll Loss: 1.4731\tTriple Loss(1): 0.0453\tClassification Loss: 1.3825\r\n",
      "Train Epoch: 33 [128000/209222 (61%)]\tAll Loss: 1.7903\tTriple Loss(1): 0.1824\tClassification Loss: 1.4254\r\n",
      "Train Epoch: 33 [160000/209222 (76%)]\tAll Loss: 1.7331\tTriple Loss(0): 0.0000\tClassification Loss: 1.7331\r\n",
      "Train Epoch: 33 [192000/209222 (92%)]\tAll Loss: 2.1235\tTriple Loss(1): 0.0839\tClassification Loss: 1.9558\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/33_epochs\r\n",
      "Train Epoch: 34 [0/209222 (0%)]\tAll Loss: 1.9937\tTriple Loss(0): 0.0000\tClassification Loss: 1.9937\r\n",
      "\r\n",
      "Test set: Average loss: 1.3396\r\n",
      "Top 1 Accuracy: 48963/80000 (61%)\r\n",
      "Top 3 Accuracy: 65876/80000 (82%)\r\n",
      "Top 5 Accuracy: 71858/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 34 [32000/209222 (15%)]\tAll Loss: 1.6978\tTriple Loss(0): 0.1823\tClassification Loss: 1.3332\r\n",
      "Train Epoch: 34 [64000/209222 (31%)]\tAll Loss: 1.9933\tTriple Loss(1): 0.0683\tClassification Loss: 1.8568\r\n",
      "Train Epoch: 34 [96000/209222 (46%)]\tAll Loss: 1.5360\tTriple Loss(0): 0.0000\tClassification Loss: 1.5360\r\n",
      "Train Epoch: 34 [128000/209222 (61%)]\tAll Loss: 1.4894\tTriple Loss(0): 0.0000\tClassification Loss: 1.4894\r\n",
      "Train Epoch: 34 [160000/209222 (76%)]\tAll Loss: 1.8964\tTriple Loss(1): 0.0000\tClassification Loss: 1.8964\r\n",
      "Train Epoch: 34 [192000/209222 (92%)]\tAll Loss: 1.8835\tTriple Loss(0): 0.0000\tClassification Loss: 1.8835\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/34_epochs\r\n",
      "Train Epoch: 35 [0/209222 (0%)]\tAll Loss: 2.3856\tTriple Loss(1): 0.2452\tClassification Loss: 1.8952\r\n",
      "\r\n",
      "Test set: Average loss: 1.3285\r\n",
      "Top 1 Accuracy: 49442/80000 (62%)\r\n",
      "Top 3 Accuracy: 66087/80000 (83%)\r\n",
      "Top 5 Accuracy: 72014/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 35 [32000/209222 (15%)]\tAll Loss: 1.5216\tTriple Loss(1): 0.0940\tClassification Loss: 1.3335\r\n",
      "Train Epoch: 35 [64000/209222 (31%)]\tAll Loss: 1.9986\tTriple Loss(1): 0.0519\tClassification Loss: 1.8949\r\n",
      "Train Epoch: 35 [96000/209222 (46%)]\tAll Loss: 1.3708\tTriple Loss(1): 0.0054\tClassification Loss: 1.3600\r\n",
      "Train Epoch: 35 [128000/209222 (61%)]\tAll Loss: 1.4992\tTriple Loss(1): 0.0593\tClassification Loss: 1.3806\r\n",
      "Train Epoch: 35 [160000/209222 (76%)]\tAll Loss: 2.1249\tTriple Loss(1): 0.1636\tClassification Loss: 1.7977\r\n",
      "Train Epoch: 35 [192000/209222 (92%)]\tAll Loss: 2.9075\tTriple Loss(0): 0.5775\tClassification Loss: 1.7526\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/35_epochs\r\n"
     ]
    }
   ],
   "source": [
    "# Continuing \"models/freeze=False/lr=0.001/30_epochs\"\n",
    "# FREEZE = False. LR=0.001. in-shop=True.\n",
    "! python train.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "Loading model freeze=False/lr=0.001/35_epochs\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\r\n",
      "  warnings.warn(msg, category=FutureWarning)\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Loading model freeze=False/lr=0.001/35_epochs\r\n",
      "Train Epoch: 36 [0/209222 (0%)]\tAll Loss: 2.7008\tTriple Loss(1): 0.4123\tClassification Loss: 1.8762\r\n",
      "train.py:211: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 1.3492\r\n",
      "Top 1 Accuracy: 48885/80000 (61%)\r\n",
      "Top 3 Accuracy: 65530/80000 (82%)\r\n",
      "Top 5 Accuracy: 71684/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 36 [32000/209222 (15%)]\tAll Loss: 2.0340\tTriple Loss(1): 0.0123\tClassification Loss: 2.0094\r\n",
      "Train Epoch: 36 [64000/209222 (31%)]\tAll Loss: 1.2264\tTriple Loss(0): 0.0000\tClassification Loss: 1.2264\r\n",
      "Train Epoch: 36 [96000/209222 (46%)]\tAll Loss: 1.6258\tTriple Loss(1): 0.0920\tClassification Loss: 1.4417\r\n",
      "Train Epoch: 36 [128000/209222 (61%)]\tAll Loss: 2.0134\tTriple Loss(1): 0.1649\tClassification Loss: 1.6836\r\n",
      "Train Epoch: 36 [160000/209222 (76%)]\tAll Loss: 1.6589\tTriple Loss(0): 0.0000\tClassification Loss: 1.6589\r\n",
      "Train Epoch: 36 [192000/209222 (92%)]\tAll Loss: 1.7822\tTriple Loss(1): 0.0701\tClassification Loss: 1.6420\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/36_epochs\r\n",
      "Train Epoch: 37 [0/209222 (0%)]\tAll Loss: 2.1207\tTriple Loss(1): 0.2610\tClassification Loss: 1.5986\r\n",
      "\r\n",
      "Test set: Average loss: 1.2983\r\n",
      "Top 1 Accuracy: 49855/80000 (62%)\r\n",
      "Top 3 Accuracy: 66437/80000 (83%)\r\n",
      "Top 5 Accuracy: 72260/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 37 [32000/209222 (15%)]\tAll Loss: 1.7590\tTriple Loss(1): 0.1068\tClassification Loss: 1.5453\r\n",
      "Train Epoch: 37 [64000/209222 (31%)]\tAll Loss: 1.2852\tTriple Loss(0): 0.0000\tClassification Loss: 1.2852\r\n",
      "Train Epoch: 37 [96000/209222 (46%)]\tAll Loss: 1.3542\tTriple Loss(1): 0.0414\tClassification Loss: 1.2715\r\n",
      "Train Epoch: 37 [128000/209222 (61%)]\tAll Loss: 1.5621\tTriple Loss(0): 0.0000\tClassification Loss: 1.5621\r\n",
      "Train Epoch: 37 [160000/209222 (76%)]\tAll Loss: 1.7482\tTriple Loss(1): 0.0335\tClassification Loss: 1.6811\r\n",
      "Train Epoch: 37 [192000/209222 (92%)]\tAll Loss: 17.3824\tTriple Loss(0): 7.7851\tClassification Loss: 1.8122\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/37_epochs\r\n",
      "Train Epoch: 38 [0/209222 (0%)]\tAll Loss: 2.0768\tTriple Loss(1): 0.1873\tClassification Loss: 1.7023\r\n",
      "\r\n",
      "Test set: Average loss: 1.3189\r\n",
      "Top 1 Accuracy: 49730/80000 (62%)\r\n",
      "Top 3 Accuracy: 66210/80000 (83%)\r\n",
      "Top 5 Accuracy: 72021/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 38 [32000/209222 (15%)]\tAll Loss: 2.0088\tTriple Loss(1): 0.1682\tClassification Loss: 1.6724\r\n",
      "Train Epoch: 38 [64000/209222 (31%)]\tAll Loss: 1.3004\tTriple Loss(1): 0.0386\tClassification Loss: 1.2231\r\n",
      "Train Epoch: 38 [96000/209222 (46%)]\tAll Loss: 1.4203\tTriple Loss(1): 0.0726\tClassification Loss: 1.2752\r\n",
      "Train Epoch: 38 [128000/209222 (61%)]\tAll Loss: 1.7374\tTriple Loss(1): 0.0952\tClassification Loss: 1.5470\r\n",
      "Train Epoch: 38 [160000/209222 (76%)]\tAll Loss: 7.2645\tTriple Loss(0): 2.7245\tClassification Loss: 1.8154\r\n",
      "Train Epoch: 38 [192000/209222 (92%)]\tAll Loss: 2.1441\tTriple Loss(1): 0.1865\tClassification Loss: 1.7711\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/38_epochs\r\n",
      "Train Epoch: 39 [0/209222 (0%)]\tAll Loss: 9.1340\tTriple Loss(0): 3.6938\tClassification Loss: 1.7464\r\n",
      "\r\n",
      "Test set: Average loss: 1.2934\r\n",
      "Top 1 Accuracy: 50029/80000 (63%)\r\n",
      "Top 3 Accuracy: 66518/80000 (83%)\r\n",
      "Top 5 Accuracy: 72283/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 39 [32000/209222 (15%)]\tAll Loss: 1.5645\tTriple Loss(1): 0.0056\tClassification Loss: 1.5533\r\n",
      "Train Epoch: 39 [64000/209222 (31%)]\tAll Loss: 1.4052\tTriple Loss(1): 0.0407\tClassification Loss: 1.3238\r\n",
      "Train Epoch: 39 [96000/209222 (46%)]\tAll Loss: 1.5595\tTriple Loss(1): 0.1294\tClassification Loss: 1.3006\r\n",
      "Train Epoch: 39 [128000/209222 (61%)]\tAll Loss: 1.5319\tTriple Loss(1): 0.0071\tClassification Loss: 1.5177\r\n",
      "Train Epoch: 39 [160000/209222 (76%)]\tAll Loss: 1.7899\tTriple Loss(0): 0.0000\tClassification Loss: 1.7899\r\n",
      "Train Epoch: 39 [192000/209222 (92%)]\tAll Loss: 1.8665\tTriple Loss(1): 0.0635\tClassification Loss: 1.7394\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/39_epochs\r\n",
      "Train Epoch: 40 [0/209222 (0%)]\tAll Loss: 2.2265\tTriple Loss(1): 0.3530\tClassification Loss: 1.5206\r\n",
      "\r\n",
      "Test set: Average loss: 1.3117\r\n",
      "Top 1 Accuracy: 49714/80000 (62%)\r\n",
      "Top 3 Accuracy: 66284/80000 (83%)\r\n",
      "Top 5 Accuracy: 72079/80000 (90%)\r\n",
      " \r\n",
      "Train Epoch: 40 [32000/209222 (15%)]\tAll Loss: 1.7171\tTriple Loss(1): 0.0337\tClassification Loss: 1.6497\r\n",
      "Train Epoch: 40 [64000/209222 (31%)]\tAll Loss: 1.2704\tTriple Loss(1): 0.0164\tClassification Loss: 1.2376\r\n",
      "Train Epoch: 40 [96000/209222 (46%)]\tAll Loss: 1.6456\tTriple Loss(1): 0.0939\tClassification Loss: 1.4578\r\n",
      "Train Epoch: 40 [128000/209222 (61%)]\tAll Loss: 1.5449\tTriple Loss(0): 0.0000\tClassification Loss: 1.5449\r\n",
      "Train Epoch: 40 [160000/209222 (76%)]\tAll Loss: 1.8320\tTriple Loss(1): 0.0698\tClassification Loss: 1.6924\r\n",
      "Train Epoch: 40 [192000/209222 (92%)]\tAll Loss: 1.8431\tTriple Loss(1): 0.0400\tClassification Loss: 1.7631\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.001/40_epochs\r\n"
     ]
    }
   ],
   "source": [
    "# Continuing \"models/freeze=False/lr=0.001/35_epochs\"\n",
    "# FREEZE = False. LR=0.001. in-shop=True.\n",
    "! python train.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "100%|| 14218/14218 [04:24<00:00, 53.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model freeze=False/lr=0.001/29_epochs\n",
      "Extracting features of in-shop test images.\n",
      "0 / 12612\n",
      "0 / 14218\n",
      "n = 1. Accuracy = 61.50%.\n",
      "n = 10. Accuracy = 87.33%.\n",
      "n = 20. Accuracy = 91.51%.\n",
      "n = 50. Accuracy = 95.20%.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{1: 61.499507666338445,\n 10: 87.32592488394992,\n 20: 91.510761007174,\n 50: 95.20326346884231}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing best model (29_epochs) on in-shop retrieval\n",
    "from in_shop_eval import eval\n",
    "eval()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\r\n",
      "  warnings.warn(msg, category=FutureWarning)\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Train Epoch: 1 [0/209222 (0%)]\tAll Loss: 5.0796\tTriple Loss(1): 0.5479\tClassification Loss: 3.9838\r\n",
      "train.py:211: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 3.9415\r\n",
      "Top 1 Accuracy: 549/80000 (1%)\r\n",
      "Top 3 Accuracy: 2017/80000 (3%)\r\n",
      "Top 5 Accuracy: 3580/80000 (4%)\r\n",
      " \r\n",
      "Train Epoch: 1 [32000/209222 (15%)]\tAll Loss: 4.5420\tTriple Loss(1): 0.7815\tClassification Loss: 2.9790\r\n",
      "Train Epoch: 1 [64000/209222 (31%)]\tAll Loss: 4.3550\tTriple Loss(1): 0.7060\tClassification Loss: 2.9430\r\n",
      "Train Epoch: 1 [96000/209222 (46%)]\tAll Loss: 4.0740\tTriple Loss(1): 0.6593\tClassification Loss: 2.7553\r\n",
      "Train Epoch: 1 [128000/209222 (61%)]\tAll Loss: 6.4166\tTriple Loss(0): 1.8121\tClassification Loss: 2.7924\r\n",
      "Train Epoch: 1 [160000/209222 (76%)]\tAll Loss: 4.4957\tTriple Loss(1): 0.8889\tClassification Loss: 2.7180\r\n",
      "Train Epoch: 1 [192000/209222 (92%)]\tAll Loss: 3.9002\tTriple Loss(1): 0.6539\tClassification Loss: 2.5924\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.002/1_epochs\r\n",
      "Train Epoch: 2 [0/209222 (0%)]\tAll Loss: 4.4130\tTriple Loss(1): 0.6332\tClassification Loss: 3.1465\r\n",
      "\r\n",
      "Test set: Average loss: 2.7041\r\n",
      "Top 1 Accuracy: 20025/80000 (25%)\r\n",
      "Top 3 Accuracy: 37059/80000 (46%)\r\n",
      "Top 5 Accuracy: 47001/80000 (59%)\r\n",
      " \r\n",
      "Train Epoch: 2 [32000/209222 (15%)]\tAll Loss: 4.8207\tTriple Loss(1): 0.9327\tClassification Loss: 2.9553\r\n",
      "Train Epoch: 2 [64000/209222 (31%)]\tAll Loss: 4.3064\tTriple Loss(1): 0.6685\tClassification Loss: 2.9695\r\n",
      "Train Epoch: 2 [96000/209222 (46%)]\tAll Loss: 2.7490\tTriple Loss(0): 0.0000\tClassification Loss: 2.7490\r\n",
      "Train Epoch: 2 [128000/209222 (61%)]\tAll Loss: 4.1369\tTriple Loss(1): 0.6999\tClassification Loss: 2.7370\r\n",
      "Train Epoch: 2 [160000/209222 (76%)]\tAll Loss: 3.6858\tTriple Loss(1): 0.5161\tClassification Loss: 2.6535\r\n",
      "Train Epoch: 2 [192000/209222 (92%)]\tAll Loss: 4.1885\tTriple Loss(1): 0.8172\tClassification Loss: 2.5541\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.002/2_epochs\r\n",
      "Train Epoch: 3 [0/209222 (0%)]\tAll Loss: 4.4271\tTriple Loss(0): 0.8358\tClassification Loss: 2.7554\r\n",
      "\r\n",
      "Test set: Average loss: 2.6745\r\n",
      "Top 1 Accuracy: 20020/80000 (25%)\r\n",
      "Top 3 Accuracy: 37323/80000 (47%)\r\n",
      "Top 5 Accuracy: 48740/80000 (61%)\r\n",
      " \r\n",
      "Train Epoch: 3 [32000/209222 (15%)]\tAll Loss: 3.9146\tTriple Loss(1): 0.5233\tClassification Loss: 2.8681\r\n",
      "Train Epoch: 3 [64000/209222 (31%)]\tAll Loss: 3.7915\tTriple Loss(1): 0.4801\tClassification Loss: 2.8314\r\n",
      "Train Epoch: 3 [96000/209222 (46%)]\tAll Loss: 5.2415\tTriple Loss(0): 1.2655\tClassification Loss: 2.7105\r\n",
      "Train Epoch: 3 [128000/209222 (61%)]\tAll Loss: 3.8056\tTriple Loss(0): 0.6193\tClassification Loss: 2.5669\r\n",
      "Train Epoch: 3 [160000/209222 (76%)]\tAll Loss: 2.6280\tTriple Loss(0): 0.0000\tClassification Loss: 2.6280\r\n",
      "Train Epoch: 3 [192000/209222 (92%)]\tAll Loss: 3.1811\tTriple Loss(1): 0.4027\tClassification Loss: 2.3757\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.002/3_epochs\r\n",
      "Train Epoch: 4 [0/209222 (0%)]\tAll Loss: 3.6598\tTriple Loss(1): 0.5295\tClassification Loss: 2.6009\r\n",
      "\r\n",
      "Test set: Average loss: 2.5321\r\n",
      "Top 1 Accuracy: 22531/80000 (28%)\r\n",
      "Top 3 Accuracy: 38668/80000 (48%)\r\n",
      "Top 5 Accuracy: 50285/80000 (63%)\r\n",
      " \r\n",
      "Train Epoch: 4 [32000/209222 (15%)]\tAll Loss: 3.5825\tTriple Loss(1): 0.4111\tClassification Loss: 2.7603\r\n",
      "Train Epoch: 4 [64000/209222 (31%)]\tAll Loss: 2.7531\tTriple Loss(0): 0.0000\tClassification Loss: 2.7531\r\n",
      "Train Epoch: 4 [96000/209222 (46%)]\tAll Loss: 3.8305\tTriple Loss(1): 0.5597\tClassification Loss: 2.7110\r\n",
      "Train Epoch: 4 [128000/209222 (61%)]\tAll Loss: 3.4494\tTriple Loss(1): 0.4094\tClassification Loss: 2.6306\r\n",
      "Train Epoch: 4 [160000/209222 (76%)]\tAll Loss: 3.6620\tTriple Loss(1): 0.5093\tClassification Loss: 2.6433\r\n",
      "Train Epoch: 4 [192000/209222 (92%)]\tAll Loss: 3.0877\tTriple Loss(1): 0.4046\tClassification Loss: 2.2785\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.002/4_epochs\r\n",
      "Train Epoch: 5 [0/209222 (0%)]\tAll Loss: 3.1631\tTriple Loss(1): 0.4043\tClassification Loss: 2.3545\r\n",
      "\r\n",
      "Test set: Average loss: 2.4083\r\n",
      "Top 1 Accuracy: 24492/80000 (31%)\r\n",
      "Top 3 Accuracy: 42869/80000 (54%)\r\n",
      "Top 5 Accuracy: 53151/80000 (66%)\r\n",
      " \r\n",
      "Train Epoch: 5 [32000/209222 (15%)]\tAll Loss: 2.9665\tTriple Loss(1): 0.2095\tClassification Loss: 2.5476\r\n",
      "Train Epoch: 5 [64000/209222 (31%)]\tAll Loss: 2.8068\tTriple Loss(1): 0.1326\tClassification Loss: 2.5416\r\n",
      "Train Epoch: 5 [96000/209222 (46%)]\tAll Loss: 3.1306\tTriple Loss(1): 0.3389\tClassification Loss: 2.4528\r\n",
      "Train Epoch: 5 [128000/209222 (61%)]\tAll Loss: 2.2665\tTriple Loss(0): 0.0000\tClassification Loss: 2.2665\r\n",
      "Train Epoch: 5 [160000/209222 (76%)]\tAll Loss: 2.4218\tTriple Loss(0): 0.0000\tClassification Loss: 2.4218\r\n",
      "Train Epoch: 5 [192000/209222 (92%)]\tAll Loss: 3.4224\tTriple Loss(1): 0.5864\tClassification Loss: 2.2497\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.002/5_epochs\r\n",
      "Train Epoch: 6 [0/209222 (0%)]\tAll Loss: 2.9984\tTriple Loss(1): 0.3696\tClassification Loss: 2.2592\r\n",
      "\r\n",
      "Test set: Average loss: 2.2573\r\n",
      "Top 1 Accuracy: 27814/80000 (35%)\r\n",
      "Top 3 Accuracy: 46004/80000 (58%)\r\n",
      "Top 5 Accuracy: 57267/80000 (72%)\r\n",
      " \r\n",
      "Train Epoch: 6 [32000/209222 (15%)]\tAll Loss: 3.0034\tTriple Loss(1): 0.2264\tClassification Loss: 2.5506\r\n",
      "Train Epoch: 6 [64000/209222 (31%)]\tAll Loss: 2.7003\tTriple Loss(1): 0.1533\tClassification Loss: 2.3936\r\n",
      "Train Epoch: 6 [96000/209222 (46%)]\tAll Loss: 2.5595\tTriple Loss(0): 0.0000\tClassification Loss: 2.5595\r\n",
      "Train Epoch: 6 [128000/209222 (61%)]\tAll Loss: 2.2385\tTriple Loss(0): 0.0000\tClassification Loss: 2.2385\r\n",
      "Train Epoch: 6 [160000/209222 (76%)]\tAll Loss: 2.2207\tTriple Loss(0): 0.0000\tClassification Loss: 2.2207\r\n",
      "Train Epoch: 6 [192000/209222 (92%)]\tAll Loss: 2.2400\tTriple Loss(1): 0.2072\tClassification Loss: 1.8256\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.002/6_epochs\r\n",
      "Train Epoch: 7 [0/209222 (0%)]\tAll Loss: 2.9010\tTriple Loss(1): 0.3194\tClassification Loss: 2.2622\r\n",
      "\r\n",
      "Test set: Average loss: 1.9848\r\n",
      "Top 1 Accuracy: 33807/80000 (42%)\r\n",
      "Top 3 Accuracy: 53175/80000 (66%)\r\n",
      "Top 5 Accuracy: 62434/80000 (78%)\r\n",
      " \r\n",
      "Train Epoch: 7 [32000/209222 (15%)]\tAll Loss: 2.5146\tTriple Loss(1): 0.0923\tClassification Loss: 2.3299\r\n",
      "Train Epoch: 7 [64000/209222 (31%)]\tAll Loss: 2.3419\tTriple Loss(0): 0.0000\tClassification Loss: 2.3419\r\n",
      "Train Epoch: 7 [96000/209222 (46%)]\tAll Loss: 2.9821\tTriple Loss(1): 0.2599\tClassification Loss: 2.4623\r\n",
      "Train Epoch: 7 [128000/209222 (61%)]\tAll Loss: 2.5718\tTriple Loss(1): 0.1442\tClassification Loss: 2.2834\r\n",
      "Train Epoch: 7 [160000/209222 (76%)]\tAll Loss: 2.8403\tTriple Loss(1): 0.3291\tClassification Loss: 2.1821\r\n",
      "Train Epoch: 7 [192000/209222 (92%)]\tAll Loss: 2.5501\tTriple Loss(1): 0.3376\tClassification Loss: 1.8748\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.002/7_epochs\r\n",
      "Train Epoch: 8 [0/209222 (0%)]\tAll Loss: 2.5025\tTriple Loss(1): 0.2078\tClassification Loss: 2.0869\r\n",
      "\r\n",
      "Test set: Average loss: 1.9855\r\n",
      "Top 1 Accuracy: 34636/80000 (43%)\r\n",
      "Top 3 Accuracy: 53317/80000 (67%)\r\n",
      "Top 5 Accuracy: 62636/80000 (78%)\r\n",
      " \r\n",
      "Train Epoch: 8 [32000/209222 (15%)]\tAll Loss: 3.1020\tTriple Loss(1): 0.3837\tClassification Loss: 2.3347\r\n",
      "Train Epoch: 8 [64000/209222 (31%)]\tAll Loss: 3.3249\tTriple Loss(1): 0.4485\tClassification Loss: 2.4279\r\n",
      "Train Epoch: 8 [96000/209222 (46%)]\tAll Loss: 2.8052\tTriple Loss(1): 0.2225\tClassification Loss: 2.3602\r\n",
      "Train Epoch: 8 [128000/209222 (61%)]\tAll Loss: 2.0906\tTriple Loss(0): 0.0000\tClassification Loss: 2.0906\r\n",
      "Train Epoch: 8 [160000/209222 (76%)]\tAll Loss: 2.3391\tTriple Loss(1): 0.1759\tClassification Loss: 1.9872\r\n",
      "Train Epoch: 8 [192000/209222 (92%)]\tAll Loss: 2.3739\tTriple Loss(1): 0.2234\tClassification Loss: 1.9271\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.002/8_epochs\r\n",
      "Train Epoch: 9 [0/209222 (0%)]\tAll Loss: 2.7106\tTriple Loss(1): 0.3028\tClassification Loss: 2.1050\r\n",
      "\r\n",
      "Test set: Average loss: 1.8669\r\n",
      "Top 1 Accuracy: 36557/80000 (46%)\r\n",
      "Top 3 Accuracy: 55758/80000 (70%)\r\n",
      "Top 5 Accuracy: 64577/80000 (81%)\r\n",
      " \r\n",
      "Train Epoch: 9 [32000/209222 (15%)]\tAll Loss: 2.1567\tTriple Loss(1): 0.0728\tClassification Loss: 2.0111\r\n",
      "Train Epoch: 9 [64000/209222 (31%)]\tAll Loss: 2.3294\tTriple Loss(1): 0.1497\tClassification Loss: 2.0299\r\n",
      "Train Epoch: 9 [96000/209222 (46%)]\tAll Loss: 2.4505\tTriple Loss(0): 0.0000\tClassification Loss: 2.4505\r\n",
      "Train Epoch: 9 [128000/209222 (61%)]\tAll Loss: 2.1909\tTriple Loss(1): 0.0784\tClassification Loss: 2.0341\r\n",
      "Train Epoch: 9 [160000/209222 (76%)]\tAll Loss: 2.4484\tTriple Loss(1): 0.1624\tClassification Loss: 2.1236\r\n",
      "Train Epoch: 9 [192000/209222 (92%)]\tAll Loss: 1.9262\tTriple Loss(0): 0.0000\tClassification Loss: 1.9262\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.002/9_epochs\r\n",
      "Train Epoch: 10 [0/209222 (0%)]\tAll Loss: 2.3872\tTriple Loss(1): 0.2258\tClassification Loss: 1.9357\r\n",
      "\r\n",
      "Test set: Average loss: 1.7371\r\n",
      "Top 1 Accuracy: 40157/80000 (50%)\r\n",
      "Top 3 Accuracy: 58581/80000 (73%)\r\n",
      "Top 5 Accuracy: 66650/80000 (83%)\r\n",
      " \r\n",
      "Train Epoch: 10 [32000/209222 (15%)]\tAll Loss: 2.3762\tTriple Loss(1): 0.1683\tClassification Loss: 2.0397\r\n",
      "Train Epoch: 10 [64000/209222 (31%)]\tAll Loss: 2.5377\tTriple Loss(1): 0.2136\tClassification Loss: 2.1106\r\n",
      "Train Epoch: 10 [96000/209222 (46%)]\tAll Loss: 2.2234\tTriple Loss(0): 0.0000\tClassification Loss: 2.2234\r\n"
     ]
    }
   ],
   "source": [
    "# FREEZE = False. LR=0.002. in-shop=True.\n",
    "! python train.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "Loading model freeze=False/lr=0.002/9_epochs\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\r\n",
      "  warnings.warn(msg, category=FutureWarning)\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Loading model freeze=False/lr=0.002/9_epochs\r\n",
      "Train Epoch: 10 [0/209222 (0%)]\tAll Loss: 2.8286\tTriple Loss(1): 0.2787\tClassification Loss: 2.2713\r\n",
      "train.py:211: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 1.7347\r\n",
      "Top 1 Accuracy: 40172/80000 (50%)\r\n",
      "Top 3 Accuracy: 58634/80000 (73%)\r\n",
      "Top 5 Accuracy: 66638/80000 (83%)\r\n",
      " \r\n",
      "Train Epoch: 10 [32000/209222 (15%)]\tAll Loss: 2.2351\tTriple Loss(1): 0.1249\tClassification Loss: 1.9853\r\n",
      "Train Epoch: 10 [64000/209222 (31%)]\tAll Loss: 2.7991\tTriple Loss(1): 0.2963\tClassification Loss: 2.2064\r\n",
      "Train Epoch: 10 [96000/209222 (46%)]\tAll Loss: 1.9463\tTriple Loss(1): 0.0882\tClassification Loss: 1.7699\r\n",
      "Train Epoch: 10 [128000/209222 (61%)]\tAll Loss: 1.8923\tTriple Loss(1): 0.1096\tClassification Loss: 1.6731\r\n",
      "Train Epoch: 10 [160000/209222 (76%)]\tAll Loss: 1.6912\tTriple Loss(1): 0.0840\tClassification Loss: 1.5232\r\n",
      "Train Epoch: 10 [192000/209222 (92%)]\tAll Loss: 1.9212\tTriple Loss(1): 0.1253\tClassification Loss: 1.6706\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.002/10_epochs\r\n",
      "Train Epoch: 11 [0/209222 (0%)]\tAll Loss: 2.9691\tTriple Loss(1): 0.4475\tClassification Loss: 2.0741\r\n",
      "\r\n",
      "Test set: Average loss: 1.6604\r\n",
      "Top 1 Accuracy: 41942/80000 (52%)\r\n",
      "Top 3 Accuracy: 60147/80000 (75%)\r\n",
      "Top 5 Accuracy: 67700/80000 (85%)\r\n",
      " \r\n",
      "Train Epoch: 11 [32000/209222 (15%)]\tAll Loss: 2.1874\tTriple Loss(1): 0.1945\tClassification Loss: 1.7985\r\n",
      "Train Epoch: 11 [64000/209222 (31%)]\tAll Loss: 2.3540\tTriple Loss(1): 0.2192\tClassification Loss: 1.9156\r\n",
      "Train Epoch: 11 [96000/209222 (46%)]\tAll Loss: 2.7238\tTriple Loss(1): 0.2337\tClassification Loss: 2.2563\r\n",
      "Train Epoch: 11 [128000/209222 (61%)]\tAll Loss: 2.1069\tTriple Loss(1): 0.1014\tClassification Loss: 1.9041\r\n",
      "Train Epoch: 11 [160000/209222 (76%)]\tAll Loss: 2.0217\tTriple Loss(1): 0.2179\tClassification Loss: 1.5858\r\n"
     ]
    }
   ],
   "source": [
    "# Continuing \"models/freeze=False/lr=0.002/9_epochs\"\n",
    "# FREEZE = False. LR=0.002. in-shop=True.\n",
    "! python train.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\r\n",
      "  warnings.warn(msg, category=FutureWarning)\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "Train Epoch: 1 [0/209222 (0%)]\tAll Loss: 5.0911\tTriple Loss(1): 0.5687\tClassification Loss: 3.9536\r\n",
      "train.py:214: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 3.9153\r\n",
      "Top 1 Accuracy: 2540/80000 (3%)\r\n",
      "Top 3 Accuracy: 6662/80000 (8%)\r\n",
      "Top 5 Accuracy: 9908/80000 (12%)\r\n",
      " \r\n",
      "Train Epoch: 1 [32000/209222 (15%)]\tAll Loss: 5.5844\tTriple Loss(0): 1.5435\tClassification Loss: 2.4974\r\n",
      "Train Epoch: 1 [64000/209222 (31%)]\tAll Loss: 4.2455\tTriple Loss(1): 0.7128\tClassification Loss: 2.8200\r\n",
      "Train Epoch: 1 [96000/209222 (46%)]\tAll Loss: 4.2068\tTriple Loss(1): 0.7079\tClassification Loss: 2.7910\r\n",
      "Train Epoch: 1 [128000/209222 (61%)]\tAll Loss: 3.0472\tTriple Loss(0): 0.1936\tClassification Loss: 2.6599\r\n",
      "Train Epoch: 1 [160000/209222 (76%)]\tAll Loss: 4.7454\tTriple Loss(0): 1.0386\tClassification Loss: 2.6683\r\n",
      "Train Epoch: 1 [192000/209222 (92%)]\tAll Loss: 2.6876\tTriple Loss(0): 0.0000\tClassification Loss: 2.6876\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.002/1_epochs\r\n",
      "Train Epoch: 2 [0/209222 (0%)]\tAll Loss: 4.4222\tTriple Loss(1): 0.6780\tClassification Loss: 3.0662\r\n",
      "\r\n",
      "Test set: Average loss: 2.7467\r\n",
      "Top 1 Accuracy: 20020/80000 (25%)\r\n",
      "Top 3 Accuracy: 36891/80000 (46%)\r\n",
      "Top 5 Accuracy: 43684/80000 (55%)\r\n",
      " \r\n",
      "Train Epoch: 2 [32000/209222 (15%)]\tAll Loss: 3.9914\tTriple Loss(1): 0.7584\tClassification Loss: 2.4746\r\n"
     ]
    }
   ],
   "source": [
    "# With Eastern dataset added.\n",
    "# FREEZE = False. LR=0.002. in-shop=True.\n",
    "! python train.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:210: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\r\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\r\n",
      "  warnings.warn(msg, category=FutureWarning)\r\n",
      "/home/ma02526/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/site-packages/torchvision/transforms/transforms.py:697: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\r\n",
      "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\r\n",
      "img/Eastern/1_7_50.jpg\r\n",
      "img/Eastern/2-1.jpg\r\n",
      "img/Eastern/7f817f30145d9ee906bf63b79531b610.jpg\r\n",
      "img/Eastern/7k.jpg\r\n",
      "img/Eastern/09f771893f0915cea3decef1f80222f0.jpg\r\n",
      "img/Eastern/11.jpg\r\n",
      "img/Eastern/15-1.jpg\r\n",
      "img/Eastern/181.jpg\r\n",
      "img/Eastern/245-600x846.jpg\r\n",
      "img/Eastern/9247e228c7f025f646a59e004c8d47b8.jpg\r\n",
      "img/Eastern/30821-r2_3_.jpg\r\n",
      "img/Eastern/31027_1_.jpg\r\n",
      "img/Eastern/32369_1_.jpg\r\n",
      "img/Eastern/35475_2_.jpg\r\n",
      "img/Eastern/36596_1_.jpg\r\n",
      "img/Eastern/820277877bb20fd3e719311e1e1d6efe.jpg\r\n",
      "img/Eastern/1543386762-1339407736.jpeg\r\n",
      "img/Eastern/1554186937-1535281827.jpeg\r\n",
      "img/Eastern/1554186944-1914768777.jpg\r\n",
      "img/Eastern/al-ks-2488_1_.jpg\r\n",
      "img/Eastern/black-kameez-shalwar-for-men-unstitched-1000x1000.jpg\r\n",
      "img/Eastern/black-kurta-style.jpg\r\n",
      "img/Eastern/Dobby-Kurta-with-Contrast-Manupalations-1031x1547.jpg\r\n",
      "img/Eastern/e261722a149688a1402e8445e6b3775b.jpg\r\n",
      "img/Eastern/Eden-Robe-02.png\r\n",
      "img/Eastern/f7e194e8804080ca11d0b652940071c6.jpg\r\n",
      "img/Eastern/gmsu394-sand-_1_.jpg\r\n",
      "img/Eastern/gsaxut.jpg\r\n",
      "img/Eastern/gts-4152_2__1.jpg\r\n",
      "img/Eastern/hqdefault.jpg\r\n",
      "img/Eastern/HTB1RjdAclcXBuNjt_biq6xpmpXa0.jpg_350x350.jpg\r\n",
      "img/Eastern/hyperzone_embroidery_shalwar_kameez_for_men_royal_blue_0035_.jpg\r\n",
      "img/Eastern/I-31-750x900.jpg\r\n",
      "img/Eastern/IMG_6491-40829-700x904.jpg\r\n",
      "img/Eastern/J.-Men-Kurta-Yellow.jpg\r\n",
      "img/Eastern/Junaid.J-New-Kurta-designs-for-Mens-17.jpg\r\n",
      "img/Eastern/Junaid-Jamshed-Black-CVC-Kameez-Shalwar-for-Men-JJKS-W-30102-1.jpg\r\n",
      "img/Eastern/junaid-jamshed-camel-brown-p-v-mens-kameez-shalwar-image1.jpg\r\n",
      "img/Eastern/Junaid-Jamshed-Light-Blue-Polyester-Viscose-Kameez-Shalwar-for-Men-JJKS-A-30119-650x813.jpg\r\n",
      "img/Eastern/junaid-jamshed-summer-collection-2019-dull-purple-cotton-mens-kameez-shalwar-102868121-image1.jpeg\r\n",
      "img/Eastern/junaid-jamshed-summer-collection-2019-grey-regular-kameez-shalwar-for-men-103960064-image1.jpeg\r\n",
      "img/Eastern/junaid-jamshed-summer-collection-2019-light-grey-cotton-mens-kameez-shalwar-102876121-image1.jpeg\r\n",
      "img/Eastern/junaid-jamshed-summer-collection-2019-prussian-blue-cotton-mens-kameez-shalwar-102838139-image1.jpeg\r\n",
      "img/Eastern/Kurta-45.jpg\r\n",
      "img/Eastern/Kurta-Design-1.jpg\r\n",
      "img/Eastern/Latest-Bonanza-Men-Kurtas-Shalwar-Kameez-Eid-Collection-2016-2017-5.jpg\r\n",
      "img/Eastern/Latest-Eid-Men-Kurta-Shalwar-Kameez-Designs-Collection-2017-2018-5-683x1024.jpeg\r\n",
      "img/Eastern/Latha-3.jpg\r\n",
      "img/Eastern/Men-Kurta-Shalwar-Design-By.jpg\r\n",
      "img/Eastern/Men-shalwar-kameez-light-grey-color-in-blended.jpg\r\n",
      "img/Eastern/Men-Shalwar-Kameez-Stylish-1-682x1024.jpg\r\n",
      "img/Eastern/mks-001-m_1_.jpg\r\n",
      "img/Eastern/mks-12-_5_.jpg\r\n",
      "img/Eastern/mks-17-_1_.jpg\r\n",
      "img/Eastern/mks-32-_1_.jpg\r\n",
      "img/Eastern/mks-39-_1__1.jpg\r\n",
      "img/Eastern/mks-44-_1_.jpg\r\n",
      "img/Eastern/mks-52-_1_.jpg\r\n",
      "img/Eastern/mosaic-men-shalwar-kameez-collection-md-101-blue-_1__1.jpg\r\n",
      "img/Eastern/mqs-001_1_.jpg\r\n",
      "img/Eastern/mqs-006-b-_1_.jpg\r\n",
      "img/Eastern/mqs-07-_1_.jpg\r\n",
      "img/Eastern/mqs-010-_1_.jpg\r\n",
      "img/Eastern/mqs-23-_1_.jpg\r\n",
      "img/Eastern/mqs-27-_5_.jpg\r\n",
      "img/Eastern/mqs-31-_1_.jpg\r\n",
      "img/Eastern/mqs-42-_1_.jpg\r\n",
      "img/Eastern/mqs-44-_1_.jpg\r\n",
      "img/Eastern/New-Mens-Kurta-Designs-for-.jpg\r\n",
      "img/Eastern/New-Mens-wear-shalwar-kameez-15.jpg\r\n",
      "img/Eastern/Purple-Cotton-Mens-Kameez-Shalwar-6200.jpg\r\n",
      "img/Eastern/S-1819_3.jpg\r\n",
      "img/Eastern/shalwar-_-kameez-sk4hc.jpg\r\n",
      "img/Eastern/sk-197_1-768x1024.jpg\r\n",
      "img/Eastern/SK18713-BR_1_1024x1024.jpg\r\n",
      "img/Eastern/SK19023-LGN_1_2e7e44c0-d4ab-4dda-b167-afb15483152b_1024x1024.jpg\r\n",
      "img/Eastern/SK19101-WT.jpg\r\n",
      "img/Eastern/sks-147_1_.jpg\r\n",
      "img/Eastern/SQ3.jpg\r\n",
      "img/Eastern/st-991-_4__1.jpg\r\n",
      "img/Eastern/st-1041-_1_.jpg\r\n",
      "img/Eastern/st-1089-_1_.jpg\r\n",
      "img/Eastern/unnamed(1).jpg\r\n",
      "img/Eastern/unnamed(2).jpg\r\n",
      "img/Eastern/unnamed(3).jpg\r\n",
      "img/Eastern/unnamed(4).jpg\r\n",
      "img/Eastern/unnamed(5).jpg\r\n",
      "img/Eastern/unnamed.jpg\r\n",
      "img/Eastern/web1_6_19.jpg\r\n",
      "img/Eastern/Wedding-Mens-Shalwar-Kameez-Designs-4.jpg\r\n",
      "img/Eastern/White-Kameez-Shalwar-Men.jpg\r\n",
      "img/Eastern/winter-men-s-kameez-shalwar-suits-sks18w-03-_4_.jpg\r\n",
      "img/Eastern/winter-men-s-kameez-shalwar-suits-sks18w-09-_1_.jpg\r\n",
      "img/Eastern/winter-men-s-kameez-shalwar-suits-sks18w-11-_1_.jpg\r\n",
      "img/Eastern/zellbury_eastern_wear_to_for_man_shalwar_kameez_-_mint_green_-_zmsk19461-e-1.jpg\r\n",
      "img/Eastern/zellbury_eastern_wear_to_for_man_shalwar_kameez_-_off_white_-_zmsk19462-e-1.jpg\r\n",
      "img/Eastern/zellbury_ready_to_wear_for_men_shalwar_kameez_2019_-_black_-_zmsk19045-e-1.jpg\r\n",
      "img/Eastern/zellbury-eastern-wear-2019-men-shalwar-kameez-lucky-point-blue-cotton-zmsk19438-s-1.jpg\r\n",
      "img/Eastern/zellbury-eastern-wear-man-shalwar_kameez-zmsk19447-e-1.jpg\r\n",
      "img/Eastern/Men-Kameez-Shalwar-Designs-723x469.jpg\r\n",
      "scrapped/jdot/0a0696c7b8f9c84c97e916cafac11a491b2f1230.jpg\r\n",
      "scrapped/jdot/0ad8953502aa99550cb26556560eb64fface5db7.jpg\r\n",
      "scrapped/jdot/0bbbcba93098a2a8cea59e3cc531685efc30e2ed.jpg\r\n",
      "scrapped/jdot/0d615c7c56e76fdf84e9b48191240755f4cc3804.jpg\r\n",
      "scrapped/jdot/0dbc2f21435c0e1cfc8b3f883d6c47df464e4e5b.jpg\r\n",
      "scrapped/jdot/0df6793aa25b13e2e51b70712dc6f74c5315159f.jpg\r\n",
      "scrapped/jdot/0ec9cddb6910c4bba113679432cf48c598b77969.jpg\r\n",
      "scrapped/jdot/1b84c450431041a7d85b827c3c2fb5467cb504a6.jpg\r\n",
      "scrapped/jdot/1d1e47e53b360bedb46a49382222ca1b693dc24e.jpg\r\n",
      "scrapped/jdot/1d91c48fa8f899a570db6904b7adc5b463eb85b5.jpg\r\n",
      "scrapped/jdot/2aa032fee6c7c26c2a9ee33e485a1ed073e770e5.jpg\r\n",
      "scrapped/jdot/2bf319dac8f05b775f651cc602b733134610bb37.jpg\r\n",
      "scrapped/jdot/2f1a88faa0112ca51d8f320b935f6bfc9c05829d.jpg\r\n",
      "scrapped/jdot/4e359672c99f2c6da4f1c699e6eaa2f4a7066597.jpg\r\n",
      "scrapped/jdot/5b37b203adf3a84b5958903f522884fa88d5108b.jpg\r\n",
      "scrapped/jdot/5be74da0bb2d289551281d7c09155d5fee539861.jpg\r\n",
      "scrapped/jdot/5d9a868a9baae4d4f27a695cf86063fc40723850.jpg\r\n",
      "scrapped/jdot/5df704753cc1fc6491d928eca11b90e008d57b04.jpg\r\n",
      "scrapped/jdot/5edd3e7faf56ad312cbd88fd65a1d1afd716fcaa.jpg\r\n",
      "scrapped/jdot/5f17121cb04a29e25151a11dc11e48b2c9959490.jpg\r\n",
      "scrapped/jdot/6d2c11645af7ae63c142835ab873cbdb3a3862f0.jpg\r\n",
      "scrapped/jdot/7a1da94a60aef69d1ed03ae9c8a81218d32302f5.jpg\r\n",
      "scrapped/jdot/7a33bc8f7f3556a1bb6171076b2218bf78ed40c2.jpg\r\n",
      "scrapped/jdot/7b40d18f09957b653482fc7fc1bb7dbb141d8b34.jpg\r\n",
      "scrapped/jdot/7ece9db9dca2b201438480bede74ba6c324292ce.jpg\r\n",
      "scrapped/jdot/7fa8684f2970a1aa0b57b4cffd93bc5cb42fbc36.jpg\r\n",
      "scrapped/jdot/8c3c1d6e07379f990da69b1063b670537e665fb6.jpg\r\n",
      "scrapped/jdot/8d6ef326210b65b5155056afd74934959ed6b120.jpg\r\n",
      "scrapped/jdot/8dfe1fea818660ff809f7c2acd8abfcae2a84e70.jpg\r\n",
      "scrapped/jdot/8f07dae2d1e44f6d58bbed1b1423de429b0fcf60.jpg\r\n",
      "scrapped/jdot/8f25fb1d84a035ef7851b4fc6dbeea957d13b3dd.jpg\r\n",
      "scrapped/jdot/9af8e094e8a01be72b683e11d71eb95cd643a500.jpg\r\n",
      "scrapped/jdot/9c9e09c8b2c290a6febb17966a0bef318858ca58.jpg\r\n",
      "scrapped/jdot/9d3dbef0cc0269b21ba7c7b2e9721c3280369537.jpg\r\n",
      "scrapped/jdot/9d7209a5aa1747f3c82a939ec039244bc608c67d.jpg\r\n",
      "scrapped/jdot/013fb1d678abfcc571e0d4d701e82cec37b0ac33.jpg\r\n",
      "scrapped/jdot/15eab078067b59d82b0127e7519f615068c4d016.jpg\r\n",
      "scrapped/jdot/17f17ef0df4a07af72662372cf591ef0a577bd18.jpg\r\n",
      "scrapped/jdot/24a84da1d89f9006cec35f6256bb4ae167f638ee.jpg\r\n",
      "scrapped/jdot/35be4150267ede558c33ba8f28345c957fc7b370.jpg\r\n",
      "scrapped/jdot/37cb9fd6989dd260f4031139a864a22c11b9874c.jpg\r\n",
      "scrapped/jdot/37e0f337d75f6cc6d41d88e4ac82df1eca3cc1cb.jpg\r\n",
      "scrapped/jdot/40bed6681d23182795ba828e0e78e4f5894839e9.jpg\r\n",
      "scrapped/jdot/41f868814966f695a64517d3ffe1dd5cf23ebf3a.jpg\r\n",
      "scrapped/jdot/43c86ac859d48705d79a29f0ca6a2275e607c4f2.jpg\r\n",
      "scrapped/jdot/46f6ec2db186a953921e69fed1c0b3e945a81f73.jpg\r\n",
      "scrapped/jdot/49a6fe14f1c0bf2d7379910ed8787d75a79f2ece.jpg\r\n",
      "scrapped/jdot/54c276b5c34e308ca0a6b3c6128c7b3697bf917d.jpg\r\n",
      "scrapped/jdot/57dc1ffdb7f8cbefacab7ac412c6c1483f6131cd.jpg\r\n",
      "scrapped/jdot/65fd1769f52eb49d8218aa5174574df661db75e4.jpg\r\n",
      "scrapped/jdot/68b996a0213d49ceac9996b8236b11d7d39e08f8.jpg\r\n",
      "scrapped/jdot/72aa6a3629761aecf7126ab122fa509eb1deb122.jpg\r\n",
      "scrapped/jdot/76fc043650b02b70cec80be86b68db6c8975c23c.jpg\r\n",
      "scrapped/jdot/77c00f9faabc9effd9c87ae54a8ab02899b6e506.jpg\r\n",
      "scrapped/jdot/79bdb2ac6ff9fc0fc47767f14bbf02bc26a37b66.jpg\r\n",
      "scrapped/jdot/81a455fddca4c297a97f50aba721a850fbcb7fdc.jpg\r\n",
      "scrapped/jdot/086f8f6171fece30558548784cc3162db069319e.jpg\r\n",
      "scrapped/jdot/90ac48ff002ede4d5ba4f71dfcf27f48e3f5f913.jpg\r\n",
      "scrapped/jdot/95b96ce99d9b8dc441a6e33efe5d269d9ba18ff8.jpg\r\n",
      "scrapped/jdot/106bd2ffbf7d044fb32c38efcdea3690f4a9b91e.jpg\r\n",
      "scrapped/jdot/239f6d511f569341f9dd766e4b215979eba53558.jpg\r\n",
      "scrapped/jdot/422a7480fba11617b147a1735146ff08b22f6d4a.jpg\r\n",
      "scrapped/jdot/435c8c07759c73a2b86a3182d85a4d5c93a5388a.jpg\r\n",
      "scrapped/jdot/534af489687f16c6343b00fa9add6d9bc9ae8cad.jpg\r\n",
      "scrapped/jdot/544c3fb1d6217df87066cd6c91dee423e2a1e2ed.jpg\r\n",
      "scrapped/jdot/652d4136c97d4de47d839c22047b54c63ee26312.jpg\r\n",
      "scrapped/jdot/1469a6ed3d5c0c659d26ba927d58baab7102fe51.jpg\r\n",
      "scrapped/jdot/1746afe4118d5394e5277d6f6ca7720481998c27.jpg\r\n",
      "scrapped/jdot/3750fdf3371be975a8585ec17922a595000ee62b.jpg\r\n",
      "scrapped/jdot/5721c5f3d24a832558e92ebd10afe6c3374ebb41.jpg\r\n",
      "scrapped/jdot/6302fdf9345d5e45f3decdd59a76c6d83c02d8bb.jpg\r\n",
      "scrapped/jdot/7046cf6c5eca98b9a7c263fbfa4e21414ad3e185.jpg\r\n",
      "scrapped/jdot/7745fd3d33acf94e1757123e114be6ed69b8725e.jpg\r\n",
      "scrapped/jdot/9013b4d44e5e80d6ad84f265449d2eab749eba73.jpg\r\n",
      "scrapped/jdot/9165a05befc1fae7a04965aeff285c7f5c2dd3d9.jpg\r\n",
      "scrapped/jdot/9265f20c114058ee81cdc51d83eb2583234ce489.jpg\r\n",
      "scrapped/jdot/17603a9095104cc7604ee258da0df31df395591f.jpg\r\n",
      "scrapped/jdot/30632f23d41caf94420d241bc8adf7d1ce0d9632.jpg\r\n",
      "scrapped/jdot/056386d89726f07398b73741eb8f0475b596af0e.jpg\r\n",
      "scrapped/jdot/64191e786da228adf06bc607ac99aaefa11e6402.jpg\r\n",
      "scrapped/jdot/78742a7423aaffa15f8f843b7dd981b92c373034.jpg\r\n",
      "scrapped/jdot/79167f934e159c376287442b8b15ad6307d69485.jpg\r\n",
      "scrapped/jdot/149347cba0f14b805f5a50fd77b55ffda3374691.jpg\r\n",
      "scrapped/jdot/547994e22feca9edf0faa083176f3d2beecfb158.jpg\r\n",
      "scrapped/jdot/554259c95b3ace15dd75b09afbc1f8bbddfd6828.jpg\r\n",
      "scrapped/jdot/572798c2bd3897a23c83c272dda091f9344bd50a.jpg\r\n",
      "scrapped/jdot/651020ba8c02c38503ec2bbd0adb85b48fa9b107.jpg\r\n",
      "scrapped/jdot/0703735d1c78c2db82dcb1c1b607225ae7a410d7.jpg\r\n",
      "scrapped/jdot/9843830bfa3385e65b388644a2ac8110f2cd524d.jpg\r\n",
      "scrapped/jdot/60793386dad1564bef298e26c140a53a7a2445f1.jpg\r\n",
      "scrapped/jdot/113572739dc25598b7206f227d1d4a5ffb220de3.jpg\r\n",
      "scrapped/jdot/858780355c4fd47fe0f538bb8d69379ebc81bb38.jpg\r\n",
      "scrapped/jdot/8997603072b0d08167b4196c3e31ff9e102451f7.jpg\r\n",
      "scrapped/jdot/a0bf4ca7e6f536e322030182afc2e9a1d2f400aa.jpg\r\n",
      "scrapped/jdot/a5c1a6c9461cddccaaad48ea11514a508921d521.jpg\r\n",
      "scrapped/jdot/a6d5cdd96efdd52a1a1e429c0223633c130763d1.jpg\r\n",
      "scrapped/jdot/a8fa498f99530621a81d1dbb4d1088bd819fde65.jpg\r\n",
      "scrapped/jdot/a35de30614ba01f63568334e64190ee0849ab437.jpg\r\n",
      "scrapped/jdot/a44c3216708be757830da568bd32ae1392bdf416.jpg\r\n",
      "scrapped/jdot/a73de0a9457a6c8c2ca3aa7f25f6470e7c521dce.jpg\r\n",
      "scrapped/jdot/a1268748c5449a1b4d60c59be5077e5b2feae03c.jpg\r\n",
      "scrapped/jdot/b7d671d1c7a3da0b6626dabfc4779c810231da53.jpg\r\n",
      "scrapped/jdot/b73845d819ecef9b226bdd63174075653bc628bb.jpg\r\n",
      "scrapped/jdot/b079081f150cdb24093376c4210ebdcee7cafe38.jpg\r\n",
      "scrapped/jdot/bb1766f7a51dabddc139e27131009cc9244089ef.jpg\r\n",
      "scrapped/jdot/bf1904dd49bd3c706a15a6ccc7f668add7523c4c.jpg\r\n",
      "scrapped/jdot/c6e3ed830e6589b0cf346323962f001ac639dde8.jpg\r\n",
      "scrapped/jdot/c09d8dcce9c820e3077a4732653fd7a5932e8dc9.jpg\r\n",
      "scrapped/jdot/c24c8ec0d24ca8a32d60ccf1792d4a14294bc8a2.jpg\r\n",
      "scrapped/jdot/c119ab119ae571ac248dd9acfb7621ac81d4c008.jpg\r\n",
      "scrapped/jdot/c699f5cc445b8b1578868623ae7bf8f3c16e7679.jpg\r\n",
      "scrapped/jdot/cb22fe26296644673017abf0c554564a0d535f62.jpg\r\n",
      "scrapped/jdot/cd3a4a2b12e07aecdc1ae0b55b74f871733f96c0.jpg\r\n",
      "scrapped/jdot/cec68c5a5f2f210f232e5cee53f8bb9f24a884e6.jpg\r\n",
      "scrapped/jdot/cf2148e5b9aa851d841cae1c46e86bc7ae534c94.jpg\r\n",
      "scrapped/jdot/d9a136944fa16284a6b209e3c5ab4a20f8ba508c.jpg\r\n",
      "scrapped/jdot/d36e1d6d5d73bfa17bb360e5df5d3e5f220e1edb.jpg\r\n",
      "scrapped/jdot/d93fcd64a695258057d237d521cbac575b1e35c3.jpg\r\n",
      "scrapped/jdot/d571d5000374305a7402065c63f6502a674700a4.jpg\r\n",
      "scrapped/jdot/d079320ab7e04a898816e08e7d61a1f251a01d81.jpg\r\n",
      "scrapped/jdot/d64662049f0046028823ecb7bd672fda198cb8dc.jpg\r\n",
      "scrapped/jdot/d997798471dca8473b1332302ceca44674d693d9.jpg\r\n",
      "scrapped/jdot/da698140f30d780d012edf493bc7ec418930818e.jpg\r\n",
      "scrapped/jdot/db2b98415e14a8e3aefd3844226fd4ea8937ddd8.jpg\r\n",
      "scrapped/jdot/db3481c9fd93e4431d509a685568476f094cbfec.jpg\r\n",
      "scrapped/jdot/dbfbb4f7ccbc601f73bd29483b0dc1938ccc466a.jpg\r\n",
      "scrapped/jdot/dffcc86cfd61b394f34886908b8fdf4c55b657d9.jpg\r\n",
      "scrapped/jdot/e0e3f0f71c94c87c0d6c15b07af9f18119b8363b.jpg\r\n",
      "scrapped/jdot/e3e5ad4da7933223ad01988ca5f4340d4cf5522b.jpg\r\n",
      "scrapped/jdot/e7de361d6749da57e27871eb4134a613100b8a50.jpg\r\n",
      "scrapped/jdot/e55f37c44fc333d49a3b2b3e9e6168989579839b.jpg\r\n",
      "scrapped/jdot/e83e6171d932a59ea399e2b2d53e96e53f460cd5.jpg\r\n",
      "scrapped/jdot/e167f036a59d9f56a8084b66a1db6c925220a159.jpg\r\n",
      "scrapped/jdot/e654f224abce4a8c4792b5889be7853204082573.jpg\r\n",
      "scrapped/jdot/e0921d9f55079adb26ec8c844945ccb1718d8eb9.jpg\r\n",
      "scrapped/jdot/ea3bd5eb7f89436ad09c22f9ed54c61112556989.jpg\r\n",
      "scrapped/jdot/eb6b1c4756c18aea338edd89e009df381f489556.jpg\r\n",
      "scrapped/jdot/ebac146a51dc55ba3ab6db3ab3b2f346380ccafc.jpg\r\n",
      "scrapped/jdot/ebc30e894f38a139b4717a1edfb67d348fbc9e4b.jpg\r\n",
      "scrapped/jdot/ec092da3e715a1fde55b0409be251eb4c4fa2423.jpg\r\n",
      "scrapped/jdot/eed6669dfceb9c23d5e1947ada478af4845869ba.jpg\r\n",
      "scrapped/jdot/efaf74df19bae753d5e43aedda819fa00a9b8e98.jpg\r\n",
      "scrapped/jdot/f8a3b7925595768c749efdf0c43a79000ad8dd71.jpg\r\n",
      "scrapped/jdot/f8c26f5e0571e231f714ed6e9ce5025f9c495d9d.jpg\r\n",
      "scrapped/jdot/f53fcb1054903fe2ec7c9d09bc79ab1655c487aa.jpg\r\n",
      "scrapped/jdot/fa93d7d9cd5f02d3eeb061adf2cbb358a373a908.jpg\r\n",
      "scrapped/jdot/fe8f66bcd2725fa330a24c2d5b4cac05ab0369fb.jpg\r\n",
      "scrapped/zellbury/0b0c765bbbb4c42cb4dd5e0ee12e060819e42542.jpg\r\n",
      "scrapped/zellbury/0bb26012078901fc05fee8868c5af7f6c729da68.jpg\r\n",
      "scrapped/zellbury/0d8a0c2f1b1a0856221c8cf775f75af16891365c.jpg\r\n",
      "scrapped/zellbury/1d3c08130167f30ff24e5b4eecac3f14312bd31b.jpg\r\n",
      "scrapped/zellbury/1e48e5732d89e2106e21e14fa4cb5e4b27da20fa.jpg\r\n",
      "scrapped/zellbury/1ecf96a3a6c5239dd82e6d3e0003af03c3813fd4.jpg\r\n",
      "scrapped/zellbury/3ab667c0275b82c2d6294933e7d9a07fa30f739c.jpg\r\n",
      "scrapped/zellbury/5b29658a88a42f7fde1a0aff2d0725588e6dac7e.jpg\r\n",
      "scrapped/zellbury/6d25b6da13e9f6d48d63c6b476d04c4cff22af2a.jpg\r\n",
      "scrapped/zellbury/6ec5f7999052d2177c071c18845b60c645126e56.jpg\r\n",
      "scrapped/zellbury/6fe4ca99a03af663259863351a18ff560c9bcc9a.jpg\r\n",
      "scrapped/zellbury/7b220ab4cb5090c6ec642b7288e4b7db3e0a880a.jpg\r\n",
      "scrapped/zellbury/08afcebdeb86e1904034a3a0b2a68114dec48676.jpg\r\n",
      "scrapped/zellbury/08c2d4865a715e712742f24ee7a2909463b2e5d2.jpg\r\n",
      "scrapped/zellbury/16a711dde3649ed807671b41d96c53cd5e3ba027.jpg\r\n",
      "scrapped/zellbury/030fc5176c57007f4fe18a323634632925d4f484.jpg\r\n",
      "scrapped/zellbury/46fd190f00a60897910cf597d1a60a75571d5105.jpg\r\n",
      "scrapped/zellbury/61c90bff61c128981a2685a41cd22871f47bdb41.jpg\r\n",
      "scrapped/zellbury/72f09f22295c47f47947b564358f9ef26090162c.jpg\r\n",
      "scrapped/zellbury/87ade9ee0c9c71489c0ece5bd822647eac4e0fc4.jpg\r\n",
      "scrapped/zellbury/92b58eb1ef278e640f898b7cd9bf219d8c2b2428.jpg\r\n",
      "scrapped/zellbury/92ecff0e91269f1c3bab2465dddbfe6c3d7d7bac.jpg\r\n",
      "scrapped/zellbury/147ceba434e8403da93e96371f8e1882fde53efb.jpg\r\n",
      "scrapped/zellbury/238b80a69dc8ab8030918947a318f66fed9c3401.jpg\r\n",
      "scrapped/zellbury/318b58665d4187849f19d26896c25fcd9fa8e0da.jpg\r\n",
      "scrapped/zellbury/352cdd6d3a5191bed0ba17de2f055ad28fde6b1e.jpg\r\n",
      "scrapped/zellbury/407c344d7940cde617fe60927520586110f25198.jpg\r\n",
      "scrapped/zellbury/495a519c0dcb188148159d322cbdd482225b1bb1.jpg\r\n",
      "scrapped/zellbury/498ef7406798011a06eafb8e25b7fcc8a7aafaf3.jpg\r\n",
      "scrapped/zellbury/600da463143faf6bf4c7915bd9144db499532370.jpg\r\n",
      "scrapped/zellbury/688c973a89e95ac2ffb25abf441fd2cf7870487d.jpg\r\n",
      "scrapped/zellbury/876d96cfba2e60805fc50e77e4db2b2935b292e0.jpg\r\n",
      "scrapped/zellbury/5085b8c3eda97df61cf3f3c09cf86746abe8dd86.jpg\r\n",
      "scrapped/zellbury/6786b472fe65891ee52ab592dbc0a1f22c402082.jpg\r\n",
      "scrapped/zellbury/7258fac2725c4db2ea572d72c06c52a8534275ef.jpg\r\n",
      "scrapped/zellbury/7474026571b02264e3fda1b15fe583a21d625617.jpg\r\n",
      "scrapped/zellbury/acfca6667ebd6a2bab66d02d523859840ace2be0.jpg\r\n",
      "scrapped/zellbury/ad0cf46780d127dcb46a538eacb764103ca5313a.jpg\r\n",
      "scrapped/zellbury/b2b03852720d9f24ea37d553b81384867074eec3.jpg\r\n",
      "scrapped/zellbury/c46f5a22515baec876171a235beda55bb2a6848f.jpg\r\n",
      "scrapped/zellbury/c0715ce14c1a179af12822d38313403395a2542e.jpg\r\n",
      "scrapped/zellbury/ca81ae94b665e232e2c9782e53ef1bf989193eb4.jpg\r\n",
      "scrapped/zellbury/ce681fa135be6f26523831f5db95d9cd73dcffda.jpg\r\n",
      "scrapped/zellbury/ce53381b36c61ef1d4de26531c6a5b950f9fa858.jpg\r\n",
      "scrapped/zellbury/ceb20bf5ec74da77e835c12f7edc0cbf461f79e9.jpg\r\n",
      "scrapped/zellbury/d36aee2dee691856c72b24d5cb72151a95646598.jpg\r\n",
      "scrapped/zellbury/ded1ceb99d663aa5cf2ba2128f284c501ade4645.jpg\r\n",
      "scrapped/zellbury/e7fa5a51f6ea53ece5e308fb680fe61630a10fa9.jpg\r\n",
      "scrapped/zellbury/ea5d2851d39787a10ec3306b54f265319e5c5b4a.jpg\r\n",
      "scrapped/zellbury/edec283f651a18fb651e037d2db7e091cb57d922.jpg\r\n",
      "scrapped/zellbury/ee3b2a3c783dac5027d681b4d3a0f38ba983836d.jpg\r\n",
      "scrapped/zellbury/efcef19fa6cc13eb8b0f0b1cd22b5c953be1320e.jpg\r\n",
      "scrapped/zellbury/f52b3b8925b5ddca73c72508fff57b1127474f9f.jpg\r\n",
      "scrapped/zellbury/f52eb80d186186e498a13f541601e9514de9f46a.jpg\r\n",
      "scrapped/zellbury/f694296b96bf66718e1bb0f6ddb08d2599e2e48c.jpg\r\n",
      "scrapped/zellbury/fc27c54ca17d91cac6b5832aa7ab1cf5b016b683.jpg\r\n",
      "scrapped/zellbury/a1549fedbe79219de4246dfc230f45afc498f974.jpg\r\n",
      "scrapped/elo/0c89b9543020b7a2f844e0b2860d5322b2867180.jpg\r\n",
      "scrapped/elo/0e018730b1224a4ce77c2bf043d9610788803a79.jpg\r\n",
      "scrapped/elo/1dc8a7a93f9e7146351d5346f78afde9b1379a81.jpg\r\n",
      "scrapped/elo/4e1d8ff16555cb2a09bce5635e2d4aba0ba2dd7e.jpg\r\n",
      "scrapped/elo/8caccb0e8d6c295c0e18c4ea447d0c5d3bb13e47.jpg\r\n",
      "scrapped/elo/9edb9232e3992b1529a210c8f9d4346167afcec6.jpg\r\n",
      "scrapped/elo/16c8c8476d3be362941301f733ba7df319f1f83f.jpg\r\n",
      "scrapped/elo/55beefa4357c691d6a5d1f3bfe22bea31b6a47f0.jpg\r\n",
      "scrapped/elo/4072d865a0658401347ae1f8435e2326b14b3307.jpg\r\n",
      "scrapped/elo/7653b2adad9fef091ab57e384346bb62133e80df.jpg\r\n",
      "scrapped/elo/13199bac3e55997f2d2a826f370dea50a4428edb.jpg\r\n",
      "scrapped/elo/aa0d21fe3d3bc84bf55fe9bb3f106e7883d4143f.jpg\r\n",
      "scrapped/elo/b7cfa2c36fca4693bfd5810823dc383823c13b94.jpg\r\n",
      "scrapped/elo/b50c187f79ea1f52c291389b7e9dee31424ad66f.jpg\r\n",
      "scrapped/elo/ba35be6f42cbe26086f3f027d633613881ba5f24.jpg\r\n",
      "scrapped/elo/bd42562b3a26cbaed4b0d930c38a924b8983d97c.jpg\r\n",
      "scrapped/elo/c90dbde15b154ddefd60ad54f8c8d1e293d2bebe.jpg\r\n",
      "scrapped/elo/ccb84ce7f3b4c3d66f9efba606590c32752b91f1.jpg\r\n",
      "scrapped/elo/d512eebf3b693257e7728258727b1bfcece5e32a.jpg\r\n",
      "scrapped/elo/e0a5ea628eb65e0135b86e56a570a950b769d2b5.jpg\r\n",
      "scrapped/elo/e1d88431a74e1b247d8e3b424afc65ffea672d67.jpg\r\n",
      "scrapped/elo/e6344dbccac469c7d4439c9934589b1c945bde84.jpg\r\n",
      "scrapped/elo/ee4834e3e236f782fa3c3cadf3b7dc526d331773.jpg\r\n",
      "scrapped/elo/fa0d3bc7274af71a11721ec2458f9dee213ad386.jpg\r\n",
      "scrapped/elo/fe4277d4d1640d19275dc1e4c7f3b57b5292a0be.jpg\r\n",
      "img/Eastern/1_7_50.jpg\r\n",
      "img/Eastern/2-1.jpg\r\n",
      "img/Eastern/7f817f30145d9ee906bf63b79531b610.jpg\r\n",
      "img/Eastern/7k.jpg\r\n",
      "img/Eastern/09f771893f0915cea3decef1f80222f0.jpg\r\n",
      "img/Eastern/11.jpg\r\n",
      "img/Eastern/15-1.jpg\r\n",
      "img/Eastern/181.jpg\r\n",
      "img/Eastern/245-600x846.jpg\r\n",
      "img/Eastern/9247e228c7f025f646a59e004c8d47b8.jpg\r\n",
      "img/Eastern/30821-r2_3_.jpg\r\n",
      "img/Eastern/31027_1_.jpg\r\n",
      "img/Eastern/32369_1_.jpg\r\n",
      "img/Eastern/35475_2_.jpg\r\n",
      "img/Eastern/36596_1_.jpg\r\n",
      "img/Eastern/820277877bb20fd3e719311e1e1d6efe.jpg\r\n",
      "img/Eastern/1543386762-1339407736.jpeg\r\n",
      "img/Eastern/1554186937-1535281827.jpeg\r\n",
      "img/Eastern/1554186944-1914768777.jpg\r\n",
      "img/Eastern/al-ks-2488_1_.jpg\r\n",
      "img/Eastern/black-kameez-shalwar-for-men-unstitched-1000x1000.jpg\r\n",
      "img/Eastern/black-kurta-style.jpg\r\n",
      "img/Eastern/Dobby-Kurta-with-Contrast-Manupalations-1031x1547.jpg\r\n",
      "img/Eastern/e261722a149688a1402e8445e6b3775b.jpg\r\n",
      "img/Eastern/Eden-Robe-02.png\r\n",
      "img/Eastern/f7e194e8804080ca11d0b652940071c6.jpg\r\n",
      "img/Eastern/gmsu394-sand-_1_.jpg\r\n",
      "img/Eastern/gsaxut.jpg\r\n",
      "img/Eastern/gts-4152_2__1.jpg\r\n",
      "img/Eastern/hqdefault.jpg\r\n",
      "img/Eastern/HTB1RjdAclcXBuNjt_biq6xpmpXa0.jpg_350x350.jpg\r\n",
      "img/Eastern/hyperzone_embroidery_shalwar_kameez_for_men_royal_blue_0035_.jpg\r\n",
      "img/Eastern/I-31-750x900.jpg\r\n",
      "img/Eastern/IMG_6491-40829-700x904.jpg\r\n",
      "img/Eastern/J.-Men-Kurta-Yellow.jpg\r\n",
      "img/Eastern/Junaid.J-New-Kurta-designs-for-Mens-17.jpg\r\n",
      "img/Eastern/Junaid-Jamshed-Black-CVC-Kameez-Shalwar-for-Men-JJKS-W-30102-1.jpg\r\n",
      "img/Eastern/junaid-jamshed-camel-brown-p-v-mens-kameez-shalwar-image1.jpg\r\n",
      "img/Eastern/Junaid-Jamshed-Light-Blue-Polyester-Viscose-Kameez-Shalwar-for-Men-JJKS-A-30119-650x813.jpg\r\n",
      "img/Eastern/junaid-jamshed-summer-collection-2019-dull-purple-cotton-mens-kameez-shalwar-102868121-image1.jpeg\r\n",
      "img/Eastern/junaid-jamshed-summer-collection-2019-grey-regular-kameez-shalwar-for-men-103960064-image1.jpeg\r\n",
      "img/Eastern/junaid-jamshed-summer-collection-2019-light-grey-cotton-mens-kameez-shalwar-102876121-image1.jpeg\r\n",
      "img/Eastern/junaid-jamshed-summer-collection-2019-prussian-blue-cotton-mens-kameez-shalwar-102838139-image1.jpeg\r\n",
      "img/Eastern/Kurta-45.jpg\r\n",
      "img/Eastern/Kurta-Design-1.jpg\r\n",
      "img/Eastern/Latest-Bonanza-Men-Kurtas-Shalwar-Kameez-Eid-Collection-2016-2017-5.jpg\r\n",
      "img/Eastern/Latest-Eid-Men-Kurta-Shalwar-Kameez-Designs-Collection-2017-2018-5-683x1024.jpeg\r\n",
      "img/Eastern/Latha-3.jpg\r\n",
      "img/Eastern/Men-Kurta-Shalwar-Design-By.jpg\r\n",
      "img/Eastern/Men-shalwar-kameez-light-grey-color-in-blended.jpg\r\n",
      "img/Eastern/Men-Shalwar-Kameez-Stylish-1-682x1024.jpg\r\n",
      "img/Eastern/mks-001-m_1_.jpg\r\n",
      "img/Eastern/mks-12-_5_.jpg\r\n",
      "img/Eastern/mks-17-_1_.jpg\r\n",
      "img/Eastern/mks-32-_1_.jpg\r\n",
      "img/Eastern/mks-39-_1__1.jpg\r\n",
      "img/Eastern/mks-44-_1_.jpg\r\n",
      "img/Eastern/mks-52-_1_.jpg\r\n",
      "img/Eastern/mosaic-men-shalwar-kameez-collection-md-101-blue-_1__1.jpg\r\n",
      "img/Eastern/mqs-001_1_.jpg\r\n",
      "img/Eastern/mqs-006-b-_1_.jpg\r\n",
      "img/Eastern/mqs-07-_1_.jpg\r\n",
      "img/Eastern/mqs-010-_1_.jpg\r\n",
      "img/Eastern/mqs-23-_1_.jpg\r\n",
      "img/Eastern/mqs-27-_5_.jpg\r\n",
      "img/Eastern/mqs-31-_1_.jpg\r\n",
      "img/Eastern/mqs-42-_1_.jpg\r\n",
      "img/Eastern/mqs-44-_1_.jpg\r\n",
      "img/Eastern/New-Mens-Kurta-Designs-for-.jpg\r\n",
      "img/Eastern/New-Mens-wear-shalwar-kameez-15.jpg\r\n",
      "img/Eastern/Purple-Cotton-Mens-Kameez-Shalwar-6200.jpg\r\n",
      "img/Eastern/S-1819_3.jpg\r\n",
      "img/Eastern/shalwar-_-kameez-sk4hc.jpg\r\n",
      "img/Eastern/sk-197_1-768x1024.jpg\r\n",
      "img/Eastern/SK18713-BR_1_1024x1024.jpg\r\n",
      "img/Eastern/SK19023-LGN_1_2e7e44c0-d4ab-4dda-b167-afb15483152b_1024x1024.jpg\r\n",
      "img/Eastern/SK19101-WT.jpg\r\n",
      "img/Eastern/sks-147_1_.jpg\r\n",
      "img/Eastern/SQ3.jpg\r\n",
      "img/Eastern/st-991-_4__1.jpg\r\n",
      "img/Eastern/st-1041-_1_.jpg\r\n",
      "img/Eastern/st-1089-_1_.jpg\r\n",
      "img/Eastern/unnamed(1).jpg\r\n",
      "img/Eastern/unnamed(2).jpg\r\n",
      "img/Eastern/unnamed(3).jpg\r\n",
      "img/Eastern/unnamed(4).jpg\r\n",
      "img/Eastern/unnamed(5).jpg\r\n",
      "img/Eastern/unnamed.jpg\r\n",
      "img/Eastern/web1_6_19.jpg\r\n",
      "img/Eastern/Wedding-Mens-Shalwar-Kameez-Designs-4.jpg\r\n",
      "img/Eastern/White-Kameez-Shalwar-Men.jpg\r\n",
      "img/Eastern/winter-men-s-kameez-shalwar-suits-sks18w-03-_4_.jpg\r\n",
      "img/Eastern/winter-men-s-kameez-shalwar-suits-sks18w-09-_1_.jpg\r\n",
      "img/Eastern/winter-men-s-kameez-shalwar-suits-sks18w-11-_1_.jpg\r\n",
      "img/Eastern/zellbury_eastern_wear_to_for_man_shalwar_kameez_-_mint_green_-_zmsk19461-e-1.jpg\r\n",
      "img/Eastern/zellbury_eastern_wear_to_for_man_shalwar_kameez_-_off_white_-_zmsk19462-e-1.jpg\r\n",
      "img/Eastern/zellbury_ready_to_wear_for_men_shalwar_kameez_2019_-_black_-_zmsk19045-e-1.jpg\r\n",
      "img/Eastern/zellbury-eastern-wear-2019-men-shalwar-kameez-lucky-point-blue-cotton-zmsk19438-s-1.jpg\r\n",
      "img/Eastern/zellbury-eastern-wear-man-shalwar_kameez-zmsk19447-e-1.jpg\r\n",
      "img/Eastern/Men-Kameez-Shalwar-Designs-723x469.jpg\r\n",
      "scrapped/jdot/0a0696c7b8f9c84c97e916cafac11a491b2f1230.jpg\r\n",
      "scrapped/jdot/0ad8953502aa99550cb26556560eb64fface5db7.jpg\r\n",
      "scrapped/jdot/0bbbcba93098a2a8cea59e3cc531685efc30e2ed.jpg\r\n",
      "scrapped/jdot/0d615c7c56e76fdf84e9b48191240755f4cc3804.jpg\r\n",
      "scrapped/jdot/0dbc2f21435c0e1cfc8b3f883d6c47df464e4e5b.jpg\r\n",
      "scrapped/jdot/0df6793aa25b13e2e51b70712dc6f74c5315159f.jpg\r\n",
      "scrapped/jdot/0ec9cddb6910c4bba113679432cf48c598b77969.jpg\r\n",
      "scrapped/jdot/1b84c450431041a7d85b827c3c2fb5467cb504a6.jpg\r\n",
      "scrapped/jdot/1d1e47e53b360bedb46a49382222ca1b693dc24e.jpg\r\n",
      "scrapped/jdot/1d91c48fa8f899a570db6904b7adc5b463eb85b5.jpg\r\n",
      "scrapped/jdot/2aa032fee6c7c26c2a9ee33e485a1ed073e770e5.jpg\r\n",
      "scrapped/jdot/2bf319dac8f05b775f651cc602b733134610bb37.jpg\r\n",
      "scrapped/jdot/2f1a88faa0112ca51d8f320b935f6bfc9c05829d.jpg\r\n",
      "scrapped/jdot/4e359672c99f2c6da4f1c699e6eaa2f4a7066597.jpg\r\n",
      "scrapped/jdot/5b37b203adf3a84b5958903f522884fa88d5108b.jpg\r\n",
      "scrapped/jdot/5be74da0bb2d289551281d7c09155d5fee539861.jpg\r\n",
      "scrapped/jdot/5d9a868a9baae4d4f27a695cf86063fc40723850.jpg\r\n",
      "scrapped/jdot/5df704753cc1fc6491d928eca11b90e008d57b04.jpg\r\n",
      "scrapped/jdot/5edd3e7faf56ad312cbd88fd65a1d1afd716fcaa.jpg\r\n",
      "scrapped/jdot/5f17121cb04a29e25151a11dc11e48b2c9959490.jpg\r\n",
      "scrapped/jdot/6d2c11645af7ae63c142835ab873cbdb3a3862f0.jpg\r\n",
      "scrapped/jdot/7a1da94a60aef69d1ed03ae9c8a81218d32302f5.jpg\r\n",
      "scrapped/jdot/7a33bc8f7f3556a1bb6171076b2218bf78ed40c2.jpg\r\n",
      "scrapped/jdot/7b40d18f09957b653482fc7fc1bb7dbb141d8b34.jpg\r\n",
      "scrapped/jdot/7ece9db9dca2b201438480bede74ba6c324292ce.jpg\r\n",
      "scrapped/jdot/7fa8684f2970a1aa0b57b4cffd93bc5cb42fbc36.jpg\r\n",
      "scrapped/jdot/8c3c1d6e07379f990da69b1063b670537e665fb6.jpg\r\n",
      "scrapped/jdot/8d6ef326210b65b5155056afd74934959ed6b120.jpg\r\n",
      "scrapped/jdot/8dfe1fea818660ff809f7c2acd8abfcae2a84e70.jpg\r\n",
      "scrapped/jdot/8f07dae2d1e44f6d58bbed1b1423de429b0fcf60.jpg\r\n",
      "scrapped/jdot/8f25fb1d84a035ef7851b4fc6dbeea957d13b3dd.jpg\r\n",
      "scrapped/jdot/9af8e094e8a01be72b683e11d71eb95cd643a500.jpg\r\n",
      "scrapped/jdot/9c9e09c8b2c290a6febb17966a0bef318858ca58.jpg\r\n",
      "scrapped/jdot/9d3dbef0cc0269b21ba7c7b2e9721c3280369537.jpg\r\n",
      "scrapped/jdot/9d7209a5aa1747f3c82a939ec039244bc608c67d.jpg\r\n",
      "scrapped/jdot/013fb1d678abfcc571e0d4d701e82cec37b0ac33.jpg\r\n",
      "scrapped/jdot/15eab078067b59d82b0127e7519f615068c4d016.jpg\r\n",
      "scrapped/jdot/17f17ef0df4a07af72662372cf591ef0a577bd18.jpg\r\n",
      "scrapped/jdot/24a84da1d89f9006cec35f6256bb4ae167f638ee.jpg\r\n",
      "scrapped/jdot/35be4150267ede558c33ba8f28345c957fc7b370.jpg\r\n",
      "scrapped/jdot/37cb9fd6989dd260f4031139a864a22c11b9874c.jpg\r\n",
      "scrapped/jdot/37e0f337d75f6cc6d41d88e4ac82df1eca3cc1cb.jpg\r\n",
      "scrapped/jdot/40bed6681d23182795ba828e0e78e4f5894839e9.jpg\r\n",
      "scrapped/jdot/41f868814966f695a64517d3ffe1dd5cf23ebf3a.jpg\r\n",
      "scrapped/jdot/43c86ac859d48705d79a29f0ca6a2275e607c4f2.jpg\r\n",
      "scrapped/jdot/46f6ec2db186a953921e69fed1c0b3e945a81f73.jpg\r\n",
      "scrapped/jdot/49a6fe14f1c0bf2d7379910ed8787d75a79f2ece.jpg\r\n",
      "scrapped/jdot/54c276b5c34e308ca0a6b3c6128c7b3697bf917d.jpg\r\n",
      "scrapped/jdot/57dc1ffdb7f8cbefacab7ac412c6c1483f6131cd.jpg\r\n",
      "scrapped/jdot/65fd1769f52eb49d8218aa5174574df661db75e4.jpg\r\n",
      "scrapped/jdot/68b996a0213d49ceac9996b8236b11d7d39e08f8.jpg\r\n",
      "scrapped/jdot/72aa6a3629761aecf7126ab122fa509eb1deb122.jpg\r\n",
      "scrapped/jdot/76fc043650b02b70cec80be86b68db6c8975c23c.jpg\r\n",
      "scrapped/jdot/77c00f9faabc9effd9c87ae54a8ab02899b6e506.jpg\r\n",
      "scrapped/jdot/79bdb2ac6ff9fc0fc47767f14bbf02bc26a37b66.jpg\r\n",
      "scrapped/jdot/81a455fddca4c297a97f50aba721a850fbcb7fdc.jpg\r\n",
      "scrapped/jdot/086f8f6171fece30558548784cc3162db069319e.jpg\r\n",
      "scrapped/jdot/90ac48ff002ede4d5ba4f71dfcf27f48e3f5f913.jpg\r\n",
      "scrapped/jdot/95b96ce99d9b8dc441a6e33efe5d269d9ba18ff8.jpg\r\n",
      "scrapped/jdot/106bd2ffbf7d044fb32c38efcdea3690f4a9b91e.jpg\r\n",
      "scrapped/jdot/239f6d511f569341f9dd766e4b215979eba53558.jpg\r\n",
      "scrapped/jdot/422a7480fba11617b147a1735146ff08b22f6d4a.jpg\r\n",
      "scrapped/jdot/435c8c07759c73a2b86a3182d85a4d5c93a5388a.jpg\r\n",
      "scrapped/jdot/534af489687f16c6343b00fa9add6d9bc9ae8cad.jpg\r\n",
      "scrapped/jdot/544c3fb1d6217df87066cd6c91dee423e2a1e2ed.jpg\r\n",
      "scrapped/jdot/652d4136c97d4de47d839c22047b54c63ee26312.jpg\r\n",
      "scrapped/jdot/1469a6ed3d5c0c659d26ba927d58baab7102fe51.jpg\r\n",
      "scrapped/jdot/1746afe4118d5394e5277d6f6ca7720481998c27.jpg\r\n",
      "scrapped/jdot/3750fdf3371be975a8585ec17922a595000ee62b.jpg\r\n",
      "scrapped/jdot/5721c5f3d24a832558e92ebd10afe6c3374ebb41.jpg\r\n",
      "scrapped/jdot/6302fdf9345d5e45f3decdd59a76c6d83c02d8bb.jpg\r\n",
      "scrapped/jdot/7046cf6c5eca98b9a7c263fbfa4e21414ad3e185.jpg\r\n",
      "scrapped/jdot/7745fd3d33acf94e1757123e114be6ed69b8725e.jpg\r\n",
      "scrapped/jdot/9013b4d44e5e80d6ad84f265449d2eab749eba73.jpg\r\n",
      "scrapped/jdot/9165a05befc1fae7a04965aeff285c7f5c2dd3d9.jpg\r\n",
      "scrapped/jdot/9265f20c114058ee81cdc51d83eb2583234ce489.jpg\r\n",
      "scrapped/jdot/17603a9095104cc7604ee258da0df31df395591f.jpg\r\n",
      "scrapped/jdot/30632f23d41caf94420d241bc8adf7d1ce0d9632.jpg\r\n",
      "scrapped/jdot/056386d89726f07398b73741eb8f0475b596af0e.jpg\r\n",
      "scrapped/jdot/64191e786da228adf06bc607ac99aaefa11e6402.jpg\r\n",
      "scrapped/jdot/78742a7423aaffa15f8f843b7dd981b92c373034.jpg\r\n",
      "scrapped/jdot/79167f934e159c376287442b8b15ad6307d69485.jpg\r\n",
      "scrapped/jdot/149347cba0f14b805f5a50fd77b55ffda3374691.jpg\r\n",
      "scrapped/jdot/547994e22feca9edf0faa083176f3d2beecfb158.jpg\r\n",
      "scrapped/jdot/554259c95b3ace15dd75b09afbc1f8bbddfd6828.jpg\r\n",
      "scrapped/jdot/572798c2bd3897a23c83c272dda091f9344bd50a.jpg\r\n",
      "scrapped/jdot/651020ba8c02c38503ec2bbd0adb85b48fa9b107.jpg\r\n",
      "scrapped/jdot/0703735d1c78c2db82dcb1c1b607225ae7a410d7.jpg\r\n",
      "scrapped/jdot/9843830bfa3385e65b388644a2ac8110f2cd524d.jpg\r\n",
      "scrapped/jdot/60793386dad1564bef298e26c140a53a7a2445f1.jpg\r\n",
      "scrapped/jdot/113572739dc25598b7206f227d1d4a5ffb220de3.jpg\r\n",
      "scrapped/jdot/858780355c4fd47fe0f538bb8d69379ebc81bb38.jpg\r\n",
      "scrapped/jdot/8997603072b0d08167b4196c3e31ff9e102451f7.jpg\r\n",
      "scrapped/jdot/a0bf4ca7e6f536e322030182afc2e9a1d2f400aa.jpg\r\n",
      "scrapped/jdot/a5c1a6c9461cddccaaad48ea11514a508921d521.jpg\r\n",
      "scrapped/jdot/a6d5cdd96efdd52a1a1e429c0223633c130763d1.jpg\r\n",
      "scrapped/jdot/a8fa498f99530621a81d1dbb4d1088bd819fde65.jpg\r\n",
      "scrapped/jdot/a35de30614ba01f63568334e64190ee0849ab437.jpg\r\n",
      "scrapped/jdot/a44c3216708be757830da568bd32ae1392bdf416.jpg\r\n",
      "scrapped/jdot/a73de0a9457a6c8c2ca3aa7f25f6470e7c521dce.jpg\r\n",
      "scrapped/jdot/a1268748c5449a1b4d60c59be5077e5b2feae03c.jpg\r\n",
      "scrapped/jdot/b7d671d1c7a3da0b6626dabfc4779c810231da53.jpg\r\n",
      "scrapped/jdot/b73845d819ecef9b226bdd63174075653bc628bb.jpg\r\n",
      "scrapped/jdot/b079081f150cdb24093376c4210ebdcee7cafe38.jpg\r\n",
      "scrapped/jdot/bb1766f7a51dabddc139e27131009cc9244089ef.jpg\r\n",
      "scrapped/jdot/bf1904dd49bd3c706a15a6ccc7f668add7523c4c.jpg\r\n",
      "scrapped/jdot/c6e3ed830e6589b0cf346323962f001ac639dde8.jpg\r\n",
      "scrapped/jdot/c09d8dcce9c820e3077a4732653fd7a5932e8dc9.jpg\r\n",
      "scrapped/jdot/c24c8ec0d24ca8a32d60ccf1792d4a14294bc8a2.jpg\r\n",
      "scrapped/jdot/c119ab119ae571ac248dd9acfb7621ac81d4c008.jpg\r\n",
      "scrapped/jdot/c699f5cc445b8b1578868623ae7bf8f3c16e7679.jpg\r\n",
      "scrapped/jdot/cb22fe26296644673017abf0c554564a0d535f62.jpg\r\n",
      "scrapped/jdot/cd3a4a2b12e07aecdc1ae0b55b74f871733f96c0.jpg\r\n",
      "scrapped/jdot/cec68c5a5f2f210f232e5cee53f8bb9f24a884e6.jpg\r\n",
      "scrapped/jdot/cf2148e5b9aa851d841cae1c46e86bc7ae534c94.jpg\r\n",
      "scrapped/jdot/d9a136944fa16284a6b209e3c5ab4a20f8ba508c.jpg\r\n",
      "scrapped/jdot/d36e1d6d5d73bfa17bb360e5df5d3e5f220e1edb.jpg\r\n",
      "scrapped/jdot/d93fcd64a695258057d237d521cbac575b1e35c3.jpg\r\n",
      "scrapped/jdot/d571d5000374305a7402065c63f6502a674700a4.jpg\r\n",
      "scrapped/jdot/d079320ab7e04a898816e08e7d61a1f251a01d81.jpg\r\n",
      "scrapped/jdot/d64662049f0046028823ecb7bd672fda198cb8dc.jpg\r\n",
      "scrapped/jdot/d997798471dca8473b1332302ceca44674d693d9.jpg\r\n",
      "scrapped/jdot/da698140f30d780d012edf493bc7ec418930818e.jpg\r\n",
      "scrapped/jdot/db2b98415e14a8e3aefd3844226fd4ea8937ddd8.jpg\r\n",
      "scrapped/jdot/db3481c9fd93e4431d509a685568476f094cbfec.jpg\r\n",
      "scrapped/jdot/dbfbb4f7ccbc601f73bd29483b0dc1938ccc466a.jpg\r\n",
      "scrapped/jdot/dffcc86cfd61b394f34886908b8fdf4c55b657d9.jpg\r\n",
      "scrapped/jdot/e0e3f0f71c94c87c0d6c15b07af9f18119b8363b.jpg\r\n",
      "scrapped/jdot/e3e5ad4da7933223ad01988ca5f4340d4cf5522b.jpg\r\n",
      "scrapped/jdot/e7de361d6749da57e27871eb4134a613100b8a50.jpg\r\n",
      "scrapped/jdot/e55f37c44fc333d49a3b2b3e9e6168989579839b.jpg\r\n",
      "scrapped/jdot/e83e6171d932a59ea399e2b2d53e96e53f460cd5.jpg\r\n",
      "scrapped/jdot/e167f036a59d9f56a8084b66a1db6c925220a159.jpg\r\n",
      "scrapped/jdot/e654f224abce4a8c4792b5889be7853204082573.jpg\r\n",
      "scrapped/jdot/e0921d9f55079adb26ec8c844945ccb1718d8eb9.jpg\r\n",
      "scrapped/jdot/ea3bd5eb7f89436ad09c22f9ed54c61112556989.jpg\r\n",
      "scrapped/jdot/eb6b1c4756c18aea338edd89e009df381f489556.jpg\r\n",
      "scrapped/jdot/ebac146a51dc55ba3ab6db3ab3b2f346380ccafc.jpg\r\n",
      "scrapped/jdot/ebc30e894f38a139b4717a1edfb67d348fbc9e4b.jpg\r\n",
      "scrapped/jdot/ec092da3e715a1fde55b0409be251eb4c4fa2423.jpg\r\n",
      "scrapped/jdot/eed6669dfceb9c23d5e1947ada478af4845869ba.jpg\r\n",
      "scrapped/jdot/efaf74df19bae753d5e43aedda819fa00a9b8e98.jpg\r\n",
      "scrapped/jdot/f8a3b7925595768c749efdf0c43a79000ad8dd71.jpg\r\n",
      "scrapped/jdot/f8c26f5e0571e231f714ed6e9ce5025f9c495d9d.jpg\r\n",
      "scrapped/jdot/f53fcb1054903fe2ec7c9d09bc79ab1655c487aa.jpg\r\n",
      "scrapped/jdot/fa93d7d9cd5f02d3eeb061adf2cbb358a373a908.jpg\r\n",
      "scrapped/jdot/fe8f66bcd2725fa330a24c2d5b4cac05ab0369fb.jpg\r\n",
      "scrapped/zellbury/0b0c765bbbb4c42cb4dd5e0ee12e060819e42542.jpg\r\n",
      "scrapped/zellbury/0bb26012078901fc05fee8868c5af7f6c729da68.jpg\r\n",
      "scrapped/zellbury/0d8a0c2f1b1a0856221c8cf775f75af16891365c.jpg\r\n",
      "scrapped/zellbury/1d3c08130167f30ff24e5b4eecac3f14312bd31b.jpg\r\n",
      "scrapped/zellbury/1e48e5732d89e2106e21e14fa4cb5e4b27da20fa.jpg\r\n",
      "scrapped/zellbury/1ecf96a3a6c5239dd82e6d3e0003af03c3813fd4.jpg\r\n",
      "scrapped/zellbury/3ab667c0275b82c2d6294933e7d9a07fa30f739c.jpg\r\n",
      "scrapped/zellbury/5b29658a88a42f7fde1a0aff2d0725588e6dac7e.jpg\r\n",
      "scrapped/zellbury/6d25b6da13e9f6d48d63c6b476d04c4cff22af2a.jpg\r\n",
      "scrapped/zellbury/6ec5f7999052d2177c071c18845b60c645126e56.jpg\r\n",
      "scrapped/zellbury/6fe4ca99a03af663259863351a18ff560c9bcc9a.jpg\r\n",
      "scrapped/zellbury/7b220ab4cb5090c6ec642b7288e4b7db3e0a880a.jpg\r\n",
      "scrapped/zellbury/08afcebdeb86e1904034a3a0b2a68114dec48676.jpg\r\n",
      "scrapped/zellbury/08c2d4865a715e712742f24ee7a2909463b2e5d2.jpg\r\n",
      "scrapped/zellbury/16a711dde3649ed807671b41d96c53cd5e3ba027.jpg\r\n",
      "scrapped/zellbury/030fc5176c57007f4fe18a323634632925d4f484.jpg\r\n",
      "scrapped/zellbury/46fd190f00a60897910cf597d1a60a75571d5105.jpg\r\n",
      "scrapped/zellbury/61c90bff61c128981a2685a41cd22871f47bdb41.jpg\r\n",
      "scrapped/zellbury/72f09f22295c47f47947b564358f9ef26090162c.jpg\r\n",
      "scrapped/zellbury/87ade9ee0c9c71489c0ece5bd822647eac4e0fc4.jpg\r\n",
      "scrapped/zellbury/92b58eb1ef278e640f898b7cd9bf219d8c2b2428.jpg\r\n",
      "scrapped/zellbury/92ecff0e91269f1c3bab2465dddbfe6c3d7d7bac.jpg\r\n",
      "scrapped/zellbury/147ceba434e8403da93e96371f8e1882fde53efb.jpg\r\n",
      "scrapped/zellbury/238b80a69dc8ab8030918947a318f66fed9c3401.jpg\r\n",
      "scrapped/zellbury/318b58665d4187849f19d26896c25fcd9fa8e0da.jpg\r\n",
      "scrapped/zellbury/352cdd6d3a5191bed0ba17de2f055ad28fde6b1e.jpg\r\n",
      "scrapped/zellbury/407c344d7940cde617fe60927520586110f25198.jpg\r\n",
      "scrapped/zellbury/495a519c0dcb188148159d322cbdd482225b1bb1.jpg\r\n",
      "scrapped/zellbury/498ef7406798011a06eafb8e25b7fcc8a7aafaf3.jpg\r\n",
      "scrapped/zellbury/600da463143faf6bf4c7915bd9144db499532370.jpg\r\n",
      "scrapped/zellbury/688c973a89e95ac2ffb25abf441fd2cf7870487d.jpg\r\n",
      "scrapped/zellbury/876d96cfba2e60805fc50e77e4db2b2935b292e0.jpg\r\n",
      "scrapped/zellbury/5085b8c3eda97df61cf3f3c09cf86746abe8dd86.jpg\r\n",
      "scrapped/zellbury/6786b472fe65891ee52ab592dbc0a1f22c402082.jpg\r\n",
      "scrapped/zellbury/7258fac2725c4db2ea572d72c06c52a8534275ef.jpg\r\n",
      "scrapped/zellbury/7474026571b02264e3fda1b15fe583a21d625617.jpg\r\n",
      "scrapped/zellbury/acfca6667ebd6a2bab66d02d523859840ace2be0.jpg\r\n",
      "scrapped/zellbury/ad0cf46780d127dcb46a538eacb764103ca5313a.jpg\r\n",
      "scrapped/zellbury/b2b03852720d9f24ea37d553b81384867074eec3.jpg\r\n",
      "scrapped/zellbury/c46f5a22515baec876171a235beda55bb2a6848f.jpg\r\n",
      "scrapped/zellbury/c0715ce14c1a179af12822d38313403395a2542e.jpg\r\n",
      "scrapped/zellbury/ca81ae94b665e232e2c9782e53ef1bf989193eb4.jpg\r\n",
      "scrapped/zellbury/ce681fa135be6f26523831f5db95d9cd73dcffda.jpg\r\n",
      "scrapped/zellbury/ce53381b36c61ef1d4de26531c6a5b950f9fa858.jpg\r\n",
      "scrapped/zellbury/ceb20bf5ec74da77e835c12f7edc0cbf461f79e9.jpg\r\n",
      "scrapped/zellbury/d36aee2dee691856c72b24d5cb72151a95646598.jpg\r\n",
      "scrapped/zellbury/ded1ceb99d663aa5cf2ba2128f284c501ade4645.jpg\r\n",
      "scrapped/zellbury/e7fa5a51f6ea53ece5e308fb680fe61630a10fa9.jpg\r\n",
      "scrapped/zellbury/ea5d2851d39787a10ec3306b54f265319e5c5b4a.jpg\r\n",
      "scrapped/zellbury/edec283f651a18fb651e037d2db7e091cb57d922.jpg\r\n",
      "scrapped/zellbury/ee3b2a3c783dac5027d681b4d3a0f38ba983836d.jpg\r\n",
      "scrapped/zellbury/efcef19fa6cc13eb8b0f0b1cd22b5c953be1320e.jpg\r\n",
      "scrapped/zellbury/f52b3b8925b5ddca73c72508fff57b1127474f9f.jpg\r\n",
      "scrapped/zellbury/f52eb80d186186e498a13f541601e9514de9f46a.jpg\r\n",
      "scrapped/zellbury/f694296b96bf66718e1bb0f6ddb08d2599e2e48c.jpg\r\n",
      "scrapped/zellbury/fc27c54ca17d91cac6b5832aa7ab1cf5b016b683.jpg\r\n",
      "scrapped/zellbury/a1549fedbe79219de4246dfc230f45afc498f974.jpg\r\n",
      "scrapped/elo/0c89b9543020b7a2f844e0b2860d5322b2867180.jpg\r\n",
      "scrapped/elo/0e018730b1224a4ce77c2bf043d9610788803a79.jpg\r\n",
      "scrapped/elo/1dc8a7a93f9e7146351d5346f78afde9b1379a81.jpg\r\n",
      "scrapped/elo/4e1d8ff16555cb2a09bce5635e2d4aba0ba2dd7e.jpg\r\n",
      "scrapped/elo/8caccb0e8d6c295c0e18c4ea447d0c5d3bb13e47.jpg\r\n",
      "scrapped/elo/9edb9232e3992b1529a210c8f9d4346167afcec6.jpg\r\n",
      "scrapped/elo/16c8c8476d3be362941301f733ba7df319f1f83f.jpg\r\n",
      "scrapped/elo/55beefa4357c691d6a5d1f3bfe22bea31b6a47f0.jpg\r\n",
      "scrapped/elo/4072d865a0658401347ae1f8435e2326b14b3307.jpg\r\n",
      "scrapped/elo/7653b2adad9fef091ab57e384346bb62133e80df.jpg\r\n",
      "scrapped/elo/13199bac3e55997f2d2a826f370dea50a4428edb.jpg\r\n",
      "scrapped/elo/aa0d21fe3d3bc84bf55fe9bb3f106e7883d4143f.jpg\r\n",
      "scrapped/elo/b7cfa2c36fca4693bfd5810823dc383823c13b94.jpg\r\n",
      "scrapped/elo/b50c187f79ea1f52c291389b7e9dee31424ad66f.jpg\r\n",
      "scrapped/elo/ba35be6f42cbe26086f3f027d633613881ba5f24.jpg\r\n",
      "scrapped/elo/bd42562b3a26cbaed4b0d930c38a924b8983d97c.jpg\r\n",
      "scrapped/elo/c90dbde15b154ddefd60ad54f8c8d1e293d2bebe.jpg\r\n",
      "scrapped/elo/ccb84ce7f3b4c3d66f9efba606590c32752b91f1.jpg\r\n",
      "scrapped/elo/d512eebf3b693257e7728258727b1bfcece5e32a.jpg\r\n",
      "scrapped/elo/e0a5ea628eb65e0135b86e56a570a950b769d2b5.jpg\r\n",
      "scrapped/elo/e1d88431a74e1b247d8e3b424afc65ffea672d67.jpg\r\n",
      "scrapped/elo/e6344dbccac469c7d4439c9934589b1c945bde84.jpg\r\n",
      "scrapped/elo/ee4834e3e236f782fa3c3cadf3b7dc526d331773.jpg\r\n",
      "scrapped/elo/fa0d3bc7274af71a11721ec2458f9dee213ad386.jpg\r\n",
      "scrapped/elo/fe4277d4d1640d19275dc1e4c7f3b57b5292a0be.jpg\r\n",
      "img/Eastern/1_7_50.jpg\r\n",
      "img/Eastern/2-1.jpg\r\n",
      "img/Eastern/7f817f30145d9ee906bf63b79531b610.jpg\r\n",
      "img/Eastern/7k.jpg\r\n",
      "img/Eastern/09f771893f0915cea3decef1f80222f0.jpg\r\n",
      "img/Eastern/11.jpg\r\n",
      "img/Eastern/15-1.jpg\r\n",
      "img/Eastern/181.jpg\r\n",
      "img/Eastern/245-600x846.jpg\r\n",
      "img/Eastern/9247e228c7f025f646a59e004c8d47b8.jpg\r\n",
      "img/Eastern/30821-r2_3_.jpg\r\n",
      "img/Eastern/31027_1_.jpg\r\n",
      "img/Eastern/32369_1_.jpg\r\n",
      "img/Eastern/35475_2_.jpg\r\n",
      "img/Eastern/36596_1_.jpg\r\n",
      "img/Eastern/820277877bb20fd3e719311e1e1d6efe.jpg\r\n",
      "img/Eastern/1543386762-1339407736.jpeg\r\n",
      "img/Eastern/1554186937-1535281827.jpeg\r\n",
      "img/Eastern/1554186944-1914768777.jpg\r\n",
      "img/Eastern/al-ks-2488_1_.jpg\r\n",
      "img/Eastern/black-kameez-shalwar-for-men-unstitched-1000x1000.jpg\r\n",
      "img/Eastern/black-kurta-style.jpg\r\n",
      "img/Eastern/Dobby-Kurta-with-Contrast-Manupalations-1031x1547.jpg\r\n",
      "img/Eastern/e261722a149688a1402e8445e6b3775b.jpg\r\n",
      "img/Eastern/Eden-Robe-02.png\r\n",
      "img/Eastern/f7e194e8804080ca11d0b652940071c6.jpg\r\n",
      "img/Eastern/gmsu394-sand-_1_.jpg\r\n",
      "img/Eastern/gsaxut.jpg\r\n",
      "img/Eastern/gts-4152_2__1.jpg\r\n",
      "img/Eastern/hqdefault.jpg\r\n",
      "img/Eastern/HTB1RjdAclcXBuNjt_biq6xpmpXa0.jpg_350x350.jpg\r\n",
      "img/Eastern/hyperzone_embroidery_shalwar_kameez_for_men_royal_blue_0035_.jpg\r\n",
      "img/Eastern/I-31-750x900.jpg\r\n",
      "img/Eastern/IMG_6491-40829-700x904.jpg\r\n",
      "img/Eastern/J.-Men-Kurta-Yellow.jpg\r\n",
      "img/Eastern/Junaid.J-New-Kurta-designs-for-Mens-17.jpg\r\n",
      "img/Eastern/Junaid-Jamshed-Black-CVC-Kameez-Shalwar-for-Men-JJKS-W-30102-1.jpg\r\n",
      "img/Eastern/junaid-jamshed-camel-brown-p-v-mens-kameez-shalwar-image1.jpg\r\n",
      "img/Eastern/Junaid-Jamshed-Light-Blue-Polyester-Viscose-Kameez-Shalwar-for-Men-JJKS-A-30119-650x813.jpg\r\n",
      "img/Eastern/junaid-jamshed-summer-collection-2019-dull-purple-cotton-mens-kameez-shalwar-102868121-image1.jpeg\r\n",
      "img/Eastern/junaid-jamshed-summer-collection-2019-grey-regular-kameez-shalwar-for-men-103960064-image1.jpeg\r\n",
      "img/Eastern/junaid-jamshed-summer-collection-2019-light-grey-cotton-mens-kameez-shalwar-102876121-image1.jpeg\r\n",
      "img/Eastern/junaid-jamshed-summer-collection-2019-prussian-blue-cotton-mens-kameez-shalwar-102838139-image1.jpeg\r\n",
      "img/Eastern/Kurta-45.jpg\r\n",
      "img/Eastern/Kurta-Design-1.jpg\r\n",
      "img/Eastern/Latest-Bonanza-Men-Kurtas-Shalwar-Kameez-Eid-Collection-2016-2017-5.jpg\r\n",
      "img/Eastern/Latest-Eid-Men-Kurta-Shalwar-Kameez-Designs-Collection-2017-2018-5-683x1024.jpeg\r\n",
      "img/Eastern/Latha-3.jpg\r\n",
      "img/Eastern/Men-Kurta-Shalwar-Design-By.jpg\r\n",
      "img/Eastern/Men-shalwar-kameez-light-grey-color-in-blended.jpg\r\n",
      "img/Eastern/Men-Shalwar-Kameez-Stylish-1-682x1024.jpg\r\n",
      "img/Eastern/mks-001-m_1_.jpg\r\n",
      "img/Eastern/mks-12-_5_.jpg\r\n",
      "img/Eastern/mks-17-_1_.jpg\r\n",
      "img/Eastern/mks-32-_1_.jpg\r\n",
      "img/Eastern/mks-39-_1__1.jpg\r\n",
      "img/Eastern/mks-44-_1_.jpg\r\n",
      "img/Eastern/mks-52-_1_.jpg\r\n",
      "img/Eastern/mosaic-men-shalwar-kameez-collection-md-101-blue-_1__1.jpg\r\n",
      "img/Eastern/mqs-001_1_.jpg\r\n",
      "img/Eastern/mqs-006-b-_1_.jpg\r\n",
      "img/Eastern/mqs-07-_1_.jpg\r\n",
      "img/Eastern/mqs-010-_1_.jpg\r\n",
      "img/Eastern/mqs-23-_1_.jpg\r\n",
      "img/Eastern/mqs-27-_5_.jpg\r\n",
      "img/Eastern/mqs-31-_1_.jpg\r\n",
      "img/Eastern/mqs-42-_1_.jpg\r\n",
      "img/Eastern/mqs-44-_1_.jpg\r\n",
      "img/Eastern/New-Mens-Kurta-Designs-for-.jpg\r\n",
      "img/Eastern/New-Mens-wear-shalwar-kameez-15.jpg\r\n",
      "img/Eastern/Purple-Cotton-Mens-Kameez-Shalwar-6200.jpg\r\n",
      "img/Eastern/S-1819_3.jpg\r\n",
      "img/Eastern/shalwar-_-kameez-sk4hc.jpg\r\n",
      "img/Eastern/sk-197_1-768x1024.jpg\r\n",
      "img/Eastern/SK18713-BR_1_1024x1024.jpg\r\n",
      "img/Eastern/SK19023-LGN_1_2e7e44c0-d4ab-4dda-b167-afb15483152b_1024x1024.jpg\r\n",
      "img/Eastern/SK19101-WT.jpg\r\n",
      "img/Eastern/sks-147_1_.jpg\r\n",
      "img/Eastern/SQ3.jpg\r\n",
      "img/Eastern/st-991-_4__1.jpg\r\n",
      "img/Eastern/st-1041-_1_.jpg\r\n",
      "img/Eastern/st-1089-_1_.jpg\r\n",
      "img/Eastern/unnamed(1).jpg\r\n",
      "img/Eastern/unnamed(2).jpg\r\n",
      "img/Eastern/unnamed(3).jpg\r\n",
      "img/Eastern/unnamed(4).jpg\r\n",
      "img/Eastern/unnamed(5).jpg\r\n",
      "img/Eastern/unnamed.jpg\r\n",
      "img/Eastern/web1_6_19.jpg\r\n",
      "img/Eastern/Wedding-Mens-Shalwar-Kameez-Designs-4.jpg\r\n",
      "img/Eastern/White-Kameez-Shalwar-Men.jpg\r\n",
      "img/Eastern/winter-men-s-kameez-shalwar-suits-sks18w-03-_4_.jpg\r\n",
      "img/Eastern/winter-men-s-kameez-shalwar-suits-sks18w-09-_1_.jpg\r\n",
      "img/Eastern/winter-men-s-kameez-shalwar-suits-sks18w-11-_1_.jpg\r\n",
      "img/Eastern/zellbury_eastern_wear_to_for_man_shalwar_kameez_-_mint_green_-_zmsk19461-e-1.jpg\r\n",
      "img/Eastern/zellbury_eastern_wear_to_for_man_shalwar_kameez_-_off_white_-_zmsk19462-e-1.jpg\r\n",
      "img/Eastern/zellbury_ready_to_wear_for_men_shalwar_kameez_2019_-_black_-_zmsk19045-e-1.jpg\r\n",
      "img/Eastern/zellbury-eastern-wear-2019-men-shalwar-kameez-lucky-point-blue-cotton-zmsk19438-s-1.jpg\r\n",
      "img/Eastern/zellbury-eastern-wear-man-shalwar_kameez-zmsk19447-e-1.jpg\r\n",
      "img/Eastern/Men-Kameez-Shalwar-Designs-723x469.jpg\r\n",
      "scrapped/jdot/0a0696c7b8f9c84c97e916cafac11a491b2f1230.jpg\r\n",
      "scrapped/jdot/0ad8953502aa99550cb26556560eb64fface5db7.jpg\r\n",
      "scrapped/jdot/0bbbcba93098a2a8cea59e3cc531685efc30e2ed.jpg\r\n",
      "scrapped/jdot/0d615c7c56e76fdf84e9b48191240755f4cc3804.jpg\r\n",
      "scrapped/jdot/0dbc2f21435c0e1cfc8b3f883d6c47df464e4e5b.jpg\r\n",
      "scrapped/jdot/0df6793aa25b13e2e51b70712dc6f74c5315159f.jpg\r\n",
      "scrapped/jdot/0ec9cddb6910c4bba113679432cf48c598b77969.jpg\r\n",
      "scrapped/jdot/1b84c450431041a7d85b827c3c2fb5467cb504a6.jpg\r\n",
      "scrapped/jdot/1d1e47e53b360bedb46a49382222ca1b693dc24e.jpg\r\n",
      "scrapped/jdot/1d91c48fa8f899a570db6904b7adc5b463eb85b5.jpg\r\n",
      "scrapped/jdot/2aa032fee6c7c26c2a9ee33e485a1ed073e770e5.jpg\r\n",
      "scrapped/jdot/2bf319dac8f05b775f651cc602b733134610bb37.jpg\r\n",
      "scrapped/jdot/2f1a88faa0112ca51d8f320b935f6bfc9c05829d.jpg\r\n",
      "scrapped/jdot/4e359672c99f2c6da4f1c699e6eaa2f4a7066597.jpg\r\n",
      "scrapped/jdot/5b37b203adf3a84b5958903f522884fa88d5108b.jpg\r\n",
      "scrapped/jdot/5be74da0bb2d289551281d7c09155d5fee539861.jpg\r\n",
      "scrapped/jdot/5d9a868a9baae4d4f27a695cf86063fc40723850.jpg\r\n",
      "scrapped/jdot/5df704753cc1fc6491d928eca11b90e008d57b04.jpg\r\n",
      "scrapped/jdot/5edd3e7faf56ad312cbd88fd65a1d1afd716fcaa.jpg\r\n",
      "scrapped/jdot/5f17121cb04a29e25151a11dc11e48b2c9959490.jpg\r\n",
      "scrapped/jdot/6d2c11645af7ae63c142835ab873cbdb3a3862f0.jpg\r\n",
      "scrapped/jdot/7a1da94a60aef69d1ed03ae9c8a81218d32302f5.jpg\r\n",
      "scrapped/jdot/7a33bc8f7f3556a1bb6171076b2218bf78ed40c2.jpg\r\n",
      "scrapped/jdot/7b40d18f09957b653482fc7fc1bb7dbb141d8b34.jpg\r\n",
      "scrapped/jdot/7ece9db9dca2b201438480bede74ba6c324292ce.jpg\r\n",
      "scrapped/jdot/7fa8684f2970a1aa0b57b4cffd93bc5cb42fbc36.jpg\r\n",
      "scrapped/jdot/8c3c1d6e07379f990da69b1063b670537e665fb6.jpg\r\n",
      "scrapped/jdot/8d6ef326210b65b5155056afd74934959ed6b120.jpg\r\n",
      "scrapped/jdot/8dfe1fea818660ff809f7c2acd8abfcae2a84e70.jpg\r\n",
      "scrapped/jdot/8f07dae2d1e44f6d58bbed1b1423de429b0fcf60.jpg\r\n",
      "scrapped/jdot/8f25fb1d84a035ef7851b4fc6dbeea957d13b3dd.jpg\r\n",
      "scrapped/jdot/9af8e094e8a01be72b683e11d71eb95cd643a500.jpg\r\n",
      "scrapped/jdot/9c9e09c8b2c290a6febb17966a0bef318858ca58.jpg\r\n",
      "scrapped/jdot/9d3dbef0cc0269b21ba7c7b2e9721c3280369537.jpg\r\n",
      "scrapped/jdot/9d7209a5aa1747f3c82a939ec039244bc608c67d.jpg\r\n",
      "scrapped/jdot/013fb1d678abfcc571e0d4d701e82cec37b0ac33.jpg\r\n",
      "scrapped/jdot/15eab078067b59d82b0127e7519f615068c4d016.jpg\r\n",
      "scrapped/jdot/17f17ef0df4a07af72662372cf591ef0a577bd18.jpg\r\n",
      "scrapped/jdot/24a84da1d89f9006cec35f6256bb4ae167f638ee.jpg\r\n",
      "scrapped/jdot/35be4150267ede558c33ba8f28345c957fc7b370.jpg\r\n",
      "scrapped/jdot/37cb9fd6989dd260f4031139a864a22c11b9874c.jpg\r\n",
      "scrapped/jdot/37e0f337d75f6cc6d41d88e4ac82df1eca3cc1cb.jpg\r\n",
      "scrapped/jdot/40bed6681d23182795ba828e0e78e4f5894839e9.jpg\r\n",
      "scrapped/jdot/41f868814966f695a64517d3ffe1dd5cf23ebf3a.jpg\r\n",
      "scrapped/jdot/43c86ac859d48705d79a29f0ca6a2275e607c4f2.jpg\r\n",
      "scrapped/jdot/46f6ec2db186a953921e69fed1c0b3e945a81f73.jpg\r\n",
      "scrapped/jdot/49a6fe14f1c0bf2d7379910ed8787d75a79f2ece.jpg\r\n",
      "scrapped/jdot/54c276b5c34e308ca0a6b3c6128c7b3697bf917d.jpg\r\n",
      "scrapped/jdot/57dc1ffdb7f8cbefacab7ac412c6c1483f6131cd.jpg\r\n",
      "scrapped/jdot/65fd1769f52eb49d8218aa5174574df661db75e4.jpg\r\n",
      "scrapped/jdot/68b996a0213d49ceac9996b8236b11d7d39e08f8.jpg\r\n",
      "scrapped/jdot/72aa6a3629761aecf7126ab122fa509eb1deb122.jpg\r\n",
      "scrapped/jdot/76fc043650b02b70cec80be86b68db6c8975c23c.jpg\r\n",
      "scrapped/jdot/77c00f9faabc9effd9c87ae54a8ab02899b6e506.jpg\r\n",
      "scrapped/jdot/79bdb2ac6ff9fc0fc47767f14bbf02bc26a37b66.jpg\r\n",
      "scrapped/jdot/81a455fddca4c297a97f50aba721a850fbcb7fdc.jpg\r\n",
      "scrapped/jdot/086f8f6171fece30558548784cc3162db069319e.jpg\r\n",
      "scrapped/jdot/90ac48ff002ede4d5ba4f71dfcf27f48e3f5f913.jpg\r\n",
      "scrapped/jdot/95b96ce99d9b8dc441a6e33efe5d269d9ba18ff8.jpg\r\n",
      "scrapped/jdot/106bd2ffbf7d044fb32c38efcdea3690f4a9b91e.jpg\r\n",
      "scrapped/jdot/239f6d511f569341f9dd766e4b215979eba53558.jpg\r\n",
      "scrapped/jdot/422a7480fba11617b147a1735146ff08b22f6d4a.jpg\r\n",
      "scrapped/jdot/435c8c07759c73a2b86a3182d85a4d5c93a5388a.jpg\r\n",
      "scrapped/jdot/534af489687f16c6343b00fa9add6d9bc9ae8cad.jpg\r\n",
      "scrapped/jdot/544c3fb1d6217df87066cd6c91dee423e2a1e2ed.jpg\r\n",
      "scrapped/jdot/652d4136c97d4de47d839c22047b54c63ee26312.jpg\r\n",
      "scrapped/jdot/1469a6ed3d5c0c659d26ba927d58baab7102fe51.jpg\r\n",
      "scrapped/jdot/1746afe4118d5394e5277d6f6ca7720481998c27.jpg\r\n",
      "scrapped/jdot/3750fdf3371be975a8585ec17922a595000ee62b.jpg\r\n",
      "scrapped/jdot/5721c5f3d24a832558e92ebd10afe6c3374ebb41.jpg\r\n",
      "scrapped/jdot/6302fdf9345d5e45f3decdd59a76c6d83c02d8bb.jpg\r\n",
      "scrapped/jdot/7046cf6c5eca98b9a7c263fbfa4e21414ad3e185.jpg\r\n",
      "scrapped/jdot/7745fd3d33acf94e1757123e114be6ed69b8725e.jpg\r\n",
      "scrapped/jdot/9013b4d44e5e80d6ad84f265449d2eab749eba73.jpg\r\n",
      "scrapped/jdot/9165a05befc1fae7a04965aeff285c7f5c2dd3d9.jpg\r\n",
      "scrapped/jdot/9265f20c114058ee81cdc51d83eb2583234ce489.jpg\r\n",
      "scrapped/jdot/17603a9095104cc7604ee258da0df31df395591f.jpg\r\n",
      "scrapped/jdot/30632f23d41caf94420d241bc8adf7d1ce0d9632.jpg\r\n",
      "scrapped/jdot/056386d89726f07398b73741eb8f0475b596af0e.jpg\r\n",
      "scrapped/jdot/64191e786da228adf06bc607ac99aaefa11e6402.jpg\r\n",
      "scrapped/jdot/78742a7423aaffa15f8f843b7dd981b92c373034.jpg\r\n",
      "scrapped/jdot/79167f934e159c376287442b8b15ad6307d69485.jpg\r\n",
      "scrapped/jdot/149347cba0f14b805f5a50fd77b55ffda3374691.jpg\r\n",
      "scrapped/jdot/547994e22feca9edf0faa083176f3d2beecfb158.jpg\r\n",
      "scrapped/jdot/554259c95b3ace15dd75b09afbc1f8bbddfd6828.jpg\r\n",
      "scrapped/jdot/572798c2bd3897a23c83c272dda091f9344bd50a.jpg\r\n",
      "scrapped/jdot/651020ba8c02c38503ec2bbd0adb85b48fa9b107.jpg\r\n",
      "scrapped/jdot/0703735d1c78c2db82dcb1c1b607225ae7a410d7.jpg\r\n",
      "scrapped/jdot/9843830bfa3385e65b388644a2ac8110f2cd524d.jpg\r\n",
      "scrapped/jdot/60793386dad1564bef298e26c140a53a7a2445f1.jpg\r\n",
      "scrapped/jdot/113572739dc25598b7206f227d1d4a5ffb220de3.jpg\r\n",
      "scrapped/jdot/858780355c4fd47fe0f538bb8d69379ebc81bb38.jpg\r\n",
      "scrapped/jdot/8997603072b0d08167b4196c3e31ff9e102451f7.jpg\r\n",
      "scrapped/jdot/a0bf4ca7e6f536e322030182afc2e9a1d2f400aa.jpg\r\n",
      "scrapped/jdot/a5c1a6c9461cddccaaad48ea11514a508921d521.jpg\r\n",
      "scrapped/jdot/a6d5cdd96efdd52a1a1e429c0223633c130763d1.jpg\r\n",
      "scrapped/jdot/a8fa498f99530621a81d1dbb4d1088bd819fde65.jpg\r\n",
      "scrapped/jdot/a35de30614ba01f63568334e64190ee0849ab437.jpg\r\n",
      "scrapped/jdot/a44c3216708be757830da568bd32ae1392bdf416.jpg\r\n",
      "scrapped/jdot/a73de0a9457a6c8c2ca3aa7f25f6470e7c521dce.jpg\r\n",
      "scrapped/jdot/a1268748c5449a1b4d60c59be5077e5b2feae03c.jpg\r\n",
      "scrapped/jdot/b7d671d1c7a3da0b6626dabfc4779c810231da53.jpg\r\n",
      "scrapped/jdot/b73845d819ecef9b226bdd63174075653bc628bb.jpg\r\n",
      "scrapped/jdot/b079081f150cdb24093376c4210ebdcee7cafe38.jpg\r\n",
      "scrapped/jdot/bb1766f7a51dabddc139e27131009cc9244089ef.jpg\r\n",
      "scrapped/jdot/bf1904dd49bd3c706a15a6ccc7f668add7523c4c.jpg\r\n",
      "scrapped/jdot/c6e3ed830e6589b0cf346323962f001ac639dde8.jpg\r\n",
      "scrapped/jdot/c09d8dcce9c820e3077a4732653fd7a5932e8dc9.jpg\r\n",
      "scrapped/jdot/c24c8ec0d24ca8a32d60ccf1792d4a14294bc8a2.jpg\r\n",
      "scrapped/jdot/c119ab119ae571ac248dd9acfb7621ac81d4c008.jpg\r\n",
      "scrapped/jdot/c699f5cc445b8b1578868623ae7bf8f3c16e7679.jpg\r\n",
      "scrapped/jdot/cb22fe26296644673017abf0c554564a0d535f62.jpg\r\n",
      "scrapped/jdot/cd3a4a2b12e07aecdc1ae0b55b74f871733f96c0.jpg\r\n",
      "scrapped/jdot/cec68c5a5f2f210f232e5cee53f8bb9f24a884e6.jpg\r\n",
      "scrapped/jdot/cf2148e5b9aa851d841cae1c46e86bc7ae534c94.jpg\r\n",
      "scrapped/jdot/d9a136944fa16284a6b209e3c5ab4a20f8ba508c.jpg\r\n",
      "scrapped/jdot/d36e1d6d5d73bfa17bb360e5df5d3e5f220e1edb.jpg\r\n",
      "scrapped/jdot/d93fcd64a695258057d237d521cbac575b1e35c3.jpg\r\n",
      "scrapped/jdot/d571d5000374305a7402065c63f6502a674700a4.jpg\r\n",
      "scrapped/jdot/d079320ab7e04a898816e08e7d61a1f251a01d81.jpg\r\n",
      "scrapped/jdot/d64662049f0046028823ecb7bd672fda198cb8dc.jpg\r\n",
      "scrapped/jdot/d997798471dca8473b1332302ceca44674d693d9.jpg\r\n",
      "scrapped/jdot/da698140f30d780d012edf493bc7ec418930818e.jpg\r\n",
      "scrapped/jdot/db2b98415e14a8e3aefd3844226fd4ea8937ddd8.jpg\r\n",
      "scrapped/jdot/db3481c9fd93e4431d509a685568476f094cbfec.jpg\r\n",
      "scrapped/jdot/dbfbb4f7ccbc601f73bd29483b0dc1938ccc466a.jpg\r\n",
      "scrapped/jdot/dffcc86cfd61b394f34886908b8fdf4c55b657d9.jpg\r\n",
      "scrapped/jdot/e0e3f0f71c94c87c0d6c15b07af9f18119b8363b.jpg\r\n",
      "scrapped/jdot/e3e5ad4da7933223ad01988ca5f4340d4cf5522b.jpg\r\n",
      "scrapped/jdot/e7de361d6749da57e27871eb4134a613100b8a50.jpg\r\n",
      "scrapped/jdot/e55f37c44fc333d49a3b2b3e9e6168989579839b.jpg\r\n",
      "scrapped/jdot/e83e6171d932a59ea399e2b2d53e96e53f460cd5.jpg\r\n",
      "scrapped/jdot/e167f036a59d9f56a8084b66a1db6c925220a159.jpg\r\n",
      "scrapped/jdot/e654f224abce4a8c4792b5889be7853204082573.jpg\r\n",
      "scrapped/jdot/e0921d9f55079adb26ec8c844945ccb1718d8eb9.jpg\r\n",
      "scrapped/jdot/ea3bd5eb7f89436ad09c22f9ed54c61112556989.jpg\r\n",
      "scrapped/jdot/eb6b1c4756c18aea338edd89e009df381f489556.jpg\r\n",
      "scrapped/jdot/ebac146a51dc55ba3ab6db3ab3b2f346380ccafc.jpg\r\n",
      "scrapped/jdot/ebc30e894f38a139b4717a1edfb67d348fbc9e4b.jpg\r\n",
      "scrapped/jdot/ec092da3e715a1fde55b0409be251eb4c4fa2423.jpg\r\n",
      "scrapped/jdot/eed6669dfceb9c23d5e1947ada478af4845869ba.jpg\r\n",
      "scrapped/jdot/efaf74df19bae753d5e43aedda819fa00a9b8e98.jpg\r\n",
      "scrapped/jdot/f8a3b7925595768c749efdf0c43a79000ad8dd71.jpg\r\n",
      "scrapped/jdot/f8c26f5e0571e231f714ed6e9ce5025f9c495d9d.jpg\r\n",
      "scrapped/jdot/f53fcb1054903fe2ec7c9d09bc79ab1655c487aa.jpg\r\n",
      "scrapped/jdot/fa93d7d9cd5f02d3eeb061adf2cbb358a373a908.jpg\r\n",
      "scrapped/jdot/fe8f66bcd2725fa330a24c2d5b4cac05ab0369fb.jpg\r\n",
      "scrapped/zellbury/0b0c765bbbb4c42cb4dd5e0ee12e060819e42542.jpg\r\n",
      "scrapped/zellbury/0bb26012078901fc05fee8868c5af7f6c729da68.jpg\r\n",
      "scrapped/zellbury/0d8a0c2f1b1a0856221c8cf775f75af16891365c.jpg\r\n",
      "scrapped/zellbury/1d3c08130167f30ff24e5b4eecac3f14312bd31b.jpg\r\n",
      "scrapped/zellbury/1e48e5732d89e2106e21e14fa4cb5e4b27da20fa.jpg\r\n",
      "scrapped/zellbury/1ecf96a3a6c5239dd82e6d3e0003af03c3813fd4.jpg\r\n",
      "scrapped/zellbury/3ab667c0275b82c2d6294933e7d9a07fa30f739c.jpg\r\n",
      "scrapped/zellbury/5b29658a88a42f7fde1a0aff2d0725588e6dac7e.jpg\r\n",
      "scrapped/zellbury/6d25b6da13e9f6d48d63c6b476d04c4cff22af2a.jpg\r\n",
      "scrapped/zellbury/6ec5f7999052d2177c071c18845b60c645126e56.jpg\r\n",
      "scrapped/zellbury/6fe4ca99a03af663259863351a18ff560c9bcc9a.jpg\r\n",
      "scrapped/zellbury/7b220ab4cb5090c6ec642b7288e4b7db3e0a880a.jpg\r\n",
      "scrapped/zellbury/08afcebdeb86e1904034a3a0b2a68114dec48676.jpg\r\n",
      "scrapped/zellbury/08c2d4865a715e712742f24ee7a2909463b2e5d2.jpg\r\n",
      "scrapped/zellbury/16a711dde3649ed807671b41d96c53cd5e3ba027.jpg\r\n",
      "scrapped/zellbury/030fc5176c57007f4fe18a323634632925d4f484.jpg\r\n",
      "scrapped/zellbury/46fd190f00a60897910cf597d1a60a75571d5105.jpg\r\n",
      "scrapped/zellbury/61c90bff61c128981a2685a41cd22871f47bdb41.jpg\r\n",
      "scrapped/zellbury/72f09f22295c47f47947b564358f9ef26090162c.jpg\r\n",
      "scrapped/zellbury/87ade9ee0c9c71489c0ece5bd822647eac4e0fc4.jpg\r\n",
      "scrapped/zellbury/92b58eb1ef278e640f898b7cd9bf219d8c2b2428.jpg\r\n",
      "scrapped/zellbury/92ecff0e91269f1c3bab2465dddbfe6c3d7d7bac.jpg\r\n",
      "scrapped/zellbury/147ceba434e8403da93e96371f8e1882fde53efb.jpg\r\n",
      "scrapped/zellbury/238b80a69dc8ab8030918947a318f66fed9c3401.jpg\r\n",
      "scrapped/zellbury/318b58665d4187849f19d26896c25fcd9fa8e0da.jpg\r\n",
      "scrapped/zellbury/352cdd6d3a5191bed0ba17de2f055ad28fde6b1e.jpg\r\n",
      "scrapped/zellbury/407c344d7940cde617fe60927520586110f25198.jpg\r\n",
      "scrapped/zellbury/495a519c0dcb188148159d322cbdd482225b1bb1.jpg\r\n",
      "scrapped/zellbury/498ef7406798011a06eafb8e25b7fcc8a7aafaf3.jpg\r\n",
      "scrapped/zellbury/600da463143faf6bf4c7915bd9144db499532370.jpg\r\n",
      "scrapped/zellbury/688c973a89e95ac2ffb25abf441fd2cf7870487d.jpg\r\n",
      "scrapped/zellbury/876d96cfba2e60805fc50e77e4db2b2935b292e0.jpg\r\n",
      "scrapped/zellbury/5085b8c3eda97df61cf3f3c09cf86746abe8dd86.jpg\r\n",
      "scrapped/zellbury/6786b472fe65891ee52ab592dbc0a1f22c402082.jpg\r\n",
      "scrapped/zellbury/7258fac2725c4db2ea572d72c06c52a8534275ef.jpg\r\n",
      "scrapped/zellbury/7474026571b02264e3fda1b15fe583a21d625617.jpg\r\n",
      "scrapped/zellbury/acfca6667ebd6a2bab66d02d523859840ace2be0.jpg\r\n",
      "scrapped/zellbury/ad0cf46780d127dcb46a538eacb764103ca5313a.jpg\r\n",
      "scrapped/zellbury/b2b03852720d9f24ea37d553b81384867074eec3.jpg\r\n",
      "scrapped/zellbury/c46f5a22515baec876171a235beda55bb2a6848f.jpg\r\n",
      "scrapped/zellbury/c0715ce14c1a179af12822d38313403395a2542e.jpg\r\n",
      "scrapped/zellbury/ca81ae94b665e232e2c9782e53ef1bf989193eb4.jpg\r\n",
      "scrapped/zellbury/ce681fa135be6f26523831f5db95d9cd73dcffda.jpg\r\n",
      "scrapped/zellbury/ce53381b36c61ef1d4de26531c6a5b950f9fa858.jpg\r\n",
      "scrapped/zellbury/ceb20bf5ec74da77e835c12f7edc0cbf461f79e9.jpg\r\n",
      "scrapped/zellbury/d36aee2dee691856c72b24d5cb72151a95646598.jpg\r\n",
      "scrapped/zellbury/ded1ceb99d663aa5cf2ba2128f284c501ade4645.jpg\r\n",
      "scrapped/zellbury/e7fa5a51f6ea53ece5e308fb680fe61630a10fa9.jpg\r\n",
      "scrapped/zellbury/ea5d2851d39787a10ec3306b54f265319e5c5b4a.jpg\r\n",
      "scrapped/zellbury/edec283f651a18fb651e037d2db7e091cb57d922.jpg\r\n",
      "scrapped/zellbury/ee3b2a3c783dac5027d681b4d3a0f38ba983836d.jpg\r\n",
      "scrapped/zellbury/efcef19fa6cc13eb8b0f0b1cd22b5c953be1320e.jpg\r\n",
      "scrapped/zellbury/f52b3b8925b5ddca73c72508fff57b1127474f9f.jpg\r\n",
      "scrapped/zellbury/f52eb80d186186e498a13f541601e9514de9f46a.jpg\r\n",
      "scrapped/zellbury/f694296b96bf66718e1bb0f6ddb08d2599e2e48c.jpg\r\n",
      "scrapped/zellbury/fc27c54ca17d91cac6b5832aa7ab1cf5b016b683.jpg\r\n",
      "scrapped/zellbury/a1549fedbe79219de4246dfc230f45afc498f974.jpg\r\n",
      "scrapped/elo/0c89b9543020b7a2f844e0b2860d5322b2867180.jpg\r\n",
      "scrapped/elo/0e018730b1224a4ce77c2bf043d9610788803a79.jpg\r\n",
      "scrapped/elo/1dc8a7a93f9e7146351d5346f78afde9b1379a81.jpg\r\n",
      "scrapped/elo/4e1d8ff16555cb2a09bce5635e2d4aba0ba2dd7e.jpg\r\n",
      "scrapped/elo/8caccb0e8d6c295c0e18c4ea447d0c5d3bb13e47.jpg\r\n",
      "scrapped/elo/9edb9232e3992b1529a210c8f9d4346167afcec6.jpg\r\n",
      "scrapped/elo/16c8c8476d3be362941301f733ba7df319f1f83f.jpg\r\n",
      "scrapped/elo/55beefa4357c691d6a5d1f3bfe22bea31b6a47f0.jpg\r\n",
      "scrapped/elo/4072d865a0658401347ae1f8435e2326b14b3307.jpg\r\n",
      "scrapped/elo/7653b2adad9fef091ab57e384346bb62133e80df.jpg\r\n",
      "scrapped/elo/13199bac3e55997f2d2a826f370dea50a4428edb.jpg\r\n",
      "scrapped/elo/aa0d21fe3d3bc84bf55fe9bb3f106e7883d4143f.jpg\r\n",
      "scrapped/elo/b7cfa2c36fca4693bfd5810823dc383823c13b94.jpg\r\n",
      "scrapped/elo/b50c187f79ea1f52c291389b7e9dee31424ad66f.jpg\r\n",
      "scrapped/elo/ba35be6f42cbe26086f3f027d633613881ba5f24.jpg\r\n",
      "scrapped/elo/bd42562b3a26cbaed4b0d930c38a924b8983d97c.jpg\r\n",
      "scrapped/elo/c90dbde15b154ddefd60ad54f8c8d1e293d2bebe.jpg\r\n",
      "scrapped/elo/ccb84ce7f3b4c3d66f9efba606590c32752b91f1.jpg\r\n",
      "scrapped/elo/d512eebf3b693257e7728258727b1bfcece5e32a.jpg\r\n",
      "scrapped/elo/e0a5ea628eb65e0135b86e56a570a950b769d2b5.jpg\r\n",
      "scrapped/elo/e1d88431a74e1b247d8e3b424afc65ffea672d67.jpg\r\n",
      "scrapped/elo/e6344dbccac469c7d4439c9934589b1c945bde84.jpg\r\n",
      "scrapped/elo/ee4834e3e236f782fa3c3cadf3b7dc526d331773.jpg\r\n",
      "scrapped/elo/fa0d3bc7274af71a11721ec2458f9dee213ad386.jpg\r\n",
      "scrapped/elo/fe4277d4d1640d19275dc1e4c7f3b57b5292a0be.jpg\r\n",
      "Train Epoch: 1 [0/209454 (0%)]\tAll Loss: 5.0146\tTriple Loss(1): 0.5748\tClassification Loss: 3.8651\r\n",
      "train.py:214: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\r\n",
      "\r\n",
      "Test set: Average loss: 3.8320\r\n",
      "Top 1 Accuracy: 4836/80128 (6%)\r\n",
      "Top 3 Accuracy: 12331/80128 (15%)\r\n",
      "Top 5 Accuracy: 19107/80128 (24%)\r\n",
      " \r\n",
      "Train Epoch: 1 [640/209454 (0%)]\tAll Loss: 3.1627\tTriple Loss(0): 0.0000\tClassification Loss: 3.1627\r\n",
      "Train Epoch: 1 [1280/209454 (1%)]\tAll Loss: 6.3173\tTriple Loss(0): 1.1470\tClassification Loss: 4.0232\r\n",
      "Train Epoch: 1 [1920/209454 (1%)]\tAll Loss: 7.1409\tTriple Loss(1): 1.4600\tClassification Loss: 4.2209\r\n",
      "Train Epoch: 1 [2560/209454 (1%)]\tAll Loss: 4.6367\tTriple Loss(1): 0.8861\tClassification Loss: 2.8646\r\n",
      "Train Epoch: 1 [3200/209454 (2%)]\tAll Loss: 5.0698\tTriple Loss(1): 0.8638\tClassification Loss: 3.3422\r\n",
      "Train Epoch: 1 [3840/209454 (2%)]\tAll Loss: 4.4857\tTriple Loss(1): 0.7517\tClassification Loss: 2.9823\r\n",
      "Train Epoch: 1 [4480/209454 (2%)]\tAll Loss: 3.9345\tTriple Loss(1): 0.5591\tClassification Loss: 2.8163\r\n",
      "Train Epoch: 1 [5120/209454 (2%)]\tAll Loss: 4.4960\tTriple Loss(1): 0.7990\tClassification Loss: 2.8981\r\n",
      "Train Epoch: 1 [5760/209454 (3%)]\tAll Loss: 5.7915\tTriple Loss(1): 0.9155\tClassification Loss: 3.9605\r\n",
      "Train Epoch: 1 [6400/209454 (3%)]\tAll Loss: 7.4210\tTriple Loss(1): 1.0526\tClassification Loss: 5.3158\r\n",
      "Train Epoch: 1 [7040/209454 (3%)]\tAll Loss: 9.1359\tTriple Loss(1): 1.8369\tClassification Loss: 5.4621\r\n",
      "Train Epoch: 1 [7680/209454 (4%)]\tAll Loss: 9.0866\tTriple Loss(0): 2.6896\tClassification Loss: 3.7073\r\n",
      "Train Epoch: 1 [8320/209454 (4%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [8960/209454 (4%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [9600/209454 (5%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [10240/209454 (5%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [10880/209454 (5%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [11520/209454 (6%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [12160/209454 (6%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [12800/209454 (6%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [13440/209454 (6%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [14080/209454 (7%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [14720/209454 (7%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [15360/209454 (7%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [16000/209454 (8%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [16640/209454 (8%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [17280/209454 (8%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [17920/209454 (9%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [18560/209454 (9%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [19200/209454 (9%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [19840/209454 (9%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [20480/209454 (10%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [21120/209454 (10%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [21760/209454 (10%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [22400/209454 (11%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [23040/209454 (11%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [23680/209454 (11%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [24320/209454 (12%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [24960/209454 (12%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [25600/209454 (12%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [26240/209454 (13%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [26880/209454 (13%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [27520/209454 (13%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [28160/209454 (13%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [28800/209454 (14%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [29440/209454 (14%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [30080/209454 (14%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [30720/209454 (15%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [31360/209454 (15%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [32000/209454 (15%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [32640/209454 (16%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [33280/209454 (16%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [33920/209454 (16%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [34560/209454 (17%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [35200/209454 (17%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [35840/209454 (17%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [36480/209454 (17%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [37120/209454 (18%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [37760/209454 (18%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [38400/209454 (18%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [39040/209454 (19%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [39680/209454 (19%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [40320/209454 (19%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [40960/209454 (20%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [41600/209454 (20%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [42240/209454 (20%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [42880/209454 (20%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [43520/209454 (21%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [44160/209454 (21%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [44800/209454 (21%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [45440/209454 (22%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [46080/209454 (22%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [46720/209454 (22%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [47360/209454 (23%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [48000/209454 (23%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [48640/209454 (23%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [49280/209454 (24%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [49920/209454 (24%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [50560/209454 (24%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [51200/209454 (24%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [51840/209454 (25%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [52480/209454 (25%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [53120/209454 (25%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [53760/209454 (26%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [54400/209454 (26%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [55040/209454 (26%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [55680/209454 (27%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [56320/209454 (27%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [56960/209454 (27%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [57600/209454 (28%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [58240/209454 (28%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [58880/209454 (28%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [59520/209454 (28%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [60160/209454 (29%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [60800/209454 (29%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [61440/209454 (29%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [62080/209454 (30%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [62720/209454 (30%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [63360/209454 (30%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [64000/209454 (31%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [64640/209454 (31%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [65280/209454 (31%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [65920/209454 (31%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [66560/209454 (32%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [67200/209454 (32%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [67840/209454 (32%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [68480/209454 (33%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [69120/209454 (33%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [69760/209454 (33%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [70400/209454 (34%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [71040/209454 (34%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [71680/209454 (34%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [72320/209454 (35%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [72960/209454 (35%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [73600/209454 (35%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [74240/209454 (35%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [74880/209454 (36%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [75520/209454 (36%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [76160/209454 (36%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [76800/209454 (37%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [77440/209454 (37%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [78080/209454 (37%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [78720/209454 (38%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [79360/209454 (38%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [80000/209454 (38%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [80640/209454 (39%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [81280/209454 (39%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [81920/209454 (39%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [82560/209454 (39%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [83200/209454 (40%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [83840/209454 (40%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [84480/209454 (40%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [85120/209454 (41%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [85760/209454 (41%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [86400/209454 (41%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [87040/209454 (42%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [87680/209454 (42%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [88320/209454 (42%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [88960/209454 (42%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [89600/209454 (43%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [90240/209454 (43%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [90880/209454 (43%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [91520/209454 (44%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [92160/209454 (44%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [92800/209454 (44%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [93440/209454 (45%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [94080/209454 (45%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [94720/209454 (45%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [95360/209454 (46%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [96000/209454 (46%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [96640/209454 (46%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [97280/209454 (46%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [97920/209454 (47%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [98560/209454 (47%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [99200/209454 (47%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [99840/209454 (48%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [100480/209454 (48%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [101120/209454 (48%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [101760/209454 (49%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [102400/209454 (49%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [103040/209454 (49%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [103680/209454 (50%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [104320/209454 (50%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [104960/209454 (50%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [105600/209454 (50%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [106240/209454 (51%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [106880/209454 (51%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [107520/209454 (51%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [108160/209454 (52%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [108800/209454 (52%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [109440/209454 (52%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [110080/209454 (53%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [110720/209454 (53%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [111360/209454 (53%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [112000/209454 (53%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [112640/209454 (54%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [113280/209454 (54%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [113920/209454 (54%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [114560/209454 (55%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [115200/209454 (55%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [115840/209454 (55%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [116480/209454 (56%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [117120/209454 (56%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [117760/209454 (56%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [118400/209454 (57%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [119040/209454 (57%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [119680/209454 (57%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [120320/209454 (57%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [120960/209454 (58%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [121600/209454 (58%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [122240/209454 (58%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [122880/209454 (59%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [123520/209454 (59%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [124160/209454 (59%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [124800/209454 (60%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [125440/209454 (60%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [126080/209454 (60%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [126720/209454 (61%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [127360/209454 (61%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [128000/209454 (61%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [128640/209454 (61%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [129280/209454 (62%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [129920/209454 (62%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [130560/209454 (62%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [131200/209454 (63%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [131840/209454 (63%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [132480/209454 (63%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [133120/209454 (64%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [133760/209454 (64%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [134400/209454 (64%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [135040/209454 (64%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [135680/209454 (65%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [136320/209454 (65%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [136960/209454 (65%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [137600/209454 (66%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [138240/209454 (66%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [138880/209454 (66%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [139520/209454 (67%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [140160/209454 (67%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [140800/209454 (67%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [141440/209454 (68%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [142080/209454 (68%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [142720/209454 (68%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [143360/209454 (68%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [144000/209454 (69%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [144640/209454 (69%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [145280/209454 (69%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [145920/209454 (70%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [146560/209454 (70%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [147200/209454 (70%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [147840/209454 (71%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [148480/209454 (71%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [149120/209454 (71%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [149760/209454 (72%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [150400/209454 (72%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [151040/209454 (72%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [151680/209454 (72%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [152320/209454 (73%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [152960/209454 (73%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [153600/209454 (73%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [154240/209454 (74%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [154880/209454 (74%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [155520/209454 (74%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [156160/209454 (75%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [156800/209454 (75%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [157440/209454 (75%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [158080/209454 (75%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [158720/209454 (76%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [159360/209454 (76%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [160000/209454 (76%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [160640/209454 (77%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [161280/209454 (77%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [161920/209454 (77%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [162560/209454 (78%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [163200/209454 (78%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [163840/209454 (78%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [164480/209454 (79%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [165120/209454 (79%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [165760/209454 (79%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [166400/209454 (79%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [167040/209454 (80%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [167680/209454 (80%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [168320/209454 (80%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [168960/209454 (81%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [169600/209454 (81%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [170240/209454 (81%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [170880/209454 (82%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [171520/209454 (82%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [172160/209454 (82%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [172800/209454 (83%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [173440/209454 (83%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [174080/209454 (83%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [174720/209454 (83%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [175360/209454 (84%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [176000/209454 (84%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [176640/209454 (84%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [177280/209454 (85%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [177920/209454 (85%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [178560/209454 (85%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [179200/209454 (86%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [179840/209454 (86%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [180480/209454 (86%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [181120/209454 (86%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [181760/209454 (87%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [182400/209454 (87%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [183040/209454 (87%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [183680/209454 (88%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [184320/209454 (88%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [184960/209454 (88%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [185600/209454 (89%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [186240/209454 (89%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [186880/209454 (89%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [187520/209454 (90%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [188160/209454 (90%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [188800/209454 (90%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [189440/209454 (90%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [190080/209454 (91%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [190720/209454 (91%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [191360/209454 (91%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [192000/209454 (92%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [192640/209454 (92%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [193280/209454 (92%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [193920/209454 (93%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [194560/209454 (93%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [195200/209454 (93%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [195840/209454 (94%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [196480/209454 (94%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [197120/209454 (94%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [197760/209454 (94%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [198400/209454 (95%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [199040/209454 (95%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [199680/209454 (95%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [200320/209454 (96%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [200960/209454 (96%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [201600/209454 (96%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [202240/209454 (97%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [202880/209454 (97%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [203520/209454 (97%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [204160/209454 (97%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [204800/209454 (98%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [205440/209454 (98%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [206080/209454 (98%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [206720/209454 (99%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [207360/209454 (99%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [208000/209454 (99%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [208640/209454 (100%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 1 [209280/209454 (100%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Model saved to /home/ma02526/ResNet/base/models/freeze=False/lr=0.002/1_epochs\r\n",
      "Train Epoch: 2 [0/209454 (0%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "\r\n",
      "Test set: Average loss: nan\r\n",
      "Top 1 Accuracy: 2087/80128 (3%)\r\n",
      "Top 3 Accuracy: 8931/80128 (11%)\r\n",
      "Top 5 Accuracy: 9098/80128 (11%)\r\n",
      " \r\n",
      "Train Epoch: 2 [640/209454 (0%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [1280/209454 (1%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [1920/209454 (1%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [2560/209454 (1%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [3200/209454 (2%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [3840/209454 (2%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [4480/209454 (2%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [5120/209454 (2%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [5760/209454 (3%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [6400/209454 (3%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [7040/209454 (3%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [7680/209454 (4%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [8320/209454 (4%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [8960/209454 (4%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [9600/209454 (5%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [10240/209454 (5%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [10880/209454 (5%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [11520/209454 (6%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [12160/209454 (6%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [12800/209454 (6%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [13440/209454 (6%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [14080/209454 (7%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [14720/209454 (7%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [15360/209454 (7%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [16000/209454 (8%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [16640/209454 (8%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [17280/209454 (8%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [17920/209454 (9%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [18560/209454 (9%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [19200/209454 (9%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [19840/209454 (9%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [20480/209454 (10%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [21120/209454 (10%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [21760/209454 (10%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [22400/209454 (11%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [23040/209454 (11%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [23680/209454 (11%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [24320/209454 (12%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [24960/209454 (12%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [25600/209454 (12%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [26240/209454 (13%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [26880/209454 (13%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [27520/209454 (13%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [28160/209454 (13%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [28800/209454 (14%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [29440/209454 (14%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [30080/209454 (14%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [30720/209454 (15%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [31360/209454 (15%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [32000/209454 (15%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [32640/209454 (16%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [33280/209454 (16%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [33920/209454 (16%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [34560/209454 (17%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [35200/209454 (17%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [35840/209454 (17%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [36480/209454 (17%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [37120/209454 (18%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [37760/209454 (18%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [38400/209454 (18%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [39040/209454 (19%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [39680/209454 (19%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [40320/209454 (19%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [40960/209454 (20%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [41600/209454 (20%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [42240/209454 (20%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [42880/209454 (20%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [43520/209454 (21%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [44160/209454 (21%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [44800/209454 (21%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [45440/209454 (22%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [46080/209454 (22%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [46720/209454 (22%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [47360/209454 (23%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [48000/209454 (23%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [48640/209454 (23%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [49280/209454 (24%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [49920/209454 (24%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [50560/209454 (24%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [51200/209454 (24%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [51840/209454 (25%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [52480/209454 (25%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [53120/209454 (25%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [53760/209454 (26%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [54400/209454 (26%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [55040/209454 (26%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [55680/209454 (27%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [56320/209454 (27%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [56960/209454 (27%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [57600/209454 (28%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [58240/209454 (28%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [58880/209454 (28%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [59520/209454 (28%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [60160/209454 (29%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [60800/209454 (29%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [61440/209454 (29%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [62080/209454 (30%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [62720/209454 (30%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [63360/209454 (30%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [64000/209454 (31%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [64640/209454 (31%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [65280/209454 (31%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [65920/209454 (31%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [66560/209454 (32%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [67200/209454 (32%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [67840/209454 (32%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [68480/209454 (33%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [69120/209454 (33%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [69760/209454 (33%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [70400/209454 (34%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [71040/209454 (34%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [71680/209454 (34%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [72320/209454 (35%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [72960/209454 (35%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [73600/209454 (35%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [74240/209454 (35%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [74880/209454 (36%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [75520/209454 (36%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [76160/209454 (36%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [76800/209454 (37%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [77440/209454 (37%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [78080/209454 (37%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [78720/209454 (38%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [79360/209454 (38%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [80000/209454 (38%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [80640/209454 (39%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [81280/209454 (39%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [81920/209454 (39%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [82560/209454 (39%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [83200/209454 (40%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [83840/209454 (40%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [84480/209454 (40%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [85120/209454 (41%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [85760/209454 (41%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [86400/209454 (41%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [87040/209454 (42%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [87680/209454 (42%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [88320/209454 (42%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [88960/209454 (42%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [89600/209454 (43%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [90240/209454 (43%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [90880/209454 (43%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [91520/209454 (44%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [92160/209454 (44%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [92800/209454 (44%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [93440/209454 (45%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [94080/209454 (45%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [94720/209454 (45%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [95360/209454 (46%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [96000/209454 (46%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [96640/209454 (46%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [97280/209454 (46%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [97920/209454 (47%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [98560/209454 (47%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [99200/209454 (47%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [99840/209454 (48%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [100480/209454 (48%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [101120/209454 (48%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [101760/209454 (49%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [102400/209454 (49%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [103040/209454 (49%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [103680/209454 (50%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [104320/209454 (50%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [104960/209454 (50%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [105600/209454 (50%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [106240/209454 (51%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [106880/209454 (51%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [107520/209454 (51%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [108160/209454 (52%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [108800/209454 (52%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [109440/209454 (52%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [110080/209454 (53%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [110720/209454 (53%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [111360/209454 (53%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [112000/209454 (53%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [112640/209454 (54%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [113280/209454 (54%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [113920/209454 (54%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [114560/209454 (55%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [115200/209454 (55%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [115840/209454 (55%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [116480/209454 (56%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [117120/209454 (56%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [117760/209454 (56%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [118400/209454 (57%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [119040/209454 (57%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [119680/209454 (57%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [120320/209454 (57%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [120960/209454 (58%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [121600/209454 (58%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [122240/209454 (58%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [122880/209454 (59%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [123520/209454 (59%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [124160/209454 (59%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [124800/209454 (60%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [125440/209454 (60%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [126080/209454 (60%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [126720/209454 (61%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [127360/209454 (61%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [128000/209454 (61%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [128640/209454 (61%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [129280/209454 (62%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [129920/209454 (62%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [130560/209454 (62%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [131200/209454 (63%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [131840/209454 (63%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [132480/209454 (63%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [133120/209454 (64%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [133760/209454 (64%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [134400/209454 (64%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [135040/209454 (64%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [135680/209454 (65%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [136320/209454 (65%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [136960/209454 (65%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [137600/209454 (66%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [138240/209454 (66%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [138880/209454 (66%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [139520/209454 (67%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [140160/209454 (67%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [140800/209454 (67%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [141440/209454 (68%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [142080/209454 (68%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [142720/209454 (68%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [143360/209454 (68%)]\tAll Loss: nan\tTriple Loss(0): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [144000/209454 (69%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n",
      "Train Epoch: 2 [144640/209454 (69%)]\tAll Loss: nan\tTriple Loss(1): nan\tClassification Loss: nan\r\n"
     ]
    }
   ],
   "source": [
    "# With Eastern dataset added.\n",
    "# FREEZE = False. LR=0.002. in-shop=True.\n",
    "! python train.py\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEDtAX9gj2Tq",
    "colab_type": "text"
   },
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c4w2MEm5U8R3",
    "colab_type": "code",
    "outputId": "d781e6f7-ce04-4faf-eabe-11dfc63f1f84",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1586704220059,
     "user_tz": -300,
     "elapsed": 726830,
     "user": {
      "displayName": "Muhammad Ali",
      "photoUrl": "",
      "userId": "15673831022739340207"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "from config import *\n",
    "from plotcm import plot_confusion_matrix\n",
    "\n",
    "import importlib\n",
    "dfretrieval = importlib.import_module(\"deep-fashion-retrieval/train\")\n",
    "from dfretrieval import get_conf_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names = ['Anorak', 'Blazer', 'Bomber', 'Button-Down', 'Cardigan', \n",
    "              'Flannel', 'Henley', 'Hoodie', 'Jacket', 'Jersey', 'Parka', \n",
    "              'Peacoat', 'Sweater', 'Tank', 'Tee', 'Top', 'Turtleneck', \n",
    "              'Chinos','Jeans', 'Joggers', 'Shorts', 'Sweatpants', \n",
    "              'Sweatshorts', 'Trunks', 'Coat', 'Robe']\n",
    "\n",
    "cm = get_conf_matrix()\n",
    "print(cm.shape)\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plot_confusion_matrix(cm, names)"
   ],
   "execution_count": 37,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deep-fashion-retrieval/train'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-37-5e01d999f235>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mdfretrieval\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimport_module\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"deep-fashion-retrieval/train\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mdfretrieval\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mget_conf_matrix\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/importlib/__init__.py\u001B[0m in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    125\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    126\u001B[0m             \u001B[0mlevel\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 127\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_bootstrap\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_gcd_import\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mlevel\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpackage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    128\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/deep-fashion-retrieval/lib/python3.8/importlib/_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'deep-fashion-retrieval/train'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HLtMI6lYCGip",
    "colab_type": "code",
    "outputId": "4a176329-4b70-43c8-d737-a215fc2d3bbb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1586706743938,
     "user_tz": -300,
     "elapsed": 4738,
     "user": {
      "displayName": "Muhammad Ali",
      "photoUrl": "",
      "userId": "15673831022739340207"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cm, names)\n",
    "plt.savefig('conf_matrix.png')"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[   0    0    0    0    1    0    0    1   35    0    0    0    0    0\n",
      "     1    0    0    0    0    0    0    0    0    0    1    0]\n",
      " [   0  590    0    0  294    1    0    0  691    0    0    0   19   37\n",
      "   317   15    0    0   26    6   79    0    0    0   12    0]\n",
      " [   0    1    0    0    3    0    0    0   64    0    0    0    0    0\n",
      "     8    0    0    0    1    0    2    0    0    0    1    0]\n",
      " [   0    0    0    3    5    2    0    0   21    0    0    0    2    4\n",
      "    39    1    0    0    2    0    6    0    0    0    2    0]\n",
      " [   0   73    0    0 1756    0    0    5  521    0    0    0  261   76\n",
      "   772   50    0    0   31   18  128    1    0    0   13    0]\n",
      " [   0    0    0    2    8    5    0    1   10    0    0    0    3    1\n",
      "    58    3    0    0    0    2    7    0    0    0    0    0]\n",
      " [   0    5    0    0    9    0    0    8   15    0    0    0    9    1\n",
      "   138    1    0    0    2    4    3    0    0    0    0    0]\n",
      " [   0    2    0    0   89    0    0  188  211    0    0    0   72   24\n",
      "   506    6    0    0    6    9   25    0    0    0    0    0]\n",
      " [   0  147    0    0  322    0    0   19 1792    0    3    0   21   35\n",
      "   391   29    0    0   37   16   73    0    0    0   34    0]\n",
      " [   0    1    0    0    2    0    0    1   14    0    0    0    0   20\n",
      "   174    0    0    0    0    2    0    0    0    0    0    0]\n",
      " [   0    2    0    0   11    0    0    0  136    0    6    0    2    0\n",
      "     5    0    0    0    1    0    3    0    0    0   19    0]\n",
      " [   0    4    0    0    3    0    0    0   19    0    0    0    0    0\n",
      "     2    0    0    0    0    0    1    0    0    0    5    0]\n",
      " [   0   19    0    0  671    0    0   15  196    0    0    0 1140   81\n",
      "  1308   42    0    0   33    9   89    0    0    0    3    0]\n",
      " [   0    8    0    0   46    0    0    1   36    0    0    0   18 2499\n",
      "  1295   40    0    0   20   14  246    0    0    0    2    0]\n",
      " [   0   22    0    3  160    0    0   17  222    0    0    0  111  665\n",
      "  8501   64    0    0   75   37  353    0    0    0    4    0]\n",
      " [   0   11    0    0  144    0    0    1  102    1    0    0   73  553\n",
      "  1492  124    0    0   21   37  246    1    0    0    2    0]\n",
      " [   0    0    0    0    7    0    0    1    1    0    0    0   14    1\n",
      "    17    2    0    0    0    0    4    0    0    0    0    0]\n",
      " [   0    0    0    0    1    0    0    0    2    0    0    0    0    1\n",
      "    11    0    0   19   29   65   24    0    0    0    1    0]\n",
      " [   0    1    0    0   22    0    0    0   61    0    0    0   10   13\n",
      "   208    2    0    2 1368  204   54    5    0    0    0    0]\n",
      " [   0    5    0    0   23    0    0    0   40    0    0    0    4   14\n",
      "   170    6    0    5  184  617   79    9    0    0    0    0]\n",
      " [   0    9    0    0   49    0    0    0   94    0    0    0   22  295\n",
      "   772   21    0    1   77   86 4037    4    0    2    2    0]\n",
      " [   0    3    0    0   13    0    0    1   19    0    0    0    2    6\n",
      "   130    0    0    8  106  419   62   55    0    0    0    0]\n",
      " [   0    0    0    0    8    0    0    0    4    0    0    0    4    2\n",
      "    61    0    0    0    6   69  163    6    2    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
      "     5    0    0    0    0    0   87    0    0    6    0    0]\n",
      " [   0   28    0    0   90    0    0    0  251    0    1    0    2    2\n",
      "    30    2    0    0    2    1    8    0    0    0  164    0]\n",
      " [   0    1    0    1   10    0    0    0    5    0    0    0    0    5\n",
      "    12    5    0    0    0    0    3    0    0    0    1    0]]\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "16Q2YK_uS-jI",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# os.path.exists('//content/drive/My Drive/Deep Fashion Retrieval/base/img/Leaf_Print-Sleeve_Tee/img_00000031.jpg')\n"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'May30_00-44-53'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  }
 ]
}